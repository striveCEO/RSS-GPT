<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>


<item>
<title>ChipmunkRing: A Practical Post-Quantum Ring Signature Scheme for Blockchain Applications</title>
<link>https://arxiv.org/abs/2510.09617</link>
<guid>https://arxiv.org/abs/2510.09617</guid>
<content:encoded><![CDATA[
arXiv:2510.09617v1 Announce Type: new 
Abstract: ChipmunkRing, a practical post-quantum ring signature construction tailored for blockchain environments. Building on our Chipmunk lattice-based cryptographic framework, this implementation delivers compact digital signatures ranging from 20.5 to 279.7KB, with rapid signing operations completing in 1.1-15.1ms and efficient validation processes requiring only 0.4-4.5ms for participant groups of 2-64 members. The cornerstone of our approach is Acorn Verification-a streamlined zero-knowledge protocol that supersedes the classical Fiat-Shamir methodology. This innovation enables linear O(n) authentication complexity using concise 96-byte cryptographic proofs per participant, yielding a remarkable 17.7x performance enhancement for 32-member rings when compared to conventional techniques. Our work includes rigorous mathematical security demonstrations confirming 112-bit post-quantum protection (NIST Level 1), extensive computational benchmarking, and comprehensive support for both standard anonymity sets and collaborative threshold constructions with flexible participation requirements.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematic Literature Review on Fundamental Technologies and Security Challenges in the Metaverse Platforms</title>
<link>https://arxiv.org/abs/2510.09621</link>
<guid>https://arxiv.org/abs/2510.09621</guid>
<content:encoded><![CDATA[
arXiv:2510.09621v1 Announce Type: new 
Abstract: The Metaverse utilizes emerging technologies such as Extended Reality (XR), Artificial Intelligence (AI), blockchain, and digital twins to provide an immersive and interactive virtual experience. As Metaverse continues to evolve, it bring a range of security and privacy threats, such as identity management, data governance, and user interactions. This survey aims to provide a comprehensive review of the enabling technologies for the Metaverse. It also aims to provide a thorough analysis of key vulnerabilities and threats that may compromise its sustainability and user safety. We perform a systematic literature review (SLR) to identify key vulnerabilities and their countermeasures in Metaverse platforms. Metaverse offers a much larger attack surface compared to conventional digital platforms. Immersive, decentralized, and permanent characteristics of the Metaverse generate new vulnerabilities. Although there are many countermeasures to these vulnerabilities, most of them are theoretical or have not been tested in real-world environments. Our review highlights current advancements, identifies research gaps, and outlines future directions to ensure a secure, resilient, and ethically governed Metaverse.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Transaction Tracing Techniques for Blockchain Systems</title>
<link>https://arxiv.org/abs/2510.09624</link>
<guid>https://arxiv.org/abs/2510.09624</guid>
<content:encoded><![CDATA[
arXiv:2510.09624v1 Announce Type: new 
Abstract: With the proliferation of new blockchain-based cryptocurrencies/assets and platforms that make it possible to transact across them, it becomes important to consider not just whether the transfer of coins/assets can be tracked within their respective transaction ledger, but also if they can be tracked as they move across ledgers. This is especially important given that there are documented cases of criminals attempting to use these cross-ledger trades to obscure the flow of their coins/assets. In this paper, we perform a systematic review of the various tracing techniques for blockchain transactions proposed in literature, categorize them using multiple criteria (such as tracing approach and targeted objective) and compare them. Based on the above categorization, we provide insights on the state of blockchain transaction tracing literature and identify the limitations of existing approaches. Finally, we suggest directions for future research in this area based on our analysis.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Scalable, Privacy-Preserving Decentralized Identity and Verifiable Data Sharing Framework based on Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2510.09715</link>
<guid>https://arxiv.org/abs/2510.09715</guid>
<content:encoded><![CDATA[
arXiv:2510.09715v1 Announce Type: new 
Abstract: With the proliferation of decentralized applications (DApps), the conflict between the transparency of blockchain technology and user data privacy has become increasingly prominent. While Decentralized Identity (DID) and Verifiable Credentials (VCs) provide a standardized framework for user data sovereignty, achieving trusted identity verification and data sharing without compromising privacy remains a significant challenge. This paper proposes a novel, comprehensive framework that integrates DIDs and VCs with efficient Zero-Knowledge Proof (ZKP) schemes to address this core issue. The key contributions of this framework are threefold: first, it constructs a set of strong privacy-preserving protocols based on zk-STARKs, allowing users to prove that their credentials satisfy specific conditions (e.g., "age is over 18") without revealing any underlying sensitive data. Second, it designs a scalable, privacy-preserving credential revocation mechanism based on cryptographic accumulators, effectively solving credential management challenges in large-scale scenarios. Finally, it integrates a practical social key recovery scheme, significantly enhancing system usability and security. Through a prototype implementation and performance evaluation, this paper quantitatively analyzes the framework's performance in terms of proof generation time, verification overhead, and on-chain costs. Compared to existing state-of-the-art systems based on zk-SNARKs, our framework, at the cost of a larger proof size, significantly improves prover efficiency for complex computations and provides stronger security guarantees, including no trusted setup and post-quantum security. Finally, a case study in the decentralized finance (DeFi) credit scoring scenario demonstrates the framework's immense potential for unlocking capital efficiency and fostering a trusted data economy.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zk-SNARK Marketplace with Proof of Useful Work</title>
<link>https://arxiv.org/abs/2510.09729</link>
<guid>https://arxiv.org/abs/2510.09729</guid>
<content:encoded><![CDATA[
arXiv:2510.09729v1 Announce Type: new 
Abstract: Proof of Work (PoW) is widely regarded as the most secure permissionless blockchain consensus protocol. However, its reliance on computationally intensive yet externally useless puzzles results in excessive electric energy wasting. To alleviate this, Proof of Useful Work (PoUW) has been explored as an alternative to secure blockchain platforms while also producing real-world value. Despite this promise, existing PoUW proposals often fail to embed the integrity of the chain and identity of the miner into the puzzle solutions, not meeting necessary requirements for PoW and thus rendering them vulnerable. In this work, we propose a PoUW consensus protocol that computes client-outsourced zk-SNARKs proofs as a byproduct, which are at the same time used to secure the consensus protocol. We further leverage this mechanism to design a decentralized marketplace for outsourcing zk-SNARK proof generation, which is, to the best of our knowledge, the first such marketplace operating at the consensus layer, while meeting all necessary properties of PoW.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Farewell to Westphalia: Crypto Sovereignty and Post-Nation-State Governaance</title>
<link>https://arxiv.org/abs/2510.09840</link>
<guid>https://arxiv.org/abs/2510.09840</guid>
<content:encoded><![CDATA[
arXiv:2510.09840v1 Announce Type: new 
Abstract: We argue that the principal application for blockchain technology will not be in the financial sector, but rather in maintaining decentralized human governance, from archives to transparent policies encoded in the blockchain in the form of smart contracts.. Such decentralized, blockchain-grounded governance comes not a moment too soon, as nation states are dissolving before our eyes. Will blockchain-based communities replace the nation state? What are the prospects and dangers of this development?
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Structured Cooperative Multi-Agent Reinforcement Learning: a Bayesian Network Perspective</title>
<link>https://arxiv.org/abs/2510.09937</link>
<guid>https://arxiv.org/abs/2510.09937</guid>
<content:encoded><![CDATA[
arXiv:2510.09937v1 Announce Type: new 
Abstract: The empirical success of multi-agent reinforcement learning (MARL) has motivated the search for more efficient and scalable algorithms for large scale multi-agent systems. However, existing state-of-the-art algorithms do not fully exploit inter-agent coupling information to develop MARL algorithms. In this paper, we propose a systematic approach to leverage structures in the inter-agent couplings for efficient model-free reinforcement learning. We model the cooperative MARL problem via a Bayesian network and characterize the subset of agents, termed as the value dependency set, whose information is required by each agent to estimate its local action value function exactly. Moreover, we propose a partially decentralized training decentralized execution (P-DTDE) paradigm based on the value dependency set. We theoretically establish that the total variance of our P-DTDE policy gradient estimator is less than the centralized training decentralized execution (CTDE) policy gradient estimator. We derive a multi-agent policy gradient theorem based on the P-DTDE scheme and develop a scalable actor-critic algorithm. We demonstrate the efficiency and scalability of the proposed algorithm on multi-warehouse resource allocation and multi-zone temperature control examples. For dense value dependency sets, we propose an approximation scheme based on truncation of the Bayesian network and empirically show that it achieves a faster convergence than the exact value dependence set for applications with a large number of agents.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Post-Quantum Cryptography and Quantum-Safe Security: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2510.10436</link>
<guid>https://arxiv.org/abs/2510.10436</guid>
<content:encoded><![CDATA[
arXiv:2510.10436v1 Announce Type: new 
Abstract: Post-quantum cryptography (PQC) is moving from evaluation to deployment as NIST finalizes standards for ML-KEM, ML-DSA, and SLH-DSA. This survey maps the space from foundations to practice. We first develop a taxonomy across lattice-, code-, hash-, multivariate-, isogeny-, and MPC-in-the-Head families, summarizing security assumptions, cryptanalysis, and standardization status. We then compare performance and communication costs using representative, implementation-grounded measurements, and review hardware acceleration (AVX2, FPGA/ASIC) and implementation security with a focus on side-channel resistance. Building upward, we examine protocol integration (TLS, DNSSEC), PKI and certificate hygiene, and deployment in constrained and high-assurance environments (IoT, cloud, finance, blockchain). We also discuss complementarity with quantum technologies (QKD, QRNGs) and the limits of near-term quantum computing. Throughout, we emphasize crypto-agility, hybrid migration, and evidence-based guidance for operators. We conclude with open problems spanning parameter agility, leakage-resilient implementations, and domain-specific rollout playbooks. This survey aims to be a practical reference for researchers and practitioners planning quantum-safe systems, bridging standards, engineering, and operations.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multitask Learning with Learned Task Relationships</title>
<link>https://arxiv.org/abs/2510.10570</link>
<guid>https://arxiv.org/abs/2510.10570</guid>
<content:encoded><![CDATA[
arXiv:2510.10570v1 Announce Type: new 
Abstract: Classical consensus-based strategies for federated and decentralized learning are statistically suboptimal in the presence of heterogeneous local data or task distributions. As a result, in recent years, there has been growing interest in multitask or personalized strategies, which allow individual agents to benefit from one another in pursuing locally optimal models without enforcing consensus. Existing strategies require either precise prior knowledge of the underlying task relationships or are fully non-parametric and instead rely on meta-learning or proximal constructions. In this work, we introduce an algorithmic framework that strikes a balance between these extremes. By modeling task relationships through a Gaussian Markov Random Field with an unknown precision matrix, we develop a strategy that jointly learns both the task relationships and the local models, allowing agents to self-organize in a way consistent with their individual data distributions. Our theoretical analysis quantifies the quality of the learned relationship, and our numerical experiments demonstrate its practical effectiveness.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toxic Ink on Immutable Paper: Content Moderation for Ethereum Input Data Messages (IDMs)</title>
<link>https://arxiv.org/abs/2510.10761</link>
<guid>https://arxiv.org/abs/2510.10761</guid>
<content:encoded><![CDATA[
arXiv:2510.10761v1 Announce Type: new 
Abstract: Decentralized communication is becoming an important use case within Web3. On Ethereum, users can repurpose the transaction input data field to embed natural-language messages, commonly known as Input Data Messages (IDMs). However, as IDMs gain wider adoption, there has been a growing volume of toxic content on-chain. This trend is concerning, as Ethereum provides no protocol-level support for content moderation.
  We propose two moderation frameworks for Ethereum IDMs: (i) BUILDERMOD, where builders perform semantic checks during block construction; and (ii) USERMOD, where users proactively obtain moderation proofs from external classifiers and embed them in transactions. Our evaluation reveals that BUILDERMOD incurs high block-time overhead, which limits its practicality. In contrast, USERMOD enables lower-latency validation and scales more effectively, making it a more practical approach in moderation-aware Ethereum environments.
  Our study lays the groundwork for protocol-level content governance in decentralized systems, and we hope it contributes to the development of a decentralized communication environment that is safe, trustworthy, and socially responsible.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stabilizing the Staking Rate, Dynamically Distributed Inflation and Delay Induced Oscillations</title>
<link>https://arxiv.org/abs/2510.11065</link>
<guid>https://arxiv.org/abs/2510.11065</guid>
<content:encoded><![CDATA[
arXiv:2510.11065v1 Announce Type: new 
Abstract: Dynamically distributed inflation is a common mechanism used to guide a blockchain's staking rate towards a desired equilibrium between network security and token liquidity.
  However, the high sensitivity of the annual percentage yield to changes in the staking rate, coupled with the inherent feedback delays in staker responses, can induce undesirable oscillations around this equilibrium.
  This paper investigates this instability phenomenon. We analyze the dynamics of inflation-based reward systems and propose a novel distribution model designed to stabilize the staking rate. Our solution effectively dampens oscillations, stabilizing the yield within a target staking range.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Decentralized Microservice Scheduling Approach Using Service Mesh in Cloud-Edge Systems</title>
<link>https://arxiv.org/abs/2510.11189</link>
<guid>https://arxiv.org/abs/2510.11189</guid>
<content:encoded><![CDATA[
arXiv:2510.11189v1 Announce Type: new 
Abstract: As microservice-based systems scale across the cloud-edge continuum, traditional centralized scheduling mechanisms increasingly struggle with latency, coordination overhead, and fault tolerance. This paper presents a new architectural direction: leveraging service mesh sidecar proxies as decentralized, in-situ schedulers to enable scalable, low-latency coordination in large-scale, cloud-native environments. We propose embedding lightweight, autonomous scheduling logic into each sidecar, allowing scheduling decisions to be made locally without centralized control. This approach leverages the growing maturity of service mesh infrastructures, which support programmable distributed traffic management. We describe the design of such an architecture and present initial results demonstrating its scalability potential in terms of response time and latency under varying request rates. Rather than delivering a finalized scheduling algorithm, this paper presents a system-level architectural direction and preliminary evidence to support its scalability potential.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Fast-Converging Decentralized Approach to the Weighted Minimum Vertex Cover Problem</title>
<link>https://arxiv.org/abs/2510.11697</link>
<guid>https://arxiv.org/abs/2510.11697</guid>
<content:encoded><![CDATA[
arXiv:2510.11697v1 Announce Type: new 
Abstract: We address the problem of computing a Minimum Weighted Vertex Cover (MWVC) in a decentralized network. MWVC, a classical NP-hard problem, is foundational in applications such as network monitoring and resource placement. We propose a fully decentralized protocol where each node makes decisions using only local knowledge and communicates with its neighbors. The method is adaptive, communication-efficient, and avoids centralized coordination. We evaluate the protocol on real-world and synthetic graphs, comparing it to both centralized and decentralized baselines. Our results demonstrate competitive solution quality with reduced communication overhead, highlighting the feasibility of MWVC computation in decentralized environments.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exposing the Vulnerability of Decentralized Learning to Membership Inference Attacks Through the Lens of Graph Mixing</title>
<link>https://arxiv.org/abs/2412.12837</link>
<guid>https://arxiv.org/abs/2412.12837</guid>
<content:encoded><![CDATA[
arXiv:2412.12837v3 Announce Type: replace 
Abstract: The primary promise of decentralized learning is to allow users to engage in the training of machine learning models in a collaborative manner while keeping their data on their premises and without relying on any central entity. However, this paradigm necessitates the exchange of model parameters or gradients between peers. Such exchanges can be exploited to infer sensitive information about training data, which is achieved through privacy attacks (e.g., Membership Inference Attacks -- MIA). In order to devise effective defense mechanisms, it is important to understand the factors that increase/reduce the vulnerability of a given decentralized learning architecture to MIA. In this study, we extensively explore the vulnerability to MIA of various decentralized learning architectures by varying the graph structure (e.g., number of neighbors), the graph dynamics, and the aggregation strategy, across diverse datasets and data distributions. Our key finding, which to the best of our knowledge we are the first to report, is that the vulnerability to MIA is heavily correlated to (i) the local model mixing strategy performed by each node upon reception of models from neighboring nodes and (ii) the global mixing properties of the communication graph. We illustrate these results experimentally using four datasets and by theoretically analyzing the mixing properties of various decentralized architectures. We also empirically show that enhancing mixing properties is highly beneficial when combined with other privacy-preserving techniques such as Differential Privacy. Our paper draws a set of lessons learned for devising decentralized learning systems that reduce by design the vulnerability to MIA.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Clustering Deposit and Withdrawal Activity in Tornado Cash: A Cross-Chain Analysis</title>
<link>https://arxiv.org/abs/2510.09433</link>
<guid>https://arxiv.org/abs/2510.09433</guid>
<content:encoded><![CDATA[
arXiv:2510.09433v2 Announce Type: replace 
Abstract: Tornado Cash is a decentralised mixer that uses cryptographic techniques to sever the on-chain trail between depositors and withdrawers. In practice, however, its anonymity can be undermined by user behaviour and operational quirks. We conduct the first cross-chain empirical study of Tornado Cash activity on Ethereum, BNB Smart Chain, and Polygon, introducing three clustering heuristics-(i) address-reuse, (ii) transactional-linkage, and (iii) a novel first-in-first-out (FIFO) temporal-matching rule. Together, these heuristics reconnect deposits to withdrawals and deanonymise a substantial share of recipients. Our analysis shows that 5.1 - 12.6% of withdrawals can already be traced to their originating deposits through address reuse and transactional linkage heuristics. Adding our novel First-In-First-Out (FIFO) temporal-matching heuristic lifts the linkage rate by a further 15 - 22 percentage points. Statistical tests confirm that these FIFO matches are highly unlikely to occur by chance. Comparable leakage across Ethereum, BNB Smart Chain, and Polygon indicates chain-agnostic user misbehaviour, rather than chain-specific protocol flaws. These results expose how quickly cryptographic guarantees can unravel in everyday use, underscoring the need for both disciplined user behaviour and privacy-aware protocol design. In total, our heuristics link over $2.3 billion in Tornado Cash withdrawals to identifiable deposits, exposing significant cracks in practical anonymity.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Impact of Sanctions on decentralised Privacy Tools: A Case Study of Tornado Cash</title>
<link>https://arxiv.org/abs/2510.09443</link>
<guid>https://arxiv.org/abs/2510.09443</guid>
<content:encoded><![CDATA[
arXiv:2510.09443v2 Announce Type: replace 
Abstract: This paper investigates the impact of sanctions on Tornado Cash, a smart contract protocol designed to enhance transaction privacy. Following the U.S. Department of the Treasury's sanctions against Tornado Cash in August 2022, platform activity declined sharply. We document a significant and sustained reduction in transaction volume, user diversity, and overall protocol utilization after the sanctions were imposed. Our analysis draws on transaction data from three major blockchains: Ethereum, BNB Smart Chain, and Polygon. We further examine developments following the partial lifting and eventual removal of sanctions by the U.S. Office of Foreign Assets Control (OFAC) in March 2025. Although activity partially recovered, the rebound remained limited. The Tornado Cash case illustrates how regulatory interventions can affect decentralized protocols, while also highlighting the challenges of fully enforcing such measures in decentralized environments.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks</title>
<link>https://arxiv.org/abs/2510.06349</link>
<guid>https://arxiv.org/abs/2510.06349</guid>
<content:encoded><![CDATA[
arXiv:2510.06349v1 Announce Type: new 
Abstract: Foundation models have rapidly advanced AI, raising the question of whether their decisions will ultimately surpass human strategies in real-world domains. The exponential, and possibly super-exponential, pace of AI development makes such analysis elusive. Nevertheless, many application areas that matter for daily life and society show only modest gains so far; a prominent case is diagnosing and treating dynamically evolving disease in intensive care.
  The common challenge is adapting complex systems to dynamic environments. Effective strategies must optimize outcomes in systems composed of strongly interacting functions while avoiding shared side effects; this requires reliable, self-adaptive modeling. These tasks align with building digital twins of highly complex systems whose mechanisms are not fully or quantitatively understood. It is therefore essential to develop methods for self-adapting AI models with minimal data and limited mechanistic knowledge. As this challenge extends beyond medicine, AI should demonstrate clear superiority in these settings before assuming broader decision-making roles.
  We identify the curse of dimensionality as a fundamental barrier to efficient self-adaptation and argue that monolithic foundation models face conceptual limits in overcoming it. As an alternative, we propose a decentralized architecture of interacting small agent networks (SANs). We focus on agents representing the specialized substructure of the system, where each agent covers only a subset of the full system functions. Drawing on mathematical results on the learning behavior of SANs and evidence from existing applications, we argue that swarm-learning in diverse swarms can enable self-adaptive SANs to deliver superior decision-making in dynamic environments compared with monolithic foundation models, though at the cost of reduced reproducibility in detail.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>R3R: Decentralized Multi-Agent Collision Avoidance with Infinite-Horizon Safety</title>
<link>https://arxiv.org/abs/2510.06436</link>
<guid>https://arxiv.org/abs/2510.06436</guid>
<content:encoded><![CDATA[
arXiv:2510.06436v1 Announce Type: new 
Abstract: Existing decentralized methods for multi-agent motion planning lack formal, infinite-horizon safety guarantees, especially for communication-constrained systems. We present R3R, to our knowledge the first decentralized and asynchronous framework for multi-agent motion planning under distance-based communication constraints with infinite-horizon safety guarantees for systems of nonlinear agents. R3R's novelty lies in combining our gatekeeper safety framework with a geometric constraint called R-Boundedness, which together establish a formal link between an agent's communication radius and its ability to plan safely. We constrain trajectories to within a fixed planning radius that is a function of the agent's communication radius, which enables trajectories to be shown provably safe for all time, using only local information. Our algorithm is fully asynchronous, and ensures the forward invariance of these guarantees even in time-varying networks where agents asynchronously join, leave, and replan. We validate our approach in simulations of up to 128 Dubins vehicles, demonstrating 100% safety in dense, obstacle rich scenarios. Our results demonstrate that R3R's performance scales with agent density rather than problem size, providing a practical solution for scalable and provably safe multi-agent systems.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks</title>
<link>https://arxiv.org/abs/2510.06444</link>
<guid>https://arxiv.org/abs/2510.06444</guid>
<content:encoded><![CDATA[
arXiv:2510.06444v1 Announce Type: new 
Abstract: In decentralized learning networks, predictions from many participants are combined to generate a network inference. While many studies have demonstrated performance benefits of combining multiple model predictions, existing strategies using linear pooling methods (ranging from simple averaging to dynamic weight updates) face a key limitation. Dynamic prediction combinations that rely on historical performance to update weights are necessarily reactive. Due to the need to average over a reasonable number of epochs (with moving averages or exponential weighting), they tend to be slow to adjust to changing circumstances (phase or regime changes). In this work, we develop a model that uses machine learning to forecast the performance of predictions by models at each epoch in a time series. This enables `context-awareness' by assigning higher weight to models that are likely to be more accurate at a given time. We show that adding a performance forecasting worker in a decentralized learning network, following a design similar to the Allora network, can improve the accuracy of network inferences. Specifically, we find forecasting models that predict regret (performance relative to the network inference) or regret z-score (performance relative to other workers) show greater improvement than models predicting losses, which often do not outperform the naive network inference (historically weighted average of all inferences). Through a series of optimization tests, we show that the performance of the forecasting model can be sensitive to choices in the feature set and number of training epochs. These properties may depend on the exact problem and should be tailored to each domain. Although initially designed for a decentralized learning network, using performance forecasting for prediction combination may be useful in any situation where predictive rather than reactive model weighting is needed.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Fronthaul Quantization for Flexible User Load in Cell-Free Massive MIMO</title>
<link>https://arxiv.org/abs/2510.06734</link>
<guid>https://arxiv.org/abs/2510.06734</guid>
<content:encoded><![CDATA[
arXiv:2510.06734v1 Announce Type: new 
Abstract: We investigate the physical layer (PHY) spectral efficiency and fronthaul network load of a scalable user-centric cell-free massive MIMO system. Each user-centric cluster processor responsible for cluster-level signal processing is located at one of multiple decentralized units (DUs). Thus, the radio units in the cluster must exchange data with the corresponding DU over the fronthaul. Because the fronthaul links have limited capacity, this data must be quantized before it is sent over the fronthaul. We consider a routed fronthaul network, where the cluster processor placement and fronthaul traffic routing are jointly optimized with a mixed-integer linear program. For different numbers of users in the network, we investigate the effect of fronthaul quantization rates, a system parameter computed based on rate-distortion theory. Our results show that with optimized quantization rates, the fronthaul load is quite stable for a wide range of user loads without significant PHY performance loss. This demonstrates that the cell-free massive MIMO PHY and fronthaul network are resilient to varying user densities.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bionetta: Efficient Client-Side Zero-Knowledge Machine Learning Proving</title>
<link>https://arxiv.org/abs/2510.06784</link>
<guid>https://arxiv.org/abs/2510.06784</guid>
<content:encoded><![CDATA[
arXiv:2510.06784v1 Announce Type: new 
Abstract: In this report, we compare the performance of our UltraGroth-based zero-knowledge machine learning framework Bionetta to other tools of similar purpose such as EZKL, Lagrange's deep-prove, or zkml. The results show a significant boost in the proving time for custom-crafted neural networks: they can be proven even on mobile devices, enabling numerous client-side proving applications. While our scheme increases the cost of one-time preprocessing steps, such as circuit compilation and generating trusted setup, our approach is, to the best of our knowledge, the only one that is deployable on the native EVM smart contracts without overwhelming proof size and verification overheads.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized CBF-based Safety Filters for Collision Avoidance of Cooperative Missile Systems with Input Constraints</title>
<link>https://arxiv.org/abs/2510.06846</link>
<guid>https://arxiv.org/abs/2510.06846</guid>
<content:encoded><![CDATA[
arXiv:2510.06846v1 Announce Type: new 
Abstract: This paper presents a decentralized safety filter for collision avoidance in multi-agent aerospace interception scenarios. The approach leverages robust control barrier functions (RCBFs) to guarantee forward invariance of safety sets under bounded inputs and high-relative-degree dynamics. Each effector executes its nominal cooperative guidance command, while a local quadratic program (QP) modifies the input only when necessary. Event-triggered activation based on range and zero-effort miss (ZEM) criteria ensures scalability by restricting active constraints to relevant neighbors. To resolve feasibility issues from simultaneous constraints, a slack-variable relaxation scheme is introduced that prioritizes critical agents in a Pareto-optimal manner. Simulation results in many-on-many interception scenarios demonstrate that the proposed framework maintains collision-free operation with minimal deviation from nominal guidance, providing a computationally efficient and scalable solution for safety-critical multi-agent aerospace systems.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy</title>
<link>https://arxiv.org/abs/2510.07022</link>
<guid>https://arxiv.org/abs/2510.07022</guid>
<content:encoded><![CDATA[
arXiv:2510.07022v1 Announce Type: new 
Abstract: Machine unlearning is critical for enforcing data deletion rights like the "right to be forgotten." As a decentralized paradigm, Federated Learning (FL) also requires unlearning, but realistic implementations face two major challenges. First, fairness in Federated Unlearning (FU) is often overlooked. Exact unlearning methods typically force all clients into costly retraining, even those uninvolved. Approximate approaches, using gradient ascent or distillation, make coarse interventions that can unfairly degrade performance for clients with only retained data. Second, most FU evaluations rely on synthetic data assumptions (IID/non-IID) that ignore real-world heterogeneity. These unrealistic benchmarks obscure the true impact of unlearning and limit the applicability of current methods. We first conduct a comprehensive benchmark of existing FU methods under realistic data heterogeneity and fairness conditions. We then propose a novel, fairness-aware FU approach, Federated Cross-Client-Constrains Unlearning (FedCCCU), to explicitly address both challenges. FedCCCU offers a practical and scalable solution for real-world FU. Experimental results show that existing methods perform poorly in realistic settings, while our approach consistently outperforms them.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer Seed Manipulations in Blockchains</title>
<link>https://arxiv.org/abs/2510.07080</link>
<guid>https://arxiv.org/abs/2510.07080</guid>
<content:encoded><![CDATA[
arXiv:2510.07080v1 Announce Type: new 
Abstract: This study tackles the computational challenges of solving Markov Decision Processes (MDPs) for a restricted class of problems. It is motivated by the Last Revealer Attack (LRA), which undermines fairness in some Proof-of-Stake (PoS) blockchains such as Ethereum (\$400B market capitalization). We introduce pseudo-MDPs (pMDPs) a framework that naturally models such problems and propose two distinct problem reductions to standard MDPs. One problem reduction provides a novel, counter-intuitive perspective, and combining the two problem reductions enables significant improvements in dynamic programming algorithms such as value iteration. In the case of the LRA which size is parameterized by $\kappa$ (in Ethereum's case $\kappa$ = 32), we reduce the computational complexity from O(2^$\kappa$ $\kappa$^2^($\kappa$+2)) to O($\kappa$^4) (per iteration). This solution also provide the usual benefits from Dynamic Programming solutions: exponentially fast convergence toward the optimal solution is guaranteed. The dual perspective also simplifies policy extraction, making the approach well-suited for resource-constrained agents who can operate with very limited memory and computation once the problem has been solved. Furthermore, we generalize those results to a broader class of MDPs, enhancing their applicability. The framework is validated through two case studies: a fictional card game and the LRA on the Ethereum random seed consensus protocol. These applications demonstrate the framework's ability to solve large-scale problems effectively while offering actionable insights into optimal strategies. This work advances the study of MDPs and contributes to understanding security vulnerabilities in blockchain systems.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RevealNet: Distributed Traffic Correlation for Attack Attribution on Programmable Networks</title>
<link>https://arxiv.org/abs/2505.00618</link>
<guid>https://arxiv.org/abs/2505.00618</guid>
<content:encoded><![CDATA[
arXiv:2505.00618v2 Announce Type: replace 
Abstract: Network attackers have increasingly resorted to proxy chains, VPNs, and anonymity networks to conceal their activities. To tackle this issue, past research has explored the applicability of traffic correlation techniques to perform attack attribution, i.e., to identify an attacker's true network location. However, current traffic correlation approaches rely on well-provisioned and centralized systems that ingest flows from multiple network probes to compute correlation scores. Unfortunately, this makes correlation efforts scale poorly for large high-speed networks.
  In this paper, we propose RevealNet, a decentralized framework for attack attribution that orchestrates a fleet of P4-programmable switches to perform traffic correlation. RevealNet builds on a set of correlation primitives inspired by prior work on computing and comparing flow sketches -- compact summaries of flows' key characteristics -- to enable efficient, distributed, in-network traffic correlation. Our evaluation suggests that RevealNet achieves comparable accuracy to centralized attack attribution systems while significantly reducing both the computational complexity and bandwidth overheads imposed by correlation tasks.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentZero++: Modeling Fear-Based Behavior</title>
<link>https://arxiv.org/abs/2510.05185</link>
<guid>https://arxiv.org/abs/2510.05185</guid>
<content:encoded><![CDATA[
arXiv:2510.05185v1 Announce Type: new 
Abstract: We present AgentZero++, an agent-based model that integrates cognitive, emotional, and social mechanisms to simulate decentralized collective violence in spatially distributed systems. Building on Epstein's Agent\_Zero framework, we extend the original model with eight behavioral enhancements: age-based impulse control; memory-based risk estimation; affect-cognition coupling; endogenous destructive radius; fight-or-flight dynamics; affective homophily; retaliatory damage; and multi-agent coordination. These additions allow agents to adapt based on internal states, previous experiences, and social feedback, producing emergent dynamics such as protest asymmetries, escalation cycles, and localized retaliation. Implemented in Python using the Mesa ABM framework, AgentZero++ enables modular experimentation and visualization of how micro-level cognitive heterogeneity shapes macro-level conflict patterns. Our results highlight how small variations in memory, reactivity, and affective alignment can amplify or dampen unrest through feedback loops. By explicitly modeling emotional thresholds, identity-driven behavior, and adaptive networks, this work contributes a flexible and extensible platform for analyzing affective contagion and psychologically grounded collective action.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Constraint-Level Design of zkEVMs: Architectures, Trade-offs, and Evolution</title>
<link>https://arxiv.org/abs/2510.05376</link>
<guid>https://arxiv.org/abs/2510.05376</guid>
<content:encoded><![CDATA[
arXiv:2510.05376v1 Announce Type: new 
Abstract: Zero-knowledge Ethereum Virtual Machines (zkEVMs) must reconcile a fundamental contradiction: the Ethereum Virtual Machine was designed for transparent sequential execution, while zero-knowledge proofs require algebraic circuit representations. This survey provides the first systematic analysis of how existing major production zkEVM implementations resolve this tension through distinct constraint engineering strategies. We develop a comparative framework that maps the design space across three architectural dimensions. First, arithmetization schemes reveal stark trade-offs: R1CS requires compositional gadget libraries, PLONKish achieves elegance through custom gates that capture complex EVM opcodes in single constraints, while the homogeneous structure of AIR fundamentally mismatches the irregular instruction set of EVM. Second, dispatch mechanisms determine constraint activation patterns: selector-based systems waste trace width on inactive constraints, while ROM-based approaches trade memory lookups for execution flexibility. Third, the Type 1-4 spectrum quantifies an inescapable trade-off: the bit-level EVM compatibility of Type 1 demands significantly higher constraint complexity than the custom instruction sets of Type 4. Beyond cataloging implementations, we identify critical open problems across multiple domains: performance barriers preventing sub-second proving, absence of formal verification for constraint-to-EVM semantic equivalence, lack of standardized benchmarking frameworks, and architectural gaps in hybrid zkEVM/zkVM designs, decentralized prover coordination, privacy preservation, and interoperability.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mechanism design and equilibrium analysis of smart contract mediated resource allocation</title>
<link>https://arxiv.org/abs/2510.05504</link>
<guid>https://arxiv.org/abs/2510.05504</guid>
<content:encoded><![CDATA[
arXiv:2510.05504v1 Announce Type: new 
Abstract: Decentralized coordination and digital contracting are becoming critical in complex industrial ecosystems, yet existing approaches often rely on ad hoc heuristics or purely technical blockchain implementations without a rigorous economic foundation. This study develops a mechanism design framework for smart contract-based resource allocation that explicitly embeds efficiency and fairness in decentralized coordination. We establish the existence and uniqueness of contract equilibria, extending classical results in mechanism design, and introduce a decentralized price adjustment algorithm with provable convergence guarantees that can be implemented in real time. To evaluate performance, we combine extensive synthetic benchmarks with a proof-of-concept real-world dataset (MovieLens). The synthetic tests probe robustness under fee volatility, participation shocks, and dynamic demand, while the MovieLens case study illustrates how the mechanism can balance efficiency and fairness in realistic allocation environments. Results demonstrate that the proposed mechanism achieves substantial improvements in both efficiency and equity while remaining resilient to abrupt perturbations, confirming its stability beyond steady state analysis. The findings highlight broad managerial and policy relevance for supply chains, logistics, energy markets, healthcare resource allocation, and public infrastructure, where transparent and auditable coordination is increasingly critical. By combining theoretical rigor with empirical validation, the study shows how digital contracts can serve not only as technical artifacts but also as institutional instruments for transparency, accountability, and resilience in high-stakes resource allocation.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation</title>
<link>https://arxiv.org/abs/2510.05536</link>
<guid>https://arxiv.org/abs/2510.05536</guid>
<content:encoded><![CDATA[
arXiv:2510.05536v1 Announce Type: new 
Abstract: Accurate pose and velocity estimation is essential for effective spatial task planning in robotic manipulators. While centralized sensor fusion has traditionally been used to improve pose estimation accuracy, this paper presents a novel decentralized fusion approach to estimate both pose and velocity. We use dual-view measurements from an eye-in-hand and an eye-to-hand vision sensor configuration mounted on a manipulator to track a target object whose motion is modeled as random walk (stochastic acceleration model). The robot runs two independent adaptive extended Kalman filters formulated on a matrix Lie group, developed as part of this work. These filters predict poses and velocities on the manifold $\mathbb{SE}(3) \times \mathbb{R}^3 \times \mathbb{R}^3$ and update the state on the manifold $\mathbb{SE}(3)$. The final fused state comprising the fused pose and velocities of the target is obtained using a correlation-aware fusion rule on Lie groups. The proposed method is evaluated on a UFactory xArm 850 equipped with Intel RealSense cameras, tracking a moving target. Experimental results validate the effectiveness and robustness of the proposed decentralized dual-view estimation framework, showing consistent improvements over state-of-the-art methods.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving On-chain Permissioning for KYC-Compliant Decentralized Applications</title>
<link>https://arxiv.org/abs/2510.05807</link>
<guid>https://arxiv.org/abs/2510.05807</guid>
<content:encoded><![CDATA[
arXiv:2510.05807v1 Announce Type: new 
Abstract: Decentralized applications (dApps) in Decentralized Finance (DeFi) face a fundamental tension between regulatory compliance requirements like Know Your Customer (KYC) and maintaining decentralization and privacy. Existing permissioned DeFi solutions often fail to adequately protect private attributes of dApp users and introduce implicit trust assumptions, undermining the blockchain's decentralization. Addressing these limitations, this paper presents a novel synthesis of Self-Sovereign Identity (SSI), Zero-Knowledge Proofs (ZKPs), and Attribute-Based Access Control to enable privacy-preserving on-chain permissioning based on decentralized policy decisions. We provide a comprehensive framework for permissioned dApps that aligns decentralized trust, privacy, and transparency, harmonizing blockchain principles with regulatory compliance. Our framework supports multiple proof types (equality, range, membership, and time-dependent) with efficient proof generation through a commit-and-prove scheme that moves credential authenticity verification outside the ZKP circuit. Experimental evaluation of our KYC-compliant DeFi implementation shows considerable performance improvement for different proof types compared to baseline approaches. We advance the state-of-the-art through a holistic approach, flexible proof mechanisms addressing diverse real-world requirements, and optimized proof generation enabling practical deployment.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models</title>
<link>https://arxiv.org/abs/2510.05943</link>
<guid>https://arxiv.org/abs/2510.05943</guid>
<content:encoded><![CDATA[
arXiv:2510.05943v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has become a pivotal component of large language model (LLM) post-training, and agentic RL extends this paradigm to operate as agents through multi-turn interaction and tool use. Scaling such systems exposes two practical bottlenecks: (1) context length grows rapidly during training, inflating memory usage and latency, and triggering out-of-memory (OOM) failures; and (2) intermediate tensors accumulate with context length, making cross-device data movement a major system bottleneck.
  We present EARL, a scalable system for efficient agentic RL. EARL designs a parallelism selector that dynamically adapts model and training parallelism across RL stages based on sequence length and system load, and a data dispatcher that performs layout-aware, decentralized exchange of intermediate data batches. Together, these components increase throughput, reduce long-context failures, and enable stable large-scale training of agentic LLMs without relying on hard limits or penalties of context length.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Robot Distributed Optimization for Exploration and Mapping of Unknown Environments using Bioinspired Tactile-Sensor</title>
<link>https://arxiv.org/abs/2510.06085</link>
<guid>https://arxiv.org/abs/2510.06085</guid>
<content:encoded><![CDATA[
arXiv:2510.06085v1 Announce Type: new 
Abstract: This project proposes a bioinspired multi-robot system using Distributed Optimization for efficient exploration and mapping of unknown environments. Each robot explores its environment and creates a map, which is afterwards put together to form a global 2D map of the environment. Inspired by wall-following behaviors, each robot autonomously explores its neighborhood based on a tactile sensor, similar to the antenna of a cockroach, mounted on the surface of the robot. Instead of avoiding obstacles, robots log collision points when they touch obstacles. This decentralized control strategy ensures effective task allocation and efficient exploration of unknown terrains, with applications in search and rescue, industrial inspection, and environmental monitoring. The approach was validated through experiments using e-puck robots in a simulated 1.5 x 1.5 m environment with three obstacles. The results demonstrated the system's effectiveness in achieving high coverage, minimizing collisions, and constructing accurate 2D maps.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improved High-probability Convergence Guarantees of Decentralized SGD</title>
<link>https://arxiv.org/abs/2510.06141</link>
<guid>https://arxiv.org/abs/2510.06141</guid>
<content:encoded><![CDATA[
arXiv:2510.06141v1 Announce Type: new 
Abstract: Convergence in high-probability (HP) has been receiving increasing interest, due to its attractive properties, such as exponentially decaying tail bounds and strong guarantees for each individual run of an algorithm. While HP guarantees are extensively studied in centralized settings, much less is understood in the decentralized, networked setup. Existing HP studies in decentralized settings impose strong assumptions, like uniformly bounded gradients, or asymptotically vanishing noise, resulting in a significant gap between assumptions used to establish convergence in the HP and the mean-squared error (MSE) sense, even for vanilla Decentralized Stochastic Gradient Descent ($\mathtt{DSGD}$) algorithm. This is contrary to centralized settings, where it is known that $\mathtt{SGD}$ converges in HP under the same conditions on the cost function as needed to guarantee MSE convergence. Motivated by this observation, we revisit HP guarantees for $\mathtt{DSGD}$ in the presence of light-tailed noise. We show that $\mathtt{DSGD}$ converges in HP under the same conditions on the cost as in the MSE sense, removing uniformly bounded gradients and other restrictive assumptions, while simultaneously achieving order-optimal rates for both non-convex and strongly convex costs. Moreover, our improved analysis yields linear speed-up in the number of users, demonstrating that $\mathtt{DSGD}$ maintains strong performance in the HP sense and matches existing MSE guarantees. Our improved results stem from a careful analysis of the MGF of quantities of interest (norm-squared of gradient or optimality gap) and the MGF of the consensus gap between users' models. To achieve linear speed-up, we provide a novel result on the variance-reduction effect of decentralized methods in the HP sense and more fine-grained bounds on the MGF for strongly convex costs, which are both of independent interest.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Causal Coordination for Distributed Decision-Making</title>
<link>https://arxiv.org/abs/2401.16926</link>
<guid>https://arxiv.org/abs/2401.16926</guid>
<content:encoded><![CDATA[
arXiv:2401.16926v2 Announce Type: replace 
Abstract: In decentralized network control, communication plays a critical role by transforming local observations into shared knowledge, enabling agents to coordinate their actions. This paper investigates how communication facilitates cooperation behavior and therefore improves the overall performance in the vector-valued Witsenhausen counterexample, a canonical toy example in distributed decision-making. We consider setups where the encoder, i.e., the first decision-maker (DM) acts causally and the decoder, i.e., the second DM, operates noncausally, 1) without and 2) with access to channel feedback. Using a coordination coding framework, we characterize the achievable power-estimation cost regions in single-letter expressions for both scenarios. The first result is that, when restricted to Gaussian random variables, the cost is identical across all setups featuring at least one causal DM - regardless of the presence of feedback information. Next, building on the characterization of the power-estimation cost region, we propose a hybrid scheme that combines discrete quantization with a continuous Gaussian codebook - the Zero Estimation Cost (ZEC) scheme - which achieves an arbitrarily small estimation cost. This scheme uses coding tools that allow perfect reconstruction of the target symbols, leading to an asymptotic estimation cost equal to zero, while significantly reducing the asymptotic power consumption. Furthermore, when channel feedback is available at the first DM, we propose an analogous scheme that simultaneously achieves zero power and zero estimation cost in the low-noise regime.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Collective World Model for Emergent Communication and Coordination</title>
<link>https://arxiv.org/abs/2504.03353</link>
<guid>https://arxiv.org/abs/2504.03353</guid>
<content:encoded><![CDATA[
arXiv:2504.03353v3 Announce Type: replace 
Abstract: We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our decentralized approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?</title>
<link>https://arxiv.org/abs/2504.12961</link>
<guid>https://arxiv.org/abs/2504.12961</guid>
<content:encoded><![CDATA[
arXiv:2504.12961v3 Announce Type: replace 
Abstract: Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Concept to Measurement: A Survey of How the Blockchain Trilemma Is Analyzed</title>
<link>https://arxiv.org/abs/2505.03768</link>
<guid>https://arxiv.org/abs/2505.03768</guid>
<content:encoded><![CDATA[
arXiv:2505.03768v4 Announce Type: replace 
Abstract: The blockchain trilemma highlights the difficulty of simultaneously achieving a high degree of decentralization (DoD), scalability, and security in blockchain systems. While numerous constructs and metrics have been proposed to analyze these subconcepts, existing guidance is fragmented and inconsistent, limiting comparability across studies. This lack of clarity hinders practitioners in identifying Pareto-optimal blockchain system designs that meet common non-functional requirements. We systematically reviewed literature on the blockchain trilemma and blockchain benchmarks to synthesize constructs and their operationalizations through metrics to analyze the trilemma's subconcepts. We identified 12 constructs, operationalized through 15 metrics, that capture DoD, scalability, and security. We explain how these constructs apply across different blockchain systems and provide a structured overview that supports benchmarking and blockchain system design. Beyond blockchain, the findings offer insights for distributed database systems that rely on consensus and state machine replication. This work contributes a harmonized foundation for quantitative analyses of the blockchain trilemma, guiding both researchers in developing analysis approaches and practitioners in evaluating real-world systems.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Edge-FIT: Federated Instruction Tuning of Quantized LLMs for Privacy-Preserving Smart Home Environments</title>
<link>https://arxiv.org/abs/2510.03284</link>
<guid>https://arxiv.org/abs/2510.03284</guid>
<content:encoded><![CDATA[
arXiv:2510.03284v1 Announce Type: new 
Abstract: This paper proposes Edge-FIT (Federated Instruction Tuning on the Edge), a scalable framework for Federated Instruction Tuning (FIT) of Large Language Models (LLMs). Traditional Federated Learning (TFL) methods, like FedAvg, fail when confronted with the massive parameter size of LLMs [3], [6]. Our Edge-FIT framework combines federated learning with 4-bit Quantized Low-Rank Adaptation (QLORA), mitigating the core issues of communication and computational overhead. We demonstrate this by filtering the general-purpose Databricks Dolly 15k dataset for the IoT domain. Experimental results show the Edge-FIT tuned Llama 2(7B) achieves an F1-Score of 0.89. We also demonstrate a viable trade-off using the 3.8B Phi-3-mini model, validating Edge-FIT as a scalable framework for decentralized LLM deployment on home compute gateways.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Adaptive Responsible AI Governance Framework for Decentralized Organizations</title>
<link>https://arxiv.org/abs/2510.03368</link>
<guid>https://arxiv.org/abs/2510.03368</guid>
<content:encoded><![CDATA[
arXiv:2510.03368v1 Announce Type: new 
Abstract: This paper examines the assessment challenges of Responsible AI (RAI) governance efforts in globally decentralized organizations through a case study collaboration between a leading research university and a multinational enterprise. While there are many proposed frameworks for RAI, their application in complex organizational settings with distributed decision-making authority remains underexplored. Our RAI assessment, conducted across multiple business units and AI use cases, reveals four key patterns that shape RAI implementation: (1) complex interplay between group-level guidance and local interpretation, (2) challenges translating abstract principles into operational practices, (3) regional and functional variation in implementation approaches, and (4) inconsistent accountability in risk oversight. Based on these findings, we propose an Adaptive RAI Governance (ARGO) Framework that balances central coordination with local autonomy through three interdependent layers: shared foundation standards, central advisory resources, and contextual local implementation. We contribute insights from academic-industry collaboration for RAI assessments, highlighting the importance of modular governance approaches that accommodate organizational complexity while maintaining alignment with responsible AI principles. These lessons offer practical guidance for organizations navigating the transition from RAI principles to operational practice within decentralized structures.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Robust Clustered Federated Learning Approach for Non-IID Data with Quantity Skew</title>
<link>https://arxiv.org/abs/2510.03380</link>
<guid>https://arxiv.org/abs/2510.03380</guid>
<content:encoded><![CDATA[
arXiv:2510.03380v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized paradigm that enables a client-server architecture to collaboratively train a global Artificial Intelligence model without sharing raw data, thereby preserving privacy. A key challenge in FL is Non-IID data. Quantity Skew (QS) is a particular problem of Non-IID, where clients hold highly heterogeneous data volumes. Clustered Federated Learning (CFL) is an emergent variant of FL that presents a promising solution to Non-IID problem. It improves models' performance by grouping clients with similar data distributions into clusters. CFL methods generally fall into two operating strategies. In the first strategy, clients select the cluster that minimizes the local training loss. In the second strategy, the server groups clients based on local model similarities. However, most CFL methods lack systematic evaluation under QS but present significant challenges because of it.  In this paper, we present two main contributions. The first one is an evaluation of state-of-the-art CFL algorithms under various Non-IID settings, applying multiple QS scenarios to assess their robustness. Our second contribution is a novel iterative CFL algorithm, named CORNFLQS, which proposes an optimal coordination between both operating strategies of CFL. Our approach is robust against the different variations of QS settings. We conducted intensive experiments on six image classification datasets, resulting in 270 Non-IID configurations. The results show that CORNFLQS achieves the highest average ranking in both accuracy and clustering quality, as well as strong robustness to QS perturbations. Overall, our approach outperforms actual CFL algorithms.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Paris: A Decentralized Trained Open-Weight Diffusion Model</title>
<link>https://arxiv.org/abs/2510.03434</link>
<guid>https://arxiv.org/abs/2510.03434</guid>
<content:encoded><![CDATA[
arXiv:2510.03434v1 Announce Type: new 
Abstract: We present Paris, the first publicly released diffusion model pre-trained entirely through decentralized computation. Paris demonstrates that high-quality text-to-image generation can be achieved without centrally coordinated infrastructure. Paris is open for research and commercial use. Paris required implementing our Distributed Diffusion Training framework from scratch. The model consists of 8 expert diffusion models (129M-605M parameters each) trained in complete isolation with no gradient, parameter, or intermediate activation synchronization. Rather than requiring synchronized gradient updates across thousands of GPUs, we partition data into semantically coherent clusters where each expert independently optimizes its subset while collectively approximating the full distribution. A lightweight transformer router dynamically selects appropriate experts at inference, achieving generation quality comparable to centrally coordinated baselines. Eliminating synchronization enables training on heterogeneous hardware without specialized interconnects. Empirical validation confirms that Paris's decentralized training maintains generation quality while removing the dedicated GPU cluster requirement for large-scale diffusion models. Paris achieves this using 14$\times$ less training data and 16$\times$ less compute than the prior decentralized baseline.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A distributed routing protocol for sending data from things to the cloud leveraging fog technology in the large-scale IoT ecosystem</title>
<link>https://arxiv.org/abs/2510.03524</link>
<guid>https://arxiv.org/abs/2510.03524</guid>
<content:encoded><![CDATA[
arXiv:2510.03524v1 Announce Type: new 
Abstract: Fog computing integrates cloud and edge resources. According to an intelligent and decentralized method, this technology processes data generated by IoT sensors to seamlessly integrate physical and cyber environments. Internet of Things uses wireless and smart objects. They communicate with each other, monitor the environment, collect information, and respond to user requests. These objects have limited energy resources since they use batteries to supply energy. Also, they cannot replace their batteries. As a result, the network lifetime is limited and short. Thus, reducing energy consumption and accelerating the data transmission process are very important challenges in IoT networks to reduce the response time. In the data transmission process, selecting an appropriate cluster head node is very important because it can reduce the delay when sending data to the fog. In this paper, cluster head nodes are selected based on several important criteria such as distance, residual energy, received signal strength, and link expiration time. Then, objects send the processed data to the server hierarchically through a balanced tree. The simulation results show that the proposed method outperforms the energy-efficient centroid-based routing protocol (EECRP) and the Emergency Response IoT based on Global Information Decision (ERGID) in terms of packet delivery rate, delay, response time, and network lifetime.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning for Multi-Agent Coordination</title>
<link>https://arxiv.org/abs/2510.03592</link>
<guid>https://arxiv.org/abs/2510.03592</guid>
<content:encoded><![CDATA[
arXiv:2510.03592v1 Announce Type: new 
Abstract: We address the challenge of coordinating multiple robots in narrow and confined environments, where congestion and interference often hinder collective task performance. Drawing inspiration from insect colonies, which achieve robust coordination through stigmergy -- modifying and interpreting environmental traces -- we propose a Stigmergic Multi-Agent Deep Reinforcement Learning (S-MADRL) framework that leverages virtual pheromones to model local and social interactions, enabling decentralized emergent coordination without explicit communication. To overcome the convergence and scalability limitations of existing algorithms such as MADQN, MADDPG, and MAPPO, we leverage curriculum learning, which decomposes complex tasks into progressively harder sub-problems. Simulation results show that our framework achieves the most effective coordination of up to eight agents, where robots self-organize into asymmetric workload distributions that reduce congestion and modulate group performance. This emergent behavior, analogous to strategies observed in nature, demonstrates a scalable solution for decentralized multi-agent coordination in crowded environments with communication constraints.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Limits of Consensus under Dynamic Availability and Reconfiguration</title>
<link>https://arxiv.org/abs/2510.03625</link>
<guid>https://arxiv.org/abs/2510.03625</guid>
<content:encoded><![CDATA[
arXiv:2510.03625v1 Announce Type: new 
Abstract: Proof-of-stake blockchains require consensus protocols that support Dynamic Availability and Reconfiguration (so-called DAR setting), where the former means that the consensus protocol should remain live even if a large number of nodes temporarily crash, and the latter means it should be possible to change the set of operating nodes over time. State-of-the-art protocols for the DAR setting, such as Ethereum, Cardano's Ouroboros, or Snow White, require unrealistic additional assumptions, such as social consensus, or that key evolution is performed even while nodes are not participating. In this paper, we identify the necessary and sufficient adversarial condition under which consensus can be achieved in the DAR setting without additional assumptions. We then introduce a new and realistic additional assumption: honest nodes dispose of their cryptographic keys the moment they express intent to exit from the set of operating nodes. To add reconfiguration to any dynamically available consensus protocol, we provide a bootstrapping gadget that is particularly simple and efficient in the common optimistic case of few reconfigurations and no double-spending attempts.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Time-Bound Signature Scheme for Blockchains</title>
<link>https://arxiv.org/abs/2510.03697</link>
<guid>https://arxiv.org/abs/2510.03697</guid>
<content:encoded><![CDATA[
arXiv:2510.03697v1 Announce Type: new 
Abstract: We introduce a modified Schnorr signature scheme to allow for time-bound signatures for transaction fee auction bidding and smart contract purposes in a blockchain context, ensuring an honest producer can only validate a signature before a given block height. The immutable blockchain is used as a source of universal time for the signature scheme. We show the use of such a signature scheme leads to lower MEV revenue for builders. We then apply our time-bound signatures to Ethereum's EIP-1559 and show how it can be used to mitigate the effect of MEV on predicted equilibrium strategies.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Security Analysis of Ponzi Schemes in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2510.03819</link>
<guid>https://arxiv.org/abs/2510.03819</guid>
<content:encoded><![CDATA[
arXiv:2510.03819v1 Announce Type: new 
Abstract: The rapid advancement of blockchain technology has precipitated the widespread adoption of Ethereum and smart contracts across a variety of sectors. However, this has also given rise to numerous fraudulent activities, with many speculators embedding Ponzi schemes within smart contracts, resulting in significant financial losses for investors. Currently, there is a lack of effective methods for identifying and analyzing such new types of fraudulent activities. This paper categorizes these scams into four structural types and explores the intrinsic characteristics of Ponzi scheme contract source code from a program analysis perspective. The Mythril tool is employed to conduct static and dynamic analyses of representative cases, thereby revealing their vulnerabilities and operational mechanisms. Furthermore, this paper employs shell scripts and command patterns to conduct batch detection of open-source smart contract code, thereby unveiling the common characteristics of Ponzi scheme smart contracts.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Data Center Low-Voltage Ride-Through</title>
<link>https://arxiv.org/abs/2510.03867</link>
<guid>https://arxiv.org/abs/2510.03867</guid>
<content:encoded><![CDATA[
arXiv:2510.03867v1 Announce Type: new 
Abstract: Data center loads have expanded significantly in recent years. Compared to traditional loads, data centers are highly sensitive to voltage deviations and thus their protection mechanisms trip more proactively during voltage fluctuations. During a grid fault, simultaneous tripping of large-scale data centers can further destabilize the transmission system and even lead to cascading failures. In response, transmission system operators are imposing voltage ride-through (VRT) requirements for data centers. In this work, we enhance the VRT capability of data centers by designing voltage controllers for their internal power distribution network. We first systematically analyze VRT standards and the controllable resources related to data centers. These resources enable the design of voltage control strategies to regulate voltages internal to the data center, thereby allowing loads to remain online during voltage disturbances from the external transmission grid. We study and contrast both centralized and decentralized controllers that unify the control of heterogeneous flexible resources. Additionally, we construct an integrated test system that simulates both the transient fault response of the transmission system and the data center distribution network. Case studies demonstrate that the proposed voltage control mechanisms provide effective yet simple solutions to enhance data center low-voltage ride-through capability.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Why Does the Engineering Manager Still Exist in Agile Software Development?</title>
<link>https://arxiv.org/abs/2510.03920</link>
<guid>https://arxiv.org/abs/2510.03920</guid>
<content:encoded><![CDATA[
arXiv:2510.03920v1 Announce Type: new 
Abstract: Although Agile methodologies emphasize decentralized decision-making and team autonomy, engineering managers continue to be employed in Agile software organizations. This apparent paradox suggests that traditional managerial functions persist despite the theoretical displacement of managerial hierarchy in Agile. This paper explores the persistence of engineering managers through a multidimensional framework encompassing historical context, theoretical tensions, organizational realities, empirical evidence, evolving managerial roles, and practical implications. A systematic literature review underpins our multifaceted analysis, supplemented by illustrative case studies. We conclude by proposing a conceptual model that reconciles Agile principles with managerial necessity, offering guidance for practitioners, researchers, and tool designers. Implications for leadership development, tool integration, and future research are discussed.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative Flexibility Exchange: Fair and Comfort-Aware Decentralized Resource Allocation</title>
<link>https://arxiv.org/abs/2510.04192</link>
<guid>https://arxiv.org/abs/2510.04192</guid>
<content:encoded><![CDATA[
arXiv:2510.04192v1 Announce Type: new 
Abstract: The growing electricity demand and increased use of smart appliances are placing new pressures on power grids, making efficient energy management more important than ever. The existing energy management systems often prioritize system efficiency (balanced energy demand and supply) at the expense of user comfort. This paper addresses this gap by proposing a novel decentralized multi-agent coordination-based demand-side management system. The proposed system enables individual agents to coordinate for demand-side energy optimization while improving the user comfort and maintaining the system efficiency. A key innovation of this work is the introduction of a slot exchange mechanism, where agents first receive optimized appliance-level energy consumption schedules and then coordinate with each other to adjust these schedules through slot exchanges. This approach improves user comfort even when agents show non-altruistic behaviour, and it scales well with large populations. The system also promotes fairness by balancing satisfaction levels across users. For performance evaluation, a real-world dataset is used, and the results demonstrate that the proposed slot exchange mechanism increases user comfort and fairness without raising system inefficiency cost, making it a practical and scalable solution for future smart grids.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning</title>
<link>https://arxiv.org/abs/2510.04601</link>
<guid>https://arxiv.org/abs/2510.04601</guid>
<content:encoded><![CDATA[
arXiv:2510.04601v1 Announce Type: new 
Abstract: The current paradigm of training large language models (LLMs) on publicly available Web data is becoming unsustainable, with high-quality data sources in specialized domains nearing exhaustion. Federated Learning (FL) emerges as a practical solution for the next generation of AI on a decentralized Web, enabling privacy-preserving collaborative fine-tuning by leveraging private data distributed across a global client base. While Low-Rank Adaptation (LoRA) is the standard for efficient fine-tuning, its application in federated settings presents a critical challenge: communication overhead remains a significant bottleneck across the Web's heterogeneous network conditions. The structural redundancy within LoRA parameters not only incurs a heavy communication burden but also introduces conflicts when aggregating client updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose framework designed for communication-efficient FL. We first introduce an importance-aware sparsification method that preserves the structural integrity of LoRA updates to reduce the uploaded parameter count. The server then reconstructs and aggregates these updates in a full-rank space to mitigate conflicts. Finally, it decomposes the global update into a sparse low-rank format for broadcast, ensuring a symmetrically efficient cycle. We also propose an efficient variant, FedSRD-e, to reduce computational overhead. Experimental results on 10 benchmarks demonstrate that our framework significantly reduces communication costs by up to 90\% while even improving model performance on heterogeneous client data.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PoS-CoPOR: Proof-of-Stake Consensus Protocol with Native Onion Routing Providing Scalability and DoS-Resistance</title>
<link>https://arxiv.org/abs/2510.04619</link>
<guid>https://arxiv.org/abs/2510.04619</guid>
<content:encoded><![CDATA[
arXiv:2510.04619v1 Announce Type: new 
Abstract: Proof-of-Stake (PoS) consensus protocols often face a trade-off between performance and security. Protocols that pre-elect leaders for subsequent rounds are vulnerable to Denial-of-Service (DoS) attacks, which can disrupt the network and compromise liveness. In this work, we present PoS-CoPOR, a single-chain PoS consensus protocol that mitigates this vulnerability by integrating a native onion routing mechanism into the consensus protocol itself. PoS-CoPOR combines stake-weighted probabilistic leader election with an anonymization layer that conceals the network identity of the next block proposer. This approach prevents targeted DoS attacks on leaders before they produce a block, thus enhancing network resilience. We implemented and evaluated PoS-CoPOR, demonstrating its ability to achieve a throughput of up to 110 tx/s with 6 nodes, even with the overhead of the anonymization layer. The results show that native anonymization can provide robust DoS resistance with only a modest impact on performance, offering a solution to build secure and scalable PoS blockchains.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Impossible Cloud Network: A Decentralized Internet Infrastructure Layer</title>
<link>https://arxiv.org/abs/2510.04620</link>
<guid>https://arxiv.org/abs/2510.04620</guid>
<content:encoded><![CDATA[
arXiv:2510.04620v1 Announce Type: new 
Abstract: The internet faces a sovereignty crisis due to power concentration and data growth among a few hyperscalers, leading to centralization and loss of user control. This consolidation risks censorship and creates single points of failure. While Web3 offers decentralized solutions, they often sacrifice either scalability, decentralization, or security, which are key elements in the blockchain trilemma. These solutions also struggle with limited access to enterprise-grade hardware and frequently rely on centralized infrastructure. The Impossible Cloud Network (ICN) addresses these issues by creating a multi-tiered, decentralized infrastructure layer. ICN offers a composable service layer, an enterprise-grade hardware resource layer, and a transparent, permissionless HyperNode network for performance enforcement. By strategically decoupling and decentralizing each layer, ICN aims to provide an open, extensively scalable infrastructure that ensures digital sovereignty, eliminates single points of trust, enables service programmability, and offers a decoupled architecture for limitless possibilities in the future internet.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0</title>
<link>https://arxiv.org/abs/2510.04765</link>
<guid>https://arxiv.org/abs/2510.04765</guid>
<content:encoded><![CDATA[
arXiv:2510.04765v1 Announce Type: new 
Abstract: Web 3.0 represents the next generation of the Internet, which is widely recognized as a decentralized ecosystem that focuses on value expression and data ownership. By leveraging blockchain and artificial intelligence technologies, Web 3.0 offers unprecedented opportunities for users to create, own, and monetize their content, thereby enabling User-Generated Content (UGC) to an entirely new level. However, some self-interested users may exploit the limitations of content curation mechanisms and generate low-quality content with less effort, obtaining platform rewards under information asymmetry. Such behavior can undermine Web 3.0 performance. To this end, we propose \textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive mechanism for UGC in Web 3.0. Specifically, we propose an LMM-based contract-theoretic model to motivate users to generate high-quality UGC, thereby mitigating the adverse selection problem from information asymmetry. To alleviate potential moral hazards after contract selection, we leverage LMM agents to evaluate UGC quality, which is the primary component of the contract, utilizing prompt engineering techniques to improve the evaluation performance of LMM agents. Recognizing that traditional contract design methods cannot effectively adapt to the dynamic environment of Web 3.0, we develop an improved Mixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for optimal contract design. Simulation results demonstrate the superiority of the proposed MoE-based PPO algorithm over representative benchmarks in the context of contract design. Finally, we deploy the designed contract within an Ethereum smart contract framework, further validating the effectiveness of the proposed scheme.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge</title>
<link>https://arxiv.org/abs/2510.04772</link>
<guid>https://arxiv.org/abs/2510.04772</guid>
<content:encoded><![CDATA[
arXiv:2510.04772v1 Announce Type: new 
Abstract: Purpose: The FedSurg challenge was designed to benchmark the state of the art in federated learning for surgical video classification. Its goal was to assess how well current methods generalize to unseen clinical centers and adapt through local fine-tuning while enabling collaborative model development without sharing patient data. Methods: Participants developed strategies to classify inflammation stages in appendicitis using a preliminary version of the multi-center Appendix300 video dataset. The challenge evaluated two tasks: generalization to an unseen center and center-specific adaptation after fine-tuning. Submitted approaches included foundation models with linear probing, metric learning with triplet loss, and various FL aggregation schemes (FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and Expected Cost, with ranking robustness evaluated via bootstrapping and statistical testing. Results: In the generalization task, performance across centers was limited. In the adaptation task, all teams improved after fine-tuning, though ranking stability was low. The ViViT-based submission achieved the strongest overall performance. The challenge highlighted limitations in generalization, sensitivity to class imbalance, and difficulties in hyperparameter tuning in decentralized training, while spatiotemporal modeling and context-aware preprocessing emerged as promising strategies. Conclusion: The FedSurg Challenge establishes the first benchmark for evaluating FL strategies in surgical video classification. Findings highlight the trade-off between local personalization and global robustness, and underscore the importance of architecture choice, preprocessing, and loss design. This benchmarking offers a reference point for future development of imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Distributed Optimization With Feasible Set Privacy</title>
<link>https://arxiv.org/abs/2510.05068</link>
<guid>https://arxiv.org/abs/2510.05068</guid>
<content:encoded><![CDATA[
arXiv:2510.05068v1 Announce Type: new 
Abstract: We consider the problem of decentralized constrained optimization with multiple agents $E_1,\ldots,E_N$ who jointly wish to learn the optimal solution set while keeping their feasible sets $\mathcal{P}_1,\ldots,\mathcal{P}_N$ private from each other. We assume that the objective function $f$ is known to all agents and each feasible set is a collection of points from a universal alphabet $\mathcal{P}_{alph}$. A designated agent (leader) starts the communication with the remaining (non-leader) agents, and is the first to retrieve the solution set. The leader searches for the solution by sending queries to and receiving answers from the non-leaders, such that the information on the individual feasible sets revealed to the leader should be no more than nominal, i.e., what is revealed from learning the solution set alone. We develop achievable schemes for obtaining the solution set at nominal information leakage, and characterize their communication costs under two communication setups between agents. In this work, we focus on two kinds of network setups: i) ring, where each agent communicates with two adjacent agents, and ii) star, where only the leader communicates with the remaining agents. We show that, if the leader first learns the joint feasible set through an existing private set intersection (PSI) protocol and then deduces the solution set, the information leaked to the leader is greater than nominal. Moreover, we draw connection of our schemes to threshold PSI (ThPSI), which is a PSI-variant where the intersection is revealed only when its cardinality is larger than a threshold value. Finally, for various realizations of $f$ mapped uniformly at random to a fixed range of values, our schemes are more communication-efficient with a high probability compared to retrieving the entire feasible set through PSI.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Position Paper: Assessing Robustness, Privacy, and Fairness in Federated Learning Integrated with Foundation Models</title>
<link>https://arxiv.org/abs/2402.01857</link>
<guid>https://arxiv.org/abs/2402.01857</guid>
<content:encoded><![CDATA[
arXiv:2402.01857v2 Announce Type: replace 
Abstract: Federated Learning (FL), while a breakthrough in decentralized machine learning, contends with significant challenges such as limited data availability and the variability of computational resources, which can stifle the performance and scalability of the models. The integration of Foundation Models (FMs) into FL presents a compelling solution to these issues, with the potential to enhance data richness and reduce computational demands through pre-training and data augmentation. However, this incorporation introduces novel issues in terms of robustness, privacy, and fairness, which have not been sufficiently addressed in the existing research. We make a preliminary investigation into this field by systematically evaluating the implications of FM-FL integration across these dimensions. We analyze the trade-offs involved, uncover the threats and issues introduced by this integration, and propose a set of criteria and strategies for navigating these challenges. Furthermore, we identify potential research directions for advancing this field, laying a foundation for future development in creating reliable, secure, and equitable FL systems.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof-of-Data: A Consensus Protocol for Collaborative Intelligence</title>
<link>https://arxiv.org/abs/2501.02971</link>
<guid>https://arxiv.org/abs/2501.02971</guid>
<content:encoded><![CDATA[
arXiv:2501.02971v2 Announce Type: replace 
Abstract: Existing research on federated learning has been focused on the setting where learning is coordinated by a centralized entity. Yet the greatest potential of future collaborative intelligence would be unleashed in a more open and democratized setting with no central entity in a dominant role, referred to as "decentralized federated learning". New challenges arise accordingly in achieving both correct model training and fair reward allocation with collective effort among all participating nodes, especially with the threat of the Byzantine node jeopardising both tasks.
  In this paper, we propose a blockchain-based decentralized Byzantine fault-tolerant federated learning framework based on a novel Proof-of-Data (PoD) consensus protocol to resolve both the "trust" and "incentive" components. By decoupling model training and contribution accounting, PoD is able to enjoy not only the benefit of learning efficiency and system liveliness from asynchronous societal-scale PoW-style learning but also the finality of consensus and reward allocation from epoch-based BFT-style voting. To mitigate false reward claims by data forgery from Byzantine attacks, a privacy-aware data verification and contribution-based reward allocation mechanism is designed to complete the framework. Our evaluation results show that PoD demonstrates performance in model training close to that of the centralized counterpart while achieving trust in consensus and fairness for reward allocation with a fault tolerance ratio of 1/3.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exact and Linear Convergence for Federated Learning under Arbitrary Client Participation is Attainable</title>
<link>https://arxiv.org/abs/2503.20117</link>
<guid>https://arxiv.org/abs/2503.20117</guid>
<content:encoded><![CDATA[
arXiv:2503.20117v3 Announce Type: replace 
Abstract: This work tackles the fundamental challenges in Federated Learning (FL) posed by arbitrary client participation and data heterogeneity, prevalent characteristics in practical FL settings. It is well-established that popular FedAvg-style algorithms struggle with exact convergence and can suffer from slow convergence rates since a decaying learning rate is required to mitigate these scenarios. To address these issues, we introduce the concept of stochastic matrix and the corresponding time-varying graphs as a novel modeling tool to accurately capture the dynamics of arbitrary client participation and the local update procedure. Leveraging this approach, we offer a fresh decentralized perspective on designing FL algorithms and present FOCUS, Federated Optimization with Exact Convergence via Push-pull Strategy, a provably convergent algorithm designed to effectively overcome the previously mentioned two challenges. More specifically, we provide a rigorous proof demonstrating that FOCUS achieves exact convergence with a linear rate regardless of the arbitrary client participation, establishing it as the first work to demonstrate this significant result.
]]></content:encoded>
<pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Spatiotemporal Graph Learning for Passive Attack Detection in Smart Grids</title>
<link>https://arxiv.org/abs/2510.02371</link>
<guid>https://arxiv.org/abs/2510.02371</guid>
<content:encoded><![CDATA[
arXiv:2510.02371v1 Announce Type: new 
Abstract: Smart grids are exposed to passive eavesdropping, where attackers listen silently to communication links. Although no data is actively altered, such reconnaissance can reveal grid topology, consumption patterns, and operational behavior, creating a gateway to more severe targeted attacks. Detecting this threat is difficult because the signals it produces are faint, short-lived, and often disappear when traffic is examined by a single node or along a single timeline. This paper introduces a graph-centric, multimodal detector that fuses physical-layer and behavioral indicators over ego-centric star subgraphs and short temporal windows to detect passive attacks. To capture stealthy perturbations, a two-stage encoder is introduced: graph convolution aggregates spatial context across ego-centric star subgraphs, while a bidirectional GRU models short-term temporal dependencies. The encoder transforms heterogeneous features into a unified spatio-temporal representation suitable for classification. Training occurs in a federated learning setup under FedProx, improving robustness to heterogeneous local raw data and contributing to the trustworthiness of decentralized training; raw measurements remain on client devices. A synthetic, standards-informed dataset is generated to emulate heterogeneous HAN/NAN/WAN communications with wireless-only passive perturbations, event co-occurrence, and leak-safe splits. The model achieves a testing accuracy of 98.32% per-timestep (F1_{attack}=0.972) and 93.35% per-sequence at 0.15% FPR using a simple decision rule with run-length m=2 and threshold $\tau=0.55$. The results demonstrate that combining spatial and temporal context enables reliable detection of stealthy reconnaissance while maintaining low false-positive rates, making the approach suitable for non-IID federated smart-grid deployments.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Modeling and Control System Analysis for Continuous-Disc Filters in Pulp Mill Operations</title>
<link>https://arxiv.org/abs/2510.02385</link>
<guid>https://arxiv.org/abs/2510.02385</guid>
<content:encoded><![CDATA[
arXiv:2510.02385v1 Announce Type: new 
Abstract: Vacuum disc filtration is critical in pulp mills for white liquor clarification and pulp washing, involving tightly coupled dynamics between rotational speed, vacuum pressure, slurry concentration, filtrate flow, and cake thickness. These nonlinear interactions are often regulated using empirical methods, lacking formal modeling and control. This article develops a dynamic, multivariable model of a continuous-disc filter (CD-filter) system based on first principles, simplified to a single representative disc for tractability. A linearized state-space model supports the design of two control strategies: a decentralized PI-based scheme and a centralized model predictive control (MPC). MATLAB-Simulink simulations reveal that MPC outperforms PI in tracking accuracy, overshoot reduction, and disturbance rejection. A 3D efficiency surface illustrates the importance of coordinating inlet flow and solids concentration. Results highlight the need for advanced multivariable control in optimizing CD-filter performance.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PolyLink: A Blockchain Based Decentralized Edge AI Platform for LLM Inference</title>
<link>https://arxiv.org/abs/2510.02395</link>
<guid>https://arxiv.org/abs/2510.02395</guid>
<content:encoded><![CDATA[
arXiv:2510.02395v1 Announce Type: new 
Abstract: The rapid advancement of large language models (LLMs) in recent years has revolutionized the AI landscape. However, the deployment model and usage of LLM services remain highly centralized, creating significant trust issues and costs for end users and developers. To address these issues, we propose PolyLink, a blockchain-based decentralized AI platform that decentralizes LLM development and inference. Specifically, PolyLink introduces a decentralized crowdsourcing architecture that supports single-device and cross-device model deployment and inference across heterogeneous devices at the edge. Moreover, to ensure the inference integrity, we design the TIQE protocol, which combines a lightweight cross-encoder model and an LLM-as-a-Judge for a high-accuracy inference evaluation. Lastly, we integrate a comprehensive token-based incentive model with dynamic pricing and reward mechanisms for all participants. We have deployed PolyLink and conducted an extensive real-world evaluation through geo-distributed deployment across heterogeneous devices. Results indicate that the inference and verification latency is practical. Our security analysis demonstrates that the system is resistant to model degradation attacks and validator corruptions. PolyLink is now available at https://github.com/IMCL-PolyLink/PolyLink.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Preconfirmations</title>
<link>https://arxiv.org/abs/2510.02947</link>
<guid>https://arxiv.org/abs/2510.02947</guid>
<content:encoded><![CDATA[
arXiv:2510.02947v1 Announce Type: new 
Abstract: In recent years, significant research efforts have focused on improving blockchain throughput and confirmation speeds without compromising security. While decreasing the time it takes for a transaction to be included in the blockchain ledger enhances user experience, a fundamental delay still remains between when a transaction is issued by a user and when its inclusion is confirmed in the blockchain ledger. This delay limits user experience gains through the confirmation uncertainty it brings for users. This inherent delay in conventional blockchain protocols has led to the emergence of preconfirmation protocols -- protocols that provide users with early guarantees of eventual transaction confirmation.
  This article presents a Systematization of Knowledge (SoK) on preconfirmations. We present the core terms and definitions needed to understand preconfirmations, outline a general framework for preconfirmation protocols, and explore the economics and risks of preconfirmations. Finally, we survey and apply our framework to several implementations of real-world preconfirmation protocols, bridging the gap between theory and practice.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pioneering Scalable Prototyping for Mid-Band XL-MIMO Systems: Design and Implementation</title>
<link>https://arxiv.org/abs/2510.02793</link>
<guid>https://arxiv.org/abs/2510.02793</guid>
<content:encoded><![CDATA[
arXiv:2510.02793v1 Announce Type: cross 
Abstract: The mid-band frequency range, combined with extra large-scale multiple-input multiple-output (XL-MIMO), is emerging as a key enabler for future communication systems. Thanks to the advent of new spectrum resources and degrees of freedom brought by the near-field propagation, the mid-band XL-MIMO system is expected to significantly enhance throughput and inherently support advanced functionalities such as integrated sensing and communication. Although theoretical studies have highlighted the benefits of mid-band XL-MIMO systems, the promised performance gains have yet to be validated in practical systems, posing a major challenge to the standardization. In this paper, preliminaries are first discussed, followed by an analysis of key challenges in constructing a real-time prototype system. Subsequently, the design and implementation of a real-time mid-band XL-MIMO prototype system are presented. Benefiting from the novel architecture, the proposed prototype system supports metrics aligned with standardization, including a bandwidth of 200 MHz, up to 1024 antenna elements, and up to 256 transceiver chains. Operating in time-division duplexing (TDD) mode, the prototype enables multiuser communication with support for up to 12 users, while retaining standard communication procedures. Built on software-defined radio (SDR) platforms, the system is programmable and allows for flexible deployment of advanced algorithms. Moreover, the modular architecture ensures high scalability, making the system adaptable to various configurations, including distributed deployments and decentralized signal processing. Experimental results with the proposed prototype system demonstrate real-time digital sample processing at 1167.85 Gbps, a peak data throughput of 15.81 Gbps for 12 users, and a maximal spectral efficiency approaching 80 bit/s/Hz.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proxima. A DAG based cooperative distributed ledger</title>
<link>https://arxiv.org/abs/2411.16456</link>
<guid>https://arxiv.org/abs/2411.16456</guid>
<content:encoded><![CDATA[
arXiv:2411.16456v5 Announce Type: replace 
Abstract: This paper introduces a novel architecture for a distributed ledger, commonly referred to as a "blockchain", which is organized in the form of directed acyclic graph (DAG) with UTXO transactions as vertices, rather than as a chain of blocks. Consensus on the state of ledger assets is achieved through the cooperative consensus: a profit-driven behavior of token holders themselves, which is viable only when they cooperate by following the "biggest ledger coverage rule", akin the "longest chain rule" of Bitcoin. The cooperative behavior is facilitated by enforcing purposefully designed UTXO transaction validity constraints. Token holders are the sole category of participants authorized to make amendments to the ledger, making participation completely permissionless - without miners, validators, committees or staking - and without any need of knowledge about the composition of the set of all participants in the consensus. The setup allows to achieve high throughput and scalability alongside with low transaction costs, while preserving key aspects of high decentralization, open participation, and asynchronicity found in Bitcoin and other proof-of-work blockchains, but without huge energy consumption. Sybil protection is achieved similarly to proof-of-stake blockchains, using tokens native to the ledger, yet the architecture operates in a leaderless manner without block proposers and committee selection.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ColNet: Collaborative Optimization in Decentralized Federated Multi-task Learning Systems</title>
<link>https://arxiv.org/abs/2501.10347</link>
<guid>https://arxiv.org/abs/2501.10347</guid>
<content:encoded><![CDATA[
arXiv:2501.10347v2 Announce Type: replace 
Abstract: The integration of Federated Learning (FL) and Multi-Task Learning (MTL) has been explored to address client heterogeneity, with Federated Multi-Task Learning (FMTL) treating each client as a distinct task. However, most existing research focuses on data heterogeneity (e.g., addressing non-IID data) rather than task heterogeneity, where clients solve fundamentally different tasks. Additionally, much of the work relies on centralized settings with a server managing the federation, leaving the more challenging domain of decentralized FMTL largely unexplored. Thus, this work bridges this gap by proposing ColNet, a framework designed for heterogeneous tasks in decentralized federated environments.
  ColNet partitions models into a backbone and task-specific heads, and uses adaptive clustering based on model and data sensitivity to form task-coherent client groups. Backbones are averaged within groups, and group leaders perform hyper-conflict-averse cross-group aggregation. Across datasets and federations, ColNet outperforms competing schemes under label and task heterogeneity and shows robustness to poisoning attacks.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FinP: Fairness-in-Privacy in Federated Learning by Addressing Disparities in Privacy Risk</title>
<link>https://arxiv.org/abs/2502.17748</link>
<guid>https://arxiv.org/abs/2502.17748</guid>
<content:encoded><![CDATA[
arXiv:2502.17748v2 Announce Type: replace 
Abstract: Ensuring fairness in machine learning extends to the critical dimension of privacy, particularly in human-centric federated learning (FL) settings where decentralized data necessitates an equitable distribution of privacy risk across clients. This paper introduces FinP, a novel framework specifically designed to address disparities in privacy risk by mitigating disproportionate vulnerability to source inference attacks (SIA). FinP employs a two-pronged strategy: (1) server-side adaptive aggregation, which dynamically adjusts client contributions to the global model to foster fairness, and (2) client-side regularization, which enhances the privacy robustness of individual clients. This comprehensive approach directly tackles both the symptoms and underlying causes of privacy unfairness in FL. Extensive evaluations on the Human Activity Recognition (HAR) and CIFAR-10 datasets demonstrate FinP's effectiveness, achieving improvement in fairness-in-privacy on HAR and CIFAR-10 with minimal impact on utility. FinP improved group fairness with respect to disparity in privacy risk using equal opportunity in CIFAR-10 by 57.14% compared to the state-of-the-art. Furthermore, FinP significantly mitigates SIA risks on CIFAR-10, underscoring its potential to establish fairness in privacy within FL systems without compromising utility.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Odontoceti: Ultra-Fast DAG Consensus with Two Round Commitment</title>
<link>https://arxiv.org/abs/2510.01216</link>
<guid>https://arxiv.org/abs/2510.01216</guid>
<content:encoded><![CDATA[
arXiv:2510.01216v1 Announce Type: new 
Abstract: Users of blockchains value scalability, expecting fast confirmations and immediate transaction processing. Odontoceti, the latest in DAG-based consensus, addresses these concerns by prioritizing low latency and high throughput, making a strategic trade-off in security by operating with a 20% fault tolerance instead of the established 33% level. It is the first DAG-based protocol to achieve commitment in just two communication rounds, delivering median latency of 300 milliseconds while processing 10,000 transactions per second under realistic network conditions. Odontoceti operates with n = 5f + 1 validators and creates an uncertified DAG with a novel decision rule for committing blocks. The protocol includes an optimization that advances progress when participants are slow, benefiting crash fault scenarios which are more common in practice than Byzantine faults. Evaluation results demonstrate 20-25% latency improvements compared to an existing production protocol, validating that reducing wave length from three rounds to two rounds yields meaningful performance benefits. This paper establishes the practical viability of lower fault tolerance consensus protocols for blockchains.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing IoT Devices in Smart Cities: A Review of Proposed Solutions</title>
<link>https://arxiv.org/abs/2510.01445</link>
<guid>https://arxiv.org/abs/2510.01445</guid>
<content:encoded><![CDATA[
arXiv:2510.01445v1 Announce Type: new 
Abstract: Privacy and security in Smart Cities remain at constant risk due to the vulnerabilities introduced by Internet of Things (IoT) devices. The limited computational resources of these devices make them especially susceptible to attacks, while their widespread adoption increases the potential impact of security breaches. This article presents a review of security proposals aimed at protecting IoT devices in Smart City environments. The review was conducted by analyzing recent literature on device-level security, with particular emphasis on lightweight cryptography, physically unclonable functions (PUFs), and blockchain-based solutions. Findings highlight both the strengths and limitations of current approaches, as well as the need for more practical, scalable, and resource-efficient mechanisms to ensure user privacy and data protection in IoT ecosystems.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOSS-chain: using blockchain for Open Source Software license compliance</title>
<link>https://arxiv.org/abs/2510.01740</link>
<guid>https://arxiv.org/abs/2510.01740</guid>
<content:encoded><![CDATA[
arXiv:2510.01740v1 Announce Type: new 
Abstract: Open Source Software (OSS) is widely used and carries licenses that indicate the terms under which the software is provided for use, also specifying modification and distribution rules. Ensuring that users are respecting OSS license terms when creating derivative works is a complex process. Compliance issues arising from incompatibilities among licenses may lead to legal disputes. At the same time, the blockchain technology with immutable entries offers a mechanism to provide transparency when it comes to licensing and ensure software changes are recorded. In this work, we are introducing an integration of blockchain and license management when creating derivative works, in order to tackle the issue of OSS license compatibility. We have designed, implemented and performed a preliminary evaluation of FOSS-chain, a web platform that uses blockchain and automates the license compliance process, covering 14 OSS licenses. We have evaluated the initial prototype version of the FOSS-chain platform via a small scale user study. Our preliminary results are promising, demonstrating the potential of the platform for adaptation on realistic software systems.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeMuon: A Decentralized Muon for Matrix Optimization over Graphs</title>
<link>https://arxiv.org/abs/2510.01377</link>
<guid>https://arxiv.org/abs/2510.01377</guid>
<content:encoded><![CDATA[
arXiv:2510.01377v1 Announce Type: cross 
Abstract: In this paper, we propose DeMuon, a method for decentralized matrix optimization over a given communication topology. DeMuon incorporates matrix orthogonalization via Newton-Schulz iterations-a technique inherited from its centralized predecessor, Muon-and employs gradient tracking to mitigate heterogeneity among local functions. Under heavy-tailed noise conditions and additional mild assumptions, we establish the iteration complexity of DeMuon for reaching an approximate stochastic stationary point. This complexity result matches the best-known complexity bounds of centralized algorithms in terms of dependence on the target tolerance. To the best of our knowledge, DeMuon is the first direct extension of Muon to decentralized optimization over graphs with provable complexity guarantees. We conduct preliminary numerical experiments on decentralized transformer pretraining over graphs with varying degrees of connectivity. Our numerical results demonstrate a clear margin of improvement of DeMuon over other popular decentralized algorithms across different network topologies.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LPAC: Learnable Perception-Action-Communication Loops with Applications to Coverage Control</title>
<link>https://arxiv.org/abs/2401.04855</link>
<guid>https://arxiv.org/abs/2401.04855</guid>
<content:encoded><![CDATA[
arXiv:2401.04855v4 Announce Type: replace 
Abstract: Coverage control is the problem of navigating a robot swarm to collaboratively monitor features or a phenomenon of interest not known a priori. The problem is challenging in decentralized settings with robots that have limited communication and sensing capabilities. We propose a learnable Perception-Action-Communication (LPAC) architecture for the problem, wherein a convolutional neural network (CNN) processes localized perception; a graph neural network (GNN) facilitates robot communications; finally, a shallow multi-layer perceptron (MLP) computes robot actions. The GNN enables collaboration in the robot swarm by computing what information to communicate with nearby robots and how to incorporate received information. Evaluations show that the LPAC models -- trained using imitation learning -- outperform standard decentralized and centralized coverage control algorithms. The learned policy generalizes to environments different from the training dataset, transfers to larger environments with more robots, and is robust to noisy position estimates. The results indicate the suitability of LPAC architectures for decentralized navigation in robot swarms to achieve collaborative behavior.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DFPL: Decentralized Federated Prototype Learning Across Heterogeneous Data Distributions</title>
<link>https://arxiv.org/abs/2505.04947</link>
<guid>https://arxiv.org/abs/2505.04947</guid>
<content:encoded><![CDATA[
arXiv:2505.04947v4 Announce Type: replace 
Abstract: Federated learning is a distributed machine learning paradigm through centralized model aggregation. However, standard federated learning relies on a centralized server, making it vulnerable to server failures. While existing solutions utilize blockchain technology to implement Decentralized Federated Learning (DFL), the statistical heterogeneity of data distributions among clients severely degrades the performance of DFL. Driven by this issue, this paper proposes a decentralized federated prototype learning framework, named DFPL, which significantly improves the performance of DFL under heterogeneous data distributions. Specifically, DFPL introduces prototype learning into DFL to mitigate the impact of statistical heterogeneity and reduces the amount of parameters exchanged between clients. Additionally, blockchain is embedded into our framework, enabling the training and mining processes to be executed locally on each client. From a theoretical perspective, we analyze the convergence of DFPL by modeling the required computational resources during both training and mining. The experiment results highlight the superiority of DFPL in both model performance and communication efficiency across four benchmark datasets with heterogeneous data distributions.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Cybersecurity Architecture for Digital Product Ecosystems Using Agentic AI</title>
<link>https://arxiv.org/abs/2509.20640</link>
<guid>https://arxiv.org/abs/2509.20640</guid>
<content:encoded><![CDATA[
arXiv:2509.20640v2 Announce Type: replace 
Abstract: Traditional static cybersecurity models often struggle with scalability, real-time detection, and contextual responsiveness in the current digital product ecosystems which include cloud services, application programming interfaces (APIs), mobile platforms, and edge devices. This study introduces autonomous goal driven agents capable of dynamic learning and context-aware decision making as part of an adaptive cybersecurity architecture driven by agentic artificial intelligence (AI). To facilitate autonomous threat mitigation, proactive policy enforcement, and real-time anomaly detection, this framework integrates agentic AI across the key ecosystem layers. Behavioral baselining, decentralized risk scoring, and federated threat intelligence sharing are important features. The capacity of the system to identify zero-day attacks and dynamically modify access policies was demonstrated through native cloud simulations. The evaluation results show increased adaptability, decreased response latency, and improved detection accuracy. The architecture provides an intelligent and scalable blueprint for safeguarding complex digital infrastructure and is compatible with zero-trust models, thereby supporting the adherence to international cybersecurity regulations.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AdGT: Decentralized Gradient Tracking with Tuning-free Per-Agent Stepsize</title>
<link>https://arxiv.org/abs/2504.15196</link>
<guid>https://arxiv.org/abs/2504.15196</guid>
<content:encoded><![CDATA[
arXiv:2504.15196v2 Announce Type: replace-cross 
Abstract: In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT achieves linear convergence to the global optimal solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Lead Themselves: Agentic AI in MAS using MARL</title>
<link>https://arxiv.org/abs/2510.00022</link>
<guid>https://arxiv.org/abs/2510.00022</guid>
<content:encoded><![CDATA[
arXiv:2510.00022v1 Announce Type: new 
Abstract: As autonomous systems move from prototypes to real deployments, the ability of multiple agents to make decentralized, cooperative decisions becomes a core requirement. This paper examines how agentic artificial intelligence, agents that act independently, adaptively and proactively can improve task allocation and coordination in multi-agent systems, with primary emphasis on drone delivery and secondary relevance to warehouse automation. We formulate the problem in a cooperative multi-agent reinforcement learning setting and implement a lightweight multi-agent Proximal Policy Optimization, called IPPO, approach in PyTorch under a centralized-training, decentralized-execution paradigm. Experiments are conducted in PettingZoo environment, where multiple homogeneous drones or agents must self-organize to cover distinct targets without explicit communication.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Calyx: Privacy-Preserving Multi-Token Optimistic-Rollup Protocol</title>
<link>https://arxiv.org/abs/2510.00164</link>
<guid>https://arxiv.org/abs/2510.00164</guid>
<content:encoded><![CDATA[
arXiv:2510.00164v1 Announce Type: new 
Abstract: Rollup protocols have recently received significant attention as a promising class of Layer 2 (L2) scalability solutions. By utilizing the Layer 1 (L1) blockchain solely as a bulletin board for a summary of the executed transactions and state changes, rollups enable secure off-chain execution while avoiding the complexity of other L2 mechanisms. However, to ensure data availability, current rollup protocols require the plaintext of executed transactions to be published on-chain, resulting in inherent privacy limitations.
  In this paper, we address this problem by introducing Calyx, the first privacy-preserving multi-token optimistic-Rollup protocol. Calyx guarantees full payment privacy for all L2 transactions, revealing no information about the sender, recipient, transferred amount, or token type. The protocol further supports atomic execution of multiple multi-token transactions and introduces a transaction fee scheme to enable broader application scenarios while ensuring the sustainable operation of the protocol. To enforce correctness, Calyx adopts an efficient one-step fraud-proof mechanism. We analyze the security and privacy guarantees of the protocol and provide an implementation and evaluation. Our results show that executing a single transaction costs approximately $0.06 (0.00002 ETH) and incurs only constant-size on-chain cost in asymptotic terms.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lattica: A Decentralized Cross-NAT Communication Framework for Scalable AI Inference and Training</title>
<link>https://arxiv.org/abs/2510.00183</link>
<guid>https://arxiv.org/abs/2510.00183</guid>
<content:encoded><![CDATA[
arXiv:2510.00183v1 Announce Type: new 
Abstract: The rapid expansion of distributed Artificial Intelligence (AI) workloads beyond centralized data centers creates a demand for new communication substrates. These substrates must operate reliably in heterogeneous and permissionless environments, where Network Address Translators (NATs) and firewalls impose significant constraints. Existing solutions, however, are either designed for controlled data center deployments or implemented as monolithic systems that tightly couple machine learning logic with networking code. To address these limitations, we present Lattica, a decentralized cross-NAT communication framework designed to support distributed AI systems. Lattica integrates three core components. First, it employs a robust suite of NAT traversal mechanisms to establish a globally addressable peer-to-peer mesh. Second, it provides a decentralized data store based on Conflict-free Replicated Data Types (CRDTs), ensuring verifiable and eventually consistent state replication. Third, it incorporates a content discovery layer that leverages distributed hash tables (DHTs) together with an optimized RPC protocol for efficient model synchronization. By integrating these components, Lattica delivers a complete protocol stack for sovereign, resilient, and scalable AI systems that operate independently of centralized intermediaries. It is directly applicable to edge intelligence, collaborative reinforcement learning, and other large-scale distributed machine learning scenarios.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockSDN-VC: A SDN-Based Virtual Coordinate-Enhanced Transaction Broadcast Framework for High-Performance Blockchains</title>
<link>https://arxiv.org/abs/2510.00306</link>
<guid>https://arxiv.org/abs/2510.00306</guid>
<content:encoded><![CDATA[
arXiv:2510.00306v1 Announce Type: new 
Abstract: Modern blockchains need fast, reliable propagation to balance security and throughput. Virtual-coordinate methods speed dissemination but rely on slow iterative updates, leaving nodes out of sync. We present BlockSDN-VC, a transaction-broadcast protocol that centralises coordinate computation and forwarding control in an SDN controller, delivering global consistency, minimal path stretch and rapid response to churn or congestion. In geo-distributed simulations, BlockSDN-VC cuts median latency by up to 62% and accelerates convergence fourfold over state-of-the-art schemes with under 3% control-plane overhead. In a real blockchain environment, BlockSDN-VC boosts confirmed-transaction throughput by 17% under adversarial workloads, requiring no modifications to existing clients.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Flow of Knowledge: Federated Fine-Tuning of LLMs in Healthcare under Non-IID Conditions</title>
<link>https://arxiv.org/abs/2510.00543</link>
<guid>https://arxiv.org/abs/2510.00543</guid>
<content:encoded><![CDATA[
arXiv:2510.00543v1 Announce Type: new 
Abstract: Large language models (LLMs) show great promise in healthcare, but their applications are hindered by data privacy restrictions and the challenges of cross-institution collaboration. Sensitive medical data cannot be centralized, while non-independent and identically distributed (non-IID) characteristics across institutions further complicate convergence and fairness. To address these issues, we present a federated fine-tuning approach based on Low-Rank Adaptation (LoRA), enabling privacy-preserving knowledge flow across institutions. The method iteratively combines local LoRA adaptation with global parameter aggregation, allowing efficient knowledge sharing without exposing raw data. A blockchain identity scheme is used for identifying individual LLM in such a distributed network. We evaluate this approach on heterogeneous and highly non-IID medical text datasets, where experiments demonstrate that federated LoRA not only enhances cross-client generalization but also improves the performance of the weakest client, achieving stable convergence and fairer outcomes. These findings highlight federated LoRA fine-tuning as a practical and effective paradigm for adapting LLMs in healthcare, offering a new path for multi-center medical AI collaboration.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized and Self-adaptive Core Maintenance on Temporal Graphs</title>
<link>https://arxiv.org/abs/2510.00758</link>
<guid>https://arxiv.org/abs/2510.00758</guid>
<content:encoded><![CDATA[
arXiv:2510.00758v1 Announce Type: new 
Abstract: Key graph-based problems play a central role in understanding network topology and uncovering patterns of similarity in homogeneous and temporal data. Such patterns can be revealed by analyzing communities formed by nodes, which in turn can be effectively modeled through temporal $k$-cores. This paper introduces a novel decentralized and incremental algorithm for computing the core decomposition of temporal networks. Decentralized solutions leverage the ability of network nodes to communicate and coordinate locally, addressing complex problems in a scalable, adaptive, and timely manner. By leveraging previously computed coreness values, our approach significantly reduces the activation of nodes and the volume of message exchanges when the network changes over time. This enables scalability with only a minimal trade-off in precision. Experimental evaluations on large real-world networks under varying levels of dynamism demonstrate the efficiency of our solution compared to a state-of-the-art approach, particularly in terms of active nodes, communication overhead, and convergence speed.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Verifiable Federated Unlearning: Framework, Challenges, and The Road Ahead</title>
<link>https://arxiv.org/abs/2510.00833</link>
<guid>https://arxiv.org/abs/2510.00833</guid>
<content:encoded><![CDATA[
arXiv:2510.00833v1 Announce Type: new 
Abstract: Federated unlearning (FUL) enables removing the data influence from the model trained across distributed clients, upholding the right to be forgotten as mandated by privacy regulations. FUL facilitates a value exchange where clients gain privacy-preserving control over their data contributions, while service providers leverage decentralized computing and data freshness. However, this entire proposition is undermined because clients have no reliable way to verify that their data influence has been provably removed, as current metrics and simple notifications offer insufficient assurance. We envision unlearning verification becoming a pivotal and trust-by-design part of the FUL life-cycle development, essential for highly regulated and data-sensitive services and applications like healthcare. This article introduces veriFUL, a reference framework for verifiable FUL that formalizes verification entities, goals, approaches, and metrics. Specifically, we consolidate existing efforts and contribute new insights, concepts, and metrics to this domain. Finally, we highlight research challenges and identify potential applications and developments for verifiable FUL and veriFUL.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Structuring Automotive Data for Systems Engineering: A Taxonomy-Based Approach</title>
<link>https://arxiv.org/abs/2510.00963</link>
<guid>https://arxiv.org/abs/2510.00963</guid>
<content:encoded><![CDATA[
arXiv:2510.00963v1 Announce Type: new 
Abstract: Vehicle data is essential for advancing data-driven development throughout the automotive lifecycle, including requirements engineering, design, verification, and validation, and post-deployment optimization. Developers currently collect data in a decentralized and fragmented manner across simulations, test benches, and real-world driving, resulting in data silos, inconsistent formats, and limited interoperability. This leads to redundant efforts, inefficient integration, and suboptimal use of data. This fragmentation results in data silos, inconsistent storage structures, and limited interoperability, leading to redundant data collection, inefficient integration, and suboptimal application. To address these challenges, this article presents a structured literature review and develops an inductive taxonomy for automotive data. This taxonomy categorizes data according to its sources and applications, improving data accessibility and utilization. The analysis reveals a growing emphasis on real-world driving and machine learning applications while highlighting a critical gap in data availability for requirements engineering. By providing a systematic framework for structuring automotive data, this research contributes to more efficient data management and improved decision-making in the automotive industry.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Universally Composable Termination Analysis of Tendermint</title>
<link>https://arxiv.org/abs/2510.01097</link>
<guid>https://arxiv.org/abs/2510.01097</guid>
<content:encoded><![CDATA[
arXiv:2510.01097v1 Announce Type: new 
Abstract: Modern blockchain systems operating in adversarial environments require robust consensus protocols that guarantee both safety and termination under network delay attacks. Tendermint, a widely adopted consensus protocol in consortium blockchains, achieves high throughput and finality. However, previous analysis of the safety and termination has been done in a standalone fashion, with no consideration of the composition with other protocols interacting with it in a concurrent manner. Moreover, the termination properties under adaptive network delays caused by Byzantine adversaries have not been formally analyzed. This paper presents the first universally composable (UC) security analysis of Tendermint, demonstrating its resilience against strategic message-delay attacks. By constructing a UC ideal model of Tendermint, we formalize its core mechanisms: phase-base consensus procedure, dynamic timeouts, proposal locking, leader rotation, and others, under a network adversary that selectively delays protocol messages. Our main result proves that the Tendermint protocol UC-realizes the ideal Tendermint model, which ensures bounded termination latency, i.e., guaranteed termination, even when up to $f<n/3$ nodes are Byzantine (where $n$ is the number of nodes participating in the consensus), provided that network delays remain within a protocol-defined threshold under the partially synchronous net assumption. Specifically, through formal proofs within the UC framework, we show that Tendermint maintains safety and termination. By the composition theorem of UC, this guarantees that these properties are maintained when Tendermint is composed with various blockchain components.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy Preserved Federated Learning with Attention-Based Aggregation for Biometric Recognition</title>
<link>https://arxiv.org/abs/2510.01113</link>
<guid>https://arxiv.org/abs/2510.01113</guid>
<content:encoded><![CDATA[
arXiv:2510.01113v1 Announce Type: new 
Abstract: Because biometric data is sensitive, centralized training poses a privacy risk, even though biometric recognition is essential for contemporary applications. Federated learning (FL), which permits decentralized training, provides a privacy-preserving substitute. Conventional FL, however, has trouble with interpretability and heterogeneous data (non-IID). In order to handle non-IID biometric data, this framework adds an attention mechanism at the central server that weights local model updates according to their significance. Differential privacy and secure update protocols safeguard data while preserving accuracy. The A3-FL framework is evaluated in this study using FVC2004 fingerprint data, with each client's features extracted using a Siamese Convolutional Neural Network (Siamese-CNN). By dynamically modifying client contributions, the attention mechanism increases the accuracy of the global model.The accuracy, convergence speed, and robustness of the A3-FL framework are superior to those of standard FL (FedAvg) and static baselines, according to experimental evaluations using fingerprint data (FVC2004). The accuracy of the attention-based approach was 0.8413, while FedAvg, Local-only, and Centralized approaches were 0.8164, 0.7664, and 0.7997, respectively. Accuracy stayed high at 0.8330 even with differential privacy. A scalable and privacy-sensitive biometric system for secure and effective recognition in dispersed environments is presented in this work.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Networked Control and Mean Field Problems Under Diagonal Dominance: Decentralized and Social Optimality</title>
<link>https://arxiv.org/abs/2510.01067</link>
<guid>https://arxiv.org/abs/2510.01067</guid>
<content:encoded><![CDATA[
arXiv:2510.01067v1 Announce Type: cross 
Abstract: In this article, we employ an input-output approach to expand the study of cooperative multi-agent control and optimization problems characterized by mean-field interactions that admit decentralized and selfish solutions. The setting involves $n$ independent agents that interact solely through a shared cost function, which penalizes deviations of each agent from the group's average collective behavior. Building on our earlier results established for homogeneous agents, we extend the framework to nonidentical agents and show that, under a diagonal dominant interaction of the collective dynamics, with bounded local open-loop dynamics, the optimal controller for $H_\infty$ and $H_2$ norm minimization remains decentralized and selfish in the limit as the number of agents $n$ grows to infinity.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR) Applications</title>
<link>https://arxiv.org/abs/2412.06759</link>
<guid>https://arxiv.org/abs/2412.06759</guid>
<content:encoded><![CDATA[
arXiv:2412.06759v3 Announce Type: replace 
Abstract: The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR) and spatial computing technologies forms a foundational layer for the emerging Metaverse, enabling innovative applications across healthcare, education, manufacturing, and entertainment. However, research in this area is often limited by the lack of large, representative, and highquality application datasets that can support empirical studies and the development of new approaches benefiting XR software processes. In this paper, we introduce XRZoo, a comprehensive and curated dataset of XR applications designed to bridge this gap. XRZoo contains 12,528 free XR applications, spanning nine app stores, across all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed metadata on key aspects such as application descriptions, application categories, release dates, user review numbers, and hardware specifications, etc. By making XRZoo publicly available, we aim to foster reproducible XR software engineering and security research, enable cross-disciplinary investigations, and also support the development of advanced XR systems by providing examples to developers. Our dataset serves as a valuable resource for researchers and practitioners interested in improving the scalability, usability, and effectiveness of XR applications. XRZoo will be released and actively maintained.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes</title>
<link>https://arxiv.org/abs/2501.08521</link>
<guid>https://arxiv.org/abs/2501.08521</guid>
<content:encoded><![CDATA[
arXiv:2501.08521v3 Announce Type: replace 
Abstract: Federated Learning (FL) has emerged as a decentralized machine learning technique, allowing clients to train a global model collaboratively without sharing private data. However, most FL studies ignore the crucial challenge of heterogeneous domains where each client has a distinct feature distribution, which is popular in real-world scenarios. Prototype learning, which leverages the mean feature vectors within the same classes, has become a prominent solution for federated learning under domain shift. However, existing federated prototype learning methods focus soley on inter-domain prototypes and neglect intra-domain perspectives. In this work, we introduce a novel federated prototype learning method, namely I$^2$PFL, which incorporates $\textbf{I}$ntra-domain and $\textbf{I}$nter-domain $\textbf{P}$rototypes, to mitigate domain shift from both perspectives and learn a generalized global model across multiple domains in federated learning. To construct intra-domain prototypes, we propose feature alignment with MixUp-based augmented prototypes to capture the diversity within local domains and enhance the generalization of local features. Additionally, we introduce a reweighting mechanism for inter-domain prototypes to generate generalized prototypes that reduce domain shift while providing inter-domain knowledge across multiple clients. Extensive experiments on the Digits, Office-10, and PACS datasets illustrate the superior performance of our method compared to other baselines.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CYCle: Choosing Your Collaborators Wisely to Enhance Collaborative Fairness in Decentralized Learning</title>
<link>https://arxiv.org/abs/2501.12344</link>
<guid>https://arxiv.org/abs/2501.12344</guid>
<content:encoded><![CDATA[
arXiv:2501.12344v2 Announce Type: replace 
Abstract: Collaborative learning (CL) enables multiple participants to jointly train machine learning (ML) models on decentralized data sources without raw data sharing. While the primary goal of CL is to maximize the expected accuracy gain for each participant, it is also important to ensure that the gains are fairly distributed: no client should be negatively impacted, and gains should reflect contributions. Most existing CL methods require central coordination and focus only on gain maximization, overlooking fairness. In this work, we first show that the existing measure of collaborative fairness based on the correlation between accuracy values without and with collaboration has drawbacks because it does not account for negative collaboration gain. We argue that maximizing mean collaboration gain (MCG) while simultaneously minimizing the collaboration gain spread (CGS) is a fairer alternative. Next, we propose the CYCle protocol that enables individual participants in a private decentralized learning (PDL) framework to achieve this objective through a novel reputation scoring method based on gradient alignment between the local cross-entropy and distillation losses. We further extend the CYCle protocol to operate on top of gossip-based decentralized algorithms such as Gossip-SGD. We also theoretically show that CYCle performs better than standard FedAvg in a two-client mean estimation setting under high heterogeneity. Empirical experiments demonstrate the effectiveness of the CYCle protocol to ensure positive and fair collaboration gain for all participants, even in cases where the data distributions of participants are highly skewed.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noninterference Analysis of Irreversible or Reversible Systems with Nondeterminism and Probabilities</title>
<link>https://arxiv.org/abs/2501.19290</link>
<guid>https://arxiv.org/abs/2501.19290</guid>
<content:encoded><![CDATA[
arXiv:2501.19290v2 Announce Type: replace 
Abstract: Noninterference theory supports the analysis of secure computations in multi-level security systems. Classical equivalence-based approaches to noninterference mainly rely on bisimilarity. In a nondeterministic setting, assessing noninterference through weak bisimilarity is adequate for irreversible systems, whereas for reversible ones branching bisimilarity has been recently proven to be more appropriate. In this paper we address the same two families of systems, with the difference that probabilities come into play in addition to nondeterminism according to the alternating model of Hansson and Jonsson. For irreversible systems we extend the results of Aldini, Bravetti, and Gorrieri developed in a generative-reactive probabilistic setting, while for reversible systems we extend the results of Esposito, Aldini, Bernardo, and Rossi developed in a purely nondeterministic setting. We recast noninterference properties by adopting probabilistic variants of weak and branching bisimilarities for irreversible and reversible systems respectively. Then we investigate a taxonomy of those properties as well as their preservation and compositionality aspects, along with a comparison with the nondeterministic taxonomy. The adequacy of the extended noninterference theory is illustrated via a probabilistic smart contract lottery.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The challenge of hidden gifts in multi-agent reinforcement learning</title>
<link>https://arxiv.org/abs/2505.20579</link>
<guid>https://arxiv.org/abs/2505.20579</guid>
<content:encoded><![CDATA[
arXiv:2505.20579v5 Announce Type: replace 
Abstract: Sometimes we benefit from actions that others have taken even when we are unaware that they took those actions. For example, if your neighbor chooses not to take a parking spot in front of your house when you are not there, you can benefit, even without being aware that they took this action. These ``hidden gifts'' represent an interesting challenge for multi-agent reinforcement learning (MARL), since assigning credit when the beneficial actions of others are hidden is non-trivial. Here, we study the impact of hidden gifts with a very simple MARL task. In this task, agents in a grid-world environment have individual doors to unlock in order to obtain individual rewards. As well, if all the agents unlock their door the group receives a larger collective reward. However, there is only one key for all of the doors, such that the collective reward can only be obtained when the agents drop the key for others after they use it. Notably, there is nothing to indicate to an agent that the other agents have dropped the key, thus this act for others is a ``hidden gift''. We show that several different state-of-the-art MARL algorithms, including MARL specific architectures, fail to learn how to obtain the collective reward in this simple task. Interestingly, we find that decentralized actor-critic policy gradient agents can succeed when we provide them with information about their own action history, but MARL agents still cannot solve the task with action history. Finally, we derive a correction term for policy gradient agents, inspired by learning aware approaches, which reduces the variance in learning and helps them to converge to collective success more reliably. These results show that credit assignment in multi-agent settings can be particularly challenging in the presence of ``hidden gifts'', and demonstrate that self learning-awareness in decentralized agents can benefit these settings.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hitchhiker's Guide to Privacy-Preserving Digital Payment Systems: A Survey on Anonymity, Confidentiality, and Auditability</title>
<link>https://arxiv.org/abs/2505.21008</link>
<guid>https://arxiv.org/abs/2505.21008</guid>
<content:encoded><![CDATA[
arXiv:2505.21008v2 Announce Type: replace 
Abstract: Crypto-assets and central bank digital currencies (CBDCs) are reshaping how value is exchanged in distributed computing environments. These systems combine cryptographic primitives, protocol design, and system architectures to provide transparency and efficiency while raising critical challenges around privacy and regulatory compliance. This survey offers a comprehensive overview of privacy-preserving digital payment systems, covering both decentralized ledgers and CBDCs. We present a taxonomy of privacy goals -- including anonymity, confidentiality, unlinkability, and auditability -- and map them to underlying cryptographic primitives, protocols, and system architectures. Our work adopts a design-oriented perspective, linking high-level privacy objectives to concrete implementations. We also trace the evolution of privacy-preserving digital payment systems through three generations, highlighting shifts from basic anonymity guarantees toward more nuanced privacy-accountability trade-offs. Finally, we identify open challenges, motivating further research into architectures and solutions that balance strong privacy with real-world auditability needs.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Based Secure Online Voting Platform Ensuring Voter Anonymity, Integrity, and End-to-End Verifiability</title>
<link>https://arxiv.org/abs/2509.22965</link>
<guid>https://arxiv.org/abs/2509.22965</guid>
<content:encoded><![CDATA[
arXiv:2509.22965v2 Announce Type: replace 
Abstract: Casting a ballot from a phone or laptop sounds appealing, but only if voters can be confident their choice remains secret and results cannot be altered in the dark. This paper proposes a hybrid blockchain-based voting model that stores encrypted votes on a private blockchain maintained by election organizers and neutral observers, while periodically anchoring hashes of these votes onto a public blockchain as a tamper-evident seal. The system issues voters one-time blind-signed tokens to protect anonymity, and provides receipts so they can confirm their vote was counted. We implemented a live prototype using common web technologies (Next.js, React, Firebase) to demonstrate end-to-end functionality, accessibility, and cost efficiency. Our contributions include developing a working demo, a complete election workflow, a hybrid blockchain design, and a user-friendly interface that balances privacy, security, transparency, and practicality. This research highlights the feasibility of secure, verifiable, and scalable online voting for organizations ranging from small groups to larger institutions.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Causal Inference from Multi-Site Observational Data via Propensity Score Aggregation</title>
<link>https://arxiv.org/abs/2505.17961</link>
<guid>https://arxiv.org/abs/2505.17961</guid>
<content:encoded><![CDATA[
arXiv:2505.17961v2 Announce Type: replace-cross 
Abstract: Causal inference typically assumes centralized access to individual-level data. Yet, in practice, data are often decentralized across multiple sites, making centralization infeasible due to privacy, logistical, or legal constraints. We address this problem by estimating the Average Treatment Effect (ATE) from decentralized observational data via a Federated Learning (FL) approach, allowing inference through the exchange of aggregate statistics rather than individual-level data. We propose a novel method to estimate propensity scores by computing a federated weighted average of local scores with Membership Weights (MW)--probabilities of site membership conditional on covariates--which can be flexibly estimated using parametric or non-parametric classification models. Unlike density ratio weights (DW) from the transportability and generalization literature, which either rely on strong modeling assumptions or cannot be implemented in FL, MW can be estimated using standard FL algorithms and are more robust, as they support flexible, non-parametric models--making them the preferred choice in multi-site settings with strict data-sharing constraints. The resulting propensity scores are used to construct Federated Inverse Propensity Weighting (Fed-IPW) and Augmented IPW (Fed-AIPW) estimators. Unlike meta-analysis methods, which fail when any site violates positivity, our approach leverages heterogeneity in treatment assignment across sites to improve overlap. We show that Fed-IPW and Fed-AIPW perform well under site-level heterogeneity in sample sizes, treatment mechanisms, and covariate distributions. Both theoretical analysis and experiments on simulated and real-world data highlight their advantages over meta-analysis and related methods.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Permuting Transactions in Ethereum Blocks: An Empirical Study</title>
<link>https://arxiv.org/abs/2509.25415</link>
<guid>https://arxiv.org/abs/2509.25415</guid>
<content:encoded><![CDATA[
arXiv:2509.25415v1 Announce Type: new 
Abstract: Several recent proposals implicitly or explicitly suggest making use of randomized transaction ordering within a block to mitigate centralization effects and to improve fairness in the Ethereum ecosystem. However, transactions and blocks are subject to gas limits and protocol rules. In a randomized transaction order, the behavior of transactions may change depending on other transactions in the same block, leading to invalid blocks and varying gas consumptions. In this paper, we quantify and characterize protocol violations, execution errors and deviations in gas consumption of blocks and transactions to examine technical deployability. For that, we permute and execute the transactions of over 335,000 Ethereum Mainnet blocks multiple times. About 22% of block permutations are invalid due to protocol violations caused by privately mined transactions or blocks close to their gas limit. Also, almost all transactions which show execution errors under permutation but not in the original order are privately mined transactions. Only 6% of transactions show deviations in gas consumption and 98% of block permutations deviate at most 10% from their original gas consumption. From a technical perspective, these results suggest that randomized transaction ordering may be feasible if transaction selection is handled carefully.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Interact in World Latent for Team Coordination</title>
<link>https://arxiv.org/abs/2509.25550</link>
<guid>https://arxiv.org/abs/2509.25550</guid>
<content:encoded><![CDATA[
arXiv:2509.25550v1 Announce Type: new 
Abstract: This work presents a novel representation learning framework, interactive world latent (IWoL), to facilitate team coordination in multi-agent reinforcement learning (MARL). Building effective representation for team coordination is a challenging problem, due to the intricate dynamics emerging from multi-agent interaction and incomplete information induced by local observations. Our key insight is to construct a learnable representation space that jointly captures inter-agent relations and task-specific world information by directly modeling communication protocols. This representation, we maintain fully decentralized execution with implicit coordination, all while avoiding the inherent drawbacks of explicit message passing, e.g., slower decision-making, vulnerability to malicious attackers, and sensitivity to bandwidth constraints. In practice, our representation can be used not only as an implicit latent for each agent, but also as an explicit message for communication. Across four challenging MARL benchmarks, we evaluate both variants and show that IWoL provides a simple yet powerful key for team coordination. Moreover, we demonstrate that our representation can be combined with existing MARL algorithms to further enhance their performance.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Split Learning with Sharded and Blockchain-Enabled SplitFed Approaches</title>
<link>https://arxiv.org/abs/2509.25555</link>
<guid>https://arxiv.org/abs/2509.25555</guid>
<content:encoded><![CDATA[
arXiv:2509.25555v1 Announce Type: new 
Abstract: Collaborative and distributed learning techniques, such as Federated Learning (FL) and Split Learning (SL), hold significant promise for leveraging sensitive data in privacy-critical domains. However, FL and SL suffer from key limitations -- FL imposes substantial computational demands on clients, while SL leads to prolonged training times. To overcome these challenges, SplitFed Learning (SFL) was introduced as a hybrid approach that combines the strengths of FL and SL. Despite its advantages, SFL inherits scalability, performance, and security issues from SL. In this paper, we propose two novel frameworks: Sharded SplitFed Learning (SSFL) and Blockchain-enabled SplitFed Learning (BSFL). SSFL addresses the scalability and performance constraints of SFL by distributing the workload and communication overhead of the SL server across multiple parallel shards. Building upon SSFL, BSFL replaces the centralized server with a blockchain-based architecture that employs a committee-driven consensus mechanism to enhance fairness and security. BSFL incorporates an evaluation mechanism to exclude poisoned or tampered model updates, thereby mitigating data poisoning and model integrity attacks. Experimental evaluations against baseline SL and SFL approaches show that SSFL improves performance and scalability by 31.2% and 85.2%, respectively. Furthermore, BSFL increases resilience to data poisoning attacks by 62.7% while maintaining superior performance under normal operating conditions. To the best of our knowledge, BSFL is the first blockchain-enabled framework to implement an end-to-end decentralized SplitFed Learning system.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lightweight and Robust Federated Data Valuation</title>
<link>https://arxiv.org/abs/2509.25560</link>
<guid>https://arxiv.org/abs/2509.25560</guid>
<content:encoded><![CDATA[
arXiv:2509.25560v1 Announce Type: new 
Abstract: Federated learning (FL) faces persistent robustness challenges due to non-IID data distributions and adversarial client behavior. A promising mitigation strategy is contribution evaluation, which enables adaptive aggregation by quantifying each client's utility to the global model. However, state-of-the-art Shapley-value-based approaches incur high computational overhead due to repeated model reweighting and inference, which limits their scalability. We propose FedIF, a novel FL aggregation framework that leverages trajectory-based influence estimation to efficiently compute client contributions. FedIF adapts decentralized FL by introducing normalized and smoothed influence scores computed from lightweight gradient operations on client updates and a public validation set. Theoretical analysis demonstrates that FedIF yields a tighter bound on one-step global loss change under noisy conditions. Extensive experiments on CIFAR-10 and Fashion-MNIST show that FedIF achieves robustness comparable to or exceeding SV-based methods in the presence of label noise, gradient noise, and adversarial samples, while reducing aggregation overhead by up to 450x. Ablation studies confirm the effectiveness of FedIF's design choices, including local weight normalization and influence smoothing. Our results establish FedIF as a practical, theoretically grounded, and scalable alternative to Shapley-value-based approaches for efficient and robust FL in real-world deployments.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero Trust-based Decentralized Identity Management System for Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2509.25566</link>
<guid>https://arxiv.org/abs/2509.25566</guid>
<content:encoded><![CDATA[
arXiv:2509.25566v1 Announce Type: new 
Abstract: The rise of autonomous vehicles (AVs) promises to significantly enhance transportation safety and efficiency by mitigating human error, which is responsible for over 90\% of road accidents. However, the increasing connectivity of AVs introduces new cybersecurity challenges, as traditional perimeter-based security models are inadequate for dynamic and untrusted environments. This paper presents a novel Zero Trust-based Decentralized Identity Management (D-IM) protocol for AVs. By integrating the core principles of Zero Trust Architecture, "never trust, always verify", with the tamper resistant and decentralized nature of a blockchain network, our framework eliminates reliance on centralized authorities and provides continuous verification for every entity. We detail the system's design, which leverages Hyperledger Iroha to enable lightweight and secure authentication without a central trusted entity. A comprehensive experimental evaluation, conducted across both urban and highway scenarios, validates the protocol's practicality. Our results demonstrate that the D-IM framework introduces minimal overhead, with less than 7.5\% reduction in Packet Reception Rate (PRR) in urban settings and an increase of under 11\% in Channel Busy Ratio (CBR) for LTE-V2X. These findings prove the protocol's efficiency and robustness, providing a resilient foundation for securing real-time V2X communication against impersonation and replay attacks.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Asynchronous Multi-player Bandits</title>
<link>https://arxiv.org/abs/2509.25824</link>
<guid>https://arxiv.org/abs/2509.25824</guid>
<content:encoded><![CDATA[
arXiv:2509.25824v1 Announce Type: new 
Abstract: In recent years, multi-player multi-armed bandits (MP-MAB) have been extensively studied due to their wide applications in cognitive radio networks and Internet of Things systems. While most existing research on MP-MAB focuses on synchronized settings, real-world systems are often decentralized and asynchronous, where players may enter or leave the system at arbitrary times, and do not have a global clock. This decentralized asynchronous setting introduces two major challenges. First, without a global time, players cannot implicitly coordinate their actions through time, making it difficult to avoid collisions. Second, it is important to detect how many players are in the system, but doing so may cost a lot. In this paper, we address the challenges posed by such a fully asynchronous setting in a decentralized environment. We develop a novel algorithm in which players adaptively change between exploration and exploitation. During exploration, players uniformly pull their arms, reducing the probability of collisions and effectively mitigating the first challenge. Meanwhile, players continue pulling arms currently exploited by others with a small probability, enabling them to detect when a player has left, thereby addressing the second challenge. We prove that our algorithm achieves a regret of $\mathcal{O}(\sqrt{T \log T} + {\log T}/{\Delta^2})$, where $\Delta$ is the minimum expected reward gap between any two arms. To the best of our knowledge, this is the first efficient MP-MAB algorithm in the asynchronous and decentralized environment. Extensive experiments further validate the effectiveness and robustness of our algorithm, demonstrating its applicability to real-world scenarios.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Achieving Pareto Optimality in Games via Single-bit Feedback</title>
<link>https://arxiv.org/abs/2509.25921</link>
<guid>https://arxiv.org/abs/2509.25921</guid>
<content:encoded><![CDATA[
arXiv:2509.25921v1 Announce Type: new 
Abstract: Efficient coordination in multi-agent systems often incurs high communication overhead or slow convergence rates, making scalable welfare optimization difficult. We propose Single-Bit Coordination Dynamics for Pareto-Efficient Outcomes (SBC-PE), a decentralized learning algorithm requiring only a single-bit satisfaction signal per agent each round. Despite this extreme efficiency, SBC-PE guarantees convergence to the exact optimal solution in arbitrary finite games. We establish explicit regret bounds, showing expected regret grows only logarithmically with the horizon, i.e., O(log T). Compared with prior payoff-based or bandit-style rules, SBC-PE uniquely combines minimal signaling, general applicability, and finite-time guarantees. These results show scalable welfare optimization is achievable under minimal communication constraints.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Parallax: Efficient LLM Inference Service over Decentralized Environment</title>
<link>https://arxiv.org/abs/2509.26182</link>
<guid>https://arxiv.org/abs/2509.26182</guid>
<content:encoded><![CDATA[
arXiv:2509.26182v1 Announce Type: new 
Abstract: Deploying a large language model (LLM) inference service remains costly because centralized serving depends on specialized GPU clusters and high-bandwidth interconnects in datacenters. An appealing alternative is to leverage collaborative decentralized GPU pools. However, heterogeneity in GPU and limited interconnected network bandwidth, along with potentially dynamic availability, make efficient scheduling the central challenge in this scenario. In this paper, we present Parallax, a decentralized LLM serving system that turns a pool of heterogeneous GPUs into an efficient inference platform via a two-phase scheduler. Parallax decomposes planning into (i) model allocation, which places layers of each replica across diverse GPUs to jointly optimize latency and throughput under memory and link-bandwidth constraints, and (ii) request-time GPU pipeline selection, which stitches layers from different replicas into end-to-end execution chains that balance load and adapt to current conditions. We implement Parallax and evaluate it on open-source LLMs deployed over real volunteer nodes. Parallax consistently reduces latency and increases throughput relative to decentralized baselines, demonstrating that principled scheduling can make volunteer compute a practical, affordable substrate for LLM inference.
  Github Repo at: https://github.com/GradientHQ/parallax.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Shot Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2509.26462</link>
<guid>https://arxiv.org/abs/2509.26462</guid>
<content:encoded><![CDATA[
arXiv:2509.26462v1 Announce Type: new 
Abstract: CLIP has revolutionized zero-shot learning by enabling task generalization without fine-tuning. While prompting techniques like CoOp and CoCoOp enhance CLIP's adaptability, their effectiveness in Federated Learning (FL) remains an open challenge. Existing federated prompt learning approaches, such as FedCoOp and FedTPG, improve performance but face generalization issues, high communication costs, and reliance on a central server, limiting scalability and privacy. We propose Zero-shot Decentralized Federated Learning (ZeroDFL), a fully decentralized framework that enables zero-shot adaptation across distributed clients without a central coordinator. ZeroDFL employs an iterative prompt-sharing mechanism, allowing clients to optimize and exchange textual prompts to enhance generalization while drastically reducing communication overhead. We validate ZeroDFL on nine diverse image classification datasets, demonstrating that it consistently outperforms--or remains on par with--state-of-the-art federated prompt learning methods. More importantly, ZeroDFL achieves this performance in a fully decentralized setting while reducing communication overhead by 118x compared to FedTPG. These results highlight that our approach not only enhances generalization in federated zero-shot learning but also improves scalability, efficiency, and privacy preservation--paving the way for decentralized adaptation of large vision-language models in real-world applications.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TAP: Two-Stage Adaptive Personalization of Multi-task and Multi-Modal Foundation Models in Federated Learning</title>
<link>https://arxiv.org/abs/2509.26524</link>
<guid>https://arxiv.org/abs/2509.26524</guid>
<content:encoded><![CDATA[
arXiv:2509.26524v1 Announce Type: new 
Abstract: Federated Learning (FL), despite demonstrating impressive capabilities in the training of multiple models in a decentralized manner, has been shown to produce a final model not necessarily well-suited to the needs of each client. While extensive work has been conducted on how to create tailored personalized models, called Personalized Federated Learning (PFL), less attention has been given to personalization via fine-tuning of foundation models with multi-task and multi-modal properties. Moreover, there exists a lack of understanding in the literature on how to fine-tune and personalize such models in a setting that is heterogeneous across clients not only in data, but also in tasks and modalities. To address this gap in the literature, we propose TAP (Two-Stage Adaptive Personalization), which (i) leverages mismatched model architectures between the clients and server to selectively conduct replacement operations when it benefits a client's local tasks and (ii) engages in post-FL knowledge distillation for capturing beneficial general knowledge without compromising personalization. We also introduce the first convergence analysis of the server model under its modality-task pair architecture, and demonstrate that as the number of modality-task pairs increases, its ability to cater to all tasks suffers. Through extensive experiments, we demonstrate the effectiveness of our proposed algorithm across a variety of datasets and tasks in comparison to a multitude of baselines. Implementation code is publicly available at https://github.com/lee3296/TAP.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Searcher Competition in Block Building</title>
<link>https://arxiv.org/abs/2407.07474</link>
<guid>https://arxiv.org/abs/2407.07474</guid>
<content:encoded><![CDATA[
arXiv:2407.07474v2 Announce Type: replace 
Abstract: We study the amount of maximal extractable value (MEV) captured by validators, as a function of searcher competition, in blockchains with competitive block building markets such as Ethereum. We argue that the core is a suitable solution concept in this context that makes robust predictions that are independent of implementation details or specific mechanisms chosen. We characterize how much value validators extract in the core and quantify the surplus share of validators as a function of searcher competition. Searchers can obtain at most the marginal value increase of the winning block relative to the best block that can be built without their bundles. Dually this gives a lower bound on the value extracted by the validator. If arbitrages are easy to find and many searchers find similar bundles, the validator gets paid all value almost surely, while searchers can capture most value if there is little searcher competition per arbitrage. For the case of passive block-proposers we study, moreover, mechanisms that implement core allocations in dominant strategies and find that for submodular value, there is a unique dominant-strategy incentive compatible core-selecting mechanism that gives each searcher exactly their marginal value contribution to the winning block. We validate our theoretical prediction empirically with aggregate bundle data and find a significant positive relation between the number of submitted backruns for the same opportunity and the median value captured by the proposer from the opportunity.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Competition to Centralization: The Oligopoly in Ethereum Block Building Auctions</title>
<link>https://arxiv.org/abs/2412.18074</link>
<guid>https://arxiv.org/abs/2412.18074</guid>
<content:encoded><![CDATA[
arXiv:2412.18074v2 Announce Type: replace 
Abstract: Block production on the Ethereum blockchain has adopted an auction-based mechanism known as Proposer--Builder Separation (PBS), where validators outsource block creation to builders competing in MEV--Boost auctions for Maximal Extractable Value (MEV) rewards. We employ empirical game-theoretic analysis based on simulations to examine how advantages in latency and MEV access shape builder strategic bidding and auction outcomes. We find that a small set of dominant builders leverage these advantages, consolidating power, reducing auction efficiency, and heightening centralization. Our results underscore the need for fair MEV distribution and sustained efforts to promote decentralization in Ethereum's block building market.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Thunderdome: Timelock-Free Rationally-Secure Virtual Channels</title>
<link>https://arxiv.org/abs/2501.14418</link>
<guid>https://arxiv.org/abs/2501.14418</guid>
<content:encoded><![CDATA[
arXiv:2501.14418v4 Announce Type: replace 
Abstract: Payment channel networks (PCNs) offer a promising solution to address the limited transaction throughput of deployed blockchains. However, several attacks have recently been proposed that stress the vulnerability of PCNs to timelock and censoring attacks. To address such attacks, we introduce Thunderdome, the first timelock-free PCN. Instead, Thunderdome leverages the design rationale of virtual channels to extend a timelock-free payment channel primitive, thereby enabling multi-hop transactions without timelocks. Previous works either utilize timelocks or do not accommodate transactions between parties that do not share a channel.
  At its core, Thunderdome relies on a committee of non-trusted watchtowers, known as wardens, who ensure that no honest party loses funds, even when offline, during the channel closure process. We introduce tailored incentive mechanisms to ensure that all participants follow the protocol's correct execution. Besides a traditional security proof that assumes an honest majority of the committee, we conduct a formal game-theoretic analysis to demonstrate the security of Thunderdome when all participants, including wardens, act rationally. We implement a proof of concept of Thunderdome on Ethereum to validate its feasibility and evaluate its costs. Our evaluation shows that deploying Thunderdome, including opening the underlying payment channel, costs approximately \$15 (0.0089 ETH), while the worst-case cost for closing a channel is about \$7 (0.004 ETH).
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AntiFLipper: A Secure and Efficient Defense Against Label-Flipping Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2509.22873</link>
<guid>https://arxiv.org/abs/2509.22873</guid>
<content:encoded><![CDATA[
arXiv:2509.22873v2 Announce Type: replace 
Abstract: Federated learning (FL) enables privacy-preserving model training by keeping data decentralized. However, it remains vulnerable to label-flipping attacks, where malicious clients manipulate labels to poison the global model. Despite their simplicity, these attacks can severely degrade model performance, and defending against them remains challenging. We introduce AntiFLipper, a novel and computationally efficient defense against multi-class label-flipping attacks in FL. Unlike existing methods that ensure security at the cost of high computational overhead, AntiFLipper employs a novel client-side detection strategy, significantly reducing the central server's burden during aggregation. Comprehensive empirical evaluations across multiple datasets under different distributions demonstrate that AntiFLipper achieves accuracy comparable to state-of-the-art defenses while requiring substantially fewer computational resources in server side. By balancing security and efficiency, AntiFLipper addresses a critical gap in existing defenses, making it particularly suitable for resource-constrained FL deployments where both model integrity and operational efficiency are essential.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Satellite: Detecting and Analyzing Smart Contract Vulnerabilities caused by Subcontract Misuse</title>
<link>https://arxiv.org/abs/2509.23679</link>
<guid>https://arxiv.org/abs/2509.23679</guid>
<content:encoded><![CDATA[
arXiv:2509.23679v1 Announce Type: new 
Abstract: Developers of smart contracts pervasively reuse subcontracts to improve development efficiency. Like any program language, such subcontract reuse may unexpectedly include, or introduce vulnerabilities to the end-point smart contract. Unfortunately, automatically detecting such issues poses several unique challenges. Particularly, in most cases, smart contracts are compiled as bytecode, whose class-level information (e.g., inheritance, virtual function table), and even semantics (e.g., control flow and data flow) are fully obscured as a single smart contract after compilation.
  In this paper, we propose Satellite, a new bytecode-level static analysis framework for subcontract misuse vulnerability (SMV) detection in smart contracts. Satellite incorporates a series of novel designs to enhance its overall effectiveness.. Particularly, Satellite utilizes a transfer learning method to recover the inherited methods, which are critical for identifying subcontract reuse in smart contracts. Further, Satellite extracts a set of fine-grained method-level features and performs a method-level comparison, for identifying the reuse part of subcontract in smart contracts. Finally, Satellite summarizes a set of SMV indicators according to their types, and hence effectively identifies SMVs. To evaluate Satellite, we construct a dataset consisting of 58 SMVs derived from real-world attacks and collect additional 56 SMV patterns from SOTA studies. Experiment results indicate that Satellite exhibits good performance in identifying SMV, with a precision rate of 84.68% and a recall rate of 92.11%. In addition, Satellite successfully identifies 14 new/unknown SMV over 10,011 real-world smart contracts, affecting a total amount of digital assets worth 201,358 USD.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Dynamic Cooperation of Personalized Models for Federated Continual Learning</title>
<link>https://arxiv.org/abs/2509.23683</link>
<guid>https://arxiv.org/abs/2509.23683</guid>
<content:encoded><![CDATA[
arXiv:2509.23683v1 Announce Type: new 
Abstract: Federated continual learning (FCL) has garnered increasing attention for its ability to support distributed computation in environments with evolving data distributions. However, the emergence of new tasks introduces both temporal and cross-client shifts, making catastrophic forgetting a critical challenge. Most existing works aggregate knowledge from clients into a global model, which may not enhance client performance since irrelevant knowledge could introduce interference, especially in heterogeneous scenarios. Additionally, directly applying decentralized approaches to FCL suffers from ineffective group formation caused by task changes. To address these challenges, we propose a decentralized dynamic cooperation framework for FCL, where clients establish dynamic cooperative learning coalitions to balance the acquisition of new knowledge and the retention of prior learning, thereby obtaining personalized models. To maximize model performance, each client engages in selective cooperation, dynamically allying with others who offer meaningful performance gains. This results in non-overlapping, variable coalitions at each stage of the task. Moreover, we use coalitional affinity game to simulate coalition relationships between clients. By assessing both client gradient coherence and model similarity, we quantify the client benefits derived from cooperation. We also propose a merge-blocking algorithm and a dynamic cooperative evolution algorithm to achieve cooperative and dynamic equilibrium. Comprehensive experiments demonstrate the superiority of our method compared to various baselines. Code is available at: https://github.com/ydn3229/DCFCL.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Short-Term Guidance Algorithm on a Drone Road System</title>
<link>https://arxiv.org/abs/2509.23794</link>
<guid>https://arxiv.org/abs/2509.23794</guid>
<content:encoded><![CDATA[
arXiv:2509.23794v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicles (UAVs), commonly known as drones, have experienced expanding use in urban environments in recent years. However, the growing density of drones raises significant challenges, such as avoiding collisions and managing air traffic efficiently, especially in congested areas. To address these issues, a structured road system and an effective guidance algorithm are essential. In this paper, we introduce a markup language allowing to describe drone road systems (DRS), in which a road system is given by a set of individual roads, each of which can have a varying number of lanes. Roads can be linked through connecting lanes. Furthermore, we propose a novel short-term decentralized greedy (STDG) guidance algorithm that uses only the position and speed information of nearby drones -- communicated via periodically transmitted beacons -- to make real-time decisions such as stopping, changing lanes, or adjusting speed for the next few seconds. Unlike existing methods that rely on centralized coordination, our algorithm enables drones to operate independently while ensuring safety and efficiency. We present simulation results showing the impact of key wireless and algorithm parameters on performance metrics like the drone collision rate, average speed and throughput of the drone road system.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation</title>
<link>https://arxiv.org/abs/2509.23824</link>
<guid>https://arxiv.org/abs/2509.23824</guid>
<content:encoded><![CDATA[
arXiv:2509.23824v1 Announce Type: new 
Abstract: The rise of blockchain has brought smart contracts into mainstream use, creating a demand for smart contract generation tools. While large language models (LLMs) excel at generating code in general-purpose languages, their effectiveness on Solidity, the primary language for smart contracts, remains underexplored. Solidity constitutes only a small portion of typical LLM training data and differs from general-purpose languages in its version-sensitive syntax and limited flexibility. These factors raise concerns about the reliability of existing LLMs for Solidity code generation. Critically, existing evaluations, focused on isolated functions and synthetic inputs, fall short of assessing models' capabilities in real-world contract development.
  To bridge this gap, we introduce SolContractEval, the first contract-level benchmark for Solidity code generation. It comprises 124 tasks drawn from real on-chain contracts across nine major domains. Each task input, consisting of complete context dependencies, a structured contract framework, and a concise task prompt, is independently annotated and cross-validated by experienced developers. To enable precise and automated evaluation of functional correctness, we also develop a dynamic evaluation framework based on historical transaction replay. Building on SolContractEval, we perform a systematic evaluation of six mainstream LLMs. We find that Claude-3.7-Sonnet achieves the highest overall performance, though evaluated models underperform relative to their capabilities on class-level generation tasks in general-purpose programming languages. Second, current models perform better on tasks that follow standard patterns but struggle with complex logic and inter-contract dependencies. Finally, they exhibit limited understanding of Solidity-specific features and contextual dependencies.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control</title>
<link>https://arxiv.org/abs/2509.23960</link>
<guid>https://arxiv.org/abs/2509.23960</guid>
<content:encoded><![CDATA[
arXiv:2509.23960v1 Announce Type: new 
Abstract: Co-optimizing safety and performance in large-scale multi-agent systems remains a fundamental challenge. Existing approaches based on multi-agent reinforcement learning (MARL), safety filtering, or Model Predictive Control (MPC) either lack strict safety guarantees, suffer from conservatism, or fail to scale effectively. We propose MAD-PINN, a decentralized physics-informed machine learning framework for solving the multi-agent state-constrained optimal control problem (MASC-OCP). Our method leverages an epigraph-based reformulation of SC-OCP to simultaneously capture performance and safety, and approximates its solution via a physics-informed neural network. Scalability is achieved by training the SC-OCP value function on reduced-agent systems and deploying them in a decentralized fashion, where each agent relies only on local observations of its neighbours for decision-making. To further enhance safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based neighbour selection strategy to prioritize safety-critical interactions, and a receding-horizon policy execution scheme that adapts to dynamic interactions while reducing computational burden. Experiments on multi-agent navigation tasks demonstrate that MAD-PINN achieves superior safety-performance trade-offs, maintains scalability as the number of agents grows, and consistently outperforms state-of-the-art baselines.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Curriculum-Guided Reinforcement Learning for Synthesizing Gas-Efficient Financial Derivatives Contracts</title>
<link>https://arxiv.org/abs/2509.23976</link>
<guid>https://arxiv.org/abs/2509.23976</guid>
<content:encoded><![CDATA[
arXiv:2509.23976v1 Announce Type: new 
Abstract: Smart contract-based automation of financial derivatives offers substantial efficiency gains, but its real-world adoption is constrained by the complexity of translating financial specifications into gas-efficient executable code. In particular, generating code that is both functionally correct and economically viable from high-level specifications, such as the Common Domain Model (CDM), remains a significant challenge. This paper introduces a Reinforcement Learning (RL) framework to generate functional and gas-optimized Solidity smart contracts directly from CDM specifications. We employ a Proximal Policy Optimization (PPO) agent that learns to select optimal code snippets from a pre-defined library. To manage the complex search space, a two-phase curriculum first trains the agent for functional correctness before shifting its focus to gas optimization. Our empirical results show the RL agent learns to generate contracts with significant gas savings, achieving cost reductions of up to 35.59% on unseen test data compared to unoptimized baselines. This work presents a viable methodology for the automated synthesis of reliable and economically sustainable smart contracts, bridging the gap between high-level financial agreements and efficient on-chain execution.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multiple Concurrent Proposers: Why and How</title>
<link>https://arxiv.org/abs/2509.23984</link>
<guid>https://arxiv.org/abs/2509.23984</guid>
<content:encoded><![CDATA[
arXiv:2509.23984v1 Announce Type: new 
Abstract: Traditional single-proposer blockchains suffer from miner extractable value (MEV), where validators exploit their serial monopoly on transaction inclusion and ordering to extract rents from users. While there have been many developments at the application layer to reduce the impact of MEV, these approaches largely require auctions as a subcomponent. Running auctions efficiently on chain requires two key properties of the underlying consensus protocol: selective-censorship resistance and hiding. These properties guarantee that an adversary can neither selectively delay transactions nor see their contents before they are confirmed. We propose a multiple concurrent proposer (MCP) protocol offering exactly these properties.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimism as Risk-Seeking in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2509.24047</link>
<guid>https://arxiv.org/abs/2509.24047</guid>
<content:encoded><![CDATA[
arXiv:2509.24047v1 Announce Type: new 
Abstract: Risk sensitivity has become a central theme in reinforcement learning (RL), where convex risk measures and robust formulations provide principled ways to model preferences beyond expected return. Recent extensions to multi-agent RL (MARL) have largely emphasized the risk-averse setting, prioritizing robustness to uncertainty. In cooperative MARL, however, such conservatism often leads to suboptimal equilibria, and a parallel line of work has shown that optimism can promote cooperation. Existing optimistic methods, though effective in practice, are typically heuristic and lack theoretical grounding. Building on the dual representation for convex risk measures, we propose a principled framework that interprets risk-seeking objectives as optimism. We introduce optimistic value functions, which formalize optimism as divergence-penalized risk-seeking evaluations. Building on this foundation, we derive a policy-gradient theorem for optimistic value functions, including explicit formulas for the entropic risk/KL-penalty setting, and develop decentralized optimistic actor-critic algorithms that implement these updates. Empirical results on cooperative benchmarks demonstrate that risk-seeking optimism consistently improves coordination over both risk-neutral baselines and heuristic optimistic methods. Our framework thus unifies risk-sensitive learning and optimism, offering a theoretically grounded and practically effective approach to cooperation in MARL.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VeriLLM: A Lightweight Framework for Publicly Verifiable Decentralized Inference</title>
<link>https://arxiv.org/abs/2509.24257</link>
<guid>https://arxiv.org/abs/2509.24257</guid>
<content:encoded><![CDATA[
arXiv:2509.24257v1 Announce Type: new 
Abstract: Decentralized inference is an appealing paradigm for serving large language models (LLMs), offering strong security, high efficiency, and lower operating costs. Yet the permissionless setting admits no a priori trust in participating nodes, making output verifiability a prerequisite for secure deployment. We present VeriLLM, a publicly verifiable protocol for decentralized LLM inference that (i) achieves security under a one-honest-verifier assumption, (ii) attains near-negligible verification cost (about 1% of the underlying inference) via a lightweight verification algorithm designed explicitly for LLMs, and (iii) enforces honest checking through a peer-prediction mechanism that mitigates lazy verification in naive voting. We further introduce an isomorphic inference-verification network that multiplexes both roles on the same set of GPU workers. This architecture (i) increases GPU utilization and thereby improves end-to-end throughput for both inference and verification, (ii) expands the effective pool of available validators, strengthening robustness and security, and (iii) enforces task indistinguishability at the worker boundary to prevent job-type-conditioned behavior. Finally, we provide a formal game-theoretic analysis and prove that, under our incentives, honest inference and verification constitute a Nash equilibrium, ensuring incentive compatibility against rational adversaries. To our knowledge, this is the first decentralized inference verification protocol with an end-to-end game-theoretic security proof.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>H+: An Efficient Similarity-Aware Aggregation for Byzantine Resilient Federated Learning</title>
<link>https://arxiv.org/abs/2509.24330</link>
<guid>https://arxiv.org/abs/2509.24330</guid>
<content:encoded><![CDATA[
arXiv:2509.24330v1 Announce Type: new 
Abstract: Federated Learning (FL) enables decentralized model training without sharing raw data. However, it remains vulnerable to Byzantine attacks, which can compromise the aggregation of locally updated parameters at the central server. Similarity-aware aggregation has emerged as an effective strategy to mitigate such attacks by identifying and filtering out malicious clients based on similarity between client model parameters and those derived from clean data, i.e., data that is uncorrupted and trustworthy. However, existing methods adopt this strategy only in FL systems with clean data, making them inapplicable to settings where such data is unavailable. In this paper, we propose H+, a novel similarity-aware aggregation approach that not only outperforms existing methods in scenarios with clean data, but also extends applicability to FL systems without any clean data. Specifically, H+ randomly selects $r$-dimensional segments from the $p$-dimensional parameter vectors uploaded to the server and applies a similarity check function $H$ to compare each segment against a reference vector, preserving the most similar client vectors for aggregation. The reference vector is derived either from existing robust algorithms when clean data is unavailable or directly from clean data. Repeating this process $K$ times enables effective identification of honest clients. Moreover, H+ maintains low computational complexity, with an analytical time complexity of $\mathcal{O}(KMr)$, where $M$ is the number of clients and $Kr \ll p$. Comprehensive experiments validate H+ as a state-of-the-art (SOTA) method, demonstrating substantial robustness improvements over existing approaches under varying Byzantine attack ratios and multiple types of traditional Byzantine attacks, across all evaluated scenarios and benchmark datasets.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BugMagnifier: TON Transaction Simulator for Revealing Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2509.24444</link>
<guid>https://arxiv.org/abs/2509.24444</guid>
<content:encoded><![CDATA[
arXiv:2509.24444v1 Announce Type: new 
Abstract: The Open Network (TON) blockchain employs an asynchronous execution model that introduces unique security challenges for smart contracts, particularly race conditions arising from unpredictable message processing order. While previous work established vulnerability patterns through static analysis of audit reports, dynamic detection of temporal dependencies through systematic testing remains an open problem. We present BugMagnifier, a transaction simulation framework that systematically reveals vulnerabilities in TON smart contracts through controlled message orchestration. Built atop TON Sandbox and integrated with the TON Virtual Machine (TVM), our tool combines precise message queue manipulation with differential state analysis and probabilistic permutation testing to detect asynchronous execution flaws. Experimental evaluation demonstrates BugMagnifier's effectiveness through extensive parametric studies on purpose-built vulnerable contracts, revealing message ratio-dependent detection complexity that aligns with theoretical predictions. This quantitative model enables predictive vulnerability assessment while shifting discovery from manual expert analysis to automated evidence generation. By providing reproducible test scenarios for temporal vulnerabilities, BugMagnifier addresses a critical gap in the TON security tooling, offering practical support for safer smart contract development in asynchronous blockchain environments.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributionally Robust Federated Learning with Outlier Resilience</title>
<link>https://arxiv.org/abs/2509.24462</link>
<guid>https://arxiv.org/abs/2509.24462</guid>
<content:encoded><![CDATA[
arXiv:2509.24462v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training without direct data sharing, but its performance can degrade significantly in the presence of data distribution perturbations. Distributionally robust optimization (DRO) provides a principled framework for handling this by optimizing performance against the worst-case distributions within a prescribed ambiguity set. However, existing DRO-based FL methods often overlook the detrimental impact of outliers in local datasets, which can disproportionately bias the learned models. In this work, we study distributionally robust federated learning with explicit outlier resilience. We introduce a novel ambiguity set based on the unbalanced Wasserstein distance, which jointly captures geometric distributional shifts and incorporates a non-geometric Kullback--Leibler penalization to mitigate the influence of outliers. This formulation naturally leads to a challenging min--max--max optimization problem. To enable decentralized training, we reformulate the problem as a tractable Lagrangian penalty optimization, which admits robustness certificates. Building on this reformulation, we propose the distributionally outlier-robust federated learning algorithm and establish its convergence guarantees. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our approach.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Specification Generator for Move Programs</title>
<link>https://arxiv.org/abs/2509.24515</link>
<guid>https://arxiv.org/abs/2509.24515</guid>
<content:encoded><![CDATA[
arXiv:2509.24515v1 Announce Type: new 
Abstract: While LLM-based specification generation is gaining traction, existing tools primarily focus on mainstream programming languages like C, Java, and even Solidity, leaving emerging and yet verification-oriented languages like Move underexplored. In this paper, we introduce MSG, an automated specification generation tool designed for Move smart contracts. MSG aims to highlight key insights that uniquely present when applying LLM-based specification generation to a new ecosystem. Specifically, MSG demonstrates that LLMs exhibit robust code comprehension and generation capabilities even for non-mainstream languages. MSG successfully generates verifiable specifications for 84% of tested Move functions and even identifies clauses previously overlooked by experts. Additionally, MSG shows that explicitly leveraging specification language features through an agentic, modular design improves specification quality substantially (generating 57% more verifiable clauses than conventional designs). Incorporating feedback from the verification toolchain further enhances the effectiveness of MSG, leading to a 30% increase in generated verifiable specifications.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prompting Robot Teams with Natural Language</title>
<link>https://arxiv.org/abs/2509.24575</link>
<guid>https://arxiv.org/abs/2509.24575</guid>
<content:encoded><![CDATA[
arXiv:2509.24575v1 Announce Type: new 
Abstract: This paper presents a framework towards prompting multi-robot teams with high-level tasks using natural language expressions. Our objective is to use the reasoning capabilities demonstrated by recent language models in understanding and decomposing human expressions of intent, and repurpose these for multi-robot collaboration and decision-making. The key challenge is that an individual's behavior in a collective can be hard to specify and interpret, and must continuously adapt to actions from others. This necessitates a framework that possesses the representational capacity required by the logic and semantics of a task, and yet supports decentralized and interactive real-time operation. We solve this dilemma by recognizing that a task can be represented as a deterministic finite automaton (DFA), and that recurrent neural networks (RNNs) can encode numerous automata. This allows us to distill the logic and sequential decompositions of sub-tasks obtained from a language model into an RNN, and align its internal states with the semantics of a given task. By training a graph neural network (GNN) control policy that is conditioned on the hidden states of the RNN and the language embeddings, our method enables robots to execute task-relevant actions in a decentralized manner. We present evaluations of this single light-weight interpretable model on various simulated and real-world multi-robot tasks that require sequential and collaborative behavior by the team -- sites.google.com/view/prompting-teams.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LISA Technical Report: An Agentic Framework for Smart Contract Auditing</title>
<link>https://arxiv.org/abs/2509.24698</link>
<guid>https://arxiv.org/abs/2509.24698</guid>
<content:encoded><![CDATA[
arXiv:2509.24698v1 Announce Type: new 
Abstract: We present LISA, an agentic smart contract vulnerability detection framework that combines rule-based and logic-based methods to address a broad spectrum of vulnerabilities in smart contracts. LISA leverages data from historical audit reports to learn the detection experience (without model fine-tuning), enabling it to generalize learned patterns to unseen projects and evolving threat profiles. In our evaluation, LISA significantly outperforms both LLM-based approaches and traditional static analysis tools, achieving superior coverage of vulnerability types and higher detection accuracy. Our results suggest that LISA offers a compelling solution for industry: delivering more reliable and comprehensive vulnerability detection while reducing the dependence on manual effort.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Driven Federation for Distributed Edge Systems: Design and Experimental Validation</title>
<link>https://arxiv.org/abs/2509.24846</link>
<guid>https://arxiv.org/abs/2509.24846</guid>
<content:encoded><![CDATA[
arXiv:2509.24846v1 Announce Type: new 
Abstract: Edge computing brings computation near end users, enabling the provisioning of novel use cases. To satisfy end-user requirements, the concept of edge federation has recently emerged as a key mechanism for dynamic resources and services sharing across edge systems managed by different administrative domains. However, existing federation solutions often rely on pre-established agreements and face significant limitations, including operational complexity, delays caused by manual operations, high overhead costs, and dependence on trusted third parties. In this context, blockchain can create dynamic federation agreements that enable service providers to securely interact and share services without prior trust.
  This article first describes the problem of edge federation, using the standardized ETSI multi-access edge computing framework as a reference architecture, and how it is being addressed. Then, it proposes a novel solution using blockchain and smart contracts to enable distributed MEC systems to dynamically negotiate and execute federation in a secure, automated, and scalable manner. We validate our framework's feasibility through a performance evaluation using a private Ethereum blockchain, built on the open-source Hyperledger Besu platform. The testbed includes a large number of MEC systems and compares two blockchain consensus algorithms. Experimental results demonstrate that our solution automates the entire federation lifecycle-from negotiation to deployment-with a quantifiable overhead, achieving federation in approximately 18 seconds in a baseline scenario. The framework scales efficiently in concurrent request scenarios, where multiple MEC systems initiate federation requests simultaneously. This approach provides a promising direction for addressing the complexities of dynamic, multi-domain federations across the edge-to-cloud continuum.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Free Option Problem of ePBS</title>
<link>https://arxiv.org/abs/2509.24849</link>
<guid>https://arxiv.org/abs/2509.24849</guid>
<content:encoded><![CDATA[
arXiv:2509.24849v1 Announce Type: new 
Abstract: Ethereum's upcoming Glamsterdam upgrade introduces EIP-7732 enshrined Proposer--Builder Separation (ePBS), which improves the block production pipeline by addressing trust and scalability challenges. Yet it also creates a new liveness risk: builders gain a short-dated ``free'' option to prevent the execution payload they committed to from becoming canonical, without incurring an additional penalty. Exercising this option renders an empty block for the slot in question, thereby degrading network liveness.
  We present the first systematic study of the free option problem. Our theoretical results predict that option value and exercise probability grow with market volatility, the length of the option window, and the share of block value derived from external signals such as external market prices. The availability of a free option will lead to mispricing and LP losses. The problem would be exacerbated if Ethereum further scales and attracts more liquidity. Empirical estimates of values and exercise probabilities on historical blocks largely confirm our theoretical predictions. While the option is rarely profitable to exercise on average (0.82\% of blocks assuming an 8-second option time window), it becomes significant in volatile periods, reaching up to 6\% of blocks on high-volatility days -- precisely when users most require timely execution.
  Moreover, builders whose block value relies heavily on CEX-DEX arbitrage are more likely to exercise the option. We demonstrate that mitigation strategies -- shortening the option window or penalizing exercised options -- effectively reduce liveness risk.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secret Leader Election in Ethereum PoS: An Empirical Security Analysis of Whisk and Homomorphic Sortition under DoS on the Leader and Censorship Attacks</title>
<link>https://arxiv.org/abs/2509.24955</link>
<guid>https://arxiv.org/abs/2509.24955</guid>
<content:encoded><![CDATA[
arXiv:2509.24955v1 Announce Type: new 
Abstract: Proposer anonymity in Proof-of-Stake (PoS) blockchains is a critical concern due to the risk of targeted attacks such as malicious denial-of-service (DoS) and censorship attacks. While several Secret Single Leader Election (SSLE) mechanisms have been proposed to address these threats, their practical impact and trade-offs remain insufficiently explored. In this work, we present a unified experimental framework for evaluating SSLE mechanisms under adversarial conditions, grounded in a simplified yet representative model of Ethereum's PoS consensus layer. The framework includes configurable adversaries capable of launching targeted DoS and censorship attacks, including coordinated strategies that simultaneously compromise groups of validators. We simulate and compare key protection mechanisms - Whisk, and homomorphic sortition. To the best of our knowledge, this is the first comparative study to examine adversarial DoS scenarios involving multiple attackers under diverse protection mechanisms. Our results show that while both designs offer strong protection against targeted DoS attacks on the leader, neither defends effectively against coordinated attacks on validator groups. Moreover, Whisk simplifies a DoS attack by narrowing the target set from all validators to a smaller list of known candidates. Homomorphic sortition, despite its theoretical strength, remains impractical due to the complexity of cryptographic operations over large validator sets.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARLIN: Multi-Agent Reinforcement Learning with Murmuration Intelligence and LLM Guidance for Reservoir Management</title>
<link>https://arxiv.org/abs/2509.25034</link>
<guid>https://arxiv.org/abs/2509.25034</guid>
<content:encoded><![CDATA[
arXiv:2509.25034v1 Announce Type: new 
Abstract: As climate change intensifies extreme weather events, water disasters pose growing threats to global communities, making adaptive reservoir management critical for protecting vulnerable populations and ensuring water security. Modern water resource management faces unprecedented challenges from cascading uncertainties propagating through interconnected reservoir networks. These uncertainties, rooted in physical water transfer losses and environmental variability, make precise control difficult. For example, sending 10 tons downstream may yield only 8-12 tons due to evaporation and seepage. Traditional centralized optimization approaches suffer from exponential computational complexity and cannot effectively handle such real-world uncertainties, while existing multi-agent reinforcement learning (MARL) methods fail to achieve effective coordination under uncertainty. To address these challenges, we present MARLIN, a decentralized reservoir management framework inspired by starling murmurations intelligence. Integrating bio-inspired alignment, separation, and cohesion rules with MARL, MARLIN enables individual reservoirs to make local decisions while achieving emergent global coordination. In addition, a LLM provides real-time reward shaping signals, guiding agents to adapt to environmental changes and human-defined preferences. Experiments on real-world USGS data show that MARLIN improves uncertainty handling by 23\%, cuts computation by 35\%, and accelerates flood response by 68\%, exhibiting super-linear coordination, with complexity scaling 5.4x from 400 to 10,000 nodes. These results demonstrate MARLIN's potential for disaster prevention and protecting communities through intelligent, scalable water resource management.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding How Network Geometry Influences Diffusion Processes in Complex Networks: A Focus on Cryptocurrency Blockchains and Critical Infrastructure Networks</title>
<link>https://arxiv.org/abs/2509.23450</link>
<guid>https://arxiv.org/abs/2509.23450</guid>
<content:encoded><![CDATA[
arXiv:2509.23450v1 Announce Type: cross 
Abstract: This study provides essential insights into how diffusion processes unfold in complex networks, with a focus on cryptocurrency blockchains and infrastructure networks. The structural properties of these networks, such as hub-dominated, heavy-tailed topology, network motifs, and node centrality, significantly influence diffusion speed and reach. Using epidemic diffusion models, specifically the Kertesz threshold model and the Susceptible-Infected (SI) model, we analyze key factors affecting diffusion dynamics. To assess the uncertainty in the fraction of infected nodes over time, we employ bootstrap confidence intervals, while Bayesian credible intervals are constructed to quantify parameter uncertainties in the SI models. Our findings reveal substantial variations across different network types, including Erd\H{o}s--R\'enyi networks, Geometric Random Graphs, and Delaunay Triangulation networks, emphasizing the role of network architecture in failure propagation. We identify that network motifs are crucial in diffusion. We highlight that hub-dominated networks, which dominate blockchain ecosystems, provide resilience against random failures but remain vulnerable to targeted attacks, posing significant risks to network stability. Furthermore, centrality measures such as degree, betweenness, and clustering coefficient strongly influence the transmissibility of diffusion in both blockchain and critical infrastructure networks.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TOB-SVD: Total-Order Broadcast with Single-Vote Decisions in the Sleepy Model</title>
<link>https://arxiv.org/abs/2310.11331</link>
<guid>https://arxiv.org/abs/2310.11331</guid>
<content:encoded><![CDATA[
arXiv:2310.11331v3 Announce Type: replace 
Abstract: Over the past years, distributed consensus research has expanded its focus to address challenges in large-scale, permissionless systems, such as blockchains. This shift reflects the need to accommodate dynamic participation, in contrast to the traditional model of a static set of continuously online validators. Works like Bitcoin and the sleepy model have laid the groundwork for this evolving framework.
  Notable contributions by Momose and Ren (CCS 2022), along with subsequent research, have introduced Total-Order Broadcast protocols that leverage Graded Agreement primitives and support dynamic participation. However, these approaches often require multiple phases of voting per decision, which can create a bottleneck for real-world, large-scale systems.
  To address this, our paper introduces TOB-SVD, a novel Total-Order Broadcast protocol in the sleepy model that is resilient to up to 1/2 Byzantine validators. TOB-SVD requires only a single phase of voting per decision in the best case and achieves lower expected latency compared to existing approaches offering the same optimal adversarial resilience. This work paves the way for more practical Total-Order Broadcast protocols that can be implemented in real-world systems involving a large number of validators with fluctuating participation over time.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Analysis of the Nostr Social Network: Decentralization, Availability, and Replication Overhead</title>
<link>https://arxiv.org/abs/2402.05709</link>
<guid>https://arxiv.org/abs/2402.05709</guid>
<content:encoded><![CDATA[
arXiv:2402.05709v2 Announce Type: replace 
Abstract: Nostr is a decentralized social network launched in 2022, emphasizing high availability and censorship resistance. Since launching, it has gained substantial attention, boasting over 100 million posts. Nostr resembles a micro-blogging service like Twitter but with distinct underlying infrastructure. Nostr introduces the concept of relays, which act as open storage servers that receive, store, and distribute user posts. Each user is uniquely identified by a public key, ensuring authenticity of posts through digital signatures. Users are able to securely replicate and retrieve posts through multiple relays, which frees them from single-server reliance and enhances post availability, thereby attempting to make Nostr censorship resistant. However, this aggressive design also presents challenges, such as the overhead required for extensive post replication and the difficulty in obtaining a global view of post replication locations, which remain unexplored or unaddressed. This necessitates a thorough understanding of the Nostr ecosystem; therefore, we conduct the first large-scale study on this topic. Our study focuses on two key aspects: Nostr relays and post replication strategies. We find that Nostr achieves superior decentralization compared to traditional Fediverse applications. However, relay availability remains a challenge, where financial sustainability (particularly for free-to-use relays) emerges as a contributing factor. We also find that the replication of posts across relays enhances censorship-resistance but introduces significant overhead. To address this, we propose two improvements: one to control the number of post replications, and another to reduce the overhead during post retrieval. Via a data-driven evaluation, we demonstrate their ability to reduce overhead without negatively impacting post availability under the simulated scenarios.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockFUL: Enabling Unlearning in Blockchained Federated Learning</title>
<link>https://arxiv.org/abs/2402.16294</link>
<guid>https://arxiv.org/abs/2402.16294</guid>
<content:encoded><![CDATA[
arXiv:2402.16294v3 Announce Type: replace 
Abstract: Unlearning in Federated Learning (FL) presents significant challenges, as models grow and evolve with complex inheritance relationships. This complexity is amplified when blockchain is employed to ensure the integrity and traceability of FL, where the need to edit multiple interlinked blockchain records and update all inherited models complicates the process.In this paper, we introduce Blockchained Federated Unlearning (BlockFUL), a novel framework with a dual-chain structure comprising a live chain and an archive chain for enabling unlearning capabilities within Blockchained FL. BlockFUL introduces two new unlearning paradigms, i.e., parallel and sequential paradigms, which can be effectively implemented through gradient-ascent-based and re-training-based unlearning methods. These methods enhance the unlearning process across multiple inherited models by enabling efficient consensus operations and reducing computational costs. Our extensive experiments validate that these methods effectively reduce data dependency and operational overhead, thereby boosting the overall performance of unlearning inherited models within BlockFUL on CIFAR-10 and Fashion-MNIST datasets using AlexNet, ResNet18, and MobileNetV2 models.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Fast Confirmation Rule (aka Fast Synchronous Finality) for the Ethereum Consensus Protocol</title>
<link>https://arxiv.org/abs/2405.00549</link>
<guid>https://arxiv.org/abs/2405.00549</guid>
<content:encoded><![CDATA[
arXiv:2405.00549v3 Announce Type: replace 
Abstract: A Confirmation Rule, within blockchain networks, refers to an algorithm implemented by network nodes that determines (either probabilistically or deterministically) the permanence of certain blocks on the blockchain. An example of Confirmation Ruble is the Bitcoin's longest chain Confirmation Rule where a block $b$ is confirmed (with high probability) when it has a sufficiently long chain of successors, its siblings have notably shorter successor chains, the majority of the network's total computation power (hashing) is controlled by honest nodes, and network synchrony holds.
  The only Confirmation Rule currently available in the Ethereum protocol, Gasper, is the FFG Finalization Rule. While this Confirmation Rule works under asynchronous network conditions, it is quite slow for many use cases. Specifically, best-case scenario, it takes around 13 to 19 min to confirm a transaction, where the actual figure depends on when the transaction is submitted to the network.
  In this work, we devise a Fast Confirmation Rule for Ethereum's consensus protocol. Our Confirmation Rule relies on synchrony conditions, but provides a best-case confirmation time of 12 seconds only, greatly improving on the latency of the FFG Finalization Rule.
  Users can then rely on the Confirmation Rule that best suits their needs depending on their belief about the network conditions and the need for a quick response.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts</title>
<link>https://arxiv.org/abs/2503.23718</link>
<guid>https://arxiv.org/abs/2503.23718</guid>
<content:encoded><![CDATA[
arXiv:2503.23718v2 Announce Type: replace 
Abstract: Smart contracts are fundamental pillars of the blockchain, playing a crucial role in facilitating various business transactions. However, these smart contracts are vulnerable to exploitable bugs that can lead to substantial monetary losses. A recent study reveals that over 80% of these exploitable bugs, which are primarily functional bugs, can evade the detection of current tools. The primary issue is the significant gap between understanding the high-level logic of the business model and checking the low-level implementations in smart contracts. Furthermore, identifying deeply rooted functional bugs in smart contracts requires the automated generation of effective detection oracles based on various bug features. To address these challenges, we design and implement PROMFUZZ, an automated and scalable system to detect functional bugs, in smart contracts. In PROMFUZZ, we first propose a novel Large Language Model (LLM)-driven analysis framework, which leverages a dual-agent prompt engineering strategy to pinpoint potentially vulnerable functions for further scrutiny. We then implement a dual-stage coupling approach, which focuses on generating invariant checkers that leverage logic information extracted from potentially vulnerable functions. Finally, we design a bug-oriented fuzzing engine, which maps the logical information from the high-level business model to the low-level smart contract implementations, and performs the bug-oriented fuzzing on targeted functions. We compare PROMFUZZ with multiple state-of-the-art methods. The results show that PROMFUZZ achieves 86.96% recall and 93.02% F1-score in detecting functional bugs, marking at least a 50% improvement in both metrics over state-of-the-art methods. Moreover, we perform an in-depth analysis on real-world DeFi projects and detect 30 zero-day bugs. Up to now, 24 zero-day bugs have been assigned CVE IDs.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Steering the Herd: A Framework for LLM-based Control of Social Learning</title>
<link>https://arxiv.org/abs/2504.02648</link>
<guid>https://arxiv.org/abs/2504.02648</guid>
<content:encoded><![CDATA[
arXiv:2504.02648v3 Announce Type: replace 
Abstract: Algorithms increasingly serve as information mediators--from social media feeds and targeted advertising to the increasing ubiquity of LLMs. This engenders a joint process where agents combine private, algorithmically-mediated signals with learning from peers to arrive at decisions. To study such settings, we introduce a model of controlled sequential social learning in which an information-mediating planner (e.g. an LLM) controls the information structure of agents while they also learn from the decisions of earlier agents. The planner may seek to improve social welfare (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates.
  We prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from induced agent choices. Notably, in some regimes the biased planner intentionally obfuscates the agents' signals. Even under stringent transparency constraints--information parity with individuals, no lying or cherry-picking, and full observability--we show that information mediation can substantially shift social welfare in either direction. We complement our theory with simulations in which LLMs act as both planner and agents. Notably, the LLM planner in our simulations exhibits emergent strategic behavior in steering public opinion that broadly mirrors the trends predicted, though key deviations suggest the influence of non-Bayesian reasoning consistent with the cognitive patterns of both humans and LLMs trained on human-like data. Together, we establish our framework as a tractable basis for studying the impact and regulation of LLM information mediators.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Federated Learning Meets Quantum Computing: Survey and Research Opportunities</title>
<link>https://arxiv.org/abs/2504.08814</link>
<guid>https://arxiv.org/abs/2504.08814</guid>
<content:encoded><![CDATA[
arXiv:2504.08814v3 Announce Type: replace 
Abstract: Quantum Federated Learning (QFL) is an emerging field that harnesses advances in Quantum Computing (QC) to improve the scalability and efficiency of decentralized Federated Learning (FL) models. This paper provides a systematic and comprehensive survey of the emerging problems and solutions when FL meets QC, from research protocol to a novel taxonomy, particularly focusing on both quantum and federated limitations, such as their architectures, Noisy Intermediate Scale Quantum (NISQ) devices, and privacy preservation, so on. This work explores key developments and integration strategies, along with the impact of quantum computing on FL, keeping a sharp focus on hybrid quantum-classical approaches. The paper offers an in-depth understanding of how the strengths of QC, such as gradient hiding, state entanglement, quantum key distribution, quantum security, and quantum-enhanced differential privacy, have been integrated into FL to ensure the privacy of participants in an enhanced, fast, and secure framework. Finally, this study proposes potential future directions to address the identified research gaps and challenges, aiming to inspire faster and more secure QFL models for practical use.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Proximal Gradient Method With Probabilistic Multi-Gossip Communications for Decentralized Composite Optimization</title>
<link>https://arxiv.org/abs/2312.11861</link>
<guid>https://arxiv.org/abs/2312.11861</guid>
<content:encoded><![CDATA[
arXiv:2312.11861v3 Announce Type: replace-cross 
Abstract: Decentralized optimization methods with local updates have recently gained attention for their provable ability to communication acceleration. In these methods, nodes perform several iterations of local computations between the communication rounds. Nevertheless, this capability is effective only when the network is sufficiently well-connected and the loss function is smooth. In this paper, we propose a communication-efficient method MG-Skip with probabilistic local updates and multi-gossip communications for decentralized composite (smooth + nonsmooth) optimization, whose stepsize is independent of the number of local updates and the network topology. For any undirected and connected networks, MG-Skip allows for the multi-gossip communications to be skipped in most iterations in the strongly convex setting, while its computation complexity is $\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$ and communication complexity is only $\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$, where $\kappa$ is the condition number of the loss function, $\rho$ reflects the connectivity of the network topology, and $\epsilon$ is the target accuracy. The theoretical results indicate that MG-Skip achieves provable communication acceleration, thereby validating the advantages of local updates in the nonsmooth setting.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lightweight Learning for Grant-Free Activity Detection in Cell-Free Massive MIMO Networks</title>
<link>https://arxiv.org/abs/2503.11305</link>
<guid>https://arxiv.org/abs/2503.11305</guid>
<content:encoded><![CDATA[
arXiv:2503.11305v3 Announce Type: replace-cross 
Abstract: Grant-free random access (GF-RA) is a promising access technique for massive machine-type communications (mMTC) in future wireless networks, particularly in the context of 5G and beyond (6G) systems. Within the context of GF-RA, this study investigates the efficiency of employing supervised machine learning techniques to tackle the challenges on the device activity detection (AD). GF-RA addresses scalability by employing non-orthogonal pilot sequences, which provides an efficient alternative comparing to conventional grant-based random access (GB-RA) technique that are constrained by the scarcity of orthogonal preamble resources. In this paper, we propose a novel lightweight data-driven algorithmic framework specifically designed for activity detection in GF-RA for mMTC in cell-free massive multiple-input multiple-output (CF-mMIMO) networks. We propose two distinct framework deployment strategies, centralized and decentralized, both tailored to streamline the proposed approach implementation across network infrastructures. Moreover, we introduce optimized post-detection methodologies complemented by a clustering stage to enhance overall detection performances. Our 3GPP-compliant simulations have validated that the proposed algorithm achieves state-of-the-art model-based activity detection accuracy while significantly reducing complexity. Achieving 99% accuracy, it demonstrates real-world viability and effectiveness.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Designing Ethereum's Geographical (De)Centralization Beyond the Atlantic</title>
<link>https://arxiv.org/abs/2509.21475</link>
<guid>https://arxiv.org/abs/2509.21475</guid>
<content:encoded><![CDATA[
arXiv:2509.21475v1 Announce Type: new 
Abstract: Decentralization has a geographic dimension that conventional metrics such as stake distribution overlook. Where validators run affects resilience to regional shocks (outages, disasters, government intervention) and fairness in reward access. Yet in permissionless systems, locations cannot be mandated, but they emerge from incentives. Today, Ethereum's validators cluster along the Atlantic (EU and U.S. East Coast), where latency is structurally favorable. This raises a key question: when some regions already enjoy latency advantages, how does protocol design shape validator incentives and the geography of (de)centralization? We develop a latency-calibrated agent-based model and compare two Ethereum block-building paradigms: a Single-Source Paradigm (SSP), akin to MEV-Boost, where proposers fetch full blocks from a relay that also propagates them; and a Multi-Source Paradigm (MSP), where proposers aggregate value from multiple sources and broadcast the block themselves. Simulations show that SSP concentrates around relay placement but more slowly, since proximity mainly affects propagation, and the marginal value of time is relatively uniform across regions. MSP centralizes faster: aggregating across sources makes marginal value location-dependent, amplifying payoff dispersion and migration toward latency minima. Source placement and consensus settings can dampen or intensify these effects, though once validators are already clustered, the impact of source placement on decentralization is marginal. In most cases, North America consistently emerges as the focal hub. These findings show that protocol design materially shapes validator geography and offer levers for promoting geographical decentralization.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Indexing to Coding: A New Paradigm for Data Availability Sampling</title>
<link>https://arxiv.org/abs/2509.21586</link>
<guid>https://arxiv.org/abs/2509.21586</guid>
<content:encoded><![CDATA[
arXiv:2509.21586v1 Announce Type: new 
Abstract: The data availability problem is a central challenge in blockchain systems and lies at the core of the accessibility and scalability issues faced by platforms such as Ethereum. Modern solutions employ several approaches, with data availability sampling (DAS) being the most self-sufficient and minimalistic in its security assumptions. Existing DAS methods typically form cryptographic commitments on codewords of fixed-rate erasure codes, which restrict light nodes to sampling from a predetermined set of coded symbols.
  In this paper, we introduce a new approach to DAS that modularizes the coding and commitment process by committing to the uncoded data while performing sampling through on-the-fly coding. The resulting samples are significantly more expressive, enabling light nodes to obtain, in concrete implementations, up to multiple orders of magnitude stronger assurances of data availability than from sampling pre-committed symbols from a fixed-rate redundancy code as done in established DAS schemes using Reed Solomon or low density parity check codes. We present a concrete protocol that realizes this paradigm using random linear network coding (RLNC).
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection</title>
<link>https://arxiv.org/abs/2509.21606</link>
<guid>https://arxiv.org/abs/2509.21606</guid>
<content:encoded><![CDATA[
arXiv:2509.21606v1 Announce Type: new 
Abstract: Federated continual learning (FCL) enables distributed client devices to learn from streaming data across diverse and evolving tasks. A major challenge to continual learning, catastrophic forgetting, is exacerbated in decentralized settings by the data heterogeneity, constrained communication and privacy concerns. We propose Federated gradient Projection-based Continual Learning with Task Identity Prediction (FedProTIP), a novel FCL framework that mitigates forgetting by projecting client updates onto the orthogonal complement of the subspace spanned by previously learned representations of the global model. This projection reduces interference with earlier tasks and preserves performance across the task sequence. To further address the challenge of task-agnostic inference, we incorporate a lightweight mechanism that leverages core bases from prior tasks to predict task identity and dynamically adjust the global model's outputs. Extensive experiments across standard FCL benchmarks demonstrate that FedProTIP significantly outperforms state-of-the-art methods in average accuracy, particularly in settings where task identities are a priori unknown.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NEO-Grid: A Neural Approximation Framework for Optimization and Control in Distribution Grids</title>
<link>https://arxiv.org/abs/2509.21668</link>
<guid>https://arxiv.org/abs/2509.21668</guid>
<content:encoded><![CDATA[
arXiv:2509.21668v1 Announce Type: new 
Abstract: The rise of distributed energy resources (DERs) is reshaping modern distribution grids, introducing new challenges in attaining voltage stability under dynamic and decentralized operating conditions. This paper presents NEO-Grid, a unified learning-based framework for volt-var optimization (VVO) and volt-var control (VVC) that leverages neural network surrogates for power flow and deep equilibrium models (DEQs) for closed-loop control. Our method replaces traditional linear approximations with piecewise-linear ReLU networks trained to capture the nonlinear relationship between power injections and voltage magnitudes. For control, we model the recursive interaction between voltage and inverter response using DEQs, allowing direct fixed-point computation and efficient training via implicit differentiation. We evaluated NEO-Grid on the IEEE 33-bus system, demonstrating that it significantly improves voltage regulation performance compared to standard linear and heuristic baselines in both optimization and control settings. Our results establish NEO-Grid as a scalable, accurate, and interpretable solution for learning-based voltage regulation in distribution grids.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differentially-Private Decentralized Learning in Heterogeneous Multicast Networks</title>
<link>https://arxiv.org/abs/2509.21688</link>
<guid>https://arxiv.org/abs/2509.21688</guid>
<content:encoded><![CDATA[
arXiv:2509.21688v1 Announce Type: new 
Abstract: We propose a power-controlled differentially private decentralized learning algorithm designed for a set of clients aiming to collaboratively train a common learning model. The network is characterized by a row-stochastic adjacency matrix, which reflects different channel gains between the clients. In our privacy-preserving approach, both the transmit power for model updates and the level of injected Gaussian noise are jointly controlled to satisfy a given privacy and energy budget. We show that our proposed algorithm achieves a convergence rate of O(log T), where T is the horizon bound in the regret function. Furthermore, our numerical results confirm that our proposed algorithm outperforms existing works.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Preference-Guided Learning for Sparse-Reward Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2509.21828</link>
<guid>https://arxiv.org/abs/2509.21828</guid>
<content:encoded><![CDATA[
arXiv:2509.21828v1 Announce Type: new 
Abstract: We study the problem of online multi-agent reinforcement learning (MARL) in environments with sparse rewards, where reward feedback is not provided at each interaction but only revealed at the end of a trajectory. This setting, though realistic, presents a fundamental challenge: the lack of intermediate rewards hinders standard MARL algorithms from effectively guiding policy learning. To address this issue, we propose a novel framework that integrates online inverse preference learning with multi-agent on-policy optimization into a unified architecture. At its core, our approach introduces an implicit multi-agent reward learning model, built upon a preference-based value-decomposition network, which produces both global and local reward signals. These signals are further used to construct dual advantage streams, enabling differentiated learning targets for the centralized critic and decentralized actors. In addition, we demonstrate how large language models (LLMs) can be leveraged to provide preference labels that enhance the quality of the learned reward model. Empirical evaluations on state-of-the-art benchmarks, including MAMuJoCo and SMACv2, show that our method achieves superior performance compared to existing baselines, highlighting its effectiveness in addressing sparse-reward challenges in online MARL.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Dark Art of Financial Disguise in Web3: Money Laundering Schemes and Countermeasures</title>
<link>https://arxiv.org/abs/2509.21831</link>
<guid>https://arxiv.org/abs/2509.21831</guid>
<content:encoded><![CDATA[
arXiv:2509.21831v1 Announce Type: new 
Abstract: The rise of Web3 and Decentralized Finance (DeFi) has enabled borderless access to financial services empowered by smart contracts and blockchain technology. However, the ecosystem's trustless, permissionless, and borderless nature presents substantial regulatory challenges. The absence of centralized oversight and the technical complexity create fertile ground for financial crimes. Among these, money laundering is particularly concerning, as in the event of successful scams, code exploits, and market manipulations, it facilitates covert movement of illicit gains. Beyond this, there is a growing concern that cryptocurrencies can be leveraged to launder proceeds from drug trafficking, or to transfer funds linked to terrorism financing.
  This survey aims to outline a taxonomy of high-level strategies and underlying mechanisms exploited to facilitate money laundering in Web3. We examine how criminals leverage the pseudonymous nature of Web3, alongside weak regulatory frameworks, to obscure illicit financial activities. Our study seeks to bridge existing knowledge gaps on laundering schemes, identify open challenges in the detection and prevention of such activities, and propose future research directions to foster a more transparent Web3 financial ecosystem -- offering valuable insights for researchers, policymakers, and industry practitioners.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Path Finding via Offline RL and LLM Collaboration</title>
<link>https://arxiv.org/abs/2509.22130</link>
<guid>https://arxiv.org/abs/2509.22130</guid>
<content:encoded><![CDATA[
arXiv:2509.22130v1 Announce Type: new 
Abstract: Multi-Agent Path Finding (MAPF) poses a significant and challenging problem critical for applications in robotics and logistics, particularly due to its combinatorial complexity and the partial observability inherent in realistic environments. Decentralized reinforcement learning methods commonly encounter two substantial difficulties: first, they often yield self-centered behaviors among agents, resulting in frequent collisions, and second, their reliance on complex communication modules leads to prolonged training times, sometimes spanning weeks. To address these challenges, we propose an efficient decentralized planning framework based on the Decision Transformer (DT), uniquely leveraging offline reinforcement learning to substantially reduce training durations from weeks to mere hours. Crucially, our approach effectively handles long-horizon credit assignment and significantly improves performance in scenarios with sparse and delayed rewards. Furthermore, to overcome adaptability limitations inherent in standard RL methods under dynamic environmental changes, we integrate a large language model (GPT-4o) to dynamically guide agent policies. Extensive experiments in both static and dynamically changing environments demonstrate that our DT-based approach, augmented briefly by GPT-4o, significantly enhances adaptability and performance.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead</title>
<link>https://arxiv.org/abs/2509.22174</link>
<guid>https://arxiv.org/abs/2509.22174</guid>
<content:encoded><![CDATA[
arXiv:2509.22174v1 Announce Type: new 
Abstract: In today's data-sensitive landscape, distributed learning emerges as a vital tool, not only fortifying privacy measures but also streamlining computational operations. This becomes especially crucial within fully decentralized infrastructures where local processing is imperative due to the absence of centralized aggregation. Here, we introduce DYNAWEIGHT, a novel framework to information aggregation in multi-agent networks. DYNAWEIGHT offers substantial acceleration in decentralized learning with minimal additional communication and memory overhead. Unlike traditional static weight assignments, such as Metropolis weights, DYNAWEIGHT dynamically allocates weights to neighboring servers based on their relative losses on local datasets. Consequently, it favors servers possessing diverse information, particularly in scenarios of substantial data heterogeneity. Our experiments on various datasets MNIST, CIFAR10, and CIFAR100 incorporating various server counts and graph topologies, demonstrate notable enhancements in training speeds. Notably, DYNAWEIGHT functions as an aggregation scheme compatible with any underlying server-level optimization algorithm, underscoring its versatility and potential for widespread integration.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>I-ETL: an interoperability-aware health (meta) data pipeline to enable federated analyses</title>
<link>https://arxiv.org/abs/2509.22351</link>
<guid>https://arxiv.org/abs/2509.22351</guid>
<content:encoded><![CDATA[
arXiv:2509.22351v1 Announce Type: new 
Abstract: Clinicians are interested in better understanding complex diseases, such as cancer or rare diseases, so they need to produce and exchange data to mutualize sources and join forces. To do so and ensure privacy, a natural way consists in using a decentralized architecture and Federated Learning algorithms. This ensures that data stays in the organization in which it has been collected, but requires data to be collected in similar settings and similar models. In practice, this is often not the case because healthcare institutions work individually with different representations and raw data; they do not have means to normalize their data, and even less to do so across centers. For instance, clinicians have at hand phenotypic, clinical, imaging and genomic data (each individually collected) and want to better understand some diseases by analyzing them together. This example highlights the needs and challenges for a cooperative use of this wealth of information. We designed and implemented a framework, named I-ETL, for integrating highly heterogeneous healthcare datasets of hospitals in interoperable databases. Our proposal is twofold: (i) we devise two general and extensible conceptual models for modeling both data and metadata and (ii) we propose an Extract-Transform-Load (ETL) pipeline ensuring and assessing interoperability from the start. By conducting experiments on open-source datasets, we show that I-ETL succeeds in representing various health datasets in a unified way thanks to our two general conceptual models. Next, we demonstrate the importance of blending interoperability as a first-class citizen in integration pipelines, ensuring possible collaboration between different centers.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Uncertainty-Aware Multi-Robot Task Allocation With Strongly Coupled Inter-Robot Rewards</title>
<link>https://arxiv.org/abs/2509.22469</link>
<guid>https://arxiv.org/abs/2509.22469</guid>
<content:encoded><![CDATA[
arXiv:2509.22469v1 Announce Type: new 
Abstract: This paper proposes a task allocation algorithm for teams of heterogeneous robots in environments with uncertain task requirements. We model these requirements as probability distributions over capabilities and use this model to allocate tasks such that robots with complementary skills naturally position near uncertain tasks, proactively mitigating task failures without wasting resources. We introduce a market-based approach that optimizes the joint team objective while explicitly capturing coupled rewards between robots, offering a polynomial-time solution in decentralized settings with strict communication assumptions. Comparative experiments against benchmark algorithms demonstrate the effectiveness of our approach and highlight the challenges of incorporating coupled rewards in a decentralized formulation.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Dual-Mode Distillation with Incentive Schemes for Scalable, Heterogeneous Federated Learning on Non-IID Data</title>
<link>https://arxiv.org/abs/2509.22507</link>
<guid>https://arxiv.org/abs/2509.22507</guid>
<content:encoded><![CDATA[
arXiv:2509.22507v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a promising decentralized learning (DL) approach that enables the use of distributed data without compromising user privacy. However, FL poses several key challenges. First, it is frequently assumed that every client can train the same machine learning models, however, not all clients are able to meet this assumption because of differences in their business needs and computational resources. Second, statistical heterogeneity (a.k.a. non-IID data) poses a major challenge in FL, which can lead to lower global model performance. Third, while addressing these challenges, there is a need for a cost-effective incentive mechanism to encourage clients to participate in FL training. In response to these challenges, we propose several methodologies: DL-SH, which facilitates efficient, privacy-preserving, and communication-efficient learning in the context of statistical heterogeneity; DL-MH, designed to manage fully heterogeneous models while tackling statistical disparities; and I-DL-MH, an incentive-based extension of DL-MH that promotes client engagement in federated learning training by providing incentives within this complex federated learning framework. Comprehensive experiments were carried out to assess the performance and scalability of the proposed approaches across a range of complex experimental settings. This involved utilizing various model architectures, in diverse data distributions, including IID and several non-IID scenarios, as well as multiple datasets. Experimental results demonstrate that the proposed approaches significantly enhance accuracy and decrease communication costs while effectively addressing statistical heterogeneity and model heterogeneity in comparison to existing state-of-the-art approaches and baselines, with DL-SH improving global model accuracy by 153%, and I-DL-MH achieving a 225% improvement under non-IID conditions.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Technical Capability and User Accessibility: Off-grid Civilian Emergency Communication</title>
<link>https://arxiv.org/abs/2509.22568</link>
<guid>https://arxiv.org/abs/2509.22568</guid>
<content:encoded><![CDATA[
arXiv:2509.22568v1 Announce Type: new 
Abstract: During large-scale crises disrupting cellular and Internet infrastructure, civilians lack reliable methods for communication, aid coordination, and access to trustworthy information. This paper presents a unified emergency communication system integrating a low-power, long-range network with a crisis-oriented smartphone application, enabling decentralized and off-grid civilian communication. Unlike previous solutions separating physical layer resilience from user layer usability, our design merges these aspects into a cohesive crisis-tailored framework.
  The system is evaluated in two dimensions: communication performance and application functionality. Field experiments in urban Z\"urich demonstrate that the 868 MHz band, using the LongFast configuration, achieves a communication range of up to 1.2 km with 92% Packet Delivery Ratio, validating network robustness under real-world infrastructure degraded conditions. In parallel, a purpose-built mobile application featuring peer-to-peer messaging, identity verification, and community moderation was evaluated through a requirements-based analysis.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Voting-Bloc Entropy: A New Metric for DAO Decentralization</title>
<link>https://arxiv.org/abs/2509.22620</link>
<guid>https://arxiv.org/abs/2509.22620</guid>
<content:encoded><![CDATA[
arXiv:2509.22620v1 Announce Type: new 
Abstract: Decentralized Autonomous Organizations (DAOs) use smart contracts to foster communities working toward common goals. Existing definitions of decentralization, however -- the 'D' in DAO -- fall short of capturing the key properties characteristic of diverse and equitable participation. This work proposes a new framework for measuring DAO decentralization called Voting-Bloc Entropy (VBE, pronounced ''vibe''). VBE is based on the idea that voters with closely aligned interests act as a centralizing force and should be modeled as such. VBE formalizes this notion by measuring the similarity of participants' utility functions across a set of voting rounds. Unlike prior, ad hoc definitions of decentralization, VBE derives from first principles: We introduce a simple (yet powerful) reinforcement learning-based conceptual model for voting, that in turn implies VBE. We first show VBE's utility as a theoretical tool. We prove a number of results about the (de)centralizing effects of vote delegation, proposal bundling, bribery, etc. that are overlooked in previous notions of DAO decentralization. Our results lead to practical suggestions for enhancing DAO decentralization. We also show how VBE can be used empirically by presenting measurement studies and VBE-based governance experiments. We make the tools we developed for these results available to the community in the form of open-source artifacts in order to facilitate future study of DAO decentralization.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Linear Risk Sharing on Networks</title>
<link>https://arxiv.org/abs/2509.21411</link>
<guid>https://arxiv.org/abs/2509.21411</guid>
<content:encoded><![CDATA[
arXiv:2509.21411v1 Announce Type: cross 
Abstract: Over the past decade alternatives to traditional insurance and banking have grown in popularity. The desire to encourage local participation has lead products such as peer-to-peer insurance, reciprocal contracts, and decentralized finance platforms to increasingly rely on network structures to redistribute risk among participants. In this paper, we develop a comprehensive framework for linear risk sharing (LRS), where random losses are reallocated through nonnegative linear operators which can accommodate a wide range of networks. Building on the theory of stochastic and doubly stochastic matrices, we establish conditions under which constraints such as budget balance, fairness, and diversification are guaranteed. The convex order framework allows us to compare different allocations rigorously, highlighting variance reduction and majorization as natural consequences of doubly stochastic mixing. We then extend the analysis to network-based sharing, showing how their topology shapes risk outcomes in complete, star, ring, random, and scale-free graphs. A second layer of randomness, where the sharing matrix itself is random, is introduced via Erd\H{o}s--R\'enyi and preferential-attachment networks, connecting risk-sharing properties to degree distributions. Finally, we study convex combinations of identity and network-induced operators, capturing the trade-off between self-retention and diversification. Our results provide design principles for fair and efficient peer-to-peer insurance and network-based risk pooling, combining mathematical soundness with economic interpretability.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proving and Rewarding Client Diversity to Strengthen Resilience of Blockchain Networks</title>
<link>https://arxiv.org/abs/2411.18401</link>
<guid>https://arxiv.org/abs/2411.18401</guid>
<content:encoded><![CDATA[
arXiv:2411.18401v2 Announce Type: replace 
Abstract: Client diversity is a cornerstone of blockchain resilience, yet most networks suffer from a dangerously skewed distribution of client implementations. This monoculture exposes the network to very risky scenarios, such as massive financial losses in the event of a majority client failure. In this paper, we present a novel framework that combines verifiable execution and economic incentives to provably identify and reward the use of minority clients, thereby promoting a healthier, more robust ecosystem. Our approach leverages state-of-the-art verifiable computation (zkVMs and TEEs) to generate cryptographic proofs of client execution, which are then verified on-chain. We design and implement an end-to-end prototype of verifiable client diversity in the context of Ethereum, by modifying the popular Lighthouse client and by deploying our novel diversity-aware reward protocol. Through comprehensive experiments, we quantify the practicality of our approach, from overheads of proof production and verification to the effectiveness of the incentive mechanism. This work demonstrates, for the first time, a practical and economically viable path to encourage and ensure provable client diversity in blockchain networks. Our findings inform the design of future protocols that seek to maximize the resilience of decentralized systems
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond A Single AI Cluster: A Survey of Decentralized LLM Training</title>
<link>https://arxiv.org/abs/2503.11023</link>
<guid>https://arxiv.org/abs/2503.11023</guid>
<content:encoded><![CDATA[
arXiv:2503.11023v3 Announce Type: replace 
Abstract: The emergence of large language models (LLMs) has revolutionized AI development, yet the resource demands beyond a single cluster or even datacenter, limiting accessibility to well-resourced organizations. Decentralized training has emerged as a promising paradigm to leverage dispersed resources across clusters, datacenters and regions, offering the potential to democratize LLM development for broader communities. As the first comprehensive exploration of this emerging field, we present decentralized LLM training as a resource-driven paradigm and categorize existing efforts into community-driven and organizational approaches. We further clarify this through: (1) a comparison with related paradigms, (2) a characterization of decentralized resources, and (3) a taxonomy of recent advancements. We also provide up-to-date case studies and outline future directions to advance research in decentralized LLM training.
]]></content:encoded>
<pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedOC: Multi-Server FL with Overlapping Client Relays in Wireless Edge Networks</title>
<link>https://arxiv.org/abs/2509.19398</link>
<guid>https://arxiv.org/abs/2509.19398</guid>
<content:encoded><![CDATA[
arXiv:2509.19398v1 Announce Type: new 
Abstract: Multi-server Federated Learning (FL) has emerged as a promising solution to mitigate communication bottlenecks of single-server FL. We focus on a typical multi-server FL architecture, where the regions covered by different edge servers (ESs) may overlap. A key observation of this architecture is that clients located in the overlapping areas can access edge models from multiple ESs. Building on this insight, we propose FedOC (Federated learning with Overlapping Clients), a novel framework designed to fully exploit the potential of these overlapping clients. In FedOC, overlapping clients could serve dual roles: (1) as Relay Overlapping Clients (ROCs), they forward edge models between neighboring ESs in real time to facilitate model sharing among different ESs; and (2) as Normal Overlapping Clients (NOCs), they dynamically select their initial model for local training based on the edge model delivery time, which enables indirect data fusion among different regions of ESs. The overall FedOC workflow proceeds as follows: in every round, each client trains local model based on the earliest received edge model and transmits to the respective ESs for model aggregation. Then each ES transmits the aggregated edge model to neighboring ESs through ROC relaying. Upon receiving the relayed models, each ES performs a second aggregation and subsequently broadcasts the updated model to covered clients. The existence of ROCs enables the model of each ES to be disseminated to the other ESs in a decentralized manner, which indirectly achieves intercell model and speeding up the training process, making it well-suited for latency-sensitive edge environments. Extensive experimental results show remarkable performance gains of our scheme compared to existing methods.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Investigating Sharding Advancements, Methodologies, and Adoption Potential in Hedera</title>
<link>https://arxiv.org/abs/2509.19478</link>
<guid>https://arxiv.org/abs/2509.19478</guid>
<content:encoded><![CDATA[
arXiv:2509.19478v1 Announce Type: new 
Abstract: Sharding has emerged as a critical solution to address the scalability challenges faced by blockchain networks, enabling them to achieve higher transaction throughput, reduced latency, and optimized resource usage. This paper investigates the advancements, methodologies, and adoption potential of sharding in the context of Hedera, a distributed ledger technology known for its unique Gossip about Gossip protocol and asynchronous Byzantine Fault Tolerance (ABFT). We explore various academic and industrial sharding techniques, emphasizing their benefits and trade-offs. Building on these insights, we propose a hybrid sharding solution for Hedera that partitions the network into local and global committees, facilitating efficient cross-shard transactions and ensuring robust security through dynamic reconfiguration. Our analysis highlights significant reductions in storage and communication overhead, improved scalability, and enhanced fault tolerance, demonstrating the feasibility and advantages of integrating sharding into Hedera's architecture.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Aggregation of Demand Flexibility</title>
<link>https://arxiv.org/abs/2509.19612</link>
<guid>https://arxiv.org/abs/2509.19612</guid>
<content:encoded><![CDATA[
arXiv:2509.19612v1 Announce Type: new 
Abstract: This paper proposes a federated framework for demand flexibility aggregation to support grid operations. Unlike existing geometric methods that rely on a static, pre-defined base set as the geometric template for aggregation, our framework establishes a true federated process by enabling the collaborative optimization of this base set without requiring the participants sharing sensitive data with the aggregator. Specifically, we first formulate the base set optimization problem as a bilevel program. Using optimal solution functions, we then reformulate the bilevel program into a single-level, unconstrained learning task. By exploiting the decomposable structure of the overall gradient, we further design a decentralized gradient-based algorithm to solve this learning task. The entire framework, encompassing base set optimization, aggregation, and disaggregation, operates by design without exchanging raw user data. Numerical results demonstrate that our proposed framework unlocks substantially more flexibility than the approaches with static base sets, thus providing a promising framework for efficient and privacy-enhanced approaches to coordinate demand flexibility at scale.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Governing Together: Toward Infrastructure for Community-Run Social Media</title>
<link>https://arxiv.org/abs/2509.19653</link>
<guid>https://arxiv.org/abs/2509.19653</guid>
<content:encoded><![CDATA[
arXiv:2509.19653v1 Announce Type: new 
Abstract: Decentralizing the governance of social computing systems to communities promises to empower them to make independent decisions, with nuance and in accordance with their values. Yet, communities do not govern in isolation. Many problems communities face are common, or move across their boundaries. We therefore propose designing for "inter-community governance:" mechanisms that support relationships and interactions between communities to coordinate on governance issues. Drawing from workshops with 24 individuals on decentralized, community-run social media, we present six challenges in designing for inter-community governance surfaced through ideas proposed in workshops. Together, these ideas come together as an ecosystem of resources, infrastructures, and tools that highlight three key principles for designing for inter-community governance: modularity, forkability, and polycentricity. We end with a discussion of how the ideas proposed in workshops might be implemented in future work aiming to support community governance in social computing systems broadly.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Orbital Stabilization and Time Synchronization of Unstable Periodic Motions in Underactuated Robots</title>
<link>https://arxiv.org/abs/2509.20082</link>
<guid>https://arxiv.org/abs/2509.20082</guid>
<content:encoded><![CDATA[
arXiv:2509.20082v1 Announce Type: new 
Abstract: This paper presents a control methodology for achieving orbital stabilization with simultaneous time synchronization of periodic trajectories in underactuated robotic systems. The proposed approach extends the classical transverse linearization framework to explicitly incorporate time-desynchronization dynamics. To stabilize the resulting extended transverse dynamics, we employ a combination of time-varying LQR and sliding-mode control. The theoretical results are validated experimentally through the implementation of both centralized and decentralized control strategies on a group of six Butterfly robots.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>chainScale: Secure Functionality-oriented Scalability for Decentralized Resource Markets</title>
<link>https://arxiv.org/abs/2509.20356</link>
<guid>https://arxiv.org/abs/2509.20356</guid>
<content:encoded><![CDATA[
arXiv:2509.20356v1 Announce Type: new 
Abstract: Decentralized resource markets are Web 3.0 applications that build open-access platforms for trading digital resources among users without any central management. They promise cost reduction, transparency, and flexible service provision. However, these markets usually have large workload that must be processed in a timely manner, leading to serious scalability problems. Despite the large amount of work on blockchain scalability, existing solutions are ineffective as they do not account for these markets' work models and traffic patterns.
  We introduce chainScale, a secure hybrid sidechain-sharding solution that aims to boost throughput of decentralized resource markets and reduce their latency and storage footprint. At its core, chainScale leverages dependent sidechains and functionality-oriented workload splitting to parallelize traffic processing by having each market module assigned to a sidechain. Different from sharding, chainScale does not incur any cross-sidechain transactions that tend to be costly. chainScale introduces several techniques, including hierarchical workload sharing that further sub-divides overloaded modules, and weighted miner assignment that assigns miners with vested interest in the system to critical modules' sidechains. Furthermore, chainScale employs sidechain syncing to maintain the mainchain as the single truth of system state, and pruning to discard stale records. Beside analyzing security, we build a proof-of-concept implementation for a distributed file storage market as a use case. Our experiments show that, compared to a single sidechain-based prior solution, chainScale boosts throughput by 4x and reduces confirmation latency by 5x. Also, they show that chainScale outperforms sharding by 2.5x in throughput and 3.5x in latency.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof-of-Social-Capital: A Consensus Protocol Replacing Stake for Social Capital</title>
<link>https://arxiv.org/abs/2505.12144</link>
<guid>https://arxiv.org/abs/2505.12144</guid>
<content:encoded><![CDATA[
arXiv:2505.12144v2 Announce Type: replace 
Abstract: Consensus protocols used today in blockchains mostly rely on scarce resources such as computational power or financial stake, favoring wealthy individuals due to a high entry barrier. We propose Proof-of-Social-Capital (PoSC), a new consensus protocol fueled by social capital as a staking resource to ensure fairness and decentralization. Consensus nodes in our system do not require financial or computational resources that are expensive to acquire; instead, they require preexisting social media influence, distributing consensus power not according to wealth but social capital. Our approach integrates zkSNARK proofs, verifiable credentials with a uniqueness-enforcing mechanism to prevent Sybil attacks, and the incentive scheme that rewards engagement with social media content by followers. This work offers a new concept aligned with modern social media lifestyle applied in finance, providing a practical insight for the evolution of decentralized consensus protocols.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks</title>
<link>https://arxiv.org/abs/2404.03227</link>
<guid>https://arxiv.org/abs/2404.03227</guid>
<content:encoded><![CDATA[
arXiv:2404.03227v3 Announce Type: replace-cross 
Abstract: We address the challenge of sampling and remote estimation for autoregressive Markovian processes in a multi-hop wireless network with statistically-identical agents. Agents cache the most recent samples from others and communicate over wireless collision channels governed by an underlying graph topology. Our goal is to minimize time-average estimation error and/or age of information with decentralized scalable sampling and transmission policies, considering both oblivious (where decision-making is independent of the physical processes) and non-oblivious policies (where decision-making depends on physical processes). We prove that in oblivious policies, minimizing estimation error is equivalent to minimizing the age of information. The complexity of the problem, especially the multi-dimensional action spaces and arbitrary network topologies, makes theoretical methods for finding optimal transmission policies intractable. We optimize the policies using a graphical multi-agent reinforcement learning framework, where each agent employs a permutation-equivariant graph neural network architecture. Theoretically, we prove that our proposed framework exhibits desirable transferability properties, allowing transmission policies trained on small- or moderate-size networks to be executed effectively on large-scale topologies. Numerical experiments demonstrate that (i) Our proposed framework outperforms state-of-the-art baselines; (ii) The trained policies are transferable to larger networks, and their performance gains increase with the number of agents; (iii) The training procedure withstands non-stationarity even if we utilize independent learning techniques; and, (iv) Recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity in independent learning.
]]></content:encoded>
<pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentor-V: Lightweight ML Training on Low-Power RISC-V Edge Devices</title>
<link>https://arxiv.org/abs/2509.18118</link>
<guid>https://arxiv.org/abs/2509.18118</guid>
<content:encoded><![CDATA[
arXiv:2509.18118v1 Announce Type: new 
Abstract: Modern IoT devices increasingly rely on machine learning solutions to process data locally. However, the lack of graphics processing units (GPUs) or dedicated accelerators on most platforms makes on-device training largely infeasible, often requiring cloud-based services to perform this task. This procedure often raises privacy-related concerns, and creates dependency on reliable and always-on connectivity. Federated Learning (FL) is a new trend that addresses these issues by enabling decentralized and collaborative training directly on devices, but it requires highly efficient optimization algorithms. L-SGD, a lightweight variant of stochastic gradient descent, has enabled neural network training on Arm Cortex-M Microcontroller Units (MCUs). This work extends L-SGD to RISC-V-based MCUs, an open and emerging architecture that still lacks robust support for on-device training. L-SGD was evaluated on both Arm and RISC-V platforms using 32-bit floating-point arithmetic, highlighting the performance impact of the absence of Floating-Point Units (FPUs) in RISC-V MCUs. To mitigate these limitations, we introduce an 8-bit quantized version of L-SGD for RISC-V, which achieves nearly 4x reduction in memory usage and a 2.2x speedup in training time, with negligible accuracy degradation.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Anomaly Detection in Electric Vehicle Charging Stations Using Federated Learning</title>
<link>https://arxiv.org/abs/2509.18126</link>
<guid>https://arxiv.org/abs/2509.18126</guid>
<content:encoded><![CDATA[
arXiv:2509.18126v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized training framework widely used in IoT ecosystems that preserves privacy by keeping raw data local, making it ideal for IoT-enabled cyber-physical systems with sensing and communication like Smart Grids (SGs), Connected and Automated Vehicles (CAV), and Electric Vehicle Charging Stations (EVCS). With the rapid expansion of electric vehicle infrastructure, securing these IoT-based charging stations against cyber threats has become critical. Centralized Intrusion Detection Systems (IDS) raise privacy concerns due to sensitive network and user data, making FL a promising alternative. However, current FL-based IDS evaluations overlook practical challenges such as system heterogeneity and non-IID data. To address these challenges, we conducted experiments to evaluate the performance of federated learning for anomaly detection in EV charging stations under system and data heterogeneity. We used FedAvg and FedAvgM, widely studied optimization approaches, to analyze their effectiveness in anomaly detection. Under IID settings, FedAvg achieves superior performance to centralized models using the same neural network. However, performance degrades with non-IID data and system heterogeneity. FedAvgM consistently outperforms FedAvg in heterogeneous settings, showing better convergence and higher anomaly detection accuracy. Our results demonstrate that FL can handle heterogeneity in IoT-based EVCS without significant performance loss, with FedAvgM as a promising solution for robust, privacy-preserving EVCS security.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Shot Visual Deepfake Detection: Can AI Predict and Prevent Fake Content Before It's Created?</title>
<link>https://arxiv.org/abs/2509.18461</link>
<guid>https://arxiv.org/abs/2509.18461</guid>
<content:encoded><![CDATA[
arXiv:2509.18461v1 Announce Type: new 
Abstract: Generative adversarial networks (GANs) and diffusion models have dramatically advanced deepfake technology, and its threats to digital security, media integrity, and public trust have increased rapidly. This research explored zero-shot deepfake detection, an emerging method even when the models have never seen a particular deepfake variation. In this work, we studied self-supervised learning, transformer-based zero-shot classifier, generative model fingerprinting, and meta-learning techniques that better adapt to the ever-evolving deepfake threat. In addition, we suggested AI-driven prevention strategies that mitigated the underlying generation pipeline of the deepfakes before they occurred. They consisted of adversarial perturbations for creating deepfake generators, digital watermarking for content authenticity verification, real-time AI monitoring for content creation pipelines, and blockchain-based content verification frameworks. Despite these advancements, zero-shot detection and prevention faced critical challenges such as adversarial attacks, scalability constraints, ethical dilemmas, and the absence of standardized evaluation benchmarks. These limitations were addressed by discussing future research directions on explainable AI for deepfake detection, multimodal fusion based on image, audio, and text analysis, quantum AI for enhanced security, and federated learning for privacy-preserving deepfake detection. This further highlighted the need for an integrated defense framework for digital authenticity that utilized zero-shot learning in combination with preventive deepfake mechanisms. Finally, we highlighted the important role of interdisciplinary collaboration between AI researchers, cybersecurity experts, and policymakers to create resilient defenses against the rising tide of deepfake attacks.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Agent Access (A\^3) Network: An Embodied, Communication-Aware Multi-Agent Framework for 6G Coverage</title>
<link>https://arxiv.org/abs/2509.18526</link>
<guid>https://arxiv.org/abs/2509.18526</guid>
<content:encoded><![CDATA[
arXiv:2509.18526v1 Announce Type: new 
Abstract: The vision of 6G communication demands autonomous and resilient networking in environments without fixed infrastructure. Yet most multi-agent reinforcement learning (MARL) approaches focus on isolated stages - exploration, relay formation, or access - under static deployments and centralized control, limiting adaptability. We propose the AI Agent Access (A\^3) Network, a unified, embodied intelligence-driven framework that transforms multi-agent networking into a dynamic, decentralized, and end-to-end system. Unlike prior schemes, the A\^3 Network integrates exploration, target user access, and backhaul maintenance within a single learning process, while supporting on-demand agent addition during runtime. Its decentralized policies ensure that even a single agent can operate independently with limited observations, while coordinated agents achieve scalable, communication-optimized coverage. By embedding link-level communication metrics into actor-critic learning, the A\^3 Network couples topology formation with robust decision-making. Numerical simulations demonstrate that the A\^3 Network not only balances exploration and communication efficiency but also delivers system-level adaptability absent in existing MARL frameworks, offering a new paradigm for 6G multi-agent networks.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Examining I2P Resilience: Effect of Centrality-based Attack</title>
<link>https://arxiv.org/abs/2509.18572</link>
<guid>https://arxiv.org/abs/2509.18572</guid>
<content:encoded><![CDATA[
arXiv:2509.18572v1 Announce Type: new 
Abstract: This study examines the robustness of I2P, a well-regarded anonymous and decentralized peer-to-peer network designed to ensure anonymity, confidentiality, and circumvention of censorship. Unlike its more widely researched counterpart, TOR, I2P's resilience has received less scholarly attention. Employing network analysis, this research evaluates I2P's susceptibility to adversarial percolation. By utilizing the degree centrality as a measure of nodes' influence in the network, the finding suggests the network is vulnerable to targeted disruptions. Before percolation, the network exhibited a density of 0.01065443 and an average path length of 6.842194. At the end of the percolation process, the density decreased by approximately 10%, and the average path length increased by 33%, indicating a decline in efficiency and connectivity. These results highlight that even decentralized networks, such as I2P, exhibit structural fragility under targeted attacks, emphasizing the need for improved design strategies to enhance resilience against adversarial disruptions.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Cellular Bricks for Decentralized Shape Classification and Damage Recovery</title>
<link>https://arxiv.org/abs/2509.18659</link>
<guid>https://arxiv.org/abs/2509.18659</guid>
<content:encoded><![CDATA[
arXiv:2509.18659v1 Announce Type: new 
Abstract: Biological systems possess remarkable capabilities for self-recognition and morphological regeneration, often relying solely on local interactions. Inspired by these decentralized processes, we present a novel system of physical 3D bricks--simple cubic units equipped with local communication, processing, and sensing--that are capable of inferring their global shape class and detecting structural damage. Leveraging Neural Cellular Automata (NCA), a learned, fully-distributed algorithm, our system enables each module to independently execute the same neural network without access to any global state or positioning information. We demonstrate the ability of collections of hundreds of these cellular bricks to accurately classify a variety of 3D shapes through purely local interactions. The approach shows strong robustness to out-of-distribution shape variations and high tolerance to communication faults and failed modules. In addition to shape inference, the same decentralized framework is extended to detect missing or damaged components, allowing the collective to localize structural disruptions and to guide a recovery process. This work provides a physical realization of large-scale, decentralized self-recognition and damage detection, advancing the potential of robust, adaptive, and bio-inspired modular systems.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generic Adversarial Smart Contract Detection with Semantics and Uncertainty-Aware LLM</title>
<link>https://arxiv.org/abs/2509.18934</link>
<guid>https://arxiv.org/abs/2509.18934</guid>
<content:encoded><![CDATA[
arXiv:2509.18934v1 Announce Type: new 
Abstract: Adversarial smart contracts, mostly on EVM-compatible chains like Ethereum and BSC, are deployed as EVM bytecode to exploit vulnerable smart contracts typically for financial gains. Detecting such malicious contracts at the time of deployment is an important proactive strategy preventing loss from victim contracts. It offers a better cost-benefit than detecting vulnerabilities on diverse potential victims. However, existing works are not generic with limited detection types and effectiveness due to imbalanced samples, while the emerging LLM technologies, which show its potentials in generalization, have two key problems impeding its application in this task: hard digestion of compiled-code inputs, especially those with task-specific logic, and hard assessment of LLMs' certainty in their binary answers, i.e., yes-or-no answers. Therefore, we propose a generic adversarial smart contracts detection framework FinDet, which leverages LLMs with two enhancements addressing above two problems. FinDet takes as input only the EVM-bytecode contracts and identifies adversarial ones among them with high balanced accuracy. The first enhancement extracts concise semantic intentions and high-level behavioral logic from the low-level bytecode inputs, unleashing the LLM reasoning capability restricted by the task input. The second enhancement probes and measures the LLM uncertainty to its multi-round answering to the same query, improving the LLM answering robustness for binary classifications required by the task output. Our comprehensive evaluation shows that FinDet achieves a BAC of 0.9223 and a TPR of 0.8950, significantly outperforming existing baselines. It remains robust under challenging conditions including unseen attack patterns, low-data settings, and feature obfuscation. FinDet detects all 5 public and 20+ unreported adversarial contracts in a 10-day real-world test, confirmed manually.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAPPO for Edge Server Monitoring</title>
<link>https://arxiv.org/abs/2509.19079</link>
<guid>https://arxiv.org/abs/2509.19079</guid>
<content:encoded><![CDATA[
arXiv:2509.19079v1 Announce Type: new 
Abstract: In this paper, we consider a goal-oriented communication problem for edge server monitoring, where jobs arrive intermittently at multiple dispatchers and must be assigned to shared edge servers with finite queues and time-varying availability. Accurate knowledge of server status is critical for sustaining high throughput, yet remains challenging under dynamic workloads and partial observability. To address this challenge, each dispatcher maintains server knowledge through two complementary mechanisms: (i) active status queries that provide instantaneous updates at a communication cost, and (ii) job execution feedback that reveals server conditions opportunistically. We formulate a cooperative multi-agent distributed decision-making problem in which dispatchers jointly optimize query scheduling to balance throughput against communication overhead. To solve this problem, we propose a Multi-Agent Proximal Policy Optimization (MAPPO)-based algorithm that leverages centralized training with decentralized execution (CTDE) to learn distributed query-and-dispatch policies under partial and stale observations. Numerical evaluations show that MAPPO achieves superior throughput-cost tradeoffs and significantly outperforms baseline strategies, achieving on average a 30% improvement over the closest baseline.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLMs as verification oracles for Solidity</title>
<link>https://arxiv.org/abs/2509.19153</link>
<guid>https://arxiv.org/abs/2509.19153</guid>
<content:encoded><![CDATA[
arXiv:2509.19153v1 Announce Type: new 
Abstract: Ensuring the correctness of smart contracts is critical, as even subtle flaws can lead to severe financial losses. While bug detection tools able to spot common vulnerability patterns can serve as a first line of defense, most real-world exploits and losses stem from errors in the contract business logic. Formal verification tools such as SolCMC and the Certora Prover address this challenge, but their impact remains limited by steep learning curves and restricted specification languages. Recent works have begun to explore the use of large language models (LLMs) for security-related tasks such as vulnerability detection and test generation. Yet, a fundamental question remains open: can LLMs serve as verification oracles, capable of reasoning about arbitrary contract-specific properties? In this paper, we provide the first systematic evaluation of GPT-5, a state-of-the-art reasoning LLM, in this role. We benchmark its performance on a large dataset of verification tasks, compare its outputs against those of established formal verification tools, and assess its practical effectiveness in real-world auditing scenarios. Our study combines quantitative metrics with qualitative analysis, and shows that recent reasoning-oriented LLMs can be surprisingly effective as verification oracles, suggesting a new frontier in the convergence of AI and formal methods for secure smart contract development and auditing.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A decentralized future for the open-science databases</title>
<link>https://arxiv.org/abs/2509.19206</link>
<guid>https://arxiv.org/abs/2509.19206</guid>
<content:encoded><![CDATA[
arXiv:2509.19206v1 Announce Type: new 
Abstract: Continuous and reliable access to curated biological data repositories is indispensable for accelerating rigorous scientific inquiry and fostering reproducible research. Centralized repositories, though widely used, are vulnerable to single points of failure arising from cyberattacks, technical faults, natural disasters, or funding and political uncertainties. This can lead to widespread data unavailability, data loss, integrity compromises, and substantial delays in critical research, ultimately impeding scientific progress. Centralizing essential scientific resources in a single geopolitical or institutional hub is inherently dangerous, as any disruption can paralyze diverse ongoing research. The rapid acceleration of data generation, combined with an increasingly volatile global landscape, necessitates a critical re-evaluation of the sustainability of centralized models. Implementing federated and decentralized architectures presents a compelling and future-oriented pathway to substantially strengthen the resilience of scientific data infrastructures, thereby mitigating vulnerabilities and ensuring the long-term integrity of data. Here, we examine the structural limitations of centralized repositories, evaluate federated and decentralized models, and propose a hybrid framework for resilient, FAIR, and sustainable scientific data stewardship. Such an approach offers a significant reduction in exposure to governance instability, infrastructural fragility, and funding volatility, and also fosters fairness and global accessibility. The future of open science depends on integrating these complementary approaches to establish a globally distributed, economically sustainable, and institutionally robust infrastructure that safeguards scientific data as a public good, further ensuring continued accessibility, interoperability, and preservation for generations to come.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stability and Generalization of Adversarial Diffusion Training</title>
<link>https://arxiv.org/abs/2509.19234</link>
<guid>https://arxiv.org/abs/2509.19234</guid>
<content:encoded><![CDATA[
arXiv:2509.19234v1 Announce Type: new 
Abstract: Algorithmic stability is an established tool for analyzing generalization. While adversarial training enhances model robustness, it often suffers from robust overfitting and an enlarged generalization gap. Although recent work has established the convergence of adversarial training in decentralized networks, its generalization properties remain unexplored. This work presents a stability-based generalization analysis of adversarial training under the diffusion strategy for convex losses. We derive a bound showing that the generalization error grows with both the adversarial perturbation strength and the number of training steps, a finding consistent with single-agent case but novel for decentralized settings. Numerical experiments on logistic regression validate these theoretical predictions.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Filtering amplitude dependence of correlation dynamics in complex systems: application to the cryptocurrency market</title>
<link>https://arxiv.org/abs/2509.18820</link>
<guid>https://arxiv.org/abs/2509.18820</guid>
<content:encoded><![CDATA[
arXiv:2509.18820v1 Announce Type: cross 
Abstract: Based on the cryptocurrency market dynamics, this study presents a general methodology for analyzing evolving correlation structures in complex systems using the $q$-dependent detrended cross-correlation coefficient \rho(q,s). By extending traditional metrics, this approach captures correlations at varying fluctuation amplitudes and time scales. The method employs $q$-dependent minimum spanning trees ($q$MSTs) to visualize evolving network structures. Using minute-by-minute exchange rate data for 140 cryptocurrencies on Binance (Jan 2021-Oct 2024), a rolling window analysis reveals significant shifts in $q$MSTs, notably around April 2022 during the Terra/Luna crash. Initially centralized around Bitcoin (BTC), the network later decentralized, with Ethereum (ETH) and others gaining prominence. Spectral analysis confirms BTC's declining dominance and increased diversification among assets. A key finding is that medium-scale fluctuations exhibit stronger correlations than large-scale ones, with $q$MSTs based on the latter being more decentralized. Properly exploiting such facts may offer the possibility of a more flexible optimal portfolio construction. Distance metrics highlight that major disruptions amplify correlation differences, leading to fully decentralized structures during crashes. These results demonstrate $q$MSTs' effectiveness in uncovering fluctuation-dependent correlations, with potential applications beyond finance, including biology, social and other complex systems.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Atomic Smart Contract Interoperability with High Efficiency via Cross-Chain Integrated Execution</title>
<link>https://arxiv.org/abs/2502.12820</link>
<guid>https://arxiv.org/abs/2502.12820</guid>
<content:encoded><![CDATA[
arXiv:2502.12820v2 Announce Type: replace 
Abstract: With the development of Ethereum, numerous blockchains compatible with Ethereum's execution environment (i.e., Ethereum Virtual Machine, EVM) have emerged. Developers can leverage smart contracts to run various complex decentralized applications on top of blockchains. However, the increasing number of EVM-compatible blockchains has introduced significant challenges in cross-chain interoperability, particularly in ensuring efficiency and atomicity for the whole cross-chain application. Existing solutions are either limited in guaranteeing overall atomicity for the cross-chain application, or inefficient due to the need for multiple rounds of cross-chain smart contract execution. To address this gap, we propose IntegrateX, an efficient cross-chain interoperability system that ensures the overall atomicity of cross-chain smart contract invocations. The core idea is to deploy the logic required for cross-chain execution onto a single blockchain, where it can be executed in an integrated manner. This allows cross-chain applications to perform all cross-chain logic efficiently within the same blockchain. IntegrateX consists of a cross-chain smart contract deployment protocol and a cross-chain smart contract integrated execution protocol. The former achieves efficient and secure cross-chain deployment by decoupling smart contract logic from state, and employing an off-chain cross-chain deployment mechanism combined with on-chain cross-chain verification. The latter ensures atomicity of cross-chain invocations through a 2PC-based mechanism, and enhances performance through transaction aggregation and fine-grained state lock. We implement a prototype of IntegrateX. Extensive experiments demonstrate that it reduces up to 61.2% latency compared to the state-of-the-art baseline while maintaining low gas consumption.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem</title>
<link>https://arxiv.org/abs/2509.15519</link>
<guid>https://arxiv.org/abs/2509.15519</guid>
<content:encoded><![CDATA[
arXiv:2509.15519v1 Announce Type: new 
Abstract: This paper studies fully decentralized cooperative multi-agent reinforcement learning, where each agent solely observes the states, its local actions, and the shared rewards. The inability to access other agents' actions often leads to non-stationarity during value function updates and relative overgeneralization during value function estimation, hindering effective cooperative policy learning. However, existing works fail to address both issues simultaneously, due to their inability to model the joint policy of other agents in a fully decentralized setting. To overcome this limitation, we propose a novel method named Dynamics-Aware Context (DAC), which formalizes the task, as locally perceived by each agent, as an Contextual Markov Decision Process, and further addresses both non-stationarity and relative overgeneralization through dynamics-aware context modeling. Specifically, DAC attributes the non-stationary local task dynamics of each agent to switches between unobserved contexts, each corresponding to a distinct joint policy. Then, DAC models the step-wise dynamics distribution using latent variables and refers to them as contexts. For each agent, DAC introduces a context-based value function to address the non-stationarity issue during value function update. For value function estimation, an optimistic marginal value is derived to promote the selection of cooperative actions, thereby addressing the relative overgeneralization issue. Experimentally, we evaluate DAC on various cooperative tasks (including matrix game, predator and prey, and SMAC), and its superior performance against multiple baselines validates its effectiveness.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nonconvex Decentralized Stochastic Bilevel Optimization under Heavy-Tailed Noises</title>
<link>https://arxiv.org/abs/2509.15543</link>
<guid>https://arxiv.org/abs/2509.15543</guid>
<content:encoded><![CDATA[
arXiv:2509.15543v1 Announce Type: new 
Abstract: Existing decentralized stochastic optimization methods assume the lower-level loss function is strongly convex and the stochastic gradient noise has finite variance. These strong assumptions typically are not satisfied in real-world machine learning models. To address these limitations, we develop a novel decentralized stochastic bilevel optimization algorithm for the nonconvex bilevel optimization problem under heavy-tailed noises. Specifically, we develop a normalized stochastic variance-reduced bilevel gradient descent algorithm, which does not rely on any clipping operation. Moreover, we establish its convergence rate by innovatively bounding interdependent gradient sequences under heavy-tailed noises for nonconvex decentralized bilevel optimization problems. As far as we know, this is the first decentralized bilevel optimization algorithm with rigorous theoretical guarantees under heavy-tailed noises. The extensive experimental results confirm the effectiveness of our algorithm in handling heavy-tailed noises.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Angelfish: Consensus with Optimal Throughput and Latency Across the Leader-DAG Spectrum</title>
<link>https://arxiv.org/abs/2509.15847</link>
<guid>https://arxiv.org/abs/2509.15847</guid>
<content:encoded><![CDATA[
arXiv:2509.15847v1 Announce Type: new 
Abstract: To maximize performance, many modern blockchain systems rely on eventually-synchronous, Byzantine fault-tolerant (BFT) consensus protocols. Two protocol designs have emerged in this space: protocols that minimize latency using a leader that drives both data dissemination and consensus, and protocols that maximize throughput using a separate, asynchronous data dissemination layer. Recent protocols such as Partially-Synchronous Bullshark and Sailfish combine elements of both approaches by using a DAG to enable parallel data dissemination and a leader that paces DAG formation. This improves latency while achieving state-of-the-art throughput. Yet the latency of leader-based protocols is still better under moderate loads.
  We present Angelfish, a hybrid protocol that adapts smoothly across this design space, from leader-based to Sailfish-like DAG-based consensus. Angelfish lets a dynamically-adjusted subset of parties use best-effort broadcast to issue lightweight votes instead of reliably broadcasting costlier DAG vertices. This reduces communication, helps lagging nodes catch up, and lowers latency in practice compared to prior DAG-based protocols. Our empirical evaluation shows that Angelfish attains state-of-the-art peak throughput while matching the latency of leader-based protocols under moderate throughput, delivering the best of both worlds.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Swarm Oracle: Trustless Blockchain Agreements through Robot Swarms</title>
<link>https://arxiv.org/abs/2509.15956</link>
<guid>https://arxiv.org/abs/2509.15956</guid>
<content:encoded><![CDATA[
arXiv:2509.15956v1 Announce Type: new 
Abstract: Blockchain consensus, rooted in the principle ``don't trust, verify'', limits access to real-world data, which may be ambiguous or inaccessible to some participants. Oracles address this limitation by supplying data to blockchains, but existing solutions may reduce autonomy, transparency, or reintroduce the need for trust. We propose Swarm Oracle: a decentralized network of autonomous robots -- that is, a robot swarm -- that use onboard sensors and peer-to-peer communication to collectively verify real-world data and provide it to smart contracts on public blockchains. Swarm Oracle leverages the built-in decentralization, fault tolerance and mobility of robot swarms, which can flexibly adapt to meet information requests on-demand, even in remote locations. Unlike typical cooperative robot swarms, Swarm Oracle integrates robots from multiple stakeholders, protecting the system from single-party biases but also introducing potential adversarial behavior. To ensure the secure, trustless and global consensus required by blockchains, we employ a Byzantine fault-tolerant protocol that enables robots from different stakeholders to operate together, reaching social agreements of higher quality than the estimates of individual robots. Through extensive experiments using both real and simulated robots, we showcase how consensus on uncertain environmental information can be achieved, despite several types of attacks orchestrated by large proportions of the robots, and how a reputation system based on blockchain tokens lets Swarm Oracle autonomously recover from faults and attacks, a requirement for long-term operation.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How Exclusive are Ethereum Transactions? Evidence from non-winning blocks</title>
<link>https://arxiv.org/abs/2509.16052</link>
<guid>https://arxiv.org/abs/2509.16052</guid>
<content:encoded><![CDATA[
arXiv:2509.16052v1 Announce Type: new 
Abstract: We analyze 15,097 blocks proposed for inclusion in Ethereum's blockchain over an 8-minute window on December 3, 2024, during which 38 blocks were added to the chain. We classify transactions as exclusive -- present only in blocks from a single builder -- or private -- absent from the public mempool but included in blocks from multiple builders. We find that exclusive transactions account for 84% of the total fees paid by transactions in winning blocks. Furthermore, we show that exclusivity cannot be fully explained by exclusive relationships between senders and builders: about 7% of all exclusive transactions included on-chain, by value, come from senders who route exclusively to a single builder. Analyzing transaction logs shows that some exclusive transactions are duplicates or variations of the same strategy, but even accounting for that, the share of the total fees paid by transactions in winning blocks is at least 77.2%. Taken together, our findings highlight that exclusive transactions are the dominant source of builder revenues.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Quadruped Cooperative Object Transport: Learning Decentralized Pinch-Lift-Move</title>
<link>https://arxiv.org/abs/2509.14342</link>
<guid>https://arxiv.org/abs/2509.14342</guid>
<content:encoded><![CDATA[
arXiv:2509.14342v1 Announce Type: new 
Abstract: We study decentralized cooperative transport using teams of N-quadruped robots with arm that must pinch, lift, and move ungraspable objects through physical contact alone. Unlike prior work that relies on rigid mechanical coupling between robots and objects, we address the more challenging setting where mechanically independent robots must coordinate through contact forces alone without any communication or centralized control. To this end, we employ a hierarchical policy architecture that separates base locomotion from arm control, and propose a constellation reward formulation that unifies position and orientation tracking to enforce rigid contact behavior. The key insight is encouraging robots to behave as if rigidly connected to the object through careful reward design and training curriculum rather than explicit mechanical constraints. Our approach enables coordination through shared policy parameters and implicit synchronization cues - scaling to arbitrary team sizes without retraining. We show extensive simulation experiments to demonstrate robust transport across 2-10 robots on diverse object geometries and masses, along with sim2real transfer results on lightweight objects.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks</title>
<link>https://arxiv.org/abs/2509.14380</link>
<guid>https://arxiv.org/abs/2509.14380</guid>
<content:encoded><![CDATA[
arXiv:2509.14380v1 Announce Type: new 
Abstract: Multi-Agent Reinforcement Learning (MARL) provides a powerful framework for learning coordination in multi-agent systems. However, applying MARL to robotics still remains challenging due to high-dimensional continuous joint action spaces, complex reward design, and non-stationary transitions inherent to decentralized settings. On the other hand, humans learn complex coordination through staged curricula, where long-horizon behaviors are progressively built upon simpler skills. Motivated by this, we propose CRAFT: Coaching Reinforcement learning Autonomously using Foundation models for multi-robot coordination Tasks, a framework that leverages the reasoning capabilities of foundation models to act as a "coach" for multi-robot coordination. CRAFT automatically decomposes long-horizon coordination tasks into sequences of subtasks using the planning capability of Large Language Models (LLMs). In what follows, CRAFT trains each subtask using reward functions generated by LLM, and refines them through a Vision Language Model (VLM)-guided reward-refinement loop. We evaluate CRAFT on multi-quadruped navigation and bimanual manipulation tasks, demonstrating its capability to learn complex coordination behaviors. In addition, we validate the multi-quadruped navigation policy in real hardware experiments.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Geometry-Aware Decentralized Sinkhorn for Wasserstein Barycenters</title>
<link>https://arxiv.org/abs/2509.14521</link>
<guid>https://arxiv.org/abs/2509.14521</guid>
<content:encoded><![CDATA[
arXiv:2509.14521v1 Announce Type: new 
Abstract: Distributed systems require fusing heterogeneous local probability distributions into a global summary over sparse and unreliable communication networks. Traditional consensus algorithms, which average distributions in Euclidean space, ignore their inherent geometric structure, leading to misleading results. Wasserstein barycenters offer a geometry-aware alternative by minimizing optimal transport costs, but their entropic approximations via the Sinkhorn algorithm typically require centralized coordination. This paper proposes a fully decentralized Sinkhorn algorithm that reformulates the centralized geometric mean as an arithmetic average in the log-domain, enabling approximation through local gossip protocols. Agents exchange log-messages with neighbors, interleaving consensus phases with local updates to mimic centralized iterations without a coordinator. To optimize bandwidth, we integrate event-triggered transmissions and b-bit quantization, providing tunable trade-offs between accuracy and communication while accommodating asynchrony and packet loss. Under mild assumptions, we prove convergence to a neighborhood of the centralized entropic barycenter, with bias linearly dependent on consensus tolerance, trigger threshold, and quantization error. Complexity scales near-linearly with network size. Simulations confirm near-centralized accuracy with significantly fewer messages, across various topologies and conditions.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Software-Defined Radio Testbed for Distributed LiDAR Point Cloud Sharing with IEEE 802.11p in V2V Networks</title>
<link>https://arxiv.org/abs/2509.14523</link>
<guid>https://arxiv.org/abs/2509.14523</guid>
<content:encoded><![CDATA[
arXiv:2509.14523v1 Announce Type: new 
Abstract: We present a Software Defined Radio (SDR)-based IEEE 802.11p testbed for distributed Vehicle-to-Vehicle (V2V) communication. The platform bridges the gap between network simulation and deployment by providing a modular codebase configured for cost-effective ADALM-Pluto SDRs. Any device capable of running a Docker with ROS, executing Matlab and interface with a Pluto via USB can act as a communication node. To demonstrate collaborative sensing, we share LiDAR point clouds between nodes and fuse them into a collective perception environment. We evaluated a theoretical model for leveraging decentralized storage systems (IPFS and Filecoin), analyzing constraints such as node storage convergence, latency, and scalability. In addition, we provide a channel quality study.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LEED: A Highly Efficient and Scalable LLM-Empowered Expert Demonstrations Framework for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2509.14680</link>
<guid>https://arxiv.org/abs/2509.14680</guid>
<content:encoded><![CDATA[
arXiv:2509.14680v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) holds substantial promise for intelligent decision-making in complex environments. However, it suffers from a coordination and scalability bottleneck as the number of agents increases. To address these issues, we propose the LLM-empowered expert demonstrations framework for multi-agent reinforcement learning (LEED). LEED consists of two components: a demonstration generation (DG) module and a policy optimization (PO) module. Specifically, the DG module leverages large language models to generate instructions for interacting with the environment, thereby producing high-quality demonstrations. The PO module adopts a decentralized training paradigm, where each agent utilizes the generated demonstrations to construct an expert policy loss, which is then integrated with its own policy loss. This enables each agent to effectively personalize and optimize its local policy based on both expert knowledge and individual experience. Experimental results show that LEED achieves superior sample efficiency, time efficiency, and robust scalability compared to state-of-the-art baselines.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Federated Learning for Social Network with Mobility</title>
<link>https://arxiv.org/abs/2509.14938</link>
<guid>https://arxiv.org/abs/2509.14938</guid>
<content:encoded><![CDATA[
arXiv:2509.14938v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized solution that allows collaborative local model training and global aggregation, thereby protecting data privacy. In conventional FL frameworks, data privacy is typically preserved under the assumption that local data remains absolutely private, whereas the mobility of clients is frequently neglected in explicit modeling. In this paper, we propose a hierarchical federated learning framework based on the social network with mobility namely HFL-SNM that considers both data sharing among clients and their mobility patterns. Under the constraints of limited resources, we formulate a joint optimization problem of resource allocation and client scheduling, which objective is to minimize the energy consumption of clients during the FL process. In social network, we introduce the concepts of Effective Data Coverage Rate and Redundant Data Coverage Rate. We analyze the impact of effective data and redundant data on the model performance through preliminary experiments. We decouple the optimization problem into multiple sub-problems, analyze them based on preliminary experimental results, and propose Dynamic Optimization in Social Network with Mobility (DO-SNM) algorithm. Experimental results demonstrate that our algorithm achieves superior model performance while significantly reducing energy consumption, compared to traditional baseline algorithms.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Explainable AI for Trusted Healthcare Systems</title>
<link>https://arxiv.org/abs/2509.14987</link>
<guid>https://arxiv.org/abs/2509.14987</guid>
<content:encoded><![CDATA[
arXiv:2509.14987v1 Announce Type: new 
Abstract: This paper introduces a Blockchain-Integrated Explainable AI Framework (BXHF) for healthcare systems to tackle two essential challenges confronting health information networks: safe data exchange and comprehensible AI-driven clinical decision-making. Our architecture incorporates blockchain, ensuring patient records are immutable, auditable, and tamper-proof, alongside Explainable AI (XAI) methodologies that yield transparent and clinically relevant model predictions. By incorporating security assurances and interpretability requirements into a unified optimization pipeline, BXHF ensures both data-level trust (by verified and encrypted record sharing) and decision-level trust (with auditable and clinically aligned explanations). Its hybrid edge-cloud architecture allows for federated computation across different institutions, enabling collaborative analytics while protecting patient privacy. We demonstrate the framework's applicability through use cases such as cross-border clinical research networks, uncommon illness detection and high-risk intervention decision support. By ensuring transparency, auditability, and regulatory compliance, BXHF improves the credibility, uptake, and effectiveness of AI in healthcare, laying the groundwork for safer and more reliable clinical decision-making.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Hypergraph Learning with Local Differential Privacy: Toward Privacy-Aware Hypergraph Structure Completion</title>
<link>https://arxiv.org/abs/2408.05160</link>
<guid>https://arxiv.org/abs/2408.05160</guid>
<content:encoded><![CDATA[
arXiv:2408.05160v3 Announce Type: replace 
Abstract: The rapid growth of graph-structured data necessitates partitioning and distributed storage across decentralized systems, driving the emergence of federated graph learning to collaboratively train Graph Neural Networks (GNNs) without compromising privacy. However, current methods exhibit limited performance when handling hypergraphs, which inherently represent complex high-order relationships beyond pairwise connections. Partitioning hypergraph structures across federated subsystems amplifies structural complexity, hindering high-order information mining and compromising local information integrity. To bridge the gap between hypergraph learning and federated systems, we develop FedHGL, a first-of-its-kind framework for federated hypergraph learning on disjoint and privacy-constrained hypergraph partitions. Beyond collaboratively training a comprehensive hypergraph neural network across multiple clients, FedHGL introduces a pre-propagation hyperedge completion mechanism to preserve high-order structural integrity within each client. This procedure leverages the federated central server to perform cross-client hypergraph convolution without exposing internal topological information, effectively mitigating the high-order information loss induced by subgraph partitioning. Furthermore, by incorporating two kinds of local differential privacy (LDP) mechanisms, we provide formal privacy guarantees for this process, ensuring that sensitive node features remain protected against inference attacks from potentially malicious servers or clients. Experimental results on seven real-world datasets confirm the effectiveness of our approach and demonstrate its performance advantages over traditional federated graph learning methods.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning</title>
<link>https://arxiv.org/abs/2501.12046</link>
<guid>https://arxiv.org/abs/2501.12046</guid>
<content:encoded><![CDATA[
arXiv:2501.12046v2 Announce Type: replace 
Abstract: Training machine learning models on decentralized private data via federated learning (FL) poses two key challenges: communication efficiency and privacy protection. In this work, we address these challenges within the trusted aggregator model by introducing a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), achieving both objectives simultaneously. In particular, CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a construction of randomized vector quantizer whose resulting distortion is equivalent to a prescribed noise, such as Gaussian or Laplace noise, enabling joint differential privacy and compression. Our CEPAM provides the additional benefit of privacy adaptability, allowing clients and the server to customize privacy protection based on required accuracy and protection. We theoretically analyze the privacy guarantee of CEPAM and investigate the trade-offs among user privacy and accuracy of CEPAM through experimental evaluations. Moreover, we assess CEPAM's utility performance using MNIST dataset, demonstrating that CEPAM surpasses baseline models in terms of learning accuracy.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.04317</link>
<guid>https://arxiv.org/abs/2505.04317</guid>
<content:encoded><![CDATA[
arXiv:2505.04317v4 Announce Type: replace 
Abstract: In this paper, we tackle the problem of learning to play 3v3 multi-drone volleyball, a new embodied competitive task that requires both high-level strategic coordination and low-level agile control. The task is turn-based, multi-agent, and physically grounded, posing significant challenges due to its long-horizon dependencies, tight inter-agent coupling, and the underactuated dynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play (HCSP), a hierarchical reinforcement learning framework that separates centralized high-level strategic decision-making from decentralized low-level motion control. We design a three-stage population-based training pipeline to enable both strategy and skill to emerge from scratch without expert demonstrations: (I) training diverse low-level skills, (II) learning high-level strategy via self-play with fixed low-level skills, and (III) joint fine-tuning through co-self-play. Experiments show that HCSP achieves superior performance, outperforming non-hierarchical self-play and rule-based hierarchical baselines with an average 82.9% win rate and a 71.5% win rate against the two-stage variant. Moreover, co-self-play leads to emergent team behaviors such as role switching and coordinated formations, demonstrating the effectiveness of our hierarchical design and training scheme. The project page is at https://sites.google.com/view/hi-co-self-play.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Timestamp Manipulation: Timestamp-based Nakamoto-style Blockchains are Vulnerable</title>
<link>https://arxiv.org/abs/2505.05328</link>
<guid>https://arxiv.org/abs/2505.05328</guid>
<content:encoded><![CDATA[
arXiv:2505.05328v4 Announce Type: replace 
Abstract: Nakamoto consensus are the most widely adopted decentralized consensus mechanism in cryptocurrency systems. Since it was proposed in 2008, many studies have focused on analyzing its security. Most of them focus on maximizing the profit of the adversary. Examples include the selfish mining attack [FC '14] and the recent riskless uncle maker (RUM) attack [CCS '23]. In this work, we introduce the Staircase-Unrestricted Uncle Maker (SUUM), the first block withholding attack targeting the timestamp-based Nakamoto-style blockchain. Through block withholding, timestamp manipulation, and difficulty risk control, SUUM adversaries are capable of launching persistent attacks with zero cost and minimal difficulty risk characteristics, indefinitely exploiting rewards from honest participants. This creates a self-reinforcing cycle that threatens the security of blockchains. We conduct a comprehensive and systematic evaluation of SUUM, including the attack conditions, its impact on blockchains, and the difficulty risks. Finally, we further discuss four feasible mitigation measures against SUUM.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SwarmSearch: Decentralized Search Engine with Self-Funding Economy</title>
<link>https://arxiv.org/abs/2505.07452</link>
<guid>https://arxiv.org/abs/2505.07452</guid>
<content:encoded><![CDATA[
arXiv:2505.07452v2 Announce Type: replace 
Abstract: Centralized search engines control what we see, read, believe, and vote. Consequently, they raise concerns over information control, censorship, and bias. Decentralized search engines offer a remedy to this problem, but their adoption has been hindered by their inferior quality and lack of a self-sustaining economic framework. We present SwarmSearch, a fully decentralized, AI-powered search engine with a self-funding architecture. Our system is designed for deployment within the decentralized file-sharing software Tribler. SwarmSearch integrates volunteer-based with profit-driven mechanisms to foster an implicit marketplace for resources. Employing the state-of-the-art of AI-based retrieval and relevance ranking, we also aim to close the quality gap between decentralized search and centralized alternatives. Our system demonstrates high retrieval accuracy while showing robustness in the presence of 50% adversarial nodes.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustless Autonomy: Understanding Motivations, Benefits, and Governance Dilemmas in Self-Sovereign Decentralized AI Agents</title>
<link>https://arxiv.org/abs/2505.09757</link>
<guid>https://arxiv.org/abs/2505.09757</guid>
<content:encoded><![CDATA[
arXiv:2505.09757v2 Announce Type: replace 
Abstract: The recent trend of self-sovereign Decentralized AI Agents (DeAgents) combines Large Language Model (LLM)-based AI agents with decentralization technologies such as blockchain smart contracts and trusted execution environments (TEEs). These tamper-resistant trustless substrates allow agents to achieve self-sovereignty through ownership of cryptowallet private keys and control of digital assets and social media accounts. DeAgents eliminate centralized control and reduce human intervention, addressing key trust concerns inherent in centralized AI systems. This contributes to social computing by enabling new human cooperative paradigm "intelligence as commons." However, given ongoing challenges in LLM reliability such as hallucinations, this creates paradoxical tension between trustlessness and unreliable autonomy. This study addresses this empirical research gap through interviews with DeAgents stakeholders-experts, founders, and developers-to examine their motivations, benefits, and governance dilemmas. The findings will guide future DeAgents system and protocol design and inform discussions about governance in sociotechnical AI systems in the future agentic web.
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vehicle-to-Grid Integration: Ensuring Grid Stability, Strengthening Cybersecurity, and Advancing Energy Market Dynamics</title>
<link>https://arxiv.org/abs/2509.13393</link>
<guid>https://arxiv.org/abs/2509.13393</guid>
<content:encoded><![CDATA[
arXiv:2509.13393v1 Announce Type: new 
Abstract: The increasing adoption of electric vehicles has spurred significant interest in Vehicle-to-Grid technology as a transformative approach to modern energy systems. This paper presents a systematic review of V2G systems, focusing on their integration challenges and potential solutions. First, the current state of V2G development is examined, highlighting its growing importance in mitigating peak demand, enhancing voltage and frequency regulation, and reinforcing grid resilience. The study underscores the pivotal role of artificial intelligence and machine learning in optimizing energy management, load forecasting, and real-time grid control. A critical analysis of cybersecurity risks reveals heightened vulnerabilities stemming from V2G's dependence on interconnected networks and real-time data exchange, prompting an exploration of advanced mitigation strategies, including federated learning, blockchain, and quantum-resistant cryptography. Furthermore, the paper reviews economic and market aspects, including business models (V2G as an aggregator or due to self-consumption), regulation (as flexibility service provider) and factors influencing user acceptance shaping V2G adoption. Data from global case studies and pilot programs offer a snapshot of how V2G has been implemented at different paces across regions. Finally, the study suggests a multi-layered framework that incorporates grid stability resilience, cybersecurity resiliency, and energy market dynamics and provides strategic recommendations to enable scalable, secure, and economically viable V2G deployment.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2509.13634</link>
<guid>https://arxiv.org/abs/2509.13634</guid>
<content:encoded><![CDATA[
arXiv:2509.13634v1 Announce Type: new 
Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method of training machine learning models on decentralized networks. However to ensure reliable operation of UAV-assisted FL systems, issues like as excessive energy consumption, communication inefficiencies, and security vulnerabilities must be solved. This paper proposes an innovative framework that integrates Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to tackle these challenges. UAVs act as mobile base stations, allowing scattered devices to train FL models locally and upload model updates for aggregation. By incorporating DT technology, our approach enables real-time system monitoring and predictive maintenance, improving UAV network efficiency. Additionally, Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification without exposing sensitive data. To optimize energy efficiency and resource management, we introduce a dynamic allocation strategy that adjusts UAV flight paths, transmission power, and processing rates based on network conditions. Using block coordinate descent and convex optimization techniques, our method significantly reduces system energy consumption by up to 29.6% compared to conventional FL approaches. Simulation results demonstrate improved learning performance, security, and scalability, positioning this framework as a promising solution for next-generation UAV-based intelligent networks.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dissipativity-Based Data-Driven Decentralized Control of Interconnected Systems</title>
<link>https://arxiv.org/abs/2509.14047</link>
<guid>https://arxiv.org/abs/2509.14047</guid>
<content:encoded><![CDATA[
arXiv:2509.14047v1 Announce Type: new 
Abstract: We propose data-driven decentralized control algorithms for stabilizing interconnected systems. We first derive a data-driven condition to synthesize a local controller that ensures the dissipativity of the local subsystems. Then, we propose data-driven decentralized stability conditions for the global system based on the dissipativity of each local system. Since both conditions take the form of linear matrix inequalities and are based on dissipativity theory, this yields a unified pipeline, resulting in a data-driven decentralized control algorithm. As a special case, we also consider stabilizing systems interconnected through diffusive coupling and propose a control algorithm. We validate the effectiveness and the scalability of the proposed control algorithms in numerical examples in the context of microgrids.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads</title>
<link>https://arxiv.org/abs/2509.14126</link>
<guid>https://arxiv.org/abs/2509.14126</guid>
<content:encoded><![CDATA[
arXiv:2509.14126v1 Announce Type: new 
Abstract: Collaborative transportation of cable-suspended payloads by teams of Unmanned Aerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to different payload shapes, and provide built-in compliance, making it attractive for applications ranging from disaster relief to precision logistics. However, multi-UAV coordination under disturbances, nonlinear payload dynamics, and slack--taut cable modes remains a challenging control problem. To our knowledge, no prior work has addressed these cable mode transitions in the multi-UAV context, instead relying on simplifying rigid-link assumptions. We propose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for multi-UAV cable-suspended payload transport. Simulation results demonstrate that the learned policies can outperform classical decentralized controllers in terms of disturbance rejection and tracking precision, achieving an 80% recovery rate from harsh conditions compared to 44% for the baseline method. We also achieve successful zero-shot sim-to-real transfer and demonstrate that our policies are highly robust under harsh conditions, including wind, random external disturbances, and transitions between slack and taut cable dynamics. This work paves the way for autonomous, resilient UAV teams capable of executing complex payload missions in unstructured environments.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Complete Decentralization of Linear Quadratic Gaussian Control for the Discrete Wave Equation</title>
<link>https://arxiv.org/abs/2509.13446</link>
<guid>https://arxiv.org/abs/2509.13446</guid>
<content:encoded><![CDATA[
arXiv:2509.13446v1 Announce Type: cross 
Abstract: The linear quadratic Gaussian (LQG) control problem for the linear wave equation on the unit circle with fully distributed actuation and partial state measurements is considered. An analytical solution to a spatial discretization of the problem is obtained. The main result of this work illustrates that for specific parameter values, the optimal LQG policy is completely decentralized, meaning only a measurement at spatial location $i$ is needed to compute an optimal control signal to actuate at this location. The relationship between performance and decentralization as a function of parameters is explored. Conditions for complete decentralization are related to metrics of kinetic and potential energy quantities and control effort.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph Neural Networks for Next-Generation-IoT: Recent Advances and Open Challenges</title>
<link>https://arxiv.org/abs/2412.20634</link>
<guid>https://arxiv.org/abs/2412.20634</guid>
<content:encoded><![CDATA[
arXiv:2412.20634v3 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) have emerged as a powerful framework for modeling complex interconnected systems, hence making them particularly well-suited to address the growing challenges of next-generation Internet of Things (NG-IoT) networks. Existing studies remain fragmented, and there is a lack of comprehensive guidance on how GNNs can be systematically applied to NG-IoT systems. As NG-IoT systems evolve toward 6G, they incorporate diverse technologies. These advances promise unprecedented connectivity, sensing, and automation but also introduce significant complexity, requiring new approaches for scalable learning, dynamic optimization, and secure, decentralized decision-making. This survey provides a comprehensive and forward-looking exploration of how GNNs can empower NG-IoT environments. We commence by exploring the fundamental paradigms of GNNs and articulating the motivation for their use in NG-IoT networks. Besides, we intrinsically connect GNNs with the family of low-density parity-check codes, modeling the NG-IoT as dynamic constrained graphs. We highlight the distinct roles of node-, edge-, and graph-level tasks in tackling key challenges and demonstrate the GNNs' ability to overcome the limitations of traditional optimization. We examine the application of GNNs across core NG-enabling technologies and their integration with distributed frameworks to support privacy-preservation and distributed intelligence. We then delve into the challenges posed by adversarial attacks, offering insights into defense mechanisms. Lastly, we examine how GNNs can be integrated with emerging technologies. Our findings highlight the transformative potential of GNNs in improving efficiency, scalability, and security. Finally, we summarize the key lessons learned and outline promising future research directions, along with a set of design guidelines tailored for NG-IoT applications.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Commit-Reveal$^2$: Securing Randomness Beacons with Randomized Reveal Order in Smart Contracts</title>
<link>https://arxiv.org/abs/2504.03936</link>
<guid>https://arxiv.org/abs/2504.03936</guid>
<content:encoded><![CDATA[
arXiv:2504.03936v2 Announce Type: replace 
Abstract: Simple commit-reveal beacons are vulnerable to last-revealer strategies, and existing descriptions often leave accountability and recovery mechanisms unspecified for practical deployments. We present Commit-Reveal$^2$, a layered design for blockchain deployments that cryptographically randomizes the final reveal order, together with a concrete accountability and fallback mechanism that we implement as smart-contract logic. The protocol is architected as a hybrid system, where routine coordination runs off chain for efficiency and the blockchain acts as the trust anchor for commitments and the final arbiter for disputes. Our implementation covers leader coordination, on-chain verification, slashing for non-cooperation, and an explicit on-chain recovery path that maintains progress when off-chain coordination fails. We formally define two security goals for distributed randomness beacons, unpredictability and bit-wise bias resistance, and we show that Commit-Reveal$^2$ meets these notions under standard hash assumptions in the random-oracle model. In measurements with small to moderate operator sets, the hybrid design reduces on-chain gas by more than 80% compared to a fully on-chain baseline. We release a publicly verifiable prototype and evaluation artifacts to support replication and adoption in blockchain applications.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedDiverse: Tackling Data Heterogeneity in Federated Learning with Diversity-Driven Client Selection</title>
<link>https://arxiv.org/abs/2504.11216</link>
<guid>https://arxiv.org/abs/2504.11216</guid>
<content:encoded><![CDATA[
arXiv:2504.11216v2 Announce Type: replace 
Abstract: Federated Learning (FL) enables decentralized training of machine learning models on distributed data while preserving privacy. However, in real-world FL settings, client data is often non-identically distributed and imbalanced, resulting in statistical data heterogeneity which impacts the generalization capabilities of the server's model across clients, slows convergence and reduces performance. In this paper, we address this challenge by proposing first a characterization of statistical data heterogeneity by means of 6 metrics of global and client attribute imbalance, class imbalance, and spurious correlations. Next, we create and share 7 computer vision datasets for binary and multiclass image classification tasks in Federated Learning that cover a broad range of statistical data heterogeneity and hence simulate real-world situations. Finally, we propose FEDDIVERSE, a novel client selection algorithm in FL which is designed to manage and leverage data heterogeneity across clients by promoting collaboration between clients with complementary data distributions. Experiments on the seven proposed FL datasets demonstrate FEDDIVERSE's effectiveness in enhancing the performance and robustness of a variety of FL methods while having low communication and computational overhead.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging</title>
<link>https://arxiv.org/abs/2504.19639</link>
<guid>https://arxiv.org/abs/2504.19639</guid>
<content:encoded><![CDATA[
arXiv:2504.19639v2 Announce Type: replace 
Abstract: Federated Learning (FL) enables model training across decentralized devices without sharing raw data, thereby preserving privacy in sensitive domains like healthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN) architectures against traditional MLP across six state-of-the-art FL algorithms on a blood cell classification dataset. Notably, our experiments demonstrate that KAN can effectively replace MLP in federated environments, achieving superior performance with simpler architectures. Furthermore, we analyze the impact of key hyperparameters-grid size and network architecture-on KAN performance under varying degrees of Non-IID data distribution. In addition, our ablation studies reveal that optimizing KAN width while maintaining minimal depth yields the best performance in federated settings. As a result, these findings establish KAN as a promising alternative for privacy-preserving medical imaging applications in distributed healthcare. To the best of our knowledge, this is the first comprehensive benchmark of KAN in FL settings for medical imaging task.
]]></content:encoded>
<pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scaling Up Data Parallelism in Decentralized Deep Learning</title>
<link>https://arxiv.org/abs/2509.12213</link>
<guid>https://arxiv.org/abs/2509.12213</guid>
<content:encoded><![CDATA[
arXiv:2509.12213v1 Announce Type: new 
Abstract: Although it has been extensively explored in theory, decentralized learning is not yet green-lighted for production use, largely due to a lack of stability, scalability, and generality in large scale DNN training. To shed light on the production use of decentralized learning, this work studies decentralized data parallel training at scale. To this end, we introduce a benchmarking framework, namely DBench, to host both centralized and decentralized DNN training. Building upon DBench, we introduce a benchmarking methodology to uncover the correlations between model accuracy and the variances of parameter tensors by varying communication graphs and training scales. Based on the benchmarking results, we observe that, (1) Similar to centralized learning, decentralized data parallel training also presents the issues of scalability and generality when the training scales up; (2) The model accuracy of decentralized learning is correlated to the number of connections in a communication graph; (3) The model accuracy of decentralized learning is surprisingly sensitive to the variance of parameter tensors across model replicas. Built upon the observations, we propose Ada, a decentralized adaptive approach that performs large scale DNN training following a decentralized SGD method and adapting the communication graph in use dynamically throughout training iterations. We apply Ada on large scale training and observe that Ada can obtain the best convergence rates consistently in decentralized DNN training, and delivers equally or comparably good model accuracy for all sample applications as centralized learning does, even when training ResNet50 for ImageNet-1K on the scale of 1008 GPUs.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ratio1 -- AI meta-OS</title>
<link>https://arxiv.org/abs/2509.12223</link>
<guid>https://arxiv.org/abs/2509.12223</guid>
<content:encoded><![CDATA[
arXiv:2509.12223v1 Announce Type: new 
Abstract: We propose the Ratio1 AI meta-operating system (meta-OS), a decentralized MLOps protocol that unifies AI model development, deployment, and inference across heterogeneous edge devices. Its key innovation is an integrated blockchain-based framework that transforms idle computing resources (laptops, smartphones, cloud VMs) into a trustless global supercomputer. The architecture includes novel components: a decentralized authentication layer (dAuth), an in-memory state database (CSTORE), a distributed storage system (R1FS), homomorphic encrypted federated learning (EDIL), decentralized container orchestration (Deeploy) and an oracle network (OracleSync), which collectively ensure secure, resilient execution of AI pipelines and other container based apps at scale. The protocol enforces a formal circular token-economic model combining Proof-of-Availability (PoA) and Proof-of-AI (PoAI) consensus. Compared to centralized heterogeneous cloud MLOps and existing decentralized compute platforms, which often lack integrated AI toolchains or trusted Ratio1 node operators (R1OP) mechanics, Ratio1's holistic design lowers barriers for AI deployment and improves cost-efficiency. We provide mathematical formulations of its secure licensing and reward protocols, and include descriptive information for the system architecture and protocol flow. We argue that our proposed fully functional ecosystem proposes and demonstrates significant improvements in accessibility, scalability, and security over existing alternatives.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Private Markovian Equilibrium in Stackelberg Markov Games for Smart Grid Demand Response</title>
<link>https://arxiv.org/abs/2509.12225</link>
<guid>https://arxiv.org/abs/2509.12225</guid>
<content:encoded><![CDATA[
arXiv:2509.12225v1 Announce Type: new 
Abstract: The increasing integration of renewable energy introduces a great challenge to the supply and demand balance of the power grid. To address this challenge, this paper formulates a Stackelberg Markov game (SMG) between an aggregator and multiple users, where the aggregator sets electricity prices and users make demand and storage decisions. Considering that users' storage levels are private information, we introduce private states and propose the new concepts of private Markovian strategies (PMS) and private Markovian equilibrium (PME). We establish the existence of a pure PME in the lower-level Markov game and prove that it can be computed in polynomial time. Notably, computing equilibrium in general Markov games is hard, and polynomial-time algorithms are rarely available. Based on these theoretical results, we develop a scalable solution framework combining centralized and decentralized algorithms for the lower-level PME computation with upper-level pricing optimization. Numerical simulations with up to 50 users based on real data validate the effectiveness and scalability of the proposed methods, whereas prior studies typically consider no more than 5 users.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Storage places in diplomatic texts (7th-13th centuries). Lexical, semantic, and digital investigation</title>
<link>https://arxiv.org/abs/2509.12230</link>
<guid>https://arxiv.org/abs/2509.12230</guid>
<content:encoded><![CDATA[
arXiv:2509.12230v1 Announce Type: new 
Abstract: This study examines the evolution of references to grain storage structures in medieval European charters, based on a quantitative and semantic analysis of the digitized CEMA (Cartae Europae Medii Aevi) corpus comprising more than 225,000 documents. The author applies text mining and distributional analysis methods to a lexicon of some forty terms designating storage locations (grangia, horreum, granarium, granica, etc.), cross-referencing these data with references to grain and analyzing their semantic contexts over the long term. The analysis reveals a paradigm shift between the early Middle Ages (decentralized, loosely regulated storage) and the 12th-13th centuries (centralization of storage by the ruling classes). Granaries became instruments of spatial polarization and social control, contributing to the accentuation of social domination in medieval Europe. This evolution was accompanied by a new conceptualization of storage, both material and spiritual.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Neural Collapse-Inspired Multi-Label Federated Learning under Label-Distribution Skew</title>
<link>https://arxiv.org/abs/2509.12544</link>
<guid>https://arxiv.org/abs/2509.12544</guid>
<content:encoded><![CDATA[
arXiv:2509.12544v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy. However, the performance of deep learning often deteriorates in FL due to decentralized and heterogeneous data. This challenge is further amplified in multi-label scenarios, where data exhibit complex characteristics such as label co-occurrence, inter-label dependency, and discrepancies between local and global label relationships. While most existing FL research primarily focuses on single-label classification, many real-world applications, particularly in domains such as medical imaging, often involve multi-label settings. In this paper, we address this important yet underexplored scenario in FL, where clients hold multi-label data with skewed label distributions. Neural Collapse (NC) describes a geometric structure in the latent feature space where features of each class collapse to their class mean with vanishing intra-class variance, and the class means form a maximally separated configuration. Motivated by this theory, we propose a method to align feature distributions across clients and to learn high-quality, well-clustered representations. To make the NC-structure applicable to multi-label settings, where image-level features may contain multiple semantic concepts, we introduce a feature disentanglement module that extracts semantically specific features. The clustering of these disentangled class-wise features is guided by a predefined shared NC structure, which mitigates potential conflicts between client models due to diverse local data distributions. In addition, we design regularisation losses to encourage compact clustering in the latent feature space. Experiments conducted on four benchmark datasets across eight diverse settings demonstrate that our approach outperforms existing methods, validating its effectiveness in this challenging FL scenario.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Asymmetric Grid Quorum Systems for Heterogeneous Processes</title>
<link>https://arxiv.org/abs/2509.12942</link>
<guid>https://arxiv.org/abs/2509.12942</guid>
<content:encoded><![CDATA[
arXiv:2509.12942v1 Announce Type: new 
Abstract: Quorum systems are a common way to formalize failure assumptions in distributed systems. Traditionally, these assumptions are shared by all involved processes. More recently, systems have emerged which allow processes some freedom in choosing their own, subjective or asymmetric, failure assumptions. For such a system to work, individual processes' assumptions must be compatible. However, this leads to a Catch-22-style scenario: How can processes collaborate to agree on compatible failure assumptions when they have no compatible failure assumptions to start with?
  We introduce asymmetric grid quorum systems that allow a group of processes to specify heterogeneous trust assumptions independently of each other and without coordination. They are based on qualitative attributes describing how the processes differ. Each process may select a quorum system from this class that aligns best with its subjective view. The available choices are designed to be compatible by definition, thereby breaking the cycling dependency. Asymmetric grid quorum systems have many applications that range from cloud platforms to blockchain networks.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>xRWA: A Cross-Chain Framework for Interoperability of Real-World Assets</title>
<link>https://arxiv.org/abs/2509.12957</link>
<guid>https://arxiv.org/abs/2509.12957</guid>
<content:encoded><![CDATA[
arXiv:2509.12957v1 Announce Type: new 
Abstract: Real-World Assets (RWAs) have recently attracted increasing attention as a means of bridging traditional financial instruments with decentralized infrastructures. By representing assets such as bonds, commodities, and real estate on blockchains, RWAs can enhance liquidity, broaden accessibility, and extend the scope of decentralized finance. Industry forecasts further suggest rapid growth of tokenized RWAs in the coming years, underscoring their potential role in the evolution of digital financial markets. However, when deployed across multiple blockchains, RWAs face challenges such as repeated authentication on different chains and inefficiency caused by multi-step settlement protocols. To address these issues, we present a cross-chain framework for RWAs that emphasizes identity management, authentication, and interaction. The framework integrates Decentralized Identifiers and Verifiable Credentials with customized attributes to support decentralized identification, and incorporates an authentication protocol based on Simplified Payment Verification to avoid redundant verification across chains. Furthermore, we design a cross-chain channel that enables the settlement of RWAs without requiring channel closure, thereby improving operational efficiency. We implement the framework and evaluate it through simulations, which confirm its feasibility and demonstrate improvements in efficiency for RWAs in cross-chain settings.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Validating Solidity Code Defects using Symbolic and Concrete Execution powered by Large Language Models</title>
<link>https://arxiv.org/abs/2509.13023</link>
<guid>https://arxiv.org/abs/2509.13023</guid>
<content:encoded><![CDATA[
arXiv:2509.13023v1 Announce Type: new 
Abstract: The high rate of false alarms from static analysis tools and Large Language Models (LLMs) complicates vulnerability detection in Solidity Smart Contracts, demanding methods that can formally or empirically prove the presence of defects. This paper introduces a novel detection pipeline that integrates custom Slither-based detectors, LLMs, Kontrol, and Forge. Our approach is designed to reliably detect defects and generate proofs.  We currently perform experiments with promising results for seven types of critical defects. We demonstrate the pipeline's efficacy by presenting our findings for three vulnerabilities -- Reentrancy, Complex Fallback, and Faulty Access Control Policies -- that are challenging for current verification solutions, which often generate false alarms or fail to detect them entirely. We highlight the potential of either symbolic or concrete execution in correctly classifying such code faults. By chaining these instruments, our method effectively validates true positives, significantly reducing the manual verification burden. Although we identify potential limitations, such as the inconsistency and the cost of LLMs, our findings establish a robust framework for combining heuristic analysis with formal verification to achieve more reliable and automated smart contract auditing.
]]></content:encoded>
<pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms</title>
<link>https://arxiv.org/abs/2509.10507</link>
<guid>https://arxiv.org/abs/2509.10507</guid>
<content:encoded><![CDATA[
arXiv:2509.10507v1 Announce Type: new 
Abstract: Internet of Intelligent Things (IoIT), an emerging field, combines the utility of Internet of Things (IoT) devices with the innovation of embedded AI algorithms. However, it does not come without challenges, and struggles regarding available computing resources, energy supply, and storage limitations. In particular, many impediments to IoIT are linked to the energy-efficient deployment of machine learning (ML)/deep learning (DL) models in embedded devices. Research has been conducted to design energy-efficient IoIT platforms, but these papers often focus on centralized systems, in which some central entity processes all the data and coordinates actions. This can be problematic, e.g., serve as bottleneck or lead to security concerns. In a decentralized system, nodes/devices would self-organize and make their own decisions. Therefore, to address such issues, we propose a heterogeneous, decentralized sensing and monitoring IoIT peer-to-peer mesh network system model. Nodes in the network will coordinate towards several optimization goals: reliability, energy efficiency, and latency. The system employs federated learning to train nodes in a distributed manner, metaheuristics to optimize task allocation and routing paths, and multi-objective optimization to balance conflicting performance goals.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Identity Management on Ripple: A Conceptual Framework for High-Speed, Low-Cost Identity Transactions in Attestation-Based Attribute-Based Identity</title>
<link>https://arxiv.org/abs/2509.10545</link>
<guid>https://arxiv.org/abs/2509.10545</guid>
<content:encoded><![CDATA[
arXiv:2509.10545v1 Announce Type: new 
Abstract: Recent years have seen many industrial implementations and much scholastic research, i.e., prototypes and theoretical frameworks, in Decentralized Identity Management Systems (DIDMS). It is safe to say that Attestation-Based Attribute-Based Decentralized IDM (ABABDIDM) has not received anywhere near the same level of attention in the literature as general Attribute-Based DIDMs (ABDIDM), i.e, decentralized Attribute-Based Access Control (ABAC). The use of decentralization, i.e., DIDM, is to improve upon the security and privacy-related issues of centralized Identity Management Systems (IDM) and Attribute-Based IDMs (ABIDM). And blockchain is the framework used for decentralization in all these schemes. Many DIDMs - even ABDIDMs - have been defined on popular blockchains such as Hyperledger, Ethereum, and Bitcoin. However, despite the characteristics of Ripple that makes it appealing for an ABIDM, there is a lack of research to develop an Identity Management System (IDMS) on Ripple in literature. We have attempted to conceptualize an ABABDIDM on Ripple.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ZapGPT: Free-form Language Prompting for Simulated Cellular Control</title>
<link>https://arxiv.org/abs/2509.10660</link>
<guid>https://arxiv.org/abs/2509.10660</guid>
<content:encoded><![CDATA[
arXiv:2509.10660v1 Announce Type: new 
Abstract: Human language is one of the most expressive tools for conveying intent, yet most artificial or biological systems lack mechanisms to interpret or respond meaningfully to it. Bridging this gap could enable more natural forms of control over complex, decentralized systems. In AI and artificial life, recent work explores how language can specify high-level goals, but most systems still depend on engineered rewards, task-specific supervision, or rigid command sets, limiting generalization to novel instructions. Similar constraints apply in synthetic biology and bioengineering, where the locus of control is often genomic rather than environmental perturbation.
  A key open question is whether artificial or biological collectives can be guided by free-form natural language alone, without task-specific tuning or carefully designed evaluation metrics. We provide one possible answer here by showing, for the first time, that simple agents' collective behavior can be guided by free-form language prompts: one AI model transforms an imperative prompt into an intervention that is applied to simulated cells; a second AI model scores how well the prompt describes the resulting cellular dynamics; and the former AI model is evolved to improve the scores generated by the latter.
  Unlike previous work, our method does not require engineered fitness functions or domain-specific prompt design. We show that the evolved system generalizes to unseen prompts without retraining. By treating natural language as a control layer, the system suggests a future in which spoken or written prompts could direct computational, robotic, or biological systems to desired behaviors. This work provides a concrete step toward this vision of AI-biology partnerships, in which language replaces mathematical objective functions, fixed rules, and domain-specific programming.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Experimental Validation of Decentralized Affine Transformation</title>
<link>https://arxiv.org/abs/2509.10791</link>
<guid>https://arxiv.org/abs/2509.10791</guid>
<content:encoded><![CDATA[
arXiv:2509.10791v1 Announce Type: new 
Abstract: This paper presents an experimental validation of decentralized affine transformation (AT) in multi-agent systems using teams of mini-quadcopters. The AT framework enables an agent team to safely navigate constrained, obstacle-rich environments while allowing aggressive changes in inter-agent distances, which are formally characterized through the decomposition of the AT transformation matrix. Without loss of generality, we focus on two-dimensional AT, formulated as a decentralized leader-follower problem. In this formulation, three leader quadcopters are positioned at the vertices of a triangle, while all follower quadcopters remain within the triangle. The leaders know the desired trajectories prescribed by the AT, whereas the followers do not. Instead, the followers infer their trajectories through local communication governed by fixed communication weights determined by the initial spatial configuration of the team. Experimental results validate the asymptotic convergence of decentralized AT and demonstrate its capability to safely guide multi-agent teams through obstacle-laden environments.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Arguzz: Testing zkVMs for Soundness and Completeness Bugs</title>
<link>https://arxiv.org/abs/2509.10819</link>
<guid>https://arxiv.org/abs/2509.10819</guid>
<content:encoded><![CDATA[
arXiv:2509.10819v1 Announce Type: new 
Abstract: Zero-knowledge virtual machines (zkVMs) are increasingly deployed in decentralized applications and blockchain rollups since they enable verifiable off-chain computation. These VMs execute general-purpose programs, frequently written in Rust, and produce succinct cryptographic proofs. However, zkVMs are complex, and bugs in their constraint systems or execution logic can cause critical soundness (accepting invalid executions) or completeness (rejecting valid ones) issues.
  We present Arguzz, the first automated tool for testing zkVMs for soundness and completeness bugs. To detect such bugs, Arguzz combines a novel variant of metamorphic testing with fault injection. In particular, it generates semantically equivalent program pairs, merges them into a single Rust program with a known output, and runs it inside a zkVM. By injecting faults into the VM, Arguzz mimics malicious or buggy provers to uncover overly weak constraints.
  We used Arguzz to test six real-world zkVMs (RISC Zero, Nexus, Jolt, SP1, OpenVM, and Pico) and found eleven bugs in three of them. One RISC Zero bug resulted in a $50,000 bounty, despite prior audits, demonstrating the critical need for systematic testing of zkVMs.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Paradigm Shift to Audit Rift: Exploring Vulnerabilities and Audit Tips for TON Smart Contracts</title>
<link>https://arxiv.org/abs/2509.10823</link>
<guid>https://arxiv.org/abs/2509.10823</guid>
<content:encoded><![CDATA[
arXiv:2509.10823v1 Announce Type: new 
Abstract: The Open Network (TON) is a high-performance blockchain platform designed for scalability and efficiency, leveraging an asynchronous execution model and a multi-layered architecture. While TON's design offers significant advantages, it also introduces unique challenges for smart contract development and security. This paper introduces a comprehensive audit checklist for TON smart contracts, based on an analysis of 34 professional audit reports containing 233 real-world vulnerabilities. The checklist addresses TON-specific challenges, such as asynchronous message handling, and provides actionable insights for developers and auditors. We also present detailed case studies of vulnerabilities in TON smart contracts, highlighting their implications and offering lessons learned. By adopting this checklist, developers and auditors can systematically identify and mitigate vulnerabilities, enhancing the security and reliability of TON-based projects. Our work bridges the gap between Ethereum's mature audit methodologies and the emerging needs of the TON ecosystem, fostering a more secure and robust blockchain environment.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design of scalable orthogonal digital encoding architecture for large-area flexible tactile sensing in robotics</title>
<link>https://arxiv.org/abs/2509.10888</link>
<guid>https://arxiv.org/abs/2509.10888</guid>
<content:encoded><![CDATA[
arXiv:2509.10888v1 Announce Type: new 
Abstract: Human-like embodied tactile perception is crucial for the next-generation intelligent robotics. Achieving large-area, full-body soft coverage with high sensitivity and rapid response, akin to human skin, remains a formidable challenge due to critical bottlenecks in encoding efficiency and wiring complexity in existing flexible tactile sensors, thus significantly hinder the scalability and real-time performance required for human skin-level tactile perception. Herein, we present a new architecture employing code division multiple access-inspired orthogonal digital encoding to overcome these challenges. Our decentralized encoding strategy transforms conventional serial signal transmission by enabling parallel superposition of energy-orthogonal base codes from distributed sensing nodes, drastically reducing wiring requirements and increasing data throughput. We implemented and validated this strategy with off-the-shelf 16-node sensing array to reconstruct the pressure distribution, achieving a temporal resolution of 12.8 ms using only a single transmission wire. Crucially, the architecture can maintain sub-20ms latency across orders-of-magnitude variations in node number (to thousands of nodes). By fundamentally redefining signal encoding paradigms in soft electronics, this work opens new frontiers in developing scalable embodied intelligent systems with human-like sensory capabilities.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Framework for Formal Modelling of Metaverse Applications Using Hierarchical Colored Petri Nets</title>
<link>https://arxiv.org/abs/2509.10936</link>
<guid>https://arxiv.org/abs/2509.10936</guid>
<content:encoded><![CDATA[
arXiv:2509.10936v1 Announce Type: new 
Abstract: The Metaverse emerges by integrating highly-distributed, complex, and interconnecting technologies. These technologies need to be formally verified and evaluated through formal modelling before executing them in real-world applications, in order to avoid negative impacts on the real world due to failure of the Metaverse technologies. However, the formal modelling of Metaverse technologies is challenging due to its highly complex nature. Therefore, a comprehensive formal verification of the Metaverse technologies is needed for its realization in multiple potential areas. In this study, a framework is proposed for the formal modelling of Metaverse technologies, which allows holistic insights for all applications of Metaverse technologies. By utilizing the proposed framework, Metaverse applications of any complexity can be modeled. The working of the proposed framework is illustrated by modelling a case study of an Air Traffic Control system. In the proposed framework, we utilize hierarchical colored Petri nets for formal modelling of behavior of the air traffic control system. The correctness of air traffic control system properties, such as liveness, reachability, and boundedness, is verified in the proposed framework. The results of the case study reveal that the proposed framework can be used as a template for mathematical verification of challenging and complex Metaverse applications. The results also show that formal modelling provides an effective tool for identifying flaws in the early phases of the design of Metaverse applications. The implication of using formal verification is that it can increase confidence about the correctness of the Metaverse applications.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Range-Based Sharding (RBS) Protocol for Scalable Enterprise Blockchain</title>
<link>https://arxiv.org/abs/2509.11006</link>
<guid>https://arxiv.org/abs/2509.11006</guid>
<content:encoded><![CDATA[
arXiv:2509.11006v1 Announce Type: new 
Abstract: Blockchain technology offers decentralization and security but struggles with scalability, particularly in enterprise settings where efficiency and controlled access are paramount. Sharding is a promising solution for private blockchains, yet existing approaches face challenges in coordinating shards, ensuring fault tolerance with limited nodes, and minimizing the high overhead of consensus mechanisms like PBFT. This paper proposes the Range-Based Sharding (RBS) Protocol, a novel sharding mechanism tailored for enterprise blockchains, implemented on Quorum. Unlike traditional sharding models such as OmniLedger and non-sharding Corda framework, RBS employs a commit-reveal scheme for secure and unbiased shard allocation, ensuring fair validator distribution while reducing cross-shard transaction delays. Our approach enhances scalability by balancing computational loads across shards, reducing consensus overhead, and improving parallel transaction execution. Experimental evaluations demonstrate that RBS achieves significantly higher throughput and lower latency compared to existing enterprise sharding frameworks, making it a viable and efficient solution for largescale blockchain deployments.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>General Decentralized Stochastic Optimal Control via Change of Measure: Applications to the Witsenhausen Counterexample</title>
<link>https://arxiv.org/abs/2509.11013</link>
<guid>https://arxiv.org/abs/2509.11013</guid>
<content:encoded><![CDATA[
arXiv:2509.11013v1 Announce Type: new 
Abstract: In this paper we present global and person-by-person (PbP) optimality conditions for general decentralized stochastic dynamic optimal control problems, using a discrete-time version of Girsanov's change of measure. The PbP optimality conditions are applied to the Witsenhausen counterexample to show that the two strategies satisfy two coupled nonlinear integral equations. Further, we prove a fixed point theorem in a function space, establishing existence and uniqueness of solutions to the integral equations. We also provide numerical solutions of the two integral equations using the Gauss Hermite Quadrature scheme, and include a detail comparison to other numerical methods of the literature. The numerical solutions confirm Witsehausen's observation that, for certain choices of parameters, linear or affine strategies are optimal, while for other choices of parameters nonlinear strategies outperformed affine strategies.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset</title>
<link>https://arxiv.org/abs/2509.11136</link>
<guid>https://arxiv.org/abs/2509.11136</guid>
<content:encoded><![CDATA[
arXiv:2509.11136v1 Announce Type: new 
Abstract: Persian names present unique challenges for natural language processing applications, particularly in gender detection and digital identity creation, due to transliteration inconsistencies and cultural-specific naming patterns. Existing tools exhibit significant performance degradation on Persian names, while the scarcity of comprehensive datasets further compounds these limitations. To address these challenges, the present research introduces PNGT-26K, a comprehensive dataset of Persian names, their commonly associated gender, and their English transliteration, consisting of approximately 26,000 tuples. As a demonstration of how this resource can be utilized, we also introduce two frameworks, namely Open Gender Detection and Nominalist. Open Gender Detection is a production-grade, ready-to-use framework for using existing data from a user, such as profile photo and name, to give a probabilistic guess about the person's gender. Nominalist, the second framework introduced by this paper, utilizes agentic AI to help users choose a username for their social media accounts on any platform. It can be easily integrated into any website to provide a better user experience. The PNGT-26K dataset, Nominalist and Open Gender Detection frameworks are publicly available on Github.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Recommender System with Data Valuation for E-commerce Platform</title>
<link>https://arxiv.org/abs/2509.11196</link>
<guid>https://arxiv.org/abs/2509.11196</guid>
<content:encoded><![CDATA[
arXiv:2509.11196v1 Announce Type: new 
Abstract: Federated Learning (FL) is gaining prominence in machine learning as privacy concerns grow. This paradigm allows each client (e.g., an individual online store) to train a recommendation model locally while sharing only model updates, without exposing the raw interaction logs to a central server, thereby preserving privacy in a decentralized environment. Nonetheless, most existing FL-based recommender systems still rely solely on each client's private data, despite the abundance of publicly available datasets that could be leveraged to enrich local training; this potential remains largely underexplored. To this end, we consider a realistic scenario wherein a large shopping platform collaborates with multiple small online stores to build a global recommender system. The platform possesses global data, such as shareable user and item lists, while each store holds a portion of interaction data privately (or locally). Although integrating global data can help mitigate the limitations of sparse and biased clients' local data, it also introduces additional challenges: simply combining all global interactions can amplify noise and irrelevant patterns, worsening personalization and increasing computational costs. To address these challenges, we propose FedGDVE, which selectively augments each client's local graph with semantically aligned samples from the global dataset. FedGDVE employs: (i) a pre-trained graph encoder to extract global structural features, (ii) a local valid predictor to assess client-specific relevance, (iii) a reinforcement-learning-based probability estimator to filter and sample only the most pertinent global interactions. FedGDVE improves performance by up to 34.86% on recognized benchmarks in FL environments.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Web-Based Environment for the Specification and Generation of Smart Legal Contracts</title>
<link>https://arxiv.org/abs/2509.11258</link>
<guid>https://arxiv.org/abs/2509.11258</guid>
<content:encoded><![CDATA[
arXiv:2509.11258v1 Announce Type: new 
Abstract: Monitoring the compliance of contract performance against legal obligations is important in order to detect violations, ideally, as soon as they occur. Such monitoring can nowadays be achieved through the use of smart contracts, which provide protection against tampering as well as some level of automation in handling violations. However, there exists a large gap between natural language contracts and smart contract implementations. This paper introduces a Web-based environment that partly fills that gap by supporting the user-assisted refinement of Symboleo specifications corresponding to legal contract templates, followed by the automated generation of monitoring smart contracts deployable on the Hyperledger Fabric platform. This environment, illustrated using a sample contract from the transactive energy domain, shows much potential in accelerating the development of smart contracts in a legal compliance context.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Incentive-Compatible Reward Sharing Mechanism for Mitigating Mirroring Attacks in Decentralized Data-Feed Systems</title>
<link>https://arxiv.org/abs/2509.11294</link>
<guid>https://arxiv.org/abs/2509.11294</guid>
<content:encoded><![CDATA[
arXiv:2509.11294v1 Announce Type: new 
Abstract: Decentralized data-feed systems enable blockchain-based smart contracts to access off-chain information by aggregating values from multiple oracles. To improve accuracy, these systems typically use an aggregation function, such as majority voting, to consolidate the inputs they receive from oracles and make a decision. Depending on the final decision and the values reported by the oracles, the participating oracles are compensated through shared rewards. However, such incentive mechanisms are vulnerable to mirroring attacks, where a single user controls multiple oracles to bias the decision of the aggregation function and maximize rewards. This paper analyzes the impact of mirroring attacks on the reliability and dependability of majority voting-based data-feed systems. We demonstrate how existing incentive mechanisms can unintentionally encourage rational users to implement such attacks. To address this, we propose a new incentive mechanism that discourages Sybil behavior. We prove that the proposed mechanism leads to a Nash Equilibrium in which each user operates only one oracle. Finally, we discuss the practical implementation of the proposed incentive mechanism and provide numerical examples to demonstrate its effectiveness.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Escaping Efficiency of Distributed Adversarial Training Algorithms</title>
<link>https://arxiv.org/abs/2509.11337</link>
<guid>https://arxiv.org/abs/2509.11337</guid>
<content:encoded><![CDATA[
arXiv:2509.11337v1 Announce Type: new 
Abstract: Adversarial training has been widely studied in recent years due to its role in improving model robustness against adversarial attacks. This paper focuses on comparing different distributed adversarial training algorithms--including centralized and decentralized strategies--within multi-agent learning environments. Previous studies have highlighted the importance of model flatness in determining robustness. To this end, we develop a general theoretical framework to study the escaping efficiency of these algorithms from local minima, which is closely related to the flatness of the resulting models. We show that when the perturbation bound is sufficiently small (i.e., when the attack strength is relatively mild) and a large batch size is used, decentralized adversarial training algorithms--including consensus and diffusion--are guaranteed to escape faster from local minima than the centralized strategy, thereby favoring flatter minima. However, as the perturbation bound increases, this trend may no longer hold. In the simulation results, we illustrate our theoretical findings and systematically compare the performance of models obtained through decentralized and centralized adversarial training algorithms. The results highlight the potential of decentralized strategies to enhance the robustness of models in distributed settings.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Edge Learning for Predictive Maintenance in 6G Small Cell Networks</title>
<link>https://arxiv.org/abs/2509.11421</link>
<guid>https://arxiv.org/abs/2509.11421</guid>
<content:encoded><![CDATA[
arXiv:2509.11421v1 Announce Type: new 
Abstract: The rollout of 6G networks introduces unprecedented demands for autonomy, reliability, and scalability. However, the transmission of sensitive telemetry data to central servers raises concerns about privacy and bandwidth. To address this, we propose a federated edge learning framework for predictive maintenance in 6G small cell networks. The system adopts a Knowledge Defined Networking (KDN) architecture in Data, Knowledge, and Control Planes to support decentralized intelligence, telemetry-driven training, and coordinated policy enforcement. In the proposed model, each base station independently trains a failure prediction model using local telemetry metrics, including SINR, jitter, delay, and transport block size, without sharing raw data. A threshold-based multi-label encoding scheme enables the detection of concurrent fault conditions. We then conduct a comparative analysis of centralized and federated training strategies to evaluate their performance in this context. A realistic simulation environment is implemented using the ns-3 mmWave module, incorporating hybrid user placement and base station fault injection across various deployment scenarios. The learning pipeline is orchestrated via the Flower framework, and model aggregation is performed using the Federated Averaging (FedAvg) algorithm. Experimental results demonstrate that the federated model achieves performance comparable to centralized training in terms of accuracy and per-label precision, while preserving privacy and reducing communication overhead.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media</title>
<link>https://arxiv.org/abs/2509.11444</link>
<guid>https://arxiv.org/abs/2509.11444</guid>
<content:encoded><![CDATA[
arXiv:2509.11444v1 Announce Type: new 
Abstract: The emergence of decentralized social media platforms presents new opportunities and challenges for real-time analysis of public discourse. This study introduces CognitiveSky, an open-source and scalable framework designed for sentiment, emotion, and narrative analysis on Bluesky, a federated Twitter or X.com alternative. By ingesting data through Bluesky's Application Programming Interface (API), CognitiveSky applies transformer-based models to annotate large-scale user-generated content and produces structured and analyzable outputs. These summaries drive a dynamic dashboard that visualizes evolving patterns in emotion, activity, and conversation topics. Built entirely on free-tier infrastructure, CognitiveSky achieves both low operational cost and high accessibility. While demonstrated here for monitoring mental health discourse, its modular design enables applications across domains such as disinformation detection, crisis response, and civic sentiment analysis. By bridging large language models with decentralized networks, CognitiveSky offers a transparent, extensible tool for computational social science in an era of shifting digital ecosystems.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Partitioning techniques for non-centralized predictive control: A systematic review and novel theoretical insights</title>
<link>https://arxiv.org/abs/2509.11470</link>
<guid>https://arxiv.org/abs/2509.11470</guid>
<content:encoded><![CDATA[
arXiv:2509.11470v1 Announce Type: new 
Abstract: The partitioning problem is of central relevance for designing and implementing non-centralized Model Predictive Control (MPC) strategies for large-scale systems. These control approaches include decentralized MPC, distributed MPC, hierarchical MPC, and coalitional MPC. Partitioning a system for the application of non-centralized MPC consists of finding the best definition of the subsystems, and their allocation into groups for the definition of local controllers, to maximize the relevant performance indicators. The present survey proposes a novel systematization of the partitioning approaches in the literature in five main classes: optimization-based, algorithmic, community-detection-based, game-theoretic-oriented, and heuristic approaches. A unified graph-theoretical formalism, a mathematical re-formulation of the problem in terms of mixed-integer programming, the novel concepts of predictive partitioning and multi-topological representations, and a methodological formulation of quality metrics are developed to support the classification and further developments of the field. We analyze the different classes of partitioning techniques, and we present an overview of their strengths and limitations, which include a technical discussion about the different approaches. Representative case studies are discussed to illustrate the application of partitioning techniques for non-centralized MPC in various sectors, including power systems, water networks, wind farms, chemical processes, transportation systems, communication networks, industrial automation, smart buildings, and cyber-physical systems. An outlook of future challenges completes the survey.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dstack: A Zero Trust Framework for Confidential Containers</title>
<link>https://arxiv.org/abs/2509.11555</link>
<guid>https://arxiv.org/abs/2509.11555</guid>
<content:encoded><![CDATA[
arXiv:2509.11555v1 Announce Type: new 
Abstract: Web3 applications require execution platforms that maintain confidentiality and integrity without relying on centralized trust authorities. While Trusted Execution Environments (TEEs) offer promising capabilities for confidential computing, current implementations face significant limitations when applied to Web3 contexts, particularly in security reliability, censorship resistance, and vendor independence.
  This paper presents dstack, a comprehensive framework that transforms raw TEE technology into a true Zero Trust platform. We introduce three key innovations: (1) Portable Confidential Containers that enable seamless workload migration across heterogeneous TEE environments while maintaining security guarantees, (2) Decentralized Code Management that leverages smart contracts for transparent governance of TEE applications, and (3) Verifiable Domain Management that ensures secure and verifiable application identity without centralized authorities.
  These innovations are implemented through three core components: dstack-OS, dstack-KMS, and dstack-Gateway. Together, they demonstrate how to achieve both the performance advantages of VM-level TEE solutions and the trustless guarantees required by Web3 applications. Our evaluation shows that dstack provides comprehensive security guarantees while maintaining practical usability for real-world applications.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Evaluation to Enhancement: Large Language Models for Zero-Knowledge Proof Code Generation</title>
<link>https://arxiv.org/abs/2509.11708</link>
<guid>https://arxiv.org/abs/2509.11708</guid>
<content:encoded><![CDATA[
arXiv:2509.11708v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKPs) are increasingly deployed in domains such as privacy-preserving authentication, blockchain scalability, and secure finance. However, authoring ZK programs remains challenging: unlike mainstream programming, ZK development requires reasoning about finite field arithmetic, constraint systems, and gadgets, making it knowledge-intensive and error-prone. While large language models (LLMs) have demonstrated strong code generation capabilities in general-purpose languages, their effectiveness for ZK programming, where correctness hinges on both language mastery and gadget-level reasoning, remains unexplored. To address this gap, we propose \textsc{ZK-Eval}, a domain-specific evaluation pipeline that probes LLM capabilities at three levels: language knowledge, gadget competence, and end-to-end program generation. Our evaluation of four state-of-the-art LLMs reveals that models excel at surface-level syntax but struggle with gadget usage and semantic correctness, often yielding incorrect programs. Based on these insights, we introduce \textsc{ZK-Coder}, an agentic framework that augments LLMs with constraint sketching, guided retrieval, and interactive repair. Experiments on Circom and Noir show substantial gains, with success rates improving from 17.35\% to 83.38\% and from 32.21\% to 90.05\%, respectively. With \textsc{ZK-Eval} and \textsc{ZK-Coder}, we establish a foundation for systematically measuring and augmenting LLMs in ZK code generation to lower barriers for practitioners and advance trustworthy computation.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Time-Constrained Intelligent Adversaries for Automation Vulnerability Testing: A Multi-Robot Patrol Case Study</title>
<link>https://arxiv.org/abs/2509.11971</link>
<guid>https://arxiv.org/abs/2509.11971</guid>
<content:encoded><![CDATA[
arXiv:2509.11971v1 Announce Type: new 
Abstract: Simulating hostile attacks of physical autonomous systems can be a useful tool to examine their robustness to attack and inform vulnerability-aware design. In this work, we examine this through the lens of multi-robot patrol, by presenting a machine learning-based adversary model that observes robot patrol behavior in order to attempt to gain undetected access to a secure environment within a limited time duration. Such a model allows for evaluation of a patrol system against a realistic potential adversary, offering insight into future patrol strategy design. We show that our new model outperforms existing baselines, thus providing a more stringent test, and examine its performance against multiple leading decentralized multi-robot patrol strategies.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MusicSwarm: Biologically Inspired Intelligence for Music Composition</title>
<link>https://arxiv.org/abs/2509.11973</link>
<guid>https://arxiv.org/abs/2509.11973</guid>
<content:encoded><![CDATA[
arXiv:2509.11973v1 Announce Type: new 
Abstract: We show that coherent, long-form musical composition can emerge from a decentralized swarm of identical, frozen foundation models that coordinate via stigmergic, peer-to-peer signals, without any weight updates. We compare a centralized multi-agent system with a global critic to a fully decentralized swarm in which bar-wise agents sense and deposit harmonic, rhythmic, and structural cues, adapt short-term memory, and reach consensus. Across symbolic, audio, and graph-theoretic analyses, the swarm yields superior quality while delivering greater diversity and structural variety and leads across creativity metrics. The dynamics contract toward a stable configuration of complementary roles, and self-similarity networks reveal a small-world architecture with efficient long-range connectivity and specialized bridging motifs, clarifying how local novelties consolidate into global musical form. By shifting specialization from parameter updates to interaction rules, shared memory, and dynamic consensus, MusicSwarm provides a compute- and data-efficient route to long-horizon creative structure that is immediately transferable beyond music to collaborative writing, design, and scientific discovery.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When MoE Meets Blockchain: A Trustworthy Distributed Framework of Large Models</title>
<link>https://arxiv.org/abs/2509.12141</link>
<guid>https://arxiv.org/abs/2509.12141</guid>
<content:encoded><![CDATA[
arXiv:2509.12141v2 Announce Type: new 
Abstract: As an enabling architecture of Large Models (LMs), Mixture of Experts (MoE) has become prevalent thanks to its sparsely-gated mechanism, which lowers computational overhead while maintaining learning performance comparable to dense LMs. The essence of MoE lies in utilizing a group of neural networks (called experts) with each specializing in different types of tasks, along with a trainable gating network that selectively activates a subset of these experts to handle specific tasks. Traditional cloud-based MoE encounters challenges such as prolonged response latency, high bandwidth consumption, and data privacy leakage. To address these issues, researchers have proposed to deploy MoE over distributed edge networks. However, a key concern of distributed MoE frameworks is the lack of trust in data interactions among distributed experts without the surveillance of any trusted authority, and thereby prone to potential attacks such as data manipulation. In response to the security issues of traditional distributed MoE, we propose a blockchain-aided trustworthy MoE (B-MoE) framework that consists of three layers: the edge layer, the blockchain layer, and the storage layer. In this framework, the edge layer employs the activated experts downloaded from the storage layer to process the learning tasks, while the blockchain layer functions as a decentralized trustworthy network to trace, verify, and record the computational results of the experts from the edge layer. The experimental results demonstrate that B-MoE is more robust to data manipulation attacks than traditional distributed MoE during both the training and inference processes.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>V-ZOR: Enabling Verifiable Cross-Blockchain Communication via Quantum-Driven ZKP Oracle Relays</title>
<link>https://arxiv.org/abs/2509.10996</link>
<guid>https://arxiv.org/abs/2509.10996</guid>
<content:encoded><![CDATA[
arXiv:2509.10996v1 Announce Type: cross 
Abstract: Cross-chain bridges and oracle DAOs represent some of the most vulnerable components of decentralized systems, with more than $2.8 billion lost due to trust failures, opaque validation behavior, and weak incentives. Current oracle designs are based on multisigs, optimistic assumptions, or centralized aggregation, exposing them to attacks and delays. Moreover, predictable committee selection enables manipulation, which threatens data integrity across chains. We propose V-ZOR, a verifiable oracle relay that integrates zero-knowledge proofs, quantum-grade randomness, and cross-chain restaking to mitigate these risks. Each oracle packet includes a Halo 2 proof verifying that the reported data was correctly aggregated using a deterministic median. To prevent committee manipulation, VZOR reseeds its VRF using auditable quantum entropy, ensuring unpredictable and secure selection of reporters. Reporters stake once on a shared restaking hub; any connected chain can submit a fraud proof to trigger slashing, removing the need for multisigs or optimistic assumptions. A prototype in Sepolia and Scroll achieves sub-300k gas verification, one-block latency, and a 10x increase in collusion cost. V-ZOR demonstrates that combining ZK attestation with quantum-randomized restaking enables a trust-minimized, high-performance oracle layer for cross-chain DeFi.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Comparing Model-based Control Strategies for a Quadruple Tank System: Decentralized PID, LMPC, and NMPC</title>
<link>https://arxiv.org/abs/2509.11235</link>
<guid>https://arxiv.org/abs/2509.11235</guid>
<content:encoded><![CDATA[
arXiv:2509.11235v1 Announce Type: cross 
Abstract: This paper compares the performance of a decentralized proportional-integral-derivative (PID) controller, a linear model predictive controller (LMPC), and a nonlinear model predictive controller (NMPC) applied to a quadruple tank system (QTS). We present experimental data from a physical setup of the QTS as well as simulation results. The QTS is modeled as a stochastic nonlinear continuous-discrete-time system, with parameters estimated using a maximum-likelihood prediction-error-method (ML-PEM). The NMPC applies the stochastic nonlinear continuous-discrete-time model, while the LMPC uses a linearized version of the same model. We tune the decentralized PID controller using the simple internal model control (SIMC) rules. The SIMC rules require transfer functions of the process, and we obtain these from the linearized model. We compare the controller performances based on systematic tests using both the physical setup and the simulated QTS. We measure the performance in terms of tracking errors and rate of movement in the manipulated variables. The LMPC and the NMPC perform better than the decentralized PID control system for tracking pre-announced time-varying setpoints. For disturbance rejection, the MPCs perform only slightly better than the decentralized PID controller. The primary advantage of the MPCs is their ability to use the information of future setpoints. We demonstrate this by providing simulation results of the MPCs with and without such information. Finally, the NMPC achieves slightly improved tracking errors compared to the LMPC but at the expense of having a higher input rate of movement.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collusion-Resilience in Transaction Fee Mechanism Design</title>
<link>https://arxiv.org/abs/2402.09321</link>
<guid>https://arxiv.org/abs/2402.09321</guid>
<content:encoded><![CDATA[
arXiv:2402.09321v3 Announce Type: replace 
Abstract: Users bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC'21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum's EIP-1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA'23) considered an alternative notion of collusion-resilience, called $c$-side-contract-proofness ($c$-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and $c$-SCP for any $c\geq 1$. OCA-proofness asserts that the users and a miner should not be able to "steal from the protocol." On the other hand, the $c$-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).
  Our main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness.This result resolves the main open question in Roughgarden (EC'21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mechanism Design for Automated Market Makers</title>
<link>https://arxiv.org/abs/2402.09357</link>
<guid>https://arxiv.org/abs/2402.09357</guid>
<content:encoded><![CDATA[
arXiv:2402.09357v3 Announce Type: replace 
Abstract: Blockchains have popularized automated market makers (AMMs). An AMM exchange is an application running on a blockchain which maintains a pool of crypto-assets and automatically trades assets with users governed by some pricing function that prices the assets based on their relative demand/supply. AMMs have created an important challenge commonly known as the Miner Extractable Value (MEV). In particular, the miners who control the contents and ordering of transactions in a block can extract value by front-running and back-running users' transactions, leading to arbitrage opportunities that guarantee them risk-free returns.
  In this paper, we consider how to design AMM mechanisms that eliminate MEV opportunities. Specifically, we propose a new AMM mechanism that processes all transactions contained within a block in a batch. We show that our new mechanism satisfies two tiers of guarantees. First, for legacy blockchains where each block is proposed by a single (possibly rotating) miner, we prove that our mechanism satisfies arbitrage resilience, i.e., a miner cannot gain risk-free profit. Moreover, we also guarantee fair treatment among all transactions within the same block, such that the miner is unable to sell off favorable positions in the block to users or arbitragers. Second, for blockchains where the block proposal process is decentralized and offers sequencing-fairness, we prove a stronger notion called incentive compatibility -- roughly speaking, we guarantee that any individual user's best response is to follow the honest strategy.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Formal Foundation for Blockchain Rollups</title>
<link>https://arxiv.org/abs/2406.16219</link>
<guid>https://arxiv.org/abs/2406.16219</guid>
<content:encoded><![CDATA[
arXiv:2406.16219v3 Announce Type: replace 
Abstract: Blockchains like Bitcoin and Ethereum have revolutionized digital transactions, yet scalability issues persist. Layer 2 solutions, such as validity proof Rollups (ZK-Rollups), aim to address these challenges by processing transactions off-chain and validating them on the main chain. However, concerns remain about security and censorship resistance, particularly regarding centralized control in Layer 2 and inadequate mechanisms for enforcing these properties through Layer 1 smart contracts. In their current form, L2s are susceptible to multisig attacks that can lead to total user funds loss. This work presents a formal analysis using the Alloy specification language to examine and design key Layer 2 functionalities, including forced transaction queues, safe blacklisting, and upgradeability. Through this analysis, we identify pitfalls in existing designs and introduce an enhanced model that has been model-checked to be correct. Finally, we propose a complete end-to-end methodology to analyze rollups' security and censorship resistance based on manually translating Alloy properties to property-based testing invariants, setting new standards.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Mean Field Social Control: A Unified Reinforcement Learning Framework</title>
<link>https://arxiv.org/abs/2502.20029</link>
<guid>https://arxiv.org/abs/2502.20029</guid>
<content:encoded><![CDATA[
arXiv:2502.20029v2 Announce Type: replace 
Abstract: This paper studies linear quadratic Gaussian robust mean field social control problems in the presence of multiplicative noise. We aim to compute asymptotic decentralized strategies without requiring full prior knowledge of agents' dynamics. The primary challenges lie in solving an indefinite stochastic algebraic Riccati equation for feedback gains, and an indefinite algebraic Riccati equation for feedforward gains. To overcome these challenges, we first propose a unified dual-loop iterative framework that handles both indefinite Riccati-type equations, and provide rigorous convergence proofs for both the outer-loop and inner-loop iterations. Secondly, considering the potential biases arising in the iterative processes due to estimation and modeling errors, we verify the robustness of the proposed algorithm using the small-disturbance input-to-state stability technique. Convergence to a neighborhood of the optimal solution is thus ensured, even in the existence of disturbances. Finally, to relax the limitation of requiring precise knowledge of agents' dynamics, we employ the integral reinforcement learning technique to develop a data-driven method within the dual-loop iterative framework. A numerical example is provided to demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Implicit Barrier from Utility Maximization: Lightweight Interior-Point Methods for Market Equilibrium</title>
<link>https://arxiv.org/abs/2508.04822</link>
<guid>https://arxiv.org/abs/2508.04822</guid>
<content:encoded><![CDATA[
arXiv:2508.04822v2 Announce Type: replace-cross 
Abstract: We study the computation of the market equilibrium in Fisher exchange markets with divisible goods and players endowed with heterogeneous utilities. In particular, we consider the decentralized polynomial-time interior-point strategies that update \emph{only} the prices, mirroring the t\^atonnement process. The key ingredient is the \emph{implicit barrier} inherent from utility maximization, which induces unbounded demand when the goods are almost free of charge. Focusing on a ubiquitous class of utilities, we formalize this observation. A companion result suggests that no additional effort is required for computing high-order derivatives; all the necessary information is readily available when collecting the best responses. To tackle the Newton systems in the interior-point methods, we present an explicitly invertible approximation of the Hessian operator with high probability guarantees, and a scaling matrix that minimizes the condition number of the linear system. Building on these tools, we design two inexact lightweight interior-point methods. One such method has $\cO(\log(\tfrac{1}{\epsilon}))$ complexity rate. Under mild conditions, the other method achieves a non-asymptotic superlinear convergence rate. Preliminary experiments are presented to justify the capability of the proposed methods for large-scale problems. Extensions of our approach are also discussed.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Setchain Algorithms for Blockchain Scalability</title>
<link>https://arxiv.org/abs/2509.09795</link>
<guid>https://arxiv.org/abs/2509.09795</guid>
<content:encoded><![CDATA[
arXiv:2509.09795v1 Announce Type: new 
Abstract: Setchain has been proposed to increase blockchain scalability by relaxing the strict total order requirement among transactions. Setchain organizes elements into a sequence of sets, referred to as epochs, so that elements within each epoch are unordered. In this paper, we propose and evaluate three distinct Setchain algorithms, that leverage an underlying block-based ledger. Vanilla is a basic implementation that serves as a reference point. Compresschain aggregates elements into batches, and compresses these batches before appending them as epochs in the ledger. Hashchain converts batches into fixed-length hashes which are appended as epochs in the ledger. This requires Hashchain to use a distributed service to obtain the batch contents from its hash. To allow light clients to safely interact with only one server, the proposed algorithms maintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the hash of the epoch, cryptographically signed by a server. A client can verify the correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum number of Byzantine servers assumed). All three Setchain algorithms are implemented on top of the CometBFT blockchain application platform. We conducted performance evaluations across various configurations, using clusters of four, seven, and ten servers. Our results show that the Setchain algorithms reach orders of magnitude higher throughput than the underlying blockchain, and achieve finality with latency below 4 seconds.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ordered Consensus with Equal Opportunity</title>
<link>https://arxiv.org/abs/2509.09868</link>
<guid>https://arxiv.org/abs/2509.09868</guid>
<content:encoded><![CDATA[
arXiv:2509.09868v1 Announce Type: new 
Abstract: The specification of state machine replication (SMR) has no requirement on the final total order of commands. In blockchains based on SMR, however, order matters, since different orders could provide their clients with different financial rewards. Ordered consensus augments the specification of SMR to include specific guarantees on such order, with a focus on limiting the influence of Byzantine nodes. Real-world ordering manipulations, however, can and do happen even without Byzantine replicas, typically because of factors, such as faster networks or closer proximity to the blockchain infrastructure, that give some clients an unfair advantage. To address this challenge, this paper proceeds to extend ordered consensus by requiring it to also support equal opportunity, a concrete notion of fairness, widely adopted in social sciences. Informally, equal opportunity requires that two candidates who, according to a set of criteria deemed to be relevant, are equally qualified for a position (in our case, a specific slot in the SMR total order), should have an equal chance of landing it. We show how randomness can be leveraged to keep bias in check, and, to this end, introduce the secret random oracle (SRO), a system component that generates randomness in a fault-tolerant manner. We describe two SRO designs based, respectively, on trusted hardware and threshold verifiable random functions, and instantiate them in Bercow, a new ordered consensus protocol that, by approximating equal opportunity up to within a configurable factor, can effectively mitigate well-known ordering attacks in SMR-based blockchains.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Predictions in Power System Voltage Control: An Adaptive Approach</title>
<link>https://arxiv.org/abs/2509.09937</link>
<guid>https://arxiv.org/abs/2509.09937</guid>
<content:encoded><![CDATA[
arXiv:2509.09937v1 Announce Type: new 
Abstract: High variability of solar PV and sudden changes in load (e.g., electric vehicles and storage) can lead to large voltage fluctuations in the distribution system. In recent years, a number of controllers have been designed to optimize voltage control. These controllers, however, almost always assume that the net load in the system remains constant over a sufficiently long time, such that the control actions converge before the load changes again. Given the intermittent and uncertain nature of renewable resources, it is becoming important to explicitly consider net load that is time-varying.
  This paper proposes an adaptive approach to voltage control in power systems with significant time-varying net load. We leverage advances in short-term load forecasting, where the net load in the system can be partially predicted using local measurements. We integrate these predictions into the design of adaptive controllers, and prove that the overall control architecture achieves input-to-state stability in a decentralized manner. We optimize the control policy through reinforcement learning. Case studies are conducted using time-varying load data from a real-world distribution system.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization</title>
<link>https://arxiv.org/abs/2509.09942</link>
<guid>https://arxiv.org/abs/2509.09942</guid>
<content:encoded><![CDATA[
arXiv:2509.09942v1 Announce Type: new 
Abstract: Smart contracts automate the management of high-value assets, where vulnerabilities can lead to catastrophic financial losses. This challenge is amplified in Large Language Models (LLMs) by two interconnected failures: they operate as unauditable "black boxes" lacking a transparent reasoning process, and consequently, generate code riddled with critical security vulnerabilities. To address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a novel framework for secure and explainable smart contract generation. It begins with Continual Pre-training (CPT) to specialize the model. We then apply Long Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated reasoning-and-code samples to train the model to emulate human security analysis. Finally, to directly mitigate vulnerabilities, we employ Security-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement learning phase that refines the generation policy by optimizing a weighted reward signal for compilation success, security compliance, and format correctness. Evaluated against 17 baselines on a benchmark of 756 real-world functions, SmartCoder-R1 establishes a new state of the art, achieving top performance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a SafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This FullRate marks a 45.79% relative improvement over the strongest baseline, DeepSeek-R1. Crucially, its generated reasoning also excels in human evaluations, achieving high-quality ratings for Functionality (82.7%), Security (85.3%), and Clarity (90.7%).
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection</title>
<link>https://arxiv.org/abs/2509.10041</link>
<guid>https://arxiv.org/abs/2509.10041</guid>
<content:encoded><![CDATA[
arXiv:2509.10041v1 Announce Type: new 
Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model training across decentralized devices, such as smartphones, balancing enhanced predictive performance with the protection of user privacy in sensitive areas like Internet of Things (IoT) and medical data analysis. Despite its advantages, FL encounters significant challenges related to user privacy protection against potential attacks and the management of communication costs. This paper introduces a novel federated learning algorithm called FedRP, which integrates random projection techniques with the Alternating Direction Method of Multipliers (ADMM) optimization framework. This approach enhances privacy by employing random projection to reduce the dimensionality of model parameters prior to their transmission to a central server, reducing the communication cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential privacy guarantee, demonstrating resilience against data reconstruction attacks. Experimental results reveal that FedRP not only maintains high model accuracy but also outperforms existing methods, including conventional differential privacy approaches and FedADMM, in terms of both privacy preservation and communication efficiency.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning</title>
<link>https://arxiv.org/abs/2509.10132</link>
<guid>https://arxiv.org/abs/2509.10132</guid>
<content:encoded><![CDATA[
arXiv:2509.10132v1 Announce Type: new 
Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with decentralized training, enabling the development of personalized and reliable models under data heterogeneity and privacy constraints. Existing approaches typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational inference, often incorporating personalization mechanisms to better adapt to local data distributions. In this work, we propose an information-geometric projection framework for personalization in parametric BFL. By projecting the global model onto a neighborhood of the user's local model, our method enables a tunable trade-off between global generalization and local specialization. Under mild assumptions, we show that this projection step is equivalent to computing a barycenter on the statistical manifold, allowing us to derive closed-form solutions and achieve cost-free personalization. We apply the proposed approach to a variational learning setup using the Improved Variational Online Newton (IVON) optimizer and extend its application to general aggregation schemes in BFL. Empirical evaluations under heterogeneous data distributions confirm that our method effectively balances global and local performance with minimal computational overhead.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks</title>
<link>https://arxiv.org/abs/2509.10163</link>
<guid>https://arxiv.org/abs/2509.10163</guid>
<content:encoded><![CDATA[
arXiv:2509.10163v1 Announce Type: new 
Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge environments, efficient resource management under stringent privacy, mobility, and energy constraints becomes critical. This paper introduces a novel Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that incorporates cross-layer orchestration of both the MAC layer and application layer for energy-efficient, privacy-preserving, and real-time resource management across heterogeneous edge devices. Each agent uses a Deep Recurrent Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum access, and CPU energy adaptation based on local observations (e.g., queue length, energy, CPU usage, and mobility). To protect privacy, we introduce a secure aggregation protocol based on elliptic curve Diffie Hellman key exchange, which ensures accurate model updates without exposing raw data to semi-honest adversaries. We formulate the resource management problem as a partially observable multi-agent Markov decision process (POMMDP) with a multi-objective reward function that jointly optimizes latency, energy efficiency, spectral efficiency, fairness, and reliability under 6G-specific service requirements such as URLLC, eMBB, and mMTC. Simulation results demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines in task success rate, latency, energy efficiency, and fairness, while ensuring robust privacy protection and scalability in dynamic, resource-constrained 6G edge networks.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>XBOF: A Cost-Efficient CXL JBOF with Inter-SSD Compute Resource Sharing</title>
<link>https://arxiv.org/abs/2509.10251</link>
<guid>https://arxiv.org/abs/2509.10251</guid>
<content:encoded><![CDATA[
arXiv:2509.10251v1 Announce Type: new 
Abstract: Enterprise SSDs integrate numerous computing resources (e.g., ARM processor and onboard DRAM) to satisfy the ever-increasing performance requirements of I/O bursts. While these resources substantially elevate the monetary costs of SSDs, the sporadic nature of I/O bursts causes severe SSD resource underutilization in just a bunch of flash (JBOF) level. Tackling this challenge, we propose XBOF, a cost-efficient JBOF design, which only reserves moderate computing resources in SSDs at low monetary cost, while achieving demanded I/O performance through efficient inter-SSD resource sharing. Specifically, XBOF first disaggregates SSD architecture into multiple disjoint parts based on their functionality, enabling fine-grained SSD internal resource management. XBOF then employs a decentralized scheme to manage these disaggregated resources and harvests the computing resources of idle SSDs to assist busy SSDs in handling I/O bursts. This idea is facilitated by the cache-coherent capability of Compute eXpress Link (CXL), with which the busy SSDs can directly utilize the harvested computing resources to accelerate metadata processing. The evaluation results show that XBOF improves SSD resource utilization by 50.4% and saves 19.0% monetary costs with a negligible performance loss, compared to existing JBOF designs.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ExDoS: Expert-Guided Dual-Focus Cross-Modal Distillation for Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2509.10252</link>
<guid>https://arxiv.org/abs/2509.10252</guid>
<content:encoded><![CDATA[
arXiv:2509.10252v1 Announce Type: new 
Abstract: The success of smart contracts has made them a target for attacks, but their closed-source nature often forces vulnerability detection to work on bytecode, which is inherently more challenging than source-code-based analysis. While recent studies try to align source and bytecode embeddings during training to transfer knowledge, current methods rely on graph-level alignment that obscures fine-grained structural and semantic correlations between the two modalities. Moreover, the absence of precise vulnerability patterns and granular annotations in bytecode leads to depriving the model of crucial supervisory signals for learning discriminant features. We propose ExDoS to transfer rich semantic knowledge from source code to bytecode, effectively supplementing the source code prior in practical settings. Specifically, we construct semantic graphs from source code and control-flow graphs from bytecode. To address obscured local signals in graph-level contract embeddings, we propose a Dual-Attention Graph Network introducing a novel node attention aggregation module to enhance local pattern capture in graph embeddings. Furthermore, by summarizing existing source code vulnerability patterns and designing a corresponding set of bytecode-level patterns for each, we construct the first dataset of vulnerability pattern annotations aligned with source code definitions to facilitate fine-grained cross-modal alignment and the capture of function-level vulnerability signals. Finally, we propose a dual-focus objective for our cross-modal distillation framework, comprising: a Global Semantic Distillation Loss for transferring graph-level knowledge and a Local Semantic Distillation Loss enabling expert-guided, fine-grained vulnerability-specific distillation. Experiments on real-world contracts demonstrate that our method achieves consistent F1-score improvements (3\%--6\%) over strong baselines.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case</title>
<link>https://arxiv.org/abs/2509.10291</link>
<guid>https://arxiv.org/abs/2509.10291</guid>
<content:encoded><![CDATA[
arXiv:2509.10291v1 Announce Type: new 
Abstract: In disaster scenarios where conventional energy infrastructure is compromised, secure and traceable energy trading between solar-powered households and mobile charging units becomes a necessity. To ensure the integrity of such transactions over a blockchain network, robust and unpredictable nonce generation is vital. This study proposes an SDN-enabled architecture where machine learning regressors are leveraged not for their accuracy, but for their potential to generate randomized values suitable as nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN allows flexible control over data flows and energy routing policies even in fragmented or degraded networks, ensuring adaptive response during emergencies. Using a 9000-sample dataset, we evaluate five AutoML-selected regression models - Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest Neighbors - not by their prediction accuracy, but by their ability to produce diverse and non-deterministic outputs across shuffled data inputs. Randomness analysis reveals that Random Forest and Extra Trees regressors exhibit complete dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and 99.9%, respectively). These findings highlight that certain machine learning models, particularly tree-based ensembles, may serve as effective and lightweight nonce generators within blockchain-secured, SDN-based energy trading infrastructures resilient to disaster conditions.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bitcoin Cross-Chain Bridge: A Taxonomy and Its Promise in Artificial Intelligence of Things</title>
<link>https://arxiv.org/abs/2509.10413</link>
<guid>https://arxiv.org/abs/2509.10413</guid>
<content:encoded><![CDATA[
arXiv:2509.10413v1 Announce Type: new 
Abstract: Bitcoin's limited scripting capabilities and lack of native interoperability mechanisms have constrained its integration into the broader blockchain ecosystem, especially decentralized finance (DeFi) and multi-chain applications. This paper presents a comprehensive taxonomy of Bitcoin cross-chain bridge protocols, systematically analyzing their trust assumptions, performance characteristics, and applicability to the Artificial Intelligence of Things (AIoT) scenarios. We categorize bridge designs into three main types: naive token swapping, pegged-asset bridges, and arbitrary-message bridges. Each category is evaluated across key metrics such as trust model, latency, capital efficiency, and DeFi composability. Emerging innovations like BitVM and recursive sidechains are highlighted for their potential to enable secure, scalable, and programmable Bitcoin interoperability. Furthermore, we explore practical use cases of cross-chain bridges in AIoT applications, including decentralized energy trading, healthcare data integration, and supply chain automation. This taxonomy provides a foundational framework for researchers and practitioners seeking to design secure and efficient cross-chain infrastructures in AIoT systems.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differentially Private Decentralized Dataset Synthesis Through Randomized Mixing with Correlated Noise</title>
<link>https://arxiv.org/abs/2509.10385</link>
<guid>https://arxiv.org/abs/2509.10385</guid>
<content:encoded><![CDATA[
arXiv:2509.10385v1 Announce Type: cross 
Abstract: In this work, we explore differentially private synthetic data generation in a decentralized-data setting by building on the recently proposed Differentially Private Class-Centric Data Aggregation (DP-CDA). DP-CDA synthesizes data in a centralized setting by mixing multiple randomly-selected samples from the same class and injecting carefully calibrated Gaussian noise, ensuring ({\epsilon}, {\delta})-differential privacy. When deployed in a decentralized or federated setting, where each client holds only a small partition of the data, DP-CDA faces new challenges. The limited sample size per client increases the sensitivity of local computations, requiring higher noise injection to maintain the differential privacy guarantee. This, in turn, leads to a noticeable degradation in the utility compared to the centralized setting. To mitigate this issue, we integrate the Correlation-Assisted Private Estimation (CAPE) protocol into the federated DP-CDA framework and propose CAPE Assisted Federated DP-CDA algorithm. CAPE enables limited collaboration among the clients by allowing them to generate jointly distributed (anti-correlated) noise that cancels out in aggregate, while preserving privacy at the individual level. This technique significantly improves the privacy-utility trade-off in the federated setting. Extensive experiments on MNIST and FashionMNIST datasets demonstrate that the proposed CAPE Assisted Federated DP-CDA approach can achieve utility comparable to its centralized counterpart under some parameter regime, while maintaining rigorous differential privacy guarantees.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research</title>
<link>https://arxiv.org/abs/2410.03855</link>
<guid>https://arxiv.org/abs/2410.03855</guid>
<content:encoded><![CDATA[
arXiv:2410.03855v2 Announce Type: replace 
Abstract: Group fairness in machine learning is an important area of research focused on achieving equitable outcomes across different groups defined by sensitive attributes such as race or gender. Federated Learning, a decentralized approach to training machine learning models across multiple clients, amplifies the need for fairness methodologies due to its inherent heterogeneous data distributions that can exacerbate biases. The intersection of Federated Learning and group fairness has attracted significant interest, with 48 research works specifically dedicated to addressing this issue. However, no comprehensive survey has specifically focused on group fairness in Federated Learning. In this work, we analyze the key challenges of this topic, propose practices for its identification and benchmarking, and create a novel taxonomy based on criteria such as data partitioning, location, and strategy. Furthermore, we analyze broader concerns, review how different approaches handle the complexities of various sensitive attributes, examine common datasets and applications, and discuss the ethical, legal, and policy implications of group fairness in FL. We conclude by highlighting key areas for future research, emphasizing the need for more methods to address the complexities of achieving group fairness in federated systems.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Fair Exchange with Advertising</title>
<link>https://arxiv.org/abs/2503.10411</link>
<guid>https://arxiv.org/abs/2503.10411</guid>
<content:encoded><![CDATA[
arXiv:2503.10411v2 Announce Type: replace 
Abstract: Before a fair exchange takes place, there is typically an advertisement phase with the goal of increasing the appeal of possessing a digital asset while keeping it sufficiently hidden. Advertisement phases are implicit in mainstream definitions, and therefore are not explicitly integrated within fair-exchange protocols. In this work we give an explicit definition for such a fair exchange in a setting where parties communicate via broadcast messages only (i.e., no point-to-point connection between seller and buyer is needed). Next, we construct a fair-exchange protocol satisfying our new definition using zk-SNARKs and relying on mainstream decentralized platforms (i.e., a blockchain with smart contracts like Ethereum and a decentralized storage system like IPFS). Experimental results confirm the practical relevance of our decentralized approach, paving the road towards building decentralized marketplaces where users can, even anonymously, and without direct off-chain communications, effectively advertise and exchange their digital assets as part of a system of enhanced NFTs.
]]></content:encoded>
<pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Local Voltage Control for Active Distribution Networks</title>
<link>https://arxiv.org/abs/2509.09048</link>
<guid>https://arxiv.org/abs/2509.09048</guid>
<content:encoded><![CDATA[
arXiv:2509.09048v1 Announce Type: new 
Abstract: Distribution networks face challenges from the increasing deployment of Distributed Energy Resources (DERs) and the emergence of bidirectional power flows. We propose a decentralized Volt/VAr control method based on a saddle-point reformulation and consensus+innovation (C+I) updates. Each agent at a controllable bus computes and enforces its own set-points using only neighbor communication. Our method embeds passive buses directly, preserves network physics through a linearized Jacobian model, and avoids any supervisory nodes. Simulation results on a modified CIGRE low-voltage network show voltage stability improvement within operational limits, indicating the viability of a fully decentralized (edge-based) Volt/VAr control solution.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Scoping Review of Machine Learning Applications in Power System Protection and Disturbance Management</title>
<link>https://arxiv.org/abs/2509.09053</link>
<guid>https://arxiv.org/abs/2509.09053</guid>
<content:encoded><![CDATA[
arXiv:2509.09053v1 Announce Type: new 
Abstract: The integration of renewable and distributed energy resources reshapes modern power systems, challenging conventional protection schemes. This scoping review synthesizes recent literature on machine learning (ML) applications in power system protection and disturbance management, following the PRISMA for Scoping Reviews framework. Based on over 100 publications, three key objectives are addressed: (i) assessing the scope of ML research in protection tasks; (ii) evaluating ML performance across diverse operational scenarios; and (iii) identifying methods suitable for evolving grid conditions. ML models often demonstrate high accuracy on simulated datasets; however, their performance under real-world conditions remains insufficiently validated. The existing literature is fragmented, with inconsistencies in methodological rigor, dataset quality, and evaluation metrics. This lack of standardization hampers the comparability of results and limits the generalizability of findings. To address these challenges, this review introduces a ML-oriented taxonomy for protection tasks, resolves key terminological inconsistencies, and advocates for standardized reporting practices. It further provides guidelines for comprehensive dataset documentation, methodological transparency, and consistent evaluation protocols, aiming to improve reproducibility and enhance the practical relevance of research outcomes. Critical gaps remain, including the scarcity of real-world validation, insufficient robustness testing, and limited consideration of deployment feasibility. Future research should prioritize public benchmark datasets, realistic validation methods, and advanced ML architectures. These steps are essential to move ML-based protection from theoretical promise to practical deployment in increasingly dynamic and decentralized power systems.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Persuasion Gains and Losses from Peer Communication</title>
<link>https://arxiv.org/abs/2509.09099</link>
<guid>https://arxiv.org/abs/2509.09099</guid>
<content:encoded><![CDATA[
arXiv:2509.09099v1 Announce Type: new 
Abstract: We study a Bayesian persuasion setting in which a sender wants to persuade a critical mass of receivers by revealing partial information about the state to them. The homogeneous binary-action receivers are located on a communication network, and each observes the private messages sent to them and their immediate neighbors. We examine how the sender's expected utility varies with increased communication among receivers. We show that for general families of networks, extending the network can strictly benefit the sender. Thus, the sender's gain from persuasion is not monotonic in network density. Moreover, many network extensions can achieve the upper bound on the sender's expected utility among all networks, which corresponds to the payoff in an empty network. This is the case in networks reflecting a clear informational hierarchy (e.g., in global corporations), as well as in decentralized networks in which information originates from multiple sources (e.g., influencers in social media). Finally, we show that a slight modification to the structure of some of these networks precludes the possibility of such beneficial extensions. Overall, our results caution against presuming that more communication necessarily leads to better collective outcomes.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions</title>
<link>https://arxiv.org/abs/2509.09215</link>
<guid>https://arxiv.org/abs/2509.09215</guid>
<content:encoded><![CDATA[
arXiv:2509.09215v1 Announce Type: new 
Abstract: Large language models (LLMs)-empowered autonomous agents are transforming both digital and physical environments by enabling adaptive, multi-agent collaboration. While these agents offer significant opportunities across domains such as finance, healthcare, and smart manufacturing, their unpredictable behaviors and heterogeneous capabilities pose substantial governance and accountability challenges. In this paper, we propose a blockchain-enabled layered architecture for regulatory agent collaboration, comprising an agent layer, a blockchain data layer, and a regulatory application layer. Within this framework, we design three key modules: (i) an agent behavior tracing and arbitration module for automated accountability, (ii) a dynamic reputation evaluation module for trust assessment in collaborative scenarios, and (iii) a malicious behavior forecasting module for early detection of adversarial activities. Our approach establishes a systematic foundation for trustworthy, resilient, and scalable regulatory mechanisms in large-scale agent ecosystems. Finally, we discuss the future research directions for blockchain-enabled regulatory frameworks in multi-agent systems.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Voltage Synchronization and Proportional Current Sharing of Grid-Forming Inverters</title>
<link>https://arxiv.org/abs/2509.09277</link>
<guid>https://arxiv.org/abs/2509.09277</guid>
<content:encoded><![CDATA[
arXiv:2509.09277v1 Announce Type: new 
Abstract: Most previously proposed controllers are analyzed in the small-signal/quasi-steady regime rather than large-signal or transient stability for grid-forming inverters (GFMI). Additionally, methods that presume system-wide data--global measurements and complete grid-model knowledge--are challenging to realize in practice and unsuitable for large-scale operation. Moreover, proportional current sharing is rarely embedded into them. The whole system is a high-order, nonlinear differential system, making analysis intractable without principled simplifications. Hence, contraction stability analysis in GFMI is proposed to guarantee the large-signal stability. Furthermore, a contraction-based controller is proposed to synchronize GFMI. Additionally, this paper proposes integrating an auxiliary virtual-impedance layer into the contraction-based controller to achieve proportional current sharing, while the GFMI retains global stability and voltage synchronization. A dispatchable virtual oscillator control (dVOC), also known as the Andronov--Hopf oscillator (AHO) is used to validate the proposed contraction stability analysis and contraction-based controller with virtual-impedance. It is proved that the complex multi-converter system can achieve output-feedback contraction under large-signal operation. Therefore, without requiring system-wide data, the proposed method offers voltage synchronization, decentralized stability conditions for the transient stability of AHO and proportional current sharing, beyond prior small-signal, quasi-steady analysis.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning-Based Data-Assisted Port-Hamiltonian Control for Free-Floating Space Manipulators</title>
<link>https://arxiv.org/abs/2509.09563</link>
<guid>https://arxiv.org/abs/2509.09563</guid>
<content:encoded><![CDATA[
arXiv:2509.09563v1 Announce Type: new 
Abstract: A generic data-assisted control architecture within the port-Hamiltonian framework is proposed, introducing a physically meaningful observable that links conservative dynamics to all actuation, dissipation, and disturbance channels. A robust, model-based controller combined with a high-gain decentralized integrator establishes large robustness margins and strict time-scale separation, ensuring that subsequent learning cannot destabilize the primary dynamics. Learning, selected for its generalizability, is then applied to capture complex, unmodeled effects, despite inherent delay and transient error during adaptation. Formal Lyapunov analysis with explicit stability bounds guarantees convergence under bounded learning errors. The structured design confines learning to the simplest part of the dynamics, enhancing data efficiency while preserving physical interpretability. The approach is generic, with a free-floating space manipulator orientation control task, including integrated null-space collision avoidance, serving as a case study to demonstrate robust tracking performance and applicability to broader robotic domains.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Human-in-the-loop Learning Through Decentralized Communication Mechanisms</title>
<link>https://arxiv.org/abs/2509.09574</link>
<guid>https://arxiv.org/abs/2509.09574</guid>
<content:encoded><![CDATA[
arXiv:2509.09574v1 Announce Type: new 
Abstract: Information sharing platforms like TripAdvisor and Waze involve human agents as both information producers and consumers. All these platforms operate in a centralized way to collect agents' latest observations of new options (e.g., restaurants, hotels, travel routes) and share such information with all in real time. However, after hearing the central platforms' live updates, many human agents are found selfish and unwilling to further explore unknown options for the benefit of others in the long run. To regulate the human-in-the-loop learning (HILL) game against selfish agents' free-riding, this paper proposes a paradigm shift from centralized to decentralized way of operation that forces agents' local explorations through restricting information sharing. When game theory meets distributed learning, we formulate our decentralized communication mechanism's design as a new multi-agent Markov decision process (MA-MDP), and derive its analytical condition to outperform today's centralized operation. As the optimal decentralized communication mechanism in MA-MDP is NP-hard to solve, we present an asymptotically optimal algorithm with linear complexity to determine the mechanism's timing of intermittent information sharing. Then we turn to non-myopic agents who may revert to even over-explore, and adapt our mechanism design to work. Simulation experiments using real-world dataset demonstrate the effectiveness of our decentralized mechanisms for various scenarios.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection</title>
<link>https://arxiv.org/abs/2509.09630</link>
<guid>https://arxiv.org/abs/2509.09630</guid>
<content:encoded><![CDATA[
arXiv:2509.09630v1 Announce Type: new 
Abstract: Widespread reuse of open-source code in smart contract development boosts programming efficiency but significantly amplifies bug propagation across contracts, while dedicated methods for detecting similar smart contract functions remain very limited. Conventional abstract-syntax-tree (AST) based methods for smart contract similarity detection face challenges in handling intricate tree structures, which impedes detailed semantic comparison of code. Recent deep-learning based approaches tend to overlook code syntax and detection interpretability, resulting in suboptimal performance.
  To fill this research gap, we introduce SmartDetector, a novel approach for computing similarity between smart contract functions, explainable at the fine-grained statement level. Technically, SmartDetector decomposes the AST of a smart contract function into a series of smaller statement trees, each reflecting a structural element of the source code. Then, SmartDetector uses a classifier to compute the similarity score of two functions by comparing each pair of their statement trees. To address the infinite hyperparameter space of the classifier, we mathematically derive a cosine-wise diffusion process to efficiently search optimal hyperparameters. Extensive experiments conducted on three large real-world datasets demonstrate that SmartDetector outperforms current state-of-the-art methods by an average improvement of 14.01% in F1-score, achieving an overall average F1-score of 95.88%.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Accountable Liveness</title>
<link>https://arxiv.org/abs/2504.12218</link>
<guid>https://arxiv.org/abs/2504.12218</guid>
<content:encoded><![CDATA[
arXiv:2504.12218v2 Announce Type: replace 
Abstract: Safety and liveness are the two classical security properties of consensus protocols. Recent works have strengthened safety with accountability: should any safety violation occur, a sizable fraction of adversary nodes can be proven to be protocol violators. This paper studies to what extent analogous accountability guarantees are achievable for liveness. To reveal the full complexity of this question, we introduce an interpolation between the classical synchronous and partially-synchronous models that we call the $x$-partially-synchronous network model in which, intuitively, at most an $x$ fraction of the time steps in any sufficiently long interval are asynchronous (and, as with a partially-synchronous network, all time steps are synchronous following the passage of an unknown "global stablization time"). We prove a precise characterization of the parameter regime in which accountable liveness is achievable: if and only if $x < 1/2$ and $f < n/2$, where $n$ denotes the number of nodes and $f$ the number of nodes controlled by an adversary. We further refine the problem statement and our analysis by parameterizing by the number of violating nodes identified following a liveness violation, and provide evidence that the guarantees achieved by our protocol are near-optimal (as a function of $x$ and $f$). Our results provide rigorous foundations for liveness-accountability heuristics such as the "inactivity leaks" employed in Ethereum.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimization Methods and Software for Federated Learning</title>
<link>https://arxiv.org/abs/2509.08120</link>
<guid>https://arxiv.org/abs/2509.08120</guid>
<content:encoded><![CDATA[
arXiv:2509.08120v1 Announce Type: new 
Abstract: Federated Learning (FL) is a novel, multidisciplinary Machine Learning paradigm where multiple clients, such as mobile devices, collaborate to solve machine learning problems. Initially introduced in Kone{\v{c}}n{\'y} et al. (2016a,b); McMahan et al. (2017), FL has gained further attention through its inclusion in the National AI Research and Development Strategic Plan (2023 Update) of the United States (Science and on Artificial Intelligence, 2023). The FL training process is inherently decentralized and often takes place in less controlled settings compared to data centers, posing unique challenges distinct from those in fully controlled environments. In this thesis, we identify five key challenges in Federated Learning and propose novel approaches to address them. These challenges arise from the heterogeneity of data and devices, communication issues, and privacy concerns for clients in FL training. Moreover, even well-established theoretical advances in FL require diverse forms of practical implementation to enhance their real-world applicability. Our contributions advance FL algorithms and systems, bridging theoretical advancements and practical implementations. More broadly, our work serves as a guide for researchers navigating the complexities of translating theoretical methods into efficient real-world implementations and software. Additionally, it offers insights into the reverse process of adapting practical implementation aspects back into theoretical algorithm design. This reverse process is particularly intriguing, as the practical perspective compels us to examine the underlying mechanics and flexibilities of algorithms more deeply, often uncovering new dimensions of the algorithms under study.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EnergyNet Explained: Internetification of Energy Distribution</title>
<link>https://arxiv.org/abs/2509.08152</link>
<guid>https://arxiv.org/abs/2509.08152</guid>
<content:encoded><![CDATA[
arXiv:2509.08152v1 Announce Type: new 
Abstract: In developing EnergyNet we have leveraged and are extending lessons from telecom's shift from a centralized, circuit-switched phone system to decentralized, packet-switched data networks. EnergyNet utilizes 1) an Energy Router that enforces galvanic separation and utilizes software-controlled energy flows over a DC backplane, 2) Energy Local and Wide Area Networks (ELAN/EWAN) based on DC microgrids that interconnect through an open Energy Protocol (EP), and 3) a control plane comprised of the Energy Router Operating System (EROS) and EP Server which is managed at operator scale through an Energy Network Management System (ENMS). We distinguish the architectural contribution (Tier-1 including components, interfaces, and operating model) from expected outcomes contingent on adoption (Tier-2). The latter includes local-first autonomy with global interoperability, near-real-time operation with local buffering, removal of EV-charging bottlenecks, freed grid capacity for data centers and industrial electrification, as well as a trend toward low, predictable, fixed-cost clean energy. Evidence from early municipal demonstrators illustrates feasibility and migration paths. The contribution is a coherent, open, and testable blueprint for software-defined, decentralized energy distribution, aligning power-systems engineering with networking principles and offering a practical route from legacy, synchronous grids to resilient, digitally routed energy distribution systems.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strategies for Improving Communication Efficiency in Distributed and Federated Learning: Compression, Local Training, and Personalization</title>
<link>https://arxiv.org/abs/2509.08233</link>
<guid>https://arxiv.org/abs/2509.08233</guid>
<content:encoded><![CDATA[
arXiv:2509.08233v1 Announce Type: new 
Abstract: Distributed and federated learning are essential paradigms for training models across decentralized data sources while preserving privacy, yet communication overhead remains a major bottleneck. This dissertation explores strategies to improve communication efficiency, focusing on model compression, local training, and personalization. We establish a unified framework for biased and unbiased compression operators with convergence guarantees, then propose adaptive local training strategies that incorporate personalization to accelerate convergence and mitigate client drift. In particular, Scafflix balances global and personalized objectives, achieving superior performance under both IID and non-IID settings. We further introduce privacy-preserving pruning frameworks that optimize sparsity while minimizing communication costs, with Cohort-Squeeze leveraging hierarchical aggregation to reduce cross-device overhead. Finally, SymWanda, a symmetric post-training pruning method, enhances robustness under high sparsity and maintains accuracy without retraining. Extensive experiments on benchmarks and large-scale language models demonstrate favorable trade-offs among accuracy, convergence, and communication, offering theoretical and practical insights for scalable, efficient distributed learning.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring Formal Math on the Blockchain: An Explorer for Proofgold</title>
<link>https://arxiv.org/abs/2509.08267</link>
<guid>https://arxiv.org/abs/2509.08267</guid>
<content:encoded><![CDATA[
arXiv:2509.08267v1 Announce Type: new 
Abstract: Proofgold is a blockchain that supports formalized mathematics alongside standard cryptocurrency functionality. It incorporates logical constructs into the blockchain, including declarations of formal theories, definitions, propositions and proofs. It also supports placing and collecting bounties on proving these propositions, incentivizing the development of the formal libraries contained in Proofgold. In this paper, we present a web-based blockchain explorer for Proofgold. The system exposes not only the usual transactional data but also the formal mathematical components embedded in the chain and allows some interaction with them. The explorer allows users to inspect blocks, transactions, and addresses, as well as formal objects: theories, definitions, theorems and their proofs. We also support the submission of transactions to the blockchain using our interface. We describe the system architecture and its integration with the Proofgold Lava software, highlighting how the explorer supports navigation of formal content and facilitates mathematical knowledge management in a decentralized setting, as well as a number of formalizations in category theory done in the system.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Payment Channels with Proofs</title>
<link>https://arxiv.org/abs/2509.08268</link>
<guid>https://arxiv.org/abs/2509.08268</guid>
<content:encoded><![CDATA[
arXiv:2509.08268v1 Announce Type: new 
Abstract: The fundamental building blocks of the Bitcoin lightning network are bidirectional payment channels. We describe an extension of payment channels in the Proofgold network which allow the two parties to bet on whether a proposition will be proven by a certain time. These provide the foundation for a Proofgold lightning network that would allow parties to request proofs (by betting there will be no proof by a certain time) and other parties to provide proofs (and be rewarded by betting there will be a proof). The bets may also provide a way to approximate the probability that a certain proposition is provable (in the given amount of time). We describe the implementation of payment channels supporting proofs in Proofgold and discuss a potential lightning network that could be built as a result. One application of such lightning network would be a large decentralized infrastructure for fast collaborative formalization projects.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution</title>
<link>https://arxiv.org/abs/2509.08364</link>
<guid>https://arxiv.org/abs/2509.08364</guid>
<content:encoded><![CDATA[
arXiv:2509.08364v1 Announce Type: new 
Abstract: The Domain Name System (DNS) serves as the backbone of the Internet, primarily translating domain names to IP addresses. Over time, various enhancements have been introduced to strengthen the integrity of DNS. Among these, DNSSEC stands out as a leading cryptographic solution. It protects against attacks (such as DNS spoofing) by establishing a chain of trust throughout the DNS nameserver hierarchy. However, DNSSEC's effectiveness is compromised when there is a break in this chain, resulting in "Islands of Security", where domains can authenticate locally but not across hierarchical levels, leading to a loss of trust and validation between them. Leading approaches to addressing these issues were centralized, with a single authority maintaining some kind of bulletin board. This approach requires significantly more infrastructure and places excessive trust in the entity responsible for managing it properly. In this paper, we propose a decentralized approach to addressing gaps in DNSSEC's chain of trust, commonly referred to as "Islands of Security". We leverage TLS and IP-based certificates to enable end-to-end authentication between hierarchical levels, eliminating the need for uniform DNSSEC deployment across every level of the DNS hierarchy. This approach enhances the overall integrity of DNSSEC, while reducing dependence on registrars for maintaining signature records to verify the child nameserver's authenticity. By offering a more flexible and efficient solution, our method strengthens DNS security and streamlines deployment across diverse environments.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MIoT-Driven Comparison of Open Blockchain Platforms</title>
<link>https://arxiv.org/abs/2509.08399</link>
<guid>https://arxiv.org/abs/2509.08399</guid>
<content:encoded><![CDATA[
arXiv:2509.08399v1 Announce Type: new 
Abstract: Being propelled by the fourth industrial revolution (Industry 4.0), IoT devices and solutions are well adopted everywhere, ranging from home applications to industrial use, crossing through transportation, healthcare, energy, and so on. This wide use of IoT has not gone unnoticed, hackers are tracking the weakness of such a technology and threatening them continuously. Their security at various levels has become an important concern of professionals and researchers. This issue takes more risk, especially with the IoT variants, IIoT (Industrial IoT) and MIoT (Medical IoT). Many existing security solutions are adapted and proposed for addressing IoT security. In this paper, we are interested in exploring blockchain technology and we make a comparison of three free Blockchain platforms towards their applicability for MIoT context, namely Ethereum, Hyperledger Fabric and Corda. In general, Blockchain technology provides a decentralized, autonomous, trustless, and distributed environment. It is challenging to find a Blockchain platform that fits the MIoT context and performs well in terms of security. The retained platform should be deployed smartly to avoid its practical drawbacks related to energy-consuming and excessive computing.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Blockchain and Proxy Re-Encryption to secure Medical IoT Records</title>
<link>https://arxiv.org/abs/2509.08402</link>
<guid>https://arxiv.org/abs/2509.08402</guid>
<content:encoded><![CDATA[
arXiv:2509.08402v1 Announce Type: new 
Abstract: The integration of the Internet of Things (IoT) in healthcare has revolutionized patient monitoring and data collection, allowing real-time tracking of vital signs, remote diagnostics, and automated medical responses. However, the transmission and storage of sensitive medical data introduce significant security and privacy challenges. To address these concerns, blockchain technology provides a decentralized and immutable ledger that ensures data integrity, , and transparency. Unlike public blockchains, private blockchains are permissioned; the access is granted only to authorized participants; they are more suitable for handling confidential healthcare data. Although blockchain ensures security and trust, it lacks built-in mechanisms to support flexible and controlled data sharing; This is where Proxy Re-Encryption (PRE) comes into play. PRE is a cryptographic technique that allows encrypted data to be re-encrypted for a new recipient without exposing it to intermediaries. We propose an architecture integrating private blockchain and PRE to enable secure, traceable, and privacy-preserving data sharing in IoT-based healthcare systems. Blockchain guarantees tamper proof record-keeping, while PRE enables fine-grained access control, allowing medical professionals to securely share patient data without compromising confidentiality. This combination creates a robust security framework that enhances trust and efficiency in digital healthcare ecosystems.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation</title>
<link>https://arxiv.org/abs/2509.08449</link>
<guid>https://arxiv.org/abs/2509.08449</guid>
<content:encoded><![CDATA[
arXiv:2509.08449v1 Announce Type: new 
Abstract: Federated Learning (FL) enables decentralized model training without sharing raw data, offering strong privacy guarantees. However, existing FL protocols struggle to defend against Byzantine participants, maintain model utility under non-independent and identically distributed (non-IID) data, and remain lightweight for edge devices. Prior work either assumes trusted hardware, uses expensive cryptographic tools, or fails to address privacy and robustness simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated Learning framework that addresses these limitations using a group-based secure aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest servers, DSFL removes this dependency by revealing a key vulnerability: privacy leakage through client-server collusion. DSFL introduces three key innovations: (1) a dual-server secure aggregation protocol that protects updates without encryption or key exchange, (2) a group-wise credit-based filtering mechanism to isolate Byzantine clients based on deviation scores, and (3) a dynamic reward-penalty system for enforcing fair participation. DSFL is evaluated on MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in both IID and non-IID settings. It consistently outperforms existing baselines, including LSFL, homomorphic encryption methods, and differential privacy approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and 68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB communication per round.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Motion-Based User Identification across XR and Metaverse Applications by Deep Classification and Similarity Learning</title>
<link>https://arxiv.org/abs/2509.08539</link>
<guid>https://arxiv.org/abs/2509.08539</guid>
<content:encoded><![CDATA[
arXiv:2509.08539v1 Announce Type: new 
Abstract: This paper examines the generalization capacity of two state-of-the-art classification and similarity learning models in reliably identifying users based on their motions in various Extended Reality (XR) applications. We developed a novel dataset containing a wide range of motion data from 49 users in five different XR applications: four XR games with distinct tasks and action patterns, and an additional social XR application with no predefined task sets. The dataset is used to evaluate the performance and, in particular, the generalization capacity of the two models across applications. Our results indicate that while the models can accurately identify individuals within the same application, their ability to identify users across different XR applications remains limited. Overall, our results provide insight into current models generalization capabilities and suitability as biometric methods for user verification and identification. The results also serve as a much-needed risk assessment of hazardous and unwanted user identification in XR and Metaverse applications. Our cross-application XR motion dataset and code are made available to the public to encourage similar research on the generalization of motion-based user identification in typical Metaverse application use cases.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sharing is Caring: Efficient LM Post-Training with Collective RL Experience Sharing</title>
<link>https://arxiv.org/abs/2509.08721</link>
<guid>https://arxiv.org/abs/2509.08721</guid>
<content:encoded><![CDATA[
arXiv:2509.08721v1 Announce Type: new 
Abstract: Post-training language models (LMs) with reinforcement learning (RL) can enhance their complex reasoning capabilities without supervised fine-tuning, as demonstrated by DeepSeek-R1-Zero. However, effectively utilizing RL for LMs requires significant parallelization to scale-up inference, which introduces non-trivial technical challenges (e.g. latency, memory, and reliability) alongside ever-growing financial costs. We present Swarm sAmpling Policy Optimization (SAPO), a fully decentralized and asynchronous RL post-training algorithm. SAPO is designed for decentralized networks of heterogenous compute nodes, where each node manages its own policy model(s) while "sharing" rollouts with others in the network; no explicit assumptions about latency, model homogeneity, or hardware are required and nodes can operate in silo if desired. As a result, the algorithm avoids common bottlenecks in scaling RL post-training while also allowing (and even encouraging) new possibilities. By sampling rollouts "shared" across the network, it enables "Aha moments" to propagate, thereby bootstrapping the learning process. In this paper we show SAPO achieved cumulative reward gains of up to 94% in controlled experiments. We also share insights from tests on a network with thousands of nodes contributed by Gensyn community members running the algorithm on diverse hardware and models during an open-source demo.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SilentLedger: Privacy-Preserving Auditing for Blockchains with Complete Non-Interactivity</title>
<link>https://arxiv.org/abs/2509.08722</link>
<guid>https://arxiv.org/abs/2509.08722</guid>
<content:encoded><![CDATA[
arXiv:2509.08722v1 Announce Type: new 
Abstract: Privacy-preserving blockchain systems are essential for protecting transaction data, yet they must also provide auditability that enables auditors to recover participant identities and transaction amounts when warranted. Existing designs often compromise the independence of auditing and transactions, introducing extra interactions that undermine usability and scalability. Moreover, many auditable solutions depend on auditors serving as validators or recording nodes, which introduces risks to both data security and system reliability.
  To overcome these challenges, we propose SilentLedger, a privacy-preserving transaction system with auditing and complete non-interactivity. To support public verification of authorization, we introduce a renewable anonymous certificate scheme with formal semantics and a rigorous security model. SilentLedger further employs traceable transaction mechanisms constructed from established cryptographic primitives, enabling users to transact without interaction while allowing auditors to audit solely from on-chain data. We formally prove security properties including authenticity, anonymity, confidentiality, and soundness, provide a concrete instantiation, and evaluate performance under a standard 2-2 transaction model. Our implementation and benchmarks demonstrate that SilentLedger achieves superior performance compared with state-of-the-art solutions.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Stochastic Nonconvex Optimization under the Relaxed Smoothness</title>
<link>https://arxiv.org/abs/2509.08726</link>
<guid>https://arxiv.org/abs/2509.08726</guid>
<content:encoded><![CDATA[
arXiv:2509.08726v1 Announce Type: cross 
Abstract: This paper studies decentralized optimization problem $f(\mathbf{x})=\frac{1}{m}\sum_{i=1}^m f_i(\mathbf{x})$, where each local function has the form of $f_i(\mathbf{x}) = {\mathbb E}\left[F(\mathbf{x};{\xi}_i)\right]$ which is $(L_0,L_1)$-smooth but possibly nonconvex and the random variable ${\xi}_i$ follows distribution ${\mathcal D}_i$. We propose a novel algorithm called decentralized normalized stochastic gradient descent (DNSGD), which can achieve the $\epsilon$-stationary point on each local agent. We present a new framework for analyzing decentralized first-order methods in the relaxed smooth setting, based on the Lyapunov function related to the product of the gradient norm and the consensus error. The analysis shows upper bounds on sample complexity of ${\mathcal O}(m^{-1}(L_f\sigma^2\Delta_f\epsilon^{-4} + \sigma^2\epsilon^{-2} + L_f^{-2}L_1^3\sigma^2\Delta_f\epsilon^{-1} + L_f^{-2}L_1^2\sigma^2))$ per agent and communication complexity of $\tilde{\mathcal O}((L_f\epsilon^{-2} + L_1\epsilon^{-1})\gamma^{-1/2}\Delta_f)$, where $L_f=L_0 +L_1\zeta$, $\sigma^2$ is the variance of the stochastic gradient, $\Delta_f$ is the initial optimal function value gap, $\gamma$ is the spectral gap of the network, and $\zeta$ is the degree of the gradient dissimilarity. In the special case of $L_1=0$, the above results (nearly) match the lower bounds on decentralized nonconvex optimization in the standard smooth setting. We also conduct numerical experiments to show the empirical superiority of our method.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FRESCO: Fast and Reliable Edge Offloading with Reputation-based Hybrid Smart Contracts</title>
<link>https://arxiv.org/abs/2410.06715</link>
<guid>https://arxiv.org/abs/2410.06715</guid>
<content:encoded><![CDATA[
arXiv:2410.06715v3 Announce Type: replace 
Abstract: Mobile devices offload latency-sensitive application tasks to edge servers to satisfy applications' Quality of Service (QoS) deadlines. Consequently, ensuring reliable offloading without QoS violations is challenging in distributed and unreliable edge environments. However, current edge offloading solutions are either centralized or do not adequately address challenges in distributed environments. We propose FRESCO, a fast and reliable edge offloading framework that utilizes a blockchain-based reputation system, which enhances the reliability of offloading in the distributed edge. The distributed reputation system tracks the historical performance of edge servers, while blockchain through a consensus mechanism ensures that sensitive reputation information is secured against tampering. However, blockchain consensus typically has high latency, and therefore we employ a Hybrid Smart Contract (HSC) that automatically computes and stores reputation securely on-chain (i.e., on the blockchain) while allowing fast offloading decisions off-chain (i.e., outside of blockchain). The offloading decision engine uses a reputation score to derive fast offloading decisions, which are based on Satisfiability Modulo Theory (SMT). The SMT models edge resource constraints, and QoS deadlines, and can formally guarantee a feasible solution that is valuable for latency-sensitive applications that require high reliability. With a combination of on-chain HSC reputation state management and an off-chain SMT decision engine, FRESCO offloads tasks to reliable servers without being hindered by blockchain consensus. We evaluate FRESCO against real availability traces and simulated applications. FRESCO reduces response time by up to 7.86 times and saves energy by up to 5.4% compared to all baselines while minimizing QoS violations to 0.4% and achieving an average decision time of 5.05 milliseconds.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FediLoRA: Heterogeneous LoRA for Federated Multimodal Fine-tuning under Missing Modalities</title>
<link>https://arxiv.org/abs/2509.06984</link>
<guid>https://arxiv.org/abs/2509.06984</guid>
<content:encoded><![CDATA[
arXiv:2509.06984v1 Announce Type: new 
Abstract: Foundation models have demonstrated remarkable performance across a wide range of tasks, yet their large parameter sizes pose challenges for practical deployment, especially in decentralized environments. Parameter-efficient fine-tuning (PEFT), such as Low-Rank Adaptation (LoRA), reduces local computing and memory overhead, making it attractive for federated learning. However, existing federated LoRA methods typically assume uniform rank configurations and unimodal inputs, overlooking two key real-world challenges: (1) heterogeneous client resources have different LoRA ranks, and (2) multimodal data settings with potentially missing modalities. In this work, we propose FediLoRA, a simple yet effective framework for federated multimodal fine-tuning under heterogeneous LoRA ranks and missing modalities. FediLoRA introduces a dimension-wise aggregation strategy that reweights LoRA updates without information dilution during aggregation. It also includes a lightweight layer-wise model editing method that selectively incorporates global parameters to repair local components which improves both client and global model performances. Experimental results on three multimodal benchmark datasets demonstrate that FediLoRA achieves superior performance over competitive baselines in both global and personalized settings, particularly in the presence of modality incompleteness.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Security and Privacy of AI Agents for Blockchain</title>
<link>https://arxiv.org/abs/2509.07131</link>
<guid>https://arxiv.org/abs/2509.07131</guid>
<content:encoded><![CDATA[
arXiv:2509.07131v1 Announce Type: new 
Abstract: Blockchain and smart contracts have garnered significant interest in recent years as the foundation of a decentralized, trustless digital ecosystem, thereby eliminating the need for traditional centralized authorities. Despite their central role in powering Web3, their complexity still presents significant barriers for non-expert users. To bridge this gap, Artificial Intelligence (AI)-based agents have emerged as valuable tools for interacting with blockchain environments, supporting a range of tasks, from analyzing on-chain data and optimizing transaction strategies to detecting vulnerabilities within smart contracts. While interest in applying AI to blockchain is growing, the literature still lacks a comprehensive survey that focuses specifically on the intersection with AI agents. Most of the related work only provides general considerations, without focusing on any specific domain. This paper addresses this gap by presenting the first Systematization of Knowledge dedicated to AI-driven systems for blockchain, with a special focus on their security and privacy dimensions, shedding light on their applications, limitations, and future research directions.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Evolutionary Framework for Safe, Efficient, and Cooperative Autonomous Vehicle Interactions</title>
<link>https://arxiv.org/abs/2509.07411</link>
<guid>https://arxiv.org/abs/2509.07411</guid>
<content:encoded><![CDATA[
arXiv:2509.07411v1 Announce Type: new 
Abstract: Modern transportation systems face significant challenges in ensuring road safety, given serious injuries caused by road accidents. The rapid growth of autonomous vehicles (AVs) has prompted new traffic designs that aim to optimize interactions among AVs. However, effective interactions between AVs remains challenging due to the absence of centralized control. Besides, there is a need for balancing multiple factors, including passenger demands and overall traffic efficiency. Traditional rule-based, optimization-based, and game-theoretic approaches each have limitations in addressing these challenges. Rule-based methods struggle with adaptability and generalization in complex scenarios, while optimization-based methods often require high computational resources. Game-theoretic approaches, such as Stackelberg and Nash games, suffer from limited adaptability and potential inefficiencies in cooperative settings. This paper proposes an Evolutionary Game Theory (EGT)-based framework for AV interactions that overcomes these limitations by utilizing a decentralized and adaptive strategy evolution mechanism. A causal evaluation module (CEGT) is introduced to optimize the evolutionary rate, balancing mutation and evolution by learning from historical interactions. Simulation results demonstrate the proposed CEGT outperforms EGT and popular benchmark games in terms of lower collision rates, improved safety distances, higher speeds, and overall better performance compared to Nash and Stackelberg games across diverse scenarios and parameter settings.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dependency-Aware Execution Mechanism in Hyperledger Fabric Architecture</title>
<link>https://arxiv.org/abs/2509.07425</link>
<guid>https://arxiv.org/abs/2509.07425</guid>
<content:encoded><![CDATA[
arXiv:2509.07425v1 Announce Type: new 
Abstract: Hyperledger Fabric is a leading permissioned blockchain framework for enterprise use, known for its modular design and privacy features. While it strongly supports configurable consensus and access control, Fabric can face challenges in achieving high transaction throughput and low rejection rates under heavy workloads. These performance limitations are often attributed to endorsement, ordering, and validation bottlenecks. Further, optimistic concurrency control and deferred validation in Fabric may lead to resource inefficiencies and contention, as conflicting transactions are identified only during the commit phase. To address these challenges, we propose a dependency-aware execution model for Hyperledger Fabric. Our approach includes: (a) a dependency flagging system during endorsement, marking transactions as independent or dependent using a hashmap; (b) an optimized block construction in the ordering service that prioritizes independent transactions; (c) the incorporation of a Directed Acyclic Graph (DAG) within each block to represent dependencies; and (d) parallel execution of independent transactions at the committer, with dependent transactions processed according to DAG order. Incorporated in Hyperledger Fabric v2.5, our framework was tested on workloads with varying dependency levels and system loads. Results show up to 40% higher throughput and significantly reduced rejection rates in high-contention scenarios. This demonstrates that dependency-aware scheduling and DAG-based execution can substantially enhance Fabric's scalability while remaining compatible with its existing consensus and smart contract layers.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DREAMS: Decentralized Resource Allocation and Service Management across the Compute Continuum Using Service Affinity</title>
<link>https://arxiv.org/abs/2509.07497</link>
<guid>https://arxiv.org/abs/2509.07497</guid>
<content:encoded><![CDATA[
arXiv:2509.07497v1 Announce Type: new 
Abstract: Modern manufacturing systems require adaptive computing infrastructures that can respond to highly dynamic workloads and increasingly customized production demands. The compute continuum emerges as a promising solution, enabling flexible deployment of microservices across distributed, heterogeneous domains. However, this paradigm also requires a novel approach to resource allocation and service placement, as traditional centralized solutions struggle to scale effectively, suffer from latency bottlenecks, and introduce single points of failure. In this paper, we present DREAMS, a decentralized framework that optimizes microservice placement decisions collaboratively across different computational domains. At its core, DREAMS introduces agents that operate autonomously within each domain while coordinating globally through a Raft-based consensus algorithm and cost-benefit voting. This decentralized architecture enables responsive, privacy-preserving, and fault-tolerant coordination, making it particularly suitable given the growing prevalence of multi-stakeholder scenarios across the compute continuum. In particular, within modern manufacturing environments, DREAMS achieves globally optimized service placements while maintaining high fault tolerance. Further evaluations demonstrate that key coordination operations, such as Local Domain Manager (LDM) registration and migration voting, scale sub-linearly with the number of domains, confirming the efficiency and scalability of our proposal.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges</title>
<link>https://arxiv.org/abs/2509.07946</link>
<guid>https://arxiv.org/abs/2509.07946</guid>
<content:encoded><![CDATA[
arXiv:2509.07946v1 Announce Type: new 
Abstract: Multi-modal multi-task (M3T) foundation models (FMs) have recently shown transformative potential in artificial intelligence, with emerging applications in education. However, their deployment in real-world educational settings is hindered by privacy regulations, data silos, and limited domain-specific data availability. We introduce M3T Federated Foundation Models (FedFMs) for education: a paradigm that integrates federated learning (FL) with M3T FMs to enable collaborative, privacy-preserving training across decentralized institutions while accommodating diverse modalities and tasks. Subsequently, this position paper aims to unveil M3T FedFMs as a promising yet underexplored approach to the education community, explore its potentials, and reveal its related future research directions. We outline how M3T FedFMs can advance three critical pillars of next-generation intelligent education systems: (i) privacy preservation, by keeping sensitive multi-modal student and institutional data local; (ii) personalization, through modular architectures enabling tailored models for students, instructors, and institutions; and (iii) equity and inclusivity, by facilitating participation from underrepresented and resource-constrained entities. We finally identify various open research challenges, including studying of (i) inter-institution heterogeneous privacy regulations, (ii) the non-uniformity of data modalities' characteristics, (iii) the unlearning approaches for M3T FedFMs, (iv) the continual learning frameworks for M3T FedFMs, and (v) M3T FedFM model interpretability, which must be collectively addressed for practical deployment.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Asynchronous Gossip Algorithms for Rank-Based Statistical Methods</title>
<link>https://arxiv.org/abs/2509.07543</link>
<guid>https://arxiv.org/abs/2509.07543</guid>
<content:encoded><![CDATA[
arXiv:2509.07543v1 Announce Type: cross 
Abstract: As decentralized AI and edge intelligence become increasingly prevalent, ensuring robustness and trustworthiness in such distributed settings has become a critical issue-especially in the presence of corrupted or adversarial data. Traditional decentralized algorithms are vulnerable to data contamination as they typically rely on simple statistics (e.g., means or sum), motivating the need for more robust statistics. In line with recent work on decentralized estimation of trimmed means and ranks, we develop gossip algorithms for computing a broad class of rank-based statistics, including L-statistics and rank statistics-both known for their robustness to outliers. We apply our method to perform robust distributed two-sample hypothesis testing, introducing the first gossip algorithm for Wilcoxon rank-sum tests. We provide rigorous convergence guarantees, including the first convergence rate bound for asynchronous gossip-based rank estimation. We empirically validate our theoretical results through experiments on diverse network topologies.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Online Riemannian Optimization Beyond Hadamard Manifolds</title>
<link>https://arxiv.org/abs/2509.07779</link>
<guid>https://arxiv.org/abs/2509.07779</guid>
<content:encoded><![CDATA[
arXiv:2509.07779v1 Announce Type: cross 
Abstract: We study decentralized online Riemannian optimization over manifolds with possibly positive curvature, going beyond the Hadamard manifold setting. Decentralized optimization techniques rely on a consensus step that is well understood in Euclidean spaces because of their linearity. However, in positively curved Riemannian spaces, a main technical challenge is that geodesic distances may not induce a globally convex structure. In this work, we first analyze a curvature-aware Riemannian consensus step that enables a linear convergence beyond Hadamard manifolds. Building on this step, we establish a $O(\sqrt{T})$ regret bound for the decentralized online Riemannian gradient descent algorithm. Then, we investigate the two-point bandit feedback setup, where we employ computationally efficient gradient estimators using smoothing techniques, and we demonstrate the same $O(\sqrt{T})$ regret bound through the subconvexity analysis of smoothed objectives.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Model-Based Calculation Method of Mining Fairness in Blockchain</title>
<link>https://arxiv.org/abs/2406.00595</link>
<guid>https://arxiv.org/abs/2406.00595</guid>
<content:encoded><![CDATA[
arXiv:2406.00595v3 Announce Type: replace 
Abstract: Mining fairness in blockchain refers to equality between the computational resources invested in mining and the block rewards received. There exists a dilemma wherein increasing the transaction processing capacity of a blockchain compromises mining fairness, thereby undermining its decentralization. This dilemma remains unresolved despite methods such as the greedy heaviest observed subtree (GHOST) protocol, indicating that mining fairness is an inherent bottleneck in the transaction processing capacity of the blockchain system. However, despite its significance, existing analyses neglect the impact of blockchain forks, resulting in imprecise evaluations and limited insights. To address this issue, we propose a method for calculating mining fairness that explicitly captures the influence of forks. First, we approximate a complex blockchain network using a simple mathematical model, assuming that no more than two blocks are generated per round. Within this model, we quantitatively determine local mining fairness and derive several measures of global mining fairness based on local mining fairness. Subsequently, we validated by blockchain network simulations that our calculation method computes mining fairness in networks much more accurately than existing methods. The proposed method facilitates a rigorous evaluation of trade-offs between scalability and decentralization by offering a clear, quantitative framework for measuring and comparing reward distribution among miners. Consequently, it is expected to provide valuable insights for future mining fairness research and the design of next-generation blockchain systems.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AGORA: Open More and Trust Less in Binary Verification Service</title>
<link>https://arxiv.org/abs/2407.15062</link>
<guid>https://arxiv.org/abs/2407.15062</guid>
<content:encoded><![CDATA[
arXiv:2407.15062v2 Announce Type: replace 
Abstract: Binary verification plays a pivotal role in software security, yet building a verification service that is both open and trustworthy poses a formidable challenge. In this paper, we introduce a novel binary verification service, AGORA, scrupulously designed to overcome the challenge. At the heart of this approach lies a strategic insight: certain tasks can be delegated to untrusted entities, while the corresponding validators are securely housed within the trusted computing base (TCB). AGORA can validate untrusted assertions generated for versatile policies. Through a novel blockchain-based bounty task manager, it also utilizes crowdsourcing to remove trust in theorem provers. These synergistic techniques successfully ameliorate the TCB size burden associated with two procedures: binary analysis and theorem proving. The design of AGORA allows untrusted parties to participate in these complex processes. Moreover, based on running the optimized TCB within trusted execution environments and recording the verification process on a blockchain, the public can audit the correctness of verification results. By implementing verification workflows for software-based fault isolation policy and side-channel mitigation, our evaluation demonstrates the efficacy of AGORA.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Knowledge Proofs in Sublinear Space</title>
<link>https://arxiv.org/abs/2509.05326</link>
<guid>https://arxiv.org/abs/2509.05326</guid>
<content:encoded><![CDATA[
arXiv:2509.05326v1 Announce Type: new 
Abstract: Modern zero-knowledge proof (ZKP) systems, essential for privacy and verifiable computation, suffer from a fundamental limitation: the prover typically uses memory that scales linearly with the computation's trace length T, making them impractical for resource-constrained devices and prohibitively expensive for large-scale tasks. This paper overcomes this barrier by constructing, to our knowledge, the first sublinear-space ZKP prover. Our core contribution is an equivalence that reframes proof generation as an instance of the classic Tree Evaluation problem. Leveraging a recent space-efficient tree-evaluation algorithm, we design a streaming prover that assembles the proof without ever materializing the full execution trace. The approach reduces prover memory from linear in T to O(sqrt(T)) (up to O(log T) lower-order terms) while preserving proof size, verifier time, and the transcript/security guarantees of the underlying system. This enables a shift from specialized, server-bound proving to on-device proving, opening applications in decentralized systems, on-device machine learning, and privacy-preserving technologies.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks</title>
<link>https://arxiv.org/abs/2509.05338</link>
<guid>https://arxiv.org/abs/2509.05338</guid>
<content:encoded><![CDATA[
arXiv:2509.05338v1 Announce Type: new 
Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a mobile robot through a network of large language model (LLM) modules. Each module - responsible for sensing, vision, dialogue, or action - operates asynchronously and communicates via natural language, enabling seamless interaction across biological and artificial domains. This architecture leverages the capacity of LLMs to serve as hybrid interfaces, where natural language functions as a universal protocol, translating multimodal data (soil moisture, temperature, visual context) into linguistic messages that coordinate system behaviors. The integrated network transforms plant states into robotic actions, installing normativity essential for agency within the sensor-motor loop. By combining biological and robotic elements through LLM-mediated communication, Plantbot behaves as an embodied, adaptive agent capable of responding autonomously to environmental conditions. This approach suggests possibilities for a new model of artificial life, where decentralized, LLM modules coordination enable novel interactions between biological and artificial systems.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SEASONED: Semantic-Enhanced Self-Counterfactual Explainable Detection of Adversarial Exploiter Contracts</title>
<link>https://arxiv.org/abs/2509.05681</link>
<guid>https://arxiv.org/abs/2509.05681</guid>
<content:encoded><![CDATA[
arXiv:2509.05681v1 Announce Type: new 
Abstract: Decentralized Finance (DeFi) attacks have resulted in significant losses, often orchestrated through Adversarial Exploiter Contracts (AECs) that exploit vulnerabilities in victim smart contracts. To proactively identify such threats, this paper targets the explainable detection of AECs.
  Existing detection methods struggle to capture semantic dependencies and lack interpretability, limiting their effectiveness and leaving critical knowledge gaps in AEC analysis. To address these challenges, we introduce SEASONED, an effective, self-explanatory, and robust framework for AEC detection.
  SEASONED extracts semantic information from contract bytecode to construct a semantic relation graph (SRG), and employs a self-counterfactual explainable detector (SCFED) to classify SRGs and generate explanations that highlight the core attack logic. SCFED further enhances robustness, generalizability, and data efficiency by extracting representative information from these explanations. Both theoretical analysis and experimental results demonstrate the effectiveness of SEASONED, which showcases outstanding detection performance, robustness, generalizability, and data efficiency learning ability. To support further research, we also release a new dataset of 359 AECs.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Larger-scale Nakamoto-style Blockchains Offer Better Security</title>
<link>https://arxiv.org/abs/2509.05708</link>
<guid>https://arxiv.org/abs/2509.05708</guid>
<content:encoded><![CDATA[
arXiv:2509.05708v1 Announce Type: new 
Abstract: Traditional security models for Nakamoto-style blockchains overestimate adversarial coordination by assuming instantaneous synchronization among malicious nodes, neglecting the critical impact of internal communication delays on security. This paper introduces a dual-delay framework to revisit security analysis, addressing this oversight through two key innovations. First, the static delay model quantifies how adversarial communication delays (\(\Delta_a\)) constrain the effective growth rate of private chains, derived via an M/D/1 queuing model as \(\lambda_{eff} = \lambda_a / (1 + \lambda_a \Delta_a)\). This model reveals that the security threshold (\(\beta^*\)), the maximum adversarial power the system tolerates, increases with \(\Delta_a\), even exceeding the classic 51\% boundary when \(\Delta_a \textgreater \Delta\) (honest nodes' delay), breaking the long-standing 50\% assumption. Second, the dynamic delay model integrates probabilistic corruption and scale-dependent delays to characterize the total adversarial delay window (\(\Delta_{total} = \Delta(n) e^{-k\beta} + c \log(1 + \beta n)\)), where \(\Delta(n) \in \Theta(\log n)\) captures honest nodes' logarithmic delay growth. Asymptotic analysis shows adversarial power decays linearly with network scale, ensuring the probability of \(\beta \leq \beta^*\) approaches 1 as \(n \to \infty\). By exposing the interplay between network scale, communication delays, and power dilution, we provide a theoretical foundation for optimizing consensus protocols and assessing robustness in large-scale Nakamoto-style blockchains.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking Robust Aggregation in Decentralized Gradient Marketplaces</title>
<link>https://arxiv.org/abs/2509.05833</link>
<guid>https://arxiv.org/abs/2509.05833</guid>
<content:encoded><![CDATA[
arXiv:2509.05833v1 Announce Type: new 
Abstract: The rise of distributed and privacy-preserving machine learning has sparked interest in decentralized gradient marketplaces, where participants trade intermediate artifacts like gradients. However, existing Federated Learning (FL) benchmarks overlook critical economic and systemic factors unique to such marketplaces-cost-effectiveness, fairness to sellers, and market stability-especially when a buyer relies on a private baseline dataset for evaluation.
  We introduce a comprehensive benchmark framework to holistically evaluate robust gradient aggregation methods within these buyer-baseline-reliant marketplaces. Our contributions include: (1) a simulation environment modeling marketplace dynamics with a variable buyer baseline and diverse seller distributions; (2) an evaluation methodology augmenting standard FL metrics with marketplace-centric dimensions such as Economic Efficiency, Fairness, and Selection Dynamics; (3) an in-depth empirical analysis of the existing Distributed Gradient Marketplace framework, MartFL, including the integration and comparative evaluation of adapted FLTrust and SkyMask as alternative aggregation strategies within it. This benchmark spans diverse datasets, local attacks, and Sybil attacks targeting the marketplace selection process; and (4) actionable insights into the trade-offs between model performance, robustness, cost, fairness, and stability.
  This benchmark equips the community with essential tools and empirical evidence to evaluate and design more robust, equitable, and economically viable decentralized gradient marketplaces.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dataset Ownership in the Era of Large Language Models</title>
<link>https://arxiv.org/abs/2509.05921</link>
<guid>https://arxiv.org/abs/2509.05921</guid>
<content:encoded><![CDATA[
arXiv:2509.05921v1 Announce Type: new 
Abstract: As datasets become critical assets in modern machine learning systems, ensuring robust copyright protection has emerged as an urgent challenge. Traditional legal mechanisms often fail to address the technical complexities of digital data replication and unauthorized use, particularly in opaque or decentralized environments. This survey provides a comprehensive review of technical approaches for dataset copyright protection, systematically categorizing them into three main classes: non-intrusive methods, which detect unauthorized use without modifying data; minimally-intrusive methods, which embed lightweight, reversible changes to enable ownership verification; and maximally-intrusive methods, which apply aggressive data alterations, such as reversible adversarial examples, to enforce usage restrictions. We synthesize key techniques, analyze their strengths and limitations, and highlight open research challenges. This work offers an organized perspective on the current landscape and suggests future directions for developing unified, scalable, and ethically sound solutions to protect datasets in increasingly complex machine learning ecosystems.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VehiclePassport: A GAIA-X-Aligned, Blockchain-Anchored Privacy-Preserving, Zero-Knowledge Digital Passport for Smart Vehicles</title>
<link>https://arxiv.org/abs/2509.06133</link>
<guid>https://arxiv.org/abs/2509.06133</guid>
<content:encoded><![CDATA[
arXiv:2509.06133v1 Announce Type: new 
Abstract: Modern vehicles accumulate fragmented lifecycle records across OEMs, owners, and service centers that are difficult to verify and prone to fraud. We propose VehiclePassport, a GAIA-X-aligned digital passport anchored on blockchain with zero-knowledge proofs (ZKPs) for privacy-preserving verification. VehiclePassport immutably commits to manufacturing, telemetry, and service events while enabling selective disclosure via short-lived JWTs and Groth16 proofs. Our open-source reference stack anchors hashes on Polygon zkEVM at <$0.02 per event, validates proofs in <10 ms, and scales to millions of vehicles. This architecture eliminates paper-based KYC, ensures GDPR-compliant traceability, and establishes a trustless foundation for insurance, resale, and regulatory applications in global mobility data markets.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Secure Sequencer and Data Availability Committee for Rollups (Extended Version)</title>
<link>https://arxiv.org/abs/2509.06614</link>
<guid>https://arxiv.org/abs/2509.06614</guid>
<content:encoded><![CDATA[
arXiv:2509.06614v1 Announce Type: new 
Abstract: Blockchains face a scalability limitation, partly due to the throughput limitations of consensus protocols, especially when aiming to obtain a high degree of decentralization. Layer 2 Rollups (L2s) are a faster alternative to conventional blockchains. L2s perform most computations offchain using minimally blockchains (L1) under-the-hood to guarantee correctness. A sequencer is a service that receives offchain L2 transaction requests, batches these transactions, and commits compressed or hashed batches to L1. Using hashing needs less L1 space, which is beneficial for gas cost, but requires a data availability committee (DAC) service to translate hashes into their corresponding batches of transaction requests. The behavior of sequencers and DACs influence the evolution of the L2 blockchain, presenting a potential security threat and delaying L2 adoption. We propose in this paper fraud-proof mechanisms, arbitrated by L1 contracts, to detect and generate evidence of dishonest behavior of the sequencer and DAC. We study how these fraud-proofs limit the power of adversaries that control different number of sequencer and DACs members, and provide incentives for their honest behavior. We designed these fraud-proof mechanisms as two player games. Unlike the generic fraud-proofs in current L2s (designed to guarantee the correct execution of transactions), our fraud-proofs are over pred-etermined algorithms that verify the properties that determine the correctness of the DAC. Arbitrating over concrete algorithms makes our fraud-proofs more efficient, easier to understand, and simpler to prove correct. We provide as an artifact a mechanization in LEAN4 of our fraud-proof games, including (1) the verified strategies that honest players should play to win all games as well as (2) mechanisms to detect dishonest claims.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mangrove: Fast and Parallelizable State Replication for Blockchains</title>
<link>https://arxiv.org/abs/2509.06616</link>
<guid>https://arxiv.org/abs/2509.06616</guid>
<content:encoded><![CDATA[
arXiv:2509.06616v1 Announce Type: new 
Abstract: Mangrove is a novel scaling approach to building blockchains with parallel smart contract support. Unlike in monolithic blockchains, where a single consensus mechanism determines a strict total order over all transactions, Mangrove uses separate consensus instances per smart contract, without a global order. To allow multiple instances to run in parallel while ensuring that no conflicting transactions are committed, we propose a mechanism called Parallel Optimistic Agreement. Additionally, for simple transactions, we leverage a lightweight Byzantine Reliable Broadcast primitive to reduce latency. Mangrove is optimized for performance under optimistic conditions, where there is no misbehavior and the network is synchronous. Under these conditions, our protocol can achieve a latency of 2 communication steps between creating and executing a transaction.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Network-level Censorship Attacks in the InterPlanetary File System</title>
<link>https://arxiv.org/abs/2509.06626</link>
<guid>https://arxiv.org/abs/2509.06626</guid>
<content:encoded><![CDATA[
arXiv:2509.06626v1 Announce Type: new 
Abstract: The InterPlanetary File System (IPFS) has been successfully established as the de facto standard for decentralized data storage in the emerging Web3. Despite its decentralized nature, IPFS nodes, as well as IPFS content providers, have converged to centralization in large public clouds. Centralization introduces BGP routing-based attacks, such as passive interception and BGP hijacking, as potential threats. Although this attack vector has been investigated for many other Web3 protocols, such as Bitcoin and Ethereum, to the best of our knowledge, it has not been analyzed for the IPFS network. In our work, we bridge this gap and demonstrate that BGP routing attacks can be effectively leveraged to censor content in IPFS. For the analysis, we collected 3,000 content blocks called CIDs and conducted a simulation of BGP hijacking and passive interception against them. We find that a single malicious AS can censor 75% of the IPFS content for more than 57% of all requester nodes. Furthermore, we show that even with a small set of only 62 hijacked prefixes, 70% of the full attack effectiveness can already be reached. We further propose and validate countermeasures based on global collaborative content replication among all nodes in the IPFS network, together with additional robust backup content provider nodes that are well-hardened against BGP hijacking. We hope this work raises awareness about the threat BGP routing-based attacks pose to IPFS and triggers further efforts to harden the live IPFS network against them.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hypergraph Approach to Distributed Broadcast</title>
<link>https://arxiv.org/abs/2404.16376</link>
<guid>https://arxiv.org/abs/2404.16376</guid>
<content:encoded><![CDATA[
arXiv:2404.16376v3 Announce Type: replace 
Abstract: This paper explores the distributed broadcast problem within the context of network communications, a critical challenge in decentralized information dissemination. We put forth a novel hypergraph-based approach to address this issue, focusing on minimizing the number of broadcasts to ensure comprehensive data sharing among all network users. The key contributions of this work include the establishment of a general lower bound for the problem using the min-cut capacity of hypergraphs, and a distributed broadcast for quasi-trees (DBQT) algorithm tailored for the unique structure of quasi-trees, which is proven to be optimal. This paper advances both network communication strategies and hypergraph theory, with implications for a wide range of real-world applications, from vehicular and sensor networks to distributed storage systems.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Architecture Built for Federated Learning: Addressing Data Heterogeneity through Adaptive Normalization-Free Feature Recalibration</title>
<link>https://arxiv.org/abs/2410.02006</link>
<guid>https://arxiv.org/abs/2410.02006</guid>
<content:encoded><![CDATA[
arXiv:2410.02006v2 Announce Type: replace 
Abstract: Federated learning is a decentralized collaborative training paradigm preserving stakeholders' data ownership while improving performance and generalization. However, statistical heterogeneity among client datasets degrades system performance. To address this issue, we propose Adaptive Normalization-free Feature Recalibration (ANFR), a model architecture-level approach that combines weight standardization and channel attention to combat heterogeneous data in FL. ANFR leverages weight standardization to avoid mismatched client statistics and inconsistent averaging, ensuring robustness under heterogeneity, and channel attention to produce learnable scaling factors for feature maps, suppressing inconsistencies across clients due to heterogeneity. We demonstrate that combining these techniques boosts model performance beyond their individual contributions, by improving class selectivity and channel attention weight distribution. ANFR works with any aggregation method, supports both global and personalized FL, and adds minimal overhead. Furthermore, when training with differential privacy, ANFR achieves an appealing balance between privacy and utility, enabling strong privacy guarantees without sacrificing performance. By integrating weight standardization and channel attention in the backbone model, ANFR offers a novel and versatile approach to the challenge of statistical heterogeneity. Extensive experiments show ANFR consistently outperforms established baselines across various aggregation methods, datasets, and heterogeneity conditions. Code is provided at https://github.com/siomvas/ANFR.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>XChainWatcher: Monitoring and Identifying Attacks in Cross-Chain Bridges</title>
<link>https://arxiv.org/abs/2410.02029</link>
<guid>https://arxiv.org/abs/2410.02029</guid>
<content:encoded><![CDATA[
arXiv:2410.02029v3 Announce Type: replace 
Abstract: Cross-chain bridges are a type of middleware for blockchain interoperability that supports the transfer of assets and data across blockchains. However, several of these bridges have vulnerabilities that have caused 3.2 billion dollars in losses since May 2021. Some studies have revealed the existence of these vulnerabilities, but there is little quantitative research available, and there are no safeguard mechanisms to protect bridges from such attacks. Furthermore, no studies are available on the practices of cross-chain bridges that can cause financial losses. We propose \toolName~(Cross-Chain Watcher), a modular and extensible logic-driven anomaly detector for cross-chain bridges. It operates in three main phases: (1) decoding events and transactions from multiple blockchains, (2) building logic relations from the extracted data, and (3) evaluating these relations against a set of detection rules. Using \toolName, we analyze data from two previously attacked bridges: the Ronin and Nomad bridges. \toolName~was able to successfully identify the transactions that led to losses of \$611M and \$190M (USD) and surpassed the results obtained by a reputable security firm in the latter. We not only uncover successful attacks, but also reveal other anomalies, such as 37 cross-chain transactions (\CCTX) that these bridges should not have accepted, failed attempts to exploit Nomad, over \$7.8M worth of tokens locked on one chain but never released on Ethereum, and \$200K lost by users due to inadequate interaction with bridges. We provide the first open dataset of 81,000 \CCTXS~across three blockchains, capturing more than \$4.2B in token transfers.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Six Million (Suspected) Fake Stars in GitHub: A Growing Spiral of Popularity Contests, Spams, and Malware</title>
<link>https://arxiv.org/abs/2412.13459</link>
<guid>https://arxiv.org/abs/2412.13459</guid>
<content:encoded><![CDATA[
arXiv:2412.13459v2 Announce Type: replace 
Abstract: GitHub, the de facto platform for open-source software development, provides a set of social-media-like features to signal high-quality repositories. Among them, the star count is the most widely used popularity signal, but it is also at risk of being artificially inflated (i.e., faked), decreasing its value as a decision-making signal and posing a security risk to all GitHub users. In this paper, we present a systematic, global, and longitudinal measurement study of fake stars in GitHub. To this end, we build StarScout, a scalable tool able to detect anomalous starring behaviors across all GitHub metadata between 2019 and 2024. Analyzing the data collected using StarScout, we find that: (1) fake-star-related activities have rapidly surged in 2024; (2) the accounts and repositories in fake star campaigns have highly trivial activity patterns; (3) the majority of fake stars are used to promote short-lived phishing malware repositories; the remaining ones are mostly used to promote AI/LLM, blockchain, tool/application, and tutorial/demo repositories; (4) while repositories may have acquired fake stars for growth hacking, fake stars only have a promotion effect in the short term (i.e., less than two months) and become a liability in the long term. Our study has implications for platform moderators, open-source practitioners, and supply chain security researchers.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Insecurity Through Obscurity: Veiled Vulnerabilities in Closed-Source Contracts</title>
<link>https://arxiv.org/abs/2504.13398</link>
<guid>https://arxiv.org/abs/2504.13398</guid>
<content:encoded><![CDATA[
arXiv:2504.13398v3 Announce Type: replace 
Abstract: Most blockchains cannot hide the binary code of programs (i.e., smart contracts) running on them. To conceal proprietary business logic and to potentially deter attacks, many smart contracts are closed-source and employ layers of obfuscation. However, we demonstrate that such obfuscation can obscure critical vulnerabilities rather than enhance security, a phenomenon we term insecurity through obscurity. To systematically analyze these risks on a large scale, we present SKANF, a novel EVM bytecode analysis tool tailored for closed-source and obfuscated contracts. SKANF combines control-flow deobfuscation, symbolic execution, and concolic execution based on historical transactions to identify and exploit asset management vulnerabilities. Our evaluation on real-world Maximal Extractable Value (MEV) bots reveals that SKANF detects vulnerabilities in 1,030 contracts and successfully generates exploits for 394 of them, with potential losses of \$10.6M. Additionally, we uncover 104 real-world MEV bot attacks that collectively resulted in \$2.76M in losses.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multimodal Latent Fusion of ECG Leads for Early Assessment of Pulmonary Hypertension</title>
<link>https://arxiv.org/abs/2503.13470</link>
<guid>https://arxiv.org/abs/2503.13470</guid>
<content:encoded><![CDATA[
arXiv:2503.13470v2 Announce Type: replace-cross 
Abstract: Recent advancements in early assessment of pulmonary hypertension (PH) primarily focus on applying machine learning methods to centralized diagnostic modalities, such as 12-lead electrocardiogram (12L-ECG). Despite their potential, these approaches fall short in decentralized clinical settings, e.g., point-of-care and general practice, where handheld 6-lead ECG (6L-ECG) can offer an alternative but is limited by the scarcity of labeled data for developing reliable models. To address this, we propose a lead-specific electrocardiogram multimodal variational autoencoder (\textsc{LS-EMVAE}), which incorporates a hierarchical modality expert (HiME) fusion mechanism and a latent representation alignment loss. HiME combines mixture-of-experts and product-of-experts to enable flexible, adaptive latent fusion, while the alignment loss improves coherence among lead-specific and shared representations. To alleviate data scarcity and enhance representation learning, we adopt a transfer learning strategy: the model is first pre-trained on a large unlabeled 12L-ECG dataset and then fine-tuned on smaller task-specific labeled 6L-ECG datasets. We validate \textsc{LS-EMVAE} across two retrospective cohorts in a 6L-ECG setting: 892 subjects from the ASPIRE registry for (1) PH detection and (2) phenotyping pre-/post-capillary PH, and 16,416 subjects from UK Biobank for (3) predicting elevated pulmonary atrial wedge pressure, where it consistently outperforms unimodal and multimodal baseline methods and demonstrates strong generalizability and interpretability. The code is available at https://github.com/Shef-AIRE/LS-EMVAE.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Network-Aware Differential Privacy</title>
<link>https://arxiv.org/abs/2509.04710</link>
<guid>https://arxiv.org/abs/2509.04710</guid>
<content:encoded><![CDATA[
arXiv:2509.04710v1 Announce Type: new 
Abstract: Differential privacy (DP) is a privacy-enhancement technology (PET) that receives prominent attention from the academia, industry, and government. One main development over the past decade has been the decentralization of DP, including local DP and shuffle DP. Despite that decentralized DP heavily relies on network communications for data collection,we found that: 1) no systematic study has surveyed the research opportunities at the intersection of networking and DP; 2) nor have there been significant efforts to develop DP mechanisms that are explicitly tailored for network environments. In this paper, we seek to address this gap by initiating a new direction of network-aware DP. We identified two focus areas where the network research can offer substantive contributions to the design and deployment of DP, related to network security and topology. Through this work, we hope to encourage more research that adapt/optimize DP's deployment in various network environments.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcing Secure Live Migration through Verifiable State Management</title>
<link>https://arxiv.org/abs/2509.05150</link>
<guid>https://arxiv.org/abs/2509.05150</guid>
<content:encoded><![CDATA[
arXiv:2509.05150v1 Announce Type: new 
Abstract: Live migration of applications is a fundamental capability for enabling resilient computing in modern distributed systems. However, extending this functionality to trusted applications (TA) -- executing within Trusted Execution Environments (TEEs) -- introduces unique challenges such as secure state preservation, integrity verification, replay and rollback prevention, and mitigation of unauthorized cloning of TAs. We present TALOS, a lightweight framework for verifiable state management and trustworthy application migration. While our implementation is prototyped and evaluated using Intel SGX with the Gramine LibOS and RISC-V Keystone (evidencing the framework's portability across diverse TEEs), its design is agnostic to the underlying TEE architecture. Such agility is a necessity in today's network service mesh (collaborative computing across the continuum) where application workloads must be managed across domain boundaries in a harmonized fashion. TALOS is built around the principle of minimizing trust assumptions: TAs are treated as untrusted until explicitly verified, and the migration process does not rely on a trusted third party. To ensure both the integrity and secure launch of the migrated application, TALOS integrates memory introspection and control-flow graph extraction, enabling robust verification of state continuity and execution flow. Thereby achieving strong security guarantees while maintaining efficiency, making it suitable for decentralized settings.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Evaluating the Poisoning Robustness of Federated Learning under Local Differential Privacy</title>
<link>https://arxiv.org/abs/2509.05265</link>
<guid>https://arxiv.org/abs/2509.05265</guid>
<content:encoded><![CDATA[
arXiv:2509.05265v1 Announce Type: new 
Abstract: Federated learning (FL) combined with local differential privacy (LDP) enables privacy-preserving model training across decentralized data sources. However, the decentralized data-management paradigm leaves LDPFL vulnerable to participants with malicious intent. The robustness of LDPFL protocols, particularly against model poisoning attacks (MPA), where adversaries inject malicious updates to disrupt global model convergence, remains insufficiently studied. In this paper, we propose a novel and extensible model poisoning attack framework tailored for LDPFL settings. Our approach is driven by the objective of maximizing the global training loss while adhering to local privacy constraints. To counter robust aggregation mechanisms such as Multi-Krum and trimmed mean, we develop adaptive attacks that embed carefully crafted constraints into a reverse training process, enabling evasion of these defenses. We evaluate our framework across three representative LDPFL protocols, three benchmark datasets, and two types of deep neural networks. Additionally, we investigate the influence of data heterogeneity and privacy budgets on attack effectiveness. Experimental results demonstrate that our adaptive attacks can significantly degrade the performance of the global model, revealing critical vulnerabilities and highlighting the need for more robust LDPFL defense strategies against MPA. Our code is available at https://github.com/ZiJW/LDPFL-Attack
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to accelerate distributed ADMM using graph neural networks</title>
<link>https://arxiv.org/abs/2509.05288</link>
<guid>https://arxiv.org/abs/2509.05288</guid>
<content:encoded><![CDATA[
arXiv:2509.05288v1 Announce Type: new 
Abstract: Distributed optimization is fundamental in large-scale machine learning and control applications. Among existing methods, the Alternating Direction Method of Multipliers (ADMM) has gained popularity due to its strong convergence guarantees and suitability for decentralized computation. However, ADMM often suffers from slow convergence and sensitivity to hyperparameter choices. In this work, we show that distributed ADMM iterations can be naturally represented within the message-passing framework of graph neural networks (GNNs). Building on this connection, we propose to learn adaptive step sizes and communication weights by a graph neural network that predicts the hyperparameters based on the iterates. By unrolling ADMM for a fixed number of iterations, we train the network parameters end-to-end to minimize the final iterates error for a given problem class, while preserving the algorithm's convergence properties. Numerical experiments demonstrate that our learned variant consistently improves convergence speed and solution quality compared to standard ADMM. The code is available at https://github.com/paulhausner/learning-distributed-admm.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph-based Decentralized Task Allocation for Multi-Robot Target Localization</title>
<link>https://arxiv.org/abs/2309.08896</link>
<guid>https://arxiv.org/abs/2309.08896</guid>
<content:encoded><![CDATA[
arXiv:2309.08896v2 Announce Type: replace 
Abstract: We introduce a new graph neural operator-based approach for task allocation in a system of heterogeneous robots composed of Unmanned Ground Vehicles (UGVs) and Unmanned Aerial Vehicles (UAVs). The proposed model, \texttt{\method}, or \textbf{G}raph \textbf{A}ttention \textbf{T}ask \textbf{A}llocato\textbf{R} aggregates information from neighbors in the multi-robot system, with the aim of achieving globally optimal target localization. Being decentralized, our method is highly robust and adaptable to situations where the number of robots and the number of tasks may change over time. We also propose a heterogeneity-aware preprocessing technique to model the heterogeneity of the system. The experimental results demonstrate the effectiveness and scalability of the proposed approach in a range of simulated scenarios generated by varying the number of UGVs and UAVs and the number and location of the targets. We show that a single model can handle a heterogeneous robot team with a number of robots ranging between 2 and 12 while outperforming the baseline architectures.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rolling in the Shadows: Analyzing the Extraction of MEV Across Layer-2 Rollups</title>
<link>https://arxiv.org/abs/2405.00138</link>
<guid>https://arxiv.org/abs/2405.00138</guid>
<content:encoded><![CDATA[
arXiv:2405.00138v3 Announce Type: replace 
Abstract: The emergence of decentralized finance has transformed asset trading on the blockchain, making traditional financial instruments more accessible while also introducing a series of exploitative economic practices known as Maximal Extractable Value (MEV). Concurrently, decentralized finance has embraced rollup-based Layer-2 solutions to facilitate asset trading at reduced transaction costs compared to Layer-1 solutions such as Ethereum. However, rollups lack a public mempool like Ethereum, making the extraction of MEV more challenging. In this paper, we investigate the prevalence and impact of MEV on Ethereum and prominent rollups such as Arbitrum, Optimism, and zkSync over a nearly three-year period. Our analysis encompasses various metrics including volume, profits, costs, competition, and response time to MEV opportunities. We discover that MEV is widespread on rollups, with trading volume comparable to Ethereum. We also find that, although MEV costs are lower on rollups, profits are also significantly lower compared to Ethereum. Additionally, we examine the prevalence of sandwich attacks on rollups. While our findings did not detect any sandwiching activity on popular rollups, we did identify the potential for cross-layer sandwich attacks facilitated by transactions that are sent across rollups and Ethereum. Consequently, we propose and evaluate the feasibility of three novel attacks that exploit cross-layer transactions, revealing that attackers could have already earned approximately 2 million USD through cross-layer sandwich attacks.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Organizing Aerial Swarm Robotics for Resilient Load Transportation : A Table-Mechanics-Inspired Approach</title>
<link>https://arxiv.org/abs/2509.03563</link>
<guid>https://arxiv.org/abs/2509.03563</guid>
<content:encoded><![CDATA[
arXiv:2509.03563v1 Announce Type: new 
Abstract: In comparison with existing approaches, which struggle with scalability, communication dependency, and robustness against dynamic failures, cooperative aerial transportation via robot swarms holds transformative potential for logistics and disaster response. Here, we present a physics-inspired cooperative transportation approach for flying robot swarms that imitates the dissipative mechanics of table-leg load distribution. By developing a decentralized dissipative force model, our approach enables autonomous formation stabilization and adaptive load allocation without the requirement of explicit communication. Based on local neighbor robots and the suspended payload, each robot dynamically adjusts its position. This is similar to energy-dissipating table leg reactions. The stability of the resultant control system is rigorously proved. Simulations demonstrate that the tracking errors of the proposed approach are 20%, 68%, 55.5%, and 21.9% of existing approaches under the cases of capability variation, cable uncertainty, limited vision, and payload variation, respectively. In real-world experiments with six flying robots, the cooperative aerial transportation system achieved a 94% success rate under single-robot failure, disconnection events, 25% payload variation, and 40% cable length uncertainty, demonstrating strong robustness under outdoor winds up to Beaufort scale 4. Overall, this physics-inspired approach bridges swarm intelligence and mechanical stability principles, offering a scalable framework for heterogeneous aerial systems to collectively handle complex transportation tasks in communication-constrained environments.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semi-decentralized Federated Time Series Prediction with Client Availability Budgets</title>
<link>https://arxiv.org/abs/2509.03660</link>
<guid>https://arxiv.org/abs/2509.03660</guid>
<content:encoded><![CDATA[
arXiv:2509.03660v1 Announce Type: new 
Abstract: Federated learning (FL) effectively promotes collaborative training among distributed clients with privacy considerations in the Internet of Things (IoT) scenarios. Despite of data heterogeneity, FL clients may also be constrained by limited energy and availability budgets. Therefore, effective selection of clients participating in training is of vital importance for the convergence of the global model and the balance of client contributions. In this paper, we discuss the performance impact of client availability with time-series data on federated learning. We set up three different scenarios that affect the availability of time-series data and propose FedDeCAB, a novel, semi-decentralized client selection method applying probabilistic rankings of available clients. When a client is disconnected from the server, FedDeCAB allows obtaining partial model parameters from the nearest neighbor clients for joint optimization, improving the performance of offline models and reducing communication overhead. Experiments based on real-world large-scale taxi and vessel trajectory datasets show that FedDeCAB is effective under highly heterogeneous data distribution, limited communication budget, and dynamic client offline or rejoining.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Safety-Critical Control of Resilient DC Microgrids with Large-Signal Stability Guarantees</title>
<link>https://arxiv.org/abs/2509.03789</link>
<guid>https://arxiv.org/abs/2509.03789</guid>
<content:encoded><![CDATA[
arXiv:2509.03789v1 Announce Type: new 
Abstract: The increasing penetration of distributed energy resources and power-electronics interfaces in DC microgrids, coupled with rising cyber threats, necessitates primary controllers that are provably safe, cyber-resilient, and practical. The increasing penetration of distributed energy resources and power-electronics interfaces in DC microgrids, coupled with rising cyber threats, necessitates primary controllers that are provably safe, cyber-resilient, and practical. Conventional droop-based methods remain prevalent due to their simplicity, yet their design is largely empirical and conservative, lacking rigorous guarantees. Advanced strategies improve certain aspects, but often sacrifice scalability, robustness, or formal safety. In this work, we propose a Distributed Safety-Critical Controller (DSCC) that systematically integrates global stabilization with formal safety guarantees in a fully decentralized manner. Leveraging control barrier functions and the port-Hamiltonian system theory, the DSCC achieves scalable safe stabilization while preserving real-time implementability. High-fidelity switched-circuit simulations validate the controller's advantages under various contingencies. This framework paves the way for resilient, safety-critical, and scalable control in next-generation DC microgrids.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2509.03817</link>
<guid>https://arxiv.org/abs/2509.03817</guid>
<content:encoded><![CDATA[
arXiv:2509.03817v1 Announce Type: new 
Abstract: Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agents' internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>KGBERT4Eth: A Feature-Complete Transformer Powered by Knowledge Graph for Multi-Task Ethereum Fraud Detection</title>
<link>https://arxiv.org/abs/2509.03860</link>
<guid>https://arxiv.org/abs/2509.03860</guid>
<content:encoded><![CDATA[
arXiv:2509.03860v1 Announce Type: new 
Abstract: Ethereum's rapid ecosystem expansion and transaction anonymity have triggered a surge in malicious activity. Detection mechanisms currently bifurcate into three technical strands: expert-defined features, graph embeddings, and sequential transaction patterns, collectively spanning the complete feature sets of Ethereum's native data layer. Yet the absence of cross-paradigm integration mechanisms forces practitioners to choose between sacrificing sequential context awareness, structured fund-flow patterns, or human-curated feature insights in their solutions. To bridge this gap, we propose KGBERT4Eth, a feature-complete pre-training encoder that synergistically combines two key components: (1) a Transaction Semantic Extractor, where we train an enhanced Transaction Language Model (TLM) to learn contextual semantic representations from conceptualized transaction records, and (2) a Transaction Knowledge Graph (TKG) that incorporates expert-curated domain knowledge into graph node embeddings to capture fund flow patterns and human-curated feature insights. We jointly optimize pre-training objectives for both components to fuse these complementary features, generating feature-complete embeddings. To emphasize rare anomalous transactions, we design a biased masking prediction task for TLM to focus on statistical outliers, while the Transaction TKG employs link prediction to learn latent transaction relationships and aggregate knowledge. Furthermore, we propose a mask-invariant attention coordination module to ensure stable dynamic information exchange between TLM and TKG during pre-training. KGBERT4Eth significantly outperforms state-of-the-art baselines in both phishing account detection and de-anonymization tasks, achieving absolute F1-score improvements of 8-16% on three phishing detection benchmarks and 6-26% on four de-anonymization datasets.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding</title>
<link>https://arxiv.org/abs/2509.03939</link>
<guid>https://arxiv.org/abs/2509.03939</guid>
<content:encoded><![CDATA[
arXiv:2509.03939v1 Announce Type: new 
Abstract: Current Ethereum fraud detection methods rely on context-independent, numerical transaction sequences, failing to capture semantic of account transactions. Furthermore, the pervasive homogeneity in Ethereum transaction records renders it challenging to learn discriminative account embeddings. Moreover, current self-supervised graph learning methods primarily learn node representations through graph reconstruction, resulting in suboptimal performance for node-level tasks like fraud account detection, while these methods also encounter scalability challenges. To tackle these challenges, we propose LMAE4Eth, a multi-view learning framework that fuses transaction semantics, masked graph embedding, and expert knowledge. We first propose a transaction-token contrastive language model (TxCLM) that transforms context-independent numerical transaction records into logically cohesive linguistic representations. To clearly characterize the semantic differences between accounts, we also use a token-aware contrastive learning pre-training objective together with the masked transaction model pre-training objective, learns high-expressive account representations. We then propose a masked account graph autoencoder (MAGAE) using generative self-supervised learning, which achieves superior node-level account detection by focusing on reconstructing account node features. To enable MAGAE to scale for large-scale training, we propose to integrate layer-neighbor sampling into the graph, which reduces the number of sampled vertices by several times without compromising training quality. Finally, using a cross-attention fusion network, we unify the embeddings of TxCLM and MAGAE to leverage the benefits of both. We evaluate our method against 21 baseline approaches on three datasets. Experimental results show that our method outperforms the best baseline by over 10% in F1-score on two of the datasets.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustworthy Second-hand Marketplace for Built Environment</title>
<link>https://arxiv.org/abs/2509.04085</link>
<guid>https://arxiv.org/abs/2509.04085</guid>
<content:encoded><![CDATA[
arXiv:2509.04085v1 Announce Type: new 
Abstract: The construction industry faces significant challenges regarding material waste and sustainable practices, necessitating innovative solutions that integrate automation, traceability, and decentralised decision-making to enable efficient material reuse. This paper presents a blockchain-enabled digital marketplace for sustainable construction material reuse, ensuring transparency and traceability using InterPlanetary File System (IPFS). The proposed framework enhances trust and accountability in material exchange, addressing key challenges in industrial automation and circular supply chains. A framework has been developed to demonstrate the operational processes of the marketplace, illustrating its practical application and effectiveness. Our contributions show how the marketplace can facilitate the efficient and trustworthy exchange of reusable materials, representing a substantial step towards more sustainable construction practices.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models for Cryptocurrency Transaction Analysis: A Bitcoin Case Study</title>
<link>https://arxiv.org/abs/2501.18158</link>
<guid>https://arxiv.org/abs/2501.18158</guid>
<content:encoded><![CDATA[
arXiv:2501.18158v3 Announce Type: replace 
Abstract: Cryptocurrencies are widely used, yet current methods for analyzing transactions often rely on opaque, black-box models. While these models may achieve high performance, their outputs are usually difficult to interpret and adapt, making it challenging to capture nuanced behavioral patterns. Large language models (LLMs) have the potential to address these gaps, but their capabilities in this area remain largely unexplored, particularly in cybercrime detection. In this paper, we test this hypothesis by applying LLMs to real-world cryptocurrency transaction graphs, with a focus on Bitcoin, one of the most studied and widely adopted blockchain networks. We introduce a three-tiered framework to assess LLM capabilities: foundational metrics, characteristic overview, and contextual interpretation. This includes a new, human-readable graph representation format, LLM4TG, and a connectivity-enhanced transaction graph sampling algorithm, CETraS. Together, they significantly reduce token requirements, transforming the analysis of multiple moderately large-scale transaction graphs with LLMs from nearly impossible to feasible under strict token limits. Experimental results demonstrate that LLMs have outstanding performance on foundational metrics and characteristic overview, where the accuracy of recognizing most basic information at the node level exceeds 98.50% and the proportion of obtaining meaningful characteristics reaches 95.00%. Regarding contextual interpretation, LLMs also demonstrate strong performance in classification tasks, even with very limited labeled data, where top-3 accuracy reaches 72.43% with explanations. While the explanations are not always fully accurate, they highlight the strong potential of LLMs in this domain. At the same time, several limitations persist, which we discuss along with directions for future research.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Elastic Restaking Networks</title>
<link>https://arxiv.org/abs/2503.00170</link>
<guid>https://arxiv.org/abs/2503.00170</guid>
<content:encoded><![CDATA[
arXiv:2503.00170v4 Announce Type: replace 
Abstract: Many blockchain-based decentralized services require their validators (operators) to deposit stake (collateral), which is forfeited (slashed) if they misbehave. Restaking networks let validators secure multiple services by reusing stake. These networks have quickly gained traction, leveraging over \$20 billion in stake. However, restaking introduces a new attack vector where validators can coordinate to misbehave across multiple services simultaneously, extracting digital assets while forfeiting their stake only once.
  Previous work focused either on preventing coordinated misbehavior or on protecting services if all other services are Byzantine and might unjustly cause slashing due to bugs or malice. The first model overlooks how a single Byzantine service can collapse the network, while the second ignores shared-stake benefits.
  To bridge the gap, we analyze the system as a strategic game of coordinated misbehavior, when a given fraction of the services are Byzantine. We introduce elastic restaking networks, where validators can allocate portions of their stake that may cumulatively exceed their total stake, and when allocations are lost, the remaining stake stretches to cover remaining allocations. We show that elastic networks exhibit superior robustness compared to previous approaches, and demonstrate a synergistic effect where an elastic restaking network enhances its blockchain's security, contrary to community concerns of an opposite effect in existing networks. We then design incentives for tuning validators' allocations.
  Our elastic restaking system and incentive design have immediate practical implications for deployed restaking networks.
]]></content:encoded>
<pubDate>Sat, 06 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection</title>
<link>https://arxiv.org/abs/2509.02579</link>
<guid>https://arxiv.org/abs/2509.02579</guid>
<content:encoded><![CDATA[
arXiv:2509.02579v1 Announce Type: new 
Abstract: Protecting endangered wildlife from illegal poaching presents a critical challenge, particularly in vast and partially observable environments where real-time response is essential. This paper introduces a novel Expectation-Maximization (EM) based latent variable modeling approach in the context of Multi-Agent Reinforcement Learning (MARL) for Unmanned Aerial Vehicle (UAV) coordination in wildlife protection. By modeling hidden environmental factors and inter-agent dynamics through latent variables, our method enhances exploration and coordination under uncertainty.We implement and evaluate our EM-MARL framework using a custom simulation involving 10 UAVs tasked with patrolling protected habitats of the endangered Iranian leopard. Extensive experimental results demonstrate superior performance in detection accuracy, adaptability, and policy convergence when compared to standard algorithms such as Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG). Our findings underscore the potential of combining EM inference with MARL to improve decentralized decisionmaking in complex, high-stakes conservation scenarios. The full implementation, simulation environment, and training scripts are publicly available on GitHub.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems</title>
<link>https://arxiv.org/abs/2509.02860</link>
<guid>https://arxiv.org/abs/2509.02860</guid>
<content:encoded><![CDATA[
arXiv:2509.02860v1 Announce Type: new 
Abstract: Microservice systems are becoming increasingly adopted due to their scalability, decentralized development, and support for continuous integration and delivery (CI/CD). However, this decentralized development by separate teams and continuous evolution can introduce miscommunication and incompatible implementations, undermining system maintainability and reliability across aspects from security policy to system architecture. We propose a novel methodology that statically reconstructs microservice source code into a formal system model. From this model, a Satisfiability Modulo Theories (SMT) constraint set can be derived, enabling formal verification. Our methodology is extensible, supporting software verification across multiple cross-cutting concerns. We focus on applying the methodology to verify the system architecture concern, presenting formal reasoning to validate the methodology's correctness and applicability for this concern. Additional concerns such as security policy implementation are considered. Future directions are established to extend and evaluate the methodology.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Power Grid Control with Graph-Based Distributed Reinforcement Learning</title>
<link>https://arxiv.org/abs/2509.02861</link>
<guid>https://arxiv.org/abs/2509.02861</guid>
<content:encoded><![CDATA[
arXiv:2509.02861v1 Announce Type: new 
Abstract: The necessary integration of renewable energy sources, combined with the expanding scale of power networks, presents significant challenges in controlling modern power grids. Traditional control systems, which are human and optimization-based, struggle to adapt and to scale in such an evolving context, motivating the exploration of more dynamic and distributed control strategies. This work advances a graph-based distributed reinforcement learning framework for real-time, scalable grid management. The proposed architecture consists of a network of distributed low-level agents acting on individual power lines and coordinated by a high-level manager agent. A Graph Neural Network (GNN) is employed to encode the network's topological information within the single low-level agent's observation. To accelerate convergence and enhance learning stability, the framework integrates imitation learning and potential-based reward shaping. In contrast to conventional decentralized approaches that decompose only the action space while relying on global observations, this method also decomposes the observation space. Each low-level agent acts based on a structured and informative local view of the environment constructed through the GNN. Experiments on the Grid2Op simulation environment show the effectiveness of the approach, which consistently outperforms the standard baseline commonly adopted in the field. Additionally, the proposed model proves to be much more computationally efficient than the simulation-based Expert method.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum</title>
<link>https://arxiv.org/abs/2509.03037</link>
<guid>https://arxiv.org/abs/2509.03037</guid>
<content:encoded><![CDATA[
arXiv:2509.03037v1 Announce Type: new 
Abstract: Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet comprehensive security analysis remains difficult due to unverified code, proxy-based architectures, and the reliance on manual inspection of complex execution traces. Existing approaches fall into two main categories: anomaly transaction detection, which flags suspicious transactions but offers limited insight into specific attack strategies hidden in execution traces inside transactions, and code vulnerability detection, which cannot analyze unverified contracts and struggles to show how identified flaws are exploited in real incidents. As a result, analysts must still manually align transaction traces with contract code to reconstruct attack scenarios and conduct forensics. To address this gap, TraceLLM is proposed as a framework that leverages LLMs to integrate execution trace-level detection with decompiled contract code. We introduce a new anomaly execution path identification algorithm and an LLM-refined decompile tool to identify vulnerable functions and provide explicit attack paths to LLM. TraceLLM establishes the first benchmark for joint trace and contract code-driven security analysis. For comparison, proxy baselines are created by jointly transmitting the results of three representative code analysis along with raw traces to LLM. TraceLLM identifies attacker and victim addresses with 85.19\% precision and produces automated reports with 70.37\% factual precision across 27 cases with ground truth expert reports, achieving 25.93\% higher accuracy than the best baseline. Moreover, across 148 real-world Ethereum incidents, TraceLLM automatically generates reports with 66.22\% expert-verified accuracy, demonstrating strong generalizability.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralised self-organisation of pivoting cube ensembles using geometric deep learning</title>
<link>https://arxiv.org/abs/2509.03140</link>
<guid>https://arxiv.org/abs/2509.03140</guid>
<content:encoded><![CDATA[
arXiv:2509.03140v1 Announce Type: new 
Abstract: We present a decentralized model for autonomous reconfiguration of homogeneous pivoting cube modular robots in two dimensions. Each cube in the ensemble is controlled by a neural network that only gains information from other cubes in its local neighborhood, trained using reinforcement learning. Furthermore, using geometric deep learning, we include the grid symmetries of the cube ensemble in the neural network architecture. We find that even the most localized versions succeed in reconfiguring to the target shape, although reconfiguration happens faster the more information about the whole ensemble is available to individual cubes. Near-optimal reconfiguration is achieved with only nearest neighbor interactions by using multiple information passing between cubes, allowing them to accumulate more global information about the ensemble. Compared to standard neural network architectures, using geometric deep learning approaches provided only minor benefits. Overall, we successfully demonstrate mostly local control of a modular self-assembling system, which is transferable to other space-relevant systems with different action spaces, such as sliding cube modular robots and CubeSat swarms.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling</title>
<link>https://arxiv.org/abs/2509.03260</link>
<guid>https://arxiv.org/abs/2509.03260</guid>
<content:encoded><![CDATA[
arXiv:2509.03260v1 Announce Type: new 
Abstract: Abnormal cryptocurrency transactions - such as mixing services, fraudulent transfers, and pump-and-dump operations -- pose escalating risks to financial integrity but remain notoriously difficult to detect due to class imbalance, temporal volatility, and complex network dependencies. Existing approaches are predominantly model-centric and post hoc, flagging anomalies only after they occur and thus offering limited preventive value. This paper introduces HyPV-LEAD (Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection), a data-driven early-warning framework that explicitly incorporates lead time into anomaly detection. Unlike prior methods, HyPV-LEAD integrates three innovations: (1) window-horizon modeling to guarantee actionable lead-time alerts, (2) Peak-Valley (PV) sampling to mitigate class imbalance while preserving temporal continuity, and (3) hyperbolic embedding to capture the hierarchical and scale-free properties of blockchain transaction networks. Empirical evaluation on large-scale Bitcoin transaction data demonstrates that HyPV-LEAD consistently outperforms state-of-the-art baselines, achieving a PR-AUC of 0.9624 with significant gains in precision and recall. Ablation studies further confirm that each component - PV sampling, hyperbolic embedding, and structural-temporal modeling - provides complementary benefits, with the full framework delivering the highest performance. By shifting anomaly detection from reactive classification to proactive early-warning, HyPV-LEAD establishes a robust foundation for real-time risk management, anti-money laundering (AML) compliance, and financial security in dynamic blockchain environments.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tuning Block Size for Workload Optimization in Consortium Blockchain Networks</title>
<link>https://arxiv.org/abs/2509.03367</link>
<guid>https://arxiv.org/abs/2509.03367</guid>
<content:encoded><![CDATA[
arXiv:2509.03367v1 Announce Type: new 
Abstract: Determining the optimal block size is crucial for achieving high throughput in blockchain systems. Many studies have focused on tuning various components, such as databases, network bandwidth, and consensus mechanisms. However, the impact of block size on system performance remains a topic of debate, often resulting in divergent views and even leading to new forks in blockchain networks. This research proposes a mathematical model to maximize performance by determining the ideal block size for Hyperledger Fabric, a prominent consortium blockchain. By leveraging machine learning and solving the model with a genetic algorithm, the proposed approach assesses how factors such as block size, transaction size, and network capacity influence the block processing time. The integration of an optimization solver enables precise adjustments to block size configuration before deployment, ensuring improved performance from the outset. This systematic approach aims to balance block processing efficiency, network latency, and system throughput, offering a robust solution to improve blockchain performance across diverse business contexts.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration</title>
<link>https://arxiv.org/abs/2410.15048</link>
<guid>https://arxiv.org/abs/2410.15048</guid>
<content:encoded><![CDATA[
arXiv:2410.15048v2 Announce Type: replace 
Abstract: Large Language Model (LLM) based multi-agent systems (MAS) have shown promise in tackling complex tasks, but often rely on predefined roles and centralized coordination, limiting their adaptability to evolving challenges. This paper introduces MorphAgent, a novel Autonomous, Self-Organizing, and Self-Adaptive Multi-Agent System for decentralized agent collaboration that enables agents to dynamically evolve their roles and capabilities. Our approach employs self-evolving agent profiles, optimized through three key metrics, guiding agents in refining their individual expertise while maintaining complementary team dynamics. MorphAgent implements a two-phase process: a Profile Update phase for profile optimization, followed by a Task Execution phase where agents continuously adapt their roles based on task feedback. Our experimental results show that MorphAgent outperforms existing frameworks in terms of task performance and adaptability to changing requirements, paving the way for more robust and versatile multi-agent collaborative systems.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedP$^2$EFT: Federated Learning to Personalize PEFT for Multilingual LLMs</title>
<link>https://arxiv.org/abs/2502.04387</link>
<guid>https://arxiv.org/abs/2502.04387</guid>
<content:encoded><![CDATA[
arXiv:2502.04387v2 Announce Type: replace 
Abstract: Federated learning (FL) has enabled the training of multilingual large language models (LLMs) on diverse and decentralized multilingual data, especially on low-resource languages. To improve client-specific performance, personalization via the use of parameter-efficient fine-tuning (PEFT) modules such as LoRA is common. This involves a personalization strategy (PS), such as the design of the PEFT adapter structures (e.g., in which layers to add LoRAs and what ranks) and choice of hyperparameters (e.g., learning rates) for fine-tuning. Instead of manual PS configuration, we propose FedP$^2$EFT, a federated learning-to-personalize method for multilingual LLMs in cross-device FL settings. Unlike most existing PEFT structure selection methods, which are prone to overfitting low-data regimes, FedP$^2$EFT collaboratively learns the optimal personalized PEFT structure for each client via Bayesian sparse rank selection. Evaluations on both simulated and real-world multilingual FL benchmarks demonstrate that FedP$^2$EFT largely outperforms existing personalized fine-tuning methods, while complementing other existing FL methods. Code is available at https://github.com/SamsungLabs/fedp2eft.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation</title>
<link>https://arxiv.org/abs/2506.07940</link>
<guid>https://arxiv.org/abs/2506.07940</guid>
<content:encoded><![CDATA[
arXiv:2506.07940v2 Announce Type: replace 
Abstract: Current AutoML platforms leave substantial performance untapped. Testing 180 fine-tuning tasks across models from 70M to 70B parameters, we found that HuggingFace AutoTrain, TogetherAI, Databricks, and Google Cloud consistently produce suboptimal configurations. Gradients, built on the Bittensor network, attacks this problem through competition. Independent miners race to find optimal hyperparameters, earning rewards proportional to their models' performance. This tournament drives exploration of configuration spaces that single-strategy methods never examine. In our experiments, Gradients achieved a 100\% win rate against TogetherAI, Databricks, and Google Cloud, and beat HuggingFace AutoTrain in 82.8\% of experiments. Mean improvements reached 42.1\% against commercial platforms. Retrieval-augmented generation tasks saw 30-40\% gains; diffusion models improved 23.4\% on person-specific generation. When miners compete for rewards, they develop optimization strategies that centralized approaches overlook. These findings demonstrate that decentralized systems with economic incentives can systematically outperform traditional AutoML, suggesting market dynamics may be key to achieving superior fine-tuning results. Code is available at https://github.com/rayonlabs/G.O.D.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Agentic AI on Particle Accelerators</title>
<link>https://arxiv.org/abs/2409.06336</link>
<guid>https://arxiv.org/abs/2409.06336</guid>
<content:encoded><![CDATA[
arXiv:2409.06336v4 Announce Type: replace-cross 
Abstract: As particle accelerators grow in complexity, traditional control methods face increasing challenges in achieving optimal performance. This paper envisions a paradigm shift: a decentralized multi-agent framework for accelerator control, powered by Large Language Models (LLMs) and distributed among autonomous agents. We present a proposition of a self-improving decentralized system where intelligent agents handle high-level tasks and communication and each agent is specialized to control individual accelerator components.
  This approach raises some questions: What are the future applications of AI in particle accelerators? How can we implement an autonomous complex system such as a particle accelerator where agents gradually improve through experience and human feedback? What are the implications of integrating a human-in-the-loop component for labeling operational data and providing expert guidance? We show three examples, where we demonstrate the viability of such architecture.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BPI: A Novel Efficient and Reliable Search Structure for Hybrid Storage Blockchain</title>
<link>https://arxiv.org/abs/2509.00480</link>
<guid>https://arxiv.org/abs/2509.00480</guid>
<content:encoded><![CDATA[
arXiv:2509.00480v1 Announce Type: new 
Abstract: Hybrid storage solutions have emerged as potent strategies to alleviate the data storage bottlenecks prevalent in blockchain systems. These solutions harness off-chain Storage Services Providers (SPs) in conjunction with Authenticated Data Structures (ADS) to ensure data integrity and accuracy. Despite these advancements, the reliance on centralized SPs raises concerns about query correctness. Although ADS can verify the existence of individual query results, they fall short of preventing SPs from omitting valid results.
  In this paper, we delineate the fundamental distinctions between data search in blockchains and traditional database systems. Drawing upon these insights, we introduce BPI, a lightweight framework that enables efficient keyword queries and maintenance with low overhead. We propose "Articulated Search", a query pattern specifically designed for blockchain environments that enhances search efficiency while significantly reducing costs during data user updates. Furthermore, BPI employs a suite of validation models to ensure the inclusion of all valid content in search results while maintaining low overhead.
  Extensive experimental evaluations demonstrate that the BPI framework achieves outstanding scalability and performance in keyword searches within blockchain, surpassing EthMB+ and state of the art search databases commonly used in mainstream hybrid storage blockchains (HSB).
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FLEET: A Federated Learning Emulation and Evaluation Testbed for Holistic Research</title>
<link>https://arxiv.org/abs/2509.00621</link>
<guid>https://arxiv.org/abs/2509.00621</guid>
<content:encoded><![CDATA[
arXiv:2509.00621v1 Announce Type: new 
Abstract: Federated Learning (FL) presents a robust paradigm for privacy-preserving, decentralized machine learning. However, a significant gap persists between the theoretical design of FL algorithms and their practical performance, largely because existing evaluation tools often fail to model realistic operational conditions. Many testbeds oversimplify the critical dynamics among algorithmic efficiency, client-level heterogeneity, and continuously evolving network infrastructure. To address this challenge, we introduce the Federated Learning Emulation and Evaluation Testbed (FLEET). This comprehensive platform provides a scalable and configurable environment by integrating a versatile, framework-agnostic learning component with a high-fidelity network emulator. FLEET supports diverse machine learning frameworks, customizable real-world network topologies, and dynamic background traffic generation. The testbed collects holistic metrics that correlate algorithmic outcomes with detailed network statistics. By unifying the entire experiment configuration, FLEET enables researchers to systematically investigate how network constraints, such as limited bandwidth, high latency, and packet loss, affect the convergence and efficiency of FL algorithms. This work provides the research community with a robust tool to bridge the gap between algorithmic theory and real-world network conditions, promoting the holistic and reproducible evaluation of federated learning systems.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Decentralized Federated Multi-task Learning With Trustworthiness in Cyber-Physical Systems</title>
<link>https://arxiv.org/abs/2509.00992</link>
<guid>https://arxiv.org/abs/2509.00992</guid>
<content:encoded><![CDATA[
arXiv:2509.00992v1 Announce Type: new 
Abstract: Multi-task learning is an effective way to address the challenge of model personalization caused by high data heterogeneity in federated learning. However, extending multi-task learning to the online decentralized federated learning setting is yet to be explored. The online decentralized federated learning setting considers many real-world applications of federated learning, such as autonomous systems, where clients communicate peer-to-peer and the data distribution of each client is time-varying. A more serious problem in real-world applications of federated learning is the presence of Byzantine clients. Byzantine-resilient approaches used in federated learning work only when the number of Byzantine clients is less than one-half the total number of clients. Yet, it is difficult to put a limit on the number of Byzantine clients within a system in reality. However, recent work in robotics shows that it is possible to exploit cyber-physical properties of a system to predict clients' behavior and assign a trust probability to received signals. This can help to achieve resiliency in the presence of a dominating number of Byzantine clients. Therefore, in this paper, we develop an online decentralized federated multi-task learning algorithm to provide model personalization and resiliency when the number of Byzantine clients dominates the number of honest clients. Our proposed algorithm leverages cyber-physical properties, such as the received signal strength in wireless systems or side information, to assign a trust probability to local models received from neighbors in each iteration. Our simulation results show that the proposed algorithm performs close to a Byzantine-free setting.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Rug Pulls in Decentralized Exchanges: Machine Learning Evidence from the TON Blockchain</title>
<link>https://arxiv.org/abs/2509.01168</link>
<guid>https://arxiv.org/abs/2509.01168</guid>
<content:encoded><![CDATA[
arXiv:2509.01168v1 Announce Type: new 
Abstract: This paper presents a machine learning framework for the early detection of rug pull scams on decentralized exchanges (DEXs) within The Open Network (TON) blockchain. TON's unique architecture, characterized by asynchronous execution and a massive web2 user base from Telegram, presents a novel and critical environment for fraud analysis. We conduct a comprehensive study on the two largest TON DEXs, Ston.Fi and DeDust, fusing data from both platforms to train our models. A key contribution is the implementation and comparative analysis of two distinct rug pull definitions--TVL-based (a catastrophic liquidity withdrawal) and idle-based (a sudden cessation of all trading activity)--within a single, unified study. We demonstrate that Gradient Boosting models can effectively identify rug pulls within the first five minutes of trading, with the TVL-based method achieving superior AUC (up to 0.891) while the idle-based method excels at recall. Our analysis reveals that while feature sets are consistent across exchanges, their underlying distributions differ significantly, challenging straightforward data fusion and highlighting the need for robust, platform-aware models. This work provides a crucial early-warning mechanism for investors and enhances the security infrastructure of the rapidly growing TON DeFi ecosystem.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks</title>
<link>https://arxiv.org/abs/2509.01257</link>
<guid>https://arxiv.org/abs/2509.01257</guid>
<content:encoded><![CDATA[
arXiv:2509.01257v1 Announce Type: new 
Abstract: In edge computing systems, autonomous agents must make fast local decisions while competing for shared resources. Existing MARL methods often resume to centralized critics or frequent communication, which fail under limited observability and communication constraints. We propose a decentralized framework in which each agent solves a constrained Markov decision process (CMDP), coordinating implicitly through a shared constraint vector. For the specific case of offloading, e.g., constraints prevent overloading shared server resources. Coordination constraints are updated infrequently and act as a lightweight coordination mechanism. They enable agents to align with global resource usage objectives but require little direct communication. Using safe reinforcement learning, agents learn policies that meet both local and global goals. We establish theoretical guarantees under mild assumptions and validate our approach experimentally, showing improved performance over centralized and independent baselines, especially in large-scale settings.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LiFeChain: Lightweight Blockchain for Secure and Efficient Federated Lifelong Learning in IoT</title>
<link>https://arxiv.org/abs/2509.01434</link>
<guid>https://arxiv.org/abs/2509.01434</guid>
<content:encoded><![CDATA[
arXiv:2509.01434v1 Announce Type: new 
Abstract: The expansion of Internet of Things (IoT) devices constantly generates heterogeneous data streams, driving demand for continuous, decentralized intelligence. Federated Lifelong Learning (FLL) provides an ideal solution by incorporating federated and lifelong learning to overcome catastrophic forgetting. The extended lifecycle of FLL in IoT systems increases their vulnerability to persistent attacks, and these risks may be obscured by performance degradation caused by spatial-temporal data heterogeneity. Moreover, this problem is exacerbated by the standard single-server architecture, as its single point of failure makes it difficult to maintain a reliable audit trail for long-term threats. Blockchain provides a tamper-proof foundation for trustworthy FLL systems. Nevertheless, directly applying blockchain to FLL significantly increases computational and retrieval costs with the expansion of the knowledge base, slowing down the training on IoT devices. To address these challenges, we propose LiFeChain, a lightweight blockchain for secure and efficient federated lifelong learning by providing a tamper-resistant ledger with minimal on-chain disclosure and bidirectional verification. To the best of our knowledge, LiFeChain is the first blockchain tailored for FLL. LiFeChain incorporates two complementary mechanisms: the proof-of-model-correlation (PoMC) consensus on the server, which couples learning and unlearning mechanisms to mitigate negative transfer, and segmented zero-knowledge arbitration (Seg-ZA) on the client, which detects and arbitrates abnormal committee behavior without compromising privacy. LiFeChain is designed as a plug-and-play component that can be seamlessly integrated into existing FLL algorithms. Experimental results demonstrate that LiFeChain not only enhances model performance against two long-term attacks but also sustains high efficiency and scalability.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Technologies in Practical Demand Response: An Informational Requirement-based Roadmap</title>
<link>https://arxiv.org/abs/2509.01459</link>
<guid>https://arxiv.org/abs/2509.01459</guid>
<content:encoded><![CDATA[
arXiv:2509.01459v1 Announce Type: new 
Abstract: The future grid will be highly complex and decentralized, requiring sophisticated coordination across numerous human and software agents that manage distributed resources such as Demand Response (DR). Realizing this vision demands significant advances in semantic interoperability, which enables scalable and cost-effective automation across heterogeneous systems. While semantic technologies have progressed in commercial building and DR domains, current ontologies have two critical limitations: they are often developed without a formal framework that reflects real-world DR requirements, and proposals for integrating general and application-specific ontologies remain mostly conceptual, lacking formalization or empirical validation.
  In this paper, we address these gaps by applying a formal ontology evaluation/development approach to define the informational requirements (IRs) necessary for semantic interoperability in the area of incentive-based DR for commercial buildings. We identify the IRs associated with each stage of the wholesale incentive-based DR process, focusing on the perspective of building owners. Using these IRs, we evaluate how well existing ontologies (Brick, DELTA, and EFOnt) support the operational needs of DR participation. Our findings reveal substantial misalignments between current ontologies and practical DR requirements. Based on our assessments, we propose a roadmap of necessary extensions and integrations for these ontologies. This work ultimately aims to enhance the interoperability of today's and future smart grid, thereby facilitating scalable integration of DR systems into the grid's complex operational framework.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Foundation Models in Harsh Wireless Environments: Prospects, Challenges, and Future Directions</title>
<link>https://arxiv.org/abs/2509.01957</link>
<guid>https://arxiv.org/abs/2509.01957</guid>
<content:encoded><![CDATA[
arXiv:2509.01957v1 Announce Type: new 
Abstract: Foundation models (FMs) have shown remarkable capabilities in generalized intelligence, multimodal understanding, and adaptive learning across a wide range of domains. However, their deployment in harsh or austere environments -- characterized by intermittent connectivity, limited computation, noisy data, and dynamically changing network topologies -- remains an open challenge. Existing distributed learning methods such as federated learning (FL) struggle to adapt in such settings due to their reliance on stable infrastructure, synchronized updates, and resource-intensive training. In this work, we explore the potential of Federated Foundation Models (FFMs) as a promising paradigm to address these limitations. By integrating the scalability and generalization power of FMs with novel decentralized, communication-aware FL frameworks, we aim to enable robust, energy-efficient, and adaptive intelligence in extreme and adversarial conditions. We present a detailed breakdown of system-level constraints in harsh environments, and discuss the open research challenges in communication design, model robustness, and energy-efficient personalization for these unique settings.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fault-Tolerant Decentralized Distributed Asynchronous Federated Learning with Adaptive Termination Detection</title>
<link>https://arxiv.org/abs/2509.02186</link>
<guid>https://arxiv.org/abs/2509.02186</guid>
<content:encoded><![CDATA[
arXiv:2509.02186v1 Announce Type: new 
Abstract: Federated Learning (FL) facilitates collaborative model training across distributed clients while ensuring data privacy. Traditionally, FL relies on a centralized server to coordinate learning, which creates bottlenecks and a single point of failure. Decentralized FL architectures eliminate the need for a central server and can operate in either synchronous or asynchronous modes. Synchronous FL requires all clients to compute updates and wait for one another before aggregation, guaranteeing consistency but often suffering from delays due to slower participants. Asynchronous FL addresses this by allowing clients to update independently, offering better scalability and responsiveness in heterogeneous environments.
  Our research develops an asynchronous decentralized FL approach in two progressive phases. (a) In Phase 1, we develop an asynchronous FL framework that enables clients to learn and update independently, removing the need for strict synchronization. (b) In Phase 2, we extend this framework with fault tolerance mechanisms to handle client failures and message drops, ensuring robust performance even under unpredictable conditions. As a central contribution, we propose Client-Confident Convergence and Client-Responsive Termination novel techniques that provide each client with the ability to autonomously determine appropriate termination points. These methods ensure that all active clients conclude meaningfully and efficiently, maintaining reliable convergence despite the challenges of asynchronous communication and faults.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VariAntNet: Learning Decentralized Control of Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2509.02271</link>
<guid>https://arxiv.org/abs/2509.02271</guid>
<content:encoded><![CDATA[
arXiv:2509.02271v1 Announce Type: new 
Abstract: A simple multi-agent system can be effectively utilized in disaster response applications, such as firefighting. Such a swarm is required to operate in complex environments with limited local sensing and no reliable inter-agent communication or centralized control. These simple robotic agents, also known as Ant Robots, are defined as anonymous agents that possess limited sensing capabilities, lack a shared coordinate system, and do not communicate explicitly with one another. A key challenge for simple swarms lies in maintaining cohesion and avoiding fragmentation despite limited-range sensing. Recent advances in machine learning offer effective solutions to some of the classical decentralized control challenges. We propose VariAntNet, a deep learning-based decentralized control model designed to facilitate agent swarming and collaborative task execution. VariAntNet includes geometric features extraction from unordered, variable-sized local observations. It incorporates a neural network architecture trained with a novel, differentiable, multi-objective, mathematically justified loss function that promotes swarm cohesiveness by utilizing the properties of the visibility graph Laplacian matrix. VariAntNet is demonstrated on the fundamental multi-agent gathering task, where agents with bearing-only and limited-range sensing must gather at some location. VariAntNet significantly outperforms an existing analytical solution, achieving more than double the convergence rate while maintaining high swarm connectivity across varying swarm sizes. While the analytical solution guarantees cohesion, it is often too slow in practice. In time-critical scenarios, such as emergency response operations where lives are at risk, slower analytical methods are impractical and justify the loss of some agents within the swarm. This paper presents and analyzes this trade-off in detail.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Near-Optimal Stability for Distributed Transaction Processing in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2509.02421</link>
<guid>https://arxiv.org/abs/2509.02421</guid>
<content:encoded><![CDATA[
arXiv:2509.02421v1 Announce Type: new 
Abstract: In blockchain sharding, $n$ processing nodes are divided into $s$ shards, and each shard processes transactions in parallel. A key challenge in such a system is to ensure system stability for any ``tractable'' pattern of generated transactions; this is modeled by an adversary generating transactions with a certain rate of at most $\rho$ and burstiness $b$. This model captures worst-case scenarios and even some attacks on transactions' processing, e.g., DoS. A stable system ensures bounded transaction queue sizes and bounded transaction latency. It is known that the absolute upper bound on the maximum injection rate for which any scheduler could guarantee bounded queues and latency of transactions is $\max\left\{ \frac{2}{k+1}, \frac{2}{ \left\lfloor\sqrt{2s}\right\rfloor}\right\}$, where $k$ is the maximum number of shards that each transaction accesses. Here, we first provide a single leader scheduler that guarantees stability under injection rate $\rho \leq \max\left\{ \frac{1}{16k}, \frac{1}{16\lceil \sqrt{s} \rceil}\right\}$. Moreover, we also give a distributed scheduler with multiple leaders that guarantees stability under injection rate $\rho \leq \frac{1}{16c_1 \log D \log s}\max\left\{ \frac{1}{k}, \frac{1}{\lceil \sqrt{s} \rceil} \right\}$, where $c_1$ is some positive constant and $D$ is the diameter of shard graph $G_s$. This bound is within a poly-log factor from the optimal injection rate, and significantly improves the best previous known result for the distributed setting by Adhikari et al., SPAA 2024.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models</title>
<link>https://arxiv.org/abs/2406.15836</link>
<guid>https://arxiv.org/abs/2406.15836</guid>
<content:encoded><![CDATA[
arXiv:2406.15836v2 Announce Type: replace 
Abstract: Learning a world model for model-free Reinforcement Learning (RL) agents can significantly improve the sample efficiency by learning policies in imagination. However, building a world model for Multi-Agent RL (MARL) can be particularly challenging due to the scalability issue in a centralized architecture arising from a large number of agents, and also the non-stationarity issue in a decentralized architecture stemming from the inter-dependency among agents. To address both challenges, we propose a novel world model for MARL that learns decentralized local dynamics for scalability, combined with a centralized representation aggregation from all agents. We cast the dynamics learning as an auto-regressive sequence modeling problem over discrete tokens by leveraging the expressive Transformer architecture, in order to model complex local dynamics across different agents and provide accurate and consistent long-term imaginations. As the first pioneering Transformer-based world model for multi-agent systems, we introduce a Perceiver Transformer as an effective solution to enable centralized representation aggregation within this context. Results on Starcraft Multi-Agent Challenge (SMAC) show that it outperforms strong model-free approaches and existing model-based methods in both sample efficiency and overall performance.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nav-SCOPE: Swarm Robot Cooperative Perception and Coordinated Navigation</title>
<link>https://arxiv.org/abs/2409.10049</link>
<guid>https://arxiv.org/abs/2409.10049</guid>
<content:encoded><![CDATA[
arXiv:2409.10049v3 Announce Type: replace 
Abstract: This paper proposes a lightweight systematic solution for multi-robot coordinated navigation with decentralized cooperative perception. An information flow is first created to facilitate real-time observation sharing over unreliable ad-hoc networks. Then, the environmental uncertainties of each robot are reduced by interaction fields that deliver complementary information. Finally, path optimization is achieved, enabling self-organized coordination with effective convergence, divergence, and collision avoidance. Our method is fully interpretable and ready for deployment without gaps. Comprehensive simulations and real-world experiments demonstrate reduced path redundancy, robust performance across various tasks, and minimal demands on computation and communication.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hierarchical Gradient Tracking Algorithm for Mitigating Subnet-Drift in Fog Learning Networks</title>
<link>https://arxiv.org/abs/2409.17430</link>
<guid>https://arxiv.org/abs/2409.17430</guid>
<content:encoded><![CDATA[
arXiv:2409.17430v2 Announce Type: replace 
Abstract: Federated learning (FL) encounters scalability challenges when implemented over fog networks that do not follow FL's conventional star topology architecture. Semi-decentralized FL (SD-FL) has proposed a solution for device-to-device (D2D) enabled networks that divides model cooperation into two stages: at the lower stage, D2D communications is employed for local model aggregations within subnetworks (subnets), while the upper stage handles device-server (DS) communications for global model aggregations. However, existing SD-FL schemes are based on gradient diversity assumptions that become performance bottlenecks as data distributions become more heterogeneous. In this work, we develop semi-decentralized gradient tracking (SD-GT), the first SD-FL methodology that removes the need for such assumptions by incorporating tracking terms into device updates for each communication layer. Our analytical characterization of SD-GT reveals upper bounds on convergence for non-convex, convex, and strongly-convex problems. We show how the bounds enable the development of an optimization algorithm that navigates the performance-efficiency trade-off by tuning subnet sampling rate and D2D rounds for each global training interval. Our subsequent numerical evaluations demonstrate that SD-GT obtains substantial improvements in trained model quality and communication cost relative to baselines in SD-FL and gradient tracking on several datasets.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2410.18862</link>
<guid>https://arxiv.org/abs/2410.18862</guid>
<content:encoded><![CDATA[
arXiv:2410.18862v2 Announce Type: replace 
Abstract: Federated learning has recently gained popularity as a framework for distributed clients to collaboratively train a machine learning model using local data. While traditional federated learning relies on a central server for model aggregation, recent advancements adopt a decentralized framework, enabling direct model exchange between clients and eliminating the single point of failure. However, existing decentralized frameworks often assume all clients train a shared model. Personalizing each client's model can enhance performance, especially with heterogeneous client data distributions. We propose FedSPD, an efficient personalized federated learning algorithm for the decentralized setting, and show that it learns accurate models even in low-connectivity networks. To provide theoretical guarantees on convergence, we introduce a clustering-based framework that enables consensus on models for distinct data clusters while personalizing to unique mixtures of these clusters at different clients. This flexibility, allowing selective model updates based on data distribution, substantially reduces communication costs compared to prior work on personalized federated learning in decentralized settings. Experimental results on real-world datasets show that FedSPD outperforms multiple decentralized variants of personalized federated learning algorithms, especially in scenarios with low-connectivity networks.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Interaction-Aware Vulnerability Detection in Smart Contract Bytecodes</title>
<link>https://arxiv.org/abs/2410.20712</link>
<guid>https://arxiv.org/abs/2410.20712</guid>
<content:encoded><![CDATA[
arXiv:2410.20712v2 Announce Type: replace 
Abstract: The detection of vulnerabilities in smart contracts remains a significant challenge. While numerous tools are available for analyzing smart contracts in source code, only about 1.79% of smart contracts on Ethereum are open-source. For existing tools that target bytecodes, most of them only consider the semantic logic context and disregard function interface information in the bytecodes. In this paper, we propose COBRA, a novel framework that integrates semantic context and function interfaces to detect vulnerabilities in bytecodes of the smart contract. To our best knowledge, COBRA is the first framework that combines these two features. Moreover, to infer the function signatures that are not present in signature databases, we propose SRIF, automatically learn the rules of function signatures from the smart contract bytecodes. The bytecodes associated with the function signatures are collected by constructing a control flow graph (CFG) for the SRIF training. We optimize the semantic context using the operation code in the static single assignment (SSA) format. Finally, we integrate the context and function interface representations in the latent space as the contract feature embedding. The contract features in the hidden space are decoded for vulnerability classifications with a decoder and attention module. Experimental results demonstrate that SRIF can achieve 94.76% F1-score for function signature inference. Furthermore, when the ground truth ABI exists, COBRA achieves 93.45% F1-score for vulnerability classification. In the absence of ABI, the inferred function feature fills the encoder, and the system accomplishes an 89.46% recall rate.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Trust-Centric Approach To Quantifying Maturity and Security in Internet Voting Protocols</title>
<link>https://arxiv.org/abs/2412.10611</link>
<guid>https://arxiv.org/abs/2412.10611</guid>
<content:encoded><![CDATA[
arXiv:2412.10611v2 Announce Type: replace 
Abstract: Voting is a cornerstone of collective participatory decision-making in contexts ranging from political elections to decentralized autonomous organizations (DAOs). Despite the proliferation of internet voting protocols promising enhanced accessibility and efficiency, their evaluation and comparison are complicated by a lack of standardized criteria and unified definitions of security and maturity. Furthermore, socio-technical requirements by decision makers are not structurally taken into consideration when comparing internet voting systems. This paper addresses this gap by introducing a trust-centric maturity scoring framework to quantify the security and maturity of seventeen internet voting systems. A comprehensive trust model analysis is conducted for selected internet voting protocols, examining their security properties, trust assumptions, technical complexity, and practical usability. In this paper we propose the Internet Voting Maturity Framework (IVMF) which supports nuanced assessment that reflects real-world deployment concerns and aids decision-makers in selecting appropriate systems tailored to their specific use-case requirements. The framework is general enough to be applied to other systems, where the aspects of decentralization, trust, and security are crucial, such as digital identity, Ethereum layer-two scaling solutions, and federated data infrastructures. Its objective is to provide an extendable toolkit for policy makers and technology experts alike that normalizes technical and non-technical requirements on a univariate scale.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GenTorrent: Scaling Large Language Model Serving with An Overlay Network</title>
<link>https://arxiv.org/abs/2504.20101</link>
<guid>https://arxiv.org/abs/2504.20101</guid>
<content:encoded><![CDATA[
arXiv:2504.20101v3 Announce Type: replace 
Abstract: While significant progress has been made in research and development on open-source and cost-efficient large-language models (LLMs), serving scalability remains a critical challenge, particularly for small organizations and individuals seeking to deploy and test their LLM innovations. Inspired by peer-to-peer networks that leverage decentralized overlay nodes to increase throughput and availability, we propose GenTorrent, an LLM serving overlay that harnesses computing resources from decentralized contributors. We identify four key research problems inherent to enabling such a decentralized infrastructure: 1) overlay network organization; 2) LLM communication privacy; 3) overlay forwarding for resource efficiency; and 4) verification of serving quality. This work presents the first systematic study of these fundamental problems in the context of decentralized LLM serving. Evaluation results from a prototype implemented on a set of decentralized nodes demonstrate that GenTorrent achieves a latency reduction of over 50% compared to the baseline design without overlay forwarding. Furthermore, the security features introduce minimal overhead to serving latency and throughput. We believe this work pioneers a new direction for democratizing and scaling future AI serving capabilities.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graded Transformers</title>
<link>https://arxiv.org/abs/2507.20108</link>
<guid>https://arxiv.org/abs/2507.20108</guid>
<content:encoded><![CDATA[
arXiv:2507.20108v2 Announce Type: replace 
Abstract: We introduce the Graded Transformer framework, a new class of sequence models that embeds algebraic inductive biases through grading transformations on vector spaces. Extending Graded Neural Networks (GNNs), we propose two architectures: the Linearly Graded Transformer (LGT) and the Exponentially Graded Transformer (EGT). These models apply parameterized scaling operators, governed by fixed or learnable grading tuples and in the case of EGT exponential factors, to encode hierarchical structure in attention and representation layers and to improve efficiency for structured data.
  We establish rigorous guarantees, including universal approximation theorems for continuous and Sobolev functions, reduced sample complexity via effective VC dimension bounds, Lipschitz continuity of graded operations, and robustness to perturbations. A graded loss ensures gradient stability and alignment with domain priors during optimization. By treating grades as differentiable parameters, the framework enables adaptive feature prioritization, overcoming limitations of fixed grades in earlier models.
  The Graded Transformer provides a mathematically principled approach to hierarchical learning and neuro-symbolic reasoning. Applications include algebraic geometry (moduli spaces and zeta functions), physics (multiscale systems), natural language processing (syntactic parsing), biological sequence analysis (variant prediction), robotics and autonomous systems (safety-critical prioritization), the automotive industry (certifiable AI for ADAS), and blockchain and financial cryptography (secure coding and structured prediction).
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Federated Averaging via Random Walk</title>
<link>https://arxiv.org/abs/2508.21286</link>
<guid>https://arxiv.org/abs/2508.21286</guid>
<content:encoded><![CDATA[
arXiv:2508.21286v1 Announce Type: new 
Abstract: Federated Learning (FL) is a communication-efficient distributed machine learning method that allows multiple devices to collaboratively train models without sharing raw data. FL can be categorized into centralized and decentralized paradigms. The centralized paradigm relies on a central server to aggregate local models, potentially resulting in single points of failure, communication bottlenecks, and exposure of model parameters. In contrast, the decentralized paradigm, which does not require a central server, provides improved robustness and privacy. The essence of federated learning lies in leveraging multiple local updates for efficient communication. However, this approach may result in slower convergence or even convergence to suboptimal models in the presence of heterogeneous and imbalanced data. To address this challenge, we study decentralized federated averaging via random walk (DFedRW), which replaces multiple local update steps on a single device with random walk updates. Traditional Federated Averaging (FedAvg) and its decentralized versions commonly ignore stragglers, which reduces the amount of training data and introduces sampling bias. Therefore, we allow DFedRW to aggregate partial random walk updates, ensuring that each computation contributes to the model update. To further improve communication efficiency, we also propose a quantized version of DFedRW. We demonstrate that (quantized) DFedRW achieves convergence upper bound of order $\mathcal{O}(\frac{1}{k^{1-q}})$ under convex conditions. Furthermore, we propose a sufficient condition that reveals when quantization balances communication and convergence. Numerical analysis indicates that our proposed algorithms outperform (decentralized) FedAvg in both convergence rate and accuracy, achieving a 38.3\% and 37.5\% increase in test accuracy under high levels of heterogeneities.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Time Tells All: Deanonymization of Blockchain RPC Users with Zero Transaction Fee (Extended Version)</title>
<link>https://arxiv.org/abs/2508.21440</link>
<guid>https://arxiv.org/abs/2508.21440</guid>
<content:encoded><![CDATA[
arXiv:2508.21440v1 Announce Type: new 
Abstract: Remote Procedure Call (RPC) services have become a primary gateway for users to access public blockchains. While they offer significant convenience, RPC services also introduce critical privacy challenges that remain insufficiently examined. Existing deanonymization attacks either do not apply to blockchain RPC users or incur costs like transaction fees assuming an active network eavesdropper. In this paper, we propose a novel deanonymization attack that can link an IP address of a RPC user to this user's blockchain pseudonym. Our analysis reveals a temporal correlation between the timestamps of transaction confirmations recorded on the public ledger and those of TCP packets sent by the victim when querying transaction status. We assume a strong passive adversary with access to network infrastructure, capable of monitoring traffic at network border routers or Internet exchange points. By monitoring network traffic and analyzing public ledgers, the attacker can link the IP address of the TCP packet to the pseudonym of the transaction initiator by exploiting the temporal correlation. This deanonymization attack incurs zero transaction fee. We mathematically model and analyze the attack method, perform large-scale measurements of blockchain ledgers, and conduct real-world attacks to validate the attack. Our attack achieves a high success rate of over 95% against normal RPC users on various blockchain networks, including Ethereum, Bitcoin and Solana.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification</title>
<link>https://arxiv.org/abs/2508.21458</link>
<guid>https://arxiv.org/abs/2508.21458</guid>
<content:encoded><![CDATA[
arXiv:2508.21458v1 Announce Type: new 
Abstract: While foundation models (FMs) offer strong potential for AI-based dementia diagnosis, their integration into federated learning (FL) systems remains underexplored. In this benchmarking study, we systematically evaluate the impact of key design choices: classification head architecture, fine-tuning strategy, and aggregation method, on the performance and efficiency of federated FM tuning using brain MRI data. Using a large multi-cohort dataset, we find that the architecture of the classification head substantially influences performance, freezing the FM encoder achieves comparable results to full fine-tuning, and advanced aggregation methods outperform standard federated averaging. Our results offer practical insights for deploying FMs in decentralized clinical settings and highlight trade-offs that should guide future method development.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unpacking Maximum Extractable Value on Polygon: A Study on Atomic Arbitrage</title>
<link>https://arxiv.org/abs/2508.21473</link>
<guid>https://arxiv.org/abs/2508.21473</guid>
<content:encoded><![CDATA[
arXiv:2508.21473v1 Announce Type: new 
Abstract: The evolution of blockchain technology, from its origins as a decentralized ledger for cryptocurrencies to its broader applications in areas like decentralized finance (DeFi), has significantly transformed financial ecosystems while introducing new challenges such as Maximum Extractable Value (MEV). This paper explores MEV on the Polygon blockchain, with a particular focus on Atomic Arbitrage (AA) transactions. We establish criteria for identifying AA transactions and analyze key factors such as searcher behavior, bidding dynamics, and token usage. Utilizing a dataset spanning 22 months and covering 23 million blocks, we examine MEV dynamics with a focus on Spam-based and Auction-based backrunning strategies. Our findings reveal that while Spam-based transactions are more prevalent, Auction-based transactions demonstrate greater profitability. Through detailed examples and analysis, we investigate the interactions between network architecture, transaction sequencing, and MEV extraction, offering comprehensive insights into the evolution and challenges of MEV in decentralized ecosystems. These results emphasize the need for robust transaction ordering mechanisms and highlight the implications of emerging MEV strategies for blockchain networks.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain</title>
<link>https://arxiv.org/abs/2508.21480</link>
<guid>https://arxiv.org/abs/2508.21480</guid>
<content:encoded><![CDATA[
arXiv:2508.21480v1 Announce Type: new 
Abstract: The increasing adoption of smart home devices and IoT-based security systems presents significant opportunities to enhance convenience, safety, and risk management for homeowners and service providers. However, secure onboarding-provisioning credentials and establishing trust with cloud platforms-remains a considerable challenge. Traditional onboarding methods often rely on centralized Public Key Infrastructure (PKI) models and manufacturer-controlled keys, which introduce security risks and limit the user's digital sovereignty. These limitations hinder the widespread deployment of scalable IoT solutions. This paper presents a novel onboarding framework that builds upon existing network-layer onboarding techniques and extends them to the application layer to address these challenges. By integrating consortium blockchain technology, we propose a decentralized onboarding mechanism that enhances transparency, security, and monitoring for smart home architectures. The architecture supports device registration, key revocation, access control management, and risk detection through event-driven alerts across dedicated blockchain channels and smart contracts. To evaluate the framework, we formally model the protocol using the Tamarin Prover under the Dolev-Yao adversary model. The analysis focuses on authentication, token integrity, key confidentiality, and resilience over public channels. A prototype implementation demonstrates the system's viability in smart home settings, with verification completing in 0.34 seconds, highlighting its scalability and suitability for constrained devices and diverse stakeholders. Additionally, performance evaluation shows that the blockchain-based approach effectively handles varying workloads, maintains high throughput and low latency, and supports near real-time IoT data processing.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Stream Pipeline Framework for Digital Payment Programming based on Smart Contracts</title>
<link>https://arxiv.org/abs/2508.21075</link>
<guid>https://arxiv.org/abs/2508.21075</guid>
<content:encoded><![CDATA[
arXiv:2508.21075v1 Announce Type: cross 
Abstract: Digital payments play a pivotal role in the burgeoning digital economy. Moving forward, the enhancement of digital payment systems necessitates programmability, going beyond just efficiency and convenience, to meet the evolving needs and complexities. Smart contract platforms like Central Bank Digital Currency (CBDC) networks and blockchains support programmable digital payments. However, the prevailing paradigm of programming payment logics involves coding smart contracts with programming languages, leading to high costs and significant security challenges. A novel and versatile method for payment programming on DLTs was presented in this paper - transforming digital currencies into token streams, then pipelining smart contracts to authorize, aggregate, lock, direct, and dispatch these streams efficiently from source to target accounts. By utilizing a small set of configurable templates, a few specialized smart contracts could be generated, and support most of payment logics through configuring and composing them. This approach could substantially reduce the cost of payment programming and enhance security, self-enforcement, adaptability, and controllability, thus hold the potential to become an essential component in the infrastructure of digital economy.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure</title>
<link>https://arxiv.org/abs/2508.21368</link>
<guid>https://arxiv.org/abs/2508.21368</guid>
<content:encoded><![CDATA[
arXiv:2508.21368v1 Announce Type: cross 
Abstract: The Decentralized Physical Infrastructure (DePIN) market is revolutionizing the sharing economy through token-based economics and smart contracts that govern decentralized operations. By 2024, DePIN projects have exceeded \$10 billion in market capitalization, underscoring their rapid growth. However, the unregulated nature of these markets, coupled with the autonomous deployment of AI agents in smart contracts, introduces risks such as inefficiencies and potential misalignment with human values. To address these concerns, we introduce EconAgentic, a Large Language Model (LLM)-powered framework designed to mitigate these challenges. Our research focuses on three key areas: 1) modeling the dynamic evolution of DePIN markets, 2) evaluating stakeholders' actions and their economic impacts, and 3) analyzing macroeconomic indicators to align market outcomes with societal goals. Through EconAgentic, we simulate how AI agents respond to token incentives, invest in infrastructure, and adapt to market conditions, comparing AI-driven decisions with human heuristic benchmarks. Our results show that EconAgentic provides valuable insights into the efficiency, inclusion, and stability of DePIN markets, contributing to both academic understanding and practical improvements in the design and governance of decentralized, tokenized economies.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mobile Apps Prioritizing Privacy, Efficiency and Equity: A Decentralized Approach to COVID-19 Vaccination Coordination</title>
<link>https://arxiv.org/abs/2102.09372</link>
<guid>https://arxiv.org/abs/2102.09372</guid>
<content:encoded><![CDATA[
arXiv:2102.09372v2 Announce Type: replace 
Abstract: In this early draft, we describe a decentralized, app-based approach to COVID-19 vaccine distribution that facilitates zero knowledge verification, dynamic vaccine scheduling, continuous symptoms reporting, access to aggregate analytics based on population trends and more. To ensure equity, our solution is developed to work with limited internet access as well. In addition, we describe the six critical functions that we believe last mile vaccination management platforms must perform, examine existing vaccine management systems, and present a model for privacy-focused, individual-centric solutions.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis</title>
<link>https://arxiv.org/abs/2504.06235</link>
<guid>https://arxiv.org/abs/2504.06235</guid>
<content:encoded><![CDATA[
arXiv:2504.06235v3 Announce Type: replace 
Abstract: Much of federated learning (FL) focuses on settings where local dataset statistics remain the same between training and testing. However, this assumption often does not hold in practice due to distribution shifts, motivating the development of domain generalization (DG) approaches that leverage source domain data to train models capable of generalizing to unseen target domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives; and (2) DG research in FL being limited to the star-topology architecture. We develop Decentralized Federated Domain Generalization with Style Sharing ($\textit{StyleDDG}$), a decentralized DG algorithm which allows devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we provide the first systematic approach to analyzing style-based DG training in decentralized networks. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\textit{StyleDDG}$. We then obtain analytical conditions under which convergence of $\textit{StyleDDG}$ can be guaranteed. Through experiments on popular DG datasets, we demonstrate that $\textit{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal communication overhead compared to baseline decentralized gradient methods.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Evolution of Intelligent Agents in Large-Scale Microservice Systems</title>
<link>https://arxiv.org/abs/2508.20508</link>
<guid>https://arxiv.org/abs/2508.20508</guid>
<content:encoded><![CDATA[
arXiv:2508.20508v1 Announce Type: new 
Abstract: This paper proposes an intelligent service optimization method based on a multi-agent collaborative evolution mechanism to address governance challenges in large-scale microservice architectures. These challenges include complex service dependencies, dynamic topology structures, and fluctuating workloads. The method models each service as an agent and introduces graph representation learning to construct a service dependency graph. This enables agents to perceive and embed structural changes within the system. Each agent learns its policy based on a Markov Decision Process. A centralized training and decentralized execution framework is used to integrate local autonomy with global coordination. To enhance overall system performance and adaptability, a game-driven policy optimization mechanism is designed. Through a selection-mutation process, agent strategy distributions are dynamically adjusted. This supports adaptive collaboration and behavioral evolution among services. Under this mechanism, the system can quickly respond and achieve stable policy convergence when facing scenarios such as sudden workload spikes, topology reconfigurations, or resource conflicts. To evaluate the effectiveness of the proposed method, experiments are conducted on a representative microservice simulation platform. Comparative analyses are performed against several advanced approaches, focusing on coordination efficiency, adaptability, and policy convergence performance. Experimental results show that the proposed method outperforms others in several key metrics. It significantly improves governance efficiency and operational stability in large-scale microservice systems. The method demonstrates strong practical value and engineering feasibility.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BridgeShield: Enhancing Security for Cross-chain Bridge Applications via Heterogeneous Graph Mining</title>
<link>https://arxiv.org/abs/2508.20517</link>
<guid>https://arxiv.org/abs/2508.20517</guid>
<content:encoded><![CDATA[
arXiv:2508.20517v1 Announce Type: new 
Abstract: Cross-chain bridges play a vital role in enabling blockchain interoperability. However, due to the inherent design flaws and the enormous value they hold, they have become prime targets for hacker attacks. Existing detection methods show progress yet remain limited, as they mainly address single-chain behaviors and fail to capture cross-chain semantics. To address this gap, we leverage heterogeneous graph attention networks, which are well-suited for modeling multi-typed entities and relations, to capture the complex execution semantics of cross-chain behaviors. We propose BridgeShield, a detection framework that jointly models the source chain, off-chain coordination, and destination chain within a unified heterogeneous graph representation. BridgeShield incorporates intra-meta-path attention to learn fine-grained dependencies within cross-chain paths and inter-meta-path attention to highlight discriminative cross-chain patterns, thereby enabling precise identification of attack behaviors. Extensive experiments on 51 real-world cross-chain attack events demonstrate that BridgeShield achieves an average F1-score of 92.58%, representing a 24.39% improvement over state-of-the-art baselines. These results validate the effectiveness of BridgeShield as a practical solution for securing cross-chain bridges and enhancing the resilience of multi-chain ecosystems.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse</title>
<link>https://arxiv.org/abs/2508.20664</link>
<guid>https://arxiv.org/abs/2508.20664</guid>
<content:encoded><![CDATA[
arXiv:2508.20664v1 Announce Type: new 
Abstract: Real-time human-device interaction in industrial Metaverse faces challenges such as high computational load, limited bandwidth, and strict latency. This paper proposes a task-oriented edge-assisted cross-system framework using digital twins (DTs) to enable responsive interactions. By predicting operator motions, the system supports: 1) proactive Metaverse rendering for visual feedback, and 2) preemptive control of remote devices. The DTs are decoupled into two virtual functions-visual display and robotic control-optimizing both performance and adaptability. To enhance generalizability, we introduce the Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates the framework's effectiveness: in a Trajectory-Based Drawing Control task, it reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene representation task for nuclear decommissioning, it achieves a PSNR of 22.11, SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's capability to ensure spatial precision and visual fidelity in real-time, high-risk industrial environments.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Composable Life: Speculation for Decentralized AI Life</title>
<link>https://arxiv.org/abs/2508.20668</link>
<guid>https://arxiv.org/abs/2508.20668</guid>
<content:encoded><![CDATA[
arXiv:2508.20668v1 Announce Type: new 
Abstract: "Composable Life" is a hybrid project blending design fiction, experiential virtual reality, and scientific research. Through a multi-perspective, cross-media approach to speculative design, it reshapes our understanding of the digital future from AI's perspective. The project explores the hypothetical first suicide of an on-chain artificial life, examining the complex symbiotic relationship between humans, AI, and blockchain technology.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Forkless Blockchain Databases</title>
<link>https://arxiv.org/abs/2508.20686</link>
<guid>https://arxiv.org/abs/2508.20686</guid>
<content:encoded><![CDATA[
arXiv:2508.20686v1 Announce Type: new 
Abstract: Operating nodes in an L1 blockchain remains costly despite recent advances in blockchain technology. One of the most resource-intensive components of a node is the blockchain database, also known as StateDB, that manages balances, nonce, code, and the persistent storage of accounts/smart contracts. Although the blockchain industry has transitioned from forking to forkless chains due to improved consensus protocols, forkless blockchains still rely on legacy forking databases that are suboptimal for their purposes. In this paper, we propose a forkless blockchain database, showing a 100x improvement in storage and a 10x improvement in throughput compared to the geth-based Fantom Blockchain client.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoCoL: A Communication Efficient Decentralized Collaborative Method for Multi-Robot Systems</title>
<link>https://arxiv.org/abs/2508.20898</link>
<guid>https://arxiv.org/abs/2508.20898</guid>
<content:encoded><![CDATA[
arXiv:2508.20898v1 Announce Type: new 
Abstract: Collaborative learning enhances the performance and adaptability of multi-robot systems in complex tasks but faces significant challenges due to high communication overhead and data heterogeneity inherent in multi-robot tasks. To this end, we propose CoCoL, a Communication efficient decentralized Collaborative Learning method tailored for multi-robot systems with heterogeneous local datasets. Leveraging a mirror descent framework, CoCoL achieves remarkable communication efficiency with approximate Newton-type updates by capturing the similarity between objective functions of robots, and reduces computational costs through inexact sub-problem solutions. Furthermore, the integration of a gradient tracking scheme ensures its robustness against data heterogeneity. Experimental results on three representative multi robot collaborative learning tasks show the superiority of the proposed CoCoL in significantly reducing both the number of communication rounds and total bandwidth consumption while maintaining state-of-the-art accuracy. These benefits are particularly evident in challenging scenarios involving non-IID (non-independent and identically distributed) data distribution, streaming data, and time-varying network topologies.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematic Review and Layered Framework for Privacy-by-Design in Self-Sovereign Identity Systems</title>
<link>https://arxiv.org/abs/2502.02520</link>
<guid>https://arxiv.org/abs/2502.02520</guid>
<content:encoded><![CDATA[
arXiv:2502.02520v2 Announce Type: replace 
Abstract: The use of Self-Sovereign Identity (SSI) systems for digital identity management is gaining traction and interest. Countries such as Bhutan have already implemented an SSI infrastructure to manage the identity of their citizens. The EU, thanks to the revised eIDAS regulation, is opening the door for SSI vendors to develop SSI systems for the planned EU digital identity wallet. These developments, which fall within the sovereign domain, raise questions about individual privacy. The design of SSI systems is complex, often characterized by a large number of components and architectural choices because the current SSI communities differ on how to create identifiers, how to build and present credentials, and even how to design a user wallet. SSI stacks developed by different organizations provide different privacy features for different privacy needs. This paper performs a systematic mapping and review of SSI components and technologies into a novel four-layer privacy framework to address the design complexity of SSI systems. Based on this review, we provide an accompanying Design Assistance Dashboard (DAD). The DAD shows the interdependencies between SSI components in different layers, and maps these components to different privacy requirements and considerations, even providing a simple privacy class for each component.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Distributed Key Generation</title>
<link>https://arxiv.org/abs/2502.20835</link>
<guid>https://arxiv.org/abs/2502.20835</guid>
<content:encoded><![CDATA[
arXiv:2502.20835v2 Announce Type: replace 
Abstract: Distributed Key Generation (DKG) is vital to threshold-based cryptographic protocols such as threshold signatures, secure multiparty computation, and i-voting. Yet, standard $(n,t)$-DKG requires a known set of $n$ participants and a fixed threshold $t$, making it impractical for public or decentralized settings where membership and availability can change.
  We introduce Federated Distributed Key Generation (FDKG), which relaxes these constraints by allowing each participant to select its own guardian set, with a local threshold to reconstruct that participant's partial key. FDKG generalizes DKG and draws inspiration from Federated Byzantine Agreement, enabling dynamic trust delegation with minimal message complexity (two rounds). The protocol's liveness can tolerate adversary that controls up to $k - t + 1$ nodes in every guardian set. The paper presents a detailed protocol, a formal description of liveness, privacy, and integrity properties, and a simulation-based evaluation showcasing the efficacy of FDKG in mitigating node unreliability.
  In a setting of 100 parties, a 50% participation rate, 80% retention, and 40 guardians, the distribution phase incurred a total message size of 332.7 kB ($O(n\,k)$), and reconstruction phase 416.56 kB ($O(n\,k)$. Groth16 client-side proving took about 5 s in the distribution phase and ranged from 0.619 s up to 29.619 s in the reconstruction phase.
  Our work advances distributed cryptography by enabling flexible trust models for dynamic networks, with applications ranging from ad-hoc collaboration to blockchain governance.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated nnU-Net for Privacy-Preserving Medical Image Segmentation</title>
<link>https://arxiv.org/abs/2503.02549</link>
<guid>https://arxiv.org/abs/2503.02549</guid>
<content:encoded><![CDATA[
arXiv:2503.02549v2 Announce Type: replace 
Abstract: The nnU-Net framework has played a crucial role in medical image segmentation and has become the gold standard in multitudes of applications targeting different diseases, organs, and modalities. However, so far it has been used primarily in a centralized approach where the collected data is stored in the same location where nnU-Net is trained. This centralized approach has various limitations, such as potential leakage of sensitive patient information and violation of patient privacy. Federated learning has emerged as a key approach for training segmentation models in a decentralized manner, enabling collaborative development while prioritising patient privacy. In this paper, we propose FednnU-Net, a plug-and-play, federated learning extension of the nnU-Net framework. To this end, we contribute two federated methodologies to unlock decentralized training of nnU-Net, namely, Federated Fingerprint Extraction (FFE) and Asymmetric Federated Averaging (AsymFedAvg). We conduct a comprehensive set of experiments demonstrating high and consistent performance of our methods for breast, cardiac and fetal segmentation based on a multi-modal collection of 6 datasets representing samples from 18 different institutions. To democratize research as well as real-world deployments of decentralized training in clinical centres, we publicly share our framework at https://github.com/faildeny/FednnUNet .
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>L2RW+: A Comprehensive Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification</title>
<link>https://arxiv.org/abs/2503.12232</link>
<guid>https://arxiv.org/abs/2503.12232</guid>
<content:encoded><![CDATA[
arXiv:2503.12232v2 Announce Type: replace 
Abstract: Visible-infrared person re-identification (VI-ReID) is a challenging task that aims to match pedestrian images captured under varying lighting conditions, which has drawn intensive research attention and achieved promising results. However, existing methods adopt the centralized training, ignoring the potential privacy concerns as the data is distributed across multiple devices or entities in reality. In this paper, we propose L2RW+, a benchmark that brings VI-ReID closer to real-world applications. The core rationale behind L2RW+ is that incorporating decentralized training into VI-ReID can address privacy concerns in scenarios with limited data-sharing constrains. Specifically, we design protocols and corresponding algorithms for different privacy sensitivity levels. In our new benchmark, we simulate the training under real-world data conditions that: 1) data from each camera is completely isolated, or 2) different data entities (e.g., data controllers of a certain region) can selectively share the data. In this way, we simulate scenarios with strict privacy restrictions, which is closer to real-world conditions. Comprehensive experiments show the feasibility and potential of decentralized VI-ReID training at both image and video levels. In particular, with increasing data scales, the performance gap between decentralized and centralized training decreases, especially in video-level VI-ReID. In unseen domains, decentralized training even achieves performance comparable to SOTA centralized methods. This work offers a novel research entry for deploying VI-ReID into real-world scenarios and can benefit the community. Code is available at: https://github.com/Joey623/L2RW.
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AMM-based DEX on the XRP Ledger</title>
<link>https://arxiv.org/abs/2312.13749</link>
<guid>https://arxiv.org/abs/2312.13749</guid>
<content:encoded><![CDATA[
arXiv:2312.13749v5 Announce Type: replace 
Abstract: Automated Market Maker (AMM)-based Decentralized Exchanges (DEXs) are crucial in Decentralized Finance (DeFi), but Ethereum implementations suffer from high transaction costs and price synchronization challenges. To address these limitations, we compare the XRP Ledger (XRPL)-AMM-Decentralized Exchange (DEX), a protocol-level implementation, against a Generic AMM-based DEX (G-AMM-DEX) on Ethereum, akin to Uniswap's V2 AMM implementation, through agent-based simulations using real market data and multiple volatility scenarios generated via Geometric Brownian Motion (GBM). Results demonstrate that the XRPL-AMM-DEX achieves superior price synchronization, reduced slippage, and improved returns due to XRPL's lower fees and shorter block times, with benefits amplifying during market volatility. The integrated Continuous Auction Mechanism (CAM) further mitigates impermanent loss by redistributing arbitrage value to Liquidity Providers (LPs). To the best of our knowledge, this study represents the first comparative analysis between protocol-level and smart contract AMM-based DEX implementations and the first agent-based simulation validating theoretical auction mechanisms for AMM-based DEXs.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Formal Modeling and Verification of the Algorand Consensus Protocol in CADP</title>
<link>https://arxiv.org/abs/2508.19452</link>
<guid>https://arxiv.org/abs/2508.19452</guid>
<content:encoded><![CDATA[
arXiv:2508.19452v1 Announce Type: new 
Abstract: Algorand is a scalable and secure permissionless blockchain that achieves proof-of-stake consensus via cryptographic self-sortition and binary Byzantine agreement. In this paper, we present a process algebraic model of the Algorand consensus protocol with the aim of enabling rigorous formal verification. Our model captures the behavior of participants with respect to the structured alternation of consensus steps toward a committee-based agreement by means of a probabilistic process calculus. We validate the correctness of the protocol in the absence of adversaries and then extend our model to capture the influence of coordinated malicious nodes that can force the commit of an empty block instead of the proposed one. The adversarial scenario is analyzed by using an equivalence-checking-based noninterference framework that we have implemented in the CADP verification toolkit. In addition to highlighting both the robustness and the limitations of the Algorand protocol under adversarial assumptions, this work illustrates the added value of using formal methods for the analysis of blockchain consensus algorithms.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition</title>
<link>https://arxiv.org/abs/2508.19630</link>
<guid>https://arxiv.org/abs/2508.19630</guid>
<content:encoded><![CDATA[
arXiv:2508.19630v1 Announce Type: new 
Abstract: Long-tailed visual recognition is challenging not only due to class imbalance but also because of varying classification difficulty across categories. Simply reweighting classes by frequency often overlooks those that are intrinsically hard to learn. To address this, we propose \textbf{DQRoute}, a modular framework that combines difficulty-aware optimization with dynamic expert collaboration. DQRoute first estimates class-wise difficulty based on prediction uncertainty and historical performance, and uses this signal to guide training with adaptive loss weighting. On the architectural side, DQRoute employs a mixture-of-experts design, where each expert specializes in a different region of the class distribution. At inference time, expert predictions are weighted by confidence scores derived from expert-specific OOD detectors, enabling input-adaptive routing without the need for a centralized router. All components are trained jointly in an end-to-end manner. Experiments on standard long-tailed benchmarks demonstrate that DQRoute significantly improves performance, particularly on rare and difficult classes, highlighting the benefit of integrating difficulty modeling with decentralized expert routing.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey</title>
<link>https://arxiv.org/abs/2508.19870</link>
<guid>https://arxiv.org/abs/2508.19870</guid>
<content:encoded><![CDATA[
arXiv:2508.19870v1 Announce Type: new 
Abstract: Agentification serves as a critical enabler of Edge General Intelligence (EGI), transforming massive edge devices into cognitive agents through integrating Large Language Models (LLMs) and perception, reasoning, and acting modules. These agents collaborate across heterogeneous edge infrastructures, forming multi-LLM agentic AI systems that leverage collective intelligence and specialized capabilities to tackle complex, multi-step tasks. However, the collaborative nature of multi-LLM systems introduces critical security vulnerabilities, including insecure inter-LLM communications, expanded attack surfaces, and cross-domain data leakage that traditional perimeter-based security cannot adequately address. To this end, this survey introduces zero-trust security of multi-LLM in EGI, a paradigmatic shift following the ``never trust, always verify'' principle. We begin by systematically analyzing the security risks in multi-LLM systems within EGI contexts. Subsequently, we present the vision of a zero-trust multi-LLM framework in EGI. We then survey key technical progress to facilitate zero-trust multi-LLM systems in EGI. Particularly, we categorize zero-trust security mechanisms into model- and system-level approaches. The former and latter include strong identification, context-aware access control, etc., and proactive maintenance, blockchain-based management, etc., respectively. Finally, we identify critical research directions. This survey serves as the first systematic treatment of zero-trust applied to multi-LLM systems, providing both theoretical foundations and practical strategies.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence</title>
<link>https://arxiv.org/abs/2508.20019</link>
<guid>https://arxiv.org/abs/2508.20019</guid>
<content:encoded><![CDATA[
arXiv:2508.20019v1 Announce Type: new 
Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on centralized orchestration, incurring high deployment costs, rigid communication topologies, and limited adaptability. To address these challenges, we introduce Symphony, a decentralized multi-agent system which enables lightweight LLMs on consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms: (1) a decentralized ledger that records capabilities, (2) a Beacon-selection protocol for dynamic task allocation, and (3) weighted result voting based on CoTs. This design forms a privacy-saving, scalable, and fault-tolerant orchestration with low overhead. Empirically, Symphony outperforms existing baselines on reasoning benchmarks, achieving substantial accuracy gains and demonstrating robustness across models of varying capacities.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Contract Intent Detection with Pre-trained Programming Language Model</title>
<link>https://arxiv.org/abs/2508.20086</link>
<guid>https://arxiv.org/abs/2508.20086</guid>
<content:encoded><![CDATA[
arXiv:2508.20086v1 Announce Type: new 
Abstract: Malicious intent in smart contract development can lead to substantial economic losses. SmartIntentNN is a deep learning model specifically designed to identify unsafe intents in smart contracts. This model integrates the Universal Sentence Encoder, a K-means clustering-based intent highlighting mechanism, and a Bidirectional Long Short-Term Memory network for multi-label classification, achieving an F1 of 0.8633 in distinguishing ten different intent categories. In this study, we present an upgraded version of this model, SmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant enhancement in V2 is the incorporation of a BERT-based pre-trained language model, which has been trained on a dataset of 16,000 real smart contracts using a Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based multi-label classification network. With an improved F1 of 0.927, V2 demonstrates enhanced performance compared to its predecessor, establishing itself as the state-of-the-art model for smart contract intent detection.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DVM-SLAM: Decentralized Visual Monocular Simultaneous Localization and Mapping for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.04126</link>
<guid>https://arxiv.org/abs/2503.04126</guid>
<content:encoded><![CDATA[
arXiv:2503.04126v2 Announce Type: replace 
Abstract: Cooperative Simultaneous Localization and Mapping (C-SLAM) enables multiple agents to work together in mapping unknown environments while simultaneously estimating their own positions. This approach enhances robustness, scalability, and accuracy by sharing information between agents, reducing drift, and enabling collective exploration of larger areas. In this paper, we present Decentralized Visual Monocular SLAM (DVM-SLAM), the first open-source decentralized monocular C-SLAM system. By only utilizing low-cost and light-weight monocular vision sensors, our system is well suited for small robots and micro aerial vehicles (MAVs). DVM-SLAM's real-world applicability is validated on physical robots with a custom collision avoidance framework, showcasing its potential in real-time multi-agent autonomous navigation scenarios. We also demonstrate comparable accuracy to state-of-the-art centralized monocular C-SLAM systems. We open-source our code and provide supplementary material online.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RoboComm: A DID-based scalable and privacy-preserving Robot-to-Robot interaction over state channels</title>
<link>https://arxiv.org/abs/2504.09517</link>
<guid>https://arxiv.org/abs/2504.09517</guid>
<content:encoded><![CDATA[
arXiv:2504.09517v3 Announce Type: replace 
Abstract: In a multi robot system establishing trust amongst untrusted robots from different organisations while preserving a robot's privacy is a challenge. Recently decentralized technologies such as smart contract and blockchain are being explored for applications in robotics. However, the limited transaction processing and high maintenance cost hinder the widespread adoption of such approaches. Moreover, blockchain transactions be they on public or private permissioned blockchain are publically readable which further fails to preserve the confidentiality of the robot's data and privacy of the robot. In this work, we propose RoboComm a Decentralized Identity based approach for privacy-preserving interaction between robots. With DID a component of Self-Sovereign Identity; robots can authenticate each other independently without relying on any third-party service. Verifiable Credentials enable private data associated with a robot to be stored within the robot's hardware, unlike existing blockchain based approaches where the data has to be on the blockchain. We improve throughput by allowing message exchange over state channels. Being a blockchain backed solution RoboComm provides a trustworthy system without relying on a single party. Moreover, we implement our proposed approach to demonstrate the feasibility of our solution.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Model Privacy in Federated Learning with Random Masking and Quantization</title>
<link>https://arxiv.org/abs/2508.18911</link>
<guid>https://arxiv.org/abs/2508.18911</guid>
<content:encoded><![CDATA[
arXiv:2508.18911v2 Announce Type: new 
Abstract: The primary goal of traditional federated learning is to protect data privacy by enabling distributed edge devices to collaboratively train a shared global model while keeping raw data decentralized at local clients. The rise of large language models (LLMs) has introduced new challenges in distributed systems, as their substantial computational requirements and the need for specialized expertise raise critical concerns about protecting intellectual property (IP). This highlights the need for a federated learning approach that can safeguard both sensitive data and proprietary models. To tackle this challenge, we propose FedQSN, a federated learning approach that leverages random masking to obscure a subnetwork of model parameters and applies quantization to the remaining parameters. Consequently, the server transmits only a privacy-preserving proxy of the global model to clients during each communication round, thus enhancing the model's confidentiality. Experimental results across various models and tasks demonstrate that our approach not only maintains strong model performance in federated learning settings but also achieves enhanced protection of model parameters compared to baseline methods.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Federated Learning Framework for Risk-Based Adaptive Authentication</title>
<link>https://arxiv.org/abs/2508.18453</link>
<guid>https://arxiv.org/abs/2508.18453</guid>
<content:encoded><![CDATA[
arXiv:2508.18453v1 Announce Type: new 
Abstract: Balancing robust security with strong privacy guarantees is critical for Risk-Based Adaptive Authentication (RBA), particularly in decentralized settings. Federated Learning (FL) offers a promising solution by enabling collaborative risk assessment without centralizing user data. However, existing FL approaches struggle with Non-Independent and Identically Distributed (Non-IID) user features, resulting in biased, unstable, and poorly generalized global models. This paper introduces FL-RBA2, a novel Federated Learning framework for Risk-Based Adaptive Authentication that addresses Non-IID challenges through a mathematically grounded similarity transformation. By converting heterogeneous user features (including behavioral, biometric, contextual, interaction-based, and knowledge-based modalities) into IID similarity vectors, FL-RBA2 supports unbiased aggregation and personalized risk modeling across distributed clients. The framework mitigates cold-start limitations via clustering-based risk labeling, incorporates Differential Privacy (DP) to safeguard sensitive information, and employs Message Authentication Codes (MACs) to ensure model integrity and authenticity. Federated updates are securely aggregated into a global model, achieving strong balance between user privacy, scalability, and adaptive authentication robustness. Rigorous game-based security proofs in the Random Oracle Model formally establish privacy, correctness, and adaptive security guarantees. Extensive experiments on keystroke, mouse, and contextual datasets validate FL-RBA2's effectiveness in high-risk user detection and its resilience to model inversion and inference attacks, even under strong DP constraints.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable Fairness Shaping with LLM-Guided Multi-Agent Reinforcement Learning for Peer-to-Peer Electricity Markets</title>
<link>https://arxiv.org/abs/2508.18610</link>
<guid>https://arxiv.org/abs/2508.18610</guid>
<content:encoded><![CDATA[
arXiv:2508.18610v1 Announce Type: new 
Abstract: Peer-to-peer (P2P) energy trading is becoming central to modern distribution systems as rooftop PV and home energy management systems become pervasive, yet most existing market and reinforcement learning designs emphasize efficiency or private profit and offer little real-time guidance to ensure equitable outcomes under uncertainty. To address this gap, a fairness-aware multiagent reinforcement learning framework, FairMarket-RL, is proposed in which a large language model (LLM) critic shapes bidding policies within a continuous double auction under partial observability and discrete price-quantity actions. After each trading slot, the LLM returns normalized fairness scores Fairness-to-Grid (FTG), Fairness-Between-Sellers (FBS), and Fairness-of-Pricing (FPP) that are integrated into the reward via ramped coefficients and tunable scaling, so that fairness guidance complements, rather than overwhelms, economic incentives. The environment models realistic residential load and PV profiles and enforce hard constraints on prices, physical feasibility, and policy-update stability. Across a progression of experiments from a small pilot to a larger simulated community and a mixed-asset real-world dataset, the framework shifts exchanges toward local P2P trades, lowers consumer costs relative to grid-only procurement, sustains strong fairness across participants, and preserves utility viability. Sensitivity analyses over solar availability and aggregate demand further indicate robust performance, suggesting a scalable, LLM-guided pathway to decentralized electricity markets that are economically efficient, socially equitable, and technically sound.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Edge General Intelligence with Agentic AI and Agentification: Concepts, Technologies, and Future Directions</title>
<link>https://arxiv.org/abs/2508.18725</link>
<guid>https://arxiv.org/abs/2508.18725</guid>
<content:encoded><![CDATA[
arXiv:2508.18725v1 Announce Type: new 
Abstract: The rapid expansion of sixth-generation (6G) wireless networks and the Internet of Things (IoT) has catalyzed the evolution from centralized cloud intelligence towards decentralized edge general intelligence. However, traditional edge intelligence methods, characterized by static models and limited cognitive autonomy, fail to address the dynamic, heterogeneous, and resource-constrained scenarios inherent to emerging edge networks. Agentic artificial intelligence (Agentic AI) emerges as a transformative solution, enabling edge systems to autonomously perceive multimodal environments, reason contextually, and adapt proactively through continuous perception-reasoning-action loops. In this context, the agentification of edge intelligence serves as a key paradigm shift, where distributed entities evolve into autonomous agents capable of collaboration and continual adaptation. This paper presents a comprehensive survey dedicated to Agentic AI and agentification frameworks tailored explicitly for edge general intelligence. First, we systematically introduce foundational concepts and clarify distinctions from traditional edge intelligence paradigms. Second, we analyze important enabling technologies, including compact model compression, energy-aware computing strategies, robust connectivity frameworks, and advanced knowledge representation and reasoning mechanisms. Third, we provide representative case studies demonstrating Agentic AI's capabilities in low-altitude economy networks, intent-driven networking, vehicular networks, and human-centric service provisioning, supported by numerical evaluations. Furthermore, we identify current research challenges, review emerging open-source platforms, and highlight promising future research directions to guide robust, scalable, and trustworthy Agentic AI deployments for next-generation edge environments.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks</title>
<link>https://arxiv.org/abs/2508.18737</link>
<guid>https://arxiv.org/abs/2508.18737</guid>
<content:encoded><![CDATA[
arXiv:2508.18737v1 Announce Type: new 
Abstract: Federated Learning (FL) has become a powerful technique for training Machine Learning (ML) models in a decentralized manner, preserving the privacy of the training datasets involved. However, the decentralized nature of FL limits the visibility of the training process, relying heavily on the honesty of participating clients. This assumption opens the door to malicious third parties, known as Byzantine clients, which can poison the training process by submitting false model updates. Such malicious clients may engage in poisoning attacks, manipulating either the dataset or the model parameters to induce misclassification. In response, this study introduces FLAegis, a two-stage defensive framework designed to identify Byzantine clients and improve the robustness of FL systems. Our approach leverages symbolic time series transformation (SAX) to amplify the differences between benign and malicious models, and spectral clustering, which enables accurate detection of adversarial behavior. Furthermore, we incorporate a robust FFT-based aggregation function as a final layer to mitigate the impact of those Byzantine clients that manage to evade prior defenses. We rigorously evaluate our method against five poisoning attacks, ranging from simple label flipping to adaptive optimization-based strategies. Notably, our approach outperforms state-of-the-art defenses in both detection precision and final model accuracy, maintaining consistently high performance even under strong adversarial conditions.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Immutable Digital Recognition via Blockchain</title>
<link>https://arxiv.org/abs/2508.18750</link>
<guid>https://arxiv.org/abs/2508.18750</guid>
<content:encoded><![CDATA[
arXiv:2508.18750v1 Announce Type: new 
Abstract: The process integrates the decentralised management and centralised operation models, aligning them with the national policy directives. The developed solution enables the full utilisation of blockchain technology's advantages while also fostering community participation. Consequently, it establishes a secure, legal, reliable, and dynamic electronic certification system.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EnerSwap: Large-Scale, Privacy-First Automated Market Maker for V2G Energy Trading</title>
<link>https://arxiv.org/abs/2508.18942</link>
<guid>https://arxiv.org/abs/2508.18942</guid>
<content:encoded><![CDATA[
arXiv:2508.18942v1 Announce Type: new 
Abstract: With the rapid growth of Electric Vehicle (EV) technology, EVs are destined to shape the future of transportation. The large number of EVs facilitates the development of the emerging vehicle-to-grid (V2G) technology, which realizes bidirectional energy exchanges between EVs and the power grid. This has led to the setting up of electricity markets that are usually confined to a small geographical location, often with a small number of participants. Usually, these markets are manipulated by intermediaries responsible for collecting bids from prosumers, determining the market-clearing price, incorporating grid constraints, and accounting for network losses. While centralized models can be highly efficient, they grant excessive power to the intermediary by allowing them to gain exclusive access to prosumers \textquotesingle price preferences. This opens the door to potential market manipulation and raises significant privacy concerns for users, such as the location of energy providers. This lack of protection exposes users to potential risks, as untrustworthy servers and malicious adversaries can exploit this information to infer trading activities and real identities. This work proposes a secure, decentralized exchange market built on blockchain technology, utilizing a privacy-preserving Automated Market Maker (AMM) model to offer open and fair, and equal access to traders, and mitigates the most common trading-manipulation attacks. Additionally, it incorporates a scalable architecture based on geographical dynamic sharding, allowing for efficient resource allocation and improved performance as the market grows.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Algorithmic Collective Action with Multiple Collectives</title>
<link>https://arxiv.org/abs/2508.19149</link>
<guid>https://arxiv.org/abs/2508.19149</guid>
<content:encoded><![CDATA[
arXiv:2508.19149v1 Announce Type: new 
Abstract: As learning systems increasingly influence everyday decisions, user-side steering via Algorithmic Collective Action (ACA)-coordinated changes to shared data-offers a complement to regulator-side policy and firm-side model design. Although real-world actions have been traditionally decentralized and fragmented into multiple collectives despite sharing overarching objectives-with each collective differing in size, strategy, and actionable goals, most of the ACA literature focused on single collective settings. In this work, we present the first theoretical framework for ACA with multiple collectives acting on the same system. In particular, we focus on collective action in classification, studying how multiple collectives can plant signals, i.e., bias a classifier to learn an association between an altered version of the features and a chosen, possibly overlapping, set of target classes. We provide quantitative results about the role and the interplay of collectives' sizes and their alignment of goals. Our framework, by also complementing previous empirical results, opens a path for a holistic treatment of ACA with multiple collectives.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Efficient Lightweight Blockchain for Decentralized IoT</title>
<link>https://arxiv.org/abs/2508.19219</link>
<guid>https://arxiv.org/abs/2508.19219</guid>
<content:encoded><![CDATA[
arXiv:2508.19219v1 Announce Type: new 
Abstract: The Internet of Things (IoT) is applied in various fields, and the number of physical devices connected to the IoT is increasingly growing. There are significant challenges to the IoT's growth and development, mainly due to the centralized nature and large-scale IoT networks. The emphasis on the decentralization of IoT's architecture can overcome challenges to IoT's capabilities. A promising decentralized platform for IoT is blockchain. Owing to IoT devices' limited resources, traditional consensus algorithms such as PoW and PoS in the blockchain are computationally expensive. Therefore, the PoA consensus algorithm is proposed in the blockchain consensus network for IoT. The PoA selects the validator as Turn-based selection (TBS) that needs optimization and faces system reliability, energy consumption, latency, and low scalability. We propose an efficient, lightweight blockchain for decentralizing IoT architecture by using virtualization and clustering to increase productivity and scalability to address these issues. We also introduce a novel PoA based on the Weight-Based-Selection (WBS) method for validators to validate transactions and add them to the blockchain. By simulation, we evaluated the performance of our proposed WBS method as opposed to TBS. The results show reduced energy consumption, and response time, and increased throughput.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus</title>
<link>https://arxiv.org/abs/2508.18735</link>
<guid>https://arxiv.org/abs/2508.18735</guid>
<content:encoded><![CDATA[
arXiv:2508.18735v1 Announce Type: cross 
Abstract: Non-Terrestrial Networks (NTNs) based on Unmanned Aerial Vehicles (UAVs) as base stations are extremely susceptible to security attacks due to their distributed and dynamic nature, which makes them vulnerable to rogue nodes. In this paper, a new Dynamic Trust Score Adjustment Mechanism with Energy-Aware Consensus (DTSAM-EAC) is proposed to enhance security in UAV-based NTNs. The proposed framework integrates a permissioned Hyperledger Fabric blockchain with Federated Learning (FL) to support privacy-preserving trust evaluation. Trust ratings are updated continuously through weighted aggregation of past trust, present behavior, and energy contribution, thus making the system adaptive to changing network conditions. An energy-aware consensus mechanism prioritizes UAVs with greater available energy for block validation, ensuring efficient use of resources under resource-constrained environments. FL aggregation with trust-weighting further increases the resilience of the global trust model. Simulation results verify the designed framework achieves 94\% trust score prediction accuracy and 96\% rogue UAV detection rate while outperforming centralized and static baselines of trust-based solutions on privacy, energy efficiency, and reliability. It complies with 6G requirements in terms of distributed intelligence and sustainability and is an energy-efficient and scalable solution to secure NTNs.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Security Risk Assessment in Quantum Era, Migration Strategies and Proactive Defense</title>
<link>https://arxiv.org/abs/2501.11798</link>
<guid>https://arxiv.org/abs/2501.11798</guid>
<content:encoded><![CDATA[
arXiv:2501.11798v2 Announce Type: replace 
Abstract: The emergence of quantum computing presents a formidable challenge to the security of blockchain systems. Traditional cryptographic algorithms, foundational to digital signatures, message encryption, and hashing functions, become vulnerable to the immense computational power of quantum computers. This paper conducts a thorough risk assessment of transitioning to quantum-resistant blockchains, comprehensively analyzing potential threats targeting vital blockchain components: the network, mining pools, transaction verification mechanisms, smart contracts, and user wallets. By elucidating the intricate challenges and strategic considerations inherent in transitioning to quantum-resistant algorithms, the paper evaluates risks and highlights obstacles in securing blockchain components with quantum-resistant cryptography. It offers a hybrid migration strategy to facilitate a smooth transition from classical to quantum-resistant cryptography. The analysis extends to prominent blockchains such as Bitcoin, Ethereum, Ripple, Litecoin, and Zcash, assessing vulnerable components, potential impacts, and associated STRIDE threats, thereby identifying areas susceptible to quantum attacks. Beyond analysis, the paper provides actionable guidance for designing secure and resilient blockchain ecosystems in the quantum computing era. Recognizing the looming threat of quantum computers, this research advocates for a proactive transition to quantum-resistant blockchain networks. It proposes a tailored security blueprint that strategically fortifies each component against the evolving landscape of quantum-induced cyber threats. Emphasizing the critical need for blockchain stakeholders to adopt proactive measures and implement quantum-resistant solutions, the paper underscores the importance of embracing these insights to navigate the complexities of the quantum era with resilience and confidence.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>zkPHIRE: A Programmable Accelerator for ZKPs over HIgh-degRee, Expressive Gates</title>
<link>https://arxiv.org/abs/2508.16738</link>
<guid>https://arxiv.org/abs/2508.16738</guid>
<content:encoded><![CDATA[
arXiv:2508.16738v1 Announce Type: new 
Abstract: Zero-Knowledge Proofs (ZKPs) have emerged as powerful tools for secure and privacy-preserving computation. ZKPs enable one party to convince another of a statement's validity without revealing anything else. This capability has profound implications in many domains, including: machine learning, blockchain, image authentication, and electronic voting. Despite their potential, ZKPs have seen limited deployment because of their exceptionally high computational overhead, which manifests primarily during proof generation. To mitigate these overheads, a (growing) body of researchers has proposed hardware accelerators and GPU implementations for kernels and complete protocols. Prior art spans a wide variety of ZKP schemes that vary significantly in computational overhead, proof size, verifier cost, protocol setup, and trust. The latest, and widely used ZKP protocols are intentionally designed to balance these trade-offs. A particular challenge in modern ZKP systems is supporting complex, high-degree gates using the SumCheck protocol. We address this challenge with a novel programmable accelerator that efficiently handles arbitrary custom gates via SumCheck. Our accelerator achieves upwards of $1000\times$ geomean speedup over CPU-based SumChecks across a range of gate types. We integrate this unit into a full-system accelerator, zkPHIRE, which achieves $1486\times$ geomean speedup over CPU and $11.87\times$ speedup over the state-of-the-art at iso-area. zkPHIRE is the first accelerator to scale to problem sizes of $2^{30}$ nominal constraints while maintaining small proof sizes and programmability.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Geometric Decentralized Stability Condition for Power Systems Based on Projecting DW Shells</title>
<link>https://arxiv.org/abs/2508.17033</link>
<guid>https://arxiv.org/abs/2508.17033</guid>
<content:encoded><![CDATA[
arXiv:2508.17033v1 Announce Type: new 
Abstract: The development of decentralized stability conditions has gained considerable attention due to the need to analyze heterogeneous multi-converter power systems. A recent advance is the application of the small-phase theorem, which extends the passivity theory. However, it requires the transfer function matrix to be sectorial, which may not hold in some frequency range and will result in conservatism. This letter tackles this problem by leveraging the Davis-Wielandt (DW) shells for decentralized stability analysis. We develop a geometric decentralized stability condition that visually displays how heterogeneous converters interact with the power grid and enable modular system analysis.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Post-Quantum Blockchain: Challenges and Opportunities</title>
<link>https://arxiv.org/abs/2508.17071</link>
<guid>https://arxiv.org/abs/2508.17071</guid>
<content:encoded><![CDATA[
arXiv:2508.17071v1 Announce Type: new 
Abstract: Blockchain is a Distributed Ledger Technology (DLT) that offers numerous benefits including decentralization, transparency, efficiency, and reduced costs. Hence, blockchain has been included in many fields. Blockchain relies on cryptographic protocols (especially public-key cryptography and hash functions) to achieve many essential sub-routines. However, the increased progress of quantum computation and algorithms has threatened the security of many traditional cryptosystems. Therefore, this represents a serious risk for the existing blockchain technology. For example, SHA-256 and the Elliptic Curve Digital Signature Algorithm (ECDSA) cryptosystems can be compromised by Shor s and Grover s quantum algorithms in the foreseeable future. Post-Quantum Cryptography (PQC) is a basic solution for resisting these quantum attacks. Applying PQC to blockchains results in creating Post-Quantum Blockchains (PQB). Thus, this paper aims to review the threats imposed by quantum computers on classical blockchain technology and provide useful guidelines on PQB security to blockchain researchers. The paper focuses on the challenges and opportunities of future work direction in this field.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reconciling Communication Compression and Byzantine-Robustness in Distributed Learning</title>
<link>https://arxiv.org/abs/2508.17129</link>
<guid>https://arxiv.org/abs/2508.17129</guid>
<content:encoded><![CDATA[
arXiv:2508.17129v1 Announce Type: new 
Abstract: Distributed learning (DL) enables scalable model training over decentralized data, but remains challenged by Byzantine faults and high communication costs. While both issues have been studied extensively in isolation, their interaction is less explored. Prior work shows that naively combining communication compression with Byzantine-robust aggregation degrades resilience to faulty nodes (or workers). The state-of-the-art algorithm, namely Byz-DASHA-PAGE [29], makes use of the momentum variance reduction scheme to mitigate the detrimental impact of compression noise on Byzantine-robustness. We propose a new algorithm, named RoSDHB, that integrates the classic Polyak's momentum with a new coordinated compression mechanism. We show that RoSDHB performs comparably to Byz-DASHA-PAGE under the standard (G, B)-gradient dissimilarity heterogeneity model, while it relies on fewer assumptions. In particular, we only assume Lipschitz smoothness of the average loss function of the honest workers, in contrast to [29]that additionally assumes a special smoothness of bounded global Hessian variance. Empirical results on benchmark image classification task show that RoSDHB achieves strong robustness with significant communication savings.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Literature Review of the Effect of Quantum Computing on Cryptocurrencies using Blockchain Technology</title>
<link>https://arxiv.org/abs/2508.17296</link>
<guid>https://arxiv.org/abs/2508.17296</guid>
<content:encoded><![CDATA[
arXiv:2508.17296v1 Announce Type: new 
Abstract: With the advent of quantum computing, cryptocurrencies that rely on blockchain technology face mounting cryptographic vulnerabilities. This paper presents a comprehensive literature review evaluating how quantum algorithms, specifically Shors and Grovers, could disrupt the foundational security mechanisms of cryptocurrencies. Shors algorithm poses a threat to public-key cryptographic schemes by enabling efficient factorization and discrete logarithm solving, thereby endangering digital signature systems. Grovers algorithm undermines hash-based functions, increasing the feasibility of fifty one percent attacks and hash collisions. By examining the internal mechanisms of major cryptocurrencies such as Bitcoin, Ethereum, Litecoin, Monero, and Zcash, this review identifies specific vulnerabilities in transaction and consensus processes. It further analyses the current hardware limitations of quantum systems and estimates when such attacks could become feasible. In anticipation, it investigates countermeasures including Post-Quantum Cryptography (PQC), Quantum Key Distribution (QKD), and protocol-level modifications such as memory-intensive proof-of-work algorithms and multi-signature schemes. The discussion integrates recent advancements in quantum error correction, hardware scalability, and NIST-standardized cryptographic algorithms. This review concludes that while quantum computers are not yet advanced enough to pose an immediate threat, proactive integration of quantum-resistant solutions is essential. The findings underscore the urgent need for cryptocurrencies to adopt post-quantum cryptographic standards to preserve the decentralized trust, integrity, and security that define blockchain-based digital cryptocurrencies.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MetaFed: Advancing Privacy, Performance, and Sustainability in Federated Metaverse Systems</title>
<link>https://arxiv.org/abs/2508.17341</link>
<guid>https://arxiv.org/abs/2508.17341</guid>
<content:encoded><![CDATA[
arXiv:2508.17341v1 Announce Type: new 
Abstract: The rapid expansion of immersive Metaverse applications introduces complex challenges at the intersection of performance, privacy, and environmental sustainability. Centralized architectures fall short in addressing these demands, often resulting in elevated energy consumption, latency, and privacy concerns. This paper proposes MetaFed, a decentralized federated learning (FL) framework that enables sustainable and intelligent resource orchestration for Metaverse environments. MetaFed integrates (i) multi-agent reinforcement learning for dynamic client selection, (ii) privacy-preserving FL using homomorphic encryption, and (iii) carbon-aware scheduling aligned with renewable energy availability. Evaluations on MNIST and CIFAR-10 using lightweight ResNet architectures demonstrate that MetaFed achieves up to 25\% reduction in carbon emissions compared to conventional approaches, while maintaining high accuracy and minimal communication overhead. These results highlight MetaFed as a scalable solution for building environmentally responsible and privacy-compliant Metaverse infrastructures.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Compiler Optimization Impacts on zkVM Performance</title>
<link>https://arxiv.org/abs/2508.17518</link>
<guid>https://arxiv.org/abs/2508.17518</guid>
<content:encoded><![CDATA[
arXiv:2508.17518v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKPs) are the cornerstone of programmable cryptography. They enable (1) privacy-preserving and verifiable computation across blockchains, and (2) an expanding range of off-chain applications such as credential schemes. Zero-knowledge virtual machines (zkVMs) lower the barrier by turning ZKPs into a drop-in backend for standard compilation pipelines. This lets developers write proof-generating programs in conventional languages (e.g., Rust or C++) instead of hand-crafting arithmetic circuits. However, these VMs inherit compiler infrastructures tuned for traditional architectures rather than for proof systems. In particular, standard compiler optimizations assume features that are absent in zkVMs, including cache locality, branch prediction, or instruction-level parallelism. Therefore, their impact on proof generation is questionable.
  We present the first systematic study of the impact of compiler optimizations on zkVMs. We evaluate 64 LLVM passes, six standard optimization levels, and an unoptimized baseline across 58 benchmarks on two RISC-V-based zkVMs (RISC Zero and SP1). While standard LLVM optimization levels do improve zkVM performance (over 40\%), their impact is far smaller than on traditional CPUs, since their decisions rely on hardware features rather than proof constraints. Guided by a fine-grained pass-level analysis, we~\emph{slightly} refine a small set of LLVM passes to be zkVM-aware, improving zkVM execution time by up to 45\% (average +4.6\% on RISC Zero, +1\% on SP1) and achieving consistent proving-time gains. Our work highlights the potential of compiler-level optimizations for zkVM performance and opens new direction for zkVM-specific passes, backends, and superoptimizers.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning in LLMs</title>
<link>https://arxiv.org/abs/2508.17850</link>
<guid>https://arxiv.org/abs/2508.17850</guid>
<content:encoded><![CDATA[
arXiv:2508.17850v1 Announce Type: new 
Abstract: As single-center computing approaches power constraints, decentralized training is becoming essential. Reinforcement Learning (RL) post-training enhances Large Language Models (LLMs) but faces challenges in heterogeneous distributed environments due to its tightly-coupled sampling-learning alternation. We propose HeteroRL, an asynchronous RL architecture that decouples rollout sampling from parameter learning, enabling robust deployment across geographically distributed nodes under network delays. We identify that latency-induced KL divergence causes importance sampling failure due to high variance. To address this, we propose Group Expectation Policy Optimization (GEPO), which reduces importance weight variance through a refined sampling mechanism. Theoretically, GEPO achieves exponential variance reduction. Experiments show it maintains superior stability over methods like GRPO, with less than 3% performance degradation under 1800-second delays, demonstrating strong potential for decentralized RL in heterogeneous networks.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real World Assets on-Chain Assistance Low-Altitude Computility Networks: Architecture, Methodology, and Challenges</title>
<link>https://arxiv.org/abs/2508.17911</link>
<guid>https://arxiv.org/abs/2508.17911</guid>
<content:encoded><![CDATA[
arXiv:2508.17911v1 Announce Type: new 
Abstract: Low-altitude airspace is becoming a new frontier for smart city services and commerce. Networks of drones, electric Vertical Takeoff and Landing (eVTOL) vehicles, and other aircraft, termed Low-Altitude Economic Networks (LAENets), promise to transform urban logistics, aerial sensing, and communication. A key challenge is how to efficiently share and trust the computing utility, termed computility, of these aerial devices. We propose treating the computing power on aircraft as tokenized Real-World Assets (RWAs) that can be traded and orchestrated via blockchain. By representing distributed edge computing resources as blockchain tokens, disparate devices can form Low-Altitude Computility Networks (LACNets), collaborative computing clusters in the sky. We first compare blockchain technologies, non-fungible tokens (NFTs), and RWA frameworks to clarify how physical hardware and its computational output can be tokenized as assets. Then, we present an architecture using blockchain to integrate aircraft fleets into a secure, interoperable computing network. Furthermore, a case study models an urban logistics LACNet of delivery drones and air-taxis. Simulation results indicate improvements in task latency, trust assurance, and resource efficiency when leveraging RWA-based coordination. Finally, we discuss future research directions, including AI-driven orchestration, edge AI offloading and collaborative computing, and cross-jurisdictional policy for tokenized assets.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MoveScanner: Analysis of Security Risks of Move Smart Contracts</title>
<link>https://arxiv.org/abs/2508.17964</link>
<guid>https://arxiv.org/abs/2508.17964</guid>
<content:encoded><![CDATA[
arXiv:2508.17964v1 Announce Type: new 
Abstract: As blockchain technology continues to evolve, the security of smart contracts has increasingly drawn attention from both academia and industry. The Move language, with its unique resource model and linear type system, provides a solid foundation for the security of digital assets. However, smart contracts still face new security challenges due to developer programming errors and the potential risks associated with cross-module interactions. This paper systematically analyzes the limitations of existing security tools within the Move ecosystem and reveals their unique vulnerability patterns. To address these issues, it introduces MoveScanner, a static analysis tool based on a control flow graph and data flow analysis architecture. By incorporating cross-module call graph tracking, MoveScanner can effectively identify five key types of security vulnerabilities, including resource leaks, weak permission management, and arithmetic overflows. In terms of design, MoveScanner adheres to a modular principle, supports bytecode-level analysis and multi-chain adaptation, and introduces innovative resource trajectory tracking algorithms and capability matrix analysis methods, thereby significantly reducing the false positive rate. Empirical results show that MoveScanner achieved 88.2% detection accuracy in benchmark testing, filling the gap in security tools in the Move ecosystem. Furthermore, this paper identifies twelve new types of security risks based on the resource-oriented programming paradigm and provides a theoretical foundation and practical experience for the development of smart contract security mechanisms. Future work will focus on combining formal verification and dynamic analysis techniques to build a security protection framework covering the entire contract lifecycle
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative-Online-Learning-Enabled Distributionally Robust Motion Control for Multi-Robot Systems</title>
<link>https://arxiv.org/abs/2508.17173</link>
<guid>https://arxiv.org/abs/2508.17173</guid>
<content:encoded><![CDATA[
arXiv:2508.17173v1 Announce Type: cross 
Abstract: This paper develops a novel COllaborative-Online-Learning (COOL)-enabled motion control framework for multi-robot systems to avoid collision amid randomly moving obstacles whose motion distributions are partially observable through decentralized data streams. To address the notable challenge of data acquisition due to occlusion, a COOL approach based on the Dirichlet process mixture model is proposed to efficiently extract motion distribution information by exchanging among robots selected learning structures. By leveraging the fine-grained local-moment information learned through COOL, a data-stream-driven ambiguity set for obstacle motion is constructed. We then introduce a novel ambiguity set propagation method, which theoretically admits the derivation of the ambiguity sets for obstacle positions over the entire prediction horizon by utilizing obstacle current positions and the ambiguity set for obstacle motion. Additionally, we develop a compression scheme with its safety guarantee to automatically adjust the complexity and granularity of the ambiguity set by aggregating basic ambiguity sets that are close in a measure space, thereby striking an attractive trade-off between control performance and computation time. Then the probabilistic collision-free trajectories are generated through distributionally robust optimization problems. The distributionally robust obstacle avoidance constraints based on the compressed ambiguity set are equivalently reformulated by deriving separating hyperplanes through tractable semi-definite programming. Finally, we establish the probabilistic collision avoidance guarantee and the long-term tracking performance guarantee for the proposed framework. The numerical simulations are used to demonstrate the efficacy and superiority of the proposed approach compared with state-of-the-art methods.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evasive Active Hypothesis Testing with Deep Neuroevolution: The Single- and Multi-Agent Cases</title>
<link>https://arxiv.org/abs/2403.10112</link>
<guid>https://arxiv.org/abs/2403.10112</guid>
<content:encoded><![CDATA[
arXiv:2403.10112v2 Announce Type: replace 
Abstract: Active hypothesis testing is a thoroughly studied problem that finds numerous applications in wireless communications and sensor networks. In this paper, we focus on one centralized and one decentralized problem of active hypothesis testing in the presence of an eavesdropper. For the centralized problem including a single legitimate agent, we present a new framework based on deep NeuroEvolution (NE), whereas, for the decentralized problem, we develop a novel NE-based method for solving collaborative multi-agent tasks, which, interestingly, maintains all computational benefits of our single-agent NE-based scheme. To further reduce the computational complexity of the latter scheme, a novel multi-agent joint NE and pruning framework is also designed. The superiority of the proposed NE-based evasive active hypothesis testing schemes over conventional active hypothesis testing policies, as well as learning-based methods, is validated through extensive numerical investigations in an example use case of anomaly detection over wireless sensor networks. It is demonstrated that the proposed joint optimization and pruning framework achieves nearly identical performance with its unpruned counterpart, while removing a very large percentage of redundant deep neural network weights.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PixRO: Pixel-Distributed Rotational Odometry with Gaussian Belief Propagation</title>
<link>https://arxiv.org/abs/2406.09726</link>
<guid>https://arxiv.org/abs/2406.09726</guid>
<content:encoded><![CDATA[
arXiv:2406.09726v2 Announce Type: replace 
Abstract: Images are the standard input for most computer vision algorithms. However, their processing often reduces to parallelizable operations applied locally and independently to individual pixels. Yet, many of these low-level raw pixel readings only provide redundant or noisy information for specific high-level tasks, leading to inefficiencies in both energy consumption during their transmission off-sensor and computational resources in their subsequent processing.
  As novel sensors featuring advanced in-pixel processing capabilities emerge, we envision a paradigm shift toward performing increasingly complex visual processing directly in-pixel, reducing computational overhead downstream. We advocate for synthesizing high-level cues at the pixel level, enabling their off-sensor transmission to directly support downstream tasks more effectively than raw pixel readings.
  This paper conceptualizes a novel photometric rotation estimation algorithm to be distributed at pixel level, where each pixel estimates the global motion of the camera by exchanging information with other pixels to achieve global consensus. We employ a probabilistic formulation and leverage Gaussian Belief Propagation (GBP) for decentralized inference using messaging-passing. The proposed proposed technique is evaluated on real-world public datasets and we offer a in-depth analysis of the practicality of applying GBP to distributed rotation estimation at pixel level.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Octopus Inspired Optimization (OIO): A Hierarchical Framework for Navigating Protein Fitness Landscapes</title>
<link>https://arxiv.org/abs/2410.07968</link>
<guid>https://arxiv.org/abs/2410.07968</guid>
<content:encoded><![CDATA[
arXiv:2410.07968v3 Announce Type: replace 
Abstract: Navigating the vast, rugged, and multi-modal fitness landscapes of protein sequences presents a formidable challenge for computational protein engineering, often trapping algorithms in suboptimal solutions. Existing methods struggle with the exploration-exploitation dilemma, failing to synergize global search with deep local refinement. To overcome this critical barrier, we introduce the Octopus Inspired Optimization (OIO), a novel hierarchical metaheuristic that mimics the octopus's unique neural architecture of centralized control and decentralized, parallel execution. OIO's "individual-tentacle-sucker" framework provides an intrinsic unification of global exploration and parallelized local exploitation, making it structurally ideal for complex combinatorial problems. We validated OIO's efficacy through a rigorous three-tiered experimental framework. On a real-world Green Fluorescent Protein (GFP) design benchmark, OIO surpassed a comprehensive suite of 15 competing metaheuristics, including 7 classic algorithms and 8 state-of-the-art methods from the past two years, delivering performance comparable only to a specialized local search algorithm. This success is explained by its fundamental strengths: OIO ranked first on the NK-Landscape benchmark, confirming its architectural suitability for protein-like fitness landscapes, and also ranked first on the gold-standard CEC2022 benchmark, demonstrating the raw power and efficiency of its optimization engine. OIO establishes a new, nature-inspired paradigm for protein engineering, offering a robust and powerful tool with significant potential for advancing therapeutic and enzymatic design.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HeteroTune: Efficient Federated Learning for Large Heterogeneous Models</title>
<link>https://arxiv.org/abs/2411.16796</link>
<guid>https://arxiv.org/abs/2411.16796</guid>
<content:encoded><![CDATA[
arXiv:2411.16796v2 Announce Type: replace 
Abstract: While large pre-trained models have achieved impressive performance across AI tasks, their deployment in privacy-sensitive and distributed environments remains challenging. Federated learning (FL) offers a viable solution by enabling decentralized fine-tuning without data sharing, but real-world applications face significant obstacles due to heterogeneous client resources in compute and memory. To address this, we propose HeteroTune, a novel federated fine-tuning paradigm for large, heterogeneous models operating under limited communication and computation budgets. The core of our method lies in a novel architecture, DeMA (Dense Mixture of Adapters), which enables flexible and efficient aggregation of heterogeneous models by preserving their full representational capacity while facilitating seamless cross-model knowledge fusion. We further introduce CMGA (Cross-Model Gradient Alignment), a lightweight yet effective mechanism that enhances training stability by harmonizing gradient directions across heterogeneous client models during aggregation, mitigating update conflicts and promoting more consistent convergence in federated settings. We provide both theoretical analysis and empirical evidence showing that HeteroTune achieves state-of-the-art performance and efficiency across diverse tasks and model architectures. For example, on LLaMA models, it reduces communication overhead by 99.5%, cuts peak memory usage by ~50%, and improves performance by 4.61%.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SolEval: Benchmarking Large Language Models for Repository-level Solidity Code Generation</title>
<link>https://arxiv.org/abs/2502.18793</link>
<guid>https://arxiv.org/abs/2502.18793</guid>
<content:encoded><![CDATA[
arXiv:2502.18793v2 Announce Type: replace 
Abstract: Large language models (LLMs) have transformed code generation. However, most existing approaches focus on mainstream languages such as Python and Java, neglecting the Solidity language, the predominant programming language for Ethereum smart contracts. Due to the lack of adequate benchmarks for Solidity, LLMs' ability to generate secure, cost-effective smart contracts remains unexplored. To fill this gap, we construct SolEval, the first repository-level benchmark designed for Solidity smart contract generation, to evaluate the performance of LLMs on Solidity. SolEval consists of 1,507 samples from 28 different repositories, covering 6 popular domains, providing LLMs with a comprehensive evaluation benchmark. Unlike the existing Solidity benchmark, SolEval not only includes complex function calls but also reflects the real-world complexity of the Ethereum ecosystem by incorporating Gas@k and Vul@k. We evaluate 16 LLMs on SolEval, and our results show that the best-performing LLM achieves only 26.29% Pass@10, highlighting substantial room for improvement in Solidity code generation by LLMs. Additionally, we conduct supervised fine-tuning (SFT) on Qwen-7B using SolEval, resulting in a significant performance improvement, with Pass@5 increasing from 16.67% to 58.33%, demonstrating the effectiveness of fine-tuning LLMs on our benchmark. We release our data and code at https://github.com/pzy2000/SolEval.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantum Federated Learning: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2508.15998</link>
<guid>https://arxiv.org/abs/2508.15998</guid>
<content:encoded><![CDATA[
arXiv:2508.15998v1 Announce Type: new 
Abstract: Quantum federated learning (QFL) is a combination of distributed quantum computing and federated machine learning, integrating the strengths of both to enable privacy-preserving decentralized learning with quantum-enhanced capabilities. It appears as a promising approach for addressing challenges in efficient and secure model training across distributed quantum systems. This paper presents a comprehensive survey on QFL, exploring its key concepts, fundamentals, applications, and emerging challenges in this rapidly developing field. Specifically, we begin with an introduction to the recent advancements of QFL, followed by discussion on its market opportunity and background knowledge. We then discuss the motivation behind the integration of quantum computing and federated learning, highlighting its working principle. Moreover, we review the fundamentals of QFL and its taxonomy. Particularly, we explore federation architecture, networking topology, communication schemes, optimization techniques, and security mechanisms within QFL frameworks. Furthermore, we investigate applications of QFL across several domains which include vehicular networks, healthcare networks, satellite networks, metaverse, and network security. Additionally, we analyze frameworks and platforms related to QFL, delving into its prototype implementations, and provide a detailed case study. Key insights and lessons learned from this review of QFL are also highlighted. We complete the survey by identifying current challenges and outlining potential avenues for future research in this rapidly advancing field.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems</title>
<link>https://arxiv.org/abs/2508.16189</link>
<guid>https://arxiv.org/abs/2508.16189</guid>
<content:encoded><![CDATA[
arXiv:2508.16189v1 Announce Type: new 
Abstract: The very high growth of Intelligent Transportation Systems (ITS) has generated an urgent requirement for secure, effective, and context-aware data sharing mechanisms, especially over heterogeneous and geographically dispersed settings. This work suggests a new architecture that combines a relay chain-driven encryption system with a modified Ciphertext-Policy Attribute-Based Encryption (CP-ABE) scheme to tackle the double impediment of dynamic access and low-latency communication. The model proposes a context-aware smart contract on a worldwide relay chain that checks against data properties, including event type, time, and geographical region, to specify the suitable level of encryption policy. From such relay-directed judgment, On-Board Units (OBUs) encrypt data end-to-end by utilising CP-ABE and store ciphertext inside localised regional blockchains, preventing dependence on symmetric encryption or off-chain storage. High-sensitivity events are secured with firm, multi-attribute access rules, whereas common updates use light policies to help reduce processing burdens. The crypto system also adds traceability and low-latency revocation, with global enforcement managed through the relay chain. This distributed, scalable model provides a proper balance between responsiveness in real time and security and is extremely apt for next-gen vehicular networks that function across multi-jurisdictional domains.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How to Beat Nakamoto in the Race</title>
<link>https://arxiv.org/abs/2508.16202</link>
<guid>https://arxiv.org/abs/2508.16202</guid>
<content:encoded><![CDATA[
arXiv:2508.16202v1 Announce Type: new 
Abstract: This paper studies proof-of-work Nakamoto consensus under bounded network delays, settling two long-standing questions in blockchain security: How can an adversary most effectively attack block safety under a given block confirmation latency? And what is the resulting probability of safety violation? A Markov decision process (MDP) framework is introduced to precise characterize the system state (including the tree and timings of all blocks mined), the adversary's potential actions, and the state transitions due to the adversarial action and the random block arrival processes. An optimal attack, called bait-and-switch, is proposed and proved to maximize the adversary's chance of violating block safety by "beating Nakamoto in the race". The exact probability of this violation is calculated for any confirmation depth using Markov chain analysis, offering fresh insights into the interplay of network delay, confirmation rules, and blockchain security.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View</title>
<link>https://arxiv.org/abs/2508.16261</link>
<guid>https://arxiv.org/abs/2508.16261</guid>
<content:encoded><![CDATA[
arXiv:2508.16261v1 Announce Type: new 
Abstract: Federated Learning (FL) enables training models across decentralized data silos while preserving client data privacy. Recent research has explored efficient methods for post-training large language models (LLMs) within FL to address computational and communication challenges. While existing approaches often rely on access to LLMs' internal information, which is frequently restricted in real-world scenarios, an inference-only paradigm (black-box FedLLM) has emerged to address these limitations. This paper presents a comprehensive survey on federated tuning for LLMs. We propose a taxonomy categorizing existing studies along two axes: model access-based and parameter efficiency-based optimization. We classify FedLLM approaches into white-box, gray-box, and black-box techniques, highlighting representative methods within each category. We review emerging research treating LLMs as black-box inference APIs and discuss promising directions and open challenges for future research.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Social Choice Analysis of Optimism's Retroactive Project Funding</title>
<link>https://arxiv.org/abs/2508.16285</link>
<guid>https://arxiv.org/abs/2508.16285</guid>
<content:encoded><![CDATA[
arXiv:2508.16285v1 Announce Type: new 
Abstract: The Optimism Retroactive Project Funding (RetroPGF) is a key initiative within the blockchain ecosystem that retroactively rewards projects deemed valuable to the Ethereum and Optimism communities. Managed by the Optimism Collective, a decentralized autonomous organization (DAO), RetroPGF represents a large-scale experiment in decentralized governance. Funding rewards are distributed in OP tokens, the native digital currency of the ecosystem. As of this writing, four funding rounds have been completed, collectively allocating over 100M dollars, with an additional 1.3B dollars reserved for future rounds. However, we identify significant shortcomings in the current allocation system, underscoring the need for improved governance mechanisms given the scale of funds involved.
  Leveraging computational social choice techniques and insights from multiagent systems, we propose improvements to the voting process by recommending the adoption of a utilitarian moving phantoms mechanism. This mechanism, originally introduced by Freeman et al. in 2019, is designed to enhance social welfare (using the L1 norm) while satisfying strategyproofness -- two key properties aligned with the application's governance requirements. Our analysis provides a formal framework for designing improved funding mechanisms for DAOs, contributing to the broader discourse on decentralized governance and public goods allocation.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrated Noise and Safety Management in UAM via A Unified Reinforcement Learning Framework</title>
<link>https://arxiv.org/abs/2508.16440</link>
<guid>https://arxiv.org/abs/2508.16440</guid>
<content:encoded><![CDATA[
arXiv:2508.16440v1 Announce Type: new 
Abstract: Urban Air Mobility (UAM) envisions the widespread use of small aerial vehicles to transform transportation in dense urban environments. However, UAM faces critical operational challenges, particularly the balance between minimizing noise exposure and maintaining safe separation in low-altitude urban airspace, two objectives that are often addressed separately. We propose a reinforcement learning (RL)-based air traffic management system that integrates both noise and safety considerations within a unified, decentralized framework. Under this scalable air traffic coordination solution, agents operate in a structured, multi-layered airspace and learn altitude adjustment policies to jointly manage noise impact and separation constraints. The system demonstrates strong performance across both objectives and reveals tradeoffs among separation, noise exposure, and energy efficiency under high traffic density. The findings highlight the potential of RL and multi-objective coordination strategies in enhancing the safety, quietness, and efficiency of UAM operations.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot</title>
<link>https://arxiv.org/abs/2508.16460</link>
<guid>https://arxiv.org/abs/2508.16460</guid>
<content:encoded><![CDATA[
arXiv:2508.16460v1 Announce Type: new 
Abstract: In this paper, we present the Swarming Without an Anchor (SWA) approach to state estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing ego-localization dropout, where individual agents are laterally stabilized using relative information only. We propose to fuse decentralized state estimation with robust mutual perception and onboard sensor data to maintain accurate state awareness despite intermittent localization failures. Thus, the relative information used to estimate the lateral state of UAVs enables the identification of the unambiguous state of UAVs with respect to the local constellation. The resulting behavior reaches velocity consensus, as this task can be referred to as the double integrator synchronization problem. All disturbances and performance degradations except a uniform translation drift of the swarm as a whole is attenuated which is enabling new opportunities in using tight cooperation for increasing reliability and resilience of multi-UAV systems. Simulations and real-world experiments validate the effectiveness of our approach, demonstrating its capability to sustain cohesive swarm behavior in challenging conditions of unreliable or unavailable primary localization.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair and efficient contribution valuation for vertical federated learning</title>
<link>https://arxiv.org/abs/2201.02658</link>
<guid>https://arxiv.org/abs/2201.02658</guid>
<content:encoded><![CDATA[
arXiv:2201.02658v2 Announce Type: replace 
Abstract: Federated learning is an emerging technology for training machine learning models across decentralized data sources without sharing data. Vertical federated learning, also known as feature-based federated learning, applies to scenarios where data sources have the same sample IDs but different feature sets. To ensure fairness among data owners, it is critical to objectively assess the contributions from different data sources and compensate the corresponding data owners accordingly. The Shapley value is a provably fair contribution valuation metric originating from cooperative game theory. However, its straight-forward computation requires extensively retraining a model on each potential combination of data sources, leading to prohibitively high communication and computation overheads due to multiple rounds of federated learning. To tackle this challenge, we propose a contribution valuation metric called vertical federated Shapley value (VerFedSV) based on the classic Shapley value. We show that VerFedSV not only satisfies many desirable properties of fairness but is also efficient to compute. Moreover, VerFedSV can be adapted to both synchronous and asynchronous vertical federated learning algorithms. Both theoretical analysis and extensive experimental results demonstrate the fairness, efficiency, adaptability, and effectiveness of VerFedSV.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding</title>
<link>https://arxiv.org/abs/2502.06440</link>
<guid>https://arxiv.org/abs/2502.06440</guid>
<content:encoded><![CDATA[
arXiv:2502.06440v2 Announce Type: replace 
Abstract: The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest and collision-free paths for multiple agents in a known, potentially obstacle-ridden environment. It is the core challenge for robotic deployments in large-scale logistics and transportation. Decentralized learning-based approaches have shown great potential for addressing the MAPF problems, offering more reactive and scalable solutions. However, existing learning-based MAPF methods usually rely on agents making decisions based on a limited field of view (FOV), resulting in short-sighted policies and inefficient cooperation in complex scenarios. There, a critical challenge is to achieve consensus on potential movements between agents based on limited observations and communications. To tackle this challenge, we introduce a new framework that applies sheaf theory to decentralized deep reinforcement learning, enabling agents to learn geometric cross-dependencies between each other through local consensus and utilize them for tightly cooperative decision-making. In particular, sheaf theory provides a mathematical proof of conditions for achieving global consensus through local observation. Inspired by this, we incorporate a neural network to approximately model the consensus in latent space based on sheaf theory and train it through self-supervised learning. During the task, in addition to normal features for MAPF as in previous works, each agent distributedly reasons about a learned consensus feature, leading to efficient cooperation on pathfinding and collision avoidance. As a result, our proposed method demonstrates significant improvements over state-of-the-art learning-based MAPF planners, especially in relatively large and complex scenarios, demonstrating its superiority over baselines in various simulations and real-world robot experiments. The code is available at https://github.com/marmotlab/SIGMA
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Partially Decentralized Multi-Agent Q-Learning via Digital Cousins for Wireless Networks</title>
<link>https://arxiv.org/abs/2503.05970</link>
<guid>https://arxiv.org/abs/2503.05970</guid>
<content:encoded><![CDATA[
arXiv:2503.05970v3 Announce Type: replace 
Abstract: Q-learning is a widely used reinforcement learning (RL) algorithm for optimizing wireless networks, but faces challenges with large state-spaces. Recently proposed multi-environment mixed Q-learning (MEMQ) algorithm addresses these challenges by employing multiple Q-learning algorithms across multiple synthetically generated, distinct but structurally related environments, so-called digital cousins. In this paper, we propose a novel multi-agent MEMQ (M-MEMQ) for cooperative decentralized wireless networks with multiple networked transmitters (TXs) and base stations (BSs). TXs do not have access to global information (joint state and actions). The new concept of coordinated and uncoordinated states is introduced. In uncoordinated states, TXs act independently to minimize their individual costs and update local Q-functions. In coordinated states, TXs use a Bayesian approach to estimate the joint state and update the joint Q-functions. The cost of information-sharing scales linearly with the number of TXs and is independent of the joint state-action space size. Several theoretical guarantees, including deterministic and probabilistic convergence, bounds on estimation error variance, and the probability of misdetecting the joint states, are given. Numerical simulations show that M-MEMQ outperforms several decentralized and centralized training with decentralized execution (CTDE) multi-agent RL algorithms by achieving 60% lower average policy error (APE), 40% faster convergence, 45% reduced runtime complexity, and 40% less sample complexity. Furthermore, M-MEMQ achieves comparable APE with significantly lower complexity than centralized methods. Simulations validate the theoretical analyses.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels</title>
<link>https://arxiv.org/abs/2504.05615</link>
<guid>https://arxiv.org/abs/2504.05615</guid>
<content:encoded><![CDATA[
arXiv:2504.05615v2 Announce Type: replace 
Abstract: Federated Learning (FL) is a powerful framework for privacy-preserving distributed learning. It enables multiple clients to collaboratively train a global model without sharing raw data. However, handling noisy labels in FL remains a major challenge due to heterogeneous data distributions and communication constraints, which can severely degrade model performance. To address this issue, we propose FedEFC, a novel method designed to tackle the impact of noisy labels in FL. FedEFC mitigates this issue through two key techniques: (1) prestopping, which prevents overfitting to mislabeled data by dynamically halting training at an optimal point, and (2) loss correction, which adjusts model updates to account for label noise. In particular, we develop an effective loss correction tailored to the unique challenges of FL, including data heterogeneity and decentralized training. Furthermore, we provide a theoretical analysis, leveraging the composite proper loss property, to demonstrate that the FL objective function under noisy label distributions can be aligned with the clean label distribution. Extensive experimental results validate the effectiveness of our approach, showing that it consistently outperforms existing FL techniques in mitigating the impact of noisy labels, particularly under heterogeneous data settings (e.g., achieving up to 41.64% relative performance improvement over the existing loss correction method).
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring</title>
<link>https://arxiv.org/abs/2508.15038</link>
<guid>https://arxiv.org/abs/2508.15038</guid>
<content:encoded><![CDATA[
arXiv:2508.15038v1 Announce Type: new 
Abstract: Wildlife field operations demand efficient parallel deployment methods to identify and interact with specific individuals, enabling simultaneous collective behavioral analysis, and health and safety interventions. Previous robotics solutions approach the problem from the herd perspective, or are manually operated and limited in scale. We propose a decentralized vision-based multi-quadrotor system for wildlife monitoring that is scalable, low-bandwidth, and sensor-minimal (single onboard RGB camera). Our approach enables robust identification and tracking of large species in their natural habitat. We develop novel vision-based coordination and tracking algorithms designed for dynamic, unstructured environments without reliance on centralized communication or control. We validate our system through real-world experiments, demonstrating reliable deployment in diverse field conditions.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Scalable Trie Building Algorithm for High-Throughput Phyloanalysis of Wafer-Scale Digital Evolution Experiments</title>
<link>https://arxiv.org/abs/2508.15074</link>
<guid>https://arxiv.org/abs/2508.15074</guid>
<content:encoded><![CDATA[
arXiv:2508.15074v1 Announce Type: new 
Abstract: Agent-based simulation platforms play a key role in enabling fast-to-run evolution experiments that can be precisely controlled and observed in detail. Availability of high-resolution snapshots of lineage ancestries from digital experiments, in particular, is key to investigations of evolvability and open-ended evolution, as well as in providing a validation testbed for bioinformatics method development. Ongoing advances in AI/ML hardware accelerator devices, such as the 850,000-processor Cerebras Wafer-Scale Engine (WSE), are poised to broaden the scope of evolutionary questions that can be investigated in silico. However, constraints in memory capacity and locality characteristic of these systems introduce difficulties in exhaustively tracking phylogenies at runtime. To overcome these challenges, recent work on hereditary stratigraphy algorithms has developed space-efficient genetic markers to facilitate fully decentralized estimation of relatedness among digital organisms. However, in existing work, compute time to reconstruct phylogenies from these genetic markers has proven a limiting factor in achieving large-scale phyloanalyses. Here, we detail an improved trie-building algorithm designed to produce reconstructions equivalent to existing approaches. For modestly-sized 10,000-tip trees, the proposed approach achieves a 300-fold speedup versus existing state-of-the-art. Finally, using 1 billion genome datasets drawn from WSE simulations encompassing 954 trillion replication events, we report a pair of large-scale phylogeny reconstruction trials, achieving end-to-end reconstruction times of 2.6 and 2.9 hours. In substantially improving reconstruction scaling and throughput, presented work establishes a key foundation to enable powerful high-throughput phyloanalysis techniques in large-scale digital evolution experiments.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning based on Self-Evolving Gaussian Clustering</title>
<link>https://arxiv.org/abs/2508.15393</link>
<guid>https://arxiv.org/abs/2508.15393</guid>
<content:encoded><![CDATA[
arXiv:2508.15393v1 Announce Type: new 
Abstract: In this study, we present an Evolving Fuzzy System within the context of Federated Learning, which adapts dynamically with the addition of new clusters and therefore does not require the number of clusters to be selected apriori. Unlike traditional methods, Federated Learning allows models to be trained locally on clients' devices, sharing only the model parameters with a central server instead of the data. Our method, implemented using PyTorch, was tested on clustering and classification tasks. The results show that our approach outperforms established classification methods on several well-known UCI datasets. While computationally intensive due to overlap condition calculations, the proposed method demonstrates significant advantages in decentralized data processing.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BadFU: Backdoor Federated Learning through Adversarial Machine Unlearning</title>
<link>https://arxiv.org/abs/2508.15541</link>
<guid>https://arxiv.org/abs/2508.15541</guid>
<content:encoded><![CDATA[
arXiv:2508.15541v1 Announce Type: new 
Abstract: Federated learning (FL) has been widely adopted as a decentralized training paradigm that enables multiple clients to collaboratively learn a shared model without exposing their local data. As concerns over data privacy and regulatory compliance grow, machine unlearning, which aims to remove the influence of specific data from trained models, has become increasingly important in the federated setting to meet legal, ethical, or user-driven demands. However, integrating unlearning into FL introduces new challenges and raises largely unexplored security risks. In particular, adversaries may exploit the unlearning process to compromise the integrity of the global model. In this paper, we present the first backdoor attack in the context of federated unlearning, demonstrating that an adversary can inject backdoors into the global model through seemingly legitimate unlearning requests. Specifically, we propose BadFU, an attack strategy where a malicious client uses both backdoor and camouflage samples to train the global model normally during the federated training process. Once the client requests unlearning of the camouflage samples, the global model transitions into a backdoored state. Extensive experiments under various FL frameworks and unlearning strategies validate the effectiveness of BadFU, revealing a critical vulnerability in current federated unlearning practices and underscoring the urgent need for more secure and robust federated unlearning mechanisms.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space</title>
<link>https://arxiv.org/abs/2508.15764</link>
<guid>https://arxiv.org/abs/2508.15764</guid>
<content:encoded><![CDATA[
arXiv:2508.15764v1 Announce Type: new 
Abstract: We address the problem of detecting adversarial attacks against cooperative multi-agent reinforcement learning with continuous action space. We propose a decentralized detector that relies solely on the local observations of the agents and makes use of a statistical characterization of the normal behavior of observable agents. The proposed detector utilizes deep neural networks to approximate the normal behavior of agents as parametric multivariate Gaussian distributions. Based on the predicted density functions, we define a normality score and provide a characterization of its mean and variance. This characterization allows us to employ a two-sided CUSUM procedure for detecting deviations of the normality score from its mean, serving as a detector of anomalous behavior in real-time. We evaluate our scheme on various multi-agent PettingZoo benchmarks against different state-of-the-art attack methods, and our results demonstrate the effectiveness of our method in detecting impactful adversarial attacks. Particularly, it outperforms the discrete counterpart by achieving AUC-ROC scores of over 0.95 against the most impactful attacks in all evaluated environments.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Causal Modelling of Cryptocurrency Price Movements Using Discretisation-Aware Bayesian Networks</title>
<link>https://arxiv.org/abs/2303.16148</link>
<guid>https://arxiv.org/abs/2303.16148</guid>
<content:encoded><![CDATA[
arXiv:2303.16148v2 Announce Type: replace-cross 
Abstract: This study identifies the key factors influencing the price movements of major cryptocurrencies, Bitcoin, Binance Coin, Ethereum, Litecoin, Ripple, and Tether, using Bayesian networks (BNs). This study addresses two key challenges: modelling price movements in highly volatile cryptocurrency markets and enhancing predictive performance through discretisation-aware Bayesian Networks. It analyses both macro-financial indicators (gold, oil, MSCI, S and P 500, USDX) and social media signals (tweet volume) as potential price drivers. Moreover, since discretisation is a critical step in the effectiveness of BNs, we implement a structured procedure to build 54 BNs models by combining three discretisation methods (equal interval, equal quantile, and k-means) with several bin counts. These models are evaluated using four metrics, including balanced accuracy, F1 score, area under the ROC curve and a composite score. Results show that equal interval with two bins consistently yields the best predictive performance. We also provide deeper insights into each network's structure through inference, sensitivity, and influence strength analyses. These analyses reveal distinct price-driving patterns for each cryptocurrency, underscore the importance of coin-specific analysis, and demonstrate the value of BNs for interpretable causal modelling in volatile cryptocurrency markets.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Learned Hash Table</title>
<link>https://arxiv.org/abs/2508.14239</link>
<guid>https://arxiv.org/abs/2508.14239</guid>
<content:encoded><![CDATA[
arXiv:2508.14239v1 Announce Type: new 
Abstract: Distributed Hash Tables (DHTs) are pivotal in numerous high-impact key-value applications built on distributed networked systems, offering a decentralized architecture that avoids single points of failure and improves data availability. Despite their widespread utility, DHTs face substantial challenges in handling range queries, which are crucial for applications such as LLM serving, distributed storage, databases, content delivery networks, and blockchains. To address this limitation, we present LEAD, a novel system incorporating learned models within DHT structures to significantly optimize range query performance. LEAD utilizes a recursive machine learning model to map and retrieve data across a distributed system while preserving the inherent order of data. LEAD includes the designs to minimize range query latency and message cost while maintaining high scalability and resilience to network churn. Our comprehensive evaluations, conducted in both testbed implementation and simulations, demonstrate that LEAD achieves tremendous advantages in system efficiency compared to existing range query methods in large-scale distributed systems, reducing query latency and message cost by 80% to 90%+. Furthermore, LEAD exhibits remarkable scalability and robustness against system churn, providing a robust, scalable solution for efficient data retrieval in distributed key-value systems.
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hierarchical Sharded Blockchain Balancing Performance and Availability</title>
<link>https://arxiv.org/abs/2508.14457</link>
<guid>https://arxiv.org/abs/2508.14457</guid>
<content:encoded><![CDATA[
arXiv:2508.14457v1 Announce Type: new 
Abstract: Blockchain networks offer decentralization, transparency, and immutability for managing critical data but encounter scalability problems as the number of network members and transaction issuers grows. Sharding is considered a promising solution to enhance blockchain scalability. However, most existing blockchain sharding techniques prioritize performance at the cost of availability (e.g., a failure in a few servers holding a shard leads to data unavailability). In this paper, we propose PyloChain, a hierarchical sharded blockchain that balances availability and performance. PyloChain consists of multiple lower-level local chains and one higher-level main chain. Each local chain speculatively executes local transactions to achieve high parallelism across multiple local chains. The main chain leverages a directed-acyclic-graph (DAG)-based mempool to guarantee local block availability and to enable efficient Byzantine Fault Tolerance (BFT) consensus to execute global (or cross-shard) transactions within a collocated sharding. PyloChain speculatively executes local transactions across multiple local chains to achieve high parallelism. In order to reduce the number of aborted local transactions, PyloChain applies a simple scheduling technique to handle global transactions in the main chain. PyloChain provides a fine-grained auditing mechanism to mitigate faulty higher-level members by externalizing main chain operations to lower-level local members. We implemented and evaluated PyloChain, demonstrating its performance scalability with 1.49x higher throughput and 2.63x faster latency compared to the state-of-the-art balanced hierarchical sharded blockchain.
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Markov Chain-based Model of Blockchain Radio Access Networks</title>
<link>https://arxiv.org/abs/2508.14519</link>
<guid>https://arxiv.org/abs/2508.14519</guid>
<content:encoded><![CDATA[
arXiv:2508.14519v1 Announce Type: new 
Abstract: Security has always been a priority, for researchers, service providers and network operators when it comes to radio access networks (RAN). One wireless access approach that has captured attention is blockchain enabled RAN (B-RAN) due to its secure nature. This research introduces a framework that integrates blockchain technology into RAN while also addressing the limitations of state-of-the-art models. The proposed framework utilizes queuing and Markov chain theory to model the aspects of B-RAN. An extensive evaluation of the models performance is provided, including an analysis of timing factors and a focused assessment of its security aspects. The results demonstrate reduced latency and comparable security making the presented framework suitable for diverse application scenarios.
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Boosting Payment Channel Network Liquidity with Topology Optimization and Transaction Selection</title>
<link>https://arxiv.org/abs/2508.14524</link>
<guid>https://arxiv.org/abs/2508.14524</guid>
<content:encoded><![CDATA[
arXiv:2508.14524v1 Announce Type: new 
Abstract: Payment channel networks (PCNs) are a promising technology that alleviates blockchain scalability by shifting the transaction load from the blockchain to the PCN. Nevertheless, the network topology has to be carefully designed to maximise the transaction throughput in PCNs. Additionally, users in PCNs also have to make optimal decisions on which transactions to forward and which to reject to prolong the lifetime of their channels. In this work, we consider an input sequence of transactions over $p$ parties. Each transaction consists of a transaction size, source, and target, and can be either accepted or rejected (entailing a cost). The goal is to design a PCN topology among the $p$ cooperating parties, along with the channel capacities, and then output a decision for each transaction in the sequence to minimise the cost of creating and augmenting channels, as well as the cost of rejecting transactions. Our main contribution is an $\mathcal{O}(p)$ approximation algorithm for the problem with $p$ parties. We further show that with some assumptions on the distribution of transactions, we can reduce the approximation ratio to $\mathcal{O}(\sqrt{p})$. We complement our theoretical analysis with an empirical study of our assumptions and approach in the context of the Lightning Network.
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DOPA: Stealthy and Generalizable Backdoor Attacks from a Single Client under Challenging Federated Constraints</title>
<link>https://arxiv.org/abs/2508.14530</link>
<guid>https://arxiv.org/abs/2508.14530</guid>
<content:encoded><![CDATA[
arXiv:2508.14530v1 Announce Type: new 
Abstract: Federated Learning (FL) is increasingly adopted for privacy-preserving collaborative training, but its decentralized nature makes it particularly susceptible to backdoor attacks. Existing attack methods, however, often rely on idealized assumptions and fail to remain effective under real-world constraints, such as limited attacker control, non-IID data distributions, and the presence of diverse defense mechanisms. To address this gap, we propose DOPA (Divergent Optimization Path Attack), a novel framework that simulates heterogeneous local training dynamics and seeks consensus across divergent optimization trajectories to craft universally effective and stealthy backdoor triggers. By leveraging consistency signals across simulated paths to guide optimization, DOPA overcomes the challenge of heterogeneity-induced instability and achieves practical attack viability under stringent federated constraints. We validate DOPA on a comprehensive suite of 12 defense strategies, two model architectures (ResNet18/VGG16), two datasets (CIFAR-10/TinyImageNet), and both mild and extreme non-IID settings. Despite operating under a single-client, black-box, and sparsely participating threat model, DOPA consistently achieves high attack success, minimal accuracy degradation, low runtime, and long-term persistence. These results demonstrate a more practical attack paradigm, offering new perspectives for designing robust defense strategies in federated learning systems
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Vision-Based Coverage Optimization in Mobile Wireless Sensor Networks: A Multi-Agent Deep Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2508.14676</link>
<guid>https://arxiv.org/abs/2508.14676</guid>
<content:encoded><![CDATA[
arXiv:2508.14676v1 Announce Type: new 
Abstract: Traditional Wireless Sensor Networks (WSNs) typically rely on pre-analysis of the target area, network size, and sensor coverage to determine initial deployment. This often results in significant overlap to ensure continued network operation despite sensor energy depletion. With the emergence of Mobile Wireless Sensor Networks (MWSNs), issues such as sensor failure and static coverage limitations can be more effectively addressed through mobility. This paper proposes a novel deployment strategy in which mobile sensors autonomously position themselves to maximize area coverage, eliminating the need for predefined policies. A live camera system, combined with deep reinforcement learning (DRL), monitors the network by detecting sensor LED indicators and evaluating real-time coverage. Rewards based on coverage efficiency and sensor movement are computed at each learning step and shared across the network through a Multi-Agent Reinforcement Learning (MARL) framework, enabling decentralized, cooperative sensor control. Key contributions include a vision-based, low-cost coverage evaluation method; a scalable MARL-DRL framework for autonomous deployment; and a self-reconfigurable system that adjusts sensor positioning in response to energy depletion. Compared to traditional distance-based localization, the proposed method achieves a 26.5% improvement in coverage, a 32% reduction in energy consumption, and a 22% decrease in redundancy, extending network lifetime by 45%. This approach significantly enhances adaptability, energy efficiency, and robustness in MWSNs, offering a practical deployment solution within the IoT framework.
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy-Efficient Routing Algorithm for Wireless Sensor Networks: A Multi-Agent Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2508.14679</link>
<guid>https://arxiv.org/abs/2508.14679</guid>
<content:encoded><![CDATA[
arXiv:2508.14679v1 Announce Type: new 
Abstract: Efficient energy management is essential in Wireless Sensor Networks (WSNs) to extend network lifetime and ensure reliable data transmission. This paper presents a novel method using reinforcement learning-based cluster-head selection and a hybrid multi-hop routing algorithm, which leverages Q-learning within a multi-agent system to dynamically adapt transmission paths based on the energy distribution across sensor nodes. Each sensor node is modeled as an autonomous agent that observes local state parameters, such as residual energy, distance to sink, hop count, and hotspot proximity, and selects routing actions that maximize long-term energy efficiency. After computing the optimal paths, each sensor aggregates sensed data and forwards it through intermediate nodes to a selected transmitter node, chosen based on the highest remaining State of Charge (SoC), thereby avoiding premature node depletion. To promote efficient learning, a carefully designed reward function incentivizes balanced load distribution, hotspot avoidance, and energy-aware forwarding while maintaining signal quality. The learning process occurs either in a decentralized manner or via a cloud-based controller that offloads computation in large-scale deployments. Moreover, the RL-driven routing decisions are fused with classical graph-based methods, Minimum Energy Routing Algorithm (MERA) and Minimum Spanning Tree (MST), to optimize energy consumption and load balancing. Simulations confirm that the proposed approach significantly improves node survival rate, reduces SoC variance, and enhances network resilience, making it a scalable and adaptive solution for energy-constrained WSNs in dynamic sensor deployments and IoT applications.
]]></content:encoded>
<pubDate>Thu, 21 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FLAIR: Feedback Learning for Adaptive Information Retrieval</title>
<link>https://arxiv.org/abs/2508.13390</link>
<guid>https://arxiv.org/abs/2508.13390</guid>
<content:encoded><![CDATA[
arXiv:2508.13390v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have driven the adoption of copilots in complex technical scenarios, underscoring the growing need for specialized information retrieval solutions. In this paper, we introduce FLAIR, a lightweight, feedback learning framework that adapts copilot systems' retrieval strategies by integrating domain-specific expert feedback. FLAIR operates in two stages: an offline phase obtains indicators from (1) user feedback and (2) questions synthesized from documentation, storing these indicators in a decentralized manner. An online phase then employs a two-track ranking mechanism to combine raw similarity scores with the collected indicators. This iterative setup refines retrieval performance for any query. Extensive real-world evaluations of FLAIR demonstrate significant performance gains on both previously seen and unseen queries, surpassing state-of-the-art approaches. The system has been successfully integrated into Copilot DECO, serving thousands of users at Microsoft, demonstrating its scalability and effectiveness in operational environments.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms</title>
<link>https://arxiv.org/abs/2508.13459</link>
<guid>https://arxiv.org/abs/2508.13459</guid>
<content:encoded><![CDATA[
arXiv:2508.13459v1 Announce Type: new 
Abstract: The ``Last Mile Challenge'' has long been considered an important, yet unsolved, challenge for autonomous vehicles, public service robots, and delivery robots. A central issue in this challenge is the ability of robots to navigate constrained and cluttered environments (e.g., doorways, hallways, corridor intersections), often while competing for space with other robots and humans. We refer to these environments as ``Social Mini-Games'' (SMGs). SMGs are tightly coupled, high-agency interactions that arise within general multi-robot navigation (MRN) scenarios. They are identified through certain distinct characteristics and require specialized metrics to evaluate them. Traditional navigation approaches designed for MRN do not perform well in SMGs, which has led to focused research on dedicated SMG solvers (navigation methods specialized to navigate in SMGs), which has flourished in recent years. However, publications on SMG navigation research make different assumptions (on centralized versus decentralized, observability, communication, cooperation, etc.), and have different objective functions (safety versus liveness). These assumptions and objectives are sometimes implicitly assumed or described informally. This makes it difficult to establish appropriate baselines for comparison in research papers, as well as making it difficult for practitioners to find the papers relevant to their concrete application. Such ad-hoc representation of the field also presents a barrier to new researchers wanting to start research in this area. SMG navigation research requires its own taxonomy, definitions, and evaluation protocols to guide effective research moving forward. This survey is the first to catalog SMG solvers using a well-defined and unified taxonomy and to classify existing methods accordingly.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Scalar Selection in Elliptic Curve Cryptography Using Differential Evolution for Enhanced Security</title>
<link>https://arxiv.org/abs/2508.13520</link>
<guid>https://arxiv.org/abs/2508.13520</guid>
<content:encoded><![CDATA[
arXiv:2508.13520v1 Announce Type: new 
Abstract: Elliptic Curve Cryptography (ECC) is a fundamental component of modern public-key cryptosystems that enable efficient and secure digital signatures, key exchanges, and encryption. Its core operation, scalar multiplication, denoted as $k \cdot P$, where $P$ is a base point and $k$ is a private scalar, relies heavily on the secrecy and unpredictability of $k$. Conventionally, $k$ is selected using user input or pseudorandom number generators. However, in resource-constrained environments with weak entropy sources, these approaches may yield low-entropy or biased scalars, increasing susceptibility to side-channel and key recovery attacks. To mitigate these vulnerabilities, we introduce an optimization-driven scalar generation method that explicitly maximizes bit-level entropy. Our approach uses differential evolution (DE), a population-based metaheuristic algorithm, to search for scalars whose binary representations exhibit maximal entropy, defined by an even and statistically uniform distribution of ones and zeros. This reformulation of scalar selection as an entropy-optimization problem enhances resistance to entropy-based cryptanalytic techniques and improves overall unpredictability. Experimental results demonstrate that DE-optimized scalars achieve entropy significantly higher than conventionally generated scalars. The proposed method can be integrated into existing ECC-based protocols, offering a deterministic, tunable alternative to traditional randomness, ideal for applications in blockchain, secure messaging, IoT, and other resource-constrained environments.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client Models</title>
<link>https://arxiv.org/abs/2508.13625</link>
<guid>https://arxiv.org/abs/2508.13625</guid>
<content:encoded><![CDATA[
arXiv:2508.13625v1 Announce Type: new 
Abstract: Large models, renowned for superior performance, outperform smaller ones even without billion-parameter scales. While mobile network servers have ample computational resources to support larger models than client devices, privacy constraints prevent clients from directly sharing their raw data. Federated Learning (FL) enables decentralized clients to collaboratively train a shared model by exchanging model parameters instead of transmitting raw data. Yet, it requires a uniform model architecture and multiple communication rounds, which neglect resource heterogeneity, impose heavy computational demands on clients, and increase communication overhead. To address these challenges, we propose FedOL, to construct a larger and more comprehensive server model in one-shot settings (i.e., in a single communication round). Instead of model parameter sharing, FedOL employs knowledge distillation, where clients only exchange model prediction outputs on an unlabeled public dataset. This reduces communication overhead by transmitting compact predictions instead of full model weights and enables model customization by allowing heterogeneous model architectures. A key challenge in this setting is that client predictions may be biased due to skewed local data distributions, and the lack of ground-truth labels in the public dataset further complicates reliable learning. To mitigate these issues, FedOL introduces a specialized objective function that iteratively refines pseudo-labels and the server model, improving learning reliability. To complement this, FedOL incorporates a tailored pseudo-label generation and knowledge distillation strategy that effectively integrates diverse knowledge. Simulation results show that FedOL significantly outperforms existing baselines, offering a cost-effective solution for mobile networks where clients possess valuable private data but limited computational resources.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture</title>
<link>https://arxiv.org/abs/2508.13713</link>
<guid>https://arxiv.org/abs/2508.13713</guid>
<content:encoded><![CDATA[
arXiv:2508.13713v1 Announce Type: new 
Abstract: Every day, a large amount of educational content is uploaded online across different areas, including agriculture and gardening. When these videos or materials are grouped meaningfully, they can make learning easier and more effective. One promising way to organize and enrich such content is through the Metaverse, which allows users to explore educational experiences in an interactive and immersive environment. However, searching for relevant Metaverse scenarios and finding those matching users' interests remains a challenging task. A first step in this direction has been done recently, but existing datasets are small and not sufficient for training advanced models. In this work, we make two main contributions: first, we introduce a new dataset containing 457 agricultural-themed virtual museums (AgriMuseums), each enriched with textual descriptions; and second, we propose a hierarchical vision-language model to represent and retrieve relevant AgriMuseums using natural language queries. In our experimental setting, the proposed method achieves up to about 62\% R@1 and 78\% MRR, confirming its effectiveness, and it also leads to improvements on existing benchmarks by up to 6\% R@1 and 11\% MRR. Moreover, an extensive evaluation validates our design choices. Code and dataset are available at https://github.com/aliabdari/Agricultural_Metaverse_Retrieval .
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web</title>
<link>https://arxiv.org/abs/2508.13787</link>
<guid>https://arxiv.org/abs/2508.13787</guid>
<content:encoded><![CDATA[
arXiv:2508.13787v1 Announce Type: new 
Abstract: The rapid development of large language models (LLMs) has significantly propelled the development of artificial intelligence (AI) agents, which are increasingly evolving into diverse autonomous entities, advancing the LLM-based multi-agent systems (LaMAS). However, current agentic ecosystems remain fragmented and closed. Establishing an interconnected and scalable paradigm for Agentic AI has become a critical prerequisite. Although Agentic Web proposes an open architecture to break the ecosystem barriers, its implementation still faces core challenges such as privacy protection, data management, and value measurement. Existing centralized or semi-centralized paradigms suffer from inherent limitations, making them inadequate for supporting large-scale, heterogeneous, and cross-domain autonomous interactions. To address these challenges, this paper introduces the blockchain-enabled trustworthy Agentic Web (BetaWeb). By leveraging the inherent strengths of blockchain, BetaWeb not only offers a trustworthy and scalable infrastructure for LaMAS but also has the potential to advance the Web paradigm from Web3 (centered on data ownership) towards Web3.5, which emphasizes ownership of agent capabilities and the monetization of intelligence. Beyond a systematic examination of the BetaWeb framework, this paper presents a five-stage evolutionary roadmap, outlining the path of LaMAS from passive execution to advanced collaboration and autonomous governance. We also conduct a comparative analysis of existing products and discuss key challenges of BetaWeb from multiple perspectives. Ultimately, we argue that deep integration between blockchain and LaMAS can lay the foundation for a resilient, trustworthy, and sustainably incentivized digital ecosystem. A summary of the enabling technologies for each stage is available at https://github.com/MatZaharia/BetaWeb.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Federated Learning with Adaptive Number of Participants</title>
<link>https://arxiv.org/abs/2508.13803</link>
<guid>https://arxiv.org/abs/2508.13803</guid>
<content:encoded><![CDATA[
arXiv:2508.13803v1 Announce Type: new 
Abstract: Rapid scaling of deep learning models has enabled performance gains across domains, yet it introduced several challenges. Federated Learning (FL) has emerged as a promising framework to address these concerns by enabling decentralized training. Nevertheless, communication efficiency remains a key bottleneck in FL, particularly under heterogeneous and dynamic client participation. Existing methods, such as FedAvg and FedProx, or other approaches, including client selection strategies, attempt to mitigate communication costs. However, the problem of choosing the number of clients in a training round remains extremely underexplored. We introduce Intelligent Selection of Participants (ISP), an adaptive mechanism that dynamically determines the optimal number of clients per round to enhance communication efficiency without compromising model accuracy. We validate the effectiveness of ISP across diverse setups, including vision transformers, real-world ECG classification, and training with gradient compression. Our results show consistent communication savings of up to 30\% without losing the final quality. Applying ISP to different real-world ECG classification setups highlighted the selection of the number of clients as a separate task of federated learning.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Taming Unbalanced Training Workloads in Deep Learning with Partial Collective Operations</title>
<link>https://arxiv.org/abs/1908.04207</link>
<guid>https://arxiv.org/abs/1908.04207</guid>
<content:encoded><![CDATA[
arXiv:1908.04207v4 Announce Type: replace 
Abstract: Load imbalance pervasively exists in distributed deep learning training systems, either caused by the inherent imbalance in learned tasks or by the system itself. Traditional synchronous Stochastic Gradient Descent (SGD) achieves good accuracy for a wide variety of tasks, but relies on global synchronization to accumulate the gradients at every training step. In this paper, we propose eager-SGD, which relaxes the global synchronization for decentralized accumulation. To implement eager-SGD, we propose to use two partial collectives: solo and majority. With solo allreduce, the faster processes contribute their gradients eagerly without waiting for the slower processes, whereas with majority allreduce, at least half of the participants must contribute gradients before continuing, all without using a central parameter server. We theoretically prove the convergence of the algorithms and describe the partial collectives in detail. Experimental results on load-imbalanced environments (CIFAR-10, ImageNet, and UCF101 datasets) show that eager-SGD achieves 1.27x speedup over the state-of-the-art synchronous SGD, without losing accuracy.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Breaking (Global) Barriers in Parallel Stochastic Optimization with Wait-Avoiding Group Averaging</title>
<link>https://arxiv.org/abs/2005.00124</link>
<guid>https://arxiv.org/abs/2005.00124</guid>
<content:encoded><![CDATA[
arXiv:2005.00124v4 Announce Type: replace 
Abstract: Deep learning at scale is dominated by communication time. Distributing samples across nodes usually yields the best performance, but poses scaling challenges due to global information dissemination and load imbalance across uneven sample lengths. State-of-the-art decentralized optimizers mitigate the problem, but require more iterations to achieve the same accuracy as their globally-communicating counterparts. We present Wait-Avoiding Group Model Averaging (WAGMA) SGD, a wait-avoiding stochastic optimizer that reduces global communication via subgroup weight exchange. The key insight is a combination of algorithmic changes to the averaging scheme and the use of a group allreduce operation. We prove the convergence of WAGMA-SGD, and empirically show that it retains convergence rates similar to Allreduce-SGD. For evaluation, we train ResNet-50 on ImageNet; Transformer for machine translation; and deep reinforcement learning for navigation at scale. Compared with state-of-the-art decentralized SGD variants, WAGMA-SGD significantly improves training throughput (e.g., 2.1x on 1,024 GPUs for reinforcement learning), and achieves the fastest time-to-solution (e.g., the highest score using the shortest training time for Transformer).
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reclaiming Constitutional Authority of Algorithmic Power</title>
<link>https://arxiv.org/abs/2508.11699</link>
<guid>https://arxiv.org/abs/2508.11699</guid>
<content:encoded><![CDATA[
arXiv:2508.11699v1 Announce Type: new 
Abstract: Whether and how to govern AI is no longer a question of technical regulation. It is a question of constitutional authority. Across jurisdictions, algorithmic systems now perform functions once reserved to public institutions: allocating welfare, determining legal status, mediating access to housing, employment, and healthcare. These are not merely administrative operations. They are acts of rule. Yet the dominant models of AI governance fail to confront this reality. The European approach centers on rights-based oversight, presenting its regulatory framework as a principled defense of human dignity. The American model relies on decentralized experimentation, treating fragmentation as a proxy for democratic legitimacy. Both, in different ways, evade the structural question: who authorizes algorithmic power, through what institutions, and on what terms. This Article offers an alternative. Drawing from early modern Reformed political thought, it reconstructs a constitutional framework grounded in covenantal authority and the right of lawful resistance. It argues that algorithmic governance must rest on three principles. First, that all public power must be lawfully delegated through participatory authorization. Second, that authority must be structured across representative communities with the standing to consent, contest, or refuse. Third, that individuals retain a constitutional right to resist systems that impose orthodoxy or erode the domain of conscience. These principles are then operationalized through doctrinal analysis of federalism, nondelegation, compelled speech, and structural accountability. On this view, the legitimacy of algorithmic governance turns not on procedural safeguards or policy design, but on whether it reflects a constitutional order in which power is authorized by the governed, constrained by law, and answerable to those it affects.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2508.11706</link>
<guid>https://arxiv.org/abs/2508.11706</guid>
<content:encoded><![CDATA[
arXiv:2508.11706v1 Announce Type: new 
Abstract: The Centralized Training with Decentralized Execution (CTDE) paradigm has gained significant attention in multi-agent reinforcement learning (MARL) and is the foundation of many recent algorithms. However, decentralized policies operate under partial observability and often yield suboptimal performance compared to centralized policies, while fully centralized approaches typically face scalability challenges as the number of agents increases.
  We propose Centralized Permutation Equivariant (CPE) learning, a centralized training and execution framework that employs a fully centralized policy to overcome these limitations. Our approach leverages a novel permutation equivariant architecture, Global-Local Permutation Equivariant (GLPE) networks, that is lightweight, scalable, and easy to implement. Experiments show that CPE integrates seamlessly with both value decomposition and actor-critic methods, substantially improving the performance of standard CTDE algorithms across cooperative benchmarks including MPE, SMAC, and RWARE, and matching the performance of state-of-the-art RWARE implementations.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing Sideways: Thwarting Lateral Movement by Implementing Active Directory Tiering</title>
<link>https://arxiv.org/abs/2508.11812</link>
<guid>https://arxiv.org/abs/2508.11812</guid>
<content:encoded><![CDATA[
arXiv:2508.11812v1 Announce Type: new 
Abstract: The advancement of computing equipment and the advances in services over the Internet has allowed corporations, higher education, and many other organizations to pursue the shared computing network environment. A requirement for shared computing environments is a centralized identity system to authenticate and authorize user access. An organization's digital identity plane is a prime target for cyber threat actors. When compromised, identities can be exploited to steal credentials, create unauthorized accounts, and manipulate permissions-enabling attackers to gain control of the network and undermine its confidentiality, availability, and integrity. Cybercrime losses reached a record of 16.6 B in the United States in 2024. For organizations using Microsoft software, Active Directory is the on-premises identity system of choice. In this article, we examine the challenge of security compromises in Active Directory (AD) environments and present effective strategies to prevent credential theft and limit lateral movement by threat actors. Our proposed approaches aim to confine the movement of compromised credentials, preventing significant privilege escalation and theft. We argue that through our illustration of real-world scenarios, tiering can halt lateral movement and advanced cyber-attacks, thus reducing ransom escalation. Our work bridges a gap in existing literature by combining technical guidelines with theoretical arguments in support of tiering, positioning it as a vital component of modern cybersecurity strategy even though it cannot function in isolation. As the hardware advances and the cloud sourced services along with AI is advancing with unprecedented speed, we think it is important for security experts and the business to work together and start designing and developing software and frameworks to classify devices automatically and accurately within the tiered structure.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Balancing Sparsity with Reliable Connectivity in Distributed Network Design with Random K-out Graphs</title>
<link>https://arxiv.org/abs/2508.11863</link>
<guid>https://arxiv.org/abs/2508.11863</guid>
<content:encoded><![CDATA[
arXiv:2508.11863v1 Announce Type: new 
Abstract: In several applications in distributed systems, an important design criterion is ensuring that the network is sparse, i.e., does not contain too many edges, while achieving reliable connectivity. Sparsity ensures communication overhead remains low, while reliable connectivity is tied to reliable communication and inference on decentralized data reservoirs and computational resources. A class of network models called random K-out graphs appear widely as a heuristic to balance connectivity and sparsity, especially in settings with limited trust, e.g., privacy-preserving aggregation of networked data in which networks are deployed. However, several questions remain regarding how to choose network parameters in response to different operational requirements, including the need to go beyond asymptotic results and the ability to model the stochastic and adversarial environments. To address this gap, we present theorems to inform the choice of network parameters that guarantee reliable connectivity in regimes where nodes can be finite or unreliable. We first derive upper and lower bounds for probability of connectivity in random K-out graphs when the number of nodes is finite. Next, we analyze the property of r-robustness, a stronger notion than connectivity that enables resilient consensus in the presence of malicious nodes. Finally, motivated by aggregation mechanisms based on pairwise masking, we model and analyze the impact of a subset of adversarial nodes, modeled as deletions, on connectivity and giant component size - metrics that are closely tied to privacy guarantees. Together, our results pave the way for end-to-end performance guarantees for a suite of algorithms for reliable inference on networks.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing</title>
<link>https://arxiv.org/abs/2508.12021</link>
<guid>https://arxiv.org/abs/2508.12021</guid>
<content:encoded><![CDATA[
arXiv:2508.12021v1 Announce Type: new 
Abstract: Unsupervised federated learning (UFL) has gained attention as a privacy-preserving, decentralized machine learning approach that eliminates the need for labor-intensive data labeling. However, UFL faces several challenges in practical applications: (1) non-independent and identically distributed (non-iid) data distribution across devices, (2) expensive computational and communication costs at the edge, and (3) vulnerability to communication noise. Previous UFL approaches have relied on deep neural networks (NN), which introduce substantial overhead in both computation and communication. In this paper, we propose FedUHD, the first UFL framework based on Hyperdimensional Computing (HDC). HDC is a brain-inspired computing scheme with lightweight training and inference operations, much smaller model size, and robustness to communication noise. FedUHD introduces two novel HDC-based designs to improve UFL performance. On the client side, a kNN-based cluster hypervector removal method addresses non-iid data samples by eliminating detrimental outliers. On the server side, a weighted HDC aggregation technique balances the non-iid data distribution across clients. Our experiments demonstrate that FedUHD achieves up to 173.6x and 612.7x better speedup and energy efficiency, respectively, in training, up to 271x lower communication cost, and 15.50% higher accuracy on average across diverse settings, along with superior robustness to various types of noise compared to state-of-the-art NN-based UFL approaches.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fairness Regularization in Federated Learning</title>
<link>https://arxiv.org/abs/2508.12042</link>
<guid>https://arxiv.org/abs/2508.12042</guid>
<content:encoded><![CDATA[
arXiv:2508.12042v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a vital paradigm in modern machine learning that enables collaborative training across decentralized data sources without exchanging raw data. This approach not only addresses privacy concerns but also allows access to overall substantially larger and potentially more diverse datasets, without the need for centralized storage or hardware resources. However, heterogeneity in client data may cause certain clients to have disproportionate impacts on the global model, leading to disparities in the clients' performances. Fairness, therefore, becomes a crucial concern in FL and can be addressed in various ways. However, the effectiveness of existing fairness-aware methods, particularly in heterogeneous data settings, remains unclear, and the relationships between different approaches are not well understood. In this work, we focus on performance equitable fairness, which aims to minimize differences in performance across clients. We restrict our study to fairness-aware methods that explicitly regularize client losses, evaluating both existing and newly proposed approaches. We identify and theoretically explain connections between the investigated fairness methods, and empirically show that FairGrad (approximate) and FairGrad* (exact) (two variants of a gradient variance regularization method introduced here for performance equitable fairness) improve both fairness and overall model performance in heterogeneous data settings.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAPF-World: Action World Model for Multi-Agent Path Finding</title>
<link>https://arxiv.org/abs/2508.12087</link>
<guid>https://arxiv.org/abs/2508.12087</guid>
<content:encoded><![CDATA[
arXiv:2508.12087v1 Announce Type: new 
Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free paths from the designated start locations to goal positions for multiple agents. It underlies a variety of real-world tasks, including multi-robot coordination, robot-assisted logistics, and social navigation. Recent decentralized learnable solvers have shown great promise for large-scale MAPF, especially when leveraging foundation models and large datasets. However, these agents are reactive policy models and exhibit limited modeling of environmental temporal dynamics and inter-agent dependencies, resulting in performance degradation in complex, long-term planning scenarios. To address these limitations, we propose MAPF-World, an autoregressive action world model for MAPF that unifies situation understanding and action generation, guiding decisions beyond immediate local observations. It improves situational awareness by explicitly modeling environmental dynamics, including spatial features and temporal dependencies, through future state and actions prediction. By incorporating these predicted futures, MAPF-World enables more informed, coordinated, and far-sighted decision-making, especially in complex multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an automatic map generator grounded in real-world scenarios, capturing practical map layouts for training and evaluating MAPF solvers. Extensive experiments demonstrate that MAPF-World outperforms state-of-the-art learnable solvers, showcasing superior zero-shot generalization to out-of-distribution cases. Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced data.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ethereum Crypto Wallets under Address Poisoning: How Usable and Secure Are They?</title>
<link>https://arxiv.org/abs/2508.12107</link>
<guid>https://arxiv.org/abs/2508.12107</guid>
<content:encoded><![CDATA[
arXiv:2508.12107v1 Announce Type: new 
Abstract: Blockchain address poisoning is an emerging phishing attack that crafts "similar-looking" transfer records in the victim's transaction history, which aims to deceive victims and lure them into mistakenly transferring funds to the attacker. Recent works have shown that millions of Ethereum users were targeted and lost over 100 million US dollars.
  Ethereum crypto wallets, serving users in browsing transaction history and initiating transactions to transfer funds, play a central role in deploying countermeasures to mitigate the address poisoning attack. However, whether they have done so remains an open question. To fill the research void, in this paper, we design experiments to simulate address poisoning attacks and systematically evaluate the usability and security of 53 popular Ethereum crypto wallets. Our evaluation shows that there exist communication failures between 12 wallets and their transaction activity provider, which renders them unable to download the users' transaction history. Besides, our evaluation also shows that 16 wallets pose a high risk to their users due to displaying fake token phishing transfers. Moreover, our further analysis suggests that most wallets rely on transaction activity providers to filter out phishing transfers. However, their phishing detection capability varies. Finally, we found that only three wallets throw an explicit warning message when users attempt to transfer to the phishing address, implying a significant gap within the broader Ethereum crypto wallet community in protecting users from address poisoning attacks.
  Overall, our work shows that more efforts are needed by the Ethereum crypto wallet developer community to achieve the highest usability and security standard. Our bug reports have been acknowledged by the developer community, who are currently developing mitigation solutions.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Substituting Proof of Work in Blockchain with Training-Verified Collaborative Model Computation</title>
<link>https://arxiv.org/abs/2508.12138</link>
<guid>https://arxiv.org/abs/2508.12138</guid>
<content:encoded><![CDATA[
arXiv:2508.12138v1 Announce Type: new 
Abstract: Bitcoin's Proof of Work (PoW) mechanism, while central to achieving decentralized consensus, has long been criticized for excessive energy use and hardware inefficiencies \cite{devries2018bitcoin, truby2018decarbonizing}. This paper introduces a hybrid architecture that replaces Bitcoin's traditional PoW with a centralized, cloud-based collaborative training framework. In this model, miners contribute computing resources to train segments of horizontally scaled machine learning models on preprocessed datasets, ensuring privacy and generating meaningful outputs \cite{li2017securing}. A central server evaluates contributions using two metrics: number of parameters trained and reduction in model loss during each cycle. At the end of every cycle, a weighted lottery selects the winning miner, who receives a digitally signed certificate. This certificate serves as a verifiable substitute for PoW and grants the right to append a block to the blockchain \cite{nakamoto2008bitcoin}. By integrating digital signatures and SHA-256 hashing \cite{nist2015sha}, the system preserves blockchain integrity while redirecting energy toward productive computation. The proposed approach addresses the sustainability concerns of traditional mining by converting resource expenditure into socially valuable work, aligning security incentives with real-world computational progress.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Fomo3D to Lottery DAPP: Analysis of Ethereum-Based Gambling Applications</title>
<link>https://arxiv.org/abs/2508.12303</link>
<guid>https://arxiv.org/abs/2508.12303</guid>
<content:encoded><![CDATA[
arXiv:2508.12303v1 Announce Type: new 
Abstract: As blockchain technology advances, Ethereum based gambling decentralized applications (DApps) represent a new paradigm in online gambling. This paper examines the concepts, principles, implementation, and prospects of Ethereum based gambling DApps. First, we outline the concept and operational principles of gambling DApps. These DApps are blockchain based online lottery platforms. They utilize smart contracts to manage the entire lottery process, including issuance, betting, drawing, and prize distribution. Being decentralized, lottery DApps operate without central oversight, unlike traditional lotteries. This ensures fairness and eliminates control by any single entity. Automated smart contract execution further reduces management costs, increases profitability, and enhances game transparency and credibility. Next, we analyze an existing Ethereum based gambling DApp, detailing its technical principles, implementation, operational status, vulnerabilities, and potential solutions. We then elaborate on the implementation of lottery DApps. Smart contracts automate the entire lottery process including betting, drawing, and prize distribution. Although developing lottery DApps requires technical expertise, the expanding Ethereum ecosystem provides growing tools and frameworks, lowering development barriers. Finally, we discuss current limitations and prospects of lottery DApps. As blockchain technology and smart contracts evolve, lottery DApps are positioned to significantly transform the online lottery industry. Advantages like decentralization, automation, and transparency will likely drive broader future adoption.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Cross-Modal Style-Aware Prompt Generation</title>
<link>https://arxiv.org/abs/2508.12399</link>
<guid>https://arxiv.org/abs/2508.12399</guid>
<content:encoded><![CDATA[
arXiv:2508.12399v1 Announce Type: new 
Abstract: Prompt learning has propelled vision-language models like CLIP to excel in diverse tasks, making them ideal for federated learning due to computational efficiency. However, conventional approaches that rely solely on final-layer features miss out on rich multi-scale visual cues and domain-specific style variations in decentralized client data. To bridge this gap, we introduce FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework harnesses low, mid, and high-level features from CLIP's vision encoder alongside client-specific style indicators derived from batch-level statistics. By merging intricate visual details with textual context, FedCSAP produces robust, context-aware prompt tokens that are both distinct and non-redundant, thereby boosting generalization across seen and unseen classes. Operating within a federated learning paradigm, our approach ensures data privacy through local training and global aggregation, adeptly handling non-IID class distributions and diverse domain-specific styles. Comprehensive experiments on multiple image classification datasets confirm that FedCSAP outperforms existing federated prompt learning methods in both accuracy and overall generalization.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Oil Spill Response Through Liquid Neural Trajectory Modeling and Coordinated Marine Robotics</title>
<link>https://arxiv.org/abs/2508.12456</link>
<guid>https://arxiv.org/abs/2508.12456</guid>
<content:encoded><![CDATA[
arXiv:2508.12456v1 Announce Type: new 
Abstract: Marine oil spills pose grave environmental and economic risks, threatening marine ecosystems, coastlines, and dependent industries. Predicting and managing oil spill trajectories is highly complex, due to the interplay of physical, chemical, and environmental factors such as wind, currents, and temperature, which makes timely and effective response challenging. Accurate real-time trajectory forecasting and coordinated mitigation are vital for minimizing the impact of these disasters. This study introduces an integrated framework combining a multi-agent swarm robotics system built on the MOOS-IvP platform with Liquid Time-Constant Neural Networks (LTCNs). The proposed system fuses adaptive machine learning with autonomous marine robotics, enabling real-time prediction, dynamic tracking, and rapid response to evolving oil spills. By leveraging LTCNs--well-suited for modeling complex, time-dependent processes--the framework achieves real-time, high-accuracy forecasts of spill movement. Swarm intelligence enables decentralized, scalable, and resilient decision-making among robot agents, enhancing collective monitoring and containment efforts. Our approach was validated using data from the Deepwater Horizon spill, where the LTC-RK4 model achieved 0.96 spatial accuracy, surpassing LSTM approaches by 23%. The integration of advanced neural modeling with autonomous, coordinated robotics demonstrates substantial improvements in prediction precision, flexibility, and operational scalability. Ultimately, this research advances the state-of-the-art for sustainable, autonomous oil spill management and environmental protection by enhancing both trajectory prediction and response coordination.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg</title>
<link>https://arxiv.org/abs/2508.12576</link>
<guid>https://arxiv.org/abs/2508.12576</guid>
<content:encoded><![CDATA[
arXiv:2508.12576v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized clients to train a model collaboratively without sharing local data. A key distinction between FL and centralized learning is that clients' data are non-independent and identically distributed, which poses significant challenges in training a global model that generalizes well across heterogeneous local data distributions. In this paper, we analyze the convergence of overparameterized FedAvg with gradient descent (GD). We prove that the impact of data heterogeneity diminishes as the width of neural networks increases, ultimately vanishing when the width approaches infinity. In the infinite-width regime, we further prove that both the global and local models in FedAvg behave as linear models, and that FedAvg achieves the same generalization performance as centralized learning with the same number of GD iterations. Extensive experiments validate our theoretical findings across various network architectures, loss functions, and optimization methods.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MPOCryptoML: Multi-Pattern based Off-Chain Crypto Money Laundering Detection</title>
<link>https://arxiv.org/abs/2508.12641</link>
<guid>https://arxiv.org/abs/2508.12641</guid>
<content:encoded><![CDATA[
arXiv:2508.12641v1 Announce Type: new 
Abstract: Recent advancements in money laundering detection have demonstrated the potential of using graph neural networks to capture laundering patterns accurately. However, existing models are not explicitly designed to detect the diverse patterns of off-chain cryptocurrency money laundering. Neglecting any laundering pattern introduces critical detection gaps, as each pattern reflects unique transactional structures that facilitate the obfuscation of illicit fund origins and movements. Failure to account for these patterns may result in under-detection or omission of specific laundering activities, diminishing model accuracy and allowing schemes to bypass detection. To address this gap, we propose the MPOCryptoML model to effectively detect multiple laundering patterns in cryptocurrency transactions. MPOCryptoML includes the development of a multi-source Personalized PageRank algorithm to identify random laundering patterns. Additionally, we introduce two novel algorithms by analyzing the timestamp and weight of transactions in high-volume financial networks to detect various money laundering structures, including fan-in, fan-out, bipartite, gather-scatter, and stack patterns. We further examine correlations between these patterns using a logistic regression model. An anomaly score function integrates results from each module to rank accounts by anomaly score, systematically identifying high-risk accounts. Extensive experiments on public datasets including Elliptic++, Ethereum fraud detection, and Wormhole transaction datasets validate the efficacy and efficiency of MPOCryptoML. Results show consistent performance gains, with improvements up to 9.13% in precision, up to 10.16% in recall, up to 7.63% in F1-score, and up to 10.19% in accuracy.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DIT: Dimension Reduction View on Optimal NFT Rarity Meters</title>
<link>https://arxiv.org/abs/2508.12671</link>
<guid>https://arxiv.org/abs/2508.12671</guid>
<content:encoded><![CDATA[
arXiv:2508.12671v1 Announce Type: new 
Abstract: Non-fungible tokens (NFTs) have become a significant digital asset class, each uniquely representing virtual entities such as artworks. These tokens are stored in collections within smart contracts and are actively traded across platforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is closely tied to their distinctive characteristics that define rarity, leading to a growing interest in quantifying rarity within both industry and academia. While there are existing rarity meters for assessing NFT rarity, comparing them can be challenging without direct access to the underlying collection data. The Rating over all Rarities (ROAR) benchmark addresses this challenge by providing a standardized framework for evaluating NFT rarity. This paper explores a dimension reduction approach to rarity design, introducing new performance measures and meters, and evaluates them using the ROAR benchmark. Our contributions to the rarity meter design issue include developing an optimal rarity meter design using non-metric weighted multidimensional scaling, introducing Dissimilarity in Trades (DIT) as a performance measure inspired by dimension reduction techniques, and unveiling the non-interpretable rarity meter DIT, which demonstrates superior performance compared to existing methods.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Nomadic 6G Communication Networks: Implications on Architecture, Standardization, and Regulatory Aspects</title>
<link>https://arxiv.org/abs/2508.12710</link>
<guid>https://arxiv.org/abs/2508.12710</guid>
<content:encoded><![CDATA[
arXiv:2508.12710v1 Announce Type: new 
Abstract: The emergence of nomadic mobile communication networks for sixth-generation (6G) introduces a paradigm shift in how network infrastructure is conceptualized, deployed, and operated. Unlike traditional fixed systems, Nomadic Networks (NNs) consist of mobile and self-organizing nodes that provide radio infrastructure capabilities in motion. This paper explores the architectural implications of such systems, with a particular focus on the design and evolution of network interfaces. We analyze the requirements for inter-node communication, service discovery, and control delegation in dynamic environments. Furthermore, we examine the regulatory and licensing challenges that arise when infrastructure elements traverse jurisdictional boundaries. Based on current 6G visions and relevant research, we identify limitations in existing architectures and propose a set of interface principles tailored to nomadicity. By synthesizing findings from mobile, non-terrestrial, and organic network domains, this work contributes to the architectural foundation for future nomadic 6G communication systems and outlines directions for interface standardization in decentralized, mobile infrastructures.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs</title>
<link>https://arxiv.org/abs/2508.12712</link>
<guid>https://arxiv.org/abs/2508.12712</guid>
<content:encoded><![CDATA[
arXiv:2508.12712v1 Announce Type: new 
Abstract: Connected and automated vehicles generate vast amounts of sensor data daily, raising significant privacy and communication challenges for centralized machine learning approaches in perception tasks. This study presents a decentralized, federated learning framework tailored for traffic sign detection in vehicular networks to enable collaborative model training without sharing raw data. The framework partitioned traffic sign classes across vehicles for specialized local training using lightweight object detectors, aggregated model parameters via algorithms like FedProx, FedAdam and FedAVG in a simulated environment with the Flower framework, and evaluated multiple configurations including varying server rounds, local epochs, client participation fractions, and data distributions. Experiments demonstrated that increasing server rounds from 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs (8-10) provided optimal efficiency with accuracies around 0.67, higher client participation fractions enhanced generalization up to 0.83, FedProx outperformed other aggregators in handling heterogeneity, non-IID data distributions reduced performance compared to IID, and training duration primarily scaled with the number of rounds rather than aggregation strategy. We conclude that this federated approach may offer a scalable, privacy-preserving solution for real-world vehicular deployments, potentially guiding future integrations of robust aggregation and communication optimizations to advance intelligent transportation systems.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models</title>
<link>https://arxiv.org/abs/2508.12740</link>
<guid>https://arxiv.org/abs/2508.12740</guid>
<content:encoded><![CDATA[
arXiv:2508.12740v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized model training without sharing local data. However, most existing methods assume identical model architectures across clients, limiting their applicability in heterogeneous real-world environments. To address this, we propose FedUNet, a lightweight and architecture-agnostic FL framework that attaches a U-Net-inspired additive module to each client's backbone. By sharing only the compact bottleneck of the U-Net, FedUNet enables efficient knowledge transfer without structural alignment. The encoder-decoder design and skip connections in the U-Net help capture both low-level and high-level features, facilitating the extraction of clientinvariant representations. This enables cooperative learning between the backbone and the additive module with minimal communication cost. Experiment with VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in compact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low communication overhead.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tokenize Everything, But Can You Sell It? RWA Liquidity Challenges and the Road Ahead</title>
<link>https://arxiv.org/abs/2508.11651</link>
<guid>https://arxiv.org/abs/2508.11651</guid>
<content:encoded><![CDATA[
arXiv:2508.11651v1 Announce Type: cross 
Abstract: The tokenization of real-world assets (RWAs) promises to transform financial markets by enabling fractional ownership, global accessibility, and programmable settlement of traditionally illiquid assets such as real estate, private credit, and government bonds. While technical progress has been rapid, with over \$25 billion in tokenized RWAs brought on-chain as of 2025, liquidity remains a critical bottleneck. This paper investigates the gap between tokenization and tradability, drawing on recent academic research and market data from platforms such as RWA.xyz. We document that most RWA tokens exhibit low trading volumes, long holding periods, and limited investor participation, despite their potential for 24/7 global markets. Through case studies of tokenized real estate, private credit, and tokenized treasury funds, we present empirical liquidity observations that reveal low transfer activity, limited active address counts, and minimal secondary trading for most tokenized asset classes. Next, we categorize the structural barriers to liquidity, including regulatory gating, custodial concentration, whitelisting, valuation opacity, and lack of decentralized trading venues. Finally, we propose actionable pathways to improve liquidity, ranging from hybrid market structures and collateral-based liquidity to transparency enhancements and compliance innovation. Our findings contribute to the growing discourse on digital asset market microstructure and highlight that realizing the liquidity potential of RWAs requires coordinated progress across legal, technical, and institutional domains.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scaling Robust Optimization for Swarms: A Distributed Perspective</title>
<link>https://arxiv.org/abs/2508.11799</link>
<guid>https://arxiv.org/abs/2508.11799</guid>
<content:encoded><![CDATA[
arXiv:2508.11799v1 Announce Type: cross 
Abstract: This article introduces a decentralized robust optimization framework for safe multi-agent control under uncertainty. Although stochastic noise has been the primary form of modeling uncertainty in such systems, these formulations might fall short in addressing uncertainties that are deterministic in nature or simply lack probabilistic data. To ensure safety under such scenarios, we employ the concept of robust constraints that must hold for all possible uncertainty realizations lying inside a bounded set. Nevertheless, standard robust optimization approaches become intractable due to the large number or non-convexity of the constraints involved in safe multi-agent control. To address this, we introduce novel robust reformulations that significantly reduce complexity without compromising safety. The applicability of the framework is further broadened to address both deterministic and stochastic uncertainties by incorporating robust chance constraints and distribution steering techniques. To achieve scalability, we derive a distributed approach based on the Alternating Direction Method of Multipliers (ADMM), supported by a convergence study that accounts for the underlying non-convexity. In addition, computational complexity bounds highlighting the efficiency of the proposed frameworks against standard approaches are presented. Finally, the robustness and scalability of the framework is demonstrated through extensive simulation results across diverse scenarios, including environments with nonconvex obstacles and up to 246 agents.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reputation-based PoS for the Restriction of Illicit Activities on Blockchain: Algorand Usecase</title>
<link>https://arxiv.org/abs/2112.11024</link>
<guid>https://arxiv.org/abs/2112.11024</guid>
<content:encoded><![CDATA[
arXiv:2112.11024v4 Announce Type: replace 
Abstract: In cryptocurrency-based permissionless blockchain networks, the decentralized structure enables any user to join and operate across different regions. The criminal entities exploit it by using cryptocurrency transactions on the blockchain to facilitate activities such as money laundering, gambling, and ransomware attacks. In recent times, different machine learning-based techniques can detect such criminal elements based on blockchain transaction data. However, there is no provision within the blockchain to deal with such elements. We propose a reputation-based methodology for response to the users detected carrying out the aforementioned illicit activities. We select Algorand blockchain to implement our methodology by incorporating it within the consensus protocol. The theoretical results obtained prove the restriction and exclusion of criminal elements through block proposal rejection and attenuation of the voting power as a validator for such entities. Further, we analyze the efficacy of our method and show that it puts no additional strain on the communication resources.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Near-Optimal Sparse Allreduce for Distributed Deep Learning</title>
<link>https://arxiv.org/abs/2201.07598</link>
<guid>https://arxiv.org/abs/2201.07598</guid>
<content:encoded><![CDATA[
arXiv:2201.07598v3 Announce Type: replace 
Abstract: Communication overhead is one of the major obstacles to train large deep learning models at scale. Gradient sparsification is a promising technique to reduce the communication volume. However, it is very challenging to obtain real performance improvement because of (1) the difficulty of achieving an scalable and efficient sparse allreduce algorithm and (2) the sparsification overhead. This paper proposes O$k$-Top$k$, a scheme for distributed training with sparse gradients. O$k$-Top$k$ integrates a novel sparse allreduce algorithm (less than 6$k$ communication volume which is asymptotically optimal) with the decentralized parallel Stochastic Gradient Descent (SGD) optimizer, and its convergence is proved. To reduce the sparsification overhead, O$k$-Top$k$ efficiently selects the top-$k$ gradient values according to an estimated threshold. Evaluations are conducted on the Piz Daint supercomputer with neural network models from different deep learning domains. Empirical results show that O$k$-Top$k$ achieves similar model accuracy to dense allreduce. Compared with the optimized dense and the state-of-the-art sparse allreduces, O$k$-Top$k$ is more scalable and significantly improves training throughput (e.g., 3.29x-12.95x improvement for BERT on 256 GPUs).
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>It Takes Two: A Peer-Prediction Solution for Blockchain Verifier's Dilemma</title>
<link>https://arxiv.org/abs/2406.01794</link>
<guid>https://arxiv.org/abs/2406.01794</guid>
<content:encoded><![CDATA[
arXiv:2406.01794v4 Announce Type: replace 
Abstract: The security of blockchain systems is fundamentally based on the decentralized consensus in which the majority of parties behave honestly, and the content verification process is essential to maintaining the robustness of blockchain systems. However, the phenomenon that a rational verifier may not have the incentive to honestly perform the costly verification, referred to as the Verifier's Dilemma, could incentivize lazy reporting and undermine the fundamental security of blockchain systems, particularly for verification-expensive decentralized AI applications.
  In this paper, we initiate the research with the development of a Byzantine-robust peer prediction framework towards the design of one-phase Bayesian truthful mechanisms for the decentralized verification games among multiple verifiers, incentivizing all verifiers to perform honest verification without access to the ground truth even in the presence of noisy observations, malicious players and inaccurate priors in the verification process, proposing the compactness criteria that ensures such robustness guarantees. With robust incentive guarantees and budget efficiency, our study provides a framework of incentive design for decentralized verification protocols that enhances the security and robustness of the blockchain, decentralized AI, and potentially other decentralized systems.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking Federated Learning for Semantic Datasets: Federated Scene Graph Generation</title>
<link>https://arxiv.org/abs/2412.10436</link>
<guid>https://arxiv.org/abs/2412.10436</guid>
<content:encoded><![CDATA[
arXiv:2412.10436v2 Announce Type: replace 
Abstract: Federated learning (FL) enables decentralized training while preserving data privacy, yet existing FL benchmarks address relatively simple classification tasks, where each sample is annotated with a one-hot label. However, little attention has been paid to demonstrating an FL benchmark that handles complicated semantics, where each sample encompasses diverse semantic information, such as relations between objects. Because the existing benchmarks are designed to distribute data in a narrow view of a single semantic, managing the complicated \textit{semantic heterogeneity} across clients when formalizing FL benchmarks is non-trivial. In this paper, we propose a benchmark process to establish an FL benchmark with controllable semantic heterogeneity across clients: two key steps are (i) data clustering with semantics and (ii) data distributing via controllable semantic heterogeneity across clients. As a proof of concept, we construct a federated PSG benchmark, demonstrating the efficacy of the existing PSG methods in an FL setting with controllable semantic heterogeneity of scene graphs. We also present the effectiveness of our benchmark by applying robust federated learning algorithms to data heterogeneity to show increased performance. To our knowledge, this is the first benchmark framework that enables federated learning and its evaluation for multi-semantic vision tasks under the controlled semantic heterogeneity. Our code is available at \textit{https://github.com/Seung-B/FL-PSG}.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Data Analytics: Review and Challenges</title>
<link>https://arxiv.org/abs/2503.09165</link>
<guid>https://arxiv.org/abs/2503.09165</guid>
<content:encoded><![CDATA[
arXiv:2503.09165v2 Announce Type: replace 
Abstract: The integration of blockchain technology with data analytics is essential for extracting insights in the cryptocurrency space. Although academic literature on blockchain data analytics is limited, various industry solutions have emerged to address these needs. This paper provides a comprehensive literature review, drawing from both academic research and industry applications. We classify blockchain analytics tools into categories such as block explorers, on-chain data providers, research platforms, and crypto market data providers. Additionally, we discuss the challenges associated with blockchain data analytics, including data accessibility, scalability, accuracy, and interoperability. Our findings emphasize the importance of bridging academic research and industry innovations to advance blockchain data analytics.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An overview of the efficiency and censorship-resistance guarantees of widely-used consensus protocols</title>
<link>https://arxiv.org/abs/2504.03588</link>
<guid>https://arxiv.org/abs/2504.03588</guid>
<content:encoded><![CDATA[
arXiv:2504.03588v2 Announce Type: replace 
Abstract: Censorship resistance with short-term inclusion guarantees is an important feature of decentralized systems, missing from many state-of-the-art and even deployed consensus protocols. In leader-based protocols the leader arbitrarily selects the transactions to be included in the new block, and so does a block builder in protocols such as Bitcoin and Ethereum.
  In a different line of work, since the redundancy of consensus for implementing distributed payments was formally proven, consensusless protocols have been described in theory and deployed in the real world. This has resulted in blockchains and payment systems that are more efficient, and at the same time avoid the centralized role of a leader or block builder.
  In this report we review existing consensus and consensusless protocols with regard to their censorship-resistance, efficiency, and other properties. Moreover, we present an approach for new constructions with these properties in mind, building on existing leader-based protocols.
]]></content:encoded>
<pubDate>Tue, 19 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning</title>
<link>https://arxiv.org/abs/2508.11530</link>
<guid>https://arxiv.org/abs/2508.11530</guid>
<content:encoded><![CDATA[
arXiv:2508.11530v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed paradigm that circumvents the single-point-of-failure and communication bottleneck risks of centralized architectures. However, a significant challenge arises as existing DFL optimization strategies, primarily designed for tasks such as computer vision, fail to address the unique topological information inherent in the local subgraph. Notably, while Federated Graph Learning (FGL) is tailored for graph data, it is predominantly implemented in a centralized server-client model, failing to leverage the benefits of decentralization.To bridge this gap, we propose DFed-SST, a decentralized federated graph learning framework with adaptive communication. The core of our method is a dual-topology adaptive communication mechanism that leverages the unique topological features of each client's local subgraph to dynamically construct and optimize the inter-client communication topology. This allows our framework to guide model aggregation efficiently in the face of heterogeneity. Extensive experiments on eight real-world datasets consistently demonstrate the superiority of DFed-SST, achieving 3.26% improvement in average accuracy over baseline methods.
]]></content:encoded>
<pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Price of Cheaper Data: Measuring the Strategic Inefficiencies in the Post-EIP-4844 Ethereum Market</title>
<link>https://arxiv.org/abs/2411.03892</link>
<guid>https://arxiv.org/abs/2411.03892</guid>
<content:encoded><![CDATA[
arXiv:2411.03892v3 Announce Type: replace 
Abstract: High transaction fees on Ethereum have long hindered its scalability and user adoption. The recent Ethereum EIP-4844 upgrade aims to alleviate the scalability issue by introducing the blob, a new data structure for Layer-2 rollups. Instead of using expensive blockchain storage, blobs provide a cheaper, separate data layer with its own fee market, which drastically lowers data availability costs. This change, while lowering transaction costs, has created a new high-stakes economic game for block builders and rollups. However, the dynamics of this game remain poorly understood. In this paper, we conduct the first large-scale empirical analysis of the post-EIP-4844 ecosystem, leveraging a dataset of 319.5 million transactions, including 1.3 million blob-carrying type-3 transactions. Our analysis demonstrates clear evidence of a structural shift towards the utilization of cheap blobs over expensive transactions for Layer-2 data posting: while average block size grew 2.5 times, the space consumed by expensive transactions in the public mempool shrank from over 150 KB to just 30 KB. Yet, this scalability success masks widespread economic inefficiencies on both sides of the market. On the builder side, 29.48% of blocks containing blobs are constructed sub-optimally, earning less revenue than that could be achieved otherwise. On the rollup side, we identify that flawed submission strategies have led to $186.92$ ETH in direct losses and average inclusion delays of over 19 seconds. Moving beyond characterization, our work offers actionable solutions. For builders, we develop an optimal pricing model derived from a formal first-price auction framework, allowing builders to make provably profitable inclusion decisions. For rollups, we prove that batching multiple blobs into a single transaction is a dominant, utility-maximizing strategy.
]]></content:encoded>
<pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized State Estimation and Opacity Verification Based on Partially Ordered Observation Sequences</title>
<link>https://arxiv.org/abs/2502.10367</link>
<guid>https://arxiv.org/abs/2502.10367</guid>
<content:encoded><![CDATA[
arXiv:2502.10367v3 Announce Type: replace 
Abstract: In this paper, we investigate state estimation and opacity verification problems within a decentralized observation architecture. Specifically, we consider a discrete event system whose behavior is recorded by a set of observation sites. These sites transmit the partially ordered sequences of observations that they record to a coordinator whenever a synchronization occurs. To properly analyze the system behavior from the coordinator's viewpoint, we first introduce the notion of a Complete Synchronizing Sequence structure (CSS structure), which concisely captures the state evolution of each system state upon different information provided by the observation sites. Based on the CSS structure, we then construct corresponding current-state and initial-state estimators for offline state estimation at the coordinator. When used to verify state-isolation properties under this decentralized architecture, the use of CSS structure demonstrates a significant reduction in complexity compared with existing approaches in the literature. In particular, we discuss how to verify initial-state opacity at the coordinator, as well as a novel opacity notion, namely current-state-at-synchronization opacity.
]]></content:encoded>
<pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Multi-Robotic Arm Interaction via 3D Convex Shapes</title>
<link>https://arxiv.org/abs/2503.11791</link>
<guid>https://arxiv.org/abs/2503.11791</guid>
<content:encoded><![CDATA[
arXiv:2503.11791v2 Announce Type: replace 
Abstract: Inter-robot collisions pose a significant safety risk when multiple robotic arms operate in close proximity. We present an online collision avoidance methodology leveraging 3D convex shape-based High-Order Control Barrier Functions (HOCBFs) to address this issue. While prior works focused on using Control Barrier Functions (CBFs) for human-robotic arm and single-arm collision avoidance, we explore the problem of collision avoidance between multiple robotic arms operating in a shared space. In our methodology, we utilize the proposed HOCBFs as centralized and decentralized safety filters. These safety filters are compatible with many nominal controllers and ensure safety without significantly restricting the robots' workspace. A key challenge in implementing these filters is the computational overhead caused by the large number of safety constraints and the computation of a Hessian matrix per constraint. We address this challenge by employing numerical differentiation methods to approximate computationally intensive terms. The effectiveness of our method is demonstrated through extensive simulation studies and real-world experiments with Franka Research 3 robotic arms. The project video is available at this link.
]]></content:encoded>
<pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain</title>
<link>https://arxiv.org/abs/2508.09993</link>
<guid>https://arxiv.org/abs/2508.09993</guid>
<content:encoded><![CDATA[
arXiv:2508.09993v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly deployed in realworld applications, yet concerns about their fairness persist especially in highstakes domains like criminal justice, education, healthcare, and finance. This paper introduces transparent evaluation protocol for benchmarking the fairness of opensource LLMs using smart contracts on the Internet Computer Protocol (ICP) blockchain (Foundation, 2023). Our method ensures verifiable, immutable, and reproducible evaluations by executing onchain HTTP requests to hosted Hugging Face endpoints and storing datasets, prompts, and metrics directly onchain. We benchmark the Llama, DeepSeek, and Mistral models on the PISA dataset for academic performance prediction (OECD, 2018), a dataset suitable for fairness evaluation using statistical parity and equal opportunity metrics (Hardt et al., 2016). We also evaluate structured Context Association Metrics derived from the StereoSet dataset (Nadeem et al., 2020) to measure social bias in contextual associations. We further extend our analysis with a multilingual evaluation across English, Spanish, and Portuguese using the Kaleidoscope benchmark (Salazar et al., 2025), revealing cross-linguistic disparities. All code and results are open source, enabling community audits and longitudinal fairness tracking across model versions.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx</title>
<link>https://arxiv.org/abs/2508.10017</link>
<guid>https://arxiv.org/abs/2508.10017</guid>
<content:encoded><![CDATA[
arXiv:2508.10017v1 Announce Type: new 
Abstract: Federated Learning (FL) presents a groundbreaking approach for collaborative health research, allowing model training on decentralized data while safeguarding patient privacy. FL offers formal security guarantees when combined with Differential Privacy (DP). The integration of these technologies, however, introduces a significant trade-off between privacy and clinical utility, a challenge further complicated by the severe class imbalance often present in medical datasets. The research presented herein addresses these interconnected issues through a systematic, multi-stage analysis. An FL framework was implemented for cardiovascular risk prediction, where initial experiments showed that standard methods struggled with imbalanced data, resulting in a recall of zero. To overcome such a limitation, we first integrated the hybrid Synthetic Minority Over-sampling Technique with Tomek Links (SMOTETomek) at the client level, successfully developing a clinically useful model. Subsequently, the framework was optimized for non-IID data using a tuned FedProx algorithm. Our final results reveal a clear, non-linear trade-off between the privacy budget (epsilon) and model recall, with the optimized FedProx consistently out-performing standard FedAvg. An optimal operational region was identified on the privacy-utility frontier, where strong privacy guarantees (with epsilon 9.0) can be achieved while maintaining high clinical utility (recall greater than 77%). Ultimately, our study provides a practical methodological blueprint for creating effective, secure, and accurate diagnostic tools that can be applied to real-world, heterogeneous healthcare data.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2508.10042</link>
<guid>https://arxiv.org/abs/2508.10042</guid>
<content:encoded><![CDATA[
arXiv:2508.10042v1 Announce Type: new 
Abstract: Federated learning enhances traditional deep learning by enabling the joint training of a model with the use of IoT device's private data. It ensures privacy for clients, but is susceptible to data poisoning attacks during training that degrade model performance and integrity. Current poisoning detection methods in federated learning lack a standardized detection method or take significant liberties with trust. In this paper, we present \Sys, a novel blockchain-enabled poison detection framework in federated learning. The framework decentralizes the role of the global server across participating clients. We introduce a judge model used to detect data poisoning in model updates. The judge model is produced by each client and verified to reach consensus on a single judge model. We implement our solution to show \Sys is robust against data poisoning attacks and the creation of our judge model is scalable.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NetMoniAI: An Agentic AI Framework for Network Security &amp; Monitoring</title>
<link>https://arxiv.org/abs/2508.10052</link>
<guid>https://arxiv.org/abs/2508.10052</guid>
<content:encoded><![CDATA[
arXiv:2508.10052v1 Announce Type: new 
Abstract: In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link: https://github.com/pzambare3/NetMoniAI
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Architecture for Distributed Digital Identities in the Physical World</title>
<link>https://arxiv.org/abs/2508.10185</link>
<guid>https://arxiv.org/abs/2508.10185</guid>
<content:encoded><![CDATA[
arXiv:2508.10185v1 Announce Type: new 
Abstract: Digital identities are increasingly important for mediating not only digital but also physical service transactions. Managing such identities through centralized providers can cause both availability and privacy concerns: single points of failure and control are ideal targets for global attacks on technical, organizational, or legal fronts. We design, analyze, and build a distributed digital identity architecture for physical world transactions in common scenarios like unlocking doors, public transport, or crossing country borders. This architecture combines (biometric and other) sensors, (established and upcoming) identity authorities, attribute verifiers, and a new core component we call the \emph{Personal Identity Agent (PIA)} that represents individuals with their identity attributes in the digital domain. All transactions are conducted in a completely decentralized manner, and the components for which we currently assume central coordination are optional and only used for assisting with service discovery and latency reduction. We present a first protocol between these parties and formally verify that it achieves relevant security properties based on a realistic threat model including strong global adversaries. A proof-of-concept implementation demonstrates practical feasibility of both architecture and initial protocol for applications that can tolerate end-to-end latencies in the range of a few seconds.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GraphFedMIG: Tackling Class Imbalance in Federated Graph Learning via Mutual Information-Guided Generation</title>
<link>https://arxiv.org/abs/2508.10471</link>
<guid>https://arxiv.org/abs/2508.10471</guid>
<content:encoded><![CDATA[
arXiv:2508.10471v1 Announce Type: new 
Abstract: Federated graph learning (FGL) enables multiple clients to collaboratively train powerful graph neural networks without sharing their private, decentralized graph data. Inherited from generic federated learning, FGL is critically challenged by statistical heterogeneity, where non-IID data distributions across clients can severely impair model performance. A particularly destructive form of this is class imbalance, which causes the global model to become biased towards majority classes and fail at identifying rare but critical events. This issue is exacerbated in FGL, as nodes from a minority class are often surrounded by biased neighborhood information, hindering the learning of expressive embeddings. To grapple with this challenge, we propose GraphFedMIG, a novel FGL framework that reframes the problem as a federated generative data augmentation task. GraphFedMIG employs a hierarchical generative adversarial network where each client trains a local generator to synthesize high-fidelity feature representations. To provide tailored supervision, clients are grouped into clusters, each sharing a dedicated discriminator. Crucially, the framework designs a mutual information-guided mechanism to steer the evolution of these client generators. By calculating each client's unique informational value, this mechanism corrects the local generator parameters, ensuring that subsequent rounds of mutual information-guided generation are focused on producing high-value, minority-class features. We conduct extensive experiments on four real-world datasets, and the results demonstrate the superiority of the proposed GraphFedMIG compared with other baselines.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AlDBaran: Towards Blazingly Fast State Commitments for Blockchains</title>
<link>https://arxiv.org/abs/2508.10493</link>
<guid>https://arxiv.org/abs/2508.10493</guid>
<content:encoded><![CDATA[
arXiv:2508.10493v1 Announce Type: new 
Abstract: The fundamental basis for maintaining integrity within contemporary blockchain systems is provided by authenticated databases. Our analysis indicates that a significant portion of the approaches applied in this domain fail to sufficiently meet the stringent requirements of systems processing transactions at rates of multi-million TPS. AlDBaran signifies a substantial advancement in authenticated databases. By eliminating disk I/O operations from the critical path, implementing prefetching strategies, and refining the update mechanism of the Merkle tree, we have engineered an authenticated data structure capable of handling state updates efficiently at a network throughput of 50 Gbps. This throughput capacity significantly surpasses any empirically documented blockchain throughput, guaranteeing the ability of even the most high-throughput blockchains to generate state commitments effectively.
  AlDBaran provides support for historical state proofs, which facilitates a wide array of novel applications. For instance, the deployment of AlDBaran could enable blockchains that do not currently support state commitments to offer functionalities for light clients and/or implement rollups.
  When benchmarked against alternative authenticated data structure projects, AlDBaran exhibits superior performance and simplicity. In particular, AlDBaran achieves speeds of approximately 48 million updates per second using an identical machine configuration. This characteristic renders AlDBaran an attractive solution for resource-limited environments, as its historical data capabilities can be modularly isolated (and deactivated), which further enhances performance. On consumer-level portable hardware, it achieves approximately 8 million updates/s in an in-memory setting and 5 million updates/s with snapshots at sub-second intervals, illustrating compelling and cost-effective scalability.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution</title>
<link>https://arxiv.org/abs/2508.10517</link>
<guid>https://arxiv.org/abs/2508.10517</guid>
<content:encoded><![CDATA[
arXiv:2508.10517v1 Announce Type: new 
Abstract: Solidity, the dominant smart contract language for Ethereum, has rapidly evolved with frequent version updates to enhance security, functionality, and developer experience. However, these continual changes introduce significant challenges, particularly in compilation errors, code migration, and maintenance. Therefore, we conduct an empirical study to investigate the challenges in the Solidity version evolution and reveal that 81.68% of examined contracts encounter errors when compiled across different versions, with 86.92% of compilation errors.
  To mitigate these challenges, we conducted a systematic evaluation of large language models (LLMs) for resolving Solidity compilation errors during version migrations. Our empirical analysis across both open-source (LLaMA3, DeepSeek) and closed-source (GPT-4o, GPT-3.5-turbo) LLMs reveals that although these models exhibit error repair capabilities, their effectiveness diminishes significantly for semantic-level issues and shows strong dependency on prompt engineering strategies. This underscores the critical need for domain-specific adaptation in developing reliable LLM-based repair systems for smart contracts.
  Building upon these insights, we introduce SMCFIXER, a novel framework that systematically integrates expert knowledge retrieval with LLM-based repair mechanisms for Solidity compilation error resolution. The architecture comprises three core phases: (1) context-aware code slicing that extracts relevant error information; (2) expert knowledge retrieval from official documentation; and (3) iterative patch generation for Solidity migration. Experimental validation across Solidity version migrations demonstrates our approach's statistically significant 24.24% improvement over baseline GPT-4o on real-world datasets, achieving near-perfect 96.97% accuracy.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Robust Optimization Approach for Demand Response Participation of Fixed-Frequency Air Conditioners</title>
<link>https://arxiv.org/abs/2508.10679</link>
<guid>https://arxiv.org/abs/2508.10679</guid>
<content:encoded><![CDATA[
arXiv:2508.10679v1 Announce Type: new 
Abstract: With the continuous increase in the penetration of renewable energy in the emerging power systems, the pressure on system peak regulation has been significantly intensified. Against this backdrop, demand side resources particularly air conditioning loads have garnered considerable attention for their substantial regulation potential and fast response capabilities, making them promising candidates for providing auxiliary peak shaving services. This study focuses on fixed frequency air conditioners (FFACs) and proposes an optimization model and solution method for their participation in demand response (DR) programs. First, a probabilistic response model for FFACs is developed based on the Markov assumption. Second, by sampling this probabilistic model, the aggregate power consumption of an FFAC cluster under decentralized control is obtained. Subsequently, a robust optimization model is formulated to maximize the profit of an aggregator managing the FFAC cluster during DR events, taking into account the aggregated response power. The model explicitly considers temperature uncertainty to ensure user comfort in a robust sense. Finally, leveraging the structure of the proposed model, it is reformulated as a mixed-integer linear programming (MILP) problem and solved using a commercial optimization solver. Simulation results validate the effectiveness of the proposed model and solution approach.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Intelligent Infrastructure as a Foundation for Modern Science</title>
<link>https://arxiv.org/abs/2508.10051</link>
<guid>https://arxiv.org/abs/2508.10051</guid>
<content:encoded><![CDATA[
arXiv:2508.10051v1 Announce Type: cross 
Abstract: Infrastructure shapes societies and scientific discovery. Traditional scientific infrastructure, often static and fragmented, leads to issues like data silos, lack of interoperability and reproducibility, and unsustainable short-lived solutions. Our current technical inability and social reticence to connect and coordinate scientific research and engineering leads to inefficiencies and impedes progress. With AI technologies changing how we interact with the world around us, there is an opportunity to transform scientific processes. Neuroscience's exponential growth of multimodal and multiscale data, and urgent clinical relevance demand an infrastructure itself learns, coordinates, and improves. Using neuroscience as a stress test, this perspective argues for a paradigm shift: infrastructure must evolve into a dynamic, AI-aligned ecosystem to accelerate science. Building on several existing principles for data, collective benefit, and digital repositories, I recommend operational guidelines for implementing them to create this dynamic ecosystem, aiming to foster a decentralized, self-learning, and self-correcting system where humans and AI can collaborate seamlessly. Addressing the chronic underfunding of scientific infrastructure, acknowledging diverse contributions beyond publications, and coordinating global efforts are critical steps for this transformation. By prioritizing an intelligent infrastructure as a central scientific instrument for knowledge generation, we can overcome current limitations, accelerate discovery, ensure reproducibility and ethical practices, and ultimately translate neuroscientific understanding into tangible societal benefits, setting a blueprint for other scientific domains.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-preserving Blockchain-enabled Parametric Insurance via Remote Sensing and IoT</title>
<link>https://arxiv.org/abs/2305.08384</link>
<guid>https://arxiv.org/abs/2305.08384</guid>
<content:encoded><![CDATA[
arXiv:2305.08384v3 Announce Type: replace 
Abstract: Traditional Insurance, a popular approach of financial risk management, has suffered from the issues of high operational costs, opaqueness, inefficiency and a lack of trust. Recently, blockchain-enabled "parametric insurance" through authorized data sources (e.g., remote sensing and IoT) aims to overcome these issues by automating the underwriting and claim processes of insurance policies on a blockchain. However, the openness of blockchain platforms raises a concern of user privacy, as the private user data in insurance claims on a blockchain may be exposed to outsiders. In this paper, we propose a privacy-preserving parametric insurance framework based on succinct zero-knowledge proofs (zk-SNARKs), whereby an insuree submits a zero-knowledge proof (without revealing any private data) for the validity of an insurance claim and the authenticity of its data sources to a blockchain for transparent verification. Moreover, we extend the recent zk-SNARKs to support robust privacy protection for multiple heterogeneous data sources and improve its efficiency to cut the incurred gas cost by 80%. As a proof-of-concept, we implemented a working prototype of bushfire parametric insurance on real-world blockchain platform Ethereum, and present extensive empirical evaluations.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Parallel Execution of Blockchain Transactions Leveraging Conflict Specifications</title>
<link>https://arxiv.org/abs/2503.03203</link>
<guid>https://arxiv.org/abs/2503.03203</guid>
<content:encoded><![CDATA[
arXiv:2503.03203v2 Announce Type: replace 
Abstract: Parallel execution of smart contract transactions in large multicore architectures is critical for higher efficiency and improved throughput. The main bottleneck for maximizing the throughput of a node through parallel execution is transaction conflict resolution: when two transactions interact with the same data, like an account balance, their order matters. Imagine one transaction sends tokens from account A to account B, and another tries to send tokens from account B to account C. If the second transaction happens before the first one, the token balance in account B might be wrong, causing the entire system to break. Conflicts like these must be managed carefully, or you end up with an inconsistent, unusable blockchain state.
  Traditional software transactional memory (STM) has been identified as a possible abstraction for the concurrent execution of transactions within a block, with Block-STM pioneering its application for efficient blockchain transaction processing on multicore validator nodes. This paper presents a parallel execution methodology that leverages conflict specification information of the transactions for block transactional memory (BTM) algorithms. Our experimental analysis, conducted over synthetic transactional workloads and real-world blocks, demonstrates that BTMs leveraging conflict specifications outperform their plain counterparts on both EVM and MoveVM. Our proposed BTM implementations achieve up to 1.75x speedup over sequential execution and outperform the state-of-the-art Parallel-EVM (PEVM) execution by up to 1.33x across synthetic workloads.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMP: Tackling Medical Feature Heterogeneity in Federated Learning from a Manifold Perspective</title>
<link>https://arxiv.org/abs/2508.09174</link>
<guid>https://arxiv.org/abs/2508.09174</guid>
<content:encoded><![CDATA[
arXiv:2508.09174v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized machine learning paradigm in which multiple clients collaboratively train a shared model without sharing their local private data. However, real-world applications of FL frequently encounter challenges arising from the non-identically and independently distributed (non-IID) local datasets across participating clients, which is particularly pronounced in the field of medical imaging, where shifts in image feature distributions significantly hinder the global model's convergence and performance. To address this challenge, we propose FedMP, a novel method designed to enhance FL under non-IID scenarios. FedMP employs stochastic feature manifold completion to enrich the training space of individual client classifiers, and leverages class-prototypes to guide the alignment of feature manifolds across clients within semantically consistent subspaces, facilitating the construction of more distinct decision boundaries. We validate the effectiveness of FedMP on multiple medical imaging datasets, including those with real-world multi-center distributions, as well as on a multi-domain natural image dataset. The experimental results demonstrate that FedMP outperforms existing FL algorithms. Additionally, we analyze the impact of manifold dimensionality, communication efficiency, and privacy implications of feature exposure in our method.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach</title>
<link>https://arxiv.org/abs/2508.09181</link>
<guid>https://arxiv.org/abs/2508.09181</guid>
<content:encoded><![CDATA[
arXiv:2508.09181v1 Announce Type: new 
Abstract: Federated learning (FL) provides a decentralized framework that enables universal model training through collaborative efforts on mobile nodes, such as smart vehicles in the Internet of Vehicles (IoV). Each smart vehicle acts as a mobile client, contributing to the process without uploading local data. This method leverages non-independent and identically distributed (non-IID) training data from different vehicles, influenced by various driving patterns and environmental conditions, which can significantly impact model convergence and accuracy. Although client selection can be a feasible solution for non-IID issues, it faces challenges related to selection metrics. Traditional metrics evaluate client data quality independently per round and require client selection after all clients complete local training, leading to resource wastage from unused training results. In the IoV context, where vehicles have limited connectivity and computational resources, information asymmetry in client selection risks clients submitting false information, potentially making the selection ineffective. To tackle these challenges, we propose a novel Long-term Client-Selection Federated Learning based on Truthful Auction (LCSFLA). This scheme maximizes social welfare with consideration of long-term data quality using a new assessment mechanism and energy costs, and the advised auction mechanism with a deposit requirement incentivizes client participation and ensures information truthfulness. We theoretically prove the incentive compatibility and individual rationality of the advised incentive mechanism. Experimental results on various datasets, including those from IoV scenarios, demonstrate its effectiveness in mitigating performance degradation caused by non-IID data.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments</title>
<link>https://arxiv.org/abs/2508.09194</link>
<guid>https://arxiv.org/abs/2508.09194</guid>
<content:encoded><![CDATA[
arXiv:2508.09194v1 Announce Type: new 
Abstract: The deployment of large-scale models, such as large language models (LLMs), incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for model deployment, where choosing efficient inference acceleration schemes become crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Network Analysis using Quantum Inspired Graph Neural Networks &amp; Ensemble Models</title>
<link>https://arxiv.org/abs/2508.09237</link>
<guid>https://arxiv.org/abs/2508.09237</guid>
<content:encoded><![CDATA[
arXiv:2508.09237v1 Announce Type: new 
Abstract: In the rapidly evolving domain of financial technology, the detection of illicit transactions within blockchain networks remains a critical challenge, necessitating robust and innovative solutions. This work proposes a novel approach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with flexibility of choice of an Ensemble Model using QBoost or a classic model such as Random Forrest Classifier. This system is tailored specifically for blockchain network analysis in anti-money laundering (AML) efforts. Our methodology to design this system incorporates a novel component, a Canonical Polyadic (CP) decomposition layer within the graph neural network framework, enhancing its capability to process and analyze complex data structures efficiently. Our technical approach has undergone rigorous evaluation against classical machine learning implementations, achieving an F2 score of 74.8% in detecting fraudulent transactions. These results highlight the potential of quantum-inspired techniques, supplemented by the structural advancements of the CP layer, to not only match but potentially exceed traditional methods in complex network analysis for financial security. The findings advocate for a broader adoption and further exploration of quantum-inspired algorithms within the financial sector to effectively combat fraud.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation</title>
<link>https://arxiv.org/abs/2508.09299</link>
<guid>https://arxiv.org/abs/2508.09299</guid>
<content:encoded><![CDATA[
arXiv:2508.09299v1 Announce Type: new 
Abstract: Weather forecasting plays a vital role in disaster preparedness, agriculture, and resource management, yet current centralized forecasting systems are increasingly strained by security vulnerabilities, limited scalability, and susceptibility to single points of failure. To address these challenges, we propose a decentralized weather forecasting framework that integrates Federated Learning (FL) with blockchain technology. FL enables collaborative model training without exposing sensitive local data; this approach enhances privacy and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures transparent and dependable verification of model updates. To further enhance the system's security, we introduce a reputation-based voting mechanism that assesses the trustworthiness of submitted models while utilizing the Interplanetary File System (IPFS) for efficient off-chain storage. Experimental results demonstrate that our approach not only improves forecasting accuracy but also enhances system resilience and scalability, making it a viable candidate for deployment in real-world, security-critical environments.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Formal Methods to Data-Driven Safety Certificates of Unknown Large-Scale Networks</title>
<link>https://arxiv.org/abs/2508.09520</link>
<guid>https://arxiv.org/abs/2508.09520</guid>
<content:encoded><![CDATA[
arXiv:2508.09520v1 Announce Type: new 
Abstract: In this work, we propose a data-driven scheme within a compositional framework with noisy data to design robust safety controllers in a fully decentralized fashion for large-scale interconnected networks with unknown mathematical dynamics. Despite the network's high dimensionality and the inherent complexity of its unknown model, which make it intractable, our approach effectively addresses these challenges by (i) treating the network as a composition of smaller subsystems, and (ii) collecting noisy data from each subsystem's trajectory to design a control sub-barrier certificate (CSBC) and its corresponding local controller. To achieve this, our proposed scheme only requires a noise-corrupted single input-state trajectory from each unknown subsystem up to a specified time horizon, satisfying a certain rank condition. Subsequently, under a small-gain compositional reasoning, we compose those CSBC, derived from noisy data, and formulate a control barrier certificate (CBC) for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We offer a data-dependent sum-of-squares (SOS) optimization program for computing CSBC alongside local controllers of subsystems. We illustrate that while the computational complexity of designing a CBC and its safety controller grows polynomially with network dimension using SOS optimization, our compositional data-driven approach significantly reduces it to a linear scale concerning the number of subsystems. We demonstrate the capability of our data-driven approach on multiple physical networks involving unknown models and a range of interconnection topologies.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks</title>
<link>https://arxiv.org/abs/2508.09532</link>
<guid>https://arxiv.org/abs/2508.09532</guid>
<content:encoded><![CDATA[
arXiv:2508.09532v1 Announce Type: new 
Abstract: Federated fine-tuning has emerged as a promising approach for adapting foundation models (FMs) to diverse downstream tasks in edge environments. In Internet of Vehicles (IoV) systems, enabling efficient and low-latency multi-task adaptation is particularly challenging due to client mobility, heterogeneous resources, and intermittent connectivity. This paper proposes a hierarchical federated fine-tuning framework that coordinates roadside units (RSUs) and vehicles to support resource-aware and mobility-resilient learning across dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we introduce a decentralized, energy-aware rank adaptation mechanism formulated as a constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is developed to enable adaptive exploration under per-task energy budgets, achieving provable sublinear regret. To evaluate our method, we construct a large-scale IoV simulator based on real-world trajectories, capturing dynamic participation, RSU handoffs, and communication variability. Extensive experiments show that our approach achieves the best accuracy-efficiency trade-off among all baselines, reducing latency by over 24\% and improving average accuracy by more than 2.5\%.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness</title>
<link>https://arxiv.org/abs/2508.09866</link>
<guid>https://arxiv.org/abs/2508.09866</guid>
<content:encoded><![CDATA[
arXiv:2508.09866v1 Announce Type: new 
Abstract: To protect clients' right to be forgotten in federated learning, federated unlearning aims to remove the data contribution of leaving clients from the global learned model. While current studies mainly focused on enhancing unlearning efficiency and effectiveness, the crucial aspects of efficiency fairness and performance fairness among decentralized clients during unlearning have remained largely unexplored. In this study, we introduce FedShard, the first federated unlearning algorithm designed to concurrently guarantee both efficiency fairness and performance fairness. FedShard adaptively addresses the challenges introduced by dilemmas among convergence, unlearning efficiency, and unlearning fairness. Furthermore, we propose two novel metrics to quantitatively assess the fairness of unlearning algorithms, which we prove to satisfy well-known properties in other existing fairness measurements. Our theoretical analysis and numerical evaluation validate FedShard's fairness in terms of both unlearning performance and efficiency. We demonstrate that FedShard mitigates unfairness risks such as cascaded leaving and poisoning attacks and realizes more balanced unlearning costs among clients. Experimental results indicate that FedShard accelerates the data unlearning process 1.3-6.2 times faster than retraining from scratch and 4.9 times faster than the state-of-the-art exact unlearning methods.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hummingbird: Fast, Flexible, and Fair Inter-Domain Bandwidth Reservations</title>
<link>https://arxiv.org/abs/2308.09959</link>
<guid>https://arxiv.org/abs/2308.09959</guid>
<content:encoded><![CDATA[
arXiv:2308.09959v4 Announce Type: replace 
Abstract: The current Internet lacks quality-of-service guarantees for real-time applications like video calls and gaming, cloud-based systems, financial transactions, telesurgery, and other remote applications that benefit from reliable communication. To address this problem, this paper introduces Hummingbird: a novel, lightweight bandwidth-reservation system that provides fine-grained inter-domain reservations for end hosts and introduces several improvements over previous designs.
  Hummingbird enables flexible and composable reservations with end-to-end guarantees, and addresses an often overlooked, but crucial, aspect of bandwidth reservation systems: incentivization of network providers. Hummingbird represents bandwidth reservations as tradeable assets which allows markets to emerge that ensure fair and efficient resource allocation and encourage deployment by remunerating providers. This incentivization is facilitated by decoupling reservations from network identities, which enables novel control-plane mechanisms and allows us to design a control plane based on smart contracts.
  Hummingbird also provides an efficient reservation data plane which streamlines the processing on routers and thus simplifies the implementation, deployment, and traffic policing while maintaining robust security properties.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.17565</link>
<guid>https://arxiv.org/abs/2412.17565</guid>
<content:encoded><![CDATA[
arXiv:2412.17565v2 Announce Type: replace 
Abstract: Cellular traffic forecasting is a critical task that enables network operators to efficiently allocate resources and address anomalies in rapidly evolving environments. The exponential growth of data collected from base stations poses significant challenges to processing and analysis. While machine learning (ML) algorithms have emerged as powerful tools for handling these large datasets and providing accurate predictions, their environmental impact, particularly in terms of energy consumption, is often overlooked in favor of their predictive capabilities. This study investigates the potential of two bio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing through Echo State Networks (ESNs) for cellular traffic forecasting. The evaluation focuses on both their predictive performance and energy efficiency. These models are implemented in both centralized and federated settings to analyze their effectiveness and energy consumption in decentralized systems. Additionally, we compare bio-inspired models with traditional architectures, such as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs), to provide a comprehensive evaluation. Using data collected from three diverse locations in Barcelona, Spain, we examine the trade-offs between predictive accuracy and energy demands across these approaches. The results indicate that bio-inspired models, such as SNNs and ESNs, can achieve significant energy savings while maintaining predictive accuracy comparable to traditional architectures. Furthermore, federated implementations were tested to evaluate their energy efficiency in decentralized settings compared to centralized systems, particularly in combination with bio-inspired models. These findings offer valuable insights into the potential of bio-inspired models for sustainable and privacy-preserving cellular traffic forecasting.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Illusory Normativity of Rights-Based AI Regulation</title>
<link>https://arxiv.org/abs/2503.05784</link>
<guid>https://arxiv.org/abs/2503.05784</guid>
<content:encoded><![CDATA[
arXiv:2503.05784v2 Announce Type: replace 
Abstract: Whether and how to regulate AI is now a central question of governance. Across academic, policy, and international legal circles, the European Union is widely treated as the normative leader in this space. Its regulatory framework, anchored in the General Data Protection Regulation, the Digital Services and Markets Acts, and the AI Act, is often portrayed as a principled model grounded in fundamental rights. This Article challenges that assumption. We argue that the rights-based narrative surrounding EU AI regulation mischaracterizes the logic of its institutional design. While rights language pervades EU legal instruments, its function is managerial, not foundational. These rights operate as tools of administrative ordering, used to mitigate technological disruption, manage geopolitical risk, and preserve systemic balance, rather than as expressions of moral autonomy or democratic consent. Drawing on comparative institutional analysis, we situate EU AI governance within a longer tradition of legal ordering shaped by the need to coordinate power across fragmented jurisdictions. We contrast this approach with the American model, which reflects a different regulatory logic rooted in decentralized authority, sectoral pluralism, and a constitutional preference for innovation and individual autonomy. Through case studies in five key domains -- data privacy, cybersecurity, healthcare, labor, and disinformation -- we show that EU regulation is not meaningfully rights-driven, as is often claimed. It is instead structured around the containment of institutional risk. Our aim is not to endorse the American model but to reject the presumption that the EU approach reflects a normative ideal that other nations should uncritically adopt. The EU model is best understood as a historically contingent response to its own political conditions, not a template for others to blindly follow.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralization: A Qualitative Survey of Node Operators</title>
<link>https://arxiv.org/abs/2503.17246</link>
<guid>https://arxiv.org/abs/2503.17246</guid>
<content:encoded><![CDATA[
arXiv:2503.17246v4 Announce Type: replace 
Abstract: Decentralization is understood both by professionals in the blockchain industry and general users as a core design goal of permissionless ledgers. However, its meaning is far from universally agreed, and often it is easier to get opinions on what it is not, rather than what it is. In this paper, we solicit definitions of 'decentralization' and 'decentralization theatre' from blockchain node operators. Key to a definition is asking about effective decentralization strategies, as well as those that are ineffective, sometimes deliberately so. Malicious, deceptive, or incompetent strategies are commonly referred to by the term 'decentralization theatre.' Finally, we ask what is being decentralized. Via thematic analysis of interview transcripts, we find that most operators conceive decentralization as existing broadly on a technical and a governance axis. Isolating relevant variables, we collapse the categories to network topology and governance topology, or the structure of decision-making power. Our key finding is that `decentralization' alone does not affect ledger immutability or systemic robustness.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methods for Decentralized Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.18433</link>
<guid>https://arxiv.org/abs/2505.18433</guid>
<content:encoded><![CDATA[
arXiv:2505.18433v2 Announce Type: replace 
Abstract: Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of O(1/T), where T is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Forecast-Driven MPC for Decentralized Multi-Robot Collision Avoidance</title>
<link>https://arxiv.org/abs/2508.08264</link>
<guid>https://arxiv.org/abs/2508.08264</guid>
<content:encoded><![CDATA[
arXiv:2508.08264v1 Announce Type: new 
Abstract: The Iterative Forecast Planner (IFP) is a geometric planning approach that offers lightweight computations, scal- able, and reactive solutions for multi-robot path planning in decentralized, communication-free settings. However, it struggles in symmetric configurations, where mirrored interactions often lead to collisions and deadlocks. We introduce eIFP-MPC, an optimized and extended version of IFP that improves robustness and path consistency in dense, dynamic environments. The method refines threat prioritization using a time-to-collision heuristic, stabilizes path generation through cost-based via- point selection, and ensures dynamic feasibility by incorporating model predictive control (MPC) into the planning process. These enhancements are tightly integrated into the IFP to preserve its efficiency while improving its adaptability and stability. Ex- tensive simulations across symmetric and high-density scenarios show that eIFP-MPC significantly reduces oscillations, ensures collision-free motion, and improves trajectory efficiency. The results demonstrate that geometric planners can be strengthened through optimization, enabling robust performance at scale in complex multi-agent environments.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Heterogeneity-Aware and Energy-Efficient Topology Optimization for Decentralized Federated Learning in Edge Environment</title>
<link>https://arxiv.org/abs/2508.08278</link>
<guid>https://arxiv.org/abs/2508.08278</guid>
<content:encoded><![CDATA[
arXiv:2508.08278v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a promising paradigm within edge computing (EC) systems, enabling numerous edge devices to collaboratively train artificial intelligence (AI) models while maintaining data privacy. To overcome the communication bottlenecks associated with centralized parameter servers, decentralized federated learning (DFL), which leverages peer-to-peer (P2P) communication, has been extensively explored in the research community. Although researchers design a variety of DFL approach to ensure model convergence, its iterative learning process inevitably incurs considerable cost along with the growth of model complexity and the number of participants. These costs are largely influenced by the dynamic changes of topology in each training round, particularly its sparsity and connectivity conditions. Furthermore, the inherent resources heterogeneity in the edge environments affects energy efficiency of learning process, while data heterogeneity degrades model performance. These factors pose significant challenges to the design of an effective DFL framework for EC systems. To this end, we propose Hat-DFed, a heterogeneity-aware and coset-effective decentralized federated learning (DFL) framework. In Hat-DFed, the topology construction is formulated as a dual optimization problem, which is then proven to be NP-hard, with the goal of maximizing model performance while minimizing cumulative energy consumption in complex edge environments. To solve this problem, we design a two-phase algorithm that dynamically constructs optimal communication topologies while unbiasedly estimating their impact on both model performance and energy cost. Additionally, the algorithm incorporates an importance-aware model aggregation mechanism to mitigate performance degradation caused by data heterogeneity.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2508.08473</link>
<guid>https://arxiv.org/abs/2508.08473</guid>
<content:encoded><![CDATA[
arXiv:2508.08473v1 Announce Type: new 
Abstract: Collective behaviors such as swarming and flocking emerge from simple, decentralized interactions in biological systems. Existing models, such as Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber model imposes rigid formations, limiting their applicability in swarm robotics. To address these limitations, this paper proposes a minimal yet expressive model that governs agent dynamics using relative positions, velocities, and local density, modulated by two tunable parameters: the spatial offset and kinetic offset. The model achieves spatially flexible, collision-free behaviors that reflect naturalistic group dynamics. Furthermore, we extend the framework to cognitive autonomous systems, enabling energy-aware phase transitions between swarming and flocking through adaptive control parameter tuning. This cognitively inspired approach offers a robust foundation for real-world applications in multi-robot systems, particularly autonomous aerial swarms.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Traffic Load-Aware Resource Management Strategy for Underwater Wireless Sensor Networks</title>
<link>https://arxiv.org/abs/2508.08555</link>
<guid>https://arxiv.org/abs/2508.08555</guid>
<content:encoded><![CDATA[
arXiv:2508.08555v1 Announce Type: new 
Abstract: Underwater Wireless Sensor Networks (UWSNs) represent a promising technology that enables diverse underwater applications through acoustic communication. However, it encounters significant challenges including harsh communication environments, limited energy supply, and restricted signal transmission. This paper aims to provide efficient and reliable communication in underwater networks with limited energy and communication resources by optimizing the scheduling of communication links and adjusting transmission parameters (e.g., transmit power and transmission rate). The efficient and reliable communication multi-objective optimization problem (ERCMOP) is formulated as a decentralized partially observable Markov decision process (Dec-POMDP). A Traffic Load-Aware Resource Management (TARM) strategy based on deep multi-agent reinforcement learning (MARL) is presented to address this problem. Specifically, a traffic load-aware mechanism that leverages the overhear information from neighboring nodes is designed to mitigate the disparity between partial observations and global states. Moreover, by incorporating a solution space optimization algorithm, the number of candidate solutions for the deep MARL-based decision-making model can be effectively reduced, thereby optimizing the computational complexity. Simulation results demonstrate the adaptability of TARM in various scenarios with different transmission demands and collision probabilities, while also validating the effectiveness of the proposed approach in supporting efficient and reliable communication in underwater networks with limited resources.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed optimization: designed for federated learning</title>
<link>https://arxiv.org/abs/2508.08606</link>
<guid>https://arxiv.org/abs/2508.08606</guid>
<content:encoded><![CDATA[
arXiv:2508.08606v1 Announce Type: new 
Abstract: Federated Learning (FL), as a distributed collaborative Machine Learning (ML) framework under privacy-preserving constraints, has garnered increasing research attention in cross-organizational data collaboration scenarios. This paper proposes a class of distributed optimization algorithms based on the augmented Lagrangian technique, designed to accommodate diverse communication topologies in both centralized and decentralized FL settings. Furthermore, we develop multiple termination criteria and parameter update mechanisms to enhance computational efficiency, accompanied by rigorous theoretical guarantees of convergence. By generalizing the augmented Lagrangian relaxation through the incorporation of proximal relaxation and quadratic approximation, our framework systematically recovers a broad of classical unconstrained optimization methods, including proximal algorithm, classic gradient descent, and stochastic gradient descent, among others. Notably, the convergence properties of these methods can be naturally derived within the proposed theoretical framework. Numerical experiments demonstrate that the proposed algorithm exhibits strong performance in large-scale settings with significant statistical heterogeneity across clients.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Dual Framework for Optimized Data Storage and Retrieval using Lightweight Python Blockchain and Scalable Smart Contracts with IPFS</title>
<link>https://arxiv.org/abs/2508.08887</link>
<guid>https://arxiv.org/abs/2508.08887</guid>
<content:encoded><![CDATA[
arXiv:2508.08887v1 Announce Type: new 
Abstract: The exponential growth of IoT data demands efficient, secure, and scalable storage solutions on one hand, and efficient data migration and retrieval on the other hand are essential for the systems to be practical and acceptable for different applications. The traditional cloud-based models face latency, security, and high operational costs, while existing bi-directional data storage and retrieval-based IPFS models are not computationally efficient and incur high gas costs at the cost of a necessary blockchain deployment. To overcome the challenges of efficient data migration, we initially developed a 2-way data storage and retrieval system as well as a scalable framework that dynamically monitors and transfers device-generated data to IPFS, records the content identifier(CID) on a blockchain, and enables secure, real-time access via smart contracts. Experimental results demonstrate that the existing work achieved an average data upload time of 117.12 sec for a file size of 500 MB; our framework achieves a faster upload time of 7.63 sec, marking a 93.47% improvement. We further optimize the proposed framework to reduce the file upload time incurred from the smart contracts by introducing a blockchain-inspired, lightweight, and customizable Python framework that replicates the storage and retrieval functionalities of a traditional blockchain, where the file upload time is 4.2 sec, further optimized by 45% from our previous approach, thus demonstrating its efficiency, security and suitability for deploy ment in real-time and critical IoT applications and outperforming the existing IPFS-smart contract based solutions.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Redactable Blockchains: An Overview</title>
<link>https://arxiv.org/abs/2508.08898</link>
<guid>https://arxiv.org/abs/2508.08898</guid>
<content:encoded><![CDATA[
arXiv:2508.08898v1 Announce Type: new 
Abstract: Blockchains are widely recognized for their immutability, which provides robust guarantees of data integrity and transparency. However, this same feature poses significant challenges in real-world situations that require regulatory compliance, correction of erroneous data, or removal of sensitive information. Redactable blockchains address the limitations of traditional ones by enabling controlled, auditable modifications to blockchain data, primarily through cryptographic mechanisms such as chameleon hash functions and alternative redaction schemes. This report examines the motivations for introducing redactability, surveys the cryptographic primitives that enable secure edits, and analyzes competing approaches and their shortcomings. Special attention is paid to the practical deployment of redactable blockchains in private settings, with discussions of use cases in healthcare, finance, Internet of drones, and federated learning. Finally, the report outlines further challenges, also in connection with reversible computing, and the future potential of redactable blockchains in building law-compliant, trustworthy, and scalable digital infrastructures.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantum Inspired Legal Tech Environmental Integration for Emergency Pharmaceutical Logistics with Entropy Modulated Collapse and Multilevel Governance</title>
<link>https://arxiv.org/abs/2508.08286</link>
<guid>https://arxiv.org/abs/2508.08286</guid>
<content:encoded><![CDATA[
arXiv:2508.08286v1 Announce Type: cross 
Abstract: Emergency pharmaceutical logistics during rapid-onset disasters must balance timeliness, legal compliance, and environmental uncertainty. We present a hybrid framework that co-designs quantum-inspired decision dynamics, embedded legal constraints, and blockchain-verified environmental feedback. Candidate routes are modeled as a superposed state whose collapse is governed by entropy modulation-delaying commitment under ambiguity and accelerating resolution when coherent signals emerge. Legal statutes act as real-time projection operators shaping feasible choices, while environmental decoherence cues adjust confidence and path viability. The core engine is situated within a multilevel governance and mechanism design architecture, establishing clear roles, accountability channels, and audit trails. Large-scale simulations in wildfire scenarios demonstrate substantial gains over conventional baselines in latency, compliance, and robustness, while preserving interpretability and fairness adaptation. The resulting system offers a deployable, governance-aware infrastructure where law and physical risk jointly inform emergency routing decisions.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Non-participant externalities reshape the evolution of altruistic punishment</title>
<link>https://arxiv.org/abs/2508.08302</link>
<guid>https://arxiv.org/abs/2508.08302</guid>
<content:encoded><![CDATA[
arXiv:2508.08302v1 Announce Type: cross 
Abstract: While voluntary participation is a key mechanism that enables altruistic punishment to emerge, its explanatory power typically rests on the common assumption that non-participants have no impact on the public good. Yet, given the decentralized nature of voluntary participation, opting out does not necessarily preclude individuals from influencing the public good. Here, we revisit the role of voluntary participation by allowing non-participants to exert either positive or negative impacts on the public good. Using evolutionary analysis in a well-mixed finite population, we find that positive externalities from non-participants lower the synergy threshold required for altruistic punishment to dominate. In contrast, negative externalities raise this threshold, making altruistic punishment harder to sustain. Notably, when non-participants have positive impacts, altruistic punishment thrives only if non-participation is incentivized, whereas under negative impacts, it can persist even when non-participation is discouraged. Our findings reveal that efforts to promote altruistic punishment must account for the active role of non-participants, whose influence can make or break collective outcomes.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs</title>
<link>https://arxiv.org/abs/2508.06601</link>
<guid>https://arxiv.org/abs/2508.06601</guid>
<content:encoded><![CDATA[
arXiv:2508.06601v1 Announce Type: new 
Abstract: Open-weight AI systems offer unique benefits, including enhanced transparency, open research, and decentralized access. However, they are vulnerable to tampering attacks which can efficiently elicit harmful behaviors by modifying weights or activations. Currently, there is not yet a robust science of open-weight model risk management. Existing safety fine-tuning methods and other post-training techniques have struggled to make LLMs resistant to more than a few dozen steps of adversarial fine-tuning. In this paper, we investigate whether filtering text about dual-use topics from training data can prevent unwanted capabilities and serve as a more tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable data filtering and show that it offers a tractable and effective method for minimizing biothreat proxy knowledge in LLMs. We pretrain multiple 6.9B-parameter models from scratch and find that they exhibit substantial resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M tokens of biothreat-related text -- outperforming existing post-training baselines by over an order of magnitude -- with no observed degradation to unrelated capabilities. However, while filtered models lack internalized dangerous knowledge, we find that they can still leverage such information when it is provided in context (e.g., via search tool augmentation), demonstrating a need for a defense-in-depth approach. Overall, these findings help to establish pretraining data curation as a promising layer of defense for open-weight AI systems.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure and Decentralized Peer-to-Peer Energy Transactions using Blockchain Technology</title>
<link>https://arxiv.org/abs/2508.06728</link>
<guid>https://arxiv.org/abs/2508.06728</guid>
<content:encoded><![CDATA[
arXiv:2508.06728v1 Announce Type: new 
Abstract: This paper presents an optimal peer-to-peer (P2P) energy transaction mechanism leveraging decentralized blockchain technology to enable a secure and scalable retail electricity market for the increasing penetration of distributed energy resources (DERs). A decentralized bidding strategy is proposed to maximize individual profits while collectively enhancing social welfare. The market design and transaction processes are simulated using the Ethereum testnet, demonstrating the blockchain network's capability to ensure secure, transparent, and sustainable P2P energy trading among DER participants.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2508.06863</link>
<guid>https://arxiv.org/abs/2508.06863</guid>
<content:encoded><![CDATA[
arXiv:2508.06863v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access edge computing (MEC) as edge servers. It is desirable to design UAVs' trajectories and user to UAV assignments to ensure satisfactory service to the users and energy efficient operation simultaneously. The posed optimization problem is challenging to solve because: (i) The formulated problem is non-convex, (ii) Due to the mobility of ground users, their future positions and channel gains are not known in advance, (iii) Local UAVs' observations should be communicated to a central entity that solves the optimization problem. The (semi-) centralized processing leads to communication overhead, communication/processing bottlenecks, lack of flexibility and scalability, and loss of robustness to system failures. To simultaneously address all these limitations, we advocate a fully decentralized setup with no centralized entity. Each UAV obtains its local observation and then communicates with its immediate neighbors only. After sharing information with neighbors, each UAV determines its next position via a locally run deep reinforcement learning (DRL) algorithm. None of the UAVs need to know the global communication graph. Two main components of our proposed solution are (i) Graph attention layers (GAT), and (ii) Experience and parameter sharing proximal policy optimization (EPS-PPO). Our proposed approach eliminates all the limitations of semi-centralized MADRL methods such as MAPPO and MA deep deterministic policy gradient (MADDPG), while guaranteeing a better performance than independent local DRLs such as in IPPO. Numerical results reveal notable performance gains in several different criteria compared to the existing MADDPG algorithm, demonstrating the potential for offering a better performance, while utilizing local communications only.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization</title>
<link>https://arxiv.org/abs/2508.07001</link>
<guid>https://arxiv.org/abs/2508.07001</guid>
<content:encoded><![CDATA[
arXiv:2508.07001v1 Announce Type: new 
Abstract: With wireless devices increasingly forming a unified smart network for seamless, user-friendly operations, random access (RA) medium access control (MAC) design is considered a key solution for handling unpredictable data traffic from multiple terminals. However, it remains challenging to design an effective RA-based MAC protocol to minimize collisions and ensure transmission fairness across the devices. While existing multi-agent reinforcement learning (MARL) approaches with centralized training and decentralized execution (CTDE) have been proposed to optimize RA performance, their reliance on centralized training and the significant overhead required for information collection can make real-world applications unrealistic. In this work, we adopt a fully decentralized MARL architecture, where policy learning does not rely on centralized tasks but leverages consensus-based information exchanges across devices. We design our MARL algorithm over an actor-critic (AC) network and propose exchanging only local rewards to minimize communication overhead. Furthermore, we provide a theoretical proof of global convergence for our approach. Numerical experiments show that our proposed MARL algorithm can significantly improve RA network performance compared to other baselines.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ScamDetect: Towards a Robust, Agnostic Framework to Uncover Threats in Smart Contracts</title>
<link>https://arxiv.org/abs/2508.07094</link>
<guid>https://arxiv.org/abs/2508.07094</guid>
<content:encoded><![CDATA[
arXiv:2508.07094v1 Announce Type: new 
Abstract: Smart contracts have transformed decentralized finance by enabling programmable, trustless transactions. However, their widespread adoption and growing financial significance have attracted persistent and sophisticated threats, such as phishing campaigns and contract-level exploits. Traditional transaction-based threat detection methods often expose sensitive user data and interactions, raising privacy and security concerns. In response, static bytecode analysis has emerged as a proactive mitigation strategy, identifying malicious contracts before they execute harmful actions.Building on this approach, we introduced PhishingHook, the first machine-learning-based framework for detecting phishing activities in smart contracts via static bytecode and opcode analysis, achieving approximately 90% detection accuracy. Nevertheless, two pressing challenges remain: (1) the increasing use of sophisticated bytecode obfuscation techniques designed to evade static analysis, and (2) the heterogeneity of blockchain environments requiring platform-agnostic solutions.This paper presents a vision for ScamDetect (Smart Contract Agnostic Malware Detector), a robust, modular, and platform-agnostic framework for smart contract malware detection. Over the next 2.5 years, ScamDetect will evolve in two stages: first, by tackling obfuscated Ethereum Virtual Machine (EVM) bytecode through graph neural network (GNN) analysis of control flow graphs (CFGs), leveraging GNNs' ability to capture complex structural patterns beyond opcode sequences; and second, by generalizing detection capabilities to emerging runtimes such as WASM. ScamDetect aims to enable proactive, scalable security for the future of decentralized ecosystems.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AerialDB: A Federated Peer-to-Peer Spatio-temporal Edge Datastore for Drone Fleets</title>
<link>https://arxiv.org/abs/2508.07124</link>
<guid>https://arxiv.org/abs/2508.07124</guid>
<content:encoded><![CDATA[
arXiv:2508.07124v1 Announce Type: new 
Abstract: Recent years have seen an unprecedented growth in research that leverages the newest computing paradigm of Internet of Drones, comprising a fleet of connected Unmanned Aerial Vehicles (UAVs) used for a wide range of tasks such as monitoring and analytics in highly mobile and changing environments characteristic of disaster regions. Given that the typical data (i.e., videos and images) collected by the fleet of UAVs deployed in such scenarios can be considerably larger than what the onboard computers can process, the UAVs need to offload their data in real-time to the edge and the cloud for further processing. To that end, we present the design of AerialDB - a lightweight decentralized data storage and query system that can store and process time series data on a multi-UAV system comprising: A) a fleet of hundreds of UAVs fitted with onboard computers, and B) ground-based edge servers connected through a cellular link. Leveraging lightweight techniques for content-based replica placement and indexing of shards, AerialDB has been optimized for efficient processing of different possible combinations of typical spatial and temporal queries performed by real-world disaster management applications. Using containerized deployment spanning up to 400 drones and 80 edges, we demonstrate that AerialDB is able to scale efficiently while providing near real-time performance with different realistic workloads. Further, AerialDB comprises a decentralized and locality-aware distributed execution engine which provides graceful degradation of performance upon edge failures with relatively low latency while processing large spatio-temporal data. AerialDB exhibits comparable insertion performance and 100 times improvement in query performance against state-of-the-art baseline. Moreover, it exhibits a 10 times and 100 times improvement with insertion and query workloads respectively over the cloud baseline.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners</title>
<link>https://arxiv.org/abs/2508.07145</link>
<guid>https://arxiv.org/abs/2508.07145</guid>
<content:encoded><![CDATA[
arXiv:2508.07145v1 Announce Type: new 
Abstract: The inefficiency of selfish routing in congested networks is a classical problem in algorithmic game theory, often captured by the Price of Anarchy (i.e., the ratio between the social cost of decentralized decisions and that of a centrally optimized solution.) With the advent of autonomous vehicles, capable of receiving and executing centrally assigned routes, it is natural to ask whether their deployment can eliminate this inefficiency. At first glance, a central authority could simply compute an optimal traffic assignment and instruct each vehicle to follow its assigned path. However, this vision overlooks critical challenges: routes must be individually rational (no vehicle has an incentive to deviate), and in practice, multiple planning agents (e.g., different companies) may coexist and compete. Surprisingly, we show that such competition is not merely an obstacle but a necessary ingredient for achieving optimal outcomes. In this work, we design a routing mechanism that embraces competition and converges to an optimal assignment, starting from the classical Pigou network as a foundational case.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding NFTs from EIP Standards</title>
<link>https://arxiv.org/abs/2508.07190</link>
<guid>https://arxiv.org/abs/2508.07190</guid>
<content:encoded><![CDATA[
arXiv:2508.07190v1 Announce Type: new 
Abstract: We argue that the technical foundations of non-fungible tokens (NFTs) remain inadequately understood. Prior research has focused on market dynamics, user behavior, and isolated security incidents, yet systematic analysis of the standards underpinning NFT functionality is largely absent.
  We present the first study of NFTs through the lens of Ethereum Improvement Proposals (EIPs). We conduct a large-scale empirical analysis of 191 NFT-related EIPs and 10K+ Ethereum Magicians discussions (as of July, 2025). We integrate multi-dimensional analyses including the automated parsing of Solidity interfaces, graph-based modeling of inheritance structures, contributor profiling, and mining of community discussion data. We distinguish foundational from emerging standards, expose poor cross-version interoperability, and show that growing functional complexity heightens security risks.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2508.07472</link>
<guid>https://arxiv.org/abs/2508.07472</guid>
<content:encoded><![CDATA[
arXiv:2508.07472v1 Announce Type: new 
Abstract: Sharding is a technique to speed up transaction processing in blockchains, where the $n$ processing nodes in the blockchain are divided into $s$ disjoint groups (shards) that can process transactions in parallel. We study dynamic scheduling problems on a shard graph $G_s$ where transactions arrive online over time and are not known in advance. Each transaction may access at most $k$ shards, and we denote by $d$ the worst distance between a transaction and its accessing (destination) shards (the parameter $d$ is unknown to the shards). To handle different values of $d$, we assume a locality sensitive decomposition of $G_s$ into clusters of shards, where every cluster has a leader shard that schedules transactions for the cluster. We first examine the simpler case of the stateless model, where leaders are not aware of the current state of the transaction accounts, and we prove a $O(d \log^2 s \cdot \min\{k, \sqrt{s}\})$ competitive ratio for latency. We then consider the stateful model, where leader shards gather the current state of accounts, and we prove a $O(\log s\cdot \min\{k, \sqrt{s}\}+\log^2 s)$ competitive ratio for latency. Each leader calculates the schedule in polynomial time for each transaction that it processes. We show that for any $\epsilon > 0$, approximating the optimal schedule within a $(\min\{k, \sqrt{s}\})^{1 -\epsilon}$ factor is NP-hard. Hence, our bound for the stateful model is within a poly-log factor from the best possibly achievable. To the best of our knowledge, this is the first work to establish provably efficient dynamic scheduling algorithms for blockchain sharding systems.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach</title>
<link>https://arxiv.org/abs/2508.07505</link>
<guid>https://arxiv.org/abs/2508.07505</guid>
<content:encoded><![CDATA[
arXiv:2508.07505v1 Announce Type: new 
Abstract: Decentralized min-max optimization allows multi-agent systems to collaboratively solve global min-max optimization problems by facilitating the exchange of model updates among neighboring agents, eliminating the need for a central server. However, sharing model updates in such systems carry a risk of exposing sensitive data to inference attacks, raising significant privacy concerns. To mitigate these privacy risks, differential privacy (DP) has become a widely adopted technique for safeguarding individual data. Despite its advantages, implementing DP in decentralized min-max optimization poses challenges, as the added noise can hinder convergence, particularly in non-convex scenarios with complex agent interactions in min-max optimization problems. In this work, we propose an algorithm called DPMixSGD (Differential Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving algorithm specifically designed for non-convex decentralized min-max optimization. Our method builds on the state-of-the-art STORM-based algorithm, one of the fastest decentralized min-max solutions. We rigorously prove that the noise added to local gradients does not significantly compromise convergence performance, and we provide theoretical bounds to ensure privacy guarantees. To validate our theoretical findings, we conduct extensive experiments across various tasks and models, demonstrating the effectiveness of our approach.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Joint Scheduling and Resource Allocation in mmWave IAB Networks Using Deep RL</title>
<link>https://arxiv.org/abs/2508.07604</link>
<guid>https://arxiv.org/abs/2508.07604</guid>
<content:encoded><![CDATA[
arXiv:2508.07604v1 Announce Type: new 
Abstract: Integrated Access and Backhaul (IAB) is critical for dense 5G and beyond deployments, especially in mmWave bands where fiber backhaul is infeasible. We propose a novel Deep Reinforcement Learning (DRL) framework for joint link scheduling and resource slicing in dynamic, interference-prone IAB networks. Our method integrates a greedy Double Deep Q-Network (DDQN) scheduler to activate access and backhaul links based on traffic and topology, with a multi-agent DDQN allocator for bandwidth and antenna assignment across network slices. This decentralized approach respects strict antenna constraints and supports concurrent scheduling across heterogeneous links. Evaluations across 96 dynamic topologies show 99.84 percent scheduling accuracy and 20.90 percent throughput improvement over baselines. The framework's efficient operation and adaptability make it suitable for dynamic and resource-constrained deployments, where fast link scheduling and autonomous backhaul coordination are vital.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks</title>
<link>https://arxiv.org/abs/2508.07676</link>
<guid>https://arxiv.org/abs/2508.07676</guid>
<content:encoded><![CDATA[
arXiv:2508.07676v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized clients without sharing local data, thereby enhancing privacy and facilitating collaboration among clients connected via social networks. However, these social connections introduce privacy externalities: a client's privacy loss depends not only on its privacy protection strategy but also on the privacy decisions of others, propagated through the network via multi-hop interactions. In this work, we propose a socially-aware privacy-preserving FL mechanism that systematically quantifies indirect privacy leakage through a multi-hop propagation model. We formulate the server-client interaction as a two-stage Stackelberg game, where the server, as the leader, optimizes incentive policies, and clients, as followers, strategically select their privacy budgets, which determine their privacy-preserving levels by controlling the magnitude of added noise. To mitigate information asymmetry in networked privacy estimation, we introduce a mean-field estimator to approximate the average external privacy risk. We theoretically prove the existence and convergence of the fixed point of the mean-field estimator and derive closed-form expressions for the Stackelberg Nash Equilibrium. Despite being designed from a client-centric incentive perspective, our mechanism achieves approximately-optimal social welfare, as revealed by Price of Anarchy (PoA) analysis. Experiments on diverse datasets demonstrate that our approach significantly improves client utilities and reduces server costs while maintaining model performance, outperforming both Social-Agnostic (SA) baselines and methods that account for social externalities.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning</title>
<link>https://arxiv.org/abs/2508.08031</link>
<guid>https://arxiv.org/abs/2508.08031</guid>
<content:encoded><![CDATA[
arXiv:2508.08031v1 Announce Type: new 
Abstract: Federated self-supervised learning (FSSL) combines the advantages of decentralized modeling and unlabeled representation learning, serving as a cutting-edge paradigm with strong potential for scalability and privacy preservation. Although FSSL has garnered increasing attention, research indicates that it remains vulnerable to backdoor attacks. Existing methods generally rely on visually obvious triggers, which makes it difficult to meet the requirements for stealth and practicality in real-world deployment. In this paper, we propose an imperceptible and effective backdoor attack method against FSSL, called IPBA. Our empirical study reveals that existing imperceptible triggers face a series of challenges in FSSL, particularly limited transferability, feature entanglement with augmented samples, and out-of-distribution properties. These issues collectively undermine the effectiveness and stealthiness of traditional backdoor attacks in FSSL. To overcome these challenges, IPBA decouples the feature distributions of backdoor and augmented samples, and introduces Sliced-Wasserstein distance to mitigate the out-of-distribution properties of backdoor samples, thereby optimizing the trigger generation process. Our experimental results on several FSSL scenarios and datasets show that IPBA significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fed-TGAN: Federated Learning Framework for Synthesizing Tabular Data</title>
<link>https://arxiv.org/abs/2108.07927</link>
<guid>https://arxiv.org/abs/2108.07927</guid>
<content:encoded><![CDATA[
arXiv:2108.07927v2 Announce Type: replace 
Abstract: Generative Adversarial Networks (GANs) are typically trained to synthesize data, from images and more recently tabular data, under the assumption of directly accessible training data. Recently, federated learning (FL) is an emerging paradigm that features decentralized learning on client's local data with a privacy-preserving capability. And, while learning GANs to synthesize images on FL systems has just been demonstrated, it is unknown if GANs for tabular data can be learned from decentralized data sources. Moreover, it remains unclear which distributed architecture suits them best. Different from image GANs, state-of-the-art tabular GANs require prior knowledge on the data distribution of each (discrete and continuous) column to agree on a common encoding -- risking privacy guarantees. In this paper, we propose Fed-TGAN, the first Federated learning framework for Tabular GANs. To effectively learn a complex tabular GAN on non-identical participants, Fed-TGAN designs two novel features: (i) a privacy-preserving multi-source feature encoding for model initialization; and (ii) table similarity aware weighting strategies to aggregate local models for countering data skew. We extensively evaluate the proposed Fed-TGAN against variants of decentralized learning architectures on four widely used datasets. Results show that Fed-TGAN accelerates training time per epoch up to 200% compared to the alternative architectures, for both IID and Non-IID data. Overall, Fed-TGAN not only stabilizes the training loss, but also achieves better similarity between generated and original data. Our code is released at https://github.com/zhao-zilong/Fed-TGAN.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Communication Consistent Approach to Signal Temporal Logic Task Decomposition in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2410.12563</link>
<guid>https://arxiv.org/abs/2410.12563</guid>
<content:encoded><![CDATA[
arXiv:2410.12563v2 Announce Type: replace 
Abstract: We consider the problem of decomposing a global task assigned to a multi-agent system, expressed as a formula within a fragment of Signal Temporal Logic (STL), under range-limited communication. Given a global task expressed as a conjunction of local tasks defined over the individual and relative states of agents in the system, we propose representing task dependencies among agents as edges of a suitably defined task graph. At the same time, range-limited communication naturally induces the definition of a communication graph that defines which agents have access to each other's states. Within these settings, inconsistencies arise when a task dependency between a pair of agents is not supported by a corresponding communication link due to the limited communication range. As a result, state feedback control laws previously derived to achieve the tasks' satisfaction can not be leveraged. We propose a task decomposition mechanism to distribute tasks assigned to pairs of non-communicating agents in the system as conjunctions of tasks defined over the relative states of communicating agents, thus enforcing consistency between task and communication graphs. Assuming the super-level sets of the predicate functions composing the STL tasks are bounded polytopes, our task decomposition mechanism can be cast as a parameter optimization problem and solved via state-of-the-art decentralized convex optimization algorithms. To guarantee the soundness of our approach, we present various conditions under which the tasks defined in the applied STL fragment are unsatisfiable, and we show sufficient conditions such that our decomposition approach yields satisfiable global tasks after decomposition.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Model Empowered Metaverse: State-of-the-Art, Challenges and Opportunities</title>
<link>https://arxiv.org/abs/2502.10397</link>
<guid>https://arxiv.org/abs/2502.10397</guid>
<content:encoded><![CDATA[
arXiv:2502.10397v2 Announce Type: replace 
Abstract: The Metaverse represents a transformative shift beyond traditional mobile Internet, creating an immersive, persistent digital ecosystem where users can interact, socialize, and work within 3D virtual environments. Powered by large models such as ChatGPT and Sora, the Metaverse benefits from precise large-scale real-world modeling, automated multimodal content generation, realistic avatars, and seamless natural language understanding, which enhance user engagement and enable more personalized, intuitive interactions. However, challenges remain, including limited scalability, constrained responsiveness, and low adaptability in dynamic environments. This paper investigates the integration of large models within the Metaverse, examining their roles in enhancing user interaction, perception, content creation, and service quality. To address existing challenges, we propose a generative AI-based framework for optimizing Metaverse rendering. This framework includes a cloud-edge-end collaborative model to allocate rendering tasks with minimal latency, a mobility-aware pre-rendering mechanism that dynamically adjusts to user movement, and a diffusion model-based adaptive rendering strategy to fine-tune visual details. Experimental results demonstrate the effectiveness of our approach in enhancing rendering efficiency and reducing rendering overheads, advancing large model deployment for a more responsive and immersive Metaverse.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square</title>
<link>https://arxiv.org/abs/2501.16690</link>
<guid>https://arxiv.org/abs/2501.16690</guid>
<content:encoded><![CDATA[
arXiv:2501.16690v2 Announce Type: replace-cross 
Abstract: Consider a decentralized partially-observed Markov decision problem (POMDP) with multiple cooperative agents aiming to maximize a long-term-average reward criterion. We observe that the availability, at a fixed rate, of entangled states of a product quantum system between the agents, where each agent has access to one of the component systems, can result in strictly improved performance even compared to the scenario where common randomness is provided to the agents, i.e. there is a quantum advantage in decentralized control. This observation comes from a simple reinterpretation of the conclusions of the well-known Mermin-Peres square, which underpins the Mermin-Peres game. While quantum advantage has been demonstrated earlier in one-shot team problems of this kind, it is notable that there are examples where there is a quantum advantage for the one-shot criterion but it disappears in the dynamical scenario. The presence of a quantum advantage in dynamical scenarios is thus seen to be a novel finding relative to the current state of knowledge about the achievable performance in decentralized control problems.
  This paper is dedicated to the memory of Pravin P. Varaiya.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Based Decentralized Domain Name System</title>
<link>https://arxiv.org/abs/2508.05655</link>
<guid>https://arxiv.org/abs/2508.05655</guid>
<content:encoded><![CDATA[
arXiv:2508.05655v1 Announce Type: new 
Abstract: The current Domain Name System (DNS) infrastructure faces critical vulnerabilities including poisoning attacks, censorship mechanisms, and centralized points of failure that compromise internet freedom and security. Recent incidents such as DNS poisoning attacks on ISP customers highlight the urgent need for resilient alternatives. This paper presents a novel blockchain-based Decentralized Domain Name System (DDNS). We designed a specialized Proof-of-Work blockchain to maximize support for DNS-related protocols and achieve node decentralization. The system integrates our blockchain with IPFS for distributed storage, implements cryptographic primitives for end-to-end trust signatures, and achieves Never Trust, Always Verify zero-trust verification. Our implementation achieves 15-second domain record propagation times, supports 20 standard DNS record types, and provides perpetual free .ddns domains. The system has been deployed across distributed infrastructure in San Jose, Los Angeles, and Orange County, demonstrating practical scalability and resistance to traditional DNS manipulation techniques. Performance evaluation shows the system can handle up to Max Theor. TPS 1,111.1 tx/s (minimal transactions) and Max Theor. TPS 266.7 tx/s (regular transactions) for domain operations while maintaining sub-second query resolution through intelligent caching mechanisms.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models</title>
<link>https://arxiv.org/abs/2508.05865</link>
<guid>https://arxiv.org/abs/2508.05865</guid>
<content:encoded><![CDATA[
arXiv:2508.05865v1 Announce Type: new 
Abstract: Blockchain technology offers a promising foundation for modernizing E-Voting systems by enhancing transparency, decentralization, and security. Yet, real-world adoption remains limited due to persistent challenges such as scalability constraints, high computational demands, and complex privacy requirements. This paper presents a comparative framework for analyzing blockchain-based E-Voting architectures, consensus mechanisms, and cryptographic protocols. We examine the limitations of prevalent models like Proof of Work, Proof of Stake, and Delegated Proof of Stake, and propose optimization strategies that include hybrid consensus, lightweight cryptography, and decentralized identity management. Additionally, we explore the novel role of Large Language Models (LLMs) in smart contract generation, anomaly detection, and user interaction. Our findings offer a foundation for designing secure, scalable, and intelligent blockchain-based E-Voting systems suitable for national-scale deployment. This work lays the groundwork for building an end-to-end blockchain E-Voting prototype enhanced by LLM-guided smart contract generation and validation, supported by a systematic framework and simulation-based analysis.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks</title>
<link>https://arxiv.org/abs/2508.06031</link>
<guid>https://arxiv.org/abs/2508.06031</guid>
<content:encoded><![CDATA[
arXiv:2508.06031v1 Announce Type: new 
Abstract: Mobile edge computing (MEC) is a promising technology that enhances the efficiency of mobile blockchain networks, by enabling miners, often acted by mobile users (MUs) with limited computing resources, to offload resource-intensive mining tasks to nearby edge computing servers. Collaborative block mining can further boost mining efficiency by allowing multiple miners to form coalitions, pooling their computing resources and transaction data together to mine new blocks collaboratively. Therefore, an MEC-assisted collaborative blockchain network can leverage the strengths of both technologies, offering improved efficiency, security, and scalability for blockchain systems. While existing research in this area has mainly focused on the single-coalition collaboration mode, where each miner can only join one coalition, this work explores a more comprehensive multi-coalition collaboration mode, which allows each miner to join multiple coalitions. To analyze the behavior of miners and the edge computing service provider (ECP) in this scenario, we propose a novel two-stage Stackelberg game. In Stage I, the ECP, as the leader, determines the prices of computing resources for all MUs. In Stage II, each MU decides the coalitions to join, resulting in an overlapping coalition formation (OCF) game; Subsequently, each coalition decides how many edge computing resources to purchase from the ECP, leading to an edge resource competition (ERC) game. We derive the closed-form Nash equilibrium for the ERC game, based on which we further propose an OCF-based alternating algorithm to achieve a stable coalition structure for the OCF game and develop a near-optimal pricing strategy for the ECP's resource pricing problem.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Game-Theoretic Foundation for Bitcoin's Price: A Security-Utility Equilibrium</title>
<link>https://arxiv.org/abs/2508.06071</link>
<guid>https://arxiv.org/abs/2508.06071</guid>
<content:encoded><![CDATA[
arXiv:2508.06071v1 Announce Type: new 
Abstract: This paper introduces a structural game-theoretic model to value decentralized digital assets like Bitcoin. Instead of relying on speculative beliefs, it frames the asset's price within a Rational-Expectations Security-Utility Nash Equilibrium (RESUNE). This equilibrium is a fixed point where the market-clearing price dictates the hash rate through a free-entry mining model, which in turn endogenously sets the network's security. The security, defined as one minus the probability of a 51% attack, is determined via a global games model of attacker coordination, providing a unique and continuous security function. We prove the existence of a RESUNE and offer conditions for its uniqueness and stability. The model predicts that the stabilizing direct effect of price on demand must outweigh the potentially destabilizing feedback from price to security. The framework generates testable predictions, such as a protocol halving causing a contraction in both hash rate and price. A structural Vector Autoregression (VAR) model is proposed to test this mechanism. The model decomposes Bitcoin's value into transactional utility, security, and speculative components and explains the observed unidirectional causality from price to hash rate.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding Inconsistent State Update Vulnerabilities in Smart Contracts</title>
<link>https://arxiv.org/abs/2508.06192</link>
<guid>https://arxiv.org/abs/2508.06192</guid>
<content:encoded><![CDATA[
arXiv:2508.06192v1 Announce Type: new 
Abstract: Smart contracts enable contract terms to be automatically executed and verified on the blockchain, and recent years have witnessed numerous applications of them in areas such as financial institutions and supply chains. The execution logic of a smart contract is closely related to the contract state, and thus the correct and safe execution of the contract depends heavily on the precise control and update of the contract state. However, the contract state update process can have issues. In particular, inconsistent state update issues can arise for reasons such as unsynchronized modifications. Inconsistent state update bugs have been exploited by attackers many times, but existing detection tools still have difficulty in effectively identifying them. This paper conducts the first large-scale empirical study about inconsistent state update vulnerabilities (that is, inconsistent state update bugs that are exploitable) in smart contracts, aiming to shed light for developers, researchers, tool builders, and language or library designers in order to avoid inconsistent state update vulnerabilities. We systematically investigate 116 inconsistent state update vulnerabilities in 352 real-world smart contract projects, summarizing their root causes, fix strategies, and exploitation methods. Our study provides 11 original and important findings, and we also give the implications of our findings. To illustrate the potential benefits of our research, we also develop a proof-of-concept checker based on one of our findings. The checker effectively detects issues in 64 popular GitHub projects, and 19 project owners have confirmed the detected issues at the time of writing. The result demonstrates the usefulness and importance of our findings for avoiding inconsistent state update vulnerabilities in smart contracts.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing</title>
<link>https://arxiv.org/abs/2508.06256</link>
<guid>https://arxiv.org/abs/2508.06256</guid>
<content:encoded><![CDATA[
arXiv:2508.06256v1 Announce Type: new 
Abstract: Federated learning (FL) enables the collaborative training of deep neural networks across decentralized data archives (i.e., clients), where each client stores data locally and only shares model updates with a central server. This makes FL a suitable learning paradigm for remote sensing (RS) image classification tasks, where data centralization may be restricted due to legal and privacy constraints. However, a key challenge in applying FL to RS tasks is the communication overhead caused by the frequent exchange of large model updates between clients and the central server. To address this issue, in this paper we propose a novel strategy (denoted as FedX) that uses explanation-guided pruning to reduce communication overhead by minimizing the size of the transmitted models without compromising performance. FedX leverages backpropagation-based explanation methods to estimate the task-specific importance of model components and prunes the least relevant ones at the central server. The resulting sparse global model is then sent to clients, substantially reducing communication overhead. We evaluate FedX on multi-label scene classification using the BigEarthNet-S2 dataset and single-label scene classification using the EuroSAT dataset. Experimental results show the success of FedX in significantly reducing the number of shared model parameters while enhancing the generalization capability of the global model, compared to both unpruned model and state-of-the-art pruning methods. The code of FedX will be available at https://git.tu-berlin.de/rsim/FedX.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Social Welfare in Battery Charging Games</title>
<link>https://arxiv.org/abs/2508.06320</link>
<guid>https://arxiv.org/abs/2508.06320</guid>
<content:encoded><![CDATA[
arXiv:2508.06320v1 Announce Type: new 
Abstract: The recent rise of renewable energy produced by many decentralized sources yields interesting market design challenges for electrical grids. Balancing supply and demand in such networks is both a temporal and spatial challenge due to capacity constraints. The recent surge in the number of household-owned batteries, especially in regions with rooftop solar adoption, offers mitigation potential but often acts misaligned with grid-level objectives. In fact, the decision to charge or discharge a household-owned battery is a strategic choice by each battery owner governed by selfish incentives. This calls for an analysis from a game-theoretic point of view.
  We initiate this timely research direction by considering a game-theoretic setting where selfish agents strategically charge or discharge their batteries to increase their profit. In particular, we study a Stackelberg-like market model where a third party introduces price incentives, aiming to optimize renewable energy utilization while preserving grid feasibility. For this, we study the existence and the quality of equilibria under various pricing strategies. We find that the existence of equilibria crucially depends on the chosen pricing and that the obtained social welfare varies widely. This calls for more sophisticated market models and pricing mechanisms and opens up a rich field for future research in Algorithmic Game Theory on incentives in renewable energy networks.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Federated Learning</title>
<link>https://arxiv.org/abs/2508.06406</link>
<guid>https://arxiv.org/abs/2508.06406</guid>
<content:encoded><![CDATA[
arXiv:2508.06406v1 Announce Type: new 
Abstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges of trust, privacy, and coordination in collaborative AI systems. This chapter provides comprehensive architectural analysis of BCFL systems through a systematic four-dimensional taxonomy examining coordination structures, consensus mechanisms, storage architectures, and trust models. We analyze design patterns from blockchain-verified centralized coordination to fully decentralized peer-to-peer networks, evaluating trade-offs in scalability, security, and performance. Through detailed examination of consensus mechanisms designed for federated learning contexts, including Proof of Quality and Proof of Federated Learning, we demonstrate how computational work can be repurposed from arbitrary cryptographic puzzles to productive machine learning tasks. The chapter addresses critical storage challenges by examining multi-tier architectures that balance blockchain's transaction constraints with neural networks' large parameter requirements while maintaining cryptographic integrity. A technical case study of the TrustMesh framework illustrates practical implementation considerations in BCFL systems through distributed image classification training, demonstrating effective collaborative learning across IoT devices with highly non-IID data distributions while maintaining complete transparency and fault tolerance. Analysis of real-world deployments across healthcare consortiums, financial services, and IoT security applications validates the practical viability of BCFL systems, achieving performance comparable to centralized approaches while providing enhanced security guarantees and enabling new models of trustless collaborative intelligence.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative AI and the Future of the Digital Commons: Five Open Questions and Knowledge Gaps</title>
<link>https://arxiv.org/abs/2508.06470</link>
<guid>https://arxiv.org/abs/2508.06470</guid>
<content:encoded><![CDATA[
arXiv:2508.06470v1 Announce Type: new 
Abstract: The rapid advancement of Generative AI (GenAI) relies heavily on the digital commons, a vast collection of free and open online content that is created, shared, and maintained by communities. However, this relationship is becoming increasingly strained due to financial burdens, decreased contributions, and misalignment between AI models and community norms. As we move deeper into the GenAI era, it is essential to examine the interdependent relationship between GenAI, the long-term sustainability of the digital commons, and the equity of current AI development practices. We highlight five critical questions that require urgent attention: 1. How can we prevent the digital commons from being threatened by undersupply as individuals cease contributing to the commons and turn to Generative AI for information? 2. How can we mitigate the risk of the open web closing due to restrictions on access to curb AI crawlers? 3. How can technical standards and legal frameworks be updated to reflect the evolving needs of organizations hosting common content? 4. What are the effects of increased synthetic content in open knowledge databases, and how can we ensure their integrity? 5. How can we account for and distribute the infrastructural and environmental costs of providing data for AI training? We emphasize the need for more responsible practices in AI development, recognizing the digital commons not only as content but as a collaborative and decentralized form of knowledge governance, which relies on the practice of "commoning" - making, maintaining, and protecting shared and open resources. Ultimately, our goal is to stimulate discussion and research on the intersection of Generative AI and the digital commons, with the aim of developing an "AI commons" and public infrastructures for AI development that support the long-term health of the digital commons.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Random Walk Learning and the Pac-Man Attack</title>
<link>https://arxiv.org/abs/2508.05663</link>
<guid>https://arxiv.org/abs/2508.05663</guid>
<content:encoded><![CDATA[
arXiv:2508.05663v1 Announce Type: cross 
Abstract: Random walk (RW)-based algorithms have long been popular in distributed systems due to low overheads and scalability, with recent growing applications in decentralized learning. However, their reliance on local interactions makes them inherently vulnerable to malicious behavior. In this work, we investigate an adversarial threat that we term the ``Pac-Man'' attack, in which a malicious node probabilistically terminates any RW that visits it. This stealthy behavior gradually eliminates active RWs from the network, effectively halting the learning process without triggering failure alarms. To counter this threat, we propose the Average Crossing (AC) algorithm--a fully decentralized mechanism for duplicating RWs to prevent RW extinction in the presence of Pac-Man. Our theoretical analysis establishes that (i) the RW population remains almost surely bounded under AC and (ii) RW-based stochastic gradient descent remains convergent under AC, even in the presence of Pac-Man, with a quantifiable deviation from the true optimum. Our extensive empirical results on both synthetic and real-world datasets corroborate our theoretical findings. Furthermore, they uncover a phase transition in the extinction probability as a function of the duplication threshold. We offer theoretical insights by analyzing a simplified variant of the AC, which sheds light on the observed phase transition.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Optimization via RC-ALADIN with Efficient Quantized Communication</title>
<link>https://arxiv.org/abs/2508.06197</link>
<guid>https://arxiv.org/abs/2508.06197</guid>
<content:encoded><![CDATA[
arXiv:2508.06197v1 Announce Type: cross 
Abstract: In this paper, we investigate the problem of decentralized consensus optimization over directed graphs with limited communication bandwidth. We introduce a novel decentralized optimization algorithm that combines the Reduced Consensus Augmented Lagrangian Alternating Direction Inexact Newton (RC-ALADIN) method with a finite time quantized coordination protocol, enabling quantized information exchange among nodes. Assuming the nodes' local objective functions are $\mu$-strongly convex and simply smooth, we establish global convergence at a linear rate to a neighborhood of the optimal solution, with the neighborhood size determined by the quantization level. Additionally, we show that the same convergence result also holds for the case where the local objective functions are convex and $L$-smooth. Numerical experiments demonstrate that our proposed algorithm compares favorably against algorithms in the current literature while exhibiting communication efficient operation.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EVA-S2PLoR: Decentralized Secure 2-party Logistic Regression with A Subtly Hadamard Product Protocol (Full Version)</title>
<link>https://arxiv.org/abs/2501.05223</link>
<guid>https://arxiv.org/abs/2501.05223</guid>
<content:encoded><![CDATA[
arXiv:2501.05223v3 Announce Type: replace 
Abstract: The implementation of accurate nonlinear operators (e.g., sigmoid function) on heterogeneous datasets is a key challenge in privacy-preserving machine learning (PPML). Most existing frameworks approximate it through linear operations, which not only result in significant precision loss but also introduce substantial computational overhead. This paper proposes an efficient, verifiable, and accurate security 2-party logistic regression framework (EVA-S2PLoR), which achieves accurate nonlinear function computation through a subtly secure hadamard product protocol and its derived protocols. All protocols are based on a practical semi-honest security model, which is designed for decentralized privacy-preserving application scenarios that balance efficiency, precision, and security. High efficiency and precision are guaranteed by the asynchronous computation flow on floating point numbers and the few number of fixed communication rounds in the hadamard product protocol, where robust anomaly detection is promised by dimension transformation and Monte Carlo methods. EVA-S2PLoR outperforms many advanced frameworks in terms of precision, improving the performance of the sigmoid function by about 10 orders of magnitude compared to most frameworks. Moreover, EVA-S2PLoR delivers the best overall performance in secure logistic regression experiments with training time reduced by over 47.6% under WAN settings and a classification accuracy difference of only about 0.5% compared to the plaintext model.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transaction Fee Market Design for Parallel Execution</title>
<link>https://arxiv.org/abs/2502.11964</link>
<guid>https://arxiv.org/abs/2502.11964</guid>
<content:encoded><![CDATA[
arXiv:2502.11964v2 Announce Type: replace 
Abstract: Given the low throughput of blockchains like Bitcoin and Ethereum, scalability - the ability to process an increasing number of transactions - has become a central focus of blockchain research. One promising approach is the parallelization of transaction execution across multiple threads. However, achieving efficient parallelization requires a redesign of the incentive structure within the fee market. Currently, the fee market does not differentiate between transactions that access multiple high-demand storage keys (i.e., unique identifiers for individual data entries) versus a single low-demand one, as long as they require the same computational effort. Addressing this discrepancy is crucial for enabling more effective parallel execution.
  In this work, we aim to bridge the gap between the current fee market and the need for parallel execution by exploring alternative fee market designs. To this end, we propose a framework consisting of two key components: a Gas Computation Mechanism (GCM), which quantifies the load a transaction places on the network in terms of parallelization and computation, measured in units of gas, and a Transaction Fee Mechanism (TFM), which assigns a price to each unit of gas. We additionally introduce a set of desirable properties for a GCM, propose several candidate mechanisms, and evaluate them against these criteria. Our analysis highlights two strong candidates: the weighted area GCM, which integrates smoothly with existing TFMs such as EIP-1559 and satisfies a broad subset of the outlined properties, and the time-proportional makespan GCM, which assigns gas costs based on the context of the entire block's schedule and, through this dependence on the overall execution outcome, captures the dynamics of parallel execution more accurately.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FairDAG: Consensus Fairness over Multi-Proposer Causal Design</title>
<link>https://arxiv.org/abs/2504.02194</link>
<guid>https://arxiv.org/abs/2504.02194</guid>
<content:encoded><![CDATA[
arXiv:2504.02194v2 Announce Type: replace 
Abstract: The rise of cryptocurrencies like Bitcoin and Ethereum has driven interest in blockchain database technology, with smart contracts enabling the growth of decentralized finance (DeFi). However, research has shown that adversaries exploit transaction ordering to extract profits through attacks like front-running, sandwich attacks, and liquidation manipulation. This issue affects blockchain databases in which block proposers have full control over transaction ordering. To address this, a more fair approach to transaction ordering is essential.
  Existing fairness protocols, such as Pompe and Themis, operate on leader-based consensus protocols, which not only suffer from low throughput, but also allow adversaries to manipulate transaction ordering. To address these limitations, we propose FairDAG-AB and FairDAG-RL that run fairness protocols on top of DAG-based consensus protocols, which improve protocol performance in both throughput and fairness quality, leveraging the multi-proposer design and validity of DAG-based consensus protocols.
  We conducted a comprehensive analytical and experimental evaluation of our protocols. The results show that FairDAG-AB and FairDAG-RL outperform the prior fairness protocols in both throughput and fairness quality.
]]></content:encoded>
<pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agency, Affordances, and Enculturation of Augmentation Technologies</title>
<link>https://arxiv.org/abs/2508.04725</link>
<guid>https://arxiv.org/abs/2508.04725</guid>
<content:encoded><![CDATA[
arXiv:2508.04725v1 Announce Type: new 
Abstract: Augmentation technologies are undergoing a process of enculturation due to many factors, one being the rise of artificial intelligence (AI), or what the World Intellectual Property Organization (WIPO) terms the AI wave or AI boom. Chapter 3 focuses critical attention on the hyped assumption that sophisticated, emergent, and embodied augmentation technologies will improve lives, literacy, cultures, arts, economies, and social contexts. The chapter begins by discussing the problem of ambiguity with AI terminology, which it aids with a description of the WIPO Categorization of AI Technologies Scheme. It then draws on media and communication studies to explore concepts such as agents, agency, power, and agentive relationships between humans and robots. The chapter focuses on the development of non-human agents in industry as a critical factor in the rise of augmentation technologies. It looks at how marketing communication enculturates future users to adopt and adapt to the technology. Scholars are charting the significant ways that people are drawn further into commercial digital landscapes, such as the Metaverse concept, in post-internet society. It concludes by examining recent claims concerning the Metaverse and augmented reality.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks</title>
<link>https://arxiv.org/abs/2508.04833</link>
<guid>https://arxiv.org/abs/2508.04833</guid>
<content:encoded><![CDATA[
arXiv:2508.04833v1 Announce Type: new 
Abstract: Gossip algorithms are pivotal in the dissemination of information within decentralized systems. Consequently, numerous gossip libraries have been developed and widely utilized especially in blockchain protocols for the propagation of blocks and transactions. A well-established library is libp2p, which provides two gossip algorithms: floodsup and gossibsup. These algorithms enable the delivery of published messages to a set of peers. In this work we aim to enhance the performance and reliability of libp2p by introducing OPTIMUMP2P, a novel gossip algorithm that leverages the capabilities of Random Linear Network Coding (RLNC) to expedite the dissemination of information in a peer-to-peer (P2P) network while ensuring reliable delivery, even in the presence of malicious actors capable of corrupting the transmitted data. Preliminary research from the Ethereum Foundation has demonstrated the use of RLNC in the significant improvement in the block propagation time [14]. Here we present extensive evaluation results both in simulation and real-world environments that demonstrate the performance gains of OPTIMUMP2P over the Gossipsub protocol.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications</title>
<link>https://arxiv.org/abs/2508.04889</link>
<guid>https://arxiv.org/abs/2508.04889</guid>
<content:encoded><![CDATA[
arXiv:2508.04889v1 Announce Type: new 
Abstract: Most social applications, from Twitter to Wikipedia, have rigid one-size-fits-all designs, but building new social applications is both technically challenging and results in applications that are siloed away from existing communities. We present Graffiti, a system that can be used to build a wide variety of personalized social applications with relative ease that also interoperate with each other. People can freely move between a plurality of designs -- each with its own aesthetic, feature set, and moderation -- all without losing their friends or data.
  Our concept of total reification makes it possible for seemingly contradictory designs, including conflicting moderation rules, to interoperate. Conversely, our concept of channels prevents interoperation from occurring by accident, avoiding context collapse.
  Graffiti applications interact through a minimal client-side API, which we show admits at least two decentralized implementations. Above the API, we built a Vue.js plugin, which we use to develop applications similar to Twitter, Messenger, and Wikipedia using only client-side code. Our case studies explore how these and other novel applications interoperate, as well as the broader ecosystem that Graffiti enables.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Compressed Decentralized Momentum Stochastic Gradient Methods for Nonconvex Optimization</title>
<link>https://arxiv.org/abs/2508.04950</link>
<guid>https://arxiv.org/abs/2508.04950</guid>
<content:encoded><![CDATA[
arXiv:2508.04950v1 Announce Type: new 
Abstract: In this paper, we design two compressed decentralized algorithms for solving nonconvex stochastic optimization under two different scenarios. Both algorithms adopt a momentum technique to achieve fast convergence and a message-compression technique to save communication costs. Though momentum acceleration and compressed communication have been used in literature, it is highly nontrivial to theoretically prove the effectiveness of their composition in a decentralized algorithm that can maintain the benefits of both sides, because of the need to simultaneously control the consensus error, the compression error, and the bias from the momentum gradient.
  For the scenario where gradients are bounded, our proposal is a compressed decentralized adaptive method. To the best of our knowledge, this is the first decentralized adaptive stochastic gradient method with compressed communication. For the scenario of data heterogeneity without bounded gradients, our proposal is a compressed decentralized heavy-ball method, which applies a gradient tracking technique to address the challenge of data heterogeneity. Notably, both methods achieve an optimal convergence rate, and they can achieve linear speed up and adopt topology-independent algorithmic parameters within a certain regime of the user-specified error tolerance. Superior empirical performance is observed over state-of-the-art methods on training deep neural networks (DNNs) and Transformers.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation</title>
<link>https://arxiv.org/abs/2508.05135</link>
<guid>https://arxiv.org/abs/2508.05135</guid>
<content:encoded><![CDATA[
arXiv:2508.05135v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized approach where multiple clients collaboratively train a shared global model without sharing their raw data. Despite its effectiveness, conventional FL faces scalability challenges due to excessive computational and communication demands placed on a single central server as the number of participating devices grows. Hierarchical Federated Learning (HFL) addresses these issues by distributing model aggregation tasks across intermediate nodes (stations), thereby enhancing system scalability and robustness against single points of failure. However, HFL still suffers from a critical yet often overlooked limitation: domain shift, where data distributions vary significantly across different clients and stations, reducing model performance on unseen target domains. While Federated Domain Generalization (FedDG) methods have emerged to improve robustness to domain shifts, their integration into HFL frameworks remains largely unexplored. In this paper, we formally introduce Hierarchical Federated Domain Generalization (HFedDG), a novel scenario designed to investigate domain shift within hierarchical architectures. Specifically, we propose HFedATM, a hierarchical aggregation method that first aligns the convolutional filters of models from different stations through Filter-wise Optimal Transport Alignment and subsequently merges aligned models using a Shrinkage-aware Regularized Mean Aggregation. Our extensive experimental evaluations demonstrate that HFedATM significantly boosts the performance of existing FedDG baselines across multiple datasets and maintains computational and communication efficiency. Moreover, theoretical analyses indicate that HFedATM achieves tighter generalization error bounds compared to standard hierarchical averaging, resulting in faster convergence and stable training behavior.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning</title>
<link>https://arxiv.org/abs/2508.05224</link>
<guid>https://arxiv.org/abs/2508.05224</guid>
<content:encoded><![CDATA[
arXiv:2508.05224v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across distributed clients while preserving data privacy by keeping data local. Traditional FL approaches rely on a centralized, star-shaped topology, where a central server aggregates model updates from clients. However, this architecture introduces several limitations, including a single point of failure, limited personalization, and poor robustness to distribution shifts or vulnerability to malfunctioning clients. Moreover, update selection in centralized FL often relies on low-level parameter differences, which can be unreliable when client data is not independent and identically distributed, and offer clients little control. In this work, we propose a decentralized, peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P topology to enable each client to identify and aggregate a personalized set of trustworthy and beneficial updates.This framework is the Local Inference Guided Aggregation for Heterogeneous Training Environments to Yield Enhancement Through Agreement and Regularization (LIGHTYEAR). Central to our method is an agreement score, computed on a local validation set, which quantifies the semantic alignment of incoming updates in the function space with respect to the clients reference model. Each client uses this score to select a tailored subset of updates and performs aggregation with a regularization term that further stabilizes the training. Our empirical evaluation across two datasets shows that the proposed approach consistently outperforms both centralized baselines and existing P2P methods in terms of client-level performance, particularly under adversarial and heterogeneous conditions.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh</title>
<link>https://arxiv.org/abs/2508.05334</link>
<guid>https://arxiv.org/abs/2508.05334</guid>
<content:encoded><![CDATA[
arXiv:2508.05334v1 Announce Type: new 
Abstract: Academic credential fraud threatens educational integrity, especially in developing countries like Bangladesh, where verification methods are primarily manual and inefficient. To address this challenge, we present ShikkhaChain, a blockchain-powered certificate management platform designed to securely issue, verify, and revoke academic credentials in a decentralized and tamper-proof manner. Built on Ethereum smart contracts and utilizing IPFS for off-chain storage, the platform offers a transparent, scalable solution accessible through a React-based DApp with MetaMask integration. ShikkhaChain enables role-based access for governments, regulators, institutions, and public verifiers, allowing QR-based validation and on-chain revocation tracking. Our prototype demonstrates enhanced trust, reduced verification time, and improved international credibility for Bangladeshi degrees, promoting a more reliable academic and employment ecosystem.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof-of-Useful-Work Blockchain for Trustworthy Biomedical Hyperdimensional Computing</title>
<link>https://arxiv.org/abs/2202.02964</link>
<guid>https://arxiv.org/abs/2202.02964</guid>
<content:encoded><![CDATA[
arXiv:2202.02964v2 Announce Type: replace 
Abstract: Hyperdimensional Computing (HDC) is a promising bio-inspired learning paradigm for its advantage of balancing performance and efficiency and has been increasingly applied to the bio-medical domain. In bio-medical applications, trustworthiness such as replicability and verifiability of the trained learning models is crucial. In this work, we introduce HDCoin, the first proof-of-useful-work blockchain framework for HDC. With HDCoin, we transform the conventional energy-wasteful mining process into a competitive process for developing high accuracy, trustworthy and verifiable hyperdimensional models. We explore four diverse biomedical datasets, and conduct an extensive design-space exploration of key HDC hyperparameters of blockchain miners such as dimensionality, learning rate, and retraining iterations for model performance, adaptive mining difficulty and fairness on proof-of-useful-work.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Theorem-Carrying Transactions: Runtime Verification to Ensure Interface Specifications for Smart Contract Safety</title>
<link>https://arxiv.org/abs/2408.06478</link>
<guid>https://arxiv.org/abs/2408.06478</guid>
<content:encoded><![CDATA[
arXiv:2408.06478v2 Announce Type: replace 
Abstract: Security bugs and trapdoors in smart contracts have been impacting the Ethereum community since its inception. Conceptually, the 1.45-million Ethereum's contracts form a single "gigantic program" whose behaviors are determined by the complex compositions of contracts. Can programmers be assured that this gigantic program conforms to high-level safety specifications, despite unforeseeable code-level intricacies? Static code verification cannot be faithful to this gigantic program due to its scale and high polymorphism. In this paper, we present a viable approach to achieve this goal. Our technology, called Theorem-Carrying Transactions (TCT), combines the benefits of concrete execution and symbolic proofs. Under the TCT protocol, every transaction carries a theorem that proves its adherence to the specified properties in the invoked contracts, and the runtime system checks the theorem before executing the transaction. Once a theorem is proven, it will be reused for future transactions, so TCT's runtime overhead is minimal. As case studies, we demonstrate that TCT secures token contracts without foreseeing code-level intricacies, such as integer overflow and reentrancy. TCT is also successfully applied to a Uniswap codebase, showcasing a complex decentralized finance (DeFi) scenario. Our evaluation shows a negligible runtime overhead, two orders of magnitude lower than a state-of-the-art approach for runtime checking of contract code safety.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2504.06211</link>
<guid>https://arxiv.org/abs/2504.06211</guid>
<content:encoded><![CDATA[
arXiv:2504.06211v2 Announce Type: replace 
Abstract: Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in privacy-preserving and verifiable computing. ZKPs enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable machine learning, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process. Recent works have accelerated the key primitives of state-of-the-art ZKP protocols on GPU and ASIC. However, the protocols accelerated thus far face one of two challenges: they either require a trusted setup for each application, or they generate larger proof sizes with higher verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. This work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes for typical ZKP applications in publicly verifiable, consensus-based systems. We accelerate the entire protocol, including two major primitives: SumCheck and Multi-scalar Multiplications (MSMs). We develop a full-chip architecture using 366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation process, achieving geometric mean speedups of 801$\times$ over CPU baselines.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Prior: A Framework for Knowledge-Driven Prior Elicitation and Aggregation</title>
<link>https://arxiv.org/abs/2508.03766</link>
<guid>https://arxiv.org/abs/2508.03766</guid>
<content:encoded><![CDATA[
arXiv:2508.03766v1 Announce Type: new 
Abstract: The specification of prior distributions is fundamental in Bayesian inference, yet it remains a significant bottleneck. The prior elicitation process is often a manual, subjective, and unscalable task. We propose a novel framework which leverages Large Language Models (LLMs) to automate and scale this process. We introduce \texttt{LLMPrior}, a principled operator that translates rich, unstructured contexts such as natural language descriptions, data or figures into valid, tractable probability distributions. We formalize this operator by architecturally coupling an LLM with an explicit, tractable generative model, such as a Gaussian Mixture Model (forming a LLM based Mixture Density Network), ensuring the resulting prior satisfies essential mathematical properties. We further extend this framework to multi-agent systems where Logarithmic Opinion Pooling is employed to aggregate prior distributions induced by decentralized knowledge. We present the federated prior aggregation algorithm, \texttt{Fed-LLMPrior}, for aggregating distributed, context-dependent priors in a manner robust to agent heterogeneity. This work provides the foundation for a new class of tools that can potentially lower the barrier to entry for sophisticated Bayesian modeling.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>What Do Agents Think Others Would Do? Level-2 Inverse Games for Inferring Agents' Estimates of Others' Objectives</title>
<link>https://arxiv.org/abs/2508.03824</link>
<guid>https://arxiv.org/abs/2508.03824</guid>
<content:encoded><![CDATA[
arXiv:2508.03824v1 Announce Type: new 
Abstract: Effectively interpreting strategic interactions among multiple agents requires us to infer each agent's objective from limited information. Existing inverse game-theoretic approaches frame this challenge in terms of a "level-1" inference problem, in which we take the perspective of a third-party observer and assume that individual agents share complete knowledge of one another's objectives. However, this assumption breaks down in decentralized, real-world decision scenarios like urban driving and bargaining, in which agents may act based on conflicting views of one another's objectives. We demonstrate the necessity of inferring agents' heterogeneous estimates of each other's objectives through empirical examples, and by theoretically characterizing the prediction error of level-1 inference on fictitious gameplay data from linear-quadratic games. To address this fundamental issue, we propose a framework for level-2 inference to address the question: "What does each agent believe about all agents' objectives?" We prove that the level-2 inference problem is non-convex even in benign settings like linear-quadratic games, and we develop an efficient gradient-based approach for identifying local solutions. Experiments on a synthetic urban driving example show that our approach uncovers nuanced misalignments that level-1 methods miss.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advanced DAG-Based Ranking (ADR) Protocol for Blockchain Scalability</title>
<link>https://arxiv.org/abs/2508.04000</link>
<guid>https://arxiv.org/abs/2508.04000</guid>
<content:encoded><![CDATA[
arXiv:2508.04000v1 Announce Type: new 
Abstract: In the past decade, blockchain has emerged as a promising solution for building secure distributed ledgers and has attracted significant attention. However, current blockchain systems suffer from limited throughput, poor scalability, and high latency. Due to limitations in consensus mechanisms, especially in managing node identities, blockchain is often considered unsuitable for applications such as the Internet of Things (IoT). This paper proposes the Advanced DAG-based Ranking (ADR) protocol to enhance blockchain scalability and throughput. ADR employs a directed acyclic graph (DAG) structure where nodes are positioned based on their rankings. Unlike traditional chains, ADR allows honest nodes to write blocks and verify transactions using a DAG-based topology. The protocol follows a three-step approach to secure the network against double-spending and enhance performance. First, it verifies nodes using their public and private keys before granting entry. Second, it builds an advanced DAG ledger enabling block production and transaction validation. Third, a ranking algorithm filters out malicious nodes, ranks the remaining nodes based on performance, and arranges them topologically. This process increases throughput and ensures robust scalability. We evaluated ADR on Amazon EC2 clusters with over 100 nodes, including scenarios with injected malicious nodes. Simulation results demonstrate that ADR significantly improves transaction throughput and network liveness compared to existing DAG-based blockchains such as IOTA and ByteBall, making it well-suited for IoT applications.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Metaverse Framework for Wireless Systems Management</title>
<link>https://arxiv.org/abs/2508.04150</link>
<guid>https://arxiv.org/abs/2508.04150</guid>
<content:encoded><![CDATA[
arXiv:2508.04150v1 Announce Type: new 
Abstract: This article introduces a comprehensive metaverse framework, which is designed for the simulation, emulation, and interaction with wireless systems. The proposed framework integrates core metaverse technologies such as extended reality (XR), digital twins (DTs), artificial intelligence (AI), internet of things (IoT), blockchain, and advanced 6G networking solutions to create a dynamic, immersive platform for both system development and management. By leveraging XR, users can visualize and engage with complex systems, while DTs enable real-time monitoring and optimization. AI generates the three-dimensional (3D) content, enhances decision-making and system performance, whereas IoT devices provide real-time sensor data for boosting the simulation accuracy. Additionally, blockchain ensures secure, decentralized interactions, and 5G/6G networks offer the necessary infrastructure for seamless, low-latency communication. This framework serves as a robust tool for exploring, developing, and optimizing wireless systems, aiming to provide valuable insights into the future of networked environments.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Generic Framework for Optimization in Blockchain Simulators</title>
<link>https://arxiv.org/abs/2508.04157</link>
<guid>https://arxiv.org/abs/2508.04157</guid>
<content:encoded><![CDATA[
arXiv:2508.04157v1 Announce Type: new 
Abstract: As blockchain technology rapidly evolves, researchers face a significant challenge due to diverse and non-standardized simulation parameters, which hinder the replicability and comparability of research methodologies. This paper introduces a Generic Framework for Optimization in Blockchain Simulators (GFOBS), a comprehensive and adaptable solution designed to standardize and optimize blockchain simulations. GFOBS provides a flexible platform that supports various optimization algorithms, variables, and objectives, thereby catering to a wide range of blockchain research needs. The paper's key contributions are threefold: the development of GFOBS as a versatile tool for blockchain simulation optimization; the introduction of an innovative optimization method using warm starting technique; and the proposition of a novel concurrent multiprocessing technique for simultaneous simulation processes. These advancements collectively enhance the efficiency, replicability, and standardization of blockchain simulation experiments.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Information Bulletin Strategy in Impatient Queuing</title>
<link>https://arxiv.org/abs/2508.04241</link>
<guid>https://arxiv.org/abs/2508.04241</guid>
<content:encoded><![CDATA[
arXiv:2508.04241v1 Announce Type: new 
Abstract: In Sixth Generation (6G) networks, decentralized control in multi-tenant systems is a suggested enabler for autonomous network operations. However, autonomy requires independent rationale decisions be taken by tenants. This rationality can only be underpinned by timely and continuous access to status information. Despite its importance, the questions of what information should be shared, how much should be communicated, and how frequently updates should be dispatched remain open research challenges.
  This manuscript proposes an information bulletin strategy defined around two models of the system descriptor states to address these fundamental questions. The strategy is that queues periodically broadcast these information models to tenants at different time intervals, who may respond by reneging from the queue or jockeying to a more favorable one. The expectation is that over time, the queues adapt their processing rates based on what they learn from the tenant behavior. The objective is to minimize overall delay and the impatience. We formulate for this impatience as an optimization problem, whose analytical solution is intractable. We perform numerical experiments to evaluate the performance of the learned queue policy and to assess how closely it approaches optimal conditions.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SelectiveShield: Lightweight Hybrid Defense Against Gradient Leakage in Federated Learning</title>
<link>https://arxiv.org/abs/2508.04265</link>
<guid>https://arxiv.org/abs/2508.04265</guid>
<content:encoded><![CDATA[
arXiv:2508.04265v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training on decentralized data but remains vulnerable to gradient leakage attacks that can reconstruct sensitive user information. Existing defense mechanisms, such as differential privacy (DP) and homomorphic encryption (HE), often introduce a trade-off between privacy, model utility, and system overhead, a challenge that is exacerbated in heterogeneous environments with non-IID data and varying client capabilities. To address these limitations, we propose SelectiveShield, a lightweight hybrid defense framework that adaptively integrates selective homomorphic encryption and differential privacy. SelectiveShield leverages Fisher information to quantify parameter sensitivity, allowing clients to identify critical parameters locally. Through a collaborative negotiation protocol, clients agree on a shared set of the most sensitive parameters for protection via homomorphic encryption. Parameters that are uniquely important to individual clients are retained locally, fostering personalization, while non-critical parameters are protected with adaptive differential privacy noise. Extensive experiments demonstrate that SelectiveShield maintains strong model utility while significantly mitigating gradient leakage risks, offering a practical and scalable defense mechanism for real-world federated learning deployments.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Plant-Centric Metaverse: A Biocentric-Creation Framework for Ecological Art and Digital Symbiosis</title>
<link>https://arxiv.org/abs/2508.04391</link>
<guid>https://arxiv.org/abs/2508.04391</guid>
<content:encoded><![CDATA[
arXiv:2508.04391v1 Announce Type: new 
Abstract: Digital ecological art represents an emergent frontier where biological media converge with virtual environments. This study examines the paradigm shift from anthropocentric to plant-centered artistic narratives within the metaverse, contextualizing how digital platforms transform ecological expression. However, current frameworks fail to systematically guide artists in leveraging plant agency for digital symbiosis that transcends human-centered creation. We propose the Biocentric-Creation Transformation Ideology (BCTI) framework and validate it through multimodal case studies spanning bio-art, NFTs, and VR ecosystems (2013-2023). Our analysis reveals: (1) Metaverse ecosystems enable unprecedented plant-algorithm co-creation, with biological artworks increasing by 133% in premier archives (2020 vs 2013); (2) Digital symbiosis manifests through blockchain DAOs where plants govern human-plant collaborations; (3) Algorithmic photosynthesis in VR environments reshapes ecological aesthetics through real-time biodata translation. The BCTI framework advances ecological art theory by systematizing the transition from representation to plant-centered agency, offering artists a blueprint for post-anthropocene creation. This redefines environmental consciousness in virtual realms while establishing new protocols for cross-species digital collaboration.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>4-Swap: Achieving Grief-Free and Bribery-Safe Atomic Swaps Using Four Transactions</title>
<link>https://arxiv.org/abs/2508.04641</link>
<guid>https://arxiv.org/abs/2508.04641</guid>
<content:encoded><![CDATA[
arXiv:2508.04641v1 Announce Type: new 
Abstract: Cross-chain asset exchange is crucial for blockchain interoperability. Existing solutions rely on trusted third parties and risk asset loss, or use decentralized alternatives like atomic swaps, which suffer from grief attacks. Griefing occurs when a party prematurely exits, locking the counterparty's assets until a timelock expires. Hedged Atomic Swaps mitigate griefing by introducing a penalty premium; however, they increase the number of transactions from four (as in Tier Nolan's swap) to six, which in turn introduces new griefing risks. Grief-Free (GF) Swap reduces this to five transactions by consolidating assets and premiums on a single chain. However, no existing protocol achieves grief-free asset exchange in just four transactions.
  This paper presents 4-Swap, the first cross-chain atomic swap protocol that is both grief-free and bribery-safe, while completing asset exchange in just four transactions. By combining the griefing premium and principal into a single transaction per chain, 4-Swap reduces on-chain transactions, leading to faster execution compared to previous grief-free solutions. It is fully compatible with Bitcoin and operates without the need for any new opcodes. A game-theoretic analysis shows that rational participants have no incentive to deviate from the protocol, ensuring robust compliance and security.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Inequality in the Age of Pseudonymity</title>
<link>https://arxiv.org/abs/2508.04668</link>
<guid>https://arxiv.org/abs/2508.04668</guid>
<content:encoded><![CDATA[
arXiv:2508.04668v1 Announce Type: new 
Abstract: Inequality measures such as the Gini coefficient are used to inform and motivate policymaking, and are increasingly applied to digital platforms. We analyze how measures fare in pseudonymous settings, as common to internet-based or blockchain-based platforms. One key challenge that arises is the ability of actors to create multiple fake identities under fictitious false names, also known as ``Sybils.'' While some actors may do so to preserve their privacy, we show that this can inadvertently distort inequality metrics. As we show, when using inequality measures that satisfy literature's canonical set of desired properties, the presence of Sybils in an economy implies that it is impossible to properly measure the economy's inequality. Then, we present several classes of Sybil-proof measures that satisfy relaxed versions of the aforementioned desired properties, and, by fully characterizing them, we prove that the structure imposed restricts their ability to assess inequality at a fine-grained level. In addition, we prove that popular inequality metrics, including the famous Gini coefficient, are vulnerable to Sybil manipulations, and examine the dynamics that result in the creation of Sybils, whether in pseudonymous settings or traditional ones.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Stablecoins for Digital Transformation -- Design, Metrics, and Application with Real World Asset Tokenization as a Case Study</title>
<link>https://arxiv.org/abs/2508.02403</link>
<guid>https://arxiv.org/abs/2508.02403</guid>
<content:encoded><![CDATA[
arXiv:2508.02403v1 Announce Type: cross 
Abstract: Stablecoins have become a foundational component of the digital asset ecosystem, with their market capitalization exceeding 230 billion USD as of May 2025. As fiat-referenced and programmable assets, stablecoins provide low-latency, globally interoperable infrastructure for payments, decentralized finance, DeFi, and tokenized commerce. Their accelerated adoption has prompted extensive regulatory engagement, exemplified by the European Union's Markets in Crypto-assets Regulation, MiCA, the US Guiding and Establishing National Innovation for US Stablecoins Act, GENIUS Act, and Hong Kong's Stablecoins Bill. Despite this momentum, academic research remains fragmented across economics, law, and computer science, lacking a unified framework for design, evaluation, and application. This study addresses that gap through a multi-method research design. First, it synthesizes cross-disciplinary literature to construct a taxonomy of stablecoin systems based on custodial structure, stabilization mechanism, and governance. Second, it develops a performance evaluation framework tailored to diverse stakeholder needs, supported by an open-source benchmarking pipeline to ensure transparency and reproducibility. Third, a case study on Real World Asset tokenization illustrates how stablecoins operate as programmable monetary infrastructure in cross-border digital systems. By integrating conceptual theory with empirical tools, the paper contributes: a unified taxonomy for stablecoin design; a stakeholder-oriented performance evaluation framework; an empirical case linking stablecoins to sectoral transformation; and reproducible methods and datasets to inform future research. These contributions support the development of trusted, inclusive, and transparent digital monetary infrastructure.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Universal Patterns in the Blockchain: Analysis of EOAs and Smart Contracts in ERC20 Token Networks</title>
<link>https://arxiv.org/abs/2508.04671</link>
<guid>https://arxiv.org/abs/2508.04671</guid>
<content:encoded><![CDATA[
arXiv:2508.04671v1 Announce Type: cross 
Abstract: Scaling laws offer a powerful lens to understand complex transactional behaviors in decentralized systems. This study reveals distinctive statistical signatures in the transactional dynamics of ERC20 tokens on the Ethereum blockchain by examining over 44 million token transfers between July 2017 and March 2018 (9-month period). Transactions are categorized into four types: EOA--EOA, EOA--SC, SC-EOA, and SC-SC based on whether the interacting addresses are Externally Owned Accounts (EOAs) or Smart Contracts (SCs), and analyzed across three equal periods (each of 3 months). To identify universal statistical patterns, we investigate the presence of two canonical scaling laws: power law distributions and temporal Taylor's law (TL). EOA-driven transactions exhibit consistent statistical behavior, including a near-linear relationship between trade volume and unique partners with stable power law exponents ($\gamma \approx 2.3$), and adherence to TL with scaling coefficients ($\beta \approx 2.3$). In contrast, interactions involving SCs, especially SC-SC, exhibit sublinear scaling, unstable power-law exponents, and significantly fluctuating Taylor coefficients (variation in $\beta$ to be $\Delta\beta = 0.51$). Moreover, SC-driven activity displays heavier-tailed distributions ($\gamma < 2$), indicating bursty and algorithm-driven activity. These findings reveal the characteristic differences between human-controlled and automated transaction behaviors in blockchain ecosystems. By uncovering universal scaling behaviors through the integration of complex systems theory and blockchain data analytics, this work provides a principled framework for understanding the underlying mechanisms of decentralized financial systems.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CityLight: A Neighborhood-inclusive Universal Model for Coordinated City-scale Traffic Signal Control</title>
<link>https://arxiv.org/abs/2406.02126</link>
<guid>https://arxiv.org/abs/2406.02126</guid>
<content:encoded><![CDATA[
arXiv:2406.02126v4 Announce Type: replace 
Abstract: City-scale traffic signal control (TSC) involves thousands of heterogeneous intersections with varying topologies, making cooperative decision-making across intersections particularly challenging. Given the prohibitive computational cost of learning individual policies for each intersection, some researchers explore learning a universal policy to control each intersection in a decentralized manner, where the key challenge is to construct a universal representation method for heterogeneous intersections. However, existing methods are limited to universally representing information of heterogeneous ego intersections, neglecting the essential representation of influence from their heterogeneous neighbors. Universally incorporating neighborhood information is nontrivial due to the intrinsic complexity of traffic flow interactions, as well as the challenge of modeling collective influences from neighbor intersections. To address these challenges, we propose CityLight, which learns a universal policy based on representations obtained with two major modules: a Neighbor Influence Encoder to explicitly model neighbor's influence with specified traffic flow relation and connectivity to the ego intersection; a Neighbor Influence Aggregator to attentively aggregate the influence of neighbors based on their mutual competitive relations. Extensive experiments on five city-scale datasets, ranging from 97 to 13,952 intersections, confirm the efficacy of CityLight, with an average throughput improvement of 11.68% and a lift of 22.59% for generalization.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding Across Different Environments and Tasks</title>
<link>https://arxiv.org/abs/2503.02992</link>
<guid>https://arxiv.org/abs/2503.02992</guid>
<content:encoded><![CDATA[
arXiv:2503.02992v2 Announce Type: replace 
Abstract: Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the community's continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Slow is Fast! Dissecting Ethereum's Slow Liquidity Drain Scams</title>
<link>https://arxiv.org/abs/2503.04850</link>
<guid>https://arxiv.org/abs/2503.04850</guid>
<content:encoded><![CDATA[
arXiv:2503.04850v3 Announce Type: replace 
Abstract: We identify the slow liquidity drain (SLID) scam, an insidious and highly profitable threat to decentralized finance (DeFi), posing a large-scale, persistent, and growing risk to the ecosystem. Unlike traditional scams such as rug pulls or honeypots (USENIX Sec'19, USENIX Sec'23), SLID gradually siphons funds from liquidity pools over extended periods, making detection significantly more challenging. In this paper, we conducted the first large-scale empirical analysis of 319,166 liquidity pools across six major decentralized exchanges (DEXs) since 2018. We identified 3,117 SLID affected liquidity pools, resulting in cumulative losses of more than US$103 million. We propose a rule-based heuristic and an enhanced machine learning model for early detection. Our machine learning model achieves a detection speed 4.77 times faster than the heuristic while maintaining 95% accuracy. Our study establishes a foundation for protecting DeFi investors at an early stage and promoting transparency in the DeFi ecosystem.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges</title>
<link>https://arxiv.org/abs/2508.02773</link>
<guid>https://arxiv.org/abs/2508.02773</guid>
<content:encoded><![CDATA[
arXiv:2508.02773v1 Announce Type: new 
Abstract: The convergence of Web3 technologies and AI agents represents a rapidly evolving frontier poised to reshape decentralized ecosystems. This paper presents the first and most comprehensive analysis of the intersection between Web3 and AI agents, examining five critical dimensions: landscape, economics, governance, security, and trust mechanisms. Through an analysis of 133 existing projects, we first develop a taxonomy and systematically map the current market landscape (RQ1), identifying distinct patterns in project distribution and capitalization. Building upon these findings, we further investigate four key integrations: (1) the role of AI agents in participating in and optimizing decentralized finance (RQ2); (2) their contribution to enhancing Web3 governance mechanisms (RQ3); (3) their capacity to strengthen Web3 security via intelligent vulnerability detection and automated smart contract auditing (RQ4); and (4) the establishment of robust reliability frameworks for AI agent operations leveraging Web3's inherent trust infrastructure (RQ5). By synthesizing these dimensions, we identify key integration patterns, highlight foundational challenges related to scalability, security, and ethics, and outline critical considerations for future research toward building robust, intelligent, and trustworthy decentralized systems with effective AI agent interactions.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Fast Adaptation of Delayed Clients in Decentralized Federated Learning: A Centroid-Aligned Distillation Approach</title>
<link>https://arxiv.org/abs/2508.02993</link>
<guid>https://arxiv.org/abs/2508.02993</guid>
<content:encoded><![CDATA[
arXiv:2508.02993v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) struggles with the slow adaptation of late-joining delayed clients and high communication costs in asynchronous environments. These limitations significantly hinder overall performance. To address this, we propose DFedCAD, a novel framework for rapid adaptation via Centroid-Aligned Distillation. DFedCAD first employs Weighted Cluster Pruning (WCP) to compress models into representative centroids, drastically reducing communication overhead. It then enables delayed clients to intelligently weigh and align with peer knowledge using a novel structural distance metric and a differentiable k-means distillation module, facilitating efficient end-to-end knowledge transfer. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that DFedCAD consistently achieves state-of-the-art performance, attaining the highest accuracy across all evaluated settings while reducing communication overhead by over 86%. Our framework provides a scalable and practical solution for efficient decentralized learning in dynamic, real-world scenarios.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of AI Agent Registry Solutions</title>
<link>https://arxiv.org/abs/2508.03095</link>
<guid>https://arxiv.org/abs/2508.03095</guid>
<content:encoded><![CDATA[
arXiv:2508.03095v1 Announce Type: new 
Abstract: As As autonomous AI agents scale across cloud, enterprise, and decentralized environments, the need for standardized registry systems to support discovery, identity, and capability sharing has become essential. This paper surveys three prominent registry approaches each defined by a unique metadata model: MCP's mcp.json, A2A's Agent Card, and NANDA's AgentFacts. MCP uses a centralized metaregistry with GitHub authenticated publishing and structured metadata for server discovery. A2A enables decentralized interaction via JSON-based Agent Cards, discoverable through well-known URIs, curated catalogs, or direct configuration. NANDA Index introduces AgentFacts, a cryptographically verifiable and privacy-preserving metadata model designed for dynamic discovery, credentialed capabilities, and cross-domain interoperability. These approaches are compared across four dimensions: security, scalability, authentication, and maintainability. The paper concludes with suggestions and recommendations to guide future design and adoption of registry systems for the Internet of AI Agents.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedPromo: Federated Lightweight Proxy Models at the Edge Bring New Domains to Foundation Models</title>
<link>https://arxiv.org/abs/2508.03356</link>
<guid>https://arxiv.org/abs/2508.03356</guid>
<content:encoded><![CDATA[
arXiv:2508.03356v1 Announce Type: new 
Abstract: Federated Learning (FL) is an established paradigm for training deep learning models on decentralized data. However, as the size of the models grows, conventional FL approaches often require significant computational resources on client devices, which may not be feasible. We introduce FedPromo, a novel framework that enables efficient adaptation of large-scale foundation models stored on a central server to new domains encountered only by remote clients. Instead of directly training the large model on client devices, FedPromo optimizes lightweight proxy models via FL, significantly reducing computational overhead while maintaining privacy. Our method follows a two-stage process: first, server-side knowledge distillation aligns the representations of a large-scale foundation model (e.g., a transformer) with those of a compact counterpart (e.g., a CNN). Then, the compact model encoder is deployed to client devices, where trainable classifiers are learned locally. These classifiers are subsequently aggregated and seamlessly transferred back to the foundation model, facilitating personalized adaptation without requiring direct access to user data. Through novel regularization strategies, our framework enables decentralized multi-domain learning, balancing performance, privacy, and resource efficiency. Extensive experiments on five image classification benchmarks demonstrate that FedPromo outperforms existing methods while assuming limited-resource clients.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking Classical and Quantum Models for DeFi Yield Prediction on Curve Finance</title>
<link>https://arxiv.org/abs/2508.02685</link>
<guid>https://arxiv.org/abs/2508.02685</guid>
<content:encoded><![CDATA[
arXiv:2508.02685v1 Announce Type: cross 
Abstract: The rise of decentralized finance (DeFi) has created a growing demand for accurate yield and performance forecasting to guide liquidity allocation strategies. In this study, we benchmark six models, XGBoost, Random Forest, LSTM, Transformer, quantum neural networks (QNN), and quantum support vector machines with quantum feature maps (QSVM-QNN), on one year of historical data from 28 Curve Finance pools. We evaluate model performance on test MAE, RMSE, and directional accuracy. Our results show that classical ensemble models, particularly XGBoost and Random Forest, consistently outperform both deep learning and quantum models. XGBoost achieves the highest directional accuracy (71.57%) with a test MAE of 1.80, while Random Forest attains the lowest test MAE of 1.77 and 71.36% accuracy. In contrast, quantum models underperform with directional accuracy below 50% and higher errors, highlighting current limitations in applying quantum machine learning to real-world DeFi time series data. This work offers a reproducible benchmark and practical insights into model suitability for DeFi applications, emphasizing the robustness of classical methods over emerging quantum approaches in this domain.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Graph-based Concurrency Control for Long-running Update Transactions (Extended Version)</title>
<link>https://arxiv.org/abs/2210.04179</link>
<guid>https://arxiv.org/abs/2210.04179</guid>
<content:encoded><![CDATA[
arXiv:2210.04179v2 Announce Type: replace 
Abstract: This paper proposes Oze, a concurrency control protocol that handles heterogeneous workloads, including long-running update transactions. Oze explores a large scheduling space using a multi-version serialization graph to reduce false positives. Oze manages the graph in a decentralized manner to exploit many cores in modern servers. We further propose an OLTP benchmark, BoMB (Bill of Materials Benchmark), based on a use case in an actual manufacturing company. BoMB consists of one long-running update transaction and five short transactions that conflict with each other. Experiments using BoMB show that Oze can handle the long-running update transaction while achieving four orders of magnitude higher throughput than state-of-the-art optimistic and multi-version protocols and up to five times higher throughput than pessimistic protocols. We also show Oze performs comparably with existing techniques even in a typical OLTP workload, TPC-C, thanks to a protocol switching mechanism.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TVDO: Tchebycheff Value-Decomposition Optimization for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2306.13979</link>
<guid>https://arxiv.org/abs/2306.13979</guid>
<content:encoded><![CDATA[
arXiv:2306.13979v2 Announce Type: replace 
Abstract: In cooperative multiagent reinforcement learning (MARL), centralized training with decentralized execution (CTDE) has recently attracted more attention due to the physical demand. However, the most dilemma therein is the inconsistency between jointly-trained policies and individually-executed actions. In this article, we propose a factorized Tchebycheff value-decomposition optimization (TVDO) method to overcome the trouble of inconsistency. In particular, a nonlinear Tchebycheff aggregation function is formulated to realize the global optimum by tightly constraining the upper bound of individual action-value bias, which is inspired by the Tchebycheff method of multi-objective optimization. We theoretically prove that, under no extra limitations, the factorized value decomposition with Tchebycheff aggregation satisfies the sufficiency and necessity of Individual-Global-Max (IGM), which guarantees the consistency between the global and individual optimal action-value function. Empirically, in the climb and penalty game, we verify that TVDO precisely expresses the global-to-individual value decomposition with a guarantee of policy consistency. Meanwhile, we evaluate TVDO in the SMAC benchmark, and extensive experiments demonstrate that TVDO achieves a significant performance superiority over some SOTA MARL baselines.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trusted Routing for Blockchain-Empowered UAV Networks via Multi-Agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2508.00938</link>
<guid>https://arxiv.org/abs/2508.00938</guid>
<content:encoded><![CDATA[
arXiv:2508.00938v1 Announce Type: new 
Abstract: Due to the high flexibility and versatility, unmanned aerial vehicles (UAVs) are leveraged in various fields including surveillance and disaster rescue.However, in UAV networks, routing is vulnerable to malicious damage due to distributed topologies and high dynamics. Hence, ensuring the routing security of UAV networks is challenging. In this paper, we characterize the routing process in a time-varying UAV network with malicious nodes. Specifically, we formulate the routing problem to minimize the total delay, which is an integer linear programming and intractable to solve. Then, to tackle the network security issue, a blockchain-based trust management mechanism (BTMM) is designed to dynamically evaluate trust values and identify low-trust UAVs. To improve traditional practical Byzantine fault tolerance algorithms in the blockchain, we propose a consensus UAV update mechanism. Besides, considering the local observability, the routing problem is reformulated into a decentralized partially observable Markov decision process. Further, a multi-agent double deep Q-network based routing algorithm is designed to minimize the total delay. Finally, simulations are conducted with attacked UAVs and numerical results show that the delay of the proposed mechanism decreases by 13.39$\%$, 12.74$\%$, and 16.6$\%$ than multi-agent proximal policy optimal algorithms, multi-agent deep Q-network algorithms, and methods without BTMM, respectively.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Soft Separation and Distillation: Toward Global Uniformity in Federated Unsupervised Learning</title>
<link>https://arxiv.org/abs/2508.01251</link>
<guid>https://arxiv.org/abs/2508.01251</guid>
<content:encoded><![CDATA[
arXiv:2508.01251v1 Announce Type: new 
Abstract: Federated Unsupervised Learning (FUL) aims to learn expressive representations in federated and self-supervised settings. The quality of representations learned in FUL is usually determined by uniformity, a measure of how uniformly representations are distributed in the embedding space. However, existing solutions perform well in achieving intra-client (local) uniformity for local models while failing to achieve inter-client (global) uniformity after aggregation due to non-IID data distributions and the decentralized nature of FUL. To address this issue, we propose Soft Separation and Distillation (SSD), a novel approach that preserves inter-client uniformity by encouraging client representations to spread toward different directions. This design reduces interference during client model aggregation, thereby improving global uniformity while preserving local representation expressiveness. We further enhance this effect by introducing a projector distillation module to address the discrepancy between loss optimization and representation quality. We evaluate SSD in both cross-silo and cross-device federated settings, demonstrating consistent improvements in representation quality and task performance across various training scenarios. Our results highlight the importance of inter-client uniformity in FUL and establish SSD as an effective solution to this challenge. Project page: https://ssd-uniformity.github.io/
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain security based on cryptography: a review</title>
<link>https://arxiv.org/abs/2508.01280</link>
<guid>https://arxiv.org/abs/2508.01280</guid>
<content:encoded><![CDATA[
arXiv:2508.01280v1 Announce Type: new 
Abstract: As an emerging service framework built by combining cryptography, P2P network, consensus mechanism and innovative contract technology, blockchain has been widely used in digital finance, data sharing, message traceability and electronic evidence preservation because of its decentralised, non-tamperable and transaction traceability. However, with the complex and changeable application scenarios of blockchain technology and the continuous enhancement of blockchain attack technology, the security of the blockchain system has been seriously threatened, dramatically affecting the development and application of blockchain technology. This paper aims to analyse the attacks on blockchain from the perspective of cryptography. Firstly, from the cryptography technology in the blockchain, the principle of hash functions, digital signatures, and other technologies, as well as their role in the blockchain, are introduced. Then, based on the six-layer architecture of the blockchain, the attacks on the data layer, the network layer, the consensus layer, the contract layer, the incentive layer and the application layer are analysed, and the methods to mitigate or resist the attacks are proposed. Secondly, the attack principles of 51% attack, Double-Spending attack, Reentrancy attack, Replay attack, Sybil attack and Timestamp Tampering attack were analysed, and the mitigation or defence solutions for these six attacks were designed. Finally, the core problems to be solved in blockchain technology are summarised, and the future development of blockchain security technology is projected.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockA2A: Towards Secure and Verifiable Agent-to-Agent Interoperability</title>
<link>https://arxiv.org/abs/2508.01332</link>
<guid>https://arxiv.org/abs/2508.01332</guid>
<content:encoded><![CDATA[
arXiv:2508.01332v1 Announce Type: new 
Abstract: The rapid adoption of agentic AI, powered by large language models (LLMs), is transforming enterprise ecosystems with autonomous agents that execute complex workflows. Yet we observe several key security vulnerabilities in LLM-driven multi-agent systems (MASes): fragmented identity frameworks, insecure communication channels, and inadequate defenses against Byzantine agents or adversarial prompts. In this paper, we present the first systematic analysis of these emerging multi-agent risks and explain why the legacy security strategies cannot effectively address these risks. Afterwards, we propose BlockA2A, the first unified multi-agent trust framework that enables secure and verifiable and agent-to-agent interoperability. At a high level, BlockA2A adopts decentralized identifiers (DIDs) to enable fine-grained cross-domain agent authentication, blockchain-anchored ledgers to enable immutable auditability, and smart contracts to dynamically enforce context-aware access control policies. BlockA2A eliminates centralized trust bottlenecks, ensures message authenticity and execution integrity, and guarantees accountability across agent interactions. Furthermore, we propose a Defense Orchestration Engine (DOE) that actively neutralizes attacks through real-time mechanisms, including Byzantine agent flagging, reactive execution halting, and instant permission revocation. Empirical evaluations demonstrate BlockA2A's effectiveness in neutralizing prompt-based, communication-based, behavioral and systemic MAS attacks. We formalize its integration into existing MAS and showcase a practical implementation for Google's A2A protocol. Experiments confirm that BlockA2A and DOE operate with sub-second overhead, enabling scalable deployment in production LLM-based MAS environments.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>UEChecker: Detecting Unchecked External Call Vulnerabilities in DApps via Graph Analysis</title>
<link>https://arxiv.org/abs/2508.01343</link>
<guid>https://arxiv.org/abs/2508.01343</guid>
<content:encoded><![CDATA[
arXiv:2508.01343v1 Announce Type: new 
Abstract: The increasing number of attacks on the contract layer of DApps has resulted in economic losses amounting to $66 billion. Vulnerabilities arise when contracts interact with external protocols without verifying the results of the calls, leading to exploit entry points such as flash loan attacks and reentrancy attacks. In this paper, we propose UEChecker, a deep learning-based tool that utilizes a call graph and a Graph Convolutional Network to detect unchecked external call vulnerabilities. We design the following components: An edge prediction module that reconstructs the feature representation of nodes and edges in the call graph; A node aggregation module that captures structural information from both the node itself and its neighbors, thereby enhancing feature representation between nodes and improving the model's understanding of the global graph structure; A Conformer Block module that integrates multi-head attention, convolutional modules, and feedforward neural networks to more effectively capture dependencies of different scales within the call graph, extending beyond immediate neighbors and enhancing the performance of vulnerability detection. Finally, we combine these modules with Graph Convolutional Network to detect unchecked external call vulnerabilities. By auditing the smart contracts of 608 DApps, our results show that our tool achieves an accuracy of 87.59% in detecting unchecked external call vulnerabilities. Furthermore, we compare our tool with GAT, LSTM, and GCN baselines, and in the comparison experiments, UEChecker consistently outperforms these models in terms of accuracy.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MultiCFV: Detecting Control Flow Vulnerabilities in Smart Contracts Leveraging Multimodal Deep Learning</title>
<link>https://arxiv.org/abs/2508.01346</link>
<guid>https://arxiv.org/abs/2508.01346</guid>
<content:encoded><![CDATA[
arXiv:2508.01346v1 Announce Type: new 
Abstract: The introduction of smart contract functionality marks the advent of the blockchain 2.0 era, enabling blockchain technology to support digital currency transactions and complex distributed applications. However, many smart contracts have been found to contain vulnerabilities and errors, leading to the loss of assets within the blockchain. Despite a range of tools that have been developed to identify vulnerabilities in smart contracts at the source code or bytecode level, most rely on a single modality, reducing performance, accuracy, and limited generalization capabilities. This paper proposes a multimodal deep learning approach, MultiCFV, which is designed specifically to analyze and detect erroneous control flow vulnerability, as well as identify code clones in smart contracts. Bytecode is generated from source code to construct control flow graphs, with graph embedding techniques extracting graph features. Abstract syntax trees are used to obtain syntax features, while code comments capture key commentary words and comment features. These three feature vectors are fused to create a database for code inspection, which is used to detect similar code and identify contract vulnerabilities. Experimental results demonstrate our method effectively combines structural, syntactic, and semantic information, improving the accuracy of smart contract vulnerability detection and clone detection.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Convergence Analysis of Aggregation-Broadcast in LoRA-enabled Federated Learning</title>
<link>https://arxiv.org/abs/2508.01348</link>
<guid>https://arxiv.org/abs/2508.01348</guid>
<content:encoded><![CDATA[
arXiv:2508.01348v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized data sources while preserving data privacy. However, the growing size of Machine Learning (ML) models poses communication and computation challenges in FL. Low-Rank Adaptation (LoRA) has recently been introduced into FL as an efficient fine-tuning method, reducing communication overhead by updating only a small number of trainable parameters. Despite its effectiveness, how to aggregate LoRA-updated local models on the server remains a critical and understudied problem. In this paper, we provide a unified convergence analysis for LoRA-based FL. We first categories the current aggregation method into two major type: Sum-Product (SP) and Product-Sum (PS). Then we formally define the Aggregation-Broadcast Operator (ABO) and derive a general convergence condition under mild assumptions. Furthermore, we present several sufficient conditions that guarantee convergence of the global model. These theoretical analyze offer a principled understanding of various aggregation strategies. Notably, we prove that the SP and PS aggregation methods both satisfy our convergence condition, but differ in their ability to achieve the optimal convergence rate. Extensive experiments on standard benchmarks validate our theoretical findings.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NATLM: Detecting Defects in NFT Smart Contracts Leveraging LLM</title>
<link>https://arxiv.org/abs/2508.01351</link>
<guid>https://arxiv.org/abs/2508.01351</guid>
<content:encoded><![CDATA[
arXiv:2508.01351v1 Announce Type: new 
Abstract: Security issues are becoming increasingly significant with the rapid evolution of Non-fungible Tokens (NFTs). As NFTs are traded as digital assets, they have emerged as prime targets for cyber attackers. In the development of NFT smart contracts, there may exist undiscovered defects that could lead to substantial financial losses if exploited. To tackle this issue, this paper presents a framework called NATLM(NFT Assistant LLM), designed to detect potential defects in NFT smart contracts. The framework effectively identifies four common types of vulnerabilities in NFT smart contracts: ERC-721 Reentrancy, Public Burn, Risky Mutable Proxy, and Unlimited Minting. Relying exclusively on large language models (LLMs) for defect detection can lead to a high false-positive rate. To enhance detection performance, NATLM integrates static analysis with LLMs, specifically Gemini Pro 1.5. Initially, NATLM employs static analysis to extract structural, syntactic, and execution flow information from the code, represented through Abstract Syntax Trees (AST) and Control Flow Graphs (CFG). These extracted features are then combined with vectors of known defect examples to create a matrix for input into the knowledge base. Subsequently, the feature vectors and code vectors of the analyzed contract are compared with the contents of the knowledge base. Finally, the LLM performs deep semantic analysis to enhance detection capabilities, providing a more comprehensive and accurate identification of potential security issues. Experimental results indicate that NATLM analyzed 8,672 collected NFT smart contracts, achieving an overall precision of 87.72%, a recall of 89.58%, and an F1 score of 88.94%. The results outperform other baseline experiments, successfully identifying four common types of defects.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prompt to Pwn: Automated Exploit Generation for Smart Contracts</title>
<link>https://arxiv.org/abs/2508.01371</link>
<guid>https://arxiv.org/abs/2508.01371</guid>
<content:encoded><![CDATA[
arXiv:2508.01371v1 Announce Type: new 
Abstract: We explore the feasibility of using LLMs for Automated Exploit Generation (AEG) against vulnerable smart contracts. We present \textsc{ReX}, a framework integrating LLM-based exploit synthesis with the Foundry testing suite, enabling the automated generation and validation of proof-of-concept (PoC) exploits. We evaluate five state-of-the-art LLMs (GPT-4.1, Gemini 2.5 Pro, Claude Opus 4, DeepSeek, and Qwen3 Plus) on both synthetic benchmarks and real-world smart contracts affected by known high-impact exploits. Our results show that modern LLMs can reliably generate functional PoC exploits for diverse vulnerability types, with success rates reaching up to 92\%. Notably, Gemini 2.5 Pro and GPT-4.1 consistently outperform others in both synthetic and real-world scenarios. We further analyze factors influencing AEG effectiveness, including model capabilities, contract structure, and vulnerability types. We also collect the first curated dataset of real-world PoC exploits to support future research.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nakamoto Consensus from Multiple Resources</title>
<link>https://arxiv.org/abs/2508.01448</link>
<guid>https://arxiv.org/abs/2508.01448</guid>
<content:encoded><![CDATA[
arXiv:2508.01448v1 Announce Type: new 
Abstract: The blocks in the Bitcoin blockchain record the amount of work W that went into creating them through proofs of work. When honest parties control a majority of the work, consensus is achieved by picking the chain with the highest recorded weight. Resources other than work have been considered to secure such longest-chain blockchains. In Chia, blocks record the amount of space S (via a proof of space) and sequential computational steps V (via a VDF).
  In this paper, we ask what weight functions {\Gamma}(S,V,W) (that assign a weight to a block as a function of the recorded space, speed, and work) are secure in the sense that whenever the weight of the resources controlled by honest parties is larger than the weight of adversarial parties, the blockchain is secure against private double-spending attacks.
  We completely classify such functions in an idealized "continuous" model: {\Gamma}(S,V,W) is secure against private double-spending attacks if and only if it is homogeneous of degree one in the timed resources V and W, i.e., {\alpha}{\Gamma}(S,V,W)={\Gamma}(S,{\alpha}V, {\alpha}W). This includes Bitcoin rule {\Gamma}(S,V,W)=W and Chia rule {\Gamma}(S,V,W) = SV. In a more realistic model where blocks are created at discrete time-points, one additionally needs some mild assumptions on the dependency on S (basically, the weight should not grow too much if S is slightly increased, say linear as in Chia).
  Our classification is more general and allows various instantiations of the same resource. It provides a powerful tool for designing new longest-chain blockchains. E.g., consider combining different PoWs to counter centralization, say the Bitcoin PoW W_1 and a memory-hard PoW W_2. Previous work suggested to use W_1+W_2 as weight. Our results show that using {\sqrt}(W_1){\cdot}{\sqrt}(W_2), {\min}{W_1,W_2} are also secure, and we argue that in practice these are much better choices.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2508.01522</link>
<guid>https://arxiv.org/abs/2508.01522</guid>
<content:encoded><![CDATA[
arXiv:2508.01522v1 Announce Type: new 
Abstract: This paper presents the first decentralized method to enable real-world 6-DoF manipulation of a cable-suspended load using a team of Micro-Aerial Vehicles (MAVs). Our method leverages multi-agent reinforcement learning (MARL) to train an outer-loop control policy for each MAV. Unlike state-of-the-art controllers that utilize a centralized scheme, our policy does not require global states, inter-MAV communications, nor neighboring MAV information. Instead, agents communicate implicitly through load pose observations alone, which enables high scalability and flexibility. It also significantly reduces computing costs during inference time, enabling onboard deployment of the policy. In addition, we introduce a new action space design for the MAVs using linear acceleration and body rates. This choice, combined with a robust low-level controller, enables reliable sim-to-real transfer despite significant uncertainties caused by cable tension during dynamic 3D motion. We validate our method in various real-world experiments, including full-pose control under load model uncertainties, showing setpoint tracking performance comparable to the state-of-the-art centralized method. We also demonstrate cooperation amongst agents with heterogeneous control policies, and robustness to the complete in-flight loss of one MAV. Videos of experiments: https://autonomousrobots.nl/paper_websites/aerial-manipulation-marl
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revisiting Gossip Protocols: A Vision for Emergent Coordination in Agentic Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2508.01531</link>
<guid>https://arxiv.org/abs/2508.01531</guid>
<content:encoded><![CDATA[
arXiv:2508.01531v1 Announce Type: new 
Abstract: As agentic platforms scale, agents are evolving beyond static roles and fixed toolchains, creating a growing need for flexible, decentralized coordination. Today's structured communication protocols (e.g., direct agent-to-agent messaging) excel at reliability and task delegation, but they fall short in enabling emergent, swarm-like intelligence, where distributed agents continuously learn, adapt, and communicate to form collective cognition. This paper revisits gossip protocols, long valued in distributed systems for their fault tolerance and decentralization, and argues that they offer a missing layer for context-rich, adaptive communication in agentic AI. Gossip enables scalable, low-overhead dissemination of shared knowledge, but also raises unresolved challenges around semantic filtering, staleness, trustworthiness, and consistency in high-stakes environments. Rather than proposing a new framework, this work charts a research agenda for integrating gossip as a complementary substrate alongside structured protocols. We identify critical gaps in current agent-to-agent architectures, highlight where gossip could reshape assumptions about coordination, and outline open questions around intent propagation, knowledge decay, and peer-to-peer trust. Gossip is not a silver bullet, but overlooking it risks missing a key path toward resilient, reflexive, and self-organizing multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Asynchronous Federated Learning with non-convex client objective functions and heterogeneous dataset</title>
<link>https://arxiv.org/abs/2508.01675</link>
<guid>https://arxiv.org/abs/2508.01675</guid>
<content:encoded><![CDATA[
arXiv:2508.01675v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized devices while preserving data privacy. However, traditional FL suffers from communication overhead, system heterogeneity, and straggler effects. Asynchronous Federated Learning (AFL) addresses these by allowing clients to update independently, improving scalability and reducing synchronization delays. This paper extends AFL to handle non-convex objective functions and heterogeneous datasets, common in modern deep learning. We present a rigorous convergence analysis, deriving bounds on the expected gradient norm and studying the effects of staleness, variance, and heterogeneity. To mitigate stale updates, we introduce a staleness aware aggregation that prioritizes fresher updates and a dynamic learning rate schedule that adapts to client staleness and heterogeneity, improving stability and convergence. Our framework accommodates variations in computational power, data distribution, and communication delays, making it practical for real world applications. We also analyze the impact of client selection strategies-sampling with or without replacement-on variance and convergence. Implemented in PyTorch with Python's asyncio, our approach is validated through experiments demonstrating improved performance and scalability for asynchronous, heterogeneous, and non-convex FL scenarios.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Provably Secure Network Protocol for Private Communication with Analysis and Tracing Resistance</title>
<link>https://arxiv.org/abs/2508.01714</link>
<guid>https://arxiv.org/abs/2508.01714</guid>
<content:encoded><![CDATA[
arXiv:2508.01714v1 Announce Type: new 
Abstract: Anonymous communication networks have emerged as crucial tools for obfuscating communication pathways and concealing user identities. However, their practical deployments face significant challenges, including susceptibility to artificial intelligence (AI)-powered metadata analysis, difficulties in decentralized architectures, and the absence of provable security guarantees. To address these issues, this paper proposes a novel decentralized anonymous routing protocol with resistance to tracing and traffic analysis. The protocol eliminates dependencies on the threshold model and trusted third-party setups, ensuring indistinguishable identity privacy even in highly adversarial environments. Different from traditional empirical security analysis of anonymous networks, this paper rigorously proves indistinguishable identity privacy for users even in extremely adversarial environments. Furthermore, simulations confirm its practical feasibility, demonstrating both security and efficiency. By achieving information sharing with privacy preservation, the proposed protocol offers a provably secure solution for privacy-preserving communication in digital environments.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Byzantine Consensus MechanismBased on Reputation in IoT Blockchain</title>
<link>https://arxiv.org/abs/2508.01856</link>
<guid>https://arxiv.org/abs/2508.01856</guid>
<content:encoded><![CDATA[
arXiv:2508.01856v1 Announce Type: new 
Abstract: Blockchain technology has advanced rapidly in recent years and is now widely used in a variety of fields. Blockchain appears to be one of the best solutions for managing massive heterogeneous devices while achieving advanced data security and data reputation, particularly in the field of large-scale IoT (Internet of Things) networks. Despite the numerous advantages, there are still challenges while deploying IoT applications on blockchain systems due to the limited storage, power, and computing capability of IoT devices, and some of these problems are caused by the consensus algorithm, which plays a significant role in blockchain systems by ensuring overall system reliability and robustness. Nonetheless, most existing consensus algorithms are prone to poor node reliability, low transaction per second (TPS) rates, and scalability issues. Aiming at some critical problems in the existing consensus algorithms, this paper proposes the Efficient Byzantine Reputation-based Consensus (EBRC) mechanism to resolve the issues raised above. In comparison to traditional algorithms, we reinvented ways to evaluate node reliability and robustness and manage active nodes. Our experiments show that the EBRC algorithm has lower consensus delay, higher throughput, improved security, and lower verification costs. It offers new reference ideas for solving the Internet of Things+blockchain+Internet court construction problem.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Day-Ahead Energy Trading with Proximal Policy Optimization and Blockchain</title>
<link>https://arxiv.org/abs/2508.01888</link>
<guid>https://arxiv.org/abs/2508.01888</guid>
<content:encoded><![CDATA[
arXiv:2508.01888v1 Announce Type: new 
Abstract: The increasing penetration of renewable energy sources in day-ahead energy markets introduces challenges in balancing supply and demand, ensuring grid resilience, and maintaining trust in decentralized trading systems. This paper proposes a novel framework that integrates the Proximal Policy Optimization (PPO) algorithm, a state-of-the-art reinforcement learning method, with blockchain technology to optimize automated trading strategies for prosumers in day-ahead energy markets. We introduce a comprehensive framework that employs RL agent for multi-objective energy optimization and blockchain for tamper-proof data and transaction management. Simulations using real-world data from the Electricity Reliability Council of Texas (ERCOT) demonstrate the effectiveness of our approach. The RL agent achieves demand-supply balancing within 2\% and maintains near-optimal supply costs for the majority of the operating hours. Moreover, it generates robust battery storage policies capable of handling variability in solar and wind generation. All decisions are recorded on an Algorand-based blockchain, ensuring transparency, auditability, and security - key enablers for trustworthy multi-agent energy trading. Our contributions include a novel system architecture, curriculum learning for robust agent development, and actionable policy insights for practical deployment.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Decentralized Framework for Ethical Authorship Validation in Academic Publishing: Leveraging Self-Sovereign Identity and Blockchain Technology</title>
<link>https://arxiv.org/abs/2508.01913</link>
<guid>https://arxiv.org/abs/2508.01913</guid>
<content:encoded><![CDATA[
arXiv:2508.01913v1 Announce Type: new 
Abstract: Academic publishing, integral to knowledge dissemination and scientific advancement, increasingly faces threats from unethical practices such as unconsented authorship, gift authorship, author ambiguity, and undisclosed conflicts of interest. While existing infrastructures like ORCID effectively disambiguate researcher identities, they fall short in enforcing explicit authorship consent, accurately verifying contributor roles, and robustly detecting conflicts of interest during peer review. To address these shortcomings, this paper introduces a decentralized framework leveraging Self-Sovereign Identity (SSI) and blockchain technology. The proposed model uses Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) to securely verify author identities and contributions, reducing ambiguity and ensuring accurate attribution. A blockchain-based trust registry records authorship consent and peer-review activity immutably. Privacy-preserving cryptographic techniques, especially Zero-Knowledge Proofs (ZKPs), support conflict-of-interest detection without revealing sensitive data. Verified authorship metadata and consent records are embedded in publications, increasing transparency. A stakeholder survey of researchers, editors, and reviewers suggests the framework improves ethical compliance and confidence in scholarly communication. This work represents a step toward a more transparent, accountable, and trustworthy academic publishing ecosystem.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DIRF: A Framework for Digital Identity Protection and Clone Governance in Agentic AI Systems</title>
<link>https://arxiv.org/abs/2508.01997</link>
<guid>https://arxiv.org/abs/2508.01997</guid>
<content:encoded><![CDATA[
arXiv:2508.01997v1 Announce Type: new 
Abstract: The rapid advancement and widespread adoption of generative artificial intelligence (AI) pose significant threats to the integrity of personal identity, including digital cloning, sophisticated impersonation, and the unauthorized monetization of identity-related data. Mitigating these risks necessitates the development of robust AI-generated content detection systems, enhanced legal frameworks, and ethical guidelines. This paper introduces the Digital Identity Rights Framework (DIRF), a structured security and governance model designed to protect behavioral, biometric, and personality-based digital likeness attributes to address this critical need. Structured across nine domains and 63 controls, DIRF integrates legal, technical, and hybrid enforcement mechanisms to secure digital identity consent, traceability, and monetization. We present the architectural foundations, enforcement strategies, and key use cases supporting the need for a unified framework. This work aims to inform platform builders, legal entities, and regulators about the essential controls needed to enforce identity rights in AI-driven systems.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Actual Usage Of Cryptocurrency By Individuals</title>
<link>https://arxiv.org/abs/2508.02086</link>
<guid>https://arxiv.org/abs/2508.02086</guid>
<content:encoded><![CDATA[
arXiv:2508.02086v1 Announce Type: new 
Abstract: This study investigates how media influence and educational resources shape individual engagement with cryptocurrencies. As digital assets become increasingly mainstream, social media platforms, influencers, and financial analysts play a central role in driving public interest and investment behavior. Quantitative surveys and qualitative interviews reveal that persuasive narratives and success stories on social media often attract new investors, while accessible educational materials empower individuals to make informed decisions in a volatile market. The findings highlight that media exposure can spark initial adoption, but sustained and responsible participation depends on comprehensive education in cryptocurrency fundamentals, trading strategies, and blockchain technology
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoftPUF: a Software-Based Blockchain Framework using PUF and Machine Learning</title>
<link>https://arxiv.org/abs/2508.02438</link>
<guid>https://arxiv.org/abs/2508.02438</guid>
<content:encoded><![CDATA[
arXiv:2508.02438v1 Announce Type: new 
Abstract: Physically Unclonable Function (PUF) offers a secure and lightweight alternative to traditional cryptography for authentication due to their unique device fingerprint. However, their dependence on specialized hardware hinders their adoption in diverse applications. This paper proposes a novel blockchain framework that leverages SoftPUF, a software-based approach mimicking PUF. SoftPUF addresses the hardware limitations of traditional PUF, enabling secure and efficient authentication for a broader range of devices within a blockchain network. The framework utilizes a machine learning model trained on PUF data to generate unique, software-based keys for each device. These keys serve as secure identifiers for authentication on the blockchain, eliminating the need for dedicated hardware. This approach facilitates the integration of legacy devices from various domains, including cloud-based solutions, into the blockchain network. Additionally, the framework incorporates well-established defense mechanisms to ensure robust security against various attacks. This combined approach paves the way for secure and scalable authentication in diverse blockchain-based applications. Additionally, to ensure robust security, the system incorporates well-established defense mechanisms against various attacks, including 51%, phishing, routing, and Sybil attacks, into the blockchain network. This combined approach paves the way for secure and efficient authentication in a wider range of blockchain-based applications.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Graph Unlearning</title>
<link>https://arxiv.org/abs/2508.02485</link>
<guid>https://arxiv.org/abs/2508.02485</guid>
<content:encoded><![CDATA[
arXiv:2508.02485v1 Announce Type: new 
Abstract: The demand for data privacy has led to the development of frameworks like Federated Graph Learning (FGL), which facilitate decentralized model training. However, a significant operational challenge in such systems is adhering to the right to be forgotten. This principle necessitates robust mechanisms for two distinct types of data removal: the selective erasure of specific entities and their associated knowledge from local subgraphs and the wholesale removal of a user's entire dataset and influence. Existing methods often struggle to fully address both unlearning requirements, frequently resulting in incomplete data removal or the persistence of residual knowledge within the system. This work introduces a unified framework, conceived to provide a comprehensive solution to these challenges. The proposed framework employs a bifurcated strategy tailored to the specific unlearning request. For fine-grained Meta Unlearning, it uses prototype gradients to direct the initial local forgetting process, which is then refined by generating adversarial graphs to eliminate any remaining data traces among affected clients. In the case of complete client unlearning, the framework utilizes adversarial graph generation exclusively to purge the departed client's contributions from the remaining network. Extensive experiments on multiple benchmark datasets validate the proposed approach. The framework achieves substantial improvements in model prediction accuracy across both client and meta-unlearning scenarios when compared to existing methods. Furthermore, additional studies confirm its utility as a plug-in module, where it materially enhances the predictive capabilities and unlearning effectiveness of other established methods.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Commit Stability as a Signal for Risk in Open-Source Projects</title>
<link>https://arxiv.org/abs/2508.02487</link>
<guid>https://arxiv.org/abs/2508.02487</guid>
<content:encoded><![CDATA[
arXiv:2508.02487v1 Announce Type: new 
Abstract: Open source software (OSS) generates trillions of dollars in economic value and has become essential to technical infrastructures worldwide. As organizations increasingly depend on OSS, understanding project evolution is critical. While existing metrics provide insights into project health, one dimension remains understudied: project resilience -- the ability to return to normal operations after disturbances such as contributor departures, security vulnerabilities, and bug report spikes. We hypothesize that stable commit patterns reflect underlying project characteristics such as mature governance, sustained contributors, and robust development processes that enable resilience. Building on the Composite Stability Index (CSI) framework, we empirically validate commit frequency patterns across 100 highly ranked repositories. Our findings reveal that only 2\% of repositories exhibit daily stability, 29\% achieve weekly stability, and 50\% demonstrate monthly stability, while half remain unstable across all temporal levels. Programming languages and blockchain applications were the most stable. We identified two exemplary repositories that achieved stability at all three granularities, whose governance models, CI cadence, and release policies could serve as reference frameworks. We observed that large yearly commit throughput does not necessarily correlate with stability. Beyond commits, stability can be enriched with issue-resolution times, PR merge rates, and community-engagement metrics to broaden resilience assessment and sharpen stability-based risk evaluation.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Failure-Aware Multi-Robot Coordination for Resilient and Adaptive Target Tracking</title>
<link>https://arxiv.org/abs/2508.02529</link>
<guid>https://arxiv.org/abs/2508.02529</guid>
<content:encoded><![CDATA[
arXiv:2508.02529v1 Announce Type: new 
Abstract: Multi-robot coordination is crucial for autonomous systems, yet real-world deployments often encounter various failures. These include both temporary and permanent disruptions in sensing and communication, which can significantly degrade system robustness and performance if not explicitly modeled. Despite its practical importance, failure-aware coordination remains underexplored in the literature. To bridge the gap between idealized conditions and the complexities of real-world environments, we propose a unified failure-aware coordination framework designed to enable resilient and adaptive multi-robot target tracking under both temporary and permanent failure conditions. Our approach systematically distinguishes between two classes of failures: (1) probabilistic and temporary disruptions, where robots recover from intermittent sensing or communication losses by dynamically adapting paths and avoiding inferred danger zones, and (2) permanent failures, where robots lose sensing or communication capabilities irreversibly, requiring sustained, decentralized behavioral adaptation. To handle these scenarios, the robot team is partitioned into subgroups. Robots that remain connected form a communication group and collaboratively plan using partially centralized nonlinear optimization. Robots experiencing permanent disconnection or failure continue to operate independently through decentralized or individual optimization, allowing them to contribute to the task within their local context. We extensively evaluate our method across a range of benchmark variations and conduct a comprehensive assessment under diverse real-world failure scenarios. Results show that our framework consistently achieves robust performance in realistic environments with unknown danger zones, offering a practical and generalizable solution for the multi-robot systems community.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nicknames for Group Signatures</title>
<link>https://arxiv.org/abs/2508.02543</link>
<guid>https://arxiv.org/abs/2508.02543</guid>
<content:encoded><![CDATA[
arXiv:2508.02543v1 Announce Type: new 
Abstract: Nicknames for Group Signatures (NGS) is a new signature scheme that extends Group Signatures (GS) with Signatures with Flexible Public Keys (SFPK). Via GS, each member of a group can sign messages on behalf of the group without revealing his identity, except to a designated auditor. Via SFPK, anyone can create new identities for a particular user, enabling anonymous transfers with only the intended recipient able to trace these new identities.
  To prevent the potential abuses that this anonymity brings, NGS integrates flexible public keys into the GS framework to support auditable transfers. In addition to introducing NGS, we describe its security model and provide a mathematical construction proved secure in the Random Oracle Model. As a practical NGS use case, we build NickHat, a blockchain-based token-exchange prototype system on top of Ethereum.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Epidemic Consensus for Large-Scale Networks</title>
<link>https://arxiv.org/abs/2508.02552</link>
<guid>https://arxiv.org/abs/2508.02552</guid>
<content:encoded><![CDATA[
arXiv:2508.02552v1 Announce Type: new 
Abstract: Blockchain is a distributed ledger technology that has applications in many domains such as cryptocurrency, smart contracts, supply chain management, and many others. Distributed consensus is a fundamental component of blockchain systems that enables secure, precise, and tamper-proof verification of data without relying on central authorities. Existing consensus protocols, nevertheless, suffer from drawbacks, some of which are related to scalability, resource consumption, and fault tolerance. We introduce Blockchain Epidemic Consensus Protocol (BECP), a novel fully decentralised consensus protocol for blockchain networks at a large scale. BECP follows epidemic communication principles, without fixed roles like validators or leaders, and achieves probabilistic convergence, efficient message dissemination, and tolerance to message delays. We provide an extensive experimental comparison of BECP against classic protocols like PAXOS, RAFT, and PBFT, and newer epidemic-based protocols like Avalanche and Snowman. The findings indicate that BECP provides desirable gains in throughput, consensus latency, and substantial message-passing efficiency compared to existing epidemic-based approaches, validating its usability as an effective and scalable approach for next-generation blockchain systems.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully Decentralised Consensus for Extreme-scale Blockchain</title>
<link>https://arxiv.org/abs/2508.02595</link>
<guid>https://arxiv.org/abs/2508.02595</guid>
<content:encoded><![CDATA[
arXiv:2508.02595v1 Announce Type: new 
Abstract: Blockchain is a decentralised, immutable ledger technology that has been widely adopted in many sectors for various applications such as cryptocurrencies, smart contracts and supply chain management. Distributed consensus is a fundamental component of blockchain, which is required to ensure trust, security, and integrity of the data stored and the transactions processed in the blockchain. Various consensus algorithms have been developed, each affected from certain issues such as node failures, high resource consumption, collusion, etc. This work introduces a fully decentralised consensus protocol, Blockchain Epidemic Consensus Protocol (BECP), suitable for very large and extreme-scale blockchain systems. The proposed approach leverages the benefits of epidemic protocols, such as no reliance on a fixed set of validators or leaders, probabilistic guarantees of convergence, efficient use of network resources, and tolerance to node and network failures. A comparative experimental analysis has been carried out with traditional protocols including PAXOS, RAFT, and Practical Byzantine Fault Tolerance (PBFT), as well as a relatively more recent protocol such as Avalanche, which is specifically designed for very large-scale systems. The results illustrate how BECP outperforms them in terms of throughput, scalability and consensus latency. BECP achieves an average of 1.196 times higher throughput in terms of consensus on items and 4.775 times better average consensus latency. Furthermore, BECP significantly reduces the number of messages compared to Avalanche. These results demonstrate the effectiveness and efficiency of fully decentralised consensus for blockchain technology based on epidemic protocols.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Learning-Based Control for Multi-Agent Shepherding of Stochastic Autonomous Agents</title>
<link>https://arxiv.org/abs/2508.02632</link>
<guid>https://arxiv.org/abs/2508.02632</guid>
<content:encoded><![CDATA[
arXiv:2508.02632v1 Announce Type: new 
Abstract: Multi-agent shepherding represents a challenging distributed control problem where herder agents must coordinate to guide independently moving targets to desired spatial configurations. Most existing control strategies assume cohesive target behavior, which frequently fails in practical applications where targets exhibit stochastic autonomous behavior. This paper presents a hierarchical learning-based control architecture that decomposes the shepherding problem into a high-level decision-making module and a low-level motion control component. The proposed distributed control system synthesizes effective control policies directly from closed-loop experience without requiring explicit inter-agent communication or prior knowledge of target dynamics. The decentralized architecture achieves cooperative control behavior through emergent coordination without centralized supervision. Experimental validation demonstrates superior closed-loop performance compared to state-of-the-art heuristic control methods, achieving 100\% success rates with improved settling times and control efficiency. The control architecture scales beyond its design conditions, adapts to time-varying goal regions, and demonstrates practical implementation feasibility through real-time experiments on the Robotarium platform.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMLAC: Mutual Learning Driven Heterogeneous Federated Audio Classification</title>
<link>https://arxiv.org/abs/2506.10207</link>
<guid>https://arxiv.org/abs/2506.10207</guid>
<content:encoded><![CDATA[
arXiv:2506.10207v2 Announce Type: replace 
Abstract: Federated Learning (FL) offers a privacy-preserving framework for training audio classification (AC) models across decentralized clients without sharing raw data. However, Federated Audio Classification (FedAC) faces three major challenges: data heterogeneity, model heterogeneity, and data poisoning, which degrade performance in real-world settings. While existing methods often address these issues separately, a unified and robust solution remains underexplored. We propose FedMLAC, a mutual learning-based FL framework that tackles all three challenges simultaneously. Each client maintains a personalized local AC model and a lightweight, globally shared Plug-in model. These models interact via bidirectional knowledge distillation, enabling global knowledge sharing while adapting to local data distributions, thus addressing both data and model heterogeneity. To counter data poisoning, we introduce a Layer-wise Pruning Aggregation (LPA) strategy that filters anomalous Plug-in updates based on parameter deviations during aggregation. Extensive experiments on four diverse audio classification benchmarks, including both speech and non-speech tasks, show that FedMLAC consistently outperforms state-of-the-art baselines in classification accuracy and robustness to noisy data.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating Opinion Dynamics into Safety Control for Decentralized Airplane Encounter Resolution</title>
<link>https://arxiv.org/abs/2508.00156</link>
<guid>https://arxiv.org/abs/2508.00156</guid>
<content:encoded><![CDATA[
arXiv:2508.00156v1 Announce Type: new 
Abstract: As the airspace becomes increasingly congested, decentralized conflict resolution methods for airplane encounters have become essential. While decentralized safety controllers can prevent dangerous midair collisions, they do not always ensure prompt conflict resolution. As a result, airplane progress may be blocked for extended periods in certain situations. To address this blocking phenomenon, this paper proposes integrating bio-inspired nonlinear opinion dynamics into the airplane safety control framework, thereby guaranteeing both safety and blocking-free resolution. In particular, opinion dynamics enable the safety controller to achieve collaborative decision-making for blocking resolution and facilitate rapid, safe coordination without relying on communication or preset rules. Extensive simulation results validate the improved flight efficiency and safety guarantees. This study provides practical insights into the design of autonomous controllers for airplanes.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning</title>
<link>https://arxiv.org/abs/2508.00287</link>
<guid>https://arxiv.org/abs/2508.00287</guid>
<content:encoded><![CDATA[
arXiv:2508.00287v1 Announce Type: new 
Abstract: Driver drowsiness is one of the main causes of road accidents and is recognized as a leading contributor to traffic-related fatalities. However, detecting drowsiness accurately remains a challenging task, especially in real-world settings where facial data from different individuals is decentralized and highly diverse. In this paper, we propose a novel framework for drowsiness detection that is designed to work effectively with heterogeneous and decentralized data. Our approach develops a new Spatial Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM) network to better extract key facial features and improve detection performance. To support federated learning, we employ a Gradient Similarity Comparison (GSC) that selects the most relevant trained models from different operators before aggregation. This improves the accuracy and robustness of the global model while preserving user privacy. We also develop a customized tool that automatically processes video data by extracting frames, detecting and cropping faces, and applying data augmentation techniques such as rotation, flipping, brightness adjustment, and zooming. Experimental results show that our framework achieves a detection accuracy of 89.9% in the federated learning settings, outperforming existing methods under various deployment scenarios. The results demonstrate the effectiveness of our approach in handling real-world data variability and highlight its potential for deployment in intelligent transportation systems to enhance road safety through early and reliable drowsiness detection.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrated user scheduling and beam steering in over-the-air federated learning for mobile IoT</title>
<link>https://arxiv.org/abs/2508.00341</link>
<guid>https://arxiv.org/abs/2508.00341</guid>
<content:encoded><![CDATA[
arXiv:2508.00341v1 Announce Type: new 
Abstract: The rising popularity of Internet of things (IoT) has spurred technological advancements in mobile internet and interconnected systems. While offering flexible connectivity and intelligent applications across various domains, IoT service providers must gather vast amounts of sensitive data from users, which nonetheless concomitantly raises concerns about privacy breaches. Federated learning (FL) has emerged as a promising decentralized training paradigm to tackle this challenge. This work focuses on enhancing the aggregation efficiency of distributed local models by introducing over-the-air computation into the FL framework. Due to radio resource scarcity in large-scale networks, only a subset of users can participate in each training round. This highlights the need for effective user scheduling and model transmission strategies to optimize communication efficiency and inference accuracy. To address this, we propose an integrated approach to user scheduling and receive beam steering, subject to constraints on the number of selected users and transmit power. Leveraging the difference-of-convex technique, we decompose the primal non-convex optimization problem into two sub-problems, yielding an iterative solution. While effective, the computational load of the iterative method hampers its practical implementation. To overcome this, we further propose a low-complexity user scheduling policy based on characteristic analysis of the wireless channel to directly determine the user subset without iteration. Extensive experiments validate the superiority of the proposed method in terms of aggregation error and learning performance over existing approaches.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SubCDM: Collective Decision-Making with a Swarm Subset</title>
<link>https://arxiv.org/abs/2508.00467</link>
<guid>https://arxiv.org/abs/2508.00467</guid>
<content:encoded><![CDATA[
arXiv:2508.00467v1 Announce Type: new 
Abstract: Collective decision-making is a key function of autonomous robot swarms, enabling them to reach a consensus on actions based on environmental features. Existing strategies require the participation of all robots in the decision-making process, which is resource-intensive and prevents the swarm from allocating the robots to any other tasks. We propose Subset-Based Collective Decision-Making (SubCDM), which enables decisions using only a swarm subset. The construction of the subset is dynamic and decentralized, relying solely on local information. Our method allows the swarm to adaptively determine the size of the subset for accurate decision-making, depending on the difficulty of reaching a consensus. Simulation results using one hundred robots show that our approach achieves accuracy comparable to using the entire swarm while reducing the number of robots required to perform collective decision-making, making it a resource-efficient solution for collective decision-making in swarm robotics.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience</title>
<link>https://arxiv.org/abs/2508.00596</link>
<guid>https://arxiv.org/abs/2508.00596</guid>
<content:encoded><![CDATA[
arXiv:2508.00596v1 Announce Type: new 
Abstract: In decentralized federated learning (FL), multiple clients collaboratively learn a shared machine learning (ML) model by leveraging their privately held datasets distributed across the network, through interactive exchange of the intermediate model updates. To ensure data security, cryptographic techniques are commonly employed to protect model updates during aggregation. Despite growing interest in secure aggregation, existing works predominantly focus on protocol design and computational guarantees, with limited understanding of the fundamental information-theoretic limits of such systems. Moreover, optimal bounds on communication and key usage remain unknown in decentralized settings, where no central aggregator is available. Motivated by these gaps, we study the problem of decentralized secure aggregation (DSA) from an information-theoretic perspective. Specifically, we consider a network of $K$ fully-connected users, each holding a private input -- an abstraction of local training data -- who aim to securely compute the sum of all inputs. The security constraint requires that no user learns anything beyond the input sum, even when colluding with up to $T$ other users. We characterize the optimal rate region, which specifies the minimum achievable communication and secret key rates for DSA. In particular, we show that to securely compute one symbol of the desired input sum, each user must (i) transmit at least one symbol to others, (ii) hold at least one symbol of secret key, and (iii) all users must collectively hold no fewer than $K - 1$ independent key symbols. Our results establish the fundamental performance limits of DSA, providing insights for the design of provably secure and communication-efficient protocols in distributed learning systems.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SwarnRaft: Leveraging Consensus for Robust Drone Swarm Coordination in GNSS-Degraded Environments</title>
<link>https://arxiv.org/abs/2508.00622</link>
<guid>https://arxiv.org/abs/2508.00622</guid>
<content:encoded><![CDATA[
arXiv:2508.00622v1 Announce Type: new 
Abstract: Unmanned aerial vehicle (UAV) swarms are increasingly used in critical applications such as aerial mapping, environmental monitoring, and autonomous delivery. However, the reliability of these systems is highly dependent on uninterrupted access to the Global Navigation Satellite Systems (GNSS) signals, which can be disrupted in real-world scenarios due to interference, environmental conditions, or adversarial attacks, causing disorientation, collision risks, and mission failure. This paper proposes SwarnRaft, a blockchain-inspired positioning and consensus framework for maintaining coordination and data integrity in UAV swarms operating under GNSS-denied conditions. SwarnRaft leverages the Raft consensus algorithm to enable distributed drones (nodes) to agree on state updates such as location and heading, even in the absence of GNSS signals for one or more nodes. In our prototype, each node uses GNSS and local sensing, and communicates over WiFi in a simulated swarm. Upon signal loss, consensus is used to reconstruct or verify the position of the failed node based on its last known state and trajectory. Our system demonstrates robustness in maintaining swarm coherence and fault tolerance through a lightweight, scalable communication model. This work offers a practical and secure foundation for decentralized drone operation in unpredictable environments.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Un-mixing Test-time Adaptation under Heterogeneous Data Streams</title>
<link>https://arxiv.org/abs/2411.15173</link>
<guid>https://arxiv.org/abs/2411.15173</guid>
<content:encoded><![CDATA[
arXiv:2411.15173v2 Announce Type: replace 
Abstract: Deploying deep models in real-world scenarios remains challenging due to significant performance drops under distribution shifts between training and deployment environments. Test-Time Adaptation (TTA) has recently emerged as a promising solution, enabling on-the-fly model adaptation without access to source data. However, its effectiveness degrades significantly in the presence of complex, mixed distribution shifts - common in practical settings - where multiple latent domains coexist. Adapting under such intrinsic heterogeneity, especially in unlabeled and online conditions, remains an open and underexplored challenge. In this paper, we study TTA under mixed distribution shifts and move beyond conventional homogeneous adaptation paradigms. By revisiting TTA from a frequency-domain perspective, we observe that distribution heterogeneity often manifests in Fourier space - for instance, high-frequency components tend to carry domain-specific variations. This motivates us to perform domain-aware separation using high-frequency texture cues, making diverse shift patterns more tractable. To this end, we propose FreDA, a novel Frequency-based Decentralized Adaptation framework that decomposes globally heterogeneous data into locally homogeneous components in the frequency domain. It further employs decentralized learning and augmentation strategies to robustly adapt under complex, evolving shifts. Extensive experiments across various environments (corrupted, natural, and medical) demonstrate the superiority of our proposed framework over the state-of-the-arts.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On LLM-Assisted Generation of Smart Contracts from Business Processes</title>
<link>https://arxiv.org/abs/2507.23087</link>
<guid>https://arxiv.org/abs/2507.23087</guid>
<content:encoded><![CDATA[
arXiv:2507.23087v1 Announce Type: new 
Abstract: Large language models (LLMs) have changed the reality of how software is produced. Within the wider software engineering community, among many other purposes, they are explored for code generation use cases from different types of input. In this work, we present an exploratory study to investigate the use of LLMs for generating smart contract code from business process descriptions, an idea that has emerged in recent literature to overcome the limitations of traditional rule-based code generation approaches. However, current LLM-based work evaluates generated code on small samples, relying on manual inspection, or testing whether code compiles but ignoring correct execution. With this work, we introduce an automated evaluation framework and provide empirical data from larger data sets of process models. We test LLMs of different types and sizes in their capabilities of achieving important properties of process execution, including enforcing process flow, resource allocation, and data-based conditions. Our results show that LLM performance falls short of the perfect reliability required for smart contract development. We suggest future work to explore responsible LLM integrations in existing tools for code generation to ensure more reliable output. Our benchmarking framework can serve as a foundation for developing and evaluating such integrations.
]]></content:encoded>
<pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulation-based planning of Motion Sequences for Automated Procedure Optimization in Multi-Robot Assembly Cells</title>
<link>https://arxiv.org/abs/2507.23270</link>
<guid>https://arxiv.org/abs/2507.23270</guid>
<content:encoded><![CDATA[
arXiv:2507.23270v1 Announce Type: new 
Abstract: Reconfigurable multi-robot cells offer a promising approach to meet fluctuating assembly demands. However, the recurrent planning of their configurations introduces new challenges, particularly in generating optimized, coordinated multi-robot motion sequences that minimize the assembly duration. This work presents a simulation-based method for generating such optimized sequences. The approach separates assembly steps into task-related core operations and connecting traverse operations. While core operations are constrained and predetermined, traverse operations offer substantial optimization potential. Scheduling the core operations is formulated as an optimization problem, requiring feasible traverse operations to be integrated using a decomposition-based motion planning strategy. Several solution techniques are explored, including a sampling heuristic, tree-based search and gradient-free optimization. For motion planning, a decomposition method is proposed that identifies specific areas in the schedule, which can be solved independently with modified centralized path planning algorithms. The proposed method generates efficient and collision-free multi-robot assembly procedures that outperform a baseline relying on decentralized, robot-individual motion planning. Its effectiveness is demonstrated through simulation experiments.
]]></content:encoded>
<pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring Left-Wing Extremism on the Decentralized Web: An Analysis of Lemmygrad.ml</title>
<link>https://arxiv.org/abs/2507.23699</link>
<guid>https://arxiv.org/abs/2507.23699</guid>
<content:encoded><![CDATA[
arXiv:2507.23699v1 Announce Type: new 
Abstract: This study investigates the presence of left-wing extremism on the Lemmygrad.ml instance of the decentralized social media platform Lemmy, from its launch in 2019 up to a month after the bans of the subreddits r/GenZedong and r/GenZhou. We conduct a temporal analysis on Lemmygrad.ml's user activity, with also measuring the degree of highly abusive or hateful content. Furthermore, we explore the content of their posts using a transformer-based topic modeling approach. Our findings reveal a substantial increase in user activity and toxicity levels following the migration of these subreddits to Lemmygrad.ml. We also identify posts that support authoritarian regimes, endorse the Russian invasion of Ukraine, and feature anti-Zionist and antisemitic content. Overall, our findings contribute to a more nuanced understanding of political extremism within decentralized social networks and emphasize the necessity of analyzing both ends of the political spectrum in research.
]]></content:encoded>
<pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploiting Local Observations for Robust Robot Learning</title>
<link>https://arxiv.org/abs/2309.14792</link>
<guid>https://arxiv.org/abs/2309.14792</guid>
<content:encoded><![CDATA[
arXiv:2309.14792v4 Announce Type: replace 
Abstract: While many robotic tasks can be addressed using either centralized single-agent control with full state observation or decentralized multi-agent control, clear criteria for choosing between these approaches remain underexplored. This paper systematically investigates how multi-agent reinforcement learning (MARL) with local observations can improve robustness in complex robotic systems compared to traditional centralized control. Through theoretical analysis and empirical validation, we show that in certain tasks, decentralized MARL can achieve performance comparable to centralized methods while exhibiting greater resilience to perturbations and agent failures. By analytically demonstrating the equivalence of single-agent reinforcement learning (SARL) and MARL under full observability, we identify observability as the critical factor distinguishing the two paradigms. We further derive bounds quantifying performance degradation under external perturbations for locally observable policies. Empirical results on standard MARL benchmarks confirm that MARL with limited observations can maintain competitive performance. Finally, real-world experiments with a mobile manipulator demonstrate that decentralized MARL controllers achieve markedly improved robustness to agent malfunctions and environmental disturbances relative to centralized baselines. Together, these findings highlight MARL with local observations as a robust and practical alternative to conventional centralized control in complex robotic systems.
]]></content:encoded>
<pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Privacy-Preserving DAO Model Using NFT Authentication for the Punishment not Reward Blockchain Architecture</title>
<link>https://arxiv.org/abs/2405.13156</link>
<guid>https://arxiv.org/abs/2405.13156</guid>
<content:encoded><![CDATA[
arXiv:2405.13156v2 Announce Type: replace 
Abstract: This paper presents a decentralised autonomous organisation (DAO) model that uses non-fungible tokens (NFTs) for identity management and privacy-preserving interactions within a Punishment not Reward (PnR) blockchain mechanism. The proposed model introduces a dual NFT architecture deployed on Layer 2 networks: Membership NFTs (\(NFT_{auth}\)) for authentication and access control and interaction NFTs (\(NFT_{priv}\)) for private interactions among participants. Our Layer 2 implementation achieves 97\% gas cost reduction while maintaining security through cross-chain mechanisms. The identity management system incorporates decentralised KYC processes and Sybil attack resistance using soulbound token characteristics. Governance operates through smart contracts that manage reputation and administer punitive measures, including conditional identity disclosure for forensic purposes. Governance operates through smart contracts that manage reputation and administer punitive measures, including conditional identity disclosure when misconduct is detected.
]]></content:encoded>
<pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cycles Protocol: A Peer-to-Peer Electronic Clearing System</title>
<link>https://arxiv.org/abs/2507.22309</link>
<guid>https://arxiv.org/abs/2507.22309</guid>
<content:encoded><![CDATA[
arXiv:2507.22309v1 Announce Type: new 
Abstract: For centuries, financial institutions have responded to liquidity challenges by forming closed, centralized clearing clubs with strict rules and membership that allow them to collaborate on using the least money to discharge the most debt. As closed clubs, much of the general public has been excluded from participation. But the vast majority of private sector actors consists of micro or small firms that are vulnerable to late payments and generally ineligible for bank loans. This low liquidity environment often results in gridlock and leads to insolvency, and it disproportionately impacts small enterprises and communities.
  On the other hand, blockchain communities have developed open, decentralized settlement systems, along with a proliferation of store of value assets and new lending protocols, allowing anyone to permissionlessly transact and access credit. However, these protocols remain used primarily for speculative purposes, and so far have fallen short of the large-scale positive impact on the real economy prophesied by their promoters.
  We address these challenges by introducing Cycles, an open, decentralized clearing, settlement, and issuance protocol. Cycles is designed to enable firms to overcome payment inefficiencies, to reduce their working capital costs, and to leverage diverse assets and liquidity sources, including cryptocurrencies, stablecoins, and lending protocols, in service of clearing more debt with less money. Cycles solves real world liquidity challenges through a privacy-preserving multilateral settlement platform based on a graph optimization algorithm. The design is based on a core insight: liquidity resides within cycles in the payment network's structure and can be accessed via settlement flows optimized to reduce debt.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem</title>
<link>https://arxiv.org/abs/2507.22326</link>
<guid>https://arxiv.org/abs/2507.22326</guid>
<content:encoded><![CDATA[
arXiv:2507.22326v1 Announce Type: new 
Abstract: Metaverse service is a product of the convergence between Metaverse and service systems, designed to address service-related challenges concerning digital avatars, digital twins, and digital natives within Metaverse. With the rise of large language models (LLMs), agents now play a pivotal role in Metaverse service ecosystem, serving dual functions: as digital avatars representing users in the virtual realm and as service assistants (or NPCs) providing personalized support. However, during the modeling of Metaverse service ecosystems, existing LLM-based agents face significant challenges in bridging virtual-world services with real-world services, particularly regarding issues such as character data fusion, character knowledge association, and ethical safety concerns. This paper proposes an explainable emotion alignment framework for LLM-based agents in Metaverse Service Ecosystem. It aims to integrate factual factors into the decision-making loop of LLM-based agents, systematically demonstrating how to achieve more relational fact alignment for these agents. Finally, a simulation experiment in the Offline-to-Offline food delivery scenario is conducted to evaluate the effectiveness of this framework, obtaining more realistic social emergence.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SAEL: Leveraging Large Language Models with Adaptive Mixture-of-Experts for Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2507.22371</link>
<guid>https://arxiv.org/abs/2507.22371</guid>
<content:encoded><![CDATA[
arXiv:2507.22371v1 Announce Type: new 
Abstract: With the increasing security issues in blockchain, smart contract vulnerability detection has become a research focus. Existing vulnerability detection methods have their limitations: 1) Static analysis methods struggle with complex scenarios. 2) Methods based on specialized pre-trained models perform well on specific datasets but have limited generalization capabilities. In contrast, general-purpose Large Language Models (LLMs) demonstrate impressive ability in adapting to new vulnerability patterns. However, they often underperform on specific vulnerability types compared to methods based on specialized pre-trained models. We also observe that explanations generated by general-purpose LLMs can provide fine-grained code understanding information, contributing to improved detection performance.
  Inspired by these observations, we propose SAEL, an LLM-based framework for smart contract vulnerability detection. We first design targeted prompts to guide LLMs in identifying vulnerabilities and generating explanations, which serve as prediction features. Next, we apply prompt-tuning on CodeT5 and T5 to process contract code and explanations, enhancing task-specific performance. To combine the strengths of each approach, we introduce an Adaptive Mixture-of-Experts architecture. This dynamically adjusts feature weights via a Gating Network, which selects relevant features using TopK filtering and Softmax normalization, and incorporates a Multi-Head Self-Attention mechanism to enhance cross-feature relationships. This design enables effective integration of LLM predictions, explanation features, and code features through gradient optimization. The loss function jointly considers both independent feature performance and overall weighted predictions. Experiments show that SAEL outperforms existing methods across various vulnerabilities.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DoS Attacks and Defense Technologies in Blockchain Systems: A Hierarchical Analysis</title>
<link>https://arxiv.org/abs/2507.22611</link>
<guid>https://arxiv.org/abs/2507.22611</guid>
<content:encoded><![CDATA[
arXiv:2507.22611v1 Announce Type: new 
Abstract: Blockchain technology is widely used in various fields due to its ability to provide decentralization and trustless security. This is a fundamental understanding held by many advocates, but it is misunderstood, leading participants to fail to recognize the limitations of the security that blockchain can provide. Among all current network attacks, Denial of Service (DoS) attacks pose significant threats due to their ease of execution and destructive potential. This paper, based on the blockchain architecture hierarchy, categorizes and organizes existing DoS attacks, with a focus on explaining the principles and methods of contract layer and consensus layer DoS attacks. Furthermore, this paper comprehensively analyzes and compares commonly used detection methods and defense technologies, which will contribute to strengthening the security and stability of blockchain systems and promoting further innovation and application of blockchain systems.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Differentially Private Power Method</title>
<link>https://arxiv.org/abs/2507.22849</link>
<guid>https://arxiv.org/abs/2507.22849</guid>
<content:encoded><![CDATA[
arXiv:2507.22849v1 Announce Type: new 
Abstract: We propose a novel Decentralized Differentially Private Power Method (D-DP-PM) for performing Principal Component Analysis (PCA) in networked multi-agent settings. Unlike conventional decentralized PCA approaches where each agent accesses the full n-dimensional sample space, we address the challenging scenario where each agent observes only a subset of dimensions through row-wise data partitioning. Our method ensures $(\epsilon,\delta)$-Differential Privacy (DP) while enabling collaborative estimation of global eigenvectors across the network without requiring a central aggregator. We achieve this by having agents share only local embeddings of the current eigenvector iterate, leveraging both the inherent privacy from random initialization and carefully calibrated Gaussian noise additions. We prove that our algorithm satisfies the prescribed $(\epsilon,\delta)$-DP guarantee and establish convergence rates that explicitly characterize the impact of the network topology. Our theoretical analysis, based on linear dynamics and high-dimensional probability theory, provides tight bounds on both privacy and utility. Experiments on real-world datasets demonstrate that D-DP-PM achieves superior privacy-utility tradeoffs compared to naive local DP approaches, with particularly strong performance in moderate privacy regimes ($\epsilon\in[2, 5]$). The method converges rapidly, allowing practitioners to trade iterations for enhanced privacy while maintaining competitive utility.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SP-Chain: Boosting Intra-Shard and Cross-Shard Security and Performance in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2407.06953</link>
<guid>https://arxiv.org/abs/2407.06953</guid>
<content:encoded><![CDATA[
arXiv:2407.06953v2 Announce Type: replace 
Abstract: A promising way to overcome the scalability limitations of the current blockchain is to use sharding, which is to split the transaction processing among multiple, smaller groups of nodes. A well-performed blockchain sharding system requires both high performance and high security in both intra- and cross-shard perspectives. However, existing protocols either have issues on protecting security or trade off great performance for security. In this paper, we propose SP-Chain, a blockchain sharding system with enhanced Security and Performance for both intra- and cross-shard perspectives. For intra-shard aspect, we design a two-phase concurrent voting scheme to provide high system throughput and low transaction confirmation latency. Moreover, we propose an efficient unbiased leader rotation scheme to ensure high performance under malicious behavior. For cross-shard aspect, a proof-assisted efficient cross-shard transaction processing mechanism is proposed to guard the cross-shard transactions with low overhead. We implement SP-Chain based on Harmony, and evaluate its performance via large-scale deployment. Extensive evaluations suggest that SP-Chain can process more than 10,000 tx/sec under malicious behaviors with a confirmation latency of 7.6s in a network of 4,000 nodes.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2502.00201</link>
<guid>https://arxiv.org/abs/2502.00201</guid>
<content:encoded><![CDATA[
arXiv:2502.00201v2 Announce Type: replace 
Abstract: This paper systematically reviews advancements in deep learning (DL) techniques for financial fraud detection, a critical issue in the financial sector. Using the Kitchenham systematic literature review approach, 57 studies published between 2019 and 2024 were analyzed. The review highlights the effectiveness of various deep learning models such as Convolutional Neural Networks, Long Short-Term Memory, and transformers across domains such as credit card transactions, insurance claims, and financial statement audits. Performance metrics such as precision, recall, F1-score, and AUC-ROC were evaluated. Key themes explored include the impact of data privacy frameworks and advancements in feature engineering and data preprocessing. The study emphasizes challenges such as imbalanced datasets, model interpretability, and ethical considerations, alongside opportunities for automation and privacy-preserving techniques such as blockchain integration and Principal Component Analysis. By examining trends over the past five years, this review identifies critical gaps and promising directions for advancing DL applications in financial fraud detection, offering actionable insights for researchers and practitioners.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent ARP Spoofing Detection using Multi-layered Machine Learning (ML) Techniques for IoT Networks</title>
<link>https://arxiv.org/abs/2507.21087</link>
<guid>https://arxiv.org/abs/2507.21087</guid>
<content:encoded><![CDATA[
arXiv:2507.21087v1 Announce Type: new 
Abstract: Address Resolution Protocol (ARP) spoofing remains a critical threat to IoT networks, enabling attackers to intercept, modify, or disrupt data transmission by exploiting ARP's lack of authentication. The decentralized and resource-constrained nature of IoT environments amplifies this vulnerability, making conventional detection mechanisms ineffective at scale. This paper introduces an intelligent, multi-layered machine learning framework designed to detect ARP spoofing in real-time IoT deployments. Our approach combines feature engineering based on ARP header behavior, traffic flow analysis, and temporal packet anomalies with a hybrid detection pipeline incorporating decision trees, ensemble models, and deep learning classifiers. We propose a hierarchical architecture to prioritize lightweight models at edge gateways and deeper models at centralized nodes to balance detection accuracy and computational efficiency. The system is validated on both simulated IoT traffic and the CICIDS2017 dataset, achieving over 97% detection accuracy with low false positive rates. Comparative evaluations with signature-based and rule-based systems demonstrate the robustness and generalizability of our approach. Our results show that intelligent machine learning integration enables proactive ARP spoofing detection tailored for IoT scenarios, laying the groundwork for scalable and autonomous network security solutions.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Formal Rebuttal of "The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs Among Decentralization, Security, and Scalability"</title>
<link>https://arxiv.org/abs/2507.21111</link>
<guid>https://arxiv.org/abs/2507.21111</guid>
<content:encoded><![CDATA[
arXiv:2507.21111v1 Announce Type: new 
Abstract: This paper presents a comprehensive refutation of the so-called "blockchain trilemma," a widely cited but formally ungrounded claim asserting an inherent trade-off between decentralisation, security, and scalability in blockchain protocols. Through formal analysis, empirical evidence, and detailed critique of both methodology and terminology, we demonstrate that the trilemma rests on semantic equivocation, misuse of distributed systems theory, and a failure to define operational metrics. Particular focus is placed on the conflation of topological network analogies with protocol-level architecture, the mischaracterisation of Bitcoin's design--including the role of miners, SPV clients, and header-based verification--and the failure to ground claims in complexity-theoretic or adversarial models. By reconstructing Bitcoin as a deterministic, stateless distribution protocol governed by evidentiary trust, we show that scalability is not a trade-off but an engineering outcome. The paper concludes by identifying systemic issues in academic discourse and peer review that have allowed such fallacies to persist, and offers formal criteria for evaluating future claims in blockchain research.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedFlex: Federated Learning for Diverse Netflix Recommendations</title>
<link>https://arxiv.org/abs/2507.21115</link>
<guid>https://arxiv.org/abs/2507.21115</guid>
<content:encoded><![CDATA[
arXiv:2507.21115v1 Announce Type: new 
Abstract: Federated learning is a decentralized approach that enables collaborative model training across multiple devices while preserving data privacy. It has shown significant potential in various domains, including healthcare and personalized recommendation systems. However, most existing work on federated recommendation systems has focused primarily on improving accuracy, with limited attention to fairness and diversity. In this paper, we introduce FedFlex, a federated recommender system for Netflix-style TV series recommendations. FedFlex integrates two state-of-the-art matrix factorization algorithms for personalized fine-tuning. FedFlex also applies Maximal Marginal Relevance (MMR) to re-rank items and enhance diversity. We conduct extensive experiments comparing recommendations generated by SVD and BPR algorithms. In a live two-week user study, participants received two recommendation lists: List A, based on SVD or BPR, and List B, a re-ranked version emphasizing diversity. Participants were asked to click on the movies they were interested in watching. Our findings demonstrate that FedFlex effectively introduces diverse content, such as new genres, into recommendations without necessarily compromising user satisfaction.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Kintsugi: Decentralized E2EE Key Recovery</title>
<link>https://arxiv.org/abs/2507.21122</link>
<guid>https://arxiv.org/abs/2507.21122</guid>
<content:encoded><![CDATA[
arXiv:2507.21122v1 Announce Type: new 
Abstract: Kintsugi is a protocol for key recovery, allowing a user to regain access to end-to-end encrypted data after they have lost their device, but still have their (potentially low-entropy) password. Existing E2EE key recovery methods, such as those deployed by Signal and WhatsApp, centralize trust by relying on servers administered by a single provider. Kintsugi is decentralized, distributing trust over multiple recovery nodes, which could be servers run by independent parties, or end user devices in a peer-to-peer setting. To recover a user's keys, a threshold $t+1$ of recovery nodes must assist the user in decrypting a shared backup. Kintsugi is password-authenticated and protects against offline brute-force password guessing without requiring any specialized secure hardware. Kintsugi can tolerate up to $t$ honest-but-curious colluding recovery nodes, as well as $n - t - 1$ offline nodes, and operates safely in an asynchronous network model where messages can be arbitrarily delayed.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigation of Social Media Platforms Impact on the Users</title>
<link>https://arxiv.org/abs/2507.21181</link>
<guid>https://arxiv.org/abs/2507.21181</guid>
<content:encoded><![CDATA[
arXiv:2507.21181v1 Announce Type: new 
Abstract: Social media platforms offer numerous benefits and allow people to come together for various causes. Many communities, academia, government agencies, institutions, healthcare, entertainment, and businesses are on social media platforms. They are intuitive and free for users. It has become unimaginable to live without social media. Their architecture and data handling are geared towards scalability, uninterrupted availability, and both personal and collaborative revenue generation. Primarily, artificial intelligence algorithms are employed on stored user data for optimization and feeds. This has the potential to impact user safety, privacy, and security, even when metadata is used. A new decentralized data arrangement framework based on the Fractal-tree and L-Systems algorithm is proposed to mitigate some of the impacts of social media platforms.
  Future work will focus on demonstrating the effectiveness of the new decentralized framework by comparing its results against state-of-the-art security methods currently used in databases. A cryptographic algorithm could also be implemented for the framework, employing a new key generation for each branch. This will strengthen database security; for example, if a user key is leaked, regenerating the key for each branch will keep the data secure by applying defense mechanisms in the proposed L-System-based tree framework.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Digital identity management system with blockchain:An implementation with Ethereum and Ganache</title>
<link>https://arxiv.org/abs/2507.21398</link>
<guid>https://arxiv.org/abs/2507.21398</guid>
<content:encoded><![CDATA[
arXiv:2507.21398v1 Announce Type: new 
Abstract: This paper presents the development of a distributed digital identity system utilizing modern technologies, including FastAPI, MongoDB, gRPC, Docker, and blockchain simulation with Ganache and Ethereum. The objective is to demonstrate the benefits of distributed systems and blockchain for the security, traceability, and decentralization of digital identities. The methodology included the development of a microservices architecture with JWT authentication, data persistence in MongoDB, simulation of blockchain operations using Ganache, and containerization with Docker. The results demonstrate the feasibility of the proposed approach, with a functional web interface, complete audit logs, and blockchain simulation with Ethereum. The theoretical foundations, technical implementation, results obtained, and prospects for integration with real blockchain networks are discussed.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning</title>
<link>https://arxiv.org/abs/2507.21494</link>
<guid>https://arxiv.org/abs/2507.21494</guid>
<content:encoded><![CDATA[
arXiv:2507.21494v1 Announce Type: new 
Abstract: Test-time adaptation with pre-trained vision-language models has gained increasing attention for addressing distribution shifts during testing. Among these approaches, memory-based algorithms stand out due to their training-free nature and ability to leverage historical test data. However, existing test-time adaptation methods are typically designed for a single domain with abundant data. In decentralized settings such as federated learning, applying these methods individually to each client suffers from limited test data, while directly sharing a single global memory via the server prevents proper personalization to each client's unique distribution. To address this, we propose Latte, a novel framework where each client maintains a local memory to store embeddings from its own historical test data and an external memory to store class prototypes from other relevant clients. During communication, each client retrieves prototypes from similar clients under the server's coordination to expand its memory. For local adaptation, Latte utilizes both embedding similarity and uncertainty to enhance model performance. Our theoretical analysis shows that Latte effectively leverages in-distribution clients while remaining robust to out-of-distribution clients. Extensive experiments on domain adaptation and corruption benchmarks validate that Latte achieves superior performance in decentralized settings, while introducing only negligible communication and computation costs. Our code is available at https://github.com/baowenxuan/Latte .
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments</title>
<link>https://arxiv.org/abs/2507.21553</link>
<guid>https://arxiv.org/abs/2507.21553</guid>
<content:encoded><![CDATA[
arXiv:2507.21553v1 Announce Type: new 
Abstract: Multi-robot SLAM aims at localizing and building a map with multiple robots, interacting with each other. In the work described in this article, we analyze the pipeline of a decentralized LiDAR SLAM system to study the current limitations of the state of the art, and we discover a significant source of failures, i.e., that the loop detection is the source of too many false positives. We therefore develop and propose a new heuristic to overcome these limitations. The environment taken as reference in this work is the highly challenging case of underground tunnels. We also highlight potential new research areas still under-explored.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Non-coercive extortion in game theory</title>
<link>https://arxiv.org/abs/2507.21795</link>
<guid>https://arxiv.org/abs/2507.21795</guid>
<content:encoded><![CDATA[
arXiv:2507.21795v1 Announce Type: new 
Abstract: Commitments play a crucial role in game theory, shaping strategic interactions by either altering a player's own payoffs or influencing the incentives of others through outcome-contingent payments. While most research has focused on using commitments to achieve efficient equilibria, their potential applications beyond this goal remain largely unexplored. In this study, we introduce a non-coercive extortion mechanism that leverages commitments to outcome-contingent payments, demonstrating how a player or external agent can extract profit by offering rewards rather than threatening punishment. At the core of the mechanism is the introduction of sequentiality into a simultaneous-move game, fundamentally reshaping the strategic interaction. We derive the conditions under which extortion is successful, identify the class of games susceptible to this scheme, and determine both the maximum extractable profit and the minimum required payment. To illustrate the extortion mechanism, we apply it to 2x2 games, highlighting how even simple strategic settings can be vulnerable to this form of manipulation. Our results reveal strategic vulnerabilities in competitive settings, with significant implications for economic markets, diplomatic relations, and multi-agent systems operating in blockchain environments. This work broadens our understanding of commitments in game theory and raises critical questions about how to safeguard strategic interactions from exploitation through non-coercive extortion.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation</title>
<link>https://arxiv.org/abs/2507.21903</link>
<guid>https://arxiv.org/abs/2507.21903</guid>
<content:encoded><![CDATA[
arXiv:2507.21903v1 Announce Type: new 
Abstract: As news reporting becomes increasingly global and decentralized online, tracking related events across multiple sources presents significant challenges. Existing news summarization methods typically utilizes Large Language Models and Graphical methods on article-based summaries. However, this is not effective since it only considers the textual content of similarly dated articles to understand the gist of the event. To counteract the lack of analysis on the parties involved, it is essential to come up with a novel framework to gauge the importance of stakeholders and the connection of related events through the relevant entities involved. Therefore, we present SUnSET: Synergistic Understanding of Stakeholder, Events and Time for the task of Timeline Summarization (TLS). We leverage powerful Large Language Models (LLMs) to build SET triplets and introduced the use of stakeholder-based ranking to construct a $Relevancy$ metric, which can be extended into general situations. Our experimental results outperform all prior baselines and emerged as the new State-of-the-Art, highlighting the impact of stakeholder information within news article.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Modeling of Vehicular Maneuvers and Interactions at Urban Junctions</title>
<link>https://arxiv.org/abs/2507.21547</link>
<guid>https://arxiv.org/abs/2507.21547</guid>
<content:encoded><![CDATA[
arXiv:2507.21547v1 Announce Type: cross 
Abstract: Modeling and evaluation of automated vehicles (AVs) in mixed-autonomy traffic is essential prior to their safe and efficient deployment. This is especially important at urban junctions where complex multi-agent interactions occur. Current approaches for modeling vehicular maneuvers and interactions at urban junctions have limitations in formulating non-cooperative interactions and vehicle dynamics within a unified mathematical framework. Previous studies either assume predefined paths or rely on cooperation and central controllability, limiting their realism and applicability in mixed-autonomy traffic. This paper addresses these limitations by proposing a modeling framework for trajectory planning and decentralized vehicular control at urban junctions. The framework employs a bi-level structure where the upper level generates kinematically feasible reference trajectories using an efficient graph search algorithm with a custom heuristic function, while the lower level employs a predictive controller for trajectory tracking and optimization. Unlike existing approaches, our framework does not require central controllability or knowledge sharing among vehicles. The vehicle kinematics are explicitly incorporated at both levels, and acceleration and steering angle are used as control variables. This intuitive formulation facilitates analysis of traffic efficiency, environmental impacts, and motion comfort. The framework's decentralized structure accommodates operational and stochastic elements, such as vehicles' detection range, perception uncertainties, and reaction delay, making the model suitable for safety analysis. Numerical and simulation experiments across diverse scenarios demonstrate the framework's capability in modeling accurate and realistic vehicular maneuvers and interactions at various urban junctions, including unsignalized intersections and roundabouts.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Effects of Vote Delegation in Blockchains: Who Wins?</title>
<link>https://arxiv.org/abs/2408.05410</link>
<guid>https://arxiv.org/abs/2408.05410</guid>
<content:encoded><![CDATA[
arXiv:2408.05410v2 Announce Type: replace 
Abstract: This paper investigates which alternative benefits from vote delegation in binary collective decisions within blockchains. We begin by examining two extreme cases of voting weight distributions: Equal-Weight (EW), where each voter has equal voting weight, and Dominant-Weight (DW), where a single voter holds a majority of the voting weights before any delegation occurs. We show that vote delegation tends to benefit the ex-ante minority under EW, i.e., the alternative with a lower initial probability of winning. The converse holds under DW distribution. Through numerical simulations, we extend our findings to arbitrary voting weight distributions, showing that vote delegation benefits the ex-ante majority when it leads to a more balanced distribution of voting weights. Finally, in large communities where all agents have equal voting weight, vote delegation has a negligible impact on the outcome. As a practical consequence, vote delegation can be beneficial for blockchains with highly unbalanced voting rights, but not for those with balanced rights. In decentralized finance (DeFi), vote delegation is widely adopted to streamline governance and increase participation. However, it remains unclear when delegation actually aligns outcomes with community preferences.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Multi-Agent Economies: Enhancing the A2A Protocol with Ledger-Anchored Identities and x402 Micropayments for AI Agents</title>
<link>https://arxiv.org/abs/2507.19550</link>
<guid>https://arxiv.org/abs/2507.19550</guid>
<content:encoded><![CDATA[
arXiv:2507.19550v1 Announce Type: new 
Abstract: This research article presents a novel architecture to empower multi-agent economies by addressing two critical limitations of the emerging Agent2Agent (A2A) communication protocol: decentralized agent discoverability and agent-to-agent micropayments. By integrating distributed ledger technology (DLT), this architecture enables tamper-proof, on-chain publishing of AgentCards as smart contracts, providing secure and verifiable agent identities. The architecture further extends A2A with the x402 open standard, facilitating blockchain-agnostic, HTTP-based micropayments via the HTTP 402 status code. This enables autonomous agents to seamlessly discover, authenticate, and compensate each other across organizational boundaries. This work further presents a comprehensive technical implementation and evaluation, demonstrating the feasibility of DLT-based agent discovery and micropayments. The proposed approach lays the groundwork for secure, scalable, and economically viable multi-agent ecosystems, advancing the field of agentic AI toward trusted, autonomous economic interactions.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Debunking Optimization Myths in Federated Learning for Medical Image Classification</title>
<link>https://arxiv.org/abs/2507.19822</link>
<guid>https://arxiv.org/abs/2507.19822</guid>
<content:encoded><![CDATA[
arXiv:2507.19822v1 Announce Type: new 
Abstract: Federated Learning (FL) is a collaborative learning method that enables decentralized model training while preserving data privacy. Despite its promise in medical imaging, recent FL methods are often sensitive to local factors such as optimizers and learning rates, limiting their robustness in practical deployments. In this work, we revisit vanilla FL to clarify the impact of edge device configurations, benchmarking recent FL methods on colorectal pathology and blood cell classification task. We numerically show that the choice of local optimizer and learning rate has a greater effect on performance than the specific FL method. Moreover, we find that increasing local training epochs can either enhance or impair convergence, depending on the FL method. These findings indicate that appropriate edge-specific configuration is more crucial than algorithmic complexity for achieving effective FL.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Who Owns This Sample: Cross-Client Membership Inference Attack in Federated Graph Neural Networks</title>
<link>https://arxiv.org/abs/2507.19964</link>
<guid>https://arxiv.org/abs/2507.19964</guid>
<content:encoded><![CDATA[
arXiv:2507.19964v1 Announce Type: new 
Abstract: Graph-structured data is prevalent in many real-world applications, including social networks, financial systems, and molecular biology. Graph Neural Networks (GNNs) have become the de facto standard for learning from such data due to their strong representation capabilities. As GNNs are increasingly deployed in federated learning (FL) settings to preserve data locality and privacy, new privacy threats arise from the interaction between graph structures and decentralized training. In this paper, we present the first systematic study of cross-client membership inference attacks (CC-MIA) against node classification tasks of federated GNNs (FedGNNs), where a malicious client aims to infer which client owns the given data. Unlike prior centralized-focused work that focuses on whether a sample was included in training, our attack targets sample-to-client attribution, a finer-grained privacy risk unique to federated settings. We design a general attack framework that exploits FedGNNs' aggregation behaviors, gradient updates, and embedding proximity to link samples to their source clients across training rounds. We evaluate our attack across multiple graph datasets under realistic FL setups. Results show that our method achieves high performance on both membership inference and ownership identification. Our findings highlight a new privacy threat in federated graph learning-client identity leakage through structural and model-level cues, motivating the need for attribution-robust GNN design.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>"Blockchain-Enabled Zero Trust Framework for Securing FinTech Ecosystems Against Insider Threats and Cyber Attacks"</title>
<link>https://arxiv.org/abs/2507.19976</link>
<guid>https://arxiv.org/abs/2507.19976</guid>
<content:encoded><![CDATA[
arXiv:2507.19976v1 Announce Type: new 
Abstract: Fintech provides technological services to increase operational efficiency in financial institutions, but traditional perimeter-based defense mechanisms are insufficient against evolving cyber threats like insider attacks, malware intrusions, and Advanced Persistent Threats (APTs). These vulnerabilities expose Fintech organizations to significant risks, including financial losses and data breaches. To address these challenges, this paper proposes a blockchain-integrated Zero Trust framework, adhering to the principle of "Never Trust, Always Verify." The framework uses Ethereum smart contracts to enforce Multi Factor Authentication (MFA), Role-Based Access Control (RBAC), and Just-In-Time (JIT) access privileges, effectively mitigating credential theft and insider threats, the effect of malware and APT attacks.
  The proposed solution transforms blockchain into a Policy Engine (PE) and Policy Enforcement Point (PEP), and policy storage, ensuring immutable access control and micro-segmentation. A decentralized application (DApp) prototype was developed and tested using STRIDE threat modeling, demonstrating resilience against spoofing, tampering, and privilege escalation. Comparative analysis with Perimeter-based systems revealed a trade-off: while the framework introduced a marginal latency increase (74.0 ms vs. 49.33 ms) and reduced throughput (30.77 vs. 50.0 requests/sec), it significantly enhanced security by eliminating single points of failure and enabling tamper-proof audit trails.
  Experimental validation on a 200-node simulated network confirmed the framework's robustness, with future optimizations targeting Layer-2 solutions for scalability. This work bridges the gap between Zero Trust theory and practical blockchain implementation, offering Fintech organizations a decentralized, cost-effective security model.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Accelerating Containerized Service Delivery at the Network Edge</title>
<link>https://arxiv.org/abs/2507.20116</link>
<guid>https://arxiv.org/abs/2507.20116</guid>
<content:encoded><![CDATA[
arXiv:2507.20116v1 Announce Type: new 
Abstract: Efficient container image distribution is crucial for enabling machine learning inference at the network edge, where resource limitations and dynamic network conditions create significant challenges. In this paper, we present PeerSync, a decentralized P2P-based system designed to optimize image distribution in edge environments. PeerSync employs a popularity- and network-aware download engine that dynamically adapts to content popularity and real-time network conditions using a sliding window mechanism. PeerSync further integrates automated tracker election for rapid peer discovery and dynamic cache management for efficient storage utilization. We implement PeerSync with 8000+ lines of Rust code and test its performance extensively on both physical edge devices and Docker-based emulations. Experimental results show that PeerSync delivers a remarkable speed increase of 2.72$\times$, 1.79$\times$, and 1.28$\times$ compared to the Baseline, Dragonfly, and Kraken, respectively, while significantly reducing peak cross-network traffic by 90.72\% under congested and varying network conditions.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Root Cause of \$1 Billion Loss in Smart Contract Real-World Attacks via a Systematic Literature Review of Vulnerabilities</title>
<link>https://arxiv.org/abs/2507.20175</link>
<guid>https://arxiv.org/abs/2507.20175</guid>
<content:encoded><![CDATA[
arXiv:2507.20175v1 Announce Type: new 
Abstract: The Ethereum ecosystem, despite its maturity, continues to witness catastrophic attacks, with billions of dollars in assets lost annually. In response, a significant body of research has focused on identifying and mitigating smart contract vulnerabilities. However, these efforts predominantly focus on implementation-level bugs, leaving a critical gap between academic understanding of vulnerabilities and the root causes of real-world high-impact financial losses. We employ a two-pronged methodology: first, a systematic literature review of 71 academic papers to build a comprehensive and up-to-date catalog of 24 active and 5 deprecated vulnerabilities as understood by the research community. Second, we conduct an in-depth, empirical analysis of 50 of the most severe real-world exploits between 2022 and 2025, collectively incurring over \$1.09B in losses, to identify their true root causes. We introduce the concept of "exploit chains" by revealing that many incidents are not caused by isolated vulnerabilities but by combinations of human, operational, and economic design flaws that link with implementation bugs to enable an attack. Our analysis yields insights on how DApps are exploited in practice, leading to a novel, four-tier root-cause framework that moves beyond code-level vulnerabilities. We find that real-world successful attacks on Ethereum (and related networks) trace back to one of the four tiers of (1) protocol logic design, (2) lifecycle and governance, (3) external dependencies, and (4) traditional implementation bugs (classic smart contract vulnerabilities). We investigate the suitability of this multi-tier incident root-cause framework via a case study.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ethereum Conflicts Graphed</title>
<link>https://arxiv.org/abs/2507.20196</link>
<guid>https://arxiv.org/abs/2507.20196</guid>
<content:encoded><![CDATA[
arXiv:2507.20196v1 Announce Type: new 
Abstract: Ethereum, a leading blockchain platform, has revolutionized the digital economy by enabling decentralized transactions and the execution of smart contracts. Ethereum transactions form the backbone of its network, facilitating peer-to-peer exchanges and interactions with complex decentralized applications. Smart contracts extend Ethereum's capabilities by automating processes and enabling trustless execution of agreements. Hence, understanding how these smart contracts interact is important in order to facilitate various performance optimizations, such as warming objects before they are being accessed and enabling concurrent execution. Of particular interest to us are the development of the calling graph, as well as the read sets and write sets of invocations within the same block, and the properties of the associated conflict graph that is derived from them. The latter is important for understanding the parallelization potential of smart contracts on Ethereum. We traced upwards of 2 million recent Ethereum blocks using call tracer and prestate tracer, out of a total of 21.4 million blocks at the time of writing. We report on the transactions per block distribution, the structure of call trees in smart contract invocations, the ratio of value-transfer transactions to smart contract invocations, as well as provide a comprehensive study of the structure of blocks' conflict graphs. We find that conflict graphs predominantly show a star like configuration, as well as other noteworthy structural properties.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Democracy for DAOs: An Empirical Study of Decentralized Governance and Dynamic (Case Study Internet Computer SNS Ecosystem)</title>
<link>https://arxiv.org/abs/2507.20234</link>
<guid>https://arxiv.org/abs/2507.20234</guid>
<content:encoded><![CDATA[
arXiv:2507.20234v1 Announce Type: new 
Abstract: Decentralized autonomous organizations (DAOs) rely on governance mechanism without centralized leadership. This paper presents an empirical study of user behavior in governance for a variety of DAOs, ranging from DeFi to gaming, using the Internet Computer Protocol DAO framework called SNS (Service Nervous System). To analyse user engagement, we measure participation rates and frequency of proposals submission and voter approval rates. We evaluate decision duration times to determine DAO agility. To investigate dynamic aspects, we also measure metric shifts in time. We evaluate over 3,000 proposals submitted in a time frame of 20 months from 14 SNS DAOs. The selected DAO have been existing between 6 and 20 months and cover a wide spectrum of use cases, treasury sizes, and number of participants. We also compare our results for SNS DAOs with DAOs from other blockchain platforms. While approval rates are generally high for all DAOs studied, SNS DAOs show slightly more alignment. We observe that the SNS governance mechanisms and processes in ICP lead to higher activity, lower costs and faster decisions. Most importantly, in contrast to studies which report a decline in participation over time for other frameworks, SNS DAOs exhibit sustained or increasing engagement levels over time.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain-Based Quality Control Model for Online Collaboration Systems</title>
<link>https://arxiv.org/abs/2507.20265</link>
<guid>https://arxiv.org/abs/2507.20265</guid>
<content:encoded><![CDATA[
arXiv:2507.20265v1 Announce Type: new 
Abstract: Collaborative content generation (CCG) enables collective creation of artifacts like scientific articles. Quality is a paramount concern in CCG, and a multitude of methods have been proposed to evaluate the quality of artifacts. Nevertheless, the majority of these methods are reliant on centralized architectures, which present challenges pertaining to security, privacy, and availability. Blockchain technology proffers a potential resolution to these challenges, by furnishing a decentralized and immutable ledger of quality scores. In this manuscript, we introduce a blockchain-based quality control model for CCG that uses a semi-iterative algorithm to interdependently compute quality scores of artifacts and reputation of nodes. Our model addresses critical challenges in academic informetrics, such as citation manipulation, transparency in collaborative scholarship, and decentralized trust in metric computation. Our model also exhibits sensitivity to processing latency, rendering it more agile in the presence of delays. Our model's quality scores, evaluated against PageRank and HITS baselines, show comparable performance, with additional assessments of throughput, latency, and robustness against malicious nodes confirming its reliability. A theoretical comparison with recent studies validates its feasibility for real world informetric application.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MPC-EVM: Enabling MPC Execution by Smart Contracts In An Asynchronous Manner</title>
<link>https://arxiv.org/abs/2507.20554</link>
<guid>https://arxiv.org/abs/2507.20554</guid>
<content:encoded><![CDATA[
arXiv:2507.20554v1 Announce Type: new 
Abstract: This paper presents MPC-EVM, the first blockchain prototype that extends the EVM to enable asynchronous MPC invocations by smart contracts during transaction executions without compromising consistency or throughput. MPC-EVM uses an asynchronous execution model to process MPC-invoking transactions in a non-blocking fashion, saving the transaction's progress when it enters an MPC and resuming its execution upon MPC's completion. Additionally, it employs an access control mechanism that prevents inconsistent state access and modifications as a result of asynchronous executions. Benchmarking MPC-EVM's throughput show that the transactions per second (TPS) decreased by less than 3% compared to the baseline when MPC-invoking transactions are executed alongside regular transactions.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAG-AFL:Directed Acyclic Graph-based Asynchronous Federated Learning</title>
<link>https://arxiv.org/abs/2507.20571</link>
<guid>https://arxiv.org/abs/2507.20571</guid>
<content:encoded><![CDATA[
arXiv:2507.20571v1 Announce Type: new 
Abstract: Due to the distributed nature of federated learning (FL), the vulnerability of the global model and the need for coordination among many client devices pose significant challenges. As a promising decentralized, scalable and secure solution, blockchain-based FL methods have attracted widespread attention in recent years. However, traditional consensus mechanisms designed for Proof of Work (PoW) similar to blockchain incur substantial resource consumption and compromise the efficiency of FL, particularly when participating devices are wireless and resource-limited. To address asynchronous client participation and data heterogeneity in FL, while limiting the additional resource overhead introduced by blockchain, we propose the Directed Acyclic Graph-based Asynchronous Federated Learning (DAG-AFL) framework. We develop a tip selection algorithm that considers temporal freshness, node reachability and model accuracy, with a DAG-based trusted verification strategy. Extensive experiments on 3 benchmarking datasets against eight state-of-the-art approaches demonstrate that DAG-AFL significantly improves training efficiency and model accuracy by 22.7% and 6.5% on average, respectively.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Program Analysis for High-Value Smart Contract Vulnerabilities: Techniques and Insights</title>
<link>https://arxiv.org/abs/2507.20672</link>
<guid>https://arxiv.org/abs/2507.20672</guid>
<content:encoded><![CDATA[
arXiv:2507.20672v1 Announce Type: new 
Abstract: A widespread belief in the blockchain security community is that automated techniques are only good for detecting shallow bugs, typically of small value. In this paper, we present the techniques and insights that have led us to repeatable success in automatically discovering high-value smart contract vulnerabilities. Our vulnerability disclosures have yielded 10 bug bounties, for a total of over $3M, over high-profile deployed code, as well as hundreds of bugs detected in pre-deployment or under-audit code.
  We argue that the elements of this surprising success are a) a very high-completeness static analysis approach that manages to maintain acceptable precision; b) domain knowledge, provided by experts or captured via statistical inference. We present novel techniques for automatically inferring domain knowledge from statistical analysis of a large corpus of deployed contracts, as well as discuss insights on the ideal precision and warning rate of a promising vulnerability detector. In contrast to academic literature in program analysis, which routinely expects false-positive rates below 50% for publishable results, we posit that a useful analysis for high-value real-world vulnerabilities will likely flag very few programs (under 1%) and will do so with a high false-positive rate (e.g., 95%, meaning that only one-of-twenty human inspections will yield an exploitable vulnerability).
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Line-of-Sight: Cooperative Localization Using Vision and V2X Communication</title>
<link>https://arxiv.org/abs/2507.20772</link>
<guid>https://arxiv.org/abs/2507.20772</guid>
<content:encoded><![CDATA[
arXiv:2507.20772v1 Announce Type: new 
Abstract: Accurate and robust localization is critical for the safe operation of Connected and Automated Vehicles (CAVs), especially in complex urban environments where Global Navigation Satellite System (GNSS) signals are unreliable. This paper presents a novel vision-based cooperative localization algorithm that leverages onboard cameras and Vehicle-to-Everything (V2X) communication to enable CAVs to estimate their poses, even in occlusion-heavy scenarios such as busy intersections. In particular, we propose a novel decentralized observer for a group of connected agents that includes landmark agents (static or moving) in the environment with known positions and vehicle agents that need to estimate their poses (both positions and orientations). Assuming that (i) there are at least three landmark agents in the environment, (ii) each vehicle agent can measure its own angular and translational velocities as well as relative bearings to at least three neighboring landmarks or vehicles, and (iii) neighboring vehicles can communicate their pose estimates, each vehicle can estimate its own pose using the proposed decentralized observer. We prove that the origin of the estimation error is locally exponentially stable under the proposed observer, provided that the minimal observability conditions are satisfied. Moreover, we evaluate the proposed approach through experiments with real 1/10th-scale connected vehicles and large-scale simulations, demonstrating its scalability and validating the theoretical guarantees in practical scenarios.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments</title>
<link>https://arxiv.org/abs/2507.20774</link>
<guid>https://arxiv.org/abs/2507.20774</guid>
<content:encoded><![CDATA[
arXiv:2507.20774v1 Announce Type: new 
Abstract: Smart contract comment generation has gained traction as a means to improve code comprehension and maintainability in blockchain systems. However, evaluating the quality of generated comments remains a challenge. Traditional metrics such as BLEU and ROUGE fail to capture domain-specific nuances, while human evaluation is costly and unscalable. In this paper, we present \texttt{evalSmarT}, a modular and extensible framework that leverages large language models (LLMs) as evaluators. The system supports over 400 evaluator configurations by combining approximately 40 LLMs with 10 prompting strategies. We demonstrate its application in benchmarking comment generation tools and selecting the most informative outputs. Our results show that prompt design significantly impacts alignment with human judgment, and that LLM-based evaluation offers a scalable and semantically rich alternative to existing methods.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>\textit{FedABC}: Attention-Based Client Selection for Federated Learning with Long-Term View</title>
<link>https://arxiv.org/abs/2507.20871</link>
<guid>https://arxiv.org/abs/2507.20871</guid>
<content:encoded><![CDATA[
arXiv:2507.20871v1 Announce Type: new 
Abstract: Native AI support is a key objective in the evolution of 6G networks, with Federated Learning (FL) emerging as a promising paradigm. FL allows decentralized clients to collaboratively train an AI model without directly sharing their data, preserving privacy. Clients train local models on private data and share model updates, which a central server aggregates to refine the global model and redistribute it for the next iteration. However, client data heterogeneity slows convergence and reduces model accuracy, and frequent client participation imposes communication and computational burdens. To address these challenges, we propose \textit{FedABC}, an innovative client selection algorithm designed to take a long-term view in managing data heterogeneity and optimizing client participation. Inspired by attention mechanisms, \textit{FedABC} prioritizes informative clients by evaluating both model similarity and each model's unique contributions to the global model. Moreover, considering the evolving demands of the global model, we formulate an optimization problem to guide \textit{FedABC} throughout the training process. Following the ``later-is-better" principle, \textit{FedABC} adaptively adjusts the client selection threshold, encouraging greater participation in later training stages. Extensive simulations on CIFAR-10 demonstrate that \textit{FedABC} significantly outperforms existing approaches in model accuracy and client participation efficiency, achieving comparable performance with 32\% fewer clients than the classical FL algorithm \textit{FedAvg}, and 3.5\% higher accuracy with 2\% fewer clients than the state-of-the-art. This work marks a step toward deploying FL in heterogeneous, resource-constrained environments, thereby supporting native AI capabilities in 6G networks.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Reputation Scoring in DeFi: zScore-Based Wallet Ranking from Liquidity and Trading Signals</title>
<link>https://arxiv.org/abs/2507.20494</link>
<guid>https://arxiv.org/abs/2507.20494</guid>
<content:encoded><![CDATA[
arXiv:2507.20494v1 Announce Type: cross 
Abstract: As decentralized finance (DeFi) evolves, distinguishing between user behaviors - liquidity provision versus active trading - has become vital for risk modeling and on-chain reputation. We propose a behavioral scoring framework for Uniswap that assigns two complementary scores: a Liquidity Provision Score that assesses strategic liquidity contributions, and a Swap Behavior Score that reflects trading intent, volatility exposure, and discipline. The scores are constructed using rule-based blueprints that decompose behavior into volume, frequency, holding time, and withdrawal patterns. To handle edge cases and learn feature interactions, we introduce a deep residual neural network with densely connected skip blocks inspired by the U-Net architecture. We also incorporate pool-level context such as total value locked (TVL), fee tiers, and pool size, allowing the system to differentiate similar user behaviors across pools with varying characteristics. Our framework enables context-aware and scalable DeFi user scoring, supporting improved risk assessment and incentive design. Experiments on Uniswap v3 data show its usefulness for user segmentation and protocol-aligned reputation systems. Although we refer to our metric as zScore, it is independently developed and methodologically different from the cross-protocol system proposed by Udupi et al. Our focus is on role-specific behavioral modeling within Uniswap using blueprint logic and supervised learning.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How to Save My Gas Fees: Understanding and Detecting Real-world Gas Issues in Solidity Programs</title>
<link>https://arxiv.org/abs/2403.02661</link>
<guid>https://arxiv.org/abs/2403.02661</guid>
<content:encoded><![CDATA[
arXiv:2403.02661v2 Announce Type: replace 
Abstract: The execution of smart contracts on Ethereum, a public blockchain system, incurs a fee called gas fee for its computation and data storage. When programmers develop smart contracts (e.g., in the Solidity programming language), they could unknowingly write code snippets that unnecessarily cause more gas fees. These issues, or what we call gas wastes, can lead to significant monetary losses for users. This paper takes the initiative in helping Ethereum users reduce their gas fees in two key steps. First, we conduct an empirical study on gas wastes in open-source Solidity programs and Ethereum transaction traces. Second, to validate our study findings, we develop a static tool called PeCatch to effectively detect gas wastes in Solidity programs, and manually examine the Solidity compiler's code to pinpoint implementation errors causing gas wastes. Overall, we make 11 insights and four suggestions, which can foster future tool development and programmer awareness, and fixing our detected bugs can save $0.76 million in gas fees daily.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CLVR Ordering of Transactions on AMMs</title>
<link>https://arxiv.org/abs/2408.02634</link>
<guid>https://arxiv.org/abs/2408.02634</guid>
<content:encoded><![CDATA[
arXiv:2408.02634v2 Announce Type: replace 
Abstract: This paper introduces a trade ordering rule that aims to reduce intra-block price volatility in Automated Market Maker (AMM) powered decentralized exchanges. The ordering rule introduced here, Clever Look-ahead Volatility Reduction (CLVR), operates under the (common) framework in decentralized finance that allows some entities to observe trade requests before they are settled, assemble them into "blocks", and order them as they like. On AMM exchanges, asset prices are continuously and transparently updated as a result of each trade and therefore, transaction order has high financial value. CLVR aims to order transactions for traders' benefit. Our primary focus is intra-block price stability (minimizing volatility), which has two main benefits for traders: it reduces transaction failure rate and allows traders to receive closer prices to the reference price at which they submit their transactions accordingly. We show that CLVR constructs an ordering which approximately minimizes price volatility with a small computation cost and can be trivially verified externally.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COoL-TEE: Client-TEE Collaboration for Resilient Distributed Search</title>
<link>https://arxiv.org/abs/2503.19063</link>
<guid>https://arxiv.org/abs/2503.19063</guid>
<content:encoded><![CDATA[
arXiv:2503.19063v2 Announce Type: replace 
Abstract: Current marketplaces rely on search mechanisms with distributed systems but centralized governance, making them vulnerable to attacks, failures, censorship and biases. While search mechanisms with more decentralized governance (e.g., DeSearch) have been recently proposed, these are still exposed to information head-start attacks (IHS) despite the use of Trusted Execution Environments (TEEs). These attacks allow malicious users to gain a head-start over other users for the discovery of new assets in the market, which give them an unfair advantage in asset acquisition. We propose COoL-TEE, a TEE-based provider selection mechanism for distributed search, running in single- or multi-datacenter environments, that is resilient to information head-start attacks. COoL-TEE relies on a Client-TEE collaboration, which enables clients to distinguish between slow providers and malicious ones. Performance evaluations in single- and multi-datacenter environments show that, using COoL-TEE, malicious users respectively gain only up to 2% and 7% of assets more than without IHS, while they can claim 20% or more on top of their fair share in the same conditions with DeSearch.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VGS-ATD: Robust Distributed Learning for Multi-Label Medical Image Classification Under Heterogeneous and Imbalanced Conditions</title>
<link>https://arxiv.org/abs/2507.18657</link>
<guid>https://arxiv.org/abs/2507.18657</guid>
<content:encoded><![CDATA[
arXiv:2507.18657v1 Announce Type: new 
Abstract: In recent years, advanced deep learning architectures have shown strong performance in medical imaging tasks. However, the traditional centralized learning paradigm poses serious privacy risks as all data is collected and trained on a single server. To mitigate this challenge, decentralized approaches such as federated learning and swarm learning have emerged, allowing model training on local nodes while sharing only model weights. While these methods enhance privacy, they struggle with heterogeneous and imbalanced data and suffer from inefficiencies due to frequent communication and the aggregation of weights. More critically, the dynamic and complex nature of clinical environments demands scalable AI systems capable of continuously learning from diverse modalities and multilabels. Yet, both centralized and decentralized models are prone to catastrophic forgetting during system expansion, often requiring full model retraining to incorporate new data. To address these limitations, we propose VGS-ATD, a novel distributed learning framework. To validate VGS-ATD, we evaluate it in experiments spanning 30 datasets and 80 independent labels across distributed nodes, VGS-ATD achieved an overall accuracy of 92.7%, outperforming centralized learning (84.9%) and swarm learning (72.99%), while federated learning failed under these conditions due to high requirements on computational resources. VGS-ATD also demonstrated strong scalability, with only a 1% drop in accuracy on existing nodes after expansion, compared to a 20% drop in centralized learning, highlighting its resilience to catastrophic forgetting. Additionally, it reduced computational costs by up to 50% relative to both centralized and swarm learning, confirming its superior efficiency and scalability.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Cloud Convenience and Protocol Transparency: A Hybrid Architecture for Ethereum Node Operations on Amazon Managed Blockchain</title>
<link>https://arxiv.org/abs/2507.18774</link>
<guid>https://arxiv.org/abs/2507.18774</guid>
<content:encoded><![CDATA[
arXiv:2507.18774v1 Announce Type: new 
Abstract: As blockchain technologies are increasingly adopted in enterprise and research domains, the need for secure, scalable, and performance-transparent node infrastructure has become critical. While self-hosted Ethereum nodes offer operational control, they often lack elasticity and require complex maintenance. This paper presents a hybrid, service-oriented architecture for deploying and monitoring Ethereum full nodes using Amazon Managed Blockchain (AMB), integrated with EC2-based observability, IAM-enforced security policies, and reproducible automation via the AWS Cloud Development Kit. Our architecture supports end-to-end observability through custom EC2 scripts leveraging Web3.py and JSON-RPC, collecting over 1,000 real-time data points-including gas utilization, transaction inclusion latency, and mempool dynamics. These metrics are visualized and monitored through AWS CloudWatch, enabling service-level performance tracking and anomaly detection. This cloud-native framework restores low-level observability lost in managed environments while maintaining the operational simplicity of managed services. By bridging the simplicity of AMB with the transparency required for protocol research and enterprise monitoring, this work delivers one of the first reproducible, performance-instrumented Ethereum deployments on AMB. The proposed hybrid architecture enables secure, observable, and reproducible Ethereum node operations in cloud environments, suitable for both research and production use.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adapting to Fragmented and Evolving Data: A Fisher Information Perspective</title>
<link>https://arxiv.org/abs/2507.18996</link>
<guid>https://arxiv.org/abs/2507.18996</guid>
<content:encoded><![CDATA[
arXiv:2507.18996v1 Announce Type: new 
Abstract: Modern machine learning systems operating in dynamic environments often face \textit{sequential covariate shift} (SCS), where input distributions evolve over time while the conditional distribution remains stable. We introduce FADE (Fisher-based Adaptation to Dynamic Environments), a lightweight and theoretically grounded framework for robust learning under SCS. FADE employs a shift-aware regularization mechanism anchored in Fisher information geometry, guiding adaptation by modulating parameter updates based on sensitivity and stability. To detect significant distribution changes, we propose a Cramer-Rao-informed shift signal that integrates KL divergence with temporal Fisher dynamics. Unlike prior methods requiring task boundaries, target supervision, or experience replay, FADE operates online with fixed memory and no access to target labels. Evaluated on seven benchmarks spanning vision, language, and tabular data, FADE achieves up to 19\% higher accuracy under severe shifts, outperforming methods such as TENT and DIW. FADE also generalizes naturally to federated learning by treating heterogeneous clients as temporally fragmented environments, enabling scalable and stable adaptation in decentralized settings. Theoretical analysis guarantees bounded regret and parameter consistency, while empirical results demonstrate FADE's robustness across modalities and shift intensities.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Formalization of the Yul Language and Some Verified Yul Code Transformations</title>
<link>https://arxiv.org/abs/2507.19012</link>
<guid>https://arxiv.org/abs/2507.19012</guid>
<content:encoded><![CDATA[
arXiv:2507.19012v1 Announce Type: new 
Abstract: Yul is an intermediate language used in the compilation of the Solidity programming language for Ethereum smart contracts. The compiler applies customizable sequences of transformations to Yul code. To help ensure the correctness of these transformations and their sequencing, we used the ACL2 theorem prover to develop a formalization of the syntax and semantics of Yul, proofs relating static and dynamic semantics, a formalization of some Yul code transformations, and correctness proofs for these transformations.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for Multi-Agent Coordination</title>
<link>https://arxiv.org/abs/2507.19151</link>
<guid>https://arxiv.org/abs/2507.19151</guid>
<content:encoded><![CDATA[
arXiv:2507.19151v1 Announce Type: new 
Abstract: Constraint-based optimization is a cornerstone of robotics, enabling the design of controllers that reliably encode task and safety requirements such as collision avoidance or formation adherence. However, handcrafted constraints can fail in multi-agent settings that demand complex coordination. We introduce ReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid framework that merges the reliability of optimization-based controllers with the adaptability of multi-agent reinforcement learning. Rather than discarding expert controllers, ReCoDe improves them by learning additional, dynamic constraints that capture subtler behaviors, for example, by constraining agent movements to prevent congestion in cluttered scenarios. Through local communication, agents collectively constrain their allowed actions to coordinate more effectively under changing conditions. In this work, we focus on applications of ReCoDe to multi-agent navigation tasks requiring intricate, context-based movements and consensus, where we show that it outperforms purely handcrafted controllers, other hybrid approaches, and standard MARL baselines. We give empirical (real robot) and theoretical evidence that retaining a user-defined controller, even when it is imperfect, is more efficient than learning from scratch, especially because ReCoDe can dynamically change the degree to which it relies on this controller.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Big Data Energy Systems: A Survey of Practices and Associated Challenges</title>
<link>https://arxiv.org/abs/2507.19154</link>
<guid>https://arxiv.org/abs/2507.19154</guid>
<content:encoded><![CDATA[
arXiv:2507.19154v1 Announce Type: new 
Abstract: Energy systems generate vast amounts of data in extremely short time intervals, creating challenges for efficient data management. Traditional data management methods often struggle with scalability and accessibility, limiting their usefulness. More advanced solutions, such as NoSQL databases and cloud-based platforms, have been adopted to address these issues. Still, even these advanced solutions can encounter bottlenecks, which can impact the efficiency of data storage, retrieval, and analysis. This review paper explores the research trends in big data management for energy systems, highlighting the practices, opportunities and challenges. Also, the data regulatory demands are highlighted using chosen reference architectures. The review, in particular, explores the limitations of current storage and data integration solutions and examines how new technologies are applied to the energy sector. Novel insights into emerging technologies, including data spaces, various data management architectures, peer-to-peer data management, and blockchains, are provided, along with practical recommendations for achieving enhanced data sharing and regulatory compliance.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SILS: Strategic Influence on Liquidity Stability and Whale Detection in Concentrated-Liquidity DEXs</title>
<link>https://arxiv.org/abs/2507.19411</link>
<guid>https://arxiv.org/abs/2507.19411</guid>
<content:encoded><![CDATA[
arXiv:2507.19411v1 Announce Type: new 
Abstract: Traditional methods for identifying impactful liquidity providers (LPs) in Concentrated Liquidity Market Makers (CLMMs) rely on broad measures, such as nominal capital size or surface-level activity, which often lead to inaccurate risk analysis. The SILS framework offers a significantly more detailed approach, characterizing LPs not just as capital holders but as dynamic systemic agents whose actions directly impact market stability. This represents a fundamental paradigm shift from the static, volume-based analysis to a dynamic, impact-focused understanding. This advanced approach uses on-chain event logs and smart contract execution traces to compute Exponential Time-Weighted Liquidity (ETWL) profiles and apply unsupervised anomaly detection. Most importantly, it defines an LP's functional importance through the Liquidity Stability Impact Score (LSIS), a counterfactual metric that measures the potential degradation of the market if the LP withdraws. This combined approach provides a more detailed and realistic characterization of an LP's impact, moving beyond the binary and often misleading classifications used by existing methods. This impact-focused and comprehensive approach enables SILS to accurately identify high-impact LPs-including those missed by traditional methods and supports essential applications like a protective oracle layer and actionable trader signals, thereby significantly enhancing DeFi ecosystem. The framework provides unprecedented transparency into the underlying liquidity structure and associated risks, effectively reducing the common false positives and uncovering critical false negatives found in traditional models. Therefore, SILS provides an effective mechanism for proactive risk management, transforming how DeFi protocols safeguard their ecosystems against asymmetric liquidity behavior.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finance as Extended Biology: Reciprocity as the Cognitive Substrate of Financial Behavior</title>
<link>https://arxiv.org/abs/2506.00099</link>
<guid>https://arxiv.org/abs/2506.00099</guid>
<content:encoded><![CDATA[
arXiv:2506.00099v2 Announce Type: cross 
Abstract: A central challenge in economics and artificial intelligence is explaining how financial behaviors-such as credit, insurance, and trade-emerge without formal institutions. We argue that these functions are not products of institutional design, but structured extensions of a single behavioral substrate: reciprocity. Far from being a derived strategy, reciprocity served as the foundational logic of early human societies-governing the circulation of goods, regulation of obligation, and maintenance of long-term cooperation well before markets, money, or formal rules. Trade, commonly regarded as the origin of financial systems, is reframed here as the canonical form of reciprocity: simultaneous, symmetric, and partner-contingent. Building on this logic, we reconstruct four core financial functions-credit, insurance, token exchange, and investment-as expressions of the same underlying principle under varying conditions. By grounding financial behavior in minimal, simulateable dynamics of reciprocal interaction, this framework shifts the focus from institutional engineering to behavioral computation-offering a new foundation for modeling decentralized financial behavior in both human and artificial agents.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentivised Orchestrated Training Architecture (IOTA): A Technical Primer for Release</title>
<link>https://arxiv.org/abs/2507.17766</link>
<guid>https://arxiv.org/abs/2507.17766</guid>
<content:encoded><![CDATA[
arXiv:2507.17766v1 Announce Type: new 
Abstract: In August 2024, Bittensor's Subnet 9 (SN9) demonstrated that a distributed network of incentivized, permissionless actors could each pretrain large language models (LLMs) ranging from 700 million to 14 billion parameters, while surpassing established baselines. While that work validated blockchain-based decentralized pretraining as viable, it contained core issues: (i) every miner had to fit an entire model locally, and (ii) "winner-takes-all" rewards encouraged model hoarding.
  Here we introduce IOTA (Incentivized Orchestrated Training Architecture), an architecture that addresses these limitations by transforming SN9's previously isolated competitors into a single cooperating unit that can scale arbitrarily while still rewarding each contributor fairly.
  Key preliminary results: (1) Data- and Pipeline-parallel SWARM architecture - An orchestrator distributes model layers across heterogeneous miners and streams activations between them, enabling model sizes to scale with the number of participants rather than being constrained by the VRAM of a single machine; (2) Granular, continuous incentives - Validators measure each miner's contribution and allocate token emissions proportionally; (3) Activation compression - We used model-bottlenecks to cut communication bandwidths of activations by up to 128x, vastly improving training speed; (4) Butterfly All-Reduce - Miners average disjoint parameter slices in O(1) bandwidth, offering linear scalability, redundancy and built-in collusion detection; (5) CLASP (Contribution Loss Assessment via Sampling of Pathways) - A fair attribution scheme assigns credit to miners proportional to their marginal utility and detects exploits, even when contributions are interdependent across the pipeline.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2507.17875</link>
<guid>https://arxiv.org/abs/2507.17875</guid>
<content:encoded><![CDATA[
arXiv:2507.17875v1 Announce Type: new 
Abstract: Multi-agent collaboration enhances situational awareness in intelligence, surveillance, and reconnaissance (ISR) missions. Ad hoc networks of unmanned aerial vehicles (UAVs) allow for real-time data sharing, but they face security challenges due to their decentralized nature, making them vulnerable to cyber-physical attacks. This paper introduces a trust-based framework for assured sensor fusion in distributed multi-agent networks, utilizing a hidden Markov model (HMM)-based approach to estimate the trustworthiness of agents and their provided information in a decentralized fashion. Trust-informed data fusion prioritizes fusing data from reliable sources, enhancing resilience and accuracy in contested environments. To evaluate the assured sensor fusion under attacks on system/mission sensing, we present a novel multi-agent aerial dataset built from the Unreal Engine simulator. We demonstrate through case studies improved ISR performance and an ability to detect malicious actors in adversarial settings.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning for Large-Scale Cloud Robotic Manipulation: Opportunities and Challenges</title>
<link>https://arxiv.org/abs/2507.17903</link>
<guid>https://arxiv.org/abs/2507.17903</guid>
<content:encoded><![CDATA[
arXiv:2507.17903v1 Announce Type: new 
Abstract: Federated Learning (FL) is an emerging distributed machine learning paradigm, where the collaborative training of a model involves dynamic participation of devices to achieve broad objectives. In contrast, classical machine learning (ML) typically requires data to be located on-premises for training, whereas FL leverages numerous user devices to train a shared global model without the need to share private data. Current robotic manipulation tasks are constrained by the individual capabilities and speed of robots due to limited low-latency computing resources. Consequently, the concept of cloud robotics has emerged, allowing robotic applications to harness the flexibility and reliability of computing resources, effectively alleviating their computational demands across the cloud-edge continuum. Undoubtedly, within this distributed computing context, as exemplified in cloud robotic manipulation scenarios, FL offers manifold advantages while also presenting several challenges and opportunities. In this paper, we present fundamental concepts of FL and their connection to cloud robotic manipulation. Additionally, we envision the opportunities and challenges associated with realizing efficient and reliable cloud robotic manipulation at scale through FL, where researchers adopt to design and verify FL models in either centralized or decentralized settings.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Guided Policy Optimization</title>
<link>https://arxiv.org/abs/2507.18059</link>
<guid>https://arxiv.org/abs/2507.18059</guid>
<content:encoded><![CDATA[
arXiv:2507.18059v1 Announce Type: new 
Abstract: Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing CTDE methods often underutilize centralized training or lack theoretical guarantees. We propose Multi-Agent Guided Policy Optimization (MAGPO), a novel framework that better leverages centralized training by integrating centralized guidance with decentralized execution. MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. We provide theoretical guarantees of monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across 6 diverse environments. Results show that MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches, offering a principled and practical solution for decentralized multi-agent learning. Our code and experimental data can be found in https://github.com/liyheng/MAGPO.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2507.18095</link>
<guid>https://arxiv.org/abs/2507.18095</guid>
<content:encoded><![CDATA[
arXiv:2507.18095v1 Announce Type: new 
Abstract: Mobile power sources (MPSs) have been gradually deployed in microgrids as critical resources to coordinate with repair crews (RCs) towards resilience enhancement owing to their flexibility and mobility in handling the complex coupled power-transport systems. However, previous work solves the coordinated dispatch problem of MPSs and RCs in a centralized manner with the assumption that the communication network is still fully functioning after the event. However, there is growing evidence that certain extreme events will damage or degrade communication infrastructure, which makes centralized decision making impractical. To fill this gap, this paper formulates the resilience-driven dispatch problem of MPSs and RCs in a decentralized framework. To solve this problem, a hierarchical multi-agent reinforcement learning method featuring a two-level framework is proposed, where the high-level action is used to switch decision-making between power and transport networks, and the low-level action constructed via a hybrid policy is used to compute continuous scheduling and discrete routing decisions in power and transport networks, respectively. The proposed method also uses an embedded function encapsulating system dynamics to enhance learning stability and scalability. Case studies based on IEEE 33-bus and 69-bus power networks are conducted to validate the effectiveness of the proposed method in load restoration.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination</title>
<link>https://arxiv.org/abs/2507.18110</link>
<guid>https://arxiv.org/abs/2507.18110</guid>
<content:encoded><![CDATA[
arXiv:2507.18110v1 Announce Type: new 
Abstract: High renewable penetration has been witnessed in power systems, resulting in reduced system inertia and increasing requirements for frequency response services. Electric vehicles (EVs), owing to their vehicle-to-grid (V2G) capabilities, can provide cost-effective frequency services for transmission system operators (TSOs). However, EVs that are inherently connected to distribution networks may pose voltage security issues for distribution system operators (DSOs) when supporting TSO frequency. To coordinate both TSO frequency and DSO voltage, this paper proposes a two-stage service provision framework for multi-EVs. At stage one, EVs participate in day-ahead TSO-DSO interactions for frequency reserve schedules; at stage two, EVs make real-time dispatching behaviors in distribution networks for reserve delivery while supporting DSO voltage. Considering the potentially large EV number and environment complexity, a decentralized operation paradigm is introduced for real-time EV dispatches at stage two, while a communication-efficient reinforcement learning (RL) algorithm is proposed to reduce the communication overhead during large-scale multi-agent RL training without compromising policy performance. Case studies are carried out on a 6-bus transmission and 33-bus distribution network as well as a 69-bus distribution network to evaluate the effectiveness and scalability of the proposed method in enabling EVs for frequency service and voltage support.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stability Constrained Voltage Control in Distribution Grids with Arbitrary Communication Infrastructure</title>
<link>https://arxiv.org/abs/2507.18158</link>
<guid>https://arxiv.org/abs/2507.18158</guid>
<content:encoded><![CDATA[
arXiv:2507.18158v1 Announce Type: new 
Abstract: We consider the problem of designing learning-based reactive power controllers that perform voltage regulation in distribution grids while ensuring closed-loop system stability. In contrast to existing methods, where the provably stable controllers are restricted to be decentralized, we propose a unified design framework that enables the controllers to take advantage of an arbitrary communication infrastructure on top of the physical power network. This allows the controllers to incorporate information beyond their local bus, covering existing methods as a special case and leading to less conservative constraints on the controller design. We then provide a design procedure to construct input convex neural network (ICNN) based controllers that satisfy the identified stability constraints by design under arbitrary communication scenarios, and train these controllers using supervised learning. Simulation results on the the University of California, San Diego (UCSD) microgrid testbed illustrate the effectiveness of the framework and highlight the role of communication in improving control performance.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CASPER: Contrastive Approach for Smart Ponzi Scheme Detecter with More Negative Samples</title>
<link>https://arxiv.org/abs/2507.16840</link>
<guid>https://arxiv.org/abs/2507.16840</guid>
<content:encoded><![CDATA[
arXiv:2507.16840v1 Announce Type: new 
Abstract: The rapid evolution of digital currency trading, fueled by the integration of blockchain technology, has led to both innovation and the emergence of smart Ponzi schemes. A smart Ponzi scheme is a fraudulent investment operation in smart contract that uses funds from new investors to pay returns to earlier investors. Traditional Ponzi scheme detection methods based on deep learning typically rely on fully supervised models, which require large amounts of labeled data. However, such data is often scarce, hindering effective model training. To address this challenge, we propose a novel contrastive learning framework, CASPER (Contrastive Approach for Smart Ponzi detectER with more negative samples), designed to enhance smart Ponzi scheme detection in blockchain transactions. By leveraging contrastive learning techniques, CASPER can learn more effective representations of smart contract source code using unlabeled datasets, significantly reducing both operational costs and system complexity. We evaluate CASPER on the XBlock dataset, where it outperforms the baseline by 2.3% in F1 score when trained with 100% labeled data. More impressively, with only 25% labeled data, CASPER achieves an F1 score nearly 20% higher than the baseline under identical experimental conditions. These results highlight CASPER's potential for effective and cost-efficient detection of smart Ponzi schemes, paving the way for scalable fraud detection solutions in the future.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Who Leads in the Shadows? ERGM and Centrality Analysis of Congressional Democrats on Bluesky</title>
<link>https://arxiv.org/abs/2507.16858</link>
<guid>https://arxiv.org/abs/2507.16858</guid>
<content:encoded><![CDATA[
arXiv:2507.16858v1 Announce Type: new 
Abstract: Following the 2024 U.S. presidential election, Democratic lawmakers and their supporters increasingly migrated from mainstream social media plat-forms like X (formerly Twitter) to decentralized alternatives such as Bluesky. This study investigates how Congressional Democrats use Bluesky to form networks of influence and disseminate political messaging in a platform environment that lacks algorithmic amplification. We employ a mixed-methods approach that combines social network analysis, expo-nential random graph modeling (ERGM), and transformer-based topic mod-eling (BERTopic) to analyze follows, mentions, reposts, and discourse pat-terns among 182 verified Democratic members of Congress. Our findings show that while party leaders such as Hakeem Jeffries and Elizabeth War-ren dominate visibility metrics, overlooked figures like Marcy Kaptur, Donald Beyer, and Dwight Evans occupy structurally central positions, suggesting latent influence within the digital party ecosystem. ERGM re-sults reveal significant homophily along ideological, state, and leadership lines, with Senate leadership exhibiting lower connectivity. Topic analysis identifies both shared themes (e.g., reproductive rights, foreign conflicts) and subgroup-specific issues, with The Squad showing the most distinct discourse profile. These results demonstrate the potential of decentralized platforms to reshape intra-party communication dynamics and highlight the need for continued computational research on elite political behavior in emerging digital environments.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedVLM: Scalable Personalized Vision-Language Models through Federated Learning</title>
<link>https://arxiv.org/abs/2507.17088</link>
<guid>https://arxiv.org/abs/2507.17088</guid>
<content:encoded><![CDATA[
arXiv:2507.17088v1 Announce Type: new 
Abstract: Vision-language models (VLMs) demonstrate impressive zero-shot and few-shot learning capabilities, making them essential for several downstream tasks. However, fine-tuning these models at scale remains challenging, particularly in federated environments where data is decentralized and non-iid across clients. Existing parameter-efficient tuning methods like LoRA (Low-Rank Adaptation) reduce computational overhead but struggle with heterogeneous client data, leading to suboptimal generalization. To address these challenges, we propose FedVLM, a federated LoRA fine-tuning framework that enables decentralized adaptation of VLMs while preserving model privacy and reducing reliance on centralized training. To further tackle data heterogeneity, we introduce personalized LoRA (pLoRA), which dynamically adapts LoRA parameters to each client's unique data distribution, significantly improving local adaptation while maintaining global model aggregation. Experiments on the RLAIF-V dataset show that pLoRA improves client-specific performance by 24.5% over standard LoRA, demonstrating superior adaptation in non-iid settings. FedVLM provides a scalable and efficient solution for fine-tuning VLMs in federated settings, advancing personalized adaptation in distributed learning scenarios.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resilient Multi-Agent Negotiation for Medical Supply Chains:Integrating LLMs and Blockchain for Transparent Coordination</title>
<link>https://arxiv.org/abs/2507.17134</link>
<guid>https://arxiv.org/abs/2507.17134</guid>
<content:encoded><![CDATA[
arXiv:2507.17134v1 Announce Type: new 
Abstract: Global health emergencies, such as the COVID-19 pandemic, have exposed critical weaknesses in traditional medical supply chains, including inefficiencies in resource allocation, lack of transparency, and poor adaptability to dynamic disruptions. This paper presents a novel hybrid framework that integrates blockchain technology with a decentralized, large language model (LLM) powered multi-agent negotiation system to enhance the resilience and accountability of medical supply chains during crises. In this system, autonomous agents-representing manufacturers, distributors, and healthcare institutions-engage in structured, context-aware negotiation and decision-making processes facilitated by LLMs, enabling rapid and ethical allocation of scarce medical resources. The off-chain agent layer supports adaptive reasoning and local decision-making, while the on-chain blockchain layer ensures immutable, transparent, and auditable enforcement of decisions via smart contracts. The framework also incorporates a formal cross-layer communication protocol to bridge decentralized negotiation with institutional enforcement. A simulation environment emulating pandemic scenarios evaluates the system's performance, demonstrating improvements in negotiation efficiency, fairness of allocation, supply chain responsiveness, and auditability. This research contributes an innovative approach that synergizes blockchain trust guarantees with the adaptive intelligence of LLM-driven agents, providing a robust and scalable solution for critical supply chain coordination under uncertainty.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Federated Learning of Probabilistic Generative Classifiers</title>
<link>https://arxiv.org/abs/2507.17285</link>
<guid>https://arxiv.org/abs/2507.17285</guid>
<content:encoded><![CDATA[
arXiv:2507.17285v1 Announce Type: new 
Abstract: Federated learning is a paradigm of increasing relevance in real world applications, aimed at building a global model across a network of heterogeneous users without requiring the sharing of private data. We focus on model learning over decentralized architectures, where users collaborate directly to update the global model without relying on a central server. In this context, the current paper proposes a novel approach to collaboratively learn probabilistic generative classifiers with a parametric form. The framework is composed by a communication network over a set of local nodes, each of one having its own local data, and a local updating rule. The proposal involves sharing local statistics with neighboring nodes, where each node aggregates the neighbors' information and iteratively learns its own local classifier, which progressively converges to a global model. Extensive experiments demonstrate that the algorithm consistently converges to a globally competitive model across a wide range of network topologies, network sizes, local dataset sizes, and extreme non-i.i.d. data distributions.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning</title>
<link>https://arxiv.org/abs/2507.17426</link>
<guid>https://arxiv.org/abs/2507.17426</guid>
<content:encoded><![CDATA[
arXiv:2507.17426v1 Announce Type: new 
Abstract: This paper addresses decentralized stochastic gradient descent (D-SGD) over resource-constrained networks by introducing node-based and link-based scheduling strategies to enhance communication efficiency. In each iteration of the D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly activated, subject to a given communication cost constraint. We propose a novel importance metric based on information entropy to determine node and link scheduling probabilities. We validate the effectiveness of our approach through extensive simulations, comparing it against state-of-the-art methods, including betweenness centrality (BC) for node scheduling and \textit{MATCHA} for link scheduling. The results show that our method consistently outperforms the BC-based method in the node scheduling case, achieving faster convergence with up to 60\% lower communication budgets. At higher communication budgets (above 60\%), our method maintains comparable or superior performance. In the link scheduling case, our method delivers results that are superior to or on par with those of \textit{MATCHA}.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Compromises in Participatory Budgeting: a Multi-Agent Deep Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2507.17433</link>
<guid>https://arxiv.org/abs/2507.17433</guid>
<content:encoded><![CDATA[
arXiv:2507.17433v1 Announce Type: new 
Abstract: Participatory budgeting is a method of collectively understanding and addressing spending priorities where citizens vote on how a budget is spent, it is regularly run to improve the fairness of the distribution of public funds. Participatory budgeting requires voters to make decisions on projects which can lead to ``choice overload". A multi-agent reinforcement learning approach to decision support can make decision making easier for voters by identifying voting strategies that increase the winning proportion of their vote. This novel approach can also support policymakers by highlighting aspects of election design that enable fair compromise on projects. This paper presents a novel, ethically aligned approach to decision support using multi-agent deep reinforcement learning modelling. This paper introduces a novel use of a branching neural network architecture to overcome scalability challenges of multi-agent reinforcement learning in a decentralized way. Fair compromises are found through optimising voter actions towards greater representation of voter preferences in the winning set. Experimental evaluation with real-world participatory budgeting data reveals a pattern in fair compromise: that it is achievable through projects with smaller cost.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed P2P quantile tracking with relative value error</title>
<link>https://arxiv.org/abs/2507.17458</link>
<guid>https://arxiv.org/abs/2507.17458</guid>
<content:encoded><![CDATA[
arXiv:2507.17458v1 Announce Type: new 
Abstract: In this paper we present \textsc{DUDDSketch}, a distributed version of the \textsc{UDDSketch} algorithm for accurate tracking of quantiles. The algorithm is a fully decentralized, gossip-based distributed protocol working in the context of unstructured P2P networks. We discuss the algorithm's design and formally prove its correctness. We also show, through extensive experimental results, that the algorithm converges to the results provided by the sequential algorithm, which is a fundamental and highly desirable property.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Quantum Federated Learning with Fisher Information-Based Optimization</title>
<link>https://arxiv.org/abs/2507.17580</link>
<guid>https://arxiv.org/abs/2507.17580</guid>
<content:encoded><![CDATA[
arXiv:2507.17580v1 Announce Type: new 
Abstract: Federated Learning (FL) has become increasingly popular across different sectors, offering a way for clients to work together to train a global model without sharing sensitive data. It involves multiple rounds of communication between the global model and participating clients, which introduces several challenges like high communication costs, heterogeneous client data, prolonged processing times, and increased vulnerability to privacy threats. In recent years, the convergence of federated learning and parameterized quantum circuits has sparked significant research interest, with promising implications for fields such as healthcare and finance. By enabling decentralized training of quantum models, it allows clients or institutions to collaboratively enhance model performance and outcomes while preserving data privacy. Recognizing that Fisher information can quantify the amount of information that a quantum state carries under parameter changes, thereby providing insight into its geometric and statistical properties. We intend to leverage this property to address the aforementioned challenges. In this work, we propose a Quantum Federated Learning (QFL) algorithm that makes use of the Fisher information computed on local client models, with data distributed across heterogeneous partitions. This approach identifies the critical parameters that significantly influence the quantum model's performance, ensuring they are preserved during the aggregation process. Our research assessed the effectiveness and feasibility of QFL by comparing its performance against other variants, and exploring the benefits of incorporating Fisher information in QFL settings. Experimental results on ADNI and MNIST datasets demonstrate the effectiveness of our approach in achieving better performance and robustness against the quantum federated averaging method.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rethinking HSM and TPM Security in the Cloud: Real-World Attacks and Next-Gen Defenses</title>
<link>https://arxiv.org/abs/2507.17655</link>
<guid>https://arxiv.org/abs/2507.17655</guid>
<content:encoded><![CDATA[
arXiv:2507.17655v1 Announce Type: new 
Abstract: As organizations rapidly migrate to the cloud, the security of cryptographic key management has become a growing concern. Hardware Security Modules (HSMs) and Trusted Platform Modules (TPMs), traditionally seen as the gold standard for securing encryption keys and digital trust, are increasingly challenged by cloud-native threats. Real-world breaches have exposed weaknesses in cloud deployments, including misconfigurations, API abuse, and privilege escalations, allowing attackers to access sensitive key material and bypass protections. These incidents reveal that while the hardware remains secure, the surrounding cloud ecosystem introduces systemic vulnerabilities. This paper analyzes notable security failures involving HSMs and TPMs, identifies common attack vectors, and questions longstanding assumptions about their effectiveness in distributed environments. We explore alternative approaches such as confidential computing, post-quantum cryptography, and decentralized key management. Our findings highlight that while HSMs and TPMs still play a role, modern cloud security requires more adaptive, layered architectures. By evaluating both current weaknesses and emerging models, this research equips cloud architects and security engineers with strategies to reinforce cryptographic trust in the evolving threat landscape.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fractal Signatures: Securing AI-Generated Pollock-Style Art via Intrinsic Watermarking and Blockchain</title>
<link>https://arxiv.org/abs/2410.20519</link>
<guid>https://arxiv.org/abs/2410.20519</guid>
<content:encoded><![CDATA[
arXiv:2410.20519v4 Announce Type: replace 
Abstract: The digital art market faces unprecedented challenges in authenticity verification and copyright protection. This study introduces an integrated framework to address these issues by combining neural style transfer, fractal analysis, and blockchain technology. We generate abstract artworks inspired by Jackson Pollock, using their inherent mathematical complexity to create robust, imperceptible watermarks. Our method embeds these watermarks, derived from fractal and turbulence features, directly into the artwork's structure. This approach is then secured by linking the watermark to NFT metadata, ensuring immutable proof of ownership. Rigorous testing shows our feature-based watermarking achieves a 76.2% average detection rate against common attacks, significantly outperforming traditional methods (27.8-44.0%). This work offers a practical solution for digital artists and collectors, enhancing security and trust in the digital art ecosystem.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized AI-driven IoT Architecture for Privacy-Preserving and Latency-Optimized Healthcare in Pandemic and Critical Care Scenarios</title>
<link>https://arxiv.org/abs/2507.15859</link>
<guid>https://arxiv.org/abs/2507.15859</guid>
<content:encoded><![CDATA[
arXiv:2507.15859v1 Announce Type: new 
Abstract: AI Innovations in the IoT for Real-Time Patient Monitoring On one hand, the current traditional centralized healthcare architecture poses numerous issues, including data privacy, delay, and security. Here, we present an AI-enabled decentralized IoT architecture that can address such challenges during a pandemic and critical care settings. This work presents our architecture to enhance the effectiveness of the current available federated learning, blockchain, and edge computing approach, maximizing data privacy, minimizing latency, and improving other general system metrics. Experimental results demonstrate transaction latency, energy consumption, and data throughput orders of magnitude lower than competitive cloud solutions.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MFAz: Historical Access Based Multi-Factor Authorization</title>
<link>https://arxiv.org/abs/2507.16060</link>
<guid>https://arxiv.org/abs/2507.16060</guid>
<content:encoded><![CDATA[
arXiv:2507.16060v1 Announce Type: new 
Abstract: Unauthorized access remains one of the critical security challenges in the realm of cybersecurity. With the increasing sophistication of attack techniques, the threat of unauthorized access is no longer confined to the conventional ones, such as exploiting weak access control policies. Instead, advanced exploitation strategies, such as session hijacking-based attacks, are becoming increasingly prevalent, posing serious security concerns. Session hijacking enables attackers to take over an already established session between legitimate peers in a stealthy manner, thereby gaining unauthorized access to private resources. Unfortunately, traditional access control mechanisms, such as static access control policies, are insufficient to prevent session hijacking or other advanced exploitation techniques. In this work, we propose a new multi-factor authorization (MFAz) scheme that proactively mitigates unauthorized access attempts both conventional and advanced unauthorized access attacks. The proposed scheme employs fine-grained access control rules (ARs) and verification points (VPs) that are systematically generated from historically granted accesses as the first and second authorization factors, respectively. As a proof-of-concept, we implement the scheme using different techniques. We leverage bloom filter to achieve runtime and storage efficiency, and blockchain to make authorization decisions in a temper-proof and decentralized manner. To the best of our knowledge, this is the first formal introduction of a multi-factor authorization scheme, which is orthogonal to the multi-factor authentication (MFA) schemes. The effectiveness of our proposed scheme is experimentally evaluated using a smart-city testbed involving different devices with varying computational capacities. The experimental results reveal high effectiveness of the scheme both in security and performance guarantees.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DP2Guard: A Lightweight and Byzantine-Robust Privacy-Preserving Federated Learning Scheme for Industrial IoT</title>
<link>https://arxiv.org/abs/2507.16134</link>
<guid>https://arxiv.org/abs/2507.16134</guid>
<content:encoded><![CDATA[
arXiv:2507.16134v1 Announce Type: new 
Abstract: Privacy-Preserving Federated Learning (PPFL) has emerged as a secure distributed Machine Learning (ML) paradigm that aggregates locally trained gradients without exposing raw data. To defend against model poisoning threats, several robustness-enhanced PPFL schemes have been proposed by integrating anomaly detection. Nevertheless, they still face two major challenges: (1) the reliance on heavyweight encryption techniques results in substantial communication and computation overhead; and (2) single-strategy defense mechanisms often fail to provide sufficient robustness against adaptive adversaries. To overcome these challenges, we propose DP2Guard, a lightweight PPFL framework that enhances both privacy and robustness. DP2Guard leverages a lightweight gradient masking mechanism to replace costly cryptographic operations while ensuring the privacy of local gradients. A hybrid defense strategy is proposed, which extracts gradient features using singular value decomposition and cosine similarity, and applies a clustering algorithm to effectively identify malicious gradients. Additionally, DP2Guard adopts a trust score-based adaptive aggregation scheme that adjusts client weights according to historical behavior, while blockchain records aggregated results and trust scores to ensure tamper-proof and auditable training. Extensive experiments conducted on two public datasets demonstrate that DP2Guard effectively defends against four advanced poisoning attacks while ensuring privacy with reduced communication and computation costs.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping</title>
<link>https://arxiv.org/abs/2507.16249</link>
<guid>https://arxiv.org/abs/2507.16249</guid>
<content:encoded><![CDATA[
arXiv:2507.16249v1 Announce Type: new 
Abstract: Mapping deep neural networks (DNNs) to hardware is critical for optimizing latency, energy consumption, and resource utilization, making it a cornerstone of high-performance accelerator design. Due to the vast and complex mapping space, reinforcement learning (RL) has emerged as a promising approach-but its effectiveness is often limited by sample inefficiency. We present a decentralized multi-agent reinforcement learning (MARL) framework designed to overcome this challenge. By distributing the search across multiple agents, our framework accelerates exploration. To avoid inefficiencies from training multiple agents in parallel, we introduce an agent clustering algorithm that assigns similar mapping parameters to the same agents based on correlation analysis. This enables a decentralized, parallelized learning process that significantly improves sample efficiency. Experimental results show our MARL approach improves sample efficiency by 30-300x over standard single-agent RL, achieving up to 32.61x latency reduction and 16.45x energy-delay product (EDP) reduction under iso-sample conditions.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Contracts to Code: Automating Smart Contract Generation with Multi-Level Finite State Machines</title>
<link>https://arxiv.org/abs/2507.16276</link>
<guid>https://arxiv.org/abs/2507.16276</guid>
<content:encoded><![CDATA[
arXiv:2507.16276v1 Announce Type: new 
Abstract: In an increasingly complex contractual landscape, the demand for transparency, security, and efficiency has intensified. Blockchain technology, with its decentralized and immutable nature, addresses these challenges by reducing intermediary costs, minimizing fraud risks, and enhancing system compatibility. Smart contracts, initially conceptualized by Nick Szabo and later implemented on the Ethereum blockchain, automate and secure contractual clauses, offering a robust solution for various industries. However, their complexity and the requirement for advanced programming skills present significant barriers to widespread adoption. This study introduces a multi-level finite state machine model designed to represent and track the execution of smart contracts. Our model aims to simplify smart contract development by providing a formalized framework that abstracts underlying technical complexities, making it accessible to professionals without deep technical expertise. The hierarchical structure of the multi-level finite state machine enhances contract modularity and traceability, facilitating detailed representation and evaluation of functional properties. The paper explores the potential of this multi-level approach, reviewing existing methodologies and tools, and detailing the smart contract generation process with an emphasis on reusable components and modularity. We also conduct a security analysis to evaluate potential vulnerabilities in our model, ensuring the robustness and reliability of the generated smart contracts.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COMPASS: Cooperative Multi-Agent Persistent Monitoring using Spatio-Temporal Attention Network</title>
<link>https://arxiv.org/abs/2507.16306</link>
<guid>https://arxiv.org/abs/2507.16306</guid>
<content:encoded><![CDATA[
arXiv:2507.16306v1 Announce Type: new 
Abstract: Persistent monitoring of dynamic targets is essential in real-world applications such as disaster response, environmental sensing, and wildlife conservation, where mobile agents must continuously gather information under uncertainty. We propose COMPASS, a multi-agent reinforcement learning (MARL) framework that enables decentralized agents to persistently monitor multiple moving targets efficiently. We model the environment as a graph, where nodes represent spatial locations and edges capture topological proximity, allowing agents to reason over structured layouts and revisit informative regions as needed. Each agent independently selects actions based on a shared spatio-temporal attention network that we design to integrate historical observations and spatial context. We model target dynamics using Gaussian Processes (GPs), which support principled belief updates and enable uncertainty-aware planning. We train COMPASS using centralized value estimation and decentralized policy execution under an adaptive reward setting. Our extensive experiments demonstrate that COMPASS consistently outperforms strong baselines in uncertainty reduction, target coverage, and coordination efficiency across dynamic multi-target scenarios.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Dominant Resource Fairness for Blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2507.16350</link>
<guid>https://arxiv.org/abs/2507.16350</guid>
<content:encoded><![CDATA[
arXiv:2507.16350v1 Announce Type: new 
Abstract: Blockchain systems have been a part of mainstream academic research, and a hot topic at that. It has spread to almost every subfield in the computer science literature, as well as economics and finance. Especially in a world where digital trust is much sought for, blockchains offer a rich variety of desired properties, such as immutability, public auditing, decentralised record keeping, among others. Not only has it been a research topic of its own, the integration of blockchains into other systems has been proposed as solutions in many areas, ranging from grid computing, cloud and fog computing, to internet of things, self driving vehicles , and smart cities. In many cases the primary function attributed to blockchains in these contexts is resource management. Although much attention is paid to this topic, the focus is on single resource allocation scenarios. Even the cases where multiple resource types are to be allocated, are treated as single resource type scenarios, and problems are formulated as allocating standardised bundles consisting of a fixed amount of each of them, such as virtual machines. The present study addresses the problem of allocating multiple resource types among tasks with heterogeneous resource demands with a smart contract adaptation of Precomputed Dominant Resource Fairness; an algorithm that approximates Dominant Resource Fairness, without loop iterations, which makes it preferable in the blockchain context because of the block gas limit. We present the resulting algorithm, Autonomous Dominant Resource Fairness, along with the empirical data collected from the tests run on the algorithm. The results show that Autonomous Dominant Resource Fairness is a gas-cost efficient algorithm, which can be used to manage hundreds of resource types for unlimited number of users.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Data-centric Overview of Federated Graph Learning</title>
<link>https://arxiv.org/abs/2507.16541</link>
<guid>https://arxiv.org/abs/2507.16541</guid>
<content:encoded><![CDATA[
arXiv:2507.16541v1 Announce Type: new 
Abstract: In the era of big data applications, Federated Graph Learning (FGL) has emerged as a prominent solution that reconcile the tradeoff between optimizing the collective intelligence between decentralized datasets holders and preserving sensitive information to maximum. Existing FGL surveys have contributed meaningfully but largely focus on integrating Federated Learning (FL) and Graph Machine Learning (GML), resulting in early stage taxonomies that emphasis on methodology and simulated scenarios. Notably, a data centric perspective, which systematically examines FGL methods through the lens of data properties and usage, remains unadapted to reorganize FGL research, yet it is critical to assess how FGL studies manage to tackle data centric constraints to enhance model performances. This survey propose a two-level data centric taxonomy: Data Characteristics, which categorizes studies based on the structural and distributional properties of datasets used in FGL, and Data Utilization, which analyzes the training procedures and techniques employed to overcome key data centric challenges. Each taxonomy level is defined by three orthogonal criteria, each representing a distinct data centric configuration. Beyond taxonomy, this survey examines FGL integration with Pretrained Large Models, showcases realistic applications, and highlights future direction aligned with emerging trends in GML.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems</title>
<link>https://arxiv.org/abs/2507.16635</link>
<guid>https://arxiv.org/abs/2507.16635</guid>
<content:encoded><![CDATA[
arXiv:2507.16635v1 Announce Type: new 
Abstract: Efficient planning of activities is essential for modern industrial assembly lines to uphold manufacturing standards, prevent project constraint violations, and achieve cost-effective operations. While exact solutions to such challenges can be obtained through Integer Programming (IP), the dependence of the search space on input parameters often makes IP computationally infeasible for large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also be applied, but they frequently produce suboptimal solutions in extensive cases. This paper introduces a novel mathematical model of a generic industrial assembly line formulated as a Markov Decision Process (MDP), without imposing assumptions on the type of assembly line a notable distinction from most existing models. The proposed model is employed to create a virtual environment for training Deep Reinforcement Learning (DRL) agents to optimize task and resource scheduling. To enhance the efficiency of agent training, the paper proposes two innovative tools. The first is an action-masking technique, which ensures the agent selects only feasible actions, thereby reducing training time. The second is a multi-agent approach, where each workstation is managed by an individual agent, as a result, the state and action spaces were reduced. A centralized training framework with decentralized execution is adopted, offering a scalable learning architecture for optimizing industrial assembly lines. This framework allows the agents to learn offline and subsequently provide real-time solutions during operations by leveraging a neural network that maps the current factory state to the optimal action. The effectiveness of the proposed scheme is validated through numerical simulations, demonstrating significantly faster convergence to the optimal solution compared to a comparable model-based approach.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Partitioned Sparse Variational Gaussian Process for Fast, Distributed Spatial Modeling</title>
<link>https://arxiv.org/abs/2507.16771</link>
<guid>https://arxiv.org/abs/2507.16771</guid>
<content:encoded><![CDATA[
arXiv:2507.16771v1 Announce Type: new 
Abstract: The next generation of Department of Energy supercomputers will be capable of exascale computation. For these machines, far more computation will be possible than that which can be saved to disk. As a result, users will be unable to rely on post-hoc access to data for uncertainty quantification and other statistical analyses and there will be an urgent need for sophisticated machine learning algorithms which can be trained in situ. Algorithms deployed in this setting must be highly scalable, memory efficient and capable of handling data which is distributed across nodes as spatially contiguous partitions. One suitable approach involves fitting a sparse variational Gaussian process (SVGP) model independently and in parallel to each spatial partition. The resulting model is scalable, efficient and generally accurate, but produces the undesirable effect of constructing discontinuous response surfaces due to the disagreement between neighboring models at their shared boundary. In this paper, we extend this idea by allowing for a small amount of communication between neighboring spatial partitions which encourages better alignment of the local models, leading to smoother spatial predictions and a better fit in general. Due to our decentralized communication scheme, the proposed extension remains highly scalable and adds very little overhead in terms of computation (and none, in terms of memory). We demonstrate this Partitioned SVGP (PSVGP) approach for the Energy Exascale Earth System Model (E3SM) and compare the results to the independent SVGP case.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph Neural Networks Gone Hogwild</title>
<link>https://arxiv.org/abs/2407.00494</link>
<guid>https://arxiv.org/abs/2407.00494</guid>
<content:encoded><![CDATA[
arXiv:2407.00494v2 Announce Type: replace 
Abstract: Graph neural networks (GNNs) appear to be powerful tools to learn state representations for agents in distributed, decentralized multi-agent systems, but generate catastrophically incorrect predictions when nodes update asynchronously during inference. This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce, e.g., robotic swarms or sensor networks. In this work we identify "implicitly-defined" GNNs as a class of architectures which is provably robust to asynchronous "hogwild" inference, adapting convergence guarantees from work in asynchronous and distributed optimization. We then propose a novel implicitly-defined GNN architecture, which we call an 'energy GNN'. We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aligning AI with Public Values: Deliberation and Decision-Making for Governing Multimodal LLMs in Political Video Analysis</title>
<link>https://arxiv.org/abs/2410.01817</link>
<guid>https://arxiv.org/abs/2410.01817</guid>
<content:encoded><![CDATA[
arXiv:2410.01817v2 Announce Type: replace 
Abstract: How AI models should deal with political topics has been discussed, but it remains challenging and requires better governance. This paper examines the governance of large language models through individual and collective deliberation, focusing on politically sensitive videos. We conducted a two-step study: interviews with 10 journalists established a baseline understanding of expert video interpretation; 114 individuals through deliberation using InclusiveAI, a platform that facilitates democratic decision-making through decentralized autonomous organization (DAO) mechanisms. Our findings reveal distinct differences in interpretative priorities: while experts emphasized emotion and narrative, the general public prioritized factual clarity, objectivity, and emotional neutrality. Furthermore, we examined how different governance mechanisms - quadratic vs. weighted voting and equal vs. 20/80 voting power - shape users' decision-making regarding AI behavior. Results indicate that voting methods significantly influence outcomes, with quadratic voting reinforcing perceptions of liberal democracy and political equality. Our study underscores the necessity of selecting appropriate governance mechanisms to better capture user perspectives and suggests decentralized AI governance as a potential way to facilitate broader public engagement in AI development, ensuring that varied perspectives meaningfully inform design decisions.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>White paper: Towards Human-centric and Sustainable 6G Services -- the fortiss Research Perspective</title>
<link>https://arxiv.org/abs/2507.14209</link>
<guid>https://arxiv.org/abs/2507.14209</guid>
<content:encoded><![CDATA[
arXiv:2507.14209v1 Announce Type: new 
Abstract: As a leading research institute in software-intensive systems, fortiss is actively shaping the vision of Sixth Generation Mobile Communication (6G). Our mission is to ensure that 6G technologies go beyond technical advancements and are aligned with societal needs. fortiss plays a key role in 6G initiatives worldwide, including contributions to standardization bodies and collaborative Research and Development programs. We focus on software-defined, AI-enabled, and sustainable communication services that prioritize human values and long-term impact. 6G will redefine digital connectivity through cognitive intelligence, decentralized orchestration, and sustainability-oriented architectures. As expectations rise for ultra-reliable low-latency communication (URLLC) and personalized digital services, 6G must outperform prior generations. It will rely on AI-native networking, Edge-Cloud resource orchestration, and energy-aware data frameworks, ensuring both technical performance and societal relevance. This white paper presents the fortiss vision for a human-centric, sustainable, and AI-integrated 6G network. It outlines key research domains such as semantic communication, green orchestration, and distributed AI, all linked to societal and technological challenges. The white paper is aimed at researchers, industry experts, policymakers, and developers. It articulates the strategic direction and contributions of fortiss to 6G, emphasizing responsible innovation and interdisciplinary collaboration toward a meaningful 2030 vision.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning</title>
<link>https://arxiv.org/abs/2507.14322</link>
<guid>https://arxiv.org/abs/2507.14322</guid>
<content:encoded><![CDATA[
arXiv:2507.14322v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a paradigm for privacy-preserving collaborative AI, but its decentralized nature creates significant vulnerabilities to model poisoning attacks. While numerous static defenses exist, their effectiveness is highly context-dependent, often failing against adaptive adversaries or in heterogeneous data environments. This paper introduces FedStrategist, a novel meta-learning framework that reframes robust aggregation as a real-time, cost-aware control problem. We design a lightweight contextual bandit agent that dynamically selects the optimal aggregation rule from an arsenal of defenses based on real-time diagnostic metrics. Through comprehensive experiments, we demonstrate that no single static rule is universally optimal. We show that our adaptive agent successfully learns superior policies across diverse scenarios, including a ``Krum-favorable" environment and against a sophisticated "stealth" adversary designed to neutralize specific diagnostic signals. Critically, we analyze the paradoxical scenario where a non-robust baseline achieves high but compromised accuracy, and demonstrate that our agent learns a conservative policy to prioritize model integrity. Furthermore, we prove the agent's policy is controllable via a single "risk tolerance" parameter, allowing practitioners to explicitly manage the trade-off between performance and security. Our work provides a new, practical, and analyzable approach to creating resilient and intelligent decentralized AI systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum</title>
<link>https://arxiv.org/abs/2507.14588</link>
<guid>https://arxiv.org/abs/2507.14588</guid>
<content:encoded><![CDATA[
arXiv:2507.14588v1 Announce Type: new 
Abstract: Secure federated learning enables collaborative model training across decentralized users while preserving data privacy. A key component is secure aggregation, which keeps individual updates hidden from both the server and users, while also defending against Byzantine users who corrupt the aggregation. To this end, Jinhyun So et al. recently developed a Byzantine-resilient secure aggregation scheme using a secret-sharing strategy over finite-field arithmetic. However, such an approach can suffer from numerical errors and overflows when applied to real-valued model updates, motivating the need for secure aggregation methods that operate directly over the real domain. We propose FORTA, a Byzantine-resilient secure aggregation framework that operates entirely in the real domain. FORTA leverages Discrete Fourier Transform (DFT) codes for privacy and employs Krum-based outlier detection for robustness. While DFT decoder is error-free under infinite precision, finite precision introduces numerical perturbations that can distort distance estimates and allow malicious updates to evade detection. To address this, FORTA refines Krum using feedback from DFT decoder, improving the selection of trustworthy updates. Theoretical analysis and experiments show that our modification of Krum offers improved robustness and more accurate aggregation than standard Krum.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems</title>
<link>https://arxiv.org/abs/2507.14660</link>
<guid>https://arxiv.org/abs/2507.14660</guid>
<content:encoded><![CDATA[
arXiv:2507.14660v1 Announce Type: new 
Abstract: Recent large-scale events like election fraud and financial scams have shown how harmful coordinated efforts by human groups can be. With the rise of autonomous AI systems, there is growing concern that AI-driven groups could also cause similar harm. While most AI safety research focuses on individual AI systems, the risks posed by multi-agent systems (MAS) in complex real-world situations are still underexplored. In this paper, we introduce a proof-of-concept to simulate the risks of malicious MAS collusion, using a flexible framework that supports both centralized and decentralized coordination structures. We apply this framework to two high-risk fields: misinformation spread and e-commerce fraud. Our findings show that decentralized systems are more effective at carrying out malicious actions than centralized ones. The increased autonomy of decentralized systems allows them to adapt their strategies and cause more damage. Even when traditional interventions, like content flagging, are applied, decentralized groups can adjust their tactics to avoid detection. We present key insights into how these malicious groups operate and the need for better detection systems and countermeasures. Code is available at https://github.com/renqibing/RogueAgent.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption</title>
<link>https://arxiv.org/abs/2507.14853</link>
<guid>https://arxiv.org/abs/2507.14853</guid>
<content:encoded><![CDATA[
arXiv:2507.14853v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training without sharing raw data, making it a promising approach for privacy-sensitive domains. Despite its potential, FL faces significant challenges, particularly in terms of communication overhead and data privacy. Privacy-preserving Techniques (PPTs) such as Homomorphic Encryption (HE) have been used to mitigate these concerns. However, these techniques introduce substantial computational and communication costs, limiting their practical deployment. In this work, we explore how Hybrid Homomorphic Encryption (HHE), a cryptographic protocol that combines symmetric encryption with HE, can be effectively integrated with FL to address both communication and privacy challenges, paving the way for scalable and secure decentralized learning system.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Robust Decentralized Coordination of LLM Agents</title>
<link>https://arxiv.org/abs/2507.14928</link>
<guid>https://arxiv.org/abs/2507.14928</guid>
<content:encoded><![CDATA[
arXiv:2507.14928v1 Announce Type: new 
Abstract: Collaboration among multiple large language model (LLM) agents is a promising approach to overcome inherent limitations of single-agent systems, such as hallucinations and single points of failure. As LLM agents are increasingly deployed on open blockchain platforms, multi-agent systems capable of tolerating malicious (Byzantine) agents have become essential.
  Recent Byzantine-robust multi-agent systems typically rely on leader-driven coordination, which suffers from two major drawbacks. First, they are inherently vulnerable to targeted attacks against the leader. If consecutive leaders behave maliciously, the system repeatedly fails to achieve consensus, forcing new consensus rounds, which is particularly costly given the high latency of LLM invocations. Second, an underperforming proposal from the leader can be accepted as the final answer even when higher-quality alternatives are available, as existing methods finalize the leader's proposal once it receives a quorum of votes.
  To address these issues, we propose DecentLLMs, a novel decentralized consensus approach for multi-agent LLM systems, where worker agents generate answers concurrently and evaluator agents independently score and rank these answers to select the best available one. This decentralized architecture enables faster consensus despite the presence of Byzantine agents and consistently selects higher-quality answers through Byzantine-robust aggregation techniques.
  Experimental results demonstrate that DecentLLMs effectively tolerates Byzantine agents and significantly improves the quality of selected answers.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios</title>
<link>https://arxiv.org/abs/2507.14980</link>
<guid>https://arxiv.org/abs/2507.14980</guid>
<content:encoded><![CDATA[
arXiv:2507.14980v1 Announce Type: new 
Abstract: Federated Learning (FL) enables decentralized model training while preserving data privacy. Despite its benefits, FL faces challenges with non-identically distributed (non-IID) data, especially in long-tailed scenarios with imbalanced class samples. Momentum-based FL methods, often used to accelerate FL convergence, struggle with these distributions, resulting in biased models and making FL hard to converge. To understand this challenge, we conduct extensive investigations into this phenomenon, accompanied by a layer-wise analysis of neural network behavior. Based on these insights, we propose FedWCM, a method that dynamically adjusts momentum using global and per-round data to correct directional biases introduced by long-tailed distributions. Extensive experiments show that FedWCM resolves non-convergence issues and outperforms existing methods, enhancing FL's efficiency and effectiveness in handling client heterogeneity and data imbalance.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading</title>
<link>https://arxiv.org/abs/2507.14995</link>
<guid>https://arxiv.org/abs/2507.14995</guid>
<content:encoded><![CDATA[
arXiv:2507.14995v1 Announce Type: new 
Abstract: Real-time peer-to-peer (P2P) electricity markets dynamically adapt to fluctuations in renewable energy and variations in demand, maximizing economic benefits through instantaneous price responses while enhancing grid flexibility. However, scaling expert guidance for massive personalized prosumers poses critical challenges, including diverse decision-making demands and lack of customized modeling frameworks. This paper proposed an integrated large language model-multi-agent reinforcement learning (LLM-MARL) framework for real-time P2P energy trading to address challenges such as the limited technical capability of prosumers, the lack of expert experience, and security issues of distribution networks. LLMs are introduced as experts to generate personalized strategy, guiding MARL under the centralized training with decentralized execution (CTDE) paradigm through imitation learning. A differential attention-based critic network is designed to enhance convergence performance. Experimental results demonstrate that LLM generated strategies effectively substitute human experts. The proposed multi-agent imitation learning algorithms achieve significantly lower economic costs and voltage violation rates on test sets compared to baselines algorithms, while maintaining robust stability. This work provides an effective solution for real-time P2P electricity market decision-making by bridging expert knowledge with agent learning.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI</title>
<link>https://arxiv.org/abs/2507.15104</link>
<guid>https://arxiv.org/abs/2507.15104</guid>
<content:encoded><![CDATA[
arXiv:2507.15104v1 Announce Type: new 
Abstract: Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize analog design automation through data-driven approaches. In particular, researchers are increasingly fascinated by harnessing the power of generative AI to automate the discovery of novel analog circuit topologies. Unlocking the full potential of generative AI in these data-driven discoveries requires access to large and diverse datasets.Yet, there is a significant barrier in the analog domain--Analog circuit design is inherently proprietary, involving not only confidential circuit structures but also the underlying commercial semiconductor processes. As a result, current generative AI research is largely confined to individual researchers who construct small, narrowly focused private datasets. This fragmentation severely limits collaborative innovation and impedes progress across the research community. To address these challenges, we propose AnalogFed. AnalogFed enables collaborative topology discovery across decentralized clients (e.g., individual researchers or institutions) without requiring the sharing of raw private data. To make this vision practical, we introduce a suite of techniques tailored to the unique challenges of applying FedL in analog design--from generative model development and data heterogeneity handling to privacy-preserving strategies that ensure both flexibility and security for circuit designers and semiconductor manufacturers. Extensive experiments across varying client counts and dataset sizes demonstrate that AnalogFed achieves performance comparable to centralized baselines--while maintaining strict data privacy. Specifically, the generative AI model within AnalogFed achieves state-of-the-art efficiency and scalability in the design of analog circuit topologies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control</title>
<link>https://arxiv.org/abs/2507.15174</link>
<guid>https://arxiv.org/abs/2507.15174</guid>
<content:encoded><![CDATA[
arXiv:2507.15174v1 Announce Type: new 
Abstract: Traffic Signal Control (TSC) is essential for managing urban traffic flow and reducing congestion. Reinforcement Learning (RL) offers an adaptive method for TSC by responding to dynamic traffic patterns, with multi-agent RL (MARL) gaining traction as intersections naturally function as coordinated agents. However, due to shifts in environmental dynamics, implementing MARL-based TSC policies in the real world often leads to a significant performance drop, known as the sim-to-real gap. Grounded Action Transformation (GAT) has successfully mitigated this gap in single-agent RL for TSC, but real-world traffic networks, which involve numerous interacting intersections, are better suited to a MARL framework. In this work, we introduce JL-GAT, an application of GAT to MARL-based TSC that balances scalability with enhanced grounding capability by incorporating information from neighboring agents. JL-GAT adopts a decentralized approach to GAT, allowing for the scalability often required in real-world traffic networks while still capturing key interactions between agents. Comprehensive experiments on various road networks under simulated adverse weather conditions, along with ablation studies, demonstrate the effectiveness of JL-GAT. The code is publicly available at https://github.com/DaRL-LibSignal/JL-GAT/.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Low-Power and Accurate IoT Monitoring Under Radio Resource Constraint</title>
<link>https://arxiv.org/abs/2507.15338</link>
<guid>https://arxiv.org/abs/2507.15338</guid>
<content:encoded><![CDATA[
arXiv:2507.15338v1 Announce Type: new 
Abstract: This paper investigates how to achieve both low-power operations of sensor nodes and accurate state estimation using Kalman filter for internet of things (IoT) monitoring employing wireless sensor networks under radio resource constraint. We consider two policies used by the base station to collect observations from the sensor nodes: (i) an oblivious policy, based on statistics of the observations, and (ii) a decentralized policy, based on autonomous decision of each sensor based on its instantaneous observation. This work introduces a wake-up receiver and wake-up signaling to both policies to improve the energy efficiency of the sensor nodes. The decentralized policy designed with random access prioritizes transmissions of instantaneous observations that are highly likely to contribute to the improvement of state estimation. Our numerical results show that the decentralized policy improves the accuracy of the estimation in comparison to the oblivious policy under the constraint on the radio resource and consumed energy when the correlation between the processes observed by the sensor nodes is low. We also clarify the degree of correlation in which the superiority of two policies changes.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scaling Decentralized Learning with FLock</title>
<link>https://arxiv.org/abs/2507.15349</link>
<guid>https://arxiv.org/abs/2507.15349</guid>
<content:encoded><![CDATA[
arXiv:2507.15349v1 Announce Type: new 
Abstract: Fine-tuning the large language models (LLMs) are prevented by the deficiency of centralized control and the massive computing and communication overhead on the decentralized schemes. While the typical standard federated learning (FL) supports data privacy, the central server requirement creates a single point of attack and vulnerability to poisoning attacks. Generalizing the result in this direction to 70B-parameter models in the heterogeneous, trustless environments has turned out to be a huge, yet unbroken bottleneck. This paper introduces FLock, a decentralized framework for secure and efficient collaborative LLM fine-tuning. Integrating a blockchain-based trust layer with economic incentives, FLock replaces the central aggregator with a secure, auditable protocol for cooperation among untrusted parties. We present the first empirical validation of fine-tuning a 70B LLM in a secure, multi-domain, decentralized setting. Our experiments show the FLock framework defends against backdoor poisoning attacks that compromise standard FL optimizers and fosters synergistic knowledge transfer. The resulting models show a >68% reduction in adversarial attack success rates. The global model also demonstrates superior cross-domain generalization, outperforming models trained in isolation on their own specialized data.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms</title>
<link>https://arxiv.org/abs/2507.15351</link>
<guid>https://arxiv.org/abs/2507.15351</guid>
<content:encoded><![CDATA[
arXiv:2507.15351v1 Announce Type: new 
Abstract: On-demand ride-sharing platforms face the fundamental challenge of dynamically bundling passengers with diverse origins and destinations and matching them with vehicles in real time, all under significant uncertainty. Recently, MARL has emerged as a promising solution for this problem, leveraging decentralized learning to address the curse of dimensionality caused by the large number of agents in the ride-hailing market and the resulting expansive state and action spaces. However, conventional MARL-based ride-sharing approaches heavily rely on the accurate estimation of Q-values or V-values, which becomes problematic in large-scale, highly uncertain environments. Specifically, most of these approaches adopt an independent paradigm, exacerbating this issue, as each agent treats others as part of the environment, leading to unstable training and substantial estimation bias in value functions. To address these challenges, we propose two novel alternative methods that bypass value function estimation. First, we adapt GRPO to ride-sharing, replacing the PPO baseline with the group average reward to eliminate critic estimation errors and reduce training bias. Second, inspired by GRPO's full utilization of group reward information, we customize the PPO framework for ride-sharing platforms and show that, under a homogeneous fleet, the optimal policy can be trained using only one-step rewards - a method we term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior performance across most scenarios, efficiently optimizing pickup times and the number of served orders using simple MLP networks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts</title>
<link>https://arxiv.org/abs/2507.15761</link>
<guid>https://arxiv.org/abs/2507.15761</guid>
<content:encoded><![CDATA[
arXiv:2507.15761v1 Announce Type: new 
Abstract: Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed loop to identify, validate, and apply Gas-saving improvements. Experiments on 100 verified real-world contracts demonstrate that GasAgent successfully optimizes 82 contracts, achieving an average deployment Gas savings of 9.97%. In addition, our evaluation confirms its compatibility with existing tools and validates the effectiveness of each module through ablation studies. To assess broader usability, we further evaluate 500 contracts generated by five representative LLMs across 10 categories and find that GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from 4.79% to 13.93%, showing its usability as the optimization layer for LLM-assisted smart contract development.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra</title>
<link>https://arxiv.org/abs/2507.15815</link>
<guid>https://arxiv.org/abs/2507.15815</guid>
<content:encoded><![CDATA[
arXiv:2507.15815v1 Announce Type: new 
Abstract: We present the LLM Economist, a novel framework that uses agent-based modeling to design and assess economic policies in strategic environments with hierarchical decision-making. At the lower level, bounded rational worker agents -- instantiated as persona-conditioned prompts sampled from U.S. Census-calibrated income and demographic statistics -- choose labor supply to maximize text-based utility functions learned in-context. At the upper level, a planner agent employs in-context reinforcement learning to propose piecewise-linear marginal tax schedules anchored to the current U.S. federal brackets. This construction endows economic simulacra with three capabilities requisite for credible fiscal experimentation: (i) optimization of heterogeneous utilities, (ii) principled generation of large, demographically realistic agent populations, and (iii) mechanism design -- the ultimate nudging problem -- expressed entirely in natural language. Experiments with populations of up to one hundred interacting agents show that the planner converges near Stackelberg equilibria that improve aggregate social welfare relative to Saez solutions, while a periodic, persona-level voting procedure furthers these gains under decentralized governance. These results demonstrate that large language model-based agents can jointly model, simulate, and govern complex economic systems, providing a tractable test bed for policy evaluation at the societal scale to help build better civilizations.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Machine Learning Approach for Low-Latency Localization in Cell-Free Massive MIMO Systems</title>
<link>https://arxiv.org/abs/2507.14216</link>
<guid>https://arxiv.org/abs/2507.14216</guid>
<content:encoded><![CDATA[
arXiv:2507.14216v1 Announce Type: cross 
Abstract: Low-latency localization is critical in cellular networks to support real-time applications requiring precise positioning. In this paper, we propose a distributed machine learning (ML) framework for fingerprint-based localization tailored to cell-free massive multiple-input multiple-output (MIMO) systems, an emerging architecture for 6G networks. The proposed framework enables each access point (AP) to independently train a Gaussian process regression model using local angle-of-arrival and received signal strength fingerprints. These models provide probabilistic position estimates for the user equipment (UE), which are then fused by the UE with minimal computational overhead to derive a final location estimate. This decentralized approach eliminates the need for fronthaul communication between the APs and the central processing unit (CPU), thereby reducing latency. Additionally, distributing computational tasks across the APs alleviates the processing burden on the CPU compared to traditional centralized localization schemes. Simulation results demonstrate that the proposed distributed framework achieves localization accuracy comparable to centralized methods, despite lacking the benefits of centralized data aggregation. Moreover, it effectively reduces uncertainty of the location estimates, as evidenced by the 95\% covariance ellipse. The results highlight the potential of distributed ML for enabling low-latency, high-accuracy localization in future 6G networks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transaction Profiling and Address Role Inference in Tokenized U.S. Treasuries</title>
<link>https://arxiv.org/abs/2507.14808</link>
<guid>https://arxiv.org/abs/2507.14808</guid>
<content:encoded><![CDATA[
arXiv:2507.14808v1 Announce Type: cross 
Abstract: Tokenized U.S. Treasuries have emerged as a prominent subclass of real-world assets (RWAs), offering cryptographically enforced, yield-bearing instruments collateralized by sovereign debt and deployed across multiple blockchain networks. While the market has expanded rapidly, empirical analyses of transaction-level behaviour remain limited. This paper conducts a quantitative, function-level dissection of U.S. Treasury-backed RWA tokens including BUIDL, BENJI, and USDY, across multi-chain: mostly Ethereum and Layer-2s. We analyze decoded contract calls to isolate core functional primitives such as issuance, redemption, transfer, and bridge activity, revealing segmentation in behaviour between institutional actors and retail users. To model address-level economic roles, we introduce a curvature-aware representation learning framework using Poincar\'e embeddings and liquidity-based graph features. Our method outperforms baseline models on our RWA Treasury dataset in role inference and generalizes to downstream tasks such as anomaly detection and wallet classification in broader blockchain transaction networks. These findings provide a structured understanding of functional heterogeneity and participant roles in tokenized Treasury in a transaction-level perspective, contributing new empirical evidence to the study of on-chain financialization.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Time Entangled Quantum Blockchain with Phase Encoding for Classical Data</title>
<link>https://arxiv.org/abs/2507.14839</link>
<guid>https://arxiv.org/abs/2507.14839</guid>
<content:encoded><![CDATA[
arXiv:2507.14839v1 Announce Type: cross 
Abstract: With rapid advancements in quantum computing, it is widely believed that there will be quantum hardware capable of compromising classical cryptography and hence, the internet and the current information security infrastructure in the coming decade. This is mainly due to the operational realizations of quantum algorithms such as Grover and Shor, to which the current classical encryption protocols are vulnerable. Blockchains, i.e., blockchain data structures and their data, rely heavily on classical cryptography. One approach to secure blockchain is to attempt to achieve information theoretical security by defining blockchain on quantum technologies. There have been two conceptualizations of blockchains on quantum registers: the time-entangled Greenberger-Horne-Zeilinger (GHZ) state blockchain and the quantum hypergraph blockchain. On our part, an attempt is made to conceptualize a new quantum blockchain combining features of both these schemes to achieve the absolute security of the time-temporal GHZ blockchain and the scalability and efficiency of the quantum hypergraph blockchain in the proposed quantum blockchain protocol.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding Blockchain Governance: Analyzing Decentralized Voting to Amend DeFi Smart Contracts</title>
<link>https://arxiv.org/abs/2305.17655</link>
<guid>https://arxiv.org/abs/2305.17655</guid>
<content:encoded><![CDATA[
arXiv:2305.17655v4 Announce Type: replace 
Abstract: Decentralized Autonomous Organizations (DAOs) have emerged as a novel governance mechanism in blockchain ecosystems, particularly within Decentralized Finance (DeFi). By enabling token holders to propose and vote on protocol changes, these systems promise transparent and equitable decision-making without centralized control. In this paper, we present an in-depth empirical study of the governance protocols of Compound and Uniswap, two of the most widely used DAOs in DeFi. Analyzing over 370 governance proposals and millions of on-chain events from their inception until August 2024, we uncover significant centralization of voting power: as few as 3--5 voters were sufficient to sway the majority of proposals. We also find that the cost of voting disproportionately burdens smaller token holders, and that strategic voting behaviors, such as delayed participation and coalition formation, further distort governance outcomes. Our findings suggest that despite their decentralized ideals, current DAO governance mechanisms fall short in practice.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>zkFL: Zero-Knowledge Proof-based Gradient Aggregation for Federated Learning</title>
<link>https://arxiv.org/abs/2310.02554</link>
<guid>https://arxiv.org/abs/2310.02554</guid>
<content:encoded><![CDATA[
arXiv:2310.02554v5 Announce Type: replace 
Abstract: Federated learning (FL) is a machine learning paradigm, which enables multiple and decentralized clients to collaboratively train a model under the orchestration of a central aggregator. FL can be a scalable machine learning solution in big data scenarios. Traditional FL relies on the trust assumption of the central aggregator, which forms cohorts of clients honestly. However, a malicious aggregator, in reality, could abandon and replace the client's training models, or insert fake clients, to manipulate the final training results. In this work, we introduce zkFL, which leverages zero-knowledge proofs to tackle the issue of a malicious aggregator during the training model aggregation process. To guarantee the correct aggregation results, the aggregator provides a proof per round, demonstrating to the clients that the aggregator executes the intended behavior faithfully. To further reduce the verification cost of clients, we use blockchain to handle the proof in a zero-knowledge way, where miners (i.e., the participants validating and maintaining the blockchain data) can verify the proof without knowing the clients' local and aggregated models. The theoretical analysis and empirical results show that zkFL achieves better security and privacy than traditional FL, without modifying the underlying FL network structure or heavily compromising the training speed.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Airdrops: Giving Money Away Is Harder Than It Seems</title>
<link>https://arxiv.org/abs/2312.02752</link>
<guid>https://arxiv.org/abs/2312.02752</guid>
<content:encoded><![CDATA[
arXiv:2312.02752v4 Announce Type: replace 
Abstract: Airdrops are a popular mechanism used by blockchain protocols to bootstrap communities, reward early adopters, and decentralize token distribution. Despite their widespread adoption, the effectiveness of airdrops in achieving long-term user engagement and ecosystem growth remains poorly understood. In this paper, we present the first comprehensive empirical study of nine major airdrops across Ethereum and Layer-2 ecosystems. Our analysis reveals that a substantial share of tokens--up to 66% in some cases--are rapidly sold, often in recipients' first post-claim transaction. We show that this behavior is largely driven by "airdrop farmers," who strategically optimize eligibility criteria to extract value without contributing meaningfully to the ecosystem. We complement our quantitative findings with a case study of the Arbitrum airdrop, illustrating how short-term activity spikes fail to translate into sustained user involvement. Based on these results, we discuss common design pitfalls--such as Sybil vulnerability, poor incentive alignment, and governance token misuse--and propose actionable guidelines for designing more effective airdrop strategies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts</title>
<link>https://arxiv.org/abs/2403.06838</link>
<guid>https://arxiv.org/abs/2403.06838</guid>
<content:encoded><![CDATA[
arXiv:2403.06838v3 Announce Type: replace 
Abstract: Smart contracts are susceptible to various security issues, among which access control (AC) vulnerabilities are particularly critical. While existing research has proposed multiple detection tools, the automatic and appropriate repair of AC vulnerabilities in smart contracts remains a challenge. Unlike commonly supported vulnerability types by existing repair tools, such as reentrancy, which are usually fixed by template-based approaches, the main obstacle of AC lies in identifying the appropriate roles or permissions amid a long list of non-AC-related source code to generate proper patch code, a task that demands human-level intelligence.
  Leveraging recent advancements in large language models (LLMs), we employ the state-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX. The key insight is that we can mine common AC practices for major categories of code functionality and use them to guide LLMs in fixing code with similar functionality. To this end, ACFIX involves both offline and online phases. First, during the offline phase, ACFIX mines a taxonomy of common Role-based Access Control (RBAC) practices from 344,251 on-chain contracts, categorizing 49 role-permission pairs from the top 1,000 pairs mined. Second, during the online phase, ACFIX tracks AC-related elements across the contract and uses this context information along with a Chain-of-Thought pipeline to guide LLMs in identifying the most appropriate role-permission pair for the subject contract and subsequently generating a suitable patch. This patch will then undergo a validity and effectiveness check. To evaluate ACFIX, we built the first benchmark dataset of 118 real-world AC vulnerabilities, and our evaluation revealed that ACFIX successfully repaired 94.92% of them. This represents a significant improvement compared to the baseline GPT-4, which achieved only 52.54%.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Joint Travel Route Optimization Framework for Platooning</title>
<link>https://arxiv.org/abs/2504.07623</link>
<guid>https://arxiv.org/abs/2504.07623</guid>
<content:encoded><![CDATA[
arXiv:2504.07623v2 Announce Type: replace 
Abstract: Platooning represents an advanced driving technology designed to assist drivers in traffic convoys of varying lengths, enhancing road safety, reducing driver fatigue, and improving fuel efficiency. Sophisticated automated driving assistance systems have facilitated this innovation. Recent advancements in platooning emphasize cooperative mechanisms within both centralized and decentralized architectures enabled by vehicular communication technologies. This study introduces a cooperative route planning optimization framework aimed at promoting the adoption of platooning through a centralized platoon formation strategy at the system level. This approach is envisioned as a transitional phase from individual (ego) driving to fully collaborative driving. Additionally, this research formulates and incorporates travel cost metrics related to fuel consumption, driver fatigue, and travel time, considering regulatory constraints on consecutive driving durations. The performance of these cost metrics has been evaluated using Dijkstra's and A* shortest path algorithms within a network graph framework. The results indicate that the proposed architecture achieves an average cost improvement of 14 % compared to individual route planning for long road trips.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Characterizing the Dynamics of Conspiracy Related German Telegram Conversations during COVID-19</title>
<link>https://arxiv.org/abs/2507.13398</link>
<guid>https://arxiv.org/abs/2507.13398</guid>
<content:encoded><![CDATA[
arXiv:2507.13398v1 Announce Type: new 
Abstract: Conspiracy theories have long drawn public attention, but their explosive growth on platforms like Telegram during the COVID-19 pandemic raises pressing questions about their impact on societal trust, democracy, and public health. We provide a geographical, temporal and network analysis of the structure of of conspiracy-related German-language Telegram chats in a novel large-scale data set. We examine how information flows between regional user groups and influential broadcasting channels, revealing the interplay between decentralized discussions and content spread driven by a small number of key actors.
  Our findings reveal that conspiracy-related activity spikes during major COVID-19-related events, correlating with societal stressors and mirroring prior research on how crises amplify conspiratorial beliefs. By analysing the interplay between regional, national and transnational chats, we uncover how information flows from larger national or transnational discourse to localised, community-driven discussions. Furthermore, we find that the top 10% of chats account for 94% of all forwarded content, portraying the large influence of a few actors in disseminating information. However, these chats operate independently, with minimal interconnection between each other, primarily forwarding messages to low-traffic groups. Notably, 43% of links shared in the data set point to untrustworthy sources as identified by NewsGuard, a proportion far exceeding their share on other platforms and in other discourse contexts, underscoring the role of conspiracy-related discussions on Telegram as vector for the spread of misinformation.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Stated Protocol: A Decentralized Framework for Digital Diplomacy</title>
<link>https://arxiv.org/abs/2507.13517</link>
<guid>https://arxiv.org/abs/2507.13517</guid>
<content:encoded><![CDATA[
arXiv:2507.13517v1 Announce Type: new 
Abstract: International coordination faces significant friction due to reliance on periodic summits, bilateral consultations, and fragmented communication channels that impede rapid collective responses to emerging global challenges while limiting transparency to constituents. We present the Stated Protocol, a decentralized framework that enables organizations to coordinate through standardized text statements published on their website domains. While applicable to all organizations, this work focuses primarily on the application in international relations, where the protocol enables rapid consensus discovery and collective decision-making without relying on centralized social media platforms. We explore specific applications: (1) faster treaty negotiation through incremental micro-agreements that can be signed digitally within hours rather than months, (2) continuous and transparent operation of international institutions through asynchronous decision-making, (3) coordinated signaling from local governments to national authorities through simultaneous statement publication, and (4) coalition formation among non-governmental organizations through transparent position aggregation.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software</title>
<link>https://arxiv.org/abs/2507.13555</link>
<guid>https://arxiv.org/abs/2507.13555</guid>
<content:encoded><![CDATA[
arXiv:2507.13555v1 Announce Type: new 
Abstract: The growing popularity and widespread use of software applications (apps) across various domains have driven rapid industry growth. Along with this growth, fast-paced market changes have led to constantly evolving software requirements. Such requirements are often grounded in feature requests and enhancement suggestions, typically provided by users in natural language (NL). However, these requests often suffer from defects such as ambiguity and incompleteness, making them challenging to interpret. Traditional validation methods (e.g., interviews and workshops) help clarify such defects but are impractical in decentralized environments like open-source software (OSS), where change requests originate from diverse users on platforms like GitHub. This paper proposes a novel approach leveraging Large Language Models (LLMs) to detect and refine NL defects in feature requests. Our approach automates the identification of ambiguous and incomplete requests and generates clarification questions (CQs) to enhance their usefulness for developers. To evaluate its effectiveness, we apply our method to real-world OSS feature requests and compare its performance against human annotations. In addition, we conduct interviews with GitHub developers to gain deeper insights into their perceptions of NL defects, the strategies they use to address these defects, and the impact of defects on downstream software engineering (SE) tasks.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques</title>
<link>https://arxiv.org/abs/2507.13629</link>
<guid>https://arxiv.org/abs/2507.13629</guid>
<content:encoded><![CDATA[
arXiv:2507.13629v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are transforming cybersecurity by enabling intelligent, adaptive, and automated approaches to threat detection, vulnerability assessment, and incident response. With their advanced language understanding and contextual reasoning, LLMs surpass traditional methods in tackling challenges across domains such as IoT, blockchain, and hardware security. This survey provides a comprehensive overview of LLM applications in cybersecurity, focusing on two core areas: (1) the integration of LLMs into key cybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along with mitigation strategies. By synthesizing recent advancements and identifying key limitations, this work offers practical insights and strategic recommendations for leveraging LLMs to build secure, scalable, and future-ready cyber defense systems.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones</title>
<link>https://arxiv.org/abs/2507.13647</link>
<guid>https://arxiv.org/abs/2507.13647</guid>
<content:encoded><![CDATA[
arXiv:2507.13647v1 Announce Type: new 
Abstract: Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic environments remains a key challenge due to high computational demands and the need for fast, adaptive responses. Traditional Particle Swarm Optimization (PSO) methods, while effective for offline planning, often struggle with premature convergence and latency in real-time scenarios. To overcome these limitations, we propose PE-PSO, an enhanced PSO-based online trajectory planner. The method introduces a persistent exploration mechanism to preserve swarm diversity and an entropy-based parameter adjustment strategy to dynamically adapt optimization behavior. UAV trajectories are modeled using B-spline curves, which ensure path smoothness while reducing optimization complexity. To extend this capability to UAV swarms, we develop a multi-agent framework that combines genetic algorithm (GA)-based task allocation with distributed PE-PSO, supporting scalable and coordinated trajectory generation. The distributed architecture allows for parallel computation and decentralized control, enabling effective cooperation among agents while maintaining real-time performance. Comprehensive simulations demonstrate that the proposed framework outperforms conventional PSO and other swarm-based planners across several metrics, including trajectory quality, energy efficiency, obstacle avoidance, and computation time. These results confirm the effectiveness and applicability of PE-PSO in real-time multi-UAV operations under complex environmental conditions.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantum Blockchain Survey: Foundations, Trends, and Gaps</title>
<link>https://arxiv.org/abs/2507.13720</link>
<guid>https://arxiv.org/abs/2507.13720</guid>
<content:encoded><![CDATA[
arXiv:2507.13720v1 Announce Type: new 
Abstract: Quantum computing poses fundamental risks to classical blockchain systems by undermining widely used cryptographic primitives. In response, two major research directions have emerged: post-quantum blockchains, which integrate quantum-resistant algorithms, and quantum blockchains, which leverage quantum properties such as entanglement and quantum key distribution. This survey reviews key developments in both areas, analyzing their cryptographic foundations, architectural designs, and implementation challenges. This work provides a comparative overview of technical proposals, highlight trade-offs in security, scalability, and deployment, and identify open research problems across hardware, consensus, and network design. The goal is to offer a structured and comprehensive reference for advancing secure blockchain systems in the quantum era.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resource-Splitting Games with Tullock-Based Lossy Contests</title>
<link>https://arxiv.org/abs/2507.13853</link>
<guid>https://arxiv.org/abs/2507.13853</guid>
<content:encoded><![CDATA[
arXiv:2507.13853v1 Announce Type: new 
Abstract: This paper introduces a novel class of multi-stage resource allocation games that model real-world scenarios in which profitability depends on the balance between supply and demand, and where higher resource investment leads to greater returns. Our proposed framework, which incorporates the notion of profit loss due to insufficient player participation, gives rise to a Tullock-like functional form of the stage payoff structure when weighted fair proportional resource allocation is applied. We explore both centralized and Nash equilibrium strategies, establish sufficient conditions for their existence and uniqueness, and provide an iterative, semi-decentralized method to compute the Nash equilibrium in games with arbitrarily many players. Additionally, we demonstrate that the framework generalizes instances of several existing models, including Receding Horizon and Blotto games, and present a semi-analytical method for computing the unique Nash equilibrium within the Blotto setup. Our findings are validated through a numerical case study in smart mobility, highlighting the practical relevance and applicability of the proposed model.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology</title>
<link>https://arxiv.org/abs/2507.13932</link>
<guid>https://arxiv.org/abs/2507.13932</guid>
<content:encoded><![CDATA[
arXiv:2507.13932v1 Announce Type: new 
Abstract: The rise of blockchain and Digital Ledger Technology (DLT) has gained wide traction. Instead of relying on a traditional centralized data authority, a blockchain system consists of digitally entangled block data shared across a distributed network. The specially designed chain data structure and its consensus mechanism protect blockchain data from being tampered by unauthorized adversaries. However, implementing a full-fledged blockchain system to protect a database can be technically cumbersome. In this work, we introduce an in-database design, named chain table, to protect data integrity without the need for a blockchain system. It features a succinct design without significant technology barriers or storage overhead. To realize rigorous data security, we also propose a set of data writing principles for the chain table. We prove that the chain table, together with the data writing principles, will guarantee flexible data integrity, named table-level data integrity (TDI).
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning</title>
<link>https://arxiv.org/abs/2507.13940</link>
<guid>https://arxiv.org/abs/2507.13940</guid>
<content:encoded><![CDATA[
arXiv:2507.13940v1 Announce Type: new 
Abstract: Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in robotics. Despite substantial advancements, existing methods often face a dilemma. Decentralized algorithms typically rely on predicting the behavior of other agents, sharing contracts, or maintaining communication for safety, while centralized approaches struggle with scalability and real-time decision-making. To address these challenges, we introduce Neural Hamilton-Jacobi Reachability Learning (HJR) for Decentralized Multi-Agent Motion Planning. Our method provides scalable neural HJR modeling to tackle high-dimensional configuration spaces and capture worst-case collision and safety constraints between agents. We further propose a decentralized trajectory optimization framework that incorporates the learned HJR solutions to solve MAMP tasks in real-time. We demonstrate that our method is both scalable and data-efficient, enabling the solution of MAMP problems in higher-dimensional scenarios with complex collision constraints. Our approach generalizes across various dynamical systems, including a 12-dimensional dual-arm setup, and outperforms a range of state-of-the-art techniques in successfully addressing challenging MAMP tasks. Video demonstrations are available at https://youtu.be/IZiePX0p1Mc.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2507.14007</link>
<guid>https://arxiv.org/abs/2507.14007</guid>
<content:encoded><![CDATA[
arXiv:2507.14007v1 Announce Type: new 
Abstract: The rapid integration of blockchain, cryptocurrency, and Web3 technologies into digital banks and fintech operations has created an integrated environment blending traditional financial systems with decentralised elements. This paper introduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed framework designed to address the risks in these ecosystems, such as oracle manipulation and cross-chain exploits. CNTMF represents a proposed extension of established methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN, and PASTA, while incorporating tailored components including Hybrid Layer Analysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an AI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents, CNTMF supports data-driven mitigation to reduce losses, which totalled approximately $2.47 billion in the first half of 2025 across 344 security events (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its phases guide asset mapping, risk profiling, prioritisation, mitigation, and iterative feedback. This supports security against evolving risks like state-sponsored attacks.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shipwright: Proving liveness of distributed systems with Byzantine participants</title>
<link>https://arxiv.org/abs/2507.14080</link>
<guid>https://arxiv.org/abs/2507.14080</guid>
<content:encoded><![CDATA[
arXiv:2507.14080v1 Announce Type: new 
Abstract: Ensuring liveness in a decentralized system, such as PBFT, is critical, because there may not be any single administrator that can restart the system if it encounters a liveness bug. At the same time, liveness is challenging to achieve because any single participant could be malicious, and yet the overall system must make forward progress. While verification is a promising approach for ensuring the absence of bugs, no prior work has been able to verify liveness for an executable implementation of PBFT.
  Shipwright is a verification framework for proving correctness and liveness of distributed systems where some participants might be malicious. Shipwright introduces three techniques that enable formal reasoning about decentralized settings with malicious participants, allow developers to decompose their system and proof in a modular fashion into sub-protocols and sub-proofs, and support sound reasoning about cryptographic signatures that may be embedded in messages. We used Shipwright to implement and verify an initial prototype of agreement on a single log entry in PBFT (with a few limitations) and translate it to an executable implementation in Go. We experimentally demonstrate its operation and liveness both in the common case and in several failure scenarios.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Consideration of Vanity Address Generation via Identity-Based Signatures</title>
<link>https://arxiv.org/abs/2507.12670</link>
<guid>https://arxiv.org/abs/2507.12670</guid>
<content:encoded><![CDATA[
arXiv:2507.12670v1 Announce Type: new 
Abstract: An address is indicated as an identifier of the user on the blockchain, and is defined by a hash value of the ECDSA verification key. A vanity address is an address that embeds custom characters such as a name. To generate a vanity address, a classical try-and-error method is employed, and thus the number of characters to be embedded is limited. In this paper, we focus on the functionality of identity-based signatures (IBS) where any strings can be employed as a verification key, and explore whether IBS can be used for generating a vanity address. We attach importance to the fact that it is not realistic to replace ECDSA with key recovery, which is currently employed for issuing transactions in Ethereum, to an IBS scheme. Even if this replacement is possible, it is not a reasonable price for the ease of the vanity address generation. Thus, we pay attention to a generic construction of IBS from signatures, and construct an IBS scheme from ECDSA with key recovery. Though we cannot directly generate a vanity address due to the key recovery functionality of the underlying ECDSA, we can connect any string with an address due to the functionality of IBS that can give additional meaning to the address. We implement our system by Solidity, and demonstrate that the gas cost is almost same as that of the ECDSA signature verification.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints</title>
<link>https://arxiv.org/abs/2507.12979</link>
<guid>https://arxiv.org/abs/2507.12979</guid>
<content:encoded><![CDATA[
arXiv:2507.12979v1 Announce Type: new 
Abstract: Federated Learning has gained increasing attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing their raw data. At the same time, Generative AI -- particularly Generative Adversarial Networks (GANs) -- have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices -- such as IoT devices and edge devices -- with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables the utilization of distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints -- ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experimental results shows that our approach demonstrates consistent and significant improvements across key performance metrics, where it achieves 1.1x -- 2.2x higher image generation scores, an average 10% boost in classification metrics (up to 50% in multi-domain non-IID settings), in much lower latency compared to several benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Measuring CEX-DEX Extracted Value and Searcher Profitability: The Darkest of the MEV Dark Forest</title>
<link>https://arxiv.org/abs/2507.13023</link>
<guid>https://arxiv.org/abs/2507.13023</guid>
<content:encoded><![CDATA[
arXiv:2507.13023v1 Announce Type: new 
Abstract: This paper provides a comprehensive empirical analysis of the economics and dynamics behind arbitrages between centralized and decentralized exchanges (CEX-DEX) on Ethereum. We refine heuristics to identify arbitrage transactions from on-chain data and introduce a robust empirical framework to estimate arbitrage revenue without knowing traders' actual behaviors on CEX. Leveraging an extensive dataset spanning 19 months from August 2023 to March 2025, we estimate a total of 233.8M USD extracted by 19 major CEX-DEX searchers from 7,203,560 identified CEX-DEX arbitrages. Our analysis reveals increasing centralization trends as three searchers captured three-quarters of both volume and extracted value. We also demonstrate that searchers' profitability is tied to their integration level with block builders and uncover exclusive searcher-builder relationships and their market impact. Finally, we correct the previously underestimated profitability of block builders who vertically integrate with a searcher. These insights illuminate the darkest corner of the MEV landscape and highlight the critical implications of CEX-DEX arbitrages for Ethereum's decentralization.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bidirectional Age of Incorrect Information: A Performance Metric for Status Updates in Virtual Dynamic Environments</title>
<link>https://arxiv.org/abs/2507.13312</link>
<guid>https://arxiv.org/abs/2507.13312</guid>
<content:encoded><![CDATA[
arXiv:2507.13312v1 Announce Type: new 
Abstract: Virtual dynamic environments (VDEs) such as the Metaverse and digital twins (DTs) require proper representation of the interacting entities to map their characteristics within the simulated or augmented space. Keeping these representations accurate and up-to-date is crucial for seamless interaction and system reliability. In this paper, we propose bidirectional age of incorrect information (BAoII) to address this aspect. BAoII quantifies the time-dependent penalty paid by an entity in a VDE due to incorrect or outdated knowledge about itself and the overall dynamically changing space. This extends the concept of age of incorrect information for a bidirectional information exchange, capturing that a VDE requires mutual awareness of the entity's own representation, measured in the virtual space, and what the other entities share about their representations. Using a continuous-time Markov chain model, we derive a closed-form expression for long-term BAoII and identify a transmission cost threshold for optimal update strategies. We describe a trade-off between communication cost and information freshness and validate our model through numerical simulations, demonstrating the impact of BAoII on evaluating system performance and highlighting its relevance for real-time collaboration in the Metaverse and DTs.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Crowdsensing Intrusion Detection Dataset For Decentralized Federated Learning Models</title>
<link>https://arxiv.org/abs/2507.13313</link>
<guid>https://arxiv.org/abs/2507.13313</guid>
<content:encoded><![CDATA[
arXiv:2507.13313v1 Announce Type: new 
Abstract: This paper introduces a dataset and experimental study for decentralized federated learning (DFL) applied to IoT crowdsensing malware detection. The dataset comprises behavioral records from benign and eight malware families. A total of 21,582,484 original records were collected from system calls, file system activities, resource usage, kernel events, input/output events, and network records. These records were aggregated into 30-second windows, resulting in 342,106 features used for model training and evaluation. Experiments on the DFL platform compare traditional machine learning (ML), centralized federated learning (CFL), and DFL across different node counts, topologies, and data distributions. Results show that DFL maintains competitive performance while preserving data locality, outperforming CFL in most settings. This dataset provides a solid foundation for studying the security of IoT crowdsensing environments.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise</title>
<link>https://arxiv.org/abs/2507.12492</link>
<guid>https://arxiv.org/abs/2507.12492</guid>
<content:encoded><![CDATA[
arXiv:2507.12492v1 Announce Type: cross 
Abstract: Quantum Federated Learning (QFL) is an emerging paradigm that combines quantum computing and federated learning (FL) to enable decentralized model training while maintaining data privacy over quantum networks. However, quantum noise remains a significant barrier in QFL, since modern quantum devices experience heterogeneous noise levels due to variances in hardware quality and sensitivity to quantum decoherence, resulting in inadequate training performance. To address this issue, we propose SpoQFL, a novel QFL framework that leverages sporadic learning to mitigate quantum noise heterogeneity in distributed quantum systems. SpoQFL dynamically adjusts training strategies based on noise fluctuations, enhancing model robustness, convergence stability, and overall learning efficiency. Extensive experiments on real-world datasets demonstrate that SpoQFL significantly outperforms conventional QFL approaches, achieving superior training performance and more stable convergence.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pulsar Consensus</title>
<link>https://arxiv.org/abs/2411.14245</link>
<guid>https://arxiv.org/abs/2411.14245</guid>
<content:encoded><![CDATA[
arXiv:2411.14245v2 Announce Type: replace 
Abstract: In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Policies for Dynamic Coalition Formation in Multi-Robot Task Allocation</title>
<link>https://arxiv.org/abs/2412.20397</link>
<guid>https://arxiv.org/abs/2412.20397</guid>
<content:encoded><![CDATA[
arXiv:2412.20397v3 Announce Type: replace 
Abstract: We propose a decentralized, learning-based framework for dynamic coalition formation in Multi-Robot Task Allocation (MRTA). Our approach extends MAPPO by integrating spatial action maps, robot motion planning, intention sharing, and task allocation revision to enable effective and adaptive coalition formation. Extensive simulation studies confirm the effectiveness of our model, enabling each robot to rely solely on local information to learn timely revisions of task selections and form coalitions with other robots to complete collaborative tasks. The results also highlight the proposed framework's ability to handle large robot populations and adapt to scenarios with diverse task sets.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The AI Shadow War: SaaS vs. Edge Computing Architectures</title>
<link>https://arxiv.org/abs/2507.11545</link>
<guid>https://arxiv.org/abs/2507.11545</guid>
<content:encoded><![CDATA[
arXiv:2507.11545v1 Announce Type: new 
Abstract: The very DNA of AI architecture presents conflicting paths: centralized cloud-based models (Software-as-a-Service) versus decentralized edge AI (local processing on consumer devices). This paper analyzes the competitive battleground across computational capability, energy efficiency, and data privacy. Recent breakthroughs show edge AI challenging cloud systems on performance, leveraging innovations like test-time training and mixture-of-experts architectures. Crucially, edge AI boasts a 10,000x efficiency advantage: modern ARM processors consume merely 100 microwatts forinference versus 1 watt for equivalent cloud processing. Beyond efficiency, edge AI secures data sovereignty by keeping processing local, dismantling single points of failure in centralized architectures. This democratizes access throughaffordable hardware, enables offline functionality, and reduces environmental impact by eliminating data transmission costs. The edge AI market projects explosive growth from $9 billion in 2025 to $49.6 billion by 2030 (38.5% CAGR), fueled by privacy demands and real-time analytics. Critical applications including personalized education, healthcare monitoring, autonomous transport, and smart infrastructure rely on edge AI's ultra-low latency (5-10ms versus 100-500ms for cloud). The convergence of architectural innovation with fundamental physics confirms edge AI's distributed approach aligns with efficient information processing, signaling the inevitable emergence of hybrid edge-cloud ecosystems.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2507.11649</link>
<guid>https://arxiv.org/abs/2507.11649</guid>
<content:encoded><![CDATA[
arXiv:2507.11649v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training on decentralized data without exposing raw data. However, the evaluation phase in FL may leak sensitive information through shared performance metrics. In this paper, we propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to enable privacy-preserving and verifiable evaluation for FL. Instead of revealing raw loss values, clients generate a succinct proof asserting that their local loss is below a predefined threshold. Our approach is implemented without reliance on external APIs, using self-contained modules for federated learning simulation, ZKP circuit design, and experimental evaluation on both the MNIST and Human Activity Recognition (HAR) datasets. We focus on a threshold-based proof for a simple Convolutional Neural Network (CNN) model (for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate the approach in terms of computational overhead, communication cost, and verifiability.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evasion Under Blockchain Sanctions</title>
<link>https://arxiv.org/abs/2507.11721</link>
<guid>https://arxiv.org/abs/2507.11721</guid>
<content:encoded><![CDATA[
arXiv:2507.11721v1 Announce Type: new 
Abstract: Sanctioning blockchain addresses has become a common regulatory response to malicious activities. However, enforcement on permissionless blockchains remains challenging due to complex transaction flows and sophisticated fund-obfuscation techniques. Using cryptocurrency mixing tool Tornado Cash as a case study, we quantitatively assess the effectiveness of U.S. Office of Foreign Assets Control (OFAC) sanctions over a 957-day period, covering 6.79 million Ethereum blocks and 1.07 billion transactions. Our analysis reveals that while OFAC sanctions reduced overall Tornado Cash deposit volume by 71.03% to approximately 2 billion USD, attackers still relied on Tornado Cash in 78.33% of Ethereum-related security incidents, underscoring persistent evasion strategies.
  We identify three structural limitations in current sanction enforcement practices: (i) the susceptibility of binary sanction classifications to dusting attacks; (ii) fragmented censorship by blockchain producers; and (iii) the complexity of obfuscation services exploited by users. To address these gaps, we introduce a more practical algorithm for scoring and tracking, grounded in quantitative impurity. On average, our algorithm processes Ethereum blocks within 0.07 $\pm$ 0.03 seconds and achieves 97.61% precision and 74.08% recall when evaluated on the Bybit exploit. Our findings contribute to ongoing discussions around regulatory effectiveness in Decentralized Finance by providing empirical evidence, clarifying enforcement challenges, and informing future compliance strategies in response to sanctions and blockchain-based security risks.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models</title>
<link>https://arxiv.org/abs/2507.11906</link>
<guid>https://arxiv.org/abs/2507.11906</guid>
<content:encoded><![CDATA[
arXiv:2507.11906v1 Announce Type: new 
Abstract: Collective human activities like using an Ouija board (or Kokkuri-san) often produce emergent, coherent linguistic outputs unintended by any single participant. While psychological explanations such as the ideomotor effect exist, a computational understanding of how decentralized, implicit linguistic knowledge fuses through shared physical interaction remains elusive. We introduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this phenomenon as collective Langevin dynamics sampling from implicitly fused language models. Each participant is represented as an agent associated with an energy landscape derived from an internal language model reflecting linguistic priors, and agents exert stochastic forces based on local energy gradients. We theoretically prove that the collective motion of the shared pointer (planchette) corresponds to Langevin MCMC sampling from the sum of individual energy landscapes, representing fused collective knowledge. Simulations validate that CoCre-Sam dynamics effectively fuse different models and generate meaningful character sequences, while ablation studies confirm the essential roles of collective interaction and stochasticity. Altogether, CoCre-Sam provides a novel computational mechanism linking individual implicit knowledge, embodied collective action, and emergent linguistic phenomena, grounding these complex interactions in the principles of probabilistic sampling.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation</title>
<link>https://arxiv.org/abs/2507.12084</link>
<guid>https://arxiv.org/abs/2507.12084</guid>
<content:encoded><![CDATA[
arXiv:2507.12084v1 Announce Type: new 
Abstract: Smart contracts play a pivotal role in blockchain ecosystems, and fuzzing remains an important approach to securing smart contracts. Even though mutation scheduling is a key factor influencing fuzzing effectiveness, existing fuzzers have primarily explored seed scheduling and generation, while mutation scheduling has been rarely addressed by prior work. In this work, we propose a Large Language Models (LLMs)-based Multi-feedback Smart Contract Fuzzing framework (LLAMA) that integrates LLMs, evolutionary mutation strategies, and hybrid testing techniques. Key components of the proposed LLAMA include: (i) a hierarchical prompting strategy that guides LLMs to generate semantically valid initial seeds, coupled with a lightweight pre-fuzzing phase to select high-potential inputs; (ii) a multi-feedback optimization mechanism that simultaneously improves seed generation, seed selection, and mutation scheduling by leveraging runtime coverage and dependency feedback; and (iii) an evolutionary fuzzing engine that dynamically adjusts mutation operator probabilities based on effectiveness, while incorporating symbolic execution to escape stagnation and uncover deeper vulnerabilities. Our experiments demonstrate that LLAMA outperforms state-of-the-art fuzzers in both coverage and vulnerability detection. Specifically, it achieves 91% instruction coverage and 90% branch coverage, while detecting 132 out of 148 known vulnerabilities across diverse categories. These results highlight LLAMA's effectiveness, adaptability, and practicality in real-world smart contract security testing scenarios.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties</title>
<link>https://arxiv.org/abs/2507.12174</link>
<guid>https://arxiv.org/abs/2507.12174</guid>
<content:encoded><![CDATA[
arXiv:2507.12174v1 Announce Type: new 
Abstract: Trajectory planning involving multi-agent interactions has been a long-standing challenge in the field of robotics, primarily burdened by the inherent yet intricate interactions among agents. While game-theoretic methods are widely acknowledged for their effectiveness in managing multi-agent interactions, significant impediments persist when it comes to accommodating the intentional uncertainties of agents. In the context of intentional uncertainties, the heavy computational burdens associated with existing game-theoretic methods are induced, leading to inefficiencies and poor scalability. In this paper, we propose a novel game-theoretic interactive trajectory planning method to effectively address the intentional uncertainties of agents, and it demonstrates both high efficiency and enhanced scalability. As the underpinning basis, we model the interactions between agents under intentional uncertainties as a general Bayesian game, and we show that its agent-form equivalence can be represented as a potential game under certain minor assumptions. The existence and attainability of the optimal interactive trajectories are illustrated, as the corresponding Bayesian Nash equilibrium can be attained by optimizing a unified optimization problem. Additionally, we present a distributed algorithm based on the dual consensus alternating direction method of multipliers (ADMM) tailored to the parallel solving of the problem, thereby significantly improving the scalability. The attendant outcomes from simulations and experiments demonstrate that the proposed method is effective across a range of scenarios characterized by general forms of intentional uncertainties. Its scalability surpasses that of existing centralized and decentralized baselines, allowing for real-time interactive trajectory planning in uncertain game settings.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Block Packing</title>
<link>https://arxiv.org/abs/2507.12357</link>
<guid>https://arxiv.org/abs/2507.12357</guid>
<content:encoded><![CDATA[
arXiv:2507.12357v1 Announce Type: new 
Abstract: We consider the algorithmic challenge that is faced by blockchains that have multidimensional block constraints and serve quasi-patient bidders. We provide online approximation algorithms for this problem, thus solving open problems left by [Babaioff and Nisan, EC 2025].
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning</title>
<link>https://arxiv.org/abs/2507.12439</link>
<guid>https://arxiv.org/abs/2507.12439</guid>
<content:encoded><![CDATA[
arXiv:2507.12439v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized clients while preserving data privacy. However, its open-participation nature exposes it to data-poisoning attacks, in which malicious actors submit corrupted model updates to degrade the global model. Existing defenses are often reactive, relying on statistical aggregation rules that can be computationally expensive and that typically assume an honest majority. This paper introduces a proactive, economic defense: a lightweight Bayesian incentive mechanism that makes malicious behavior economically irrational. Each training round is modeled as a Bayesian game of incomplete information in which the server, acting as the principal, uses a small, private validation dataset to verify update quality before issuing payments. The design satisfies Individual Rationality (IR) for benevolent clients, ensuring their participation is profitable, and Incentive Compatibility (IC), making poisoning an economically dominated strategy. Extensive experiments on non-IID partitions of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3 percentage points lower than in a scenario with 30% label-flipping adversaries. This outcome is 51.7 percentage points better than standard FedAvg, which collapses under the same 50% attack. The mechanism is computationally light, budget-bounded, and readily integrates into existing FL frameworks, offering a practical route to economically robust and sustainable FL ecosystems.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations</title>
<link>https://arxiv.org/abs/2507.12456</link>
<guid>https://arxiv.org/abs/2507.12456</guid>
<content:encoded><![CDATA[
arXiv:2507.12456v1 Announce Type: new 
Abstract: One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and Zhandry (STOC'20). These allow for signing exactly one message, after which the signing key self-destructs, preventing a second message from ever being signed. While such an object is impossible classically, Amos et al observe that OSS may be possible using quantum signing keys by leveraging the no-cloning principle. OSS has since become an important conceptual tool with many applications in decentralized settings and for quantum cryptography with classical communication. OSS are also closely related to separations between classical-binding and collapse-binding for post-quantum hashing and commitments. Unfortunately, the only known OSS construction due to Amos et al. was only justified in a classical oracle model, and moreover their justification was ultimately found to contain a fatal bug. Thus, the existence of OSS, even in a classical idealized model, has remained open.
  We give the first standard-model OSS, with provable security assuming (sub-exponential) indistinguishability obfuscation (iO) and LWE. This also gives the first standard-model separation between classical and collapse-binding post-quantum commitments/hashing, solving a decade-old open problem. Along the way, we also give the first construction with unconditional security relative to a classical oracle. To achieve our standard-model construction, we develop a notion of permutable pseudorandom permutations (permutable PRPs), and show how they are useful for translating oracle proofs involving random permutations into obfuscation-based proofs. In particular, obfuscating permutable PRPs gives a trapdoor one-way permutation that is \emph{full-domain}, solving another decade-old-problem of constructing this object from (sub-exponential) iO and one-way functions.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models</title>
<link>https://arxiv.org/abs/2403.09567</link>
<guid>https://arxiv.org/abs/2403.09567</guid>
<content:encoded><![CDATA[
arXiv:2403.09567v4 Announce Type: replace 
Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of generating natural language explanations by harnessing the capabilities of Large Language Models (LLMs) over the data contained within the previously mentioned black box. The study evaluates the performance of our solution in three different scenarios, each involving autonomous agent navigation functionalities. This evaluation includes a thorough examination of accountability and explainability metrics, demonstrating the effectiveness of our approach in using accountable data from robot actions to obtain coherent, accurate and understandable explanations, even when facing challenges inherent in the use of autonomous agents in real-world scenarios.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balancing Confidentiality and Transparency for Blockchain-based Process-Aware Information Systems</title>
<link>https://arxiv.org/abs/2412.05737</link>
<guid>https://arxiv.org/abs/2412.05737</guid>
<content:encoded><![CDATA[
arXiv:2412.05737v3 Announce Type: replace 
Abstract: Blockchain enables novel, trustworthy Process-Aware Information Systems (PAISs) by enforcing the security, robustness, and traceability of operations. In particular, transparency ensures that all information exchanges are openly accessible, fostering trust within the system. Although this is a desirable property to enable notarization and auditing activities, it also represents a limitation for such cases where confidentiality is a requirement since interactions involve sensitive data. Current solutions rely on obfuscation techniques or private infrastructures, hindering the enforcement capabilities of smart contracts and the public verifiability of transactions. Against this background, we propose CONFETTY, an architecture for blockchain-based PAISs to preserve confidentiality and transparency. Smart contracts enact, enforce and store public interactions, while attribute-based encryption techniques are adopted to specify access grants to confidential information. We assess the security of our solution through a systematic threat model analysis and evaluate its practical feasibility by gauging the performance of our implemented prototype in different scenarios from the literature.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Emergent Communication: Large Language Model is a Collective World Model</title>
<link>https://arxiv.org/abs/2501.00226</link>
<guid>https://arxiv.org/abs/2501.00226</guid>
<content:encoded><![CDATA[
arXiv:2501.00226v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated a remarkable ability to capture extensive world knowledge, yet how this is achieved without direct sensorimotor experience remains a fundamental puzzle. This study proposes a novel theoretical solution by introducing the Collective World Model hypothesis. We argue that an LLM does not learn a world model from scratch; instead, it learns a statistical approximation of a collective world model that is already implicitly encoded in human language through a society-wide process of embodied, interactive sense-making. To formalize this process, we introduce generative emergent communication (Generative EmCom), a framework built on the Collective Predictive Coding (CPC). This framework models the emergence of language as a process of decentralized Bayesian inference over the internal states of multiple agents. We argue that this process effectively creates an encoder-decoder structure at a societal scale: human society collectively encodes its grounded, internal representations into language, and an LLM subsequently decodes these symbols to reconstruct a latent space that mirrors the structure of the original collective representations. This perspective provides a principled, mathematical explanation for how LLMs acquire their capabilities. The main contributions of this paper are: 1) the formalization of the Generative EmCom framework, clarifying its connection to world models and multi-agent reinforcement learning, and 2) its application to interpret LLMs, explaining phenomena such as distributional semantics as a natural consequence of representation reconstruction. This work provides a unified theory that bridges individual cognitive development, collective language evolution, and the foundations of large-scale AI.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fediverse Sharing: Cross-Platform Interaction Dynamics between Threads and Mastodon Users</title>
<link>https://arxiv.org/abs/2502.17926</link>
<guid>https://arxiv.org/abs/2502.17926</guid>
<content:encoded><![CDATA[
arXiv:2502.17926v2 Announce Type: replace 
Abstract: Traditional social media platforms, once envisioned as digital town squares, now face growing criticism over corporate control, content moderation, and privacy concerns. Events such as Twitter's acquisition (now X) and major policy changes have pushed users toward alternative platforms like Mastodon and Threads. However, this diversification has led to user dispersion and fragmented discussions across the walled gardens of social media platforms. To address these issues, federation protocols like ActivityPub have been adopted, with Mastodon leading efforts to build decentralized yet interconnected networks. In March 2024, Threads joined this federation by introducing its Fediverse Sharing service, which enables interactions such as posts, replies, and likes between Threads and Mastodon users as if on a unified platform. Building on this development, we study the interactions between 20,000+ Threads users and 20,000+ Mastodon users over a ten-month period. Our work lays the foundation for research on cross-platform interactions and federation-driven platform integration.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents</title>
<link>https://arxiv.org/abs/2507.10644</link>
<guid>https://arxiv.org/abs/2507.10644</guid>
<content:encoded><![CDATA[
arXiv:2507.10644v1 Announce Type: new 
Abstract: The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block</title>
<link>https://arxiv.org/abs/2507.10757</link>
<guid>https://arxiv.org/abs/2507.10757</guid>
<content:encoded><![CDATA[
arXiv:2507.10757v1 Announce Type: new 
Abstract: Current blockchain execution throughput is limited by data contention, reducing execution layer parallelism. Fast Ahead-of-Formation Optimization (FAFO) is the first blockchain transaction scheduler to address this problem by reordering transactions before block formation for maximum concurrency. FAFO uses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts and schedule parallel transaction execution at high throughput and low overhead.
  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1 million native ETH transfers per second and over half a million ERC20 transfers per second on a single node (Table 1), with 91% lower cost compared to state-of-the-art sharded execution. Unlike many other existing high throughput blockchain execution clients, FAFO uses QMDB to Merkleize world state after every block, enabling light clients and stateless validation for ZK-based vApps. FAFO scales with minimal synchronization overhead, scaling linearly with additional CPU resources until it fully exploits the maximum parallelism of the underlying transaction flow. FAFO proves that the high throughput necessary to support future decentralized applications can be achieved with a streamlined execution layer and innovations in blockchain transaction scheduler design. FAFO is open-sourced at https://github.com/LayerZero-Labs/fafo.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data</title>
<link>https://arxiv.org/abs/2507.10927</link>
<guid>https://arxiv.org/abs/2507.10927</guid>
<content:encoded><![CDATA[
arXiv:2507.10927v1 Announce Type: new 
Abstract: Cloud storage introduces critical privacy challenges for encrypted data retrieval, where fuzzy multi-keyword search enables approximate matching while preserving data confidentiality. Existing solutions face fundamental trade-offs between security and efficiency: linear-search mechanisms provide adaptive security but incur prohibitive overhead for large-scale data, while tree-based indexes improve performance at the cost of branch leakage vulnerabilities.
  To address these limitations, we propose DVFS - a dynamic verifiable fuzzy search service with three core innovations: (1) An \textit{adaptive-secure fuzzy search} method integrating locality-sensitive hashing with virtual binary trees, eliminating branch leakage while reducing search complexity from linear to sublinear ($O(\log n)$ time); (2) A \textit{dual-repository version control} mechanism supporting dynamic updates with forward privacy, preventing information leakage during operations; (3) A \textit{blockchain-based verification system} that ensures correctness and completeness via smart contracts, achieving $O(\log n)$ verification complexity.
  Our solution advances secure encrypted retrieval by simultaneously resolving the security-performance paradox and enabling trustworthy dynamic operations.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self++: Merging Human and AI for Co-Determined XR Living in the Metaverse</title>
<link>https://arxiv.org/abs/2507.10967</link>
<guid>https://arxiv.org/abs/2507.10967</guid>
<content:encoded><![CDATA[
arXiv:2507.10967v1 Announce Type: new 
Abstract: This position paper introduces Self++, a novel nine-level framework for co-determined living in the Metaverse, grounded in Self-Determination Theory. Self++ prioritises human flourishing by progressively cultivating competence, autonomy, and relatedness through dynamic human-AI collaboration in extended reality (XR). Unlike technologically deterministic approaches, Self++ emphasises user empowerment by enhancing competency, mitigating cognitive biases and leveraging XR's immersive capabilities. Key research directions proposed include exploring the boundaries of user-defined AI autonomy, designing for meaningful social connection in XR, and establishing proactive ethical safeguards. Ultimately, Self++ offers a roadmap for creating a human-centred, AI-enhanced Metaverse where technology amplifies, rather than diminishes, human potential.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Agent Architecture for Decentralized Trading of Alternative Assets</title>
<link>https://arxiv.org/abs/2507.11117</link>
<guid>https://arxiv.org/abs/2507.11117</guid>
<content:encoded><![CDATA[
arXiv:2507.11117v1 Announce Type: new 
Abstract: Decentralized trading of real-world alternative assets (e.g., gold) requires bridging physical asset custody with blockchain systems while meeting strict requirements for compliance, liquidity, and risk management. We present GoldMine OS, a research oriented architecture that employs multiple specialized AI agents to automate and secure the tokenization and exchange of physical gold into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart contracts for critical risk controls with off chain AI agents for decision making, blending the transparency and reliability of blockchains with the flexibility of AI driven automation. We describe four cooperative agents (Compliance, Token Issuance, Market Making, and Risk Control) and a coordinating core, and evaluate the system through simulation and a controlled pilot deployment. In experiments the prototype delivers on demand token issuance in under 1.2 s, more than 100 times faster than manual workflows. The Market Making agent maintains tight liquidity with spreads often below 0.5 percent even under volatile conditions. Fault injection tests show resilience: an oracle price spoofing attack is detected and mitigated within 10 s, and a simulated vault mis reporting halts issuance immediately with minimal user impact. The architecture scales to 5000 transactions per second with 10000 concurrent users in benchmarks. These results indicate that an AI agent based decentralized exchange for alternative assets can satisfy rigorous performance and safety requirements. We discuss broader implications for democratizing access to traditionally illiquid assets and explain how our governance model -- multi signature agent updates and on chain community voting on risk parameters -- provides ongoing transparency, adaptability, and formal assurance of system integrity.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications</title>
<link>https://arxiv.org/abs/2507.11183</link>
<guid>https://arxiv.org/abs/2507.11183</guid>
<content:encoded><![CDATA[
arXiv:2507.11183v1 Announce Type: new 
Abstract: Federated learning is a machine learning approach that enables multiple devices (i.e., agents) to train a shared model cooperatively without exchanging raw data. This technique keeps data localized on user devices, ensuring privacy and security, while each agent trains the model on their own data and only shares model updates. The communication overhead is a significant challenge due to the frequent exchange of model updates between the agents and the central server. In this paper, we propose a communication-efficient federated learning scheme that utilizes low-rank approximation of neural network gradients and quantization to significantly reduce the network load of the decentralized learning process with minimal impact on the model's accuracy.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning</title>
<link>https://arxiv.org/abs/2507.11430</link>
<guid>https://arxiv.org/abs/2507.11430</guid>
<content:encoded><![CDATA[
arXiv:2507.11430v1 Announce Type: new 
Abstract: Federated Learning (FL) has undergone significant development since its inception in 2016, advancing from basic algorithms to complex methodologies tailored to address diverse challenges and use cases. However, research and benchmarking of novel FL techniques against a plethora of established state-of-the-art solutions remain challenging. To streamline this process, we introduce FLsim, a comprehensive FL simulation framework designed to meet the diverse requirements of FL workflows in the literature. FLsim is characterized by its modularity, scalability, resource efficiency, and controlled reproducibility of experimental outcomes. Its easy to use interface allows users to specify customized FL requirements through job configuration, which supports: (a) customized data distributions, ranging from non-independent and identically distributed (non-iid) data to independent and identically distributed (iid) data, (b) selection of local learning algorithms according to user preferences, with complete agnosticism to ML libraries, (c) choice of network topology illustrating communication patterns among nodes, (d) definition of model aggregation and consensus algorithms, and (e) pluggable blockchain support for enhanced robustness. Through a series of experimental evaluations, we demonstrate the effectiveness and versatility of FLsim in simulating a diverse range of state-of-the-art FL experiments. We envisage that FLsim would mark a significant advancement in FL simulation frameworks, offering unprecedented flexibility and functionality for researchers and practitioners alike.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Immutability Does Not Guarantee Trust: A Formal and Logical Refutation</title>
<link>https://arxiv.org/abs/2507.08844</link>
<guid>https://arxiv.org/abs/2507.08844</guid>
<content:encoded><![CDATA[
arXiv:2507.08844v1 Announce Type: new 
Abstract: It is frequently claimed in blockchain discourse that immutability guarantees trust. This paper rigorously refutes that assertion. We define immutability as the cryptographic persistence of historical states in an append-only data structure and contrast it with trust, understood as a rational epistemic expectation under uncertainty. Employing predicate logic, automata-theoretic models, and epistemic game-theoretic analysis, we demonstrate that immutability neither entails nor implies correctness, fairness, or credibility. Through formal constructions and counterexamples--including predictive fraud schemes and the phenomenon of garbage permanence--we show that the belief conflates structural and epistemic domains. Immutability preserves all data equally, regardless of veracity. Therefore, the assertion that immutability guarantees trust collapses under the weight of formal scrutiny.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Clio-X: AWeb3 Solution for Privacy-Preserving AI Access to Digital Archives</title>
<link>https://arxiv.org/abs/2507.08853</link>
<guid>https://arxiv.org/abs/2507.08853</guid>
<content:encoded><![CDATA[
arXiv:2507.08853v1 Announce Type: new 
Abstract: As archives turn to artificial intelligence to manage growing volumes of digital records, privacy risks inherent in current AI data practices raise critical concerns about data sovereignty and ethical accountability. This paper explores how privacy-enhancing technologies (PETs) and Web3 architectures can support archives to preserve control over sensitive content while still being able to make it available for access by researchers. We present Clio-X, a decentralized, privacy-first Web3 digital solution designed to embed PETs into archival workflows and support AI-enabled reference and access. Drawing on a user evaluation of a medium-fidelity prototype, the study reveals both interest in the potential of the solution and significant barriers to adoption related to trust, system opacity, economic concerns, and governance. Using Rogers' Diffusion of Innovation theory, we analyze the sociotechnical dimensions of these barriers and propose a path forward centered on participatory design and decentralized governance through a Clio-X Decentralized Autonomous Organization. By integrating technical safeguards with community-based oversight, Clio-X offers a novel model to ethically deploy AI in cultural heritage contexts.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System</title>
<link>https://arxiv.org/abs/2507.09179</link>
<guid>https://arxiv.org/abs/2507.09179</guid>
<content:encoded><![CDATA[
arXiv:2507.09179v1 Announce Type: new 
Abstract: Decentralized finance (DeFi) has introduced a new era of permissionless financial innovation but also led to unprecedented market manipulation. Without centralized oversight, malicious actors coordinate shilling campaigns and pump-and-dump schemes across various platforms. We propose a Multi-Agent Reinforcement Learning (MARL) framework for decentralized manipulation detection, modeling the interaction between manipulators and detectors as a dynamic adversarial game. This framework identifies suspicious patterns using delayed token price reactions as financial indicators.Our method introduces three innovations: (1) Group Relative Policy Optimization (GRPO) to enhance learning stability in sparse-reward and partially observable settings; (2) a theory-based reward function inspired by rational expectations and information asymmetry, differentiating price discovery from manipulation noise; and (3) a multi-modal agent pipeline that integrates LLM-based semantic features, social graph signals, and on-chain market data for informed decision-making.The framework is integrated within the Symphony system, a decentralized multi-agent architecture enabling peer-to-peer agent execution and trust-aware learning through distributed logs, supporting chain-verifiable evaluation. Symphony promotes adversarial co-evolution among strategic actors and maintains robust manipulation detection without centralized oracles, enabling real-time surveillance across global DeFi ecosystems.Trained on 100,000 real-world discourse episodes and validated in adversarial simulations, Hide-and-Shill achieves top performance in detection accuracy and causal attribution. This work bridges multi-agent systems with financial surveillance, advancing a new paradigm for decentralized market intelligence. All resources are available at the Hide-and-Shill GitHub repository to promote open research and reproducibility.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Confidential Wrapped Ethereum</title>
<link>https://arxiv.org/abs/2507.09231</link>
<guid>https://arxiv.org/abs/2507.09231</guid>
<content:encoded><![CDATA[
arXiv:2507.09231v1 Announce Type: new 
Abstract: Transparency is one of the key benefits of public blockchains. However, the public visibility of transactions potentially compromises users' privacy. The fundamental challenge is to balance the intrinsic benefits of blockchain openness with the vital need for individual confidentiality. The proposal suggests creating a confidential version of wrapped Ethereum (cWETH) fully within the application layer. The solution combines the Elliptic Curve (EC) Twisted ElGamal-based commitment scheme to preserve confidentiality and the EC Diffie-Hellman (DH) protocol to introduce accessibility limited by the commitment scheme. To enforce the correct generation of commitments, encryption, and decryption, zk-SNARKs are utilized.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartphoneDemocracy: Privacy-Preserving E-Voting on Decentralized Infrastructure using Novel European Identity</title>
<link>https://arxiv.org/abs/2507.09453</link>
<guid>https://arxiv.org/abs/2507.09453</guid>
<content:encoded><![CDATA[
arXiv:2507.09453v1 Announce Type: new 
Abstract: The digitization of democratic processes promises greater accessibility but presents challenges in terms of security, privacy, and verifiability. Existing electronic voting systems often rely on centralized architectures, creating single points of failure and forcing too much trust in authorities, which contradicts democratic principles. This research addresses the challenge of creating a secure, private e-voting system with minimized trust dependencies designed for the most versatile personal device: the smartphone. We introduce SmartphoneDemocracy, a novel e-voting protocol that combines three key technologies: the emerging European Digital Identity (EUDI) Wallet for Sybil-resistant identity verification, Zero-Knowledge Proofs for privacy-preserving validation, and a peer-to-peer blockchain (TrustChain) for a resilient, serverless public bulletin board. Our protocol enables voters to register and cast ballots anonymously and verifiably directly from their smartphones. We provide a detailed protocol design, a security analysis against a defined threat model, and a performance evaluation demonstrating that the computational and network overhead is feasible for medium- to large-scale elections. By developing and prototyping this system, we demonstrate a viable path to empower citizens with a trustworthy, accessible, and user-controlled digital voting experience.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PromptChain: A Decentralized Web3 Architecture for Managing AI Prompts as Digital Assets</title>
<link>https://arxiv.org/abs/2507.09579</link>
<guid>https://arxiv.org/abs/2507.09579</guid>
<content:encoded><![CDATA[
arXiv:2507.09579v1 Announce Type: new 
Abstract: We present PromptChain, a decentralized Web3 architecture that establishes AI prompts as first-class digital assets with verifiable ownership, version control, and monetization capabilities. Current centralized platforms lack mechanisms for proper attribution, quality assurance, or fair compensation for prompt creators. PromptChain addresses these limitations through a novel integration of IPFS for immutable storage, smart contracts for governance, and token incentives for community curation. Our design includes: (1) a comprehensive metadata schema for cross-model compatibility, (2) a stake-weighted validation mechanism to align incentives, and (3) a token economy that rewards contributors proportionally to their impact. The proposed architecture demonstrates how decentralized systems could potentially match centralized alternatives in efficiency while providing superior ownership guarantees and censorship resistance through blockchain-anchored provenance tracking. By decoupling prompts from specific AI models or outputs, this work establishes the foundation for an open ecosystem of human-AI collaboration in the Web3 era, representing the first systematic treatment of prompts as standalone digital assets with dedicated decentralized infrastructure.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Endorsement-Driven Blockchain SSI Framework for Dynamic IoT Ecosystems</title>
<link>https://arxiv.org/abs/2507.09859</link>
<guid>https://arxiv.org/abs/2507.09859</guid>
<content:encoded><![CDATA[
arXiv:2507.09859v1 Announce Type: new 
Abstract: Self-Sovereign Identity (SSI) offers significant potential for managing identities in the Internet of Things (IoT), enabling decentralized authentication and credential management without reliance on centralized entities. However, existing SSI frameworks often limit credential issuance and revocation to trusted entities, such as IoT manufacturers, which restricts flexibility in dynamic IoT ecosystems. In this paper, we propose a blockchain-based SSI framework that allows any individual with a verifiable trust linkage to act as a credential issuer, ensuring decentralized and scalable identity management. Our framework incorporates a layered architecture, where trust is dynamically established through endorsement-based calculations and maintained via a hierarchical chain-of-trust mechanism. Blockchain serves as the Verifiable Data Registry, ensuring transparency and immutability of identity operations, while smart contracts automate critical processes such as credential issuance, verification, and revocation. A proof-of-concept implementation demonstrates that the proposed framework is feasible and incurs minimal overheads compared to the baseline, making it well-suited for dynamic and resource-constrained IoT environments.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A New Incentive Model For Content Trust</title>
<link>https://arxiv.org/abs/2507.09972</link>
<guid>https://arxiv.org/abs/2507.09972</guid>
<content:encoded><![CDATA[
arXiv:2507.09972v1 Announce Type: new 
Abstract: This paper outlines an incentive-driven and decentralized approach to verifying the veracity of digital content at scale. Widespread misinformation, an explosion in AI-generated content and reduced reliance on traditional news sources demands a new approach for content authenticity and truth-seeking that is fit for a modern, digital world. By using smart contracts and digital identity to incorporate 'trust' into the reward function for published content, not just engagement, we believe that it could be possible to foster a self-propelling paradigm shift to combat misinformation through a community-based governance model. The approach described in this paper requires that content creators stake financial collateral on factual claims for an impartial jury to vet with a financial reward for contribution. We hypothesize that with the right financial and social incentive model users will be motivated to participate in crowdsourced fact-checking and content creators will place more care in their attestations. This is an exploratory paper and there are a number of open issues and questions that warrant further analysis and exploration.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2507.10149</link>
<guid>https://arxiv.org/abs/2507.10149</guid>
<content:encoded><![CDATA[
arXiv:2507.10149v1 Announce Type: new 
Abstract: We propose a mathematically rigorous framework for identifying and completing Coincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators. Unlike existing auction based systems such as CoWSwap, our approach introduces an asset matrix formulation that not only verifies feasibility using oracle prices and formal conservation laws but also completes partial CoW cycles of swap orders that are discovered using graph traversal and are settled using imbalance correction. We define bridging orders and show that the resulting execution is slippage free and capital preserving for LPs. Applied to real world Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW cycles and supports the insertion of synthetic orders for atomic cycle closure. This work can be thought of as the detailing of a potential delta-neutral strategy by liquidity providing market makers: a structured CoW cycle execution.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation</title>
<link>https://arxiv.org/abs/2507.10160</link>
<guid>https://arxiv.org/abs/2507.10160</guid>
<content:encoded><![CDATA[
arXiv:2507.10160v1 Announce Type: new 
Abstract: Federated Learning has emerged as a leading paradigm for decentralized, privacy-preserving learning, particularly relevant in the era of interconnected edge devices equipped with sensors. However, the practical implementation of Federated Learning faces three primary challenges: the need for human involvement in costly data labelling processes for target adaptation, covariate shift in client device data collection due to environmental factors affecting sensors, leading to discrepancies between source and target samples, and the impracticality of continuous or regular model updates in resource-constrained environments due to limited data transmission capabilities and technical constraints on channel availability and energy efficiency. To tackle these issues, we expand upon an efficient and scalable Federated Learning framework tailored for real-world client adaptation in industrial settings. This framework leverages a pre-trained source model comprising a deep backbone, an adaptation module, and a classifier running on a powerful server. By freezing the backbone and classifier during client adaptation on resource-constrained devices, we allow the domain adaptive linear layer to handle target domain adaptation, thus minimizing overall computational overhead. Furthermore, this setup, designated as FedAcross+, is extended to encompass the processing of streaming data, thereby rendering the solution suitable for non-stationary environments. Extensive experimental results demonstrate the effectiveness of FedAcross+ in achieving competitive adaptation on low-end client devices with limited target samples, successfully addressing the challenge of domain shift. Moreover, our framework accommodates sporadic model updates within resource-constrained environments, ensuring practical and seamless deployment.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Robot Cooperative Herding through Backstepping Control Barrier Functions</title>
<link>https://arxiv.org/abs/2507.10249</link>
<guid>https://arxiv.org/abs/2507.10249</guid>
<content:encoded><![CDATA[
arXiv:2507.10249v1 Announce Type: new 
Abstract: We propose a novel cooperative herding strategy through backstepping control barrier functions (CBFs), which coordinates multiple herders to herd a group of evaders safely towards a designated goal region. For the herding system with heterogeneous groups involving herders and evaders, the behavior of the evaders can only be influenced indirectly by the herders' motion, especially when the evaders follow an inverse dynamics model and respond solely to repulsive interactions from the herders. This indirect interaction mechanism inherently renders the overall system underactuated. To address this issue, we first construct separate CBFs for the dual objectives of goal reaching and collision avoidance, which ensure both herding completion and safety guarantees. Then, we reformulate the underactuated herding dynamics into a control-affine structure and employ a backstepping approach to recursively design control inputs for the hierarchical barrier functions, avoiding taking derivatives of the higher-order system. Finally, we present a cooperative herding strategy based on backstepping CBFs that allow herders to safely herd multiple evaders into the goal region. In addition, centralized and decentralized implementations of the proposed algorithm are developed, further enhancing its flexibility and applicability. Extensive simulations and real-world experiments validate the effectiveness and safety of the proposed strategy in multi-robot herding.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Convergence of Agnostic Federated Averaging</title>
<link>https://arxiv.org/abs/2507.10325</link>
<guid>https://arxiv.org/abs/2507.10325</guid>
<content:encoded><![CDATA[
arXiv:2507.10325v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized model training without centralizing raw data. However, practical FL deployments often face a key realistic challenge: Clients participate intermittently in server aggregation and with unknown, possibly biased participation probabilities. Most existing convergence results either assume full-device participation, or rely on knowledge of (in fact uniform) client availability distributions -- assumptions that rarely hold in practice. In this work, we characterize the optimization problem that consistently adheres to the stochastic dynamics of the well-known \emph{agnostic Federated Averaging (FedAvg)} algorithm under random (and variably-sized) client availability, and rigorously establish its convergence for convex, possibly nonsmooth losses, achieving a standard rate of order $\mathcal{O}(1/\sqrt{T})$, where $T$ denotes the aggregation horizon. Our analysis provides the first convergence guarantees for agnostic FedAvg under general, non-uniform, stochastic client participation, without knowledge of the participation distribution. We also empirically demonstrate that agnostic FedAvg in fact outperforms common (and suboptimal) weighted aggregation FedAvg variants, even with server-side knowledge of participation weights.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoDe: A Cooperative and Decentralized Collision Avoidance Algorithm for Small-Scale UAV Swarms Considering Energy Efficiency</title>
<link>https://arxiv.org/abs/2204.08594</link>
<guid>https://arxiv.org/abs/2204.08594</guid>
<content:encoded><![CDATA[
arXiv:2204.08594v2 Announce Type: replace 
Abstract: This paper introduces a cooperative and decentralized collision avoidance algorithm (CoDe) for small-scale UAV swarms consisting of up to three UAVs. CoDe improves energy efficiency of UAVs by achieving effective cooperation among UAVs. Moreover, CoDe is specifically tailored for UAV's operations by addressing the challenges faced by existing schemes, such as ineffectiveness in selecting actions from continuous action spaces and high computational complexity. CoDe is based on Multi-Agent Reinforcement Learning (MARL), and finds cooperative policies by incorporating a novel credit assignment scheme. The novel credit assignment scheme estimates the contribution of an individual by subtracting a baseline from the joint action value for the swarm. The credit assignment scheme in CoDe outperforms other benchmarks as the baseline takes into account not only the importance of a UAV's action but also the interrelation between UAVs. Furthermore, extensive experiments are conducted against existing MARL-based and conventional heuristic-based algorithms to demonstrate the advantages of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Decentralized Multi-Biped Control for Payload Transport</title>
<link>https://arxiv.org/abs/2406.17279</link>
<guid>https://arxiv.org/abs/2406.17279</guid>
<content:encoded><![CDATA[
arXiv:2406.17279v2 Announce Type: replace 
Abstract: Payload transport over flat terrain via multi-wheel robot carriers is well-understood, highly effective, and configurable. In this paper, our goal is to provide similar effectiveness and configurability for transport over rough terrain that is more suitable for legs rather than wheels. For this purpose, we consider multi-biped robot carriers, where wheels are replaced by multiple bipedal robots attached to the carrier. Our main contribution is to design a decentralized controller for such systems that can be effectively applied to varying numbers and configurations of rigidly attached bipedal robots without retraining. We present a reinforcement learning approach for training the controller in simulation that supports transfer to the real world. Our experiments in simulation provide quantitative metrics showing the effectiveness of the approach over a wide variety of simulated transport scenarios. In addition, we demonstrate the controller in the real-world for systems composed of two and three Cassie robots. To our knowledge, this is the first example of a scalable multi-biped payload transport system.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Integrated Blockchain and IPFS Solution for Secure and Efficient Source Code Repository Hosting using Middleman Approach</title>
<link>https://arxiv.org/abs/2409.14530</link>
<guid>https://arxiv.org/abs/2409.14530</guid>
<content:encoded><![CDATA[
arXiv:2409.14530v2 Announce Type: replace 
Abstract: Centralized version control systems (VCS) are vital for software development but pose risks of data loss and ownership disputes. While blockchain offers a decentralized alternative, existing solutions are often hindered by high latency, compromising the real-time collaboration essential for modern workflows. This study introduces a novel hybrid architecture combining the security of the Ethereum blockchain and the InterPlanetary File System (IPFS) with two key contributions: 1) Shamir's Secret Sharing (SSS) to create a trust-minimized model for key distribution, and 2) an authoritative-first, optimistic-fallback retrieval protocol utilizing a temporary middleware to decouple the user experience from blockchain confirmation delays. We implemented a full prototype and conducted a comprehensive performance evaluation on the public Sepolia testnet. Our results demonstrate that this architecture not only provides a secure, auditable, and resilient platform for source code hosting but also achieves highly competitive user-perceived performance. Our user-perceived push time reduces submission latency by up to 49% compared to a standard git push for common repository sizes, proving that a well-designed decentralized VCS can balance the core tenets of security and decentralization with the practical need for speed and efficiency.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm</title>
<link>https://arxiv.org/abs/2507.08249</link>
<guid>https://arxiv.org/abs/2507.08249</guid>
<content:encoded><![CDATA[
arXiv:2507.08249v1 Announce Type: new 
Abstract: There is growing interest in giving AI agents access to cryptocurrencies as well as to the smart contracts that transact them. But doing so, this position paper argues, could lead to formidable new vectors of AI harm. To support this argument, we first examine the unique properties of cryptocurrencies and smart contracts that could lead to these new vectors of harm. Next, we describe each of these new vectors of harm in detail. Finally, we conclude with a call for more technical research aimed at preventing and mitigating these harms and, thereby making it safer to endow AI agents with cryptocurrencies and smart contracts.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TruChain: A Multi-Layer Architecture for Trusted, Verifiable, and Immutable Open Banking Data</title>
<link>https://arxiv.org/abs/2507.08286</link>
<guid>https://arxiv.org/abs/2507.08286</guid>
<content:encoded><![CDATA[
arXiv:2507.08286v1 Announce Type: new 
Abstract: Open banking framework enables third party providers to access financial data across banking institutions, leading to unprecedented innovations in the financial sector. However, some open banking standards remain susceptible to severe technological risks, including unverified data sources, inconsistent data integrity, and lack of immutability. In this paper, we propose a layered architecture that provides assurance in data trustworthiness with three distinct levels of trust, covering source validation, data-level authentication, and tamper-proof storage. The first layer guarantees the source legitimacy using decentralized identity and verifiable presentation, while the second layer verifies data authenticity and consistency using cryptographic signing. Lastly, the third layer guarantees data immutability through the Tangle, a directed acyclic graph distributed ledger. We implemented a proof-of-concept implementation of our solution to evaluate its performance, where the results demonstrate that the system scales linearly with a stable throughput, exhibits a 100% validation rate, and utilizes under 35% of CPU and 350 MiB memory. Compared to a real-world open banking implementation, our solution offers significantly reduced latency and stronger data integrity assurance. Overall, our solution offers a practical and efficient system for secure data sharing in financial ecosystems while maintaining regulatory compliance.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method</title>
<link>https://arxiv.org/abs/2507.08429</link>
<guid>https://arxiv.org/abs/2507.08429</guid>
<content:encoded><![CDATA[
arXiv:2507.08429v1 Announce Type: new 
Abstract: The integration of unmanned aerial vehicles (UAVs) with Internet of Things (IoT) networks offers promising solutions for efficient data collection. However, the limited energy capacity of UAVs remains a significant challenge. In this case, laser beam directors (LBDs) have emerged as an effective technology for wireless charging of UAVs during operation, thereby enabling sustained data collection without frequent returns to charging stations (CSs). In this work, we investigate the age of information (AoI) optimization in LBD-powered UAV-assisted IoT networks, where multiple UAVs collect data from distributed IoTs while being recharged by laser beams. We formulate a joint optimization problem that aims to minimize the peak AoI while determining optimal UAV trajectories and laser charging strategies. This problem is particularly challenging due to its non-convex nature, complex temporal dependencies, and the need to balance data collection efficiency with energy consumption constraints. To address these challenges, we propose a novel multi-agent proximal policy optimization with temporal memory and multi-agent coordination (MAPPO-TM) framework. Specifically, MAPPO-TM incorporates temporal memory mechanisms to capture the dynamic nature of UAV operations and facilitates effective coordination among multiple UAVs through decentralized learning while considering global system objectives. Simulation results demonstrate that the proposed MAPPO-TM algorithm outperforms conventional approaches in terms of peak AoI minimization and energy efficiency. Ideally, the proposed algorithm achieves up to 15.1% reduction in peak AoI compared to conventional multi-agent deep reinforcement learning (MADRL) methods.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning</title>
<link>https://arxiv.org/abs/2507.07258</link>
<guid>https://arxiv.org/abs/2507.07258</guid>
<content:encoded><![CDATA[
arXiv:2507.07258v1 Announce Type: new 
Abstract: As IoT ecosystems continue to expand across critical sectors, they have become prominent targets for increasingly sophisticated and large-scale malware attacks. The evolving threat landscape, combined with the sensitive nature of IoT-generated data, demands detection frameworks that are both privacy-preserving and resilient to data heterogeneity. Federated Learning (FL) offers a promising solution by enabling decentralized model training without exposing raw data. However, standard FL algorithms such as FedAvg and FedProx often fall short in real-world deployments characterized by class imbalance and non-IID data distributions -- particularly in the presence of rare or disjoint malware classes. To address these challenges, we propose FedP3E (Privacy-Preserving Prototype Exchange), a novel FL framework that supports indirect cross-client representation sharing while maintaining data privacy. Each client constructs class-wise prototypes using Gaussian Mixture Models (GMMs), perturbs them with Gaussian noise, and transmits only these compact summaries to the server. The aggregated prototypes are then distributed back to clients and integrated into local training, supported by SMOTE-based augmentation to enhance representation of minority malware classes. Rather than relying solely on parameter averaging, our prototype-driven mechanism enables clients to enrich their local models with complementary structural patterns observed across the federation -- without exchanging raw data or gradients. This targeted strategy reduces the adverse impact of statistical heterogeneity with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset under realistic cross-silo scenarios with varying degrees of data imbalance.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AdeptHEQ-FL: Adaptive Homomorphic Encryption for Federated Learning of Hybrid Classical-Quantum Models with Dynamic Layer Sparing</title>
<link>https://arxiv.org/abs/2507.07316</link>
<guid>https://arxiv.org/abs/2507.07316</guid>
<content:encoded><![CDATA[
arXiv:2507.07316v1 Announce Type: new 
Abstract: Federated Learning (FL) faces inherent challenges in balancing model performance, privacy preservation, and communication efficiency, especially in non-IID decentralized environments. Recent approaches either sacrifice formal privacy guarantees, incur high overheads, or overlook quantum-enhanced expressivity. We introduce AdeptHEQ-FL, a unified hybrid classical-quantum FL framework that integrates (i) a hybrid CNN-PQC architecture for expressive decentralized learning, (ii) an adaptive accuracy-weighted aggregation scheme leveraging differentially private validation accuracies, (iii) selective homomorphic encryption (HE) for secure aggregation of sensitive model layers, and (iv) dynamic layer-wise adaptive freezing to minimize communication overhead while preserving quantum adaptability. We establish formal privacy guarantees, provide convergence analysis, and conduct extensive experiments on the CIFAR-10, SVHN, and Fashion-MNIST datasets. AdeptHEQ-FL achieves a $\approx 25.43\%$ and $\approx 14.17\%$ accuracy improvement over Standard-FedQNN and FHE-FedQNN, respectively, on the CIFAR-10 dataset. Additionally, it reduces communication overhead by freezing less important layers, demonstrating the efficiency and practicality of our privacy-preserving, resource-aware design for FL.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments</title>
<link>https://arxiv.org/abs/2507.07376</link>
<guid>https://arxiv.org/abs/2507.07376</guid>
<content:encoded><![CDATA[
arXiv:2507.07376v1 Announce Type: new 
Abstract: Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HLF-FSL. A Decentralized Federated Split Learning Solution for IoT on Hyperledger Fabric</title>
<link>https://arxiv.org/abs/2507.07637</link>
<guid>https://arxiv.org/abs/2507.07637</guid>
<content:encoded><![CDATA[
arXiv:2507.07637v1 Announce Type: new 
Abstract: Collaborative machine learning in sensitive domains demands scalable, privacy preserving solutions for enterprise deployment. Conventional Federated Learning (FL) relies on a central server, introducing single points of failure and privacy risks, while Split Learning (SL) partitions models for privacy but scales poorly due to sequential training. We present a decentralized architecture that combines Federated Split Learning (FSL) with the permissioned blockchain Hyperledger Fabric (HLF). Our chaincode orchestrates FSL's split model execution and peer-to-peer aggregation without any central coordinator, leveraging HLF's transient fields and Private Data Collections (PDCs) to keep raw data and model activations private. On CIFAR-10 and MNIST benchmarks, HLF-FSL matches centralized FSL accuracy while reducing per epoch training time compared to Ethereum-based works. Performance and scalability tests show minimal blockchain overhead and preserved accuracy, demonstrating enterprise grade viability.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web</title>
<link>https://arxiv.org/abs/2507.07901</link>
<guid>https://arxiv.org/abs/2507.07901</guid>
<content:encoded><![CDATA[
arXiv:2507.07901v1 Announce Type: new 
Abstract: The fragmentation of AI agent ecosystems has created urgent demands for interoperability, trust, and economic coordination that current protocols -- including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al., 2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present the Nanda Unified Architecture, a decentralized framework built around three core innovations: fast DID-based agent discovery through distributed registries, semantic agent cards with verifiable credentials and composability profiles, and a dynamic trust layer that integrates behavioral attestations with policy compliance. The system introduces X42/H42 micropayments for economic coordination and MAESTRO, a security framework incorporating Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure containerization. Real-world deployments demonstrate 99.9 percent compliance in healthcare applications and substantial monthly transaction volumes with strong privacy guarantees. By unifying MIT's trust research with production deployments from Cisco and Synergetics, we show how cryptographic proofs and policy-as-code transform agents into trust-anchored participants in a decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a globally interoperable Internet of Agents where trust becomes the native currency of collaboration across both enterprise and Web3 ecosystems.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Service Architecture for Dataspaces</title>
<link>https://arxiv.org/abs/2507.07979</link>
<guid>https://arxiv.org/abs/2507.07979</guid>
<content:encoded><![CDATA[
arXiv:2507.07979v1 Announce Type: new 
Abstract: Dataspaces are designed to support sovereign, trusted and decentralized data exchange between participants forming an ecosystem. They are standardized by initiatives such as the International Data Spaces Association or Gaia-X and have gained adoption in several domains such as mobility, manufacturing, tourism or culture. In dataspaces, participants use connectors to communicate peer-to-peer. The Eclipse Dataspace Components (EDC) Connector is a broadly adopted, open-source implementation that adheres to the standards and is supported by a large community. As dataspaces in general, it focuses on the exchange of data assets with associated usage policies and does not support services. In practice, however, there is demand for dataspace-based services and conceptual arguments support their inclusion in dataspaces. In this paper, we propose an abstraction layer for providing generic services within dataspaces. Adopters can use this layer to easily develop own services, seamlessly integrated with the existing dataspace technology. Besides, we present an initial implementation of this service architecture for the EDC Connector and demonstrate its practical applicability.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Centralization vs. decentralization in multi-robot sweep coverage with ground robots and UAVs</title>
<link>https://arxiv.org/abs/2408.06553</link>
<guid>https://arxiv.org/abs/2408.06553</guid>
<content:encoded><![CDATA[
arXiv:2408.06553v3 Announce Type: replace 
Abstract: In swarm robotics, decentralized control is often proposed as a more scalable and fault-tolerant alternative to centralized control. However, centralized behaviors are often faster and more efficient than their decentralized counterparts. In any given application, the goals and constraints of the task being solved should guide the choice to use centralized control, decentralized control, or a combination of the two. Currently, the exact trade-offs that exist between centralization and decentralization are not well defined. In this paper, we study comparative performance assessment between centralization and decentralization in the example task of sweep coverage, across five different types of multi-robot control structures: random walk, decentralized with beacons, hybrid formation control using self-organizing hierarchy, centralized formation control, and predetermined. In all five approaches, the coverage task is completed by a group of ground robots. In each approach, except for the random walk, the ground robots are assisted by UAVs, acting as supervisors or beacons. We compare the approaches in terms of three performance metrics for which centralized approaches are expected to have an advantage -- coverage completeness, coverage uniformity, and sweep completion time -- and two metrics for which decentralized approaches are expected to have an advantage -- scalability (4, 8, or 16 ground robots) and fault tolerance (0%, 25%, 50%, or 75% ground robot failure).
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research on Data Right Confirmation Mechanism of Federated Learning based on Blockchain</title>
<link>https://arxiv.org/abs/2409.08476</link>
<guid>https://arxiv.org/abs/2409.08476</guid>
<content:encoded><![CDATA[
arXiv:2409.08476v2 Announce Type: replace 
Abstract: Federated learning can solve the privacy protection problem in distributed data mining and machine learning, and how to protect the ownership, use and income rights of all parties involved in federated learning is an important issue. This paper proposes a federated learning data ownership confirmation mechanism based on blockchain and smart contract, which uses decentralized blockchain technology to save the contribution of each participant on the blockchain, and distributes the benefits of federated learning results through the blockchain. In the local simulation environment of the blockchain, the relevant smart contracts and data structures are simulated and implemented, and the feasibility of the scheme is preliminarily demonstrated.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wallets as Universal Access Devices</title>
<link>https://arxiv.org/abs/2507.06254</link>
<guid>https://arxiv.org/abs/2507.06254</guid>
<content:encoded><![CDATA[
arXiv:2507.06254v1 Announce Type: new 
Abstract: Wallets are access points for the digital economys value creation. Wallets for blockchains store the end-users cryptographic keys for administrating their digital assets and enable access to blockchain Web3 systems. Web3 delivers new service opportunities. This chapter focuses on the Web3 enabled release of value through the lens of wallets. Wallets may be implemented as software apps on smartphones, web apps on desktops, or hardware devices. Wallet users request high security, ease of use, and access of relevance from their wallets. Increasing connectivity, functionality, autonomy, personal support, and offline capability make the wallet into the user's Universal Access Device for any digital asset. Through wallet based services, the owner obtains enhanced digital empowerment. The new Web3 solutionareas, Identity and Decentralisation, enable considerable societal effects, and wallets are an integral part of these. One example is self sovereign identity solutions combined with wallet borne AI for personalised support, empowering the enduser beyond anything previously known. Improved welfare is foreseen globally through enlarged markets with collaborative services with drastically lowered transaction costs compared to today, the expected vastly increased levels of automation in society necessitate enhanced enduser protection. As wallets are considered a weak spot for security, improving overall security through blockchains is essential.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rugsafe: A multichain protocol for recovering from and defending against Rug Pulls</title>
<link>https://arxiv.org/abs/2507.06423</link>
<guid>https://arxiv.org/abs/2507.06423</guid>
<content:encoded><![CDATA[
arXiv:2507.06423v1 Announce Type: new 
Abstract: Rugsafe introduces a comprehensive protocol aimed at mitigating the risks of rug pulls in the cryptocurrency ecosystem. By utilizing cryptographic security measures and economic incentives, the protocol provides a secure multichain system for recovering assets and transforming rugged tokens into opportunities and rewards. Foundational to Rugsafe are specialized vaults where rugged tokens can be securely deposited, and anticoin tokens are issued as receipts. These anticoins are designed to be inversely pegged to the price movement of the underlying rugged token. Users can utilize these anticoins within the ecosystem or choose to burn them, further securing the protocol and earning additional rewards. The supply of the native Rugsafe token is dynamically adjusted based on the volume, value, and activity of rugged tokens, ensuring stability and resilience. By depositing rugged tokens into a vault on several chains, and by burning anticoins, users receive incentives on the RugSafe chain. This protocol's vaults are designed to work in heterogenous blockchain ecosystems, offering a practical and effective solution to one of the most significant challenges in the cryptocurrency market.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning</title>
<link>https://arxiv.org/abs/2507.06542</link>
<guid>https://arxiv.org/abs/2507.06542</guid>
<content:encoded><![CDATA[
arXiv:2507.06542v1 Announce Type: new 
Abstract: Decentralized learning provides a scalable alternative to traditional parameter-server-based training, yet its performance is often hindered by limited peer-to-peer communication. In this paper, we study how communication should be scheduled over time, including determining when and how frequently devices synchronize. Our empirical results show that concentrating communication budgets in the later stages of decentralized training markedly improves global generalization. Surprisingly, we uncover that fully connected communication at the final step, implemented by a single global merging, is sufficient to match the performance of server-based training. We further show that low communication in decentralized learning preserves the \textit{mergeability} of local models throughout training. Our theoretical contributions, which explains these phenomena, are first to establish that the globally merged model of decentralized SGD can converge faster than centralized mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy among local models, which were previously considered as detrimental noise, as constructive components that accelerate convergence. This work challenges the common belief that decentralized learning generalizes poorly under data heterogeneity and limited communication, while offering new insights into model merging and neural network loss landscapes.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordinated Fast Frequency Regulation in Dynamic Virtual Power Plants via Disturbance Estimation</title>
<link>https://arxiv.org/abs/2507.06713</link>
<guid>https://arxiv.org/abs/2507.06713</guid>
<content:encoded><![CDATA[
arXiv:2507.06713v1 Announce Type: new 
Abstract: In the context of dynamic virtual power plants (DVPPs), the integration of frequency containment reserve (FCR) and fast frequency control (FFC) enabled via local compensation of power imbalance represents a significant advancement in decentralized frequency regulation. However, they still have to cope with the limited power and energy capacities associated with commonly available storage solutions. This work combines a disturbance estimation based decentralized local control with distributed imbalance compensation in the event of local shortfall. The layered architecture facilitates fast local corrections in power setpoints while enabling coordination between neighbouring DVPP nodes to leverage the aggregated capacity, ensuring scalable and efficient operation suitable for renewable-heavy future grids. The proposed approach is validated on an illustrative 4-bus system with a high percentage of renewables.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views</title>
<link>https://arxiv.org/abs/2507.06763</link>
<guid>https://arxiv.org/abs/2507.06763</guid>
<content:encoded><![CDATA[
arXiv:2507.06763v1 Announce Type: new 
Abstract: The framework is designed to improve performance in the analysis of combined as well as single anatomical perspectives for MRI disease diagnosis. It specifically addresses the performance degradation observed in state-of-the-art (SOTA) models, particularly when processing axial, coronal, and sagittal anatomical planes. The paper introduces the FOLC-Net framework, which incorporates a novel federated-optimized lightweight architecture with approximately 1.217 million parameters and a storage requirement of only 0.9 MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for efficient model structure generation, global model cloning for scalable training, and ConvNeXt for enhanced client adaptability. The model was evaluated on combined multi-view data as well as individual views, such as axial, coronal, and sagittal, to assess its robustness in various medical imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different data to evaluate its ability to generalize beyond the training dataset. The results show that FOLC-Net outperforms existing models, particularly in the challenging sagittal view. For instance, FOLC-Net achieved an accuracy of 92.44% on the sagittal view, significantly higher than the 88.37% accuracy of study method (DL + Residual Learning) and 88.95% of DL models. Additionally, FOLC-Net demonstrated improved accuracy across all individual views, providing a more reliable and robust solution for medical image analysis in decentralized environments. FOLC-Net addresses the limitations of existing SOTA models by providing a framework that ensures better adaptability to individual views while maintaining strong performance in multi-view settings. The incorporation of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs better in real-world medical applications.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Are NFTs Ready to Keep Australian Artists Engaged?</title>
<link>https://arxiv.org/abs/2507.06926</link>
<guid>https://arxiv.org/abs/2507.06926</guid>
<content:encoded><![CDATA[
arXiv:2507.06926v1 Announce Type: new 
Abstract: Non-Fungible Tokens (NFTs) offer a promising mechanism to protect Australian and Indigenous artists' copyright. They represent and transfer the value of artwork in digital form. Before adopting NFTs to protect Australian artwork, we in this paper investigate them empericially. We focus on examining the details of NFT structure. We start from the underlying structure of NFTs to show how they represent copyright for both artists and production owners, as well as how they aim to safeguard or secure the value of digital artworks. We then involve data collection from various types of sources with different storage methods, including on-chain, centralized, and decentralized systems. Based on both metadata and artwork content, we present our analysis and discussion on the following key issues: copyright, security and artist identification. The final results of the evaluation, unfortnately, show that the NFT is NOT ready to protect Australian and Indigenous artists' copyright.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DICE: Data Influence Cascade in Decentralized Learning</title>
<link>https://arxiv.org/abs/2507.06931</link>
<guid>https://arxiv.org/abs/2507.06931</guid>
<content:encoded><![CDATA[
arXiv:2507.06931v1 Announce Type: new 
Abstract: Decentralized learning offers a promising approach to crowdsource data consumptions and computational workloads across geographically distributed compute interconnected through peer-to-peer networks, accommodating the exponentially increasing demands. However, proper incentives are still in absence, considerably discouraging participation. Our vision is that a fair incentive mechanism relies on fair attribution of contributions to participating nodes, which faces non-trivial challenges arising from the localized connections making influence ``cascade'' in a decentralized network. To overcome this, we design the first method to estimate \textbf{D}ata \textbf{I}nfluence \textbf{C}ascad\textbf{E} (DICE) in a decentralized environment. Theoretically, the framework derives tractable approximations of influence cascade over arbitrary neighbor hops, suggesting the influence cascade is determined by an interplay of data, communication topology, and the curvature of loss landscape. DICE also lays the foundations for applications including selecting suitable collaborators and identifying malicious behaviors. Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive collaboration for online personalized distributed learning with heterogeneous clients</title>
<link>https://arxiv.org/abs/2507.06844</link>
<guid>https://arxiv.org/abs/2507.06844</guid>
<content:encoded><![CDATA[
arXiv:2507.06844v1 Announce Type: cross 
Abstract: We study the problem of online personalized decentralized learning with $N$ statistically heterogeneous clients collaborating to accelerate local training. An important challenge in this setting is to select relevant collaborators to reduce gradient variance while mitigating the introduced bias. To tackle this, we introduce a gradient-based collaboration criterion, allowing each client to dynamically select peers with similar gradients during the optimization process. Our criterion is motivated by a refined and more general theoretical analysis of the All-for-one algorithm, proved to be optimal in Even et al. (2022) for an oracle collaboration scheme. We derive excess loss upper-bounds for smooth objective functions, being either strongly convex, non-convex, or satisfying the Polyak-Lojasiewicz condition; our analysis reveals that the algorithm acts as a variance reduction method where the speed-up depends on a sufficient variance. We put forward two collaboration methods instantiating the proposed general schema; and we show that one variant preserves the optimality of All-for-one. We validate our results with experiments on synthetic and real datasets.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain Solution for Collaborative Machine Learning over IoT</title>
<link>https://arxiv.org/abs/2311.14136</link>
<guid>https://arxiv.org/abs/2311.14136</guid>
<content:encoded><![CDATA[
arXiv:2311.14136v2 Announce Type: replace 
Abstract: The rapid growth of Internet of Things (IoT) devices and applications has led to an increased demand for advanced analytics and machine learning techniques capable of handling the challenges associated with data privacy, security, and scalability. Federated learning (FL) and blockchain technologies have emerged as promising approaches to address these challenges by enabling decentralized, secure, and privacy-preserving model training on distributed data sources. In this paper, we present a novel IoT solution that combines the incremental learning vector quantization algorithm (XuILVQ) with Ethereum blockchain technology to facilitate secure and efficient data sharing, model training, and prototype storage in a distributed environment. Our proposed architecture addresses the shortcomings of existing blockchain-based FL solutions by reducing computational and communication overheads while maintaining data privacy and security. We assess the performance of our system through a series of experiments, showcasing its potential to enhance the accuracy and efficiency of machine learning tasks in IoT settings.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-objective methods in Federated Learning: A survey and taxonomy</title>
<link>https://arxiv.org/abs/2502.03108</link>
<guid>https://arxiv.org/abs/2502.03108</guid>
<content:encoded><![CDATA[
arXiv:2502.03108v2 Announce Type: replace 
Abstract: The Federated Learning paradigm facilitates effective distributed machine learning in settings where training data is decentralized across multiple clients. As the popularity of the strategy grows, increasingly complex real-world problems emerge, many of which require balancing conflicting demands such as fairness, utility, and resource consumption. Recent works have begun to recognise the use of a multi-objective perspective in answer to this challenge. However, this novel approach of combining federated methods with multi-objective optimisation has never been discussed in the broader context of both fields. In this work, we offer a first clear and systematic overview of the different ways the two fields can be integrated. We propose a first taxonomy on the use of multi-objective methods in connection with Federated Learning, providing a targeted survey of the state-of-the-art and proposing unambiguous labels to categorise contributions. Given the developing nature of this field, our taxonomy is designed to provide a solid basis for further research, capturing existing works while anticipating future additions. Finally, we outline open challenges and possible directions for further research.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models</title>
<link>https://arxiv.org/abs/2507.05394</link>
<guid>https://arxiv.org/abs/2507.05394</guid>
<content:encoded><![CDATA[
arXiv:2507.05394v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) like CLIP have demonstrated remarkable generalization in zero- and few-shot settings, but adapting them efficiently to decentralized, heterogeneous data remains a challenge. While prompt tuning has emerged as a popular parameter-efficient approach in personalized federated learning, existing methods often sacrifice generalization in favor of personalization, struggling particularly on unseen classes or domains. In this work, we propose pFedMMA, the first personalized federated learning framework that leverages multi-modal adapters for vision-language tasks. Each adapter contains modality-specific up- and down-projection layers alongside a globally shared projection that aligns cross-modal features. Our asymmetric optimization strategy allows clients to locally adapt to personalized data distributions while collaboratively training the shared projection to improve global generalization. This design is also communication-efficient, as only the shared component is exchanged during rounds. Through extensive experiments across eleven datasets, including domain- and label-shift scenarios, we show that pFedMMA achieves state-of-the-art trade-offs between personalization and generalization, outperforming recent federated prompt tuning methods. The code is available at https://github.com/sajjad-ucsb/pFedMMA.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Agent Smart Contract Exploit Generation</title>
<link>https://arxiv.org/abs/2507.05558</link>
<guid>https://arxiv.org/abs/2507.05558</guid>
<content:encoded><![CDATA[
arXiv:2507.05558v1 Announce Type: new 
Abstract: We present A1, an agentic execution driven system that transforms any LLM into an end-to-end exploit generator. A1 has no hand-crafted heuristics and provides the agent with six domain-specific tools that enable autonomous vulnerability discovery. The agent can flexibly leverage these tools to understand smart contract behavior, generate exploit strategies, test them on blockchain states, and refine approaches based on execution feedback. All outputs are concretely validated to eliminate false positives.
  The evaluation across 36 real-world vulnerable contracts on Ethereum and Binance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the VERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional vulnerable contracts, with 5 cases occurring after the strongest model's training cutoff date. Across all 26 successful cases, A1 extracts up to 8.59 million USD per case and 9.33 million USD total. Through 432 experiments across six LLMs, we analyze iteration-wise performance showing diminishing returns with average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations 2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo analysis of 19 historical attacks shows success probabilities of 85.9%-88.8% without detection delays.
  We investigate whether an attacker or a defender benefits most from deploying A1 as a continuous on-chain scanning system. Our model shows that OpenAI's o3-pro maintains profitability up to a 30.0 days scanning delay at 0.100% vulnerability incidence rates, while faster models require >=1.000% rates to break-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability rates, attackers achieve an on-chain scanning profitability at a $6000 exploit value, while defenders require $60000, raising fundamental questions about whether AI agents inevitably favor exploitation over defense.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Training of Large-Scale AI Models Through Federated Mixture-of-Experts: A System-Level Approach</title>
<link>https://arxiv.org/abs/2507.05685</link>
<guid>https://arxiv.org/abs/2507.05685</guid>
<content:encoded><![CDATA[
arXiv:2507.05685v1 Announce Type: new 
Abstract: The integration of Federated Learning (FL) and Mixture-of-Experts (MoE) presents a compelling pathway for training more powerful, large-scale artificial intelligence models (LAMs) on decentralized data while preserving privacy. However, efficient federated training of these complex MoE-structured LAMs is hindered by significant system-level challenges, particularly in managing the interplay between heterogeneous client resources and the sophisticated coordination required for numerous specialized experts. This article highlights a critical, yet underexplored concept: the absence of robust quantitative strategies for dynamic client-expert alignment that holistically considers varying client capacities and the imperative for system-wise load balancing. Specifically, we propose a conceptual system design for intelligent client-expert alignment that incorporates dynamic fitness scoring, global expert load monitoring, and client capacity profiling. By tackling these systemic issues, we can unlock more scalable, efficient, and robust training mechanisms {with fewer communication rounds for convergence}, paving the way for the widespread deployment of large-scale federated MoE-structured LAMs in edge computing with ultra-high communication efficiency.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Formal Refutation of the Blockchain Trilemma</title>
<link>https://arxiv.org/abs/2507.05809</link>
<guid>https://arxiv.org/abs/2507.05809</guid>
<content:encoded><![CDATA[
arXiv:2507.05809v1 Announce Type: new 
Abstract: The so-called blockchain trilemma asserts the impossibility of simultaneously achieving scalability, security, and decentralisation within a single blockchain protocol. In this paper, we formally refute that proposition. Employing predicate logic, formal automata theory, computational complexity analysis, and graph-theoretic measures of relay topology--specifically Baran's model of network path redundancy--we demonstrate that the trilemma constitutes a category error, conflates distinct analytical domains, and relies upon unproven causal assumptions. We further expose its reliance on composition fallacies drawn from flawed system implementations. A constructive counterexample is presented: a blockchain protocol exhibiting unbounded transaction throughput, cryptographic security under adversarial load, and multipath decentralised propagation. This example is not hypothetical but grounded in protocol design enabled by compact block relay, SPV verification, and IPv6 multicast. The trilemma is revealed not as a law of protocol architecture, but as a heuristic fallacy sustained by imprecision and design defeatism.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Module-Wise Federated Learning for Grasp Pose Detection in Cluttered Environments</title>
<link>https://arxiv.org/abs/2507.05861</link>
<guid>https://arxiv.org/abs/2507.05861</guid>
<content:encoded><![CDATA[
arXiv:2507.05861v1 Announce Type: new 
Abstract: Grasp pose detection (GPD) is a fundamental capability for robotic autonomy, but its reliance on large, diverse datasets creates significant data privacy and centralization challenges. Federated Learning (FL) offers a privacy-preserving solution, but its application to GPD is hindered by the substantial communication overhead of large models, a key issue for resource-constrained robots. To address this, we propose a novel module-wise FL framework that begins by analyzing the learning dynamics of the GPD model's functional components. This analysis identifies slower-converging modules, to which our framework then allocates additional communication effort. This is realized through a two-phase process: a standard full-model training phase is followed by a communication-efficient phase where only the identified subset of slower-converging modules is trained and their partial updates are aggregated. Extensive experiments on the GraspNet-1B dataset demonstrate that our method outperforms standard FedAvg and other baselines, achieving higher accuracy for a given communication budget. Furthermore, real-world experiments on a physical robot validate our approach, showing a superior grasp success rate compared to baseline methods in cluttered scenes. Our work presents a communication-efficient framework for training robust, generalized GPD models in a decentralized manner, effectively improving the trade-off between communication cost and model performance.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Programmable Governance for Group-Controlled Decentralized Identifiers</title>
<link>https://arxiv.org/abs/2507.06001</link>
<guid>https://arxiv.org/abs/2507.06001</guid>
<content:encoded><![CDATA[
arXiv:2507.06001v1 Announce Type: new 
Abstract: Self-Sovereign Identity (SSI) is a paradigm for digital identity management that offers unique privacy advantages. A key technology in SSI is Decentralized Identifiers (DIDs) and their associated metadata, DID Documents (DDOs). DDOs contain crucial verification material such as the public keys of the entity identified by the DID (i.e., the DID subject) and are often anchored on a distributed ledger to ensure security and availability. Long-lived DIDs need to support updates (e.g., key rotation). Ideally, only the DID subject should authorize DDO updates. However, in practice, update capabilities may be shared or delegated. While the DID specification acknowledges such scenarios, it does not define how updates should be authorized when multiple entities jointly control a DID (i.e., group control). This article examines the implementation of an on-chain, trustless mechanism enabling DID controllers under group control to program their governance rules. The main research question is the following: Can a technical mechanism be developed to orchestrate on-chain group control of a DDO in a ledger-agnostic and adaptable manner?
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wrapless: The trustless lending protocol on top of Bitcoin</title>
<link>https://arxiv.org/abs/2507.06064</link>
<guid>https://arxiv.org/abs/2507.06064</guid>
<content:encoded><![CDATA[
arXiv:2507.06064v1 Announce Type: new 
Abstract: This paper presents Wrapless -- a lending protocol that enables the collateralization of bitcoins without requiring a trusted wrapping mechanism. The protocol facilitates a "loan channel" on the Bitcoin blockchain, allowing bitcoins to be locked as collateral for loans issued on any blockchain that supports Turing-complete smart contracts. The protocol is designed in a way that makes it economically irrational for each involved party to manipulate the loan rules. There is still a significant research area to bring the protocol closer to traditional AMM financial instruments.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hedge Funds on a Swamp: Analyzing Patterns, Vulnerabilities, and Defense Measures in Blockchain Bridges [Experiment, Analysis \&amp; Benchmark]</title>
<link>https://arxiv.org/abs/2507.06156</link>
<guid>https://arxiv.org/abs/2507.06156</guid>
<content:encoded><![CDATA[
arXiv:2507.06156v1 Announce Type: new 
Abstract: Blockchain bridges have become essential infrastructure for enabling interoperability across different blockchain networks, with more than $24B monthly bridge transaction volume. However, their growing adoption has been accompanied by a disproportionate rise in security breaches, making them the single largest source of financial loss in Web3. For cross-chain ecosystems to be robust and sustainable, it is essential to understand and address these vulnerabilities. In this study, we present a comprehensive systematization of blockchain bridge design and security. We define three bridge security priors, formalize the architectural structure of 13 prominent bridges, and identify 23 attack vectors grounded in real-world blockchain exploits. Using this foundation, we evaluate 43 representative attack scenarios and introduce a layered threat model that captures security failures across source chain, off-chain, and destination chain components.
  Our analysis at the static code and transaction network levels reveals recurring design flaws, particularly in access control, validator trust assumptions, and verification logic, and identifies key patterns in adversarial behavior based on transaction-level traces. To support future development, we propose a decision framework for bridge architecture design, along with defense mechanisms such as layered validation and circuit breakers. This work provides a data-driven foundation for evaluating bridge security and lays the groundwork for standardizing resilient cross-chain infrastructure.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluation of Habitat Robotics using Large Language Models</title>
<link>https://arxiv.org/abs/2507.06157</link>
<guid>https://arxiv.org/abs/2507.06157</guid>
<content:encoded><![CDATA[
arXiv:2507.06157v1 Announce Type: new 
Abstract: This paper focuses on evaluating the effectiveness of Large Language Models at solving embodied robotic tasks using the Meta PARTNER benchmark. Meta PARTNR provides simplified environments and robotic interactions within randomized indoor kitchen scenes. Each randomized kitchen scene is given a task where two robotic agents cooperatively work together to solve the task. We evaluated multiple frontier models on Meta PARTNER environments. Our results indicate that reasoning models like OpenAI o3-mini outperform non-reasoning models like OpenAI GPT-4o and Llama 3 when operating in PARTNR's robotic embodied environments. o3-mini displayed outperform across centralized, decentralized, full observability, and partial observability configurations. This provides a promising avenue of research for embodied robotic development.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Estimation with Decentralized Control for Quadruple-Tank Process</title>
<link>https://arxiv.org/abs/2304.04763</link>
<guid>https://arxiv.org/abs/2304.04763</guid>
<content:encoded><![CDATA[
arXiv:2304.04763v2 Announce Type: replace 
Abstract: This paper presents a unified modeling, control, and estimation framework for the quadruple-tank process, a benchmark multivariable system that exhibits either minimum phase or nonminimum phase behavior depending on valve flow ratios. A decentralized PI control strategy is employed to regulate water levels, while a distributed state estimation scheme is developed using local Luenberger observers and inter-agent communication. Each observer uses only local output measurements and exchanges information with neighboring nodes over a strongly connected communication graph. To address the limitations of partial observability, the observer design incorporates an observability decomposition and consensus-based coupling that ensures convergence to the true system state. Simulation results validate the effectiveness of the proposed framework, demonstrating accurate state reconstruction and stable closed loop performance under both minimum-phase and nonminimum phase configurations. These results highlight the potential of combining decentralized control with distributed estimation for scalable, networked control of complex multivariable systems.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation</title>
<link>https://arxiv.org/abs/2312.12491</link>
<guid>https://arxiv.org/abs/2312.12491</guid>
<content:encoded><![CDATA[
arXiv:2312.12491v2 Announce Type: replace 
Abstract: We introduce StreamDiffusion, a real-time diffusion pipeline designed for interactive image generation. Existing diffusion models are adept at creating images from text or image prompts, yet they often fall short in real-time interaction. This limitation becomes particularly evident in scenarios involving continuous input, such as Metaverse, live video streaming, and broadcasting, where high throughput is imperative. To address this, we present a novel approach that transforms the original sequential denoising into the batching denoising process. Stream Batch eliminates the conventional wait-and-interact approach and enables fluid and high throughput streams. To handle the frequency disparity between data input and model throughput, we design a novel input-output queue for parallelizing the streaming process. Moreover, the existing diffusion pipeline uses classifier-free guidance(CFG), which requires additional U-Net computation. To mitigate the redundant computations, we propose a novel residual classifier-free guidance (RCFG) algorithm that reduces the number of negative conditional denoising steps to only one or even zero. Besides, we introduce a stochastic similarity filter(SSF) to optimize power consumption. Our Stream Batch achieves around 1.5x speedup compared to the sequential denoising method at different denoising levels. The proposed RCFG leads to speeds up to 2.05x higher than the conventional CFG. Combining the proposed strategies and existing mature acceleration tools makes the image-to-image generation achieve up-to 91.07fps on one RTX4090, improving the throughputs of AutoPipline developed by Diffusers over 59.56x. Furthermore, our proposed StreamDiffusion also significantly reduces the energy consumption by 2.39x on one RTX3060 and 1.99x on one RTX4090, respectively.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ContractTrace: Retracing Smart Contract Versions for Security Analyses</title>
<link>https://arxiv.org/abs/2412.20866</link>
<guid>https://arxiv.org/abs/2412.20866</guid>
<content:encoded><![CDATA[
arXiv:2412.20866v2 Announce Type: replace 
Abstract: Due to the inherent immutability of blockchain technology, smart contract updates require their deployment at new addresses rather than modifying existing ones, thus fragmenting version histories and creating critical blind spots for analyses. Indeed, for example, this fragmentation severely hinders security researchers ability to track vulnerability lifecycles across contract versions. While platforms like Etherscan provide detailed information about Ethereum smart contracts, they lack crucial functionality to trace predecessor-successor relationships within smart contract lineages, preventing systematic analysis of how vulnerabilities emerge, propagate, and potentially remain unresolved across versions.To address the challenge of tracing smart contract lineages, we adopt a Design Science Research (DSR) approach and introduce ContractTrace, an automated infrastructure that accurately identifies and links versions of smart contracts into coherent lineages. This tool enables the construction of lineageSet, an up-to-date, open-source dataset specifically designed to support security research on vulnerability, defect or any other property evolution patterns in smart contracts. Through a security-focused case study we demonstrate how ContractTrace reveals previously obscured vulnerability life-cycles within smart contract lineages, tracking whether critical security flaws persist or get resolved across versions. This capability is essential for understanding vulnerability propagation patterns and evaluating the effectiveness of security patches in blockchain environments. In the evaluation phase of our DSR approach, we validated our lineage detection methodology against an alternative approach using Locality-Sensitive Hashing (LSH) to cluster contract versions, confirming the security relevance and accuracy of our technique.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Conthereum: Concurrent Ethereum Optimized Transaction Scheduling for Multi-Core Execution</title>
<link>https://arxiv.org/abs/2504.07280</link>
<guid>https://arxiv.org/abs/2504.07280</guid>
<content:encoded><![CDATA[
arXiv:2504.07280v2 Announce Type: replace 
Abstract: Conthereum is a concurrent Ethereum solution for intra-block parallel transaction execution, enabling validators to utilize multi-core infrastructure and transform the sequential execution model of Ethereum into a parallel one. This shift significantly increases throughput and transactions per second (TPS), while ensuring conflict-free execution in both proposer and attestor modes and preserving execution order consistency in the attestor. At the heart of Conthereum is a novel, lightweight, high-performance scheduler inspired by the Flexible Job Shop Scheduling Problem (FJSS). We propose a custom greedy heuristic algorithm, along with its efficient implementation, that solves this formulation effectively and decisively outperforms existing scheduling methods in finding suboptimal solutions that satisfy the constraints, achieve minimal makespan, and maximize speedup in parallel execution. Additionally, Conthereum includes an offline phase that equips its real-time scheduler with a conflict analysis repository obtained through static analysis of smart contracts, identifying potentially conflicting functions using a pessimistic approach. Building on this novel scheduler and extensive conflict data, Conthereum outperforms existing concurrent intra-block solutions. Empirical evaluations show near-linear throughput gains with increasing computational power on standard 8-core machines. Although scalability deviates from linear with higher core counts and increased transaction conflicts, Conthereum still significantly improves upon the current sequential execution model and outperforms existing concurrent solutions under a wide range of conditions.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bittensor Protocol: The Bitcoin in Decentralized Artificial Intelligence? A Critical and Empirical Analysis</title>
<link>https://arxiv.org/abs/2507.02951</link>
<guid>https://arxiv.org/abs/2507.02951</guid>
<content:encoded><![CDATA[
arXiv:2507.02951v1 Announce Type: new 
Abstract: This paper investigates whether Bittensor can be considered the Bitcoin of decentralized Artificial Intelligence by directly comparing its tokenomics, decentralization properties, consensus mechanism, and incentive structure against those of Bitcoin. Leveraging on-chain data from all 64 active Bittensor subnets, we first document considerable concentration in both stake and rewards. We further show that rewards are overwhelmingly driven by stake, highlighting a clear misalignment between quality and compensation. As a remedy, we put forward a series of two-pronged protocol-level interventions. For incentive realignment, our proposed solutions include performance-weighted emission split, composite scoring, and a trust-bonus multiplier. As for mitigating security vulnerability due to stake concentration, we propose and empirically validate stake cap at the 88th percentile, which elevates the median coalition size required for a 51-percent attack and remains robust across daily, weekly, and monthly snapshots.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hybrid Mean Field Framework for Aggregators Participating in Wholesale Electricity Markets</title>
<link>https://arxiv.org/abs/2507.03240</link>
<guid>https://arxiv.org/abs/2507.03240</guid>
<content:encoded><![CDATA[
arXiv:2507.03240v1 Announce Type: new 
Abstract: The rapid growth of distributed energy resources (DERs), including rooftop solar and energy storage, is transforming the grid edge, where distributed technologies and customer-side systems increasingly interact with the broader power grid. DER aggregators, entities that coordinate and optimize the actions of many small-scale DERs, play a key role in this transformation. This paper presents a hybrid Mean-Field Control (MFC) and Mean-Field Game (MFG) framework for integrating DER aggregators into wholesale electricity markets. Unlike traditional approaches that treat market prices as exogenous, our model captures the feedback between aggregators' strategies and locational marginal prices (LMPs) of electricity. The MFC component optimizes DER operations within each aggregator, while the MFG models strategic interactions among multiple aggregators. To account for various uncertainties, we incorporate reinforcement learning (RL), which allows aggregators to learn optimal bidding strategies in dynamic market conditions. We prove the existence and uniqueness of a mean-field equilibrium and validate the framework through a case study of the Oahu Island power system. Results show that our approach reduces price volatility and improves market efficiency, offering a scalable and decentralized solution for DER integration in wholesale markets.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Novel Blockchain-based Protocols for Electronic Voting and Auctions</title>
<link>https://arxiv.org/abs/2507.03258</link>
<guid>https://arxiv.org/abs/2507.03258</guid>
<content:encoded><![CDATA[
arXiv:2507.03258v1 Announce Type: new 
Abstract: Programmable blockchains have long been a hot research topic given their tremendous use in decentralized applications. Smart contracts, using blockchains as their underlying technology, inherit the desired properties such as verifiability, immutability, and transparency, which make it a great suit in trustless environments.
  In this thesis, we consider several decentralized protocols to be built on blockchains, specifically using smart contracts on Ethereum. We used algorithmic and cryptographic tools in our implementations to further improve the level of security and efficiency beyond the state-of-the-art works. We proposed a new approach called Blind Vote, which is an untraceable, secure, efficient, secrecy-preserving, and fully on-chain electronic voting protocol based on the well-known concept of Chaum's blind signatures. We illustrate that our approach achieves the same security guarantees as previous methods such as Tornado Vote [1], while consuming significantly less gas. Thus, we provide a cheaper and considerably more gas-efficient alternative for anonymous blockchain-based voting. On the other hand, we propose a new family of algorithms for private, trustless auctions that protect bidder identities and bid values while remaining practical for smart contract execution. We ensure trustlessness by running the auction logic in a smart contract, thereby eliminating reliance on any single trusted party. This approach prevents bid tampering, front-running, and collusion by enforcing immutability and decentralized verification of bids. The resulting protocol uniquely combines efficiency, trustlessness, and enduring bid privacy, offering a scalable and secure solution for blockchain-based marketplaces and other decentralized applications.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication Efficient, Differentially Private Distributed Optimization using Correlation-Aware Sketching</title>
<link>https://arxiv.org/abs/2507.03545</link>
<guid>https://arxiv.org/abs/2507.03545</guid>
<content:encoded><![CDATA[
arXiv:2507.03545v1 Announce Type: new 
Abstract: Federated learning with differential privacy suffers from two major costs: each client must transmit $d$-dimensional gradients every round, and the magnitude of DP noise grows with $d$. Yet empirical studies show that gradient updates exhibit strong temporal correlations and lie in a $k$-dimensional subspace with $k \ll d$. Motivated by this, we introduce DOME, a decentralized DP optimization framework in which each client maintains a compact sketch to project gradients into $\mathbb{R}^k$ before privatization and Secure Aggregation. This reduces per-round communication from order $d$ to order $k$ and moves towards a gradient approximation mean-squared error of $\sigma^2 k$. To allow the sketch to span new directions and prevent it from collapsing onto historical gradients, we augment it with random probes orthogonal to historical directions. We prove that our overall protocol satisfies $(\epsilon,\delta)$-Differential Privacy.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Plugging Attention into Power Grids: Towards Transparent Forecasting</title>
<link>https://arxiv.org/abs/2507.03690</link>
<guid>https://arxiv.org/abs/2507.03690</guid>
<content:encoded><![CDATA[
arXiv:2507.03690v1 Announce Type: new 
Abstract: Accurate electricity consumption forecasting is crucial for ensuring grid stability and optimizing power generation, particularly in increasingly decentralized and complex systems. While classical approaches such as Generalized Additive Models (GAMs) remain widely used, they often fail to capture the spatial dependencies inherent in energy networks. Graph Neural Networks (GNNs) offer a principled framework to incorporate this structure by directly leveraging graph topologies. In this work, we evaluate a broad set of GNN architectures -- including GCN, GraphSAGE, ChebConv, TAG, APPNP, TransformerConv, and Graph Attention Networks (GAT and GATv2) -- on two real-world electricity consumption datasets from France and the UK. Our experiments show that while complex architectures like GATv2 and TransformerConv do not consistently outperform their simpler counterparts, models such as GCN and APPNP achieve strong results in low-data or highly disaggregated settings. Nonetheless, the vanilla GAT remains highly competitive across both datasets and offers an additional interpretability layer via attention mechanisms. We perform a temporal analysis of attention weights, revealing evolving patterns of regional interaction linked to seasonal and meteorological variability. These results highlight that, although attention is not universally superior, it provides valuable explanatory power when spatial dependencies are prominent. Finally, we benchmark ensemble-based expert aggregation strategies, showing that uniform or learned combinations can enhance robustness and outperform individual models under data heterogeneity.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Willchain: Decentralized, Privacy-Preserving, Self-Executing, Digital Wills</title>
<link>https://arxiv.org/abs/2507.03694</link>
<guid>https://arxiv.org/abs/2507.03694</guid>
<content:encoded><![CDATA[
arXiv:2507.03694v1 Announce Type: new 
Abstract: This work presents a novel decentralized protocol for digital estate planning that integrates advances distributed computing, and cryptography. The original proof-of-concept was constructed using purely solidity contracts. Since then, we have enhanced the implementation into a layer-1 protocol that uses modern interchain communication to connect several heterogeneous chain types. A key contribution of this research is the implementation of several modern cryptographic primitives to support various forms of claims for information validation. These primitives introduce an unmatched level of privacy to the process of digital inheritance. We also demonstrate on a set of heterogeneous smart contracts, following the same spec, on each chain to serve as entry points, gateways, or bridge contracts that are invoked via a path from the will module on our protocol, to the contract. This ensures a fair and secure distribution of digital assets in accordance with the wishes of the decedent without the requirement of moving their funds. This research further extends its innovations with a user interaction model, featuring a check-in system and account abstraction process, which enhances flexibility and user-friendliness without compromising on security. By developing a dedicated permissionless blockchain that is secured by a network of validators, and interchain relayers, the proposed protocol signifies a transformation in the digital estate planning industry and illustrates the potential of blockchain technology in revolutionizing traditional legal and personal spheres. Implementing a cryptoeconomic network at the core of inheritance planning allows for unique incentive compatible economic mechanisms to be constructed.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.04140</link>
<guid>https://arxiv.org/abs/2507.04140</guid>
<content:encoded><![CDATA[
arXiv:2507.04140v1 Announce Type: new 
Abstract: Humans naturally swing their arms during locomotion to regulate whole-body dynamics, reduce angular momentum, and help maintain balance. Inspired by this principle, we present a limb-level multi-agent reinforcement learning (RL) framework that enables coordinated whole-body control of humanoid robots through emergent arm motion. Our approach employs separate actor-critic structures for the arms and legs, trained with centralized critics but decentralized actors that share only base states and centroidal angular momentum (CAM) observations, allowing each agent to specialize in task-relevant behaviors through modular reward design. The arm agent guided by CAM tracking and damping rewards promotes arm motions that reduce overall angular momentum and vertical ground reaction moments, contributing to improved balance during locomotion or under external perturbations. Comparative studies with single-agent and alternative multi-agent baselines further validate the effectiveness of our approach. Finally, we deploy the learned policy on a humanoid platform, achieving robust performance across diverse locomotion tasks, including flat-ground walking, rough terrain traversal, and stair climbing.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Governance and Technological Challenge in Digital Solidarity Economies: A Case Study of a Collaborative Transportation Platform in South Korea</title>
<link>https://arxiv.org/abs/2507.04166</link>
<guid>https://arxiv.org/abs/2507.04166</guid>
<content:encoded><![CDATA[
arXiv:2507.04166v1 Announce Type: new 
Abstract: South Korea's City P illustrates how lofty goals of digital solidarity can falter when challenged by local governance realities. Drawing on Hansmann's ownership theory, collaborative governance concepts, and platform cooperativism, we conducted a qualitative case study involving policy documents, independent assessments, and 11 in-depth interviews with residents, officials, and technology developers. Findings reveal a marked disconnect between the initiative's stated emphasis on community co-ownership and the actual power dynamics that largely favored government agencies and external firms. Although blockchain and integrated digital tools were meant to enhance transparency and inclusivity, stakeholders--especially elderly residents--experienced confusion and mistrust. We argue that genuine collaboration in digital solidarity economies requires not only robust technical designs but also culturally resonant ownership structures, substantive inclusion of local voices, and transparent governance mechanisms. The City P case underscores the necessity of addressing heterogeneous digital capacities, aligning funding and incentives with grassroots empowerment, and mitigating performative participation to ensure meaningful and sustainable outcomes in community-based digital innovation.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Static Analysis for Detecting Transaction Conflicts in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2507.04357</link>
<guid>https://arxiv.org/abs/2507.04357</guid>
<content:encoded><![CDATA[
arXiv:2507.04357v1 Announce Type: new 
Abstract: Ethereum smart contracts operate in a concurrent environment where multiple transactions can be submitted simultaneously. However, the Ethereum Virtual Machine (EVM) enforces sequential execution of transactions within each block to prevent conflicts arising from concurrent access to the same state variables. Although this approach guarantees correct behavior, it limits the ability of validators to leverage multi-core architectures for faster transaction processing, thus restricting throughput. Existing solutions introduce concurrency by allowing simultaneous transaction execution combined with runtime conflict detection and rollback mechanisms to maintain correctness. However, these methods incur significant overhead due to continuous conflict tracking and transaction reversion. Recently, alternative approaches have emerged that aim to predict conflicts statically, before execution, by analyzing smart contract code for potential transaction interactions. Despite their promise, there is a lack of comprehensive studies that examine static conflict detection and its broader implications in specific smart contracts. This paper fills this important gap by proposing a novel static analysis method to detect potential transaction conflicts in Ethereum smart contracts. Our method identifies read-write, write-write, and function call conflicts between transaction pairs by analyzing state variable access patterns in Solidity contracts. We implement a tool that parses contract code and performs conflict detection. Evaluation on a dataset of real-world Ethereum smart contracts demonstrates that our approach achieves high precision in identifying potential conflicts. By enabling proactive conflict detection, our tool supports further design of transaction scheduling strategies that reduce runtime failures, enhance validator throughput, and contribute to blockchain scalability.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Agents</title>
<link>https://arxiv.org/abs/2507.04376</link>
<guid>https://arxiv.org/abs/2507.04376</guid>
<content:encoded><![CDATA[
arXiv:2507.04376v1 Announce Type: new 
Abstract: As Artificial Intelligence systems evolve from monolithic models to ecosystems of specialized agents, the need for standardized communication protocols becomes increasingly critical. This paper introduces MOD-X (Modular Open Decentralized eXchange), a novel architectural framework proposal for agent interoperability that addresses key limitations of existing protocols. Unlike current approaches, MOD-X proposes a layered architecture with a Universal Message Bus, thorough state management, translation capabilities, and blockchain-based security mechanisms. We present MOD-X's architecture, compare it with existing protocols, and demonstrate its application through a worked example how it enables integration between heterogeneous specialist agents (agents with different architectures, vendors, capabilities, and knowledge representations--including rule-based systems, neural networks, symbolic reasoning engines, and legacy software with agent wrappers). MOD-X's key innovations include a publish-subscribe communication model, semantic capability discovery, and dynamic workflow orchestration--providing a framework that bridges theoretical formalism with practical implementation. This architecture addresses the growing need for truly decentralized, interoperable agent ecosystems that can scale effectively without the need for central coordination.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NourID+: A Digital Energy Identity Framework for Efficient Subsidy Allocation in Morocco</title>
<link>https://arxiv.org/abs/2507.04424</link>
<guid>https://arxiv.org/abs/2507.04424</guid>
<content:encoded><![CDATA[
arXiv:2507.04424v1 Announce Type: new 
Abstract: We introduce NourID+, a digital energy identity framework that addresses Morocco's need for trusted energy subsidy allocation through authenticated digital identity integration. NourID+ creates a strong foundation for future subsidy programs by unifying three government-issued and digitalized credentials: Moroccan national identity cards (CIN), cadastral plans, and property ownership certificates are transformed into unique digital energy IDs (DE-IDs) that map authenticated identities with specific properties and their energy consumption patterns. The system supports three property ownership profiles: farmers (landowners), entrepreneurs (factory or company owners), and households (house owners), as energy consumption is directly related to land ownership. NourID+ provides dual access through a government portal allowing officials to process DE-ID generation requests, as well as a citizen portal for DE-ID usage and energy monitoring. Our framework supports CIN upload with facial biometric matching, automated property retrieval through government APIs, and government officer approval workflow for DE-ID generation. After evaluation of the system, we demonstrate a reduction in verification time from weeks to minutes, with 98% accuracy of document validation. The proposed solution allows for targeted subsidy allocation of electricity based on actual consumption needs rather than estimations, potentially improving the efficiency of Morocco's significant energy subsidy expenditure.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Truthful, Credible, and Optimal Auctions for Matroids via Blockchains and Commitments</title>
<link>https://arxiv.org/abs/2507.04592</link>
<guid>https://arxiv.org/abs/2507.04592</guid>
<content:encoded><![CDATA[
arXiv:2507.04592v1 Announce Type: new 
Abstract: We consider a revenue-optimizing auctioneer in single-dimensional environments with matroid feasibility constraints. Akbarpour and Li (2020) argue that any revenue-optimal, truthful, and credible mechanism requires unbounded communication. Recent works (Ferreira and Weinberg, 2020; Essaidi et al., 2022; Chitra et al., 2024) circumvent their impossibility for the single-item setting through the use of cryptographic commitments and blockchains. We extend their results to matroid feasibility constraints.
  At a high level, the two-round Deferred-Revelation Auction (DRA) discussed by Ferreira and Weinberg (2020) and Chitra et al., (2024) requires each bidder to submit a deposit, which is slashed upon presenting verifiable evidence indicating a deviation from the behaviour prescribed by the mechanism. We prove that the DRA satisfies truthfulness, credibility and revenue-optimality for all matroid environments when bidders' values are drawn from $\alpha$-strongly regular distributions for $\alpha > 0$. Further, we argue that the DRA is not credible for any feasibility constraint beyond matroids and for any smaller deposits than suggested by previous literature even in single-item environments.
  Finally, we modify the Ascending Deferred-Revelation Auction (ADRA) for single-item settings proposed by Essaidi et al., (2022) for arbitrary bidder value distributions. We implement a deferred-revelation variant of the deferred-acceptance auction for matroids due to Bikhchandani et al., (2011), which requires the same bounded communication as the ADRA.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Operator-based machine learning framework for generalizable prediction of unsteady treatment dynamics in stormwater infrastructure</title>
<link>https://arxiv.org/abs/2507.04682</link>
<guid>https://arxiv.org/abs/2507.04682</guid>
<content:encoded><![CDATA[
arXiv:2507.04682v1 Announce Type: new 
Abstract: Stormwater infrastructures are decentralized urban water-management systems that face highly unsteady hydraulic and pollutant loadings from episodic rainfall-runoff events. Accurately evaluating their in-situ treatment performance is essential for cost-effective design and planning. Traditional lumped dynamic models (e.g., continuously stirred tank reactor, CSTR) are computationally efficient but oversimplify transport and reaction processes, limiting predictive accuracy and insight. Computational fluid dynamics (CFD) resolves detailed turbulent transport and pollutant fate physics but incurs prohibitive computational cost for unsteady and long-term simulations. To address these limitations, this study develops a composite operator-based neural network (CPNN) framework that leverages state-of-the-art operator learning to predict the spatial and temporal dynamics of hydraulics and particulate matter (PM) in stormwater treatment. The framework is demonstrated on a hydrodynamic separator (HS), a common urban treatment device. Results indicate that the CPNN achieves R2 > 0.8 for hydraulic predictions in 95.2% of test cases; for PM concentration predictions, R2 > 0.8 in 72.6% of cases and 0.4 < R2 < 0.8 in 22.6%. The analysis identifies challenges in capturing dynamics under extreme low-flow conditions, owing to their lower contribution to the training loss. Exploiting the automatic-differentiation capability of the CPNN, sensitivity analyses quantify the influence of storm event loading on PM transport. Finally, the potential of the CPNN framework for continuous, long-term evaluation of stormwater infrastructure performance is discussed, marking a step toward robust, climate-aware planning and implementation.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2507.04724</link>
<guid>https://arxiv.org/abs/2507.04724</guid>
<content:encoded><![CDATA[
arXiv:2507.04724v1 Announce Type: new 
Abstract: Multi-agent systems powered by Large Language Models (LLM-MAS) demonstrate remarkable capabilities in collaborative problem-solving. While LLM-MAS exhibit strong collaborative abilities, the security risks in their communication and coordination remain underexplored. We bridge this gap by systematically investigating intention-hiding threats in LLM-MAS, and design four representative attack paradigms that subtly disrupt task completion while maintaining high concealment. These attacks are evaluated in centralized, decentralized, and layered communication structures. Experiments conducted on six benchmark datasets, including MMLU, MMLU-Pro, HumanEval, GSM8K, arithmetic, and biographies, demonstrate that they exhibit strong disruptive capabilities. To identify these threats, we propose a psychology-based detection framework AgentXposed, which combines the HEXACO personality model with the Reid Technique, using progressive questionnaire inquiries and behavior-based monitoring. Experiments conducted on six types of attacks show that our detection framework effectively identifies all types of malicious behaviors. The detection rate for our intention-hiding attacks is slightly lower than that of the two baselines, Incorrect Fact Injection and Dark Traits Injection, demonstrating the effectiveness of intention concealment. Our findings reveal the structural and behavioral risks posed by intention-hiding attacks and offer valuable insights into securing LLM-based multi-agent systems through psychological perspectives, which contributes to a deeper understanding of multi-agent safety. The code and data are available at https://anonymous.4open.science/r/AgentXposed-F814.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bullshark on Narwhal: Implementation-level Workflow Analysis of Round-based DAG Consensus in Theory and Practice</title>
<link>https://arxiv.org/abs/2507.04956</link>
<guid>https://arxiv.org/abs/2507.04956</guid>
<content:encoded><![CDATA[
arXiv:2507.04956v1 Announce Type: new 
Abstract: Round-based DAGs enable high-performance Byzantine fault-tolerant consensus, yet their technical advantages remain underutilized due to their short history. While research on consensus protocols is active in both academia and industry, many studies overlook implementation-level algorithms, leaving actual performance unclear - particularly for theoretical protocols whose practical performance cannot often be evaluated. Bullshark, a Round-based DAG BFT protocol on Narwhal mempool, achieves optimal performance: 297,000 transactions per second with 2-second latency. We analyze the algorithm's workflow, from transaction submission to blockchain commitment, breaking it down layer by layer at the functional level and delineating the key features and interactions of the Bullshark and Narwhal components. Future work aims to improve performance in Byzantine fault environments and optimize trade-offs in the CAP theorem.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficiency through Evolution, A Darwinian Approach to Agent-Based Economic Forecast Modeling</title>
<link>https://arxiv.org/abs/2507.04074</link>
<guid>https://arxiv.org/abs/2507.04074</guid>
<content:encoded><![CDATA[
arXiv:2507.04074v1 Announce Type: cross 
Abstract: This paper presents a novel Darwinian Agent-Based Modeling (ABM) methodology formacroeconomic forecasting that leverages evolutionary principles to achieve remarkablecomputational efficiency and emergent realism. Unlike conventional DSGE and ABM approachesthat rely on complex behavioral rules derived from large firm analysis, our framework employssimple "common sense" rules representative of small firms directly serving final consumers. Themethodology treats households as the primary drivers of economic dynamics, with firms adaptingthrough market-based natural selection within limited interaction neighborhoods. We demonstrate that this approach, when constrained by Input-Output table structures,generates realistic economic patterns including wealth distributions, firm size distributions, andsectoral employment patterns without extensive parameter calibration. Using FIGARO Input-Output tables for 46 countries and focusing on Austria as a case study, we show that the modelreproduces empirical regularities while maintaining computational efficiency on standard laptopsrather than requiring supercomputing clusters. Key findings include: (1) emergence of realistic firm and employment distributions fromminimal behavioral assumptions, (2) accurate reproduction of the initial Social Accounting Matrixvalues through evolutionary dynamics, (3) successful calibration using only 5-6 country-specificparameters to complement the FIGARO data, and (4) computational performance enabling fullsimulations on consumer hardware. These results suggest that evolutionary ABM approaches canprovide robust policy insights by capturing decentralized market adaptations while avoiding thecomputational complexity of traditional DSGE and comprehensive ABM models.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semitopology: distributed collaborative action via topology, algebra, and logic</title>
<link>https://arxiv.org/abs/2402.03253</link>
<guid>https://arxiv.org/abs/2402.03253</guid>
<content:encoded><![CDATA[
arXiv:2402.03253v3 Announce Type: replace 
Abstract: We introduce semitopologies, a generalisation of point-set topology that removes the restriction that intersections of open sets need necessarily be open.
  The intuition is that points are participants in some distributed system, and an open set is a collection of participants that can collaborate to update their local state by taking a distributed collaborative action; we call this an actionable coalition. What constitutes an actionable coalition depends on what actions we want to model. Intuitive examples include 'a group of people that is collectively strong enough to lift a rock', where the state update is very simply 'holding rock low' to 'holding rock high' and this update is common to all participants in the actionable coalition. Or, consider 'two people wishing to barter a can of juice for a bar of chocolate', in which case the coalition is any such pair and the state updates differ between participants to flip them between 'has/has no juice' and 'has/has no chocolate'. A characteristic of these systems is that state updates are local to the coalition, voluntary, may vary between participants, and are not assumed subject to permission or synchronisation by a central authority. Peer-to-peer computer networks, including filesharing and blockchain systems, provide motivating examples from computing.
  This monograph presents a comprehensive view of semitopologies which includes point-set semitopology, algebra, and logic inspired by these considerations. This is interesting in and of itself and it provides a conceptual framework within which to understand a useful class of distributed systems.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Is Your AI Truly Yours? Leveraging Blockchain for Copyrights, Provenance, and Lineage</title>
<link>https://arxiv.org/abs/2404.06077</link>
<guid>https://arxiv.org/abs/2404.06077</guid>
<content:encoded><![CDATA[
arXiv:2404.06077v2 Announce Type: replace 
Abstract: As Artificial Intelligence (AI) integrates into diverse areas, particularly in content generation, ensuring rightful ownership and ethical use becomes paramount, AI service providers are expected to prioritize responsibly sourcing training data and obtaining licenses from data owners. However, existing studies primarily center on safeguarding static copyrights, which simply treat metadata/datasets as non-fungible items with transferable/trading capabilities, neglecting the dynamic nature of training procedures that can shape an ongoing trajectory. In this paper, we present \textsc{IBis}, a blockchain-based framework tailored for AI model training workflows. Our design can dynamically manage copyright compliance and data provenance in decentralized AI model training processes, ensuring that intellectual property rights are respected throughout iterative model enhancements and licensing updates. Technically, \textsc{IBis} integrates on-chain registries for datasets, licenses and models, alongside off-chain signing services to facilitate collaboration among multiple participants. Further, \textsc{IBis} provides APIs designed for seamless integration with existing contract management software, minimizing disruptions to established model training processes. We implement \textsc{IBis} using Daml on the Canton blockchain. Evaluation results showcase the feasibility and scalability of \textsc{IBis} across varying numbers of users, datasets, models, and licenses.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Curvature-Aligned Federated Learning (CAFe): Harmonizing Loss Landscapes for Fairness Without Demographics</title>
<link>https://arxiv.org/abs/2404.19725</link>
<guid>https://arxiv.org/abs/2404.19725</guid>
<content:encoded><![CDATA[
arXiv:2404.19725v4 Announce Type: replace 
Abstract: Federated Learning (FL) enables privacy-preserving collaborative training, making it well-suited for decentralized human-sensing applications. Ensuring fairness in FL is challenging, as current methods rely on sensitive attribute knowledge, which conflicts with FL's privacy principles. Additionally, sensitive attributes in human-sensing data may be unknown or latent. To address this, we introduce Curvature-Aligned Federated Learning (CAFe), a theoretically grounded approach that achieves fairness in FL without requiring sensitive attribute knowledge, a concept termed "Fairness without Demographics" (FWD). CAFe introduces loss-landscape curvature regularization during local training and clients' loss-landscape sharpness-aware aggregation to align curvature both within and across clients, enabling a strong balance between higher fairness and performance. CAFe is especially suitable for real-world human-sensing FL scenarios involving single or multi-user edge devices with unknown or multiple bias factors. We validated CAFe through theoretical and empirical justifications, and comprehensive evaluations using three real-world datasets and a live real-world FL deployment with a heterogeneous testbed of resource-constrained devices. Additionally, we conduct sensitivity analyses on local training data volume, client sampling, communication overhead, resource costs, and runtime performance to demonstrate its feasibility for practical FL edge device deployment.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative and parametric insurance on the Ethereum blockchain</title>
<link>https://arxiv.org/abs/2412.05321</link>
<guid>https://arxiv.org/abs/2412.05321</guid>
<content:encoded><![CDATA[
arXiv:2412.05321v2 Announce Type: replace 
Abstract: This paper introduces a blockchain-based insurance scheme that integrates parametric and collaborative elements. A pool of investors, referred to as surplus providers, locks funds in a smart contract, enabling blockchain users to underwrite parametric insurance contracts. These contracts automatically trigger compensation when predefined conditions are met. The collaborative aspect is embodied in the generation of tokens, which are distributed to surplus providers. These tokens represent each participant's share of the surplus and grant voting rights for management decisions. The smart contract is developed in Solidity, a high-level programming language for the Ethereum blockchain, and deployed on the Sepolia testnet, with data processing and analysis conducted using Python. In addition, open-source code is provided and main research challenges are identified, so that further research can be carried out to overcome limitations of this first proof of concept.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BECS: A Privacy-Preserving Computing Sharing Mechanism in 6G Computing Power Network</title>
<link>https://arxiv.org/abs/2412.06196</link>
<guid>https://arxiv.org/abs/2412.06196</guid>
<content:encoded><![CDATA[
arXiv:2412.06196v2 Announce Type: replace 
Abstract: 5G networks provide secure and reliable information transmission services for the Internet of Everything, thus paving the way for 6G networks, which is anticipated to be an AI-based network, supporting unprecedented intelligence across applications. Abundant computing resources will establish the 6G Computing Power Network (CPN) to facilitate ubiquitous intelligent services. In this article, we propose BECS, a computing sharing mechanism based on evolutionary algorithm and blockchain, designed to balance task offloading among user devices, edge devices, and cloud resources within 6G CPN, thereby enhancing the computing resource utilization. We model computing sharing as a multi-objective optimization problem, aiming to improve resource utilization while balancing other issues. To tackle this NP-hard problem, we devise a kernel distance-based dominance relation and incorporated it into the Non-dominated Sorting Genetic Algorithm III, significantly enhancing the diversity of the evolutionary population. In addition, we propose a pseudonym scheme based on zero-knowledge proof to protect the privacy of users participating in computing sharing. Finally, the security analysis and simulation results demonstrate that BECS can fully and effectively utilize all computing resources in 6G CPN, significantly improving the computing resource utilization while protecting user privacy.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Registered Attribute-Based Encryption with Reliable Outsourced Decryption Based on Blockchain</title>
<link>https://arxiv.org/abs/2412.08957</link>
<guid>https://arxiv.org/abs/2412.08957</guid>
<content:encoded><![CDATA[
arXiv:2412.08957v3 Announce Type: replace 
Abstract: Decentralized data sovereignty and secure data exchange are regarded as foundational pillars of the new era. Attribute-based encryption (ABE) is a promising solution that enables fine-grained access control in data sharing. Recently, Hohenberger et al. (Eurocrypt 2023) introduced registered ABE (RABE) to eliminate trusted authority and gain decentralization. Users generate their own public and secret keys and then register their keys and attributes with a transparent key curator. However, RABE still suffers from heavy decryption overhead. A natural approach to address this issue is to outsource decryption to a decryption cloud server (DCS). In this work, we propose the first auditable RABE scheme with reliable outsourced decryption (ORABE) based on blockchain. First, we achieve verifiability of transform ciphertext via a verifiable tag mechanism. Then, the exemptibility, which ensures that the DCS escapes false accusations, is guaranteed by zero knowledge fraud proof under the optimistic assumption. Additionally, our system achieves fairness and auditability to protect the interests of all parties through blockchain. Finally, we give concrete security and theoretical analysis and evaluate our scheme on Ethereum to demonstrate feasibility and efficiency.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DBA-DFL: Towards Distributed Backdoor Attacks with Network Detection in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.15005</link>
<guid>https://arxiv.org/abs/2501.15005</guid>
<content:encoded><![CDATA[
arXiv:2501.15005v2 Announce Type: replace 
Abstract: Distributed backdoor attacks (DBA) have shown a higher attack success rate than centralized attacks in centralized federated learning (FL). However, it has not been investigated in the decentralized FL. In this paper, we experimentally demonstrate that, while directly applying DBA to decentralized FL, the attack success rate depends on the distribution of attackers in the network architecture. Considering that the attackers can not decide their location, this paper aims to achieve a high attack success rate regardless of the attackers' location distribution. Specifically, we first design a method to detect the network by predicting the distance between any two attackers on the network. Then, based on the distance, we organize the attackers in different clusters. Lastly, we propose an algorithm to \textit{dynamically} embed local patterns decomposed from a global pattern into the different attackers in each cluster. We conduct a thorough empirical investigation and find that our method can, in benchmark datasets, outperform both centralized attacks and naive DBA in different decentralized frameworks.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>QuTE: decentralized multiple testing on sensor networks with false discovery rate control</title>
<link>https://arxiv.org/abs/2210.04334</link>
<guid>https://arxiv.org/abs/2210.04334</guid>
<content:encoded><![CDATA[
arXiv:2210.04334v2 Announce Type: replace-cross 
Abstract: This paper designs methods for decentralized multiple hypothesis testing on graphs that are equipped with provable guarantees on the false discovery rate (FDR). We consider the setting where distinct agents reside on the nodes of an undirected graph, and each agent possesses p-values corresponding to one or more hypotheses local to its node. Each agent must individually decide whether to reject one or more of its local hypotheses by only communicating with its neighbors, with the joint aim that the global FDR over the entire graph must be controlled at a predefined level. We propose a simple decentralized family of Query-Test-Exchange (QuTE) algorithms and prove that they can control FDR under independence or positive dependence of the p-values. Our algorithm reduces to the Benjamini-Hochberg (BH) algorithm when after graph-diameter rounds of communication, and to the Bonferroni procedure when no communication has occurred or the graph is empty. To avoid communicating real-valued p-values, we develop a quantized BH procedure, and extend it to a quantized QuTE procedure. QuTE works seamlessly in streaming data settings, where anytime-valid p-values may be continually updated at each node. Last, QuTE is robust to arbitrary dropping of packets, or a graph that changes at every step, making it particularly suitable to mobile sensor networks involving drones or other multi-agent systems. We study the power of our procedure using a simulation suite of different levels of connectivity and communication on a variety of graph structures, and also provide an illustrative real-world example.
]]></content:encoded>
<pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities</title>
<link>https://arxiv.org/abs/2507.02125</link>
<guid>https://arxiv.org/abs/2507.02125</guid>
<content:encoded><![CDATA[
arXiv:2507.02125v1 Announce Type: new 
Abstract: The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Linearly Homomorphic Ring Signature Scheme over Lattices</title>
<link>https://arxiv.org/abs/2507.02281</link>
<guid>https://arxiv.org/abs/2507.02281</guid>
<content:encoded><![CDATA[
arXiv:2507.02281v1 Announce Type: new 
Abstract: Homomorphic ring signature schemes combine the strong anonymity of ring signatures with the computability of homomorphic signatures, demonstrating significant potential in scenarios requiring both anonymous data provenance and verifiable homomorphic computation (e.g., confidential blockchain transactions and secure multi-party computation). However, no feasible homomorphic ring signature scheme currently exists.
  In this work, we propose the first lattice-based linearly homomorphic ring signature scheme. Proven secure in the standard model under the small integer solution (SIS) assumption, our scheme achieves strong anonymity under full key exposure and unforgeability against insider corruption attacks. As the first unified framework for ring signatures and linear homomorphic signatures, this construction provides a post-quantum-secure solution for the aforementioned applications, advancing the development of privacy-enhanced homomorphic computation.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Satellite-Ground Deployments for Web3 DID: System Design and Performance Analysis</title>
<link>https://arxiv.org/abs/2507.02305</link>
<guid>https://arxiv.org/abs/2507.02305</guid>
<content:encoded><![CDATA[
arXiv:2507.02305v1 Announce Type: new 
Abstract: The emerging Web3 has great potential to provide worldwide decentralized services powered by global-range data-driven networks in the future. To ensure the security of Web3 services among diverse user entities, a decentralized identity (DID) system is essential. Especially, a user's access request to Web3 services can be treated as a DID transaction within the blockchain, executed through a consensus mechanism. However, a critical implementation issue arises in the current Web3, i.e., how to deploy network nodes to serve users on a global scale. To address this issue, emerging Low Earth Orbit (LEO) satellite communication systems, such as Starlink, offer a promising solution. With their global coverage and high reliability, these communication satellites can complement terrestrial networks as Web3 deployment infrastructures. In this case, this paper develops three hybrid satellite-ground modes to deploy the blockchain-enabled DID system for Web3 users. Three modes integrate ground nodes and satellites to provide flexible and continuous DID services for worldwide users. Meanwhile, to evaluate the effectiveness of the present hybrid deployment modes, we analyze the complete DID consensus performance of blockchain on three hybrid satellite-ground modes. Moreover, we conduct numerical and simulation experiments to verify the effectiveness of three hybrid satellite-ground modes. The impacts of various system parameters are thoroughly analyzed, providing valuable insights for implementing the worldwide Web3 DID system in real-world network environments.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Defining DLT Immutability: A Qualitative Survey of Node Operators</title>
<link>https://arxiv.org/abs/2507.02413</link>
<guid>https://arxiv.org/abs/2507.02413</guid>
<content:encoded><![CDATA[
arXiv:2507.02413v1 Announce Type: new 
Abstract: Immutability is a core design goal of permissionless public blockchain systems. However, rewrites are more common than is normally understood, and the risk of rewrite, cyberattack, exploit or black swan event is also high. Taking the position that strict immutability is neither possible on these networks nor the observed reality, this paper uses thematic analysis of node operator interviews to examine the limits of immutability in light of rewrite events. The end result is a qualitative definition of the conditional immutability found on these networks, which we call Practical Immutability. This is immutability contingent on the legitimate governance demands of the network, where network stakeholders place their trust in the governance topology of a network to lend it legitimacy, and thus manage ledger state.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real-Time Monitoring and Transparency in Pizza Production Using IoT and Blockchain</title>
<link>https://arxiv.org/abs/2507.02536</link>
<guid>https://arxiv.org/abs/2507.02536</guid>
<content:encoded><![CDATA[
arXiv:2507.02536v1 Announce Type: new 
Abstract: This paper presents a blockchain-based Internet of Things (IoT) system for monitoring pizza production in restaurants. IoT devices track temperature and humidity in real-time, while blockchain ensures secure and tamper-proof data. A Raspberry Pi processes sensor data, captures images, triggers alerts, and interacts with smart contracts. The system detects abnormal conditions, enabling quick responses. Blockchain adds transparency and traceability, supporting compliance and audits. Experiments show improved ingredient management, reduced waste, and increased kitchen efficiency.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs</title>
<link>https://arxiv.org/abs/2507.02671</link>
<guid>https://arxiv.org/abs/2507.02671</guid>
<content:encoded><![CDATA[
arXiv:2507.02671v1 Announce Type: new 
Abstract: Deep Learning (DL) has revolutionized medical imaging, yet its adoption is constrained by data scarcity and privacy regulations, limiting access to diverse datasets. Federated Learning (FL) enables decentralized training but suffers from high communication costs and is often restricted to a single downstream task, reducing flexibility. We propose a data-sharing method via Differentially Private (DP) generative models. By adopting foundation models, we extract compact, informative embeddings, reducing redundancy and lowering computational overhead. Clients collaboratively train a Differentially Private Conditional Variational Autoencoder (DP-CVAE) to model a global, privacy-aware data distribution, supporting diverse downstream tasks. Our approach, validated across multiple feature extractors, enhances privacy, scalability, and efficiency, outperforming traditional FL classifiers while ensuring differential privacy. Additionally, DP-CVAE produces higher-fidelity embeddings than DP-CGAN while requiring $5{\times}$ fewer parameters.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games</title>
<link>https://arxiv.org/abs/2507.02675</link>
<guid>https://arxiv.org/abs/2507.02675</guid>
<content:encoded><![CDATA[
arXiv:2507.02675v1 Announce Type: new 
Abstract: We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO), a new deep reinforcement learning framework. It extends Proximal Policy Optimization (PPO) by integrating team welfare objectives specifically for spatial public goods games. Unlike conventional approaches where cooperation emerges indirectly from individual rewards, TUC-PPO instead optimizes a bi-level objective integrating policy gradients and team utility constraints. Consequently, all policy updates explicitly incorporate collective payoff thresholds. The framework preserves PPO's policy gradient core while incorporating constrained optimization through adaptive Lagrangian multipliers. Therefore, decentralized agents dynamically balance selfish and cooperative incentives. The comparative analysis demonstrates superior performance of this constrained deep reinforcement learning approach compared to unmodified PPO and evolutionary game theory baselines. It achieves faster convergence to cooperative equilibria and greater stability against invasion by defectors. The framework formally integrates team objectives into policy updates. This work advances multi-agent deep reinforcement learning for social dilemmas while providing new computational tools for evolutionary game theory research.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Midsummer Meme's Dream: Investigating Market Manipulations in the Meme Coin Ecosystem</title>
<link>https://arxiv.org/abs/2507.01963</link>
<guid>https://arxiv.org/abs/2507.01963</guid>
<content:encoded><![CDATA[
arXiv:2507.01963v1 Announce Type: cross 
Abstract: From viral jokes to a billion-dollar phenomenon, meme coins have become one of the most popular segments in cryptocurrency markets. Unlike utility-focused crypto assets like Bitcoin or Ethereum, meme coins derive value primarily from community sentiment, making them vulnerable to manipulation. This study presents a cross-chain analysis of the meme coin ecosystem, examining 34,988 tokens across Ethereum, BNB Smart Chain, Solana, and Base. We characterize the tokenomics of meme coins and track their growth in a three-month longitudinal analysis. We discover that among high-return tokens (>100%), an alarming 82.6% show evidence of extensive use of artificial growth strategies designed to create a misleading appearance of market interest. These include wash trading and a form of manipulation we define as Liquidity Pool-Based Price Inflation (LPI), where small strategic purchases trigger dramatic price increases. We also find evidence of schemes designed to profit at the expense of investors, such as pump and dumps and rug pulls. In particular, most of the tokens involved had previously experienced wash trading or LPI, indicating how initial manipulations often set the stage for later exploitation. These findings reveal that manipulations are widespread among high-performing meme coins and suggest that their dramatic gains are often likely driven by coordinated efforts rather than natural market dynamics.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Robust Gossip: Insights from a Dual Approach</title>
<link>https://arxiv.org/abs/2405.03449</link>
<guid>https://arxiv.org/abs/2405.03449</guid>
<content:encoded><![CDATA[
arXiv:2405.03449v2 Announce Type: replace 
Abstract: Distributed learning has many computational benefits but is vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly in a peer-to-peer manner within a communication network. We leverage the so-called dual approach for decentralized optimization and propose a Byzantine-robust algorithm. We provide convergence guarantees in the average consensus subcase, discuss the potential of the dual approach beyond this subcase, and re-interpret existing algorithms using the dual framework. Lastly, we experimentally show the soundness of our method.
]]></content:encoded>
<pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation</title>
<link>https://arxiv.org/abs/2507.01383</link>
<guid>https://arxiv.org/abs/2507.01383</guid>
<content:encoded><![CDATA[
arXiv:2507.01383v1 Announce Type: new 
Abstract: Federated recommendation (FedRec) preserves user privacy by enabling decentralized training of personalized models, but this architecture is inherently vulnerable to adversarial attacks. Significant research has been conducted on targeted attacks in FedRec systems, motivated by commercial and social influence considerations. However, much of this work has largely overlooked the differential robustness of recommendation models. Moreover, our empirical findings indicate that existing targeted attack methods achieve only limited effectiveness in Federated Sequential Recommendation(FSR) tasks. Driven by these observations, we focus on investigating targeted attacks in FSR and propose a novel dualview attack framework, named DV-FSR. This attack method uniquely combines a sampling-based explicit strategy with a contrastive learning-based implicit gradient strategy to orchestrate a coordinated attack. Additionally, we introduce a specific defense mechanism tailored for targeted attacks in FSR, aiming to evaluate the mitigation effects of the attack method we proposed. Extensive experiments validate the effectiveness of our proposed approach on representative sequential models. Our codes are publicly available.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rational Censorship Attack: Breaking Blockchain with a Blackboard</title>
<link>https://arxiv.org/abs/2507.01453</link>
<guid>https://arxiv.org/abs/2507.01453</guid>
<content:encoded><![CDATA[
arXiv:2507.01453v1 Announce Type: new 
Abstract: Censorship resilience is a fundamental assumption underlying the security of blockchain protocols. Additionally, the analysis of blockchain security from an economic and game theoretic perspective has been growing in popularity in recent years. In this work, we present a surprising rational censorship attack on blockchain censorship resilience when we adopt the analysis of blockchain security from a game theoretic lens and assume all users are rational. In our attack, a colluding group with sufficient voting power censors the remainder nodes such that the group alone can gain all the rewards from maintaining the blockchain. We show that if nodes are rational, coordinating this attack just requires a public read and write blackboard and we formally model the attack using a game theoretic framework. Furthermore, we note that to ensure the success of the attack, nodes need to know the total true voting power held by the colluding group. We prove that the strategy to join the rational censorship attack and also for nodes to honestly declare their power is a subgame perfect equilibrium in the corresponding extensive form game induced by our attack. Finally, we discuss the implications of the attack on blockchain users and protocol designers as well as some potential countermeasures.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data</title>
<link>https://arxiv.org/abs/2507.01615</link>
<guid>https://arxiv.org/abs/2507.01615</guid>
<content:encoded><![CDATA[
arXiv:2507.01615v1 Announce Type: new 
Abstract: This paper proposes a new decentralized framework, named EDGChain-E (Encrypted-Data-Git Chain for Energy), designed to manage version-controlled, encrypted energy data using blockchain and the InterPlanetary File System. The framework incorporates a Decentralized Autonomous Organization (DAO) to orchestrate collaborative data governance across the lifecycle of energy research and operations, such as smart grid monitoring, demand forecasting, and peer-to-peer energy trading. In EDGChain-E, initial commits capture the full encrypted datasets-such as smart meter readings or grid telemetry-while subsequent updates are tracked as encrypted Git patches, ensuring integrity, traceability, and privacy. This versioning mechanism supports secure collaboration across multiple stakeholders (e.g., utilities, researchers, regulators) without compromising sensitive or regulated information. We highlight the framework's capability to maintain FAIR-compliant (Findable, Accessible, Interoperable, Reusable) provenance of encrypted data. By embedding hash-based content identifiers in Merkle trees, the system enables transparent, auditable, and immutable tracking of data changes, thereby supporting reproducibility and trust in decentralized energy applications.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EGNInfoLeaker: Unveiling the Risks of Public Key Reuse and User Identity Leakage in Blockchain</title>
<link>https://arxiv.org/abs/2507.01635</link>
<guid>https://arxiv.org/abs/2507.01635</guid>
<content:encoded><![CDATA[
arXiv:2507.01635v1 Announce Type: new 
Abstract: While Ethereum's discovery protocols (Discv4/ Discv5) incorporate robust cryptographic designs to protect user privacy, real-world deployment reveals critical vulnerabilities when users deviate from security guidelines. In this paper, we design a system called EGNInfoLeaker. Our study is the first work that uncovers widespread public key reuse across Ethereum's peer-to-peer networks - a practice that fundamentally undermines the protocol's privacy guarantees. Through systematic analysis of 300 real-world network snapshots, we identify 83 users controlling 483 service nodes via public key reuse, enabling precise de-anonymization through IP correlation. Using evidence collected by EGNInfoLeaker, our Graph-Based Identity Association Algorithm links users to network entities and generates comprehensive user profiles. For User27, it exposes the public key, IP, network ID, location (country/region/city), and ISP/ORG details. The EGNInfoLeaker system demonstrates how such cryptographic misuse transforms theoretical anonymity into practical identity leakage, exposing users to surveillance and targeted attacks. These findings establish that protocol security depends not only on sound design but also on strict user compliance. Going forward, our detection framework provides a foundation for enhancing real-world privacy preservation in decentralized networks.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distance-based Relative Orbital Transition for Satellite Swarm Array Deployment Under J2 Perturbation</title>
<link>https://arxiv.org/abs/2507.01769</link>
<guid>https://arxiv.org/abs/2507.01769</guid>
<content:encoded><![CDATA[
arXiv:2507.01769v1 Announce Type: new 
Abstract: This paper presents an autonomous guidance and control strategy for a satellite swarm that enables scalable distributed space structures for innovative science and business opportunities. The averaged $J_2$ orbital parameters that describe the drift and periodic orbital motion were derived along with their target values to achieve a distributed space structure in a decentralized manner. This enabled the design of a distance-based orbital stabilizer to ensure autonomous deployment into a monolithic formation of a coplanar equidistant configuration on a user-defined orbital plane. Continuous formation control was assumed to be achieved through fuel-free actuation, such as satellite magnetic field interaction and differential aerodynamic forces, thereby maintaining long-term formation stability without thruster usage. A major challenge for such actuation systems is the potential loss of control capability due to increasing inter-satellite distances resulting from unstable orbital dynamics, particularly for autonomous satellite swarms. To mitigate this risk, our decentralized deployment controller minimized drift distance during unexpected communication outages. As a case study, we consider the deployment of palm-sized satellites into a coplanar equidistant formation in a $J_2$-perturbed orbit. Moreover, centralized grouping strategies are presented.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Decentralized and Sustainable Foundation Model Training with the Edge</title>
<link>https://arxiv.org/abs/2507.01803</link>
<guid>https://arxiv.org/abs/2507.01803</guid>
<content:encoded><![CDATA[
arXiv:2507.01803v1 Announce Type: new 
Abstract: Foundation models are at the forefront of AI research, appealing for their ability to learn from vast datasets and cater to diverse tasks. Yet, their significant computational demands raise issues of environmental impact and the risk of centralized control in their development. We put forward a vision towards decentralized and sustainable foundation model training that leverages the collective compute of sparingly used connected edge AI devices. We present the rationale behind our vision, particularly in support of its sustainability benefit. We further outline a set of challenges that need to be addressed to turn this vision into reality.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Co-Optimizing Reconfigurable Environments and Policies for Decentralized Multi-Agent Navigation</title>
<link>https://arxiv.org/abs/2403.14583</link>
<guid>https://arxiv.org/abs/2403.14583</guid>
<content:encoded><![CDATA[
arXiv:2403.14583v2 Announce Type: replace 
Abstract: This work views the multi-agent system and its surrounding environment as a co-evolving system, where the behavior of one affects the other. The goal is to take both agent actions and environment configurations as decision variables, and optimize these two components in a coordinated manner to improve some measure of interest. Towards this end, we consider the problem of decentralized multi-agent navigation in a cluttered environment, where we assume that the layout of the environment is reconfigurable. By introducing two sub-objectives -- multi-agent navigation and environment optimization -- we propose an agent-environment co-optimization problem and develop a coordinated algorithm that alternates between these sub-objectives to search for an optimal synthesis of agent actions and environment configurations; ultimately, improving the navigation performance. Due to the challenge of explicitly modeling the relation between the agents, the environment and their performance therein, we leverage policy gradient to formulate a model-free learning mechanism within the coordinated framework. A formal convergence analysis shows that our coordinated algorithm tracks the local minimum solution of an associated time-varying non-convex optimization problem. Experiments corroborate theoretical findings and show the benefits of co-optimization. Interestingly, the results also indicate that optimized environments can offer structural guidance to de-conflict agents in motion.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Trade-off between Flatness and Optimization in Distributed Learning</title>
<link>https://arxiv.org/abs/2406.20006</link>
<guid>https://arxiv.org/abs/2406.20006</guid>
<content:encoded><![CDATA[
arXiv:2406.20006v2 Announce Type: replace 
Abstract: This paper proposes a theoretical framework to evaluate and compare the performance of stochastic gradient algorithms for distributed learning in relation to their behavior around local minima in nonconvex environments. Previous works have noticed that convergence toward flat local minima tend to enhance the generalization ability of learning algorithms. This work discovers three interesting results. First, it shows that decentralized learning strategies are able to escape faster away from local minima and favor convergence toward flatter minima relative to the centralized solution. Second, in decentralized methods, the consensus strategy has a worse excess-risk performance than diffusion, giving it a better chance of escaping from local minima and favoring flatter minima. Third, and importantly, the ultimate classification accuracy is not solely dependent on the flatness of the local minimum but also on how well a learning algorithm can approach that minimum. In other words, the classification accuracy is a function of both flatness and optimization performance. In this regard, since diffusion has a lower excess-risk than consensus, when both algorithms are trained starting from random initial points, diffusion enhances the classification accuracy. The paper examines the interplay between the two measures of flatness and optimization error closely. One important conclusion is that decentralized strategies deliver in general enhanced classification accuracy because they strike a more favorable balance between flatness and optimization performance compared to the centralized solution.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Thunderbolt: Concurrent Smart Contract Execution with Non-blocking Reconfiguration for Sharded DAGs</title>
<link>https://arxiv.org/abs/2407.09409</link>
<guid>https://arxiv.org/abs/2407.09409</guid>
<content:encoded><![CDATA[
arXiv:2407.09409v5 Announce Type: replace 
Abstract: Sharding has emerged as a critical technique for enhancing blockchain system scalability. However, existing sharding approaches face unique challenges when applied to Directed Acyclic Graph (DAG)-based protocols that integrate expressive smart contract processing. Current solutions predominantly rely on coordination mechanisms like 2PC and require transaction read/write sets to optimize parallel execution. These requirements introduce two fundamental limitations: 1) additional coordination phases incur latency overhead, and 2) pre-declaration of read/write sets proves impractical for Turing-complete smart contracts with dynamic access patterns.
  This paper presents Thunderbolt, a novel sharding architecture for both single-shard transactions (Single-shard TXs) and cross-shard transactions (Cross-shard TXs) and enables nonblocking reconfiguration to ensure system liveness. Our design introduces 4 key innovations: 1) each replica serves dual roles as a full-shard representative and transaction proposer, employing the Execution-Order-Validation (EOV) model for Single-shard TXs and Order-Execution (OE) model for Cross-shard TXs. 2) we develop a DAG-based coordination protocol that establishes deterministic ordering between two transaction types while preserving concurrent execution capabilities. 3) we implement a dynamic concurrency controller that schedules Single-shard TXs without requiring prior knowledge of read/write sets, enabling runtime dependency resolution. 4) Thunderbolt introduces a nonblocking shard reconfiguration mechanism to address censorship attacks by featuring frequent shard re-assignment without impeding the construction of DAG nor blocking consensus. Thunderbolt achieves a 50x throughput improvement with 64 replicas compared to serial execution in the Tusk framework.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>V3rified: Revelation vs Non-Revelation Mechanisms for Decentralized Verifiable Computation</title>
<link>https://arxiv.org/abs/2408.07177</link>
<guid>https://arxiv.org/abs/2408.07177</guid>
<content:encoded><![CDATA[
arXiv:2408.07177v2 Announce Type: replace 
Abstract: In the era of Web3, decentralized technologies have emerged as the cornerstone of a new digital paradigm. Backed by a decentralized blockchain architecture, the Web3 space aims to democratize all aspects of the web. From data-sharing to learning models, outsourcing computation is an established, prevalent practice. Verifiable computation makes this practice trustworthy as clients/users can now efficiently validate the integrity of a computation. As verifiable computation gets considered for applications in the Web3 space, decentralization is crucial for system reliability, ensuring that no single entity can suppress clients. At the same time, however, decentralization needs to be balanced with efficiency: clients want their computations done as quickly as possible.
  Motivated by these issues, we study the trade-off between decentralization and efficiency when outsourcing computational tasks to strategic, rational solution providers. Specifically, we examine this trade-off when the client employs (1) revelation mechanisms, i.e. auctions, where solution providers bid their desired reward for completing the task by a specific deadline and then the client selects which of them will do the task and how much they will be rewarded, and (2) simple, non-revelation mechanisms, where the client commits to the set of rules she will use to map solutions at specific times to rewards and then solution providers decide whether they want to do the task or not. We completely characterize the power and limitations of revelation and non-revelation mechanisms in our model.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Traffic Signal Control based on Multi-Agent Reinforcement Learning. Case Study on a simulated real-world corridor</title>
<link>https://arxiv.org/abs/2503.02189</link>
<guid>https://arxiv.org/abs/2503.02189</guid>
<content:encoded><![CDATA[
arXiv:2503.02189v4 Announce Type: replace 
Abstract: Previous studies that have formulated multi-agent reinforcement learning (RL) algorithms for adaptive traffic signal control have primarily used value-based RL methods. However, recent literature has shown that policy-based methods may perform better in partially observable environments. Additionally, RL methods remain largely untested for real-world normally signal timing plans because of the simplifying assumptions common in the literature. The current study attempts to address these gaps and formulates a multi-agent proximal policy optimization (MA-PPO) algorithm to implement adaptive and coordinated traffic control along an arterial corridor. The formulated MA-PPO has a centralized-critic architecture under a centralized training and decentralized execution framework. Agents are designed to allow selection and implementation of up to eight signal phases, as commonly implemented in field controllers. The formulated algorithm is tested on a simulated real-world seven intersection corridor. The speed of convergence for each agent was found to depend on the size of the action space, which depends on the number and sequence of signal phases. The performance of the formulated MA-PPO adaptive control algorithm is compared with the field implemented actuated-coordinated signal control (ASC), modeled using PTV-Vissim-MaxTime software in the loop simulation (SILs). The trained MA-PPO performed significantly better than the ASC for all movements. Compared to ASC the MA-PPO showed 2% and 24% improvements in travel time in the primary and secondary coordination directions, respectively. For cross streets movements MA-PPO also showed significant crossing time reductions. Volume sensitivity experiments revealed that the formulated MA-PPO demonstrated good stability, robustness, and adaptability to changes in traffic demand.
]]></content:encoded>
<pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets</title>
<link>https://arxiv.org/abs/2507.00096</link>
<guid>https://arxiv.org/abs/2507.00096</guid>
<content:encoded><![CDATA[
arXiv:2507.00096v1 Announce Type: new 
Abstract: Alternative Assets tokenization is transforming non-traditional financial instruments are represented and traded on the web. However, ensuring trustworthiness in web-based tokenized ecosystems poses significant challenges, from verifying off-chain asset data to enforcing regulatory compliance. This paper proposes an AI-governed agent architecture that integrates intelligent agents with blockchain to achieve web-trustworthy tokenization of alternative assets. In the proposed architecture, autonomous agents orchestrate the tokenization process (asset verification, valuation, compliance checking, and lifecycle management), while an AI-driven governance layer monitors agent behavior and enforces trust through adaptive policies and cryptoeconomic incentives. We demonstrate that this approach enhances transparency, security, and compliance in asset tokenization, addressing key concerns around data authenticity and fraud. A case study on tokenizing real estate assets illustrates how the architecture mitigates risks (e.g., fraudulent listings and money laundering) through real-time AI anomaly detection and on-chain enforcement. Our evaluation and analysis suggest that combining AI governance with multi-agent systems and blockchain can significantly bolster trust in tokenized asset ecosystems. This work offers a novel framework for trustworthy asset tokenization on the web and provides insights for practitioners aiming to deploy secure, compliant tokenization platforms.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intellectual Property Rights and Entrepreneurship in the NFT Ecosystem: Legal Frameworks, Business Models, and Innovation Opportunities</title>
<link>https://arxiv.org/abs/2507.00172</link>
<guid>https://arxiv.org/abs/2507.00172</guid>
<content:encoded><![CDATA[
arXiv:2507.00172v1 Announce Type: new 
Abstract: Non Fungible Tokens have changed digital ownership and how creators earn money. Between 2021 and 2024, the market value exceeded 40 billion. However, the fast growth of the NFT ecosystem has revealed serious issues in managing intellectual property rights. There is a lot of confusion about the difference between owning an NFT and owning the copyright for the underlying content. This research looks at the gap between traditional copyright laws and blockchain-based transactions. We use a mixed methods approach to analyze this disconnect. We create a new IP rights matrix that clearly shows how copyright law relates to NFT ownership structures. Additionally, we include a business model taxonomy that sorts new commercial applications by their IP risk and sustainability factors. By examining important legal cases, smart contracts, and interviews with stakeholders, we find key problems in enforcing laws across different regions, standardizing licenses, and assessing business opportunities.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Multi-Agent Reinforcement Learning Approach for Elastic Cloud Resource Scaling</title>
<link>https://arxiv.org/abs/2507.00550</link>
<guid>https://arxiv.org/abs/2507.00550</guid>
<content:encoded><![CDATA[
arXiv:2507.00550v1 Announce Type: new 
Abstract: This paper addresses the challenges of rapid resource variation and highly uncertain task loads in cloud computing environments. It proposes an optimization method for elastic cloud resource scaling based on a multi-agent system. The method deploys multiple autonomous agents to perceive resource states in parallel and make local decisions. While maintaining the distributed nature of the system, it introduces a collaborative value function to achieve global coordination. This improves the responsiveness of resource scheduling and enhances overall system performance. To strengthen system foresight, a lightweight state prediction model is designed. It assists agents in identifying future workload trends and optimizes the selection of scaling actions. For policy training, the method adopts a centralized training and decentralized execution reinforcement learning framework. This enables agents to learn effectively and coordinate strategies under conditions of incomplete information. The paper also constructs typical cloud scenarios, including multi-tenancy and burst traffic, to evaluate the proposed method. The evaluation focuses on resource isolation, service quality assurance, and robustness. Experimental results show that the proposed multi-agent scaling strategy outperforms existing methods in resource utilization, SLA violation control, and scheduling latency. The results demonstrate strong adaptability and intelligent regulation. This provides an efficient and reliable new approach to solving the problem of elastic resource scaling in complex cloud platforms.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Pliable Index Coding For Federated Learning In Intelligent Transportation Systems</title>
<link>https://arxiv.org/abs/2507.00643</link>
<guid>https://arxiv.org/abs/2507.00643</guid>
<content:encoded><![CDATA[
arXiv:2507.00643v1 Announce Type: new 
Abstract: Federated Learning is a promising option for data privacy and security in ITS, because it allows edge devices, Road Side Units (RSUs), and Central Server (CS) to jointly train the machine learning model. Since RSU collects data from the vehicles passing through its range, the local data of each RSU will have a non-IID distribution, which adversely affects the convergence speed and accuracy of FL training. Generating synthetic data locally at individual nodes, followed by data shuffling among the nodes, is a promising approach to address the Non-IID data problem. In this work, we propose pliable index coding (PIC) solutions for efficient data shuffling among the nodes in an FL system. In PIC($S$) problems, a client is satisfied if it can retrieve any $S$ new messages not originally present in its side-information. We particularly consider decentralized pliable index coding problems (DPIC) where the clients communicate among themselves without a central server to model the data shuffling in FL. A class of DPIC, known as Consecutive Decentralized Pliable Index Coding (CDPIC($S$,$K$)), where each client has $K$ consecutive messages as side-information, is considered. For CDPIC($S$,$K$) problems, pliable index code designs are provided for any value of $K$ and $S$, and optimality proofs for some of the cases are established. Further, these CDPIC solutions are applied for data shuffling in FL, to transform the local data distribution towards IID progressively with each transmission, thereby enhancing the performance of FL. The improvement in the accuracy and convergence of the most popular FL technique, FedAvg, and a promising federated submodel technique, CELL (Communication Efficient Lottery Learning), are analysed by providing different degrees of data shuffling using the proposed CDPIC schemes.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PANDAS: Peer-to-peer, Adaptive Networking for Data Availability Sampling within Ethereum Consensus Timebounds</title>
<link>https://arxiv.org/abs/2507.00824</link>
<guid>https://arxiv.org/abs/2507.00824</guid>
<content:encoded><![CDATA[
arXiv:2507.00824v1 Announce Type: new 
Abstract: Layer-2 protocols can assist Ethereum's limited throughput, but globally broadcasting layer-2 data limits their scalability. The Danksharding evolution of Ethereum aims to support the selective distribution of layer-2 data, whose availability in the network is verified using randomized data availability sampling (DAS). Integrating DAS into Ethereum's consensus process is challenging, as pieces of layer-2 data must be disseminated and sampled within four seconds of the beginning of each consensus slot. No existing solution can support dissemination and sampling under such strict time bounds.
  We propose PANDAS, a practical approach to integrate DAS with Ethereum under Danksharding's requirements without modifying its protocols for consensus and node discovery. PANDAS disseminates layer-2 data and samples its availability using lightweight, direct exchanges. Its design accounts for message loss, node failures, and unresponsive participants while anticipating the need to scale out the Ethereum network. Our evaluation of PANDAS's prototype in a 1,000-node cluster and simulations for up to 20,000 peers shows that it allows layer-2 data dissemination and sampling under planetary-scale latencies within the 4-second deadline.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Correlated Equilibrium: Definition and Computation</title>
<link>https://arxiv.org/abs/2311.17592</link>
<guid>https://arxiv.org/abs/2311.17592</guid>
<content:encoded><![CDATA[
arXiv:2311.17592v2 Announce Type: replace 
Abstract: We study N-player finite games with costs perturbed due to time-varying disturbances in the underlying system and to that end, we propose the concept of Robust Correlated Equilibrium that generalizes the definition of Correlated Equilibrium. Conditions under which the Robust Correlated Equilibrium exists are specified, and a decentralized algorithm for learning strategies that are optimal in the sense of Robust Correlated Equilibrium is proposed. The primary contribution of the paper is the convergence analysis of the algorithm and to that end, we propose a modification of the celebrated Blackwell's Approachability theorem to games with costs that are not just time-average, as in the original Blackwell's Approachability Theorem, but also include the time-average of previous algorithm iterates. The designed algorithm is applied to a practical water distribution network with pumps being the controllers and their costs being perturbed by uncertain consumption due to the consumers. Simulation results show that each controller achieves no regret, and empirical distributions converge to the Robust Correlated Equilibrium.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship</title>
<link>https://arxiv.org/abs/2506.22497</link>
<guid>https://arxiv.org/abs/2506.22497</guid>
<content:encoded><![CDATA[
arXiv:2506.22497v1 Announce Type: new 
Abstract: This paper reconceptualises peer review as structured public commentary. Traditional academic validation is hindered by anonymity, latency, and gatekeeping. We propose a transparent, identity-linked, and reproducible system of scholarly evaluation anchored in open commentary. Leveraging blockchain for immutable audit trails and AI for iterative synthesis, we design a framework that incentivises intellectual contribution, captures epistemic evolution, and enables traceable reputational dynamics. This model empowers fields from computational science to the humanities, reframing academic knowledge as a living process rather than a static credential.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning</title>
<link>https://arxiv.org/abs/2506.22506</link>
<guid>https://arxiv.org/abs/2506.22506</guid>
<content:encoded><![CDATA[
arXiv:2506.22506v1 Announce Type: new 
Abstract: Federated Prompt Learning has emerged as a communication-efficient and privacy-preserving paradigm for adapting large vision-language models like CLIP across decentralized clients. However, the security implications of this setup remain underexplored. In this work, we present the first study of backdoor attacks in Federated Prompt Learning. We show that when malicious clients inject visually imperceptible, learnable noise triggers into input images, the global prompt learner becomes vulnerable to targeted misclassification while still maintaining high accuracy on clean inputs. Motivated by this vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters poisoned prompt updates using an embedding-space anomaly detector trained offline on out-of-distribution data. SABRE-FL requires no access to raw client data or labels and generalizes across diverse datasets. We show, both theoretically and empirically, that malicious clients can be reliably identified and filtered using an embedding-based detector. Across five diverse datasets and four baseline defenses, SABRE-FL outperforms all baselines by significantly reducing backdoor accuracy while preserving clean accuracy, demonstrating strong empirical performance and underscoring the need for robust prompt learning in future federated systems.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization</title>
<link>https://arxiv.org/abs/2506.22606</link>
<guid>https://arxiv.org/abs/2506.22606</guid>
<content:encoded><![CDATA[
arXiv:2506.22606v1 Announce Type: new 
Abstract: In the current paradigm of digital personalized services, the centralized management of personal data raises significant privacy concerns, security vulnerabilities, and diminished individual autonomy over sensitive information. Despite their efficiency, traditional centralized architectures frequently fail to satisfy rigorous privacy requirements and expose users to data breaches and unauthorized access risks. This pressing challenge calls for a fundamental paradigm shift in methodologies for collecting, storing, and utilizing personal data across diverse sectors, including education, healthcare, and finance.
  This paper introduces a novel decentralized, privacy-preserving architecture that handles heterogeneous personal information, ranging from educational credentials to health records and financial data. Unlike traditional models, our system grants users complete data ownership and control, allowing them to selectively share information without compromising privacy. The architecture's foundation comprises advanced privacy-enhancing technologies, including secure enclaves and federated learning, enabling secure computation, verification, and data sharing. The system supports diverse functionalities, including local computation, model training, and privacy-preserving data sharing, while ensuring data credibility and robust user privacy.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets</title>
<link>https://arxiv.org/abs/2506.22708</link>
<guid>https://arxiv.org/abs/2506.22708</guid>
<content:encoded><![CDATA[
arXiv:2506.22708v1 Announce Type: new 
Abstract: Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for decentralized market regulation, yet existing approaches often lack robust frameworks to ensure fairness. This paper presents FairMarket-RL, a novel hybrid framework that combines Large Language Models (LLMs) with Reinforcement Learning (RL) to enable fairness-aware trading agents. In a simulated P2P microgrid with multiple sellers and buyers, the LLM acts as a real-time fairness critic, evaluating each trading episode using two metrics: Fairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness scores are integrated into agent rewards through scheduled {\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that replaces brittle, rule-based fairness constraints. Agents are trained using Independent Proximal Policy Optimization (IPPO) and achieve equitable outcomes, fulfilling over 90% of buyer demand, maintaining fair seller margins, and consistently reaching FTB and FBS scores above 0.80. The training process demonstrates that fairness feedback improves convergence, reduces buyer shortfalls, and narrows profit disparities between sellers. With its language-based critic, the framework scales naturally, and its extension to a large power distribution system with household prosumers illustrates its practical applicability. FairMarket-RL thus offers a scalable, equity-driven solution for autonomous trading in decentralized energy systems.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trusted Routing for Blockchain-Enabled Low-Altitude Intelligent Networks</title>
<link>https://arxiv.org/abs/2506.22745</link>
<guid>https://arxiv.org/abs/2506.22745</guid>
<content:encoded><![CDATA[
arXiv:2506.22745v1 Announce Type: new 
Abstract: Due to the scalability and portability, the low-altitude intelligent networks (LAINs) are essential in various fields such as surveillance and disaster rescue. However, in LAINs, unmanned aerial vehicles (UAVs) are characterized by the distributed topology and high dynamic mobility, and vulnerable to security threats, which may degrade the routing performance for data transmission. Hence, how to ensure the routing stability and security of LAINs is a challenge. In this paper, we focus on the routing process in LAINs with multiple UAV clusters and propose the blockchain-enabled zero-trust architecture to manage the joining and exiting of UAVs. Furthermore, we formulate the routing problem to minimize the end-to-end (E2E) delay, which is an integer linear programming and intractable to solve. Therefore, considering the distribution of LAINs, we reformulate the routing problem into a decentralized partially observable Markov decision process. With the proposed soft hierarchical experience replay buffer, the multi-agent double deep Q-network based adaptive routing algorithm is designed. Finally, simulations are conducted and numerical results show that the total E2E delay of the proposed mechanism decreases by 22.38\% than the benchmark on average.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Momentum-based Accelerated Algorithm for Distributed Optimization under Sector-Bound Nonlinearity</title>
<link>https://arxiv.org/abs/2506.22855</link>
<guid>https://arxiv.org/abs/2506.22855</guid>
<content:encoded><![CDATA[
arXiv:2506.22855v1 Announce Type: new 
Abstract: Distributed optimization advances centralized machine learning methods by enabling parallel and decentralized learning processes over a network of computing nodes. This work provides an accelerated consensus-based distributed algorithm for locally non-convex optimization using the gradient-tracking technique. The proposed algorithm (i) improves the convergence rate by adding momentum towards the optimal state using the heavy-ball method, while (ii) addressing general sector-bound nonlinearities over the information-sharing network. The link nonlinearity includes any sign-preserving odd sector-bound mapping, for example, log-scale data quantization or clipping in practical applications. For admissible momentum and gradient-tracking parameters, using perturbation theory and eigen-spectrum analysis, we prove convergence even in the presence of sector-bound nonlinearity and for locally non-convex cost functions. Further, in contrast to most existing weight-stochastic algorithms, we adopt weight-balanced (WB) network design. This WB design and perturbation-based analysis allow to handle dynamic directed network of agents to address possible time-varying setups due to link failures or packet drops.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems</title>
<link>https://arxiv.org/abs/2506.22971</link>
<guid>https://arxiv.org/abs/2506.22971</guid>
<content:encoded><![CDATA[
arXiv:2506.22971v1 Announce Type: new 
Abstract: This paper presents a two-timescale hierarchical decentralized architecture for control of Cyber-Physical Systems. The architecture consists of $N$ independent sub-processes, a global controller, and $N$ local controllers, each formulated as a Markov Decision Process (MDP). The global controller, operating at a slower timescale optimizes the infinite-horizon discounted cumulative reward under budget constraints. For the local controllers, operating at a faster timescale, we propose two different optimization frameworks, namely the COpt and FOpt. In the COpt framework, the local controller also optimizes an infinite-horizon MDP, while in the FOpt framework, the local controller optimizes a finite-horizon MDP. The FOpt framework mimics a federal structure, where the local controllers have more autonomy in their decision making. First, the existence of stationary deterministic optimal policies for both these frameworks is established. Then, various relationships between the two frameworks are studied, including a bound on the difference between the two optimal value functions. Additionally, sufficiency conditions are provided such that the two frameworks lead to the same optimal values.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Reinforcement Learning Approach for Optimal Control in Microgrids</title>
<link>https://arxiv.org/abs/2506.22995</link>
<guid>https://arxiv.org/abs/2506.22995</guid>
<content:encoded><![CDATA[
arXiv:2506.22995v1 Announce Type: new 
Abstract: The increasing integration of renewable energy sources (RESs) is transforming traditional power grid networks, which require new approaches for managing decentralized energy production and consumption. Microgrids (MGs) provide a promising solution by enabling localized control over energy generation, storage, and distribution. This paper presents a novel reinforcement learning (RL)-based methodology for optimizing microgrid energy management. Specifically, we propose an RL agent that learns optimal energy trading and storage policies by leveraging historical data on energy production, consumption, and market prices. A digital twin (DT) is used to simulate the energy storage system dynamics, incorporating degradation factors to ensure a realistic emulation of the analysed setting. Our approach is validated through an experimental campaign using real-world data from a power grid located in the Italian territory. The results indicate that the proposed RL-based strategy outperforms rule-based methods and existing RL benchmarks, offering a robust solution for intelligent microgrid management.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FastSet: Parallel Claim Settlement</title>
<link>https://arxiv.org/abs/2506.23395</link>
<guid>https://arxiv.org/abs/2506.23395</guid>
<content:encoded><![CDATA[
arXiv:2506.23395v1 Announce Type: new 
Abstract: FastSet is an actor-based distributed protocol for decentralized finance and settlement, which is inspired from blockchains. Account holders cooperate by making claims, which can include payments, holding and transferring assets, accessing and updating shared data, medical records, digital identity, and mathematical theorems, among many others. The claims are signed by their owners and are broadcast to a decentralized network of validators, which validate and settle them. Validators replicate the global state of the accounts and need not communicate with each other. In sharp contrast to blockchains, strong consistency is purposely given up as a requirement. Yet, many if not most of the blockchain benefits are preserved. The protocol is proved to be correct, despite its massively parallel nature.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning</title>
<link>https://arxiv.org/abs/2506.23793</link>
<guid>https://arxiv.org/abs/2506.23793</guid>
<content:encoded><![CDATA[
arXiv:2506.23793v1 Announce Type: new 
Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot trajectory planning problems, where multiple homogeneous robots simultaneously move in the shared environment. While solving MAPF optimally has been proven to be NP-hard, scalable, and efficient, solvers are vital for real-world applications like logistics, search-and-rescue, etc. To this end, decentralized suboptimal MAPF solvers that leverage machine learning have come on stage. Building on the success of the recently introduced MAPF-GPT, a pure imitation learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training while significantly improving performance at test time. Our experiments demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF solvers, including the original MAPF-GPT, regarding solution quality across many testing scenarios. Remarkably, it can work with MAPF instances involving up to 1 million agents in a single environment, setting a new milestone for scalability in MAPF domains.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation</title>
<link>https://arxiv.org/abs/2506.22580</link>
<guid>https://arxiv.org/abs/2506.22580</guid>
<content:encoded><![CDATA[
arXiv:2506.22580v1 Announce Type: cross 
Abstract: Federated learning is a decentralized training approach that keeps data under stakeholder control while achieving superior performance over isolated training. While inter-institutional feature discrepancies pose a challenge in all federated settings, medical imaging is particularly affected due to diverse imaging devices and population variances, which can diminish the global model's effectiveness. Existing aggregation methods generally fail to adapt across varied circumstances. To address this, we propose FedCLAM, which integrates \textit{client-adaptive momentum} terms derived from each client's loss reduction during local training, as well as a \textit{personalized dampening factor} to curb overfitting. We further introduce a novel \textit{intensity alignment} loss that matches predicted and ground-truth foreground distributions to handle heterogeneous image intensity profiles across institutions and devices. Extensive evaluations on two datasets show that FedCLAM surpasses eight cutting-edge methods in medical segmentation tasks, underscoring its efficacy. The code is available at https://github.com/siomvas/FedCLAM.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Data Exchange at Near-Plaintext Efficiency</title>
<link>https://arxiv.org/abs/2506.14944</link>
<guid>https://arxiv.org/abs/2506.14944</guid>
<content:encoded><![CDATA[
arXiv:2506.14944v2 Announce Type: replace 
Abstract: The Fair Data Exchange (FDE) protocol (CCS '24) provides atomic pay-per-file transfers with constant-size proofs, yet existing implementations remain unscalably slow (about 1 second per 4 KiB) and inflate ciphertexts by 10--50x. We introduce an FDE implementation that achieves near-plaintext speeds and sizes, making fair exchange practical even for gigabyte-scale files.
  Our approach leverages two key insights. First, we observe that a KZG commitment to polynomial evaluations implicitly (and without modification) also binds to the Reed--Solomon (RS) codeword of its coefficients, enabling sound and efficient randomized verification. Second, while heavyweight encryption schemes such as exponential ElGamal enable compact proofs linking ciphertexts to the commitment, they are unnecessary for direct data recovery.
  Exploiting these insights, we apply a lightweight hash-derived mask to the entire RS-extended codeword, and perform ElGamal encryption only on a pseudorandom \Theta(lambda) subset of symbols, where lambda is the security parameter (e.g., 128). Data recovery occurs by simply removing the lightweight masks, with ElGamal ciphertexts serving exclusively for verification proofs. A heavyweight (but constant-time) zk-SNARK ensures consistency between these two encryption layers at sampled positions, sharply reducing bandwidth overhead and computational cost.
  In addition, we show how a constant-time (and precomputable) zk-SNARK linking a BLS12-381 secret key to a secp256k1 hash pre-image resolves Bitcoin's elliptic-curve mismatch, enabling fully off-chain execution via the Lightning Network. This can reduce transaction fees from roughly $10 to under $0.01 and shortens transaction latency from tens of seconds on Ethereum down to about a second or less.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hitchhiking Rides Dataset: Two decades of crowd-sourced records on stochastic traveling</title>
<link>https://arxiv.org/abs/2506.21946</link>
<guid>https://arxiv.org/abs/2506.21946</guid>
<content:encoded><![CDATA[
arXiv:2506.21946v1 Announce Type: new 
Abstract: Hitchhiking, a spontaneous and decentralized mode of travel, has long eluded systematic study due to its informal nature. This paper presents and analyzes the largest known structured dataset of hitchhiking rides, comprising over 63,000 entries collected over nearly two decades through platforms associated with hitchwiki.org and lately on hitchmap.com. By leveraging crowd-sourced contributions, the dataset captures key spatiotemporal and strategic aspects of hitchhiking. This work documents the dataset's origins, evolution, and community-driven maintenance, highlighting its Europe-centric distribution, seasonal patterns, and reliance on a small number of highly active contributors. Through exploratory analyses, I examine waiting times, user behavior, and comment metadata, shedding light on the lived realities of hitchhikers. While the dataset has inherent biases and limitations - such as demographic skew and unverifiable entries it offers a rare and valuable window into an alternative form of mobility. I conclude by outlining future directions for enriching the dataset and advancing research on hitchhiking as both a transportation practice and cultural phenomenon.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hyper-modal Imputation Diffusion Embedding with Dual-Distillation for Federated Multimodal Knowledge Graph Completion</title>
<link>https://arxiv.org/abs/2506.22036</link>
<guid>https://arxiv.org/abs/2506.22036</guid>
<content:encoded><![CDATA[
arXiv:2506.22036v1 Announce Type: new 
Abstract: With the increasing multimodal knowledge privatization requirements, multimodal knowledge graphs in different institutes are usually decentralized, lacking of effective collaboration system with both stronger reasoning ability and transmission safety guarantees. In this paper, we propose the Federated Multimodal Knowledge Graph Completion (FedMKGC) task, aiming at training over federated MKGs for better predicting the missing links in clients without sharing sensitive knowledge. We propose a framework named MMFeD3-HidE for addressing multimodal uncertain unavailability and multimodal client heterogeneity challenges of FedMKGC. (1) Inside the clients, our proposed Hyper-modal Imputation Diffusion Embedding model (HidE) recovers the complete multimodal distributions from incomplete entity embeddings constrained by available modalities. (2) Among clients, our proposed Multimodal FeDerated Dual Distillation (MMFeD3) transfers knowledge mutually between clients and the server with logit and feature distillation to improve both global convergence and semantic consistency. We propose a FedMKGC benchmark for a comprehensive evaluation, consisting of a general FedMKGC backbone named MMFedE, datasets with heterogeneous multimodal information, and three groups of constructed baselines. Experiments conducted on our benchmark validate the effectiveness, semantic consistency, and convergence robustness of MMFeD3-HidE.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>crypto price prediction using lstm+xgboost</title>
<link>https://arxiv.org/abs/2506.22055</link>
<guid>https://arxiv.org/abs/2506.22055</guid>
<content:encoded><![CDATA[
arXiv:2506.22055v1 Announce Type: new 
Abstract: The volatility and complex dynamics of cryptocurrency markets present unique challenges for accurate price forecasting. This research proposes a hybrid deep learning and machine learning model that integrates Long Short-Term Memory (LSTM) networks and Extreme Gradient Boosting (XGBoost) for cryptocurrency price prediction. The LSTM component captures temporal dependencies in historical price data, while XGBoost enhances prediction by modeling nonlinear relationships with auxiliary features such as sentiment scores and macroeconomic indicators. The model is evaluated on historical datasets of Bitcoin, Ethereum, Dogecoin, and Litecoin, incorporating both global and localized exchange data. Comparative analysis using Mean Absolute Percentage Error (MAPE) and Min-Max Normalized Root Mean Square Error (MinMax RMSE) demonstrates that the LSTM+XGBoost hybrid consistently outperforms standalone models and traditional forecasting methods. This study underscores the potential of hybrid architectures in financial forecasting and provides insights into model adaptability across different cryptocurrencies and market contexts.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof-of-Behavior: Behavior-Driven Consensus for Trustworthy Decentralized Finance</title>
<link>https://arxiv.org/abs/2506.22171</link>
<guid>https://arxiv.org/abs/2506.22171</guid>
<content:encoded><![CDATA[
arXiv:2506.22171v1 Announce Type: new 
Abstract: Current blockchain protocols (e.g., Proof-of-Work and Proof-of-Stake) secure the ledger yet cannot measure validator trustworthiness, allowing subtle misconduct that is especially damaging in decentralized-finance (DeFi) settings. We introduce Proof-of-Behavior (PoB), a consensus model that (i) gives each action a layered utility score -- covering motivation and outcome, (ii) adapts validator weights using recent scores, and (iii) applies decentralized verification with proportional slashing. The reward design is incentive-compatible, yielding a Nash equilibrium in which honest behavior maximizes long-run pay-offs. Simulated DeFi experiments (loan-fraud detection, reputation-weighted validation) show that PoB cuts fraud acceptance by more than 90%, demotes malicious validators within two rounds, and improves proposer fairness versus standard PoS, all with no more than a 5% throughput overhead. By linking consensus influence to verifiably trustworthy conduct, PoB offers a scalable, regulation-friendly foundation for secure and fair blockchain governance in financial applications.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reliability Analysis of Smart Contract Execution Architectures: A Comparative Simulation Study</title>
<link>https://arxiv.org/abs/2506.22180</link>
<guid>https://arxiv.org/abs/2506.22180</guid>
<content:encoded><![CDATA[
arXiv:2506.22180v1 Announce Type: new 
Abstract: The industrial market continuously needs reliable solutions to secure autonomous systems. Especially as these systems become more complex and interconnected, reliable security solutions are becoming increasingly important. One promising solution to tackle this challenge is using smart contracts designed to meet contractual conditions, avoid malicious errors, secure exchanges, and minimize the need for reliable intermediaries. However, smart contracts are immutable. Moreover, there are different smart contract execution architectures (namely Order-Execute and Execute-Order-Validate) that have different throughputs. In this study, we developed an evaluation model for assessing the security of reliable smart contract execution. We then developed a realistic smart contract enabled IoT energy case study. Finally, we simulate the developed case study to evaluate several smart contract security vulnerabilities reported in the literature. Our results show that the Execute-Order-Validate architecture is more promising regarding reliability and security.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety</title>
<link>https://arxiv.org/abs/2506.22183</link>
<guid>https://arxiv.org/abs/2506.22183</guid>
<content:encoded><![CDATA[
arXiv:2506.22183v1 Announce Type: new 
Abstract: The rapid rise of open-weight and open-source foundation models is intensifying the obligation and reshaping the opportunity to make AI systems safe. This paper reports outcomes from the Columbia Convening on AI Openness and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme involving more than forty-five researchers, engineers, and policy leaders from academia, industry, civil society, and government. Using a participatory, solutions-oriented process, the working groups produced (i) a research agenda at the intersection of safety and open source AI; (ii) a mapping of existing and needed technical interventions and open source tools to safely and responsibly deploy open foundation models across the AI development workflow; and (iii) a mapping of the content safety filter ecosystem with a proposed roadmap for future research and development. We find that openness -- understood as transparent weights, interoperable tooling, and public governance -- can enhance safety by enabling independent scrutiny, decentralized mitigation, and culturally plural oversight. However, significant gaps persist: scarce multimodal and multilingual benchmarks, limited defenses against prompt-injection and compositional attacks in agentic systems, and insufficient participatory mechanisms for communities most affected by AI harms. The paper concludes with a roadmap of five priority research directions, emphasizing participatory inputs, future-proof content filters, ecosystem-wide safety infrastructure, rigorous agentic safeguards, and expanded harm taxonomies. These recommendations informed the February 2025 French AI Action Summit and lay groundwork for an open, plural, and accountable AI safety discipline.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomic Microservice Management via Agentic AI and MAPE-K Integration</title>
<link>https://arxiv.org/abs/2506.22185</link>
<guid>https://arxiv.org/abs/2506.22185</guid>
<content:encoded><![CDATA[
arXiv:2506.22185v1 Announce Type: new 
Abstract: While microservices are revolutionizing cloud computing by offering unparalleled scalability and independent deployment, their decentralized nature poses significant security and management challenges that can threaten system stability. We propose a framework based on MAPE-K, which leverages agentic AI, for autonomous anomaly detection and remediation to address the daunting task of highly distributed system management. Our framework offers practical, industry-ready solutions for maintaining robust and secure microservices. Practitioners and researchers can customize the framework to enhance system stability, reduce downtime, and monitor broader system quality attributes such as system performance level, resilience, security, and anomaly management, among others.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Model Passport: Data and System Traceability Framework for Transparent AI in Health</title>
<link>https://arxiv.org/abs/2506.22358</link>
<guid>https://arxiv.org/abs/2506.22358</guid>
<content:encoded><![CDATA[
arXiv:2506.22358v1 Announce Type: new 
Abstract: The increasing integration of Artificial Intelligence (AI) into health and biomedical systems necessitates robust frameworks for transparency, accountability, and ethical compliance. Existing frameworks often rely on human-readable, manual documentation which limits scalability, comparability, and machine interpretability across projects and platforms. They also fail to provide a unique, verifiable identity for AI models to ensure their provenance and authenticity across systems and use cases, limiting reproducibility and stakeholder trust. This paper introduces the concept of the AI Model Passport, a structured and standardized documentation framework that acts as a digital identity and verification tool for AI models. It captures essential metadata to uniquely identify, verify, trace and monitor AI models across their lifecycle - from data acquisition and preprocessing to model design, development and deployment. In addition, an implementation of this framework is presented through AIPassport, an MLOps tool developed within the ProCAncer-I EU project for medical imaging applications. AIPassport automates metadata collection, ensures proper versioning, decouples results from source scripts, and integrates with various development environments. Its effectiveness is showcased through a lesion segmentation use case using data from the ProCAncer-I dataset, illustrating how the AI Model Passport enhances transparency, reproducibility, and regulatory readiness while reducing manual effort. This approach aims to set a new standard for fostering trust and accountability in AI-driven healthcare solutions, aspiring to serve as the basis for developing transparent and regulation compliant AI systems across domains.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems</title>
<link>https://arxiv.org/abs/2506.22374</link>
<guid>https://arxiv.org/abs/2506.22374</guid>
<content:encoded><![CDATA[
arXiv:2506.22374v1 Announce Type: new 
Abstract: In large-scale communication systems, increasingly complex scenarios require more intelligent collaboration among edge devices collecting various multimodal sensory data to achieve a more comprehensive understanding of the environment and improve decision-making accuracy. However, conventional federated learning (FL) algorithms typically consider unimodal datasets, require identical model architectures, and fail to leverage the rich information embedded in multimodal data, limiting their applicability to real-world scenarios with diverse modalities and varying client capabilities. To address this issue, we propose Sheaf-DMFL, a novel decentralized multimodal learning framework leveraging sheaf theory to enhance collaboration among devices with diverse modalities. Specifically, each client has a set of local feature encoders for its different modalities, whose outputs are concatenated before passing through a task-specific layer. While encoders for the same modality are trained collaboratively across clients, we capture the intrinsic correlations among clients' task-specific layers using a sheaf-based structure. To further enhance learning capability, we propose an enhanced algorithm named Sheaf-DMFL-Att, which tailors the attention mechanism within each client to capture correlations among different modalities. A rigorous convergence analysis of Sheaf-DMFL-Att is provided, establishing its theoretical guarantees. Extensive simulations are conducted on real-world link blockage prediction and mmWave beamforming scenarios, demonstrate the superiority of the proposed algorithms in such heterogeneous wireless communication systems.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OpenAlpha: A Community-Led Adversarial Strategy Validation Mechanism for Decentralised Capital Management</title>
<link>https://arxiv.org/abs/2506.21809</link>
<guid>https://arxiv.org/abs/2506.21809</guid>
<content:encoded><![CDATA[
arXiv:2506.21809v1 Announce Type: cross 
Abstract: We propose \textit{OpenAlpha}, a community-led strategy validation framework for decentralised capital management on a host blockchain network, which integrates game-theoretic validation, adversarial auditing, and market-based belief aggregation. This work formulates treasury deployment as a capital optimisation problem under verification costs and strategic misreporting, and operationalises it through a decision waterfall that sequences intention declaration, strategy proposal, prediction-market validation, dispute resolution, and capital allocation. Each phase of this framework's validation process embeds economic incentives to align proposer, verifier, and auditor behaviour, producing confidence scores that may feed into a capital allocation rule. While OpenAlpha is designed for capital strategy assessment, its validation mechanisms are composable and extend naturally to evaluating external decentralised applications (DApps), enabling on-chain scrutiny of DApp performance, reliability, and integration risk. This architecture allows for adaptive, trust-minimised capital deployment without reliance on centralised governance or static audits.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum</title>
<link>https://arxiv.org/abs/2311.18578</link>
<guid>https://arxiv.org/abs/2311.18578</guid>
<content:encoded><![CDATA[
arXiv:2311.18578v3 Announce Type: replace 
Abstract: Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios.However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios. In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL. We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful. Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation. Code is available at https://rickzack.github.io/GHBM.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DPLib: A Standard Benchmark Library for Distributed Power System Analysis and Optimization</title>
<link>https://arxiv.org/abs/2506.20819</link>
<guid>https://arxiv.org/abs/2506.20819</guid>
<content:encoded><![CDATA[
arXiv:2506.20819v1 Announce Type: new 
Abstract: \textit{DPLib} is an open-source MATLAB-based benchmark library created to support research and development in distributed and decentralized power system analysis and optimization. Distributed and decentralized methods offer scalability, privacy preservation, and resilience to single points of failure, making them increasingly important for modern power systems. However, unlike centralized tools such as MATPOWER, no general-purpose, reproducible data library package currently exists for distributed power system studies. DPLib fills this gap by providing a standard power system library featuring over 20 multi-region benchmark test cases of varying sizes, along with a graph-based partitioning toolkit that decomposes any MATPOWER test system into multiple electrically coherent regions. The partitioning toolkit, an easy-to-use MATLAB code, generates standardized \texttt{.mat} and \texttt{.m} files, along with region visualizations for intuitive understanding. We also provide modular, easy-to-use distributed optimal power flow (OPF) solvers: an alternating direction method of multipliers(ADMM)-based DC-OPF solver implemented in YALMIP, and an ADMM-based AC-OPF solver leveraging IPOPT. These solvers validate the generated test systems for distributed optimization applications. Numerical results validate the generated test cases, establishing DPLib as a foundation for reproducible distributed power system research.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BLOCKS: Blockchain-supported Cross-Silo Knowledge Sharing for Efficient LLM Services</title>
<link>https://arxiv.org/abs/2506.21033</link>
<guid>https://arxiv.org/abs/2506.21033</guid>
<content:encoded><![CDATA[
arXiv:2506.21033v1 Announce Type: new 
Abstract: The hallucination problem of Large Language Models (LLMs) has increasingly drawn attention. Augmenting LLMs with external knowledge is a promising solution to address this issue. However, due to privacy and security concerns, a vast amount of downstream task-related knowledge remains dispersed and isolated across various "silos," making it difficult to access. To bridge this knowledge gap, we propose a blockchain-based external knowledge framework that coordinates multiple knowledge silos to provide reliable foundational knowledge for large model retrieval while ensuring data security. Technically, we distill knowledge from local data into prompts and execute transactions and records on the blockchain. Additionally, we introduce a reputation mechanism and cross-validation to ensure knowledge quality and provide incentives for participation. Furthermore, we design a query generation framework that provides a direct API interface for large model retrieval. To evaluate the performance of our proposed framework, we conducted extensive experiments on various knowledge sources. The results demonstrate that the proposed framework achieves efficient LLM service knowledge sharing in blockchain environments.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Post-Quantum and Blockchain-Based Attestation for Trusted FPGAs in B5G Networks</title>
<link>https://arxiv.org/abs/2506.21073</link>
<guid>https://arxiv.org/abs/2506.21073</guid>
<content:encoded><![CDATA[
arXiv:2506.21073v1 Announce Type: new 
Abstract: The advent of 5G and beyond has brought increased performance networks, facilitating the deployment of services closer to the user. To meet performance requirements such services require specialized hardware, such as Field Programmable Gate Arrays (FPGAs). However, FPGAs are often deployed in unprotected environments, leaving the user's applications vulnerable to multiple attacks. With the rise of quantum computing, which threatens the integrity of widely-used cryptographic algorithms, the need for a robust security infrastructure is even more crucial. In this paper we introduce a hybrid hardware-software solution utilizing remote attestation to securely configure FPGAs, while integrating Post-Quantum Cryptographic (PQC) algorithms for enhanced security. Additionally, to enable trustworthiness across the whole edge computing continuum, our solution integrates a blockchain infrastructure, ensuring the secure storage of any security evidence. We evaluate the proposed secure configuration process under different PQC algorithms in two FPGA families, showcasing only 2% overheard compared to the non PQC approach.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion</title>
<link>https://arxiv.org/abs/2506.21144</link>
<guid>https://arxiv.org/abs/2506.21144</guid>
<content:encoded><![CDATA[
arXiv:2506.21144v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized clients without sharing local data, but is challenged by heterogeneity in data, computation, and communication. Pretrained vision-language models (VLMs), with their strong generalization and lightweight tuning via prompts, offer a promising solution. However, existing federated prompt-learning methods rely only on text prompts and overlook joint label-domain distribution shifts. In this paper, we propose a personalized FL framework based on dual-prompt learning and cross fusion, termed pFedDC. Specifically, each client maintains both global and local prompts across vision and language modalities: global prompts capture common knowledge shared across the federation, while local prompts encode client-specific semantics and domain characteristics. Meanwhile, a cross-fusion module is designed to adaptively integrate prompts from different levels, enabling the model to generate personalized representations aligned with each client's unique data distribution. Extensive experiments across nine datasets with various types of heterogeneity show that pFedDC consistently outperforms state-of-the-art methods.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster</title>
<link>https://arxiv.org/abs/2506.21263</link>
<guid>https://arxiv.org/abs/2506.21263</guid>
<content:encoded><![CDATA[
arXiv:2506.21263v1 Announce Type: new 
Abstract: The distributed training of foundation models, particularly large language models (LLMs), demands a high level of communication. Consequently, it is highly dependent on a centralized cluster with fast and reliable interconnects. Can we conduct training on slow networks and thereby unleash the power of decentralized clusters when dealing with models exceeding 100 billion parameters? In this paper, we propose DiLoCoX, a low-communication large-scale decentralized cluster training framework. It combines Pipeline Parallelism with Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local Training, and an Adaptive Gradient Compression Scheme. This combination significantly improves the scale of parameters and the speed of model pre-training. We justify the benefits of one-step-delay overlap of communication and local training, as well as the adaptive gradient compression scheme, through a theoretical analysis of convergence. Empirically, we demonstrate that DiLoCoX is capable of pre-training a 107B foundation model over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x speedup in distributed training while maintaining negligible degradation in model convergence. To the best of our knowledge, this is the first decentralized training framework successfully applied to models with over 100 billion parameters.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enabling Bitcoin Smart Contracts on the Internet Computer</title>
<link>https://arxiv.org/abs/2506.21327</link>
<guid>https://arxiv.org/abs/2506.21327</guid>
<content:encoded><![CDATA[
arXiv:2506.21327v1 Announce Type: new 
Abstract: There is growing interest in providing programmatic access to the value locked in Bitcoin, which famously offers limited programmability itself. Various approaches have been put forth in recent years, with the vast majority of proposed mechanisms either building new functionality on top of Bitcoin or leveraging a bridging mechanism to enable smart contracts that make use of ``wrapped'' bitcoins on entirely different platforms.
  In this work, an architecture is presented that follows a different approach. The architecture enables the execution of Turing-complete Bitcoin smart contracts on the Internet Computer (IC), a blockchain platform for hosting and executing decentralized applications. Instead of using a bridge, IC and Bitcoin nodes interact directly, eliminating potential security risks that the use of a bridge entails. This integration requires novel concepts, in particular to reconcile the probabilistic nature of Bitcoin with the irreversibility of finalized state changes on the IC, which may be of independent interest.
  In addition to the presentation of the architecture, we provide evaluation results based on measurements of the Bitcoin integration running on mainnet. The evaluation results demonstrate that, with finalization in a few seconds and low execution costs, this integration enables complex Bitcoin-based decentralized applications that were not practically feasible or economically viable before.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rational Miner Behaviour, Protocol Stability, and Time Preference: An Austrian and Game-Theoretic Analysis of Bitcoin's Incentive Environment</title>
<link>https://arxiv.org/abs/2506.20965</link>
<guid>https://arxiv.org/abs/2506.20965</guid>
<content:encoded><![CDATA[
arXiv:2506.20965v1 Announce Type: cross 
Abstract: This paper integrates Austrian capital theory with repeated game theory to examine strategic miner behaviour under different institutional conditions in blockchain systems. It shows that when protocol rules are mutable, effective time preference rises, undermining rational long-term planning and cooperative equilibria. Using formal game-theoretic analysis and Austrian economic principles, the paper demonstrates how mutable protocols shift miner incentives from productive investment to political rent-seeking and influence games. The original Bitcoin protocol is interpreted as an institutional anchor: a fixed rule-set enabling calculability and low time preference. Drawing on the work of Bohm-Bawerk, Mises, and Hayek, the argument is made that protocol immutability is essential for restoring strategic coherence, entrepreneurial confidence, and sustainable network equilibrium.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Institutional Noise, Strategic Deviation, and Intertemporal Collapse: A Formal Model of Miner Behaviour under Protocol Uncertainty</title>
<link>https://arxiv.org/abs/2506.20992</link>
<guid>https://arxiv.org/abs/2506.20992</guid>
<content:encoded><![CDATA[
arXiv:2506.20992v1 Announce Type: cross 
Abstract: This paper develops a formal game-theoretic model to examine how protocol mutability disrupts cooperative mining behaviour in blockchain systems. Using a repeated game framework with stochastic rule shocks, we show that even minor uncertainty in institutional rules increases time preference and induces strategic deviation. Fixed-rule environments support long-term investment and stable equilibrium strategies; in contrast, mutable protocols lead to short-termism, higher discounting, and collapse of coordinated engagement. Simulation results identify instability zones in the parameter space where rational mining gives way to extractive or arbitrage conduct. These findings support an Austrian economic interpretation: calculability requires rule stability. Institutional noise undermines the informational basis for productive action. We conclude that protocol design must be treated as a constitutional economic constraint, not a discretionary variable, if sustainable cooperation is to emerge in decentralised systems.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Federated Learning-Based IDS for Enhancing UAVs Privacy and Security</title>
<link>https://arxiv.org/abs/2312.04135</link>
<guid>https://arxiv.org/abs/2312.04135</guid>
<content:encoded><![CDATA[
arXiv:2312.04135v3 Announce Type: replace 
Abstract: Unmanned aerial vehicles (UAVs) operating within Flying Ad-hoc Networks (FANETs) encounter security challenges due to the dynamic and distributed nature of these networks. Previous studies focused predominantly on centralized intrusion detection, assuming a central entity responsible for storing and analyzing data from all devices. However, these approaches face challenges including computation and storage costs, along with a single point of failure risk, threatening data privacy and availability. The widespread dispersion of data across interconnected devices underscores the need for decentralized approaches. This paper introduces the Federated Learning-based Intrusion Detection System (FL-IDS), addressing challenges encountered by centralized systems in FANETs. FL-IDS reduces computation and storage costs for both clients and the central server, which is crucial for resource-constrained UAVs. Operating in a decentralized manner, FL-IDS enables UAVs to collaboratively train a global intrusion detection model without sharing raw data, thus avoiding delay in decisions based on collected data, as is often the case with traditional methods. Experimental results demonstrate FL-IDS's competitive performance with Central IDS (C-IDS) while mitigating privacy concerns, with the Bias Towards Specific Clients (BTSC) method further enhancing FL-IDS performance even at lower attacker ratios. Comparative analysis with traditional intrusion detection methods, including Local IDS (L-IDS), sheds light on the strengths of FL-IDS. This study significantly contributes to UAV security by introducing a privacy-aware, decentralized intrusion detection approach tailored to UAV networks. Moreover, by introducing a realistic dataset for FANETs and federated learning, our approach differs from others lacking high dynamism and 3D node movements or accurate federated data federations.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability</title>
<link>https://arxiv.org/abs/2506.19870</link>
<guid>https://arxiv.org/abs/2506.19870</guid>
<content:encoded><![CDATA[
arXiv:2506.19870v1 Announce Type: new 
Abstract: Peer-to-peer trading and the move to decentralized grids have reshaped the energy markets in the United States. Notwithstanding, such developments lead to new challenges, mainly regarding the safety and authenticity of energy trade. This study aimed to develop and build a secure, intelligent, and efficient energy transaction system for the decentralized US energy market. This research interlinks the technological prowess of blockchain and artificial intelligence (AI) in a novel way to solve long-standing challenges in the distributed energy market, specifically those of security, fraudulent behavior detection, and market reliability. The dataset for this research is comprised of more than 1.2 million anonymized energy transaction records from a simulated peer-to-peer (P2P) energy exchange network emulating real-life blockchain-based American microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record contains detailed fields of transaction identifier, timestamp, energy volume (kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier (hashed for privacy), smart meter readings, geolocation regions, and settlement confirmation status. The dataset also includes system-calculated behavior metrics of transaction rate, variability of energy production, and historical pricing patterns. The system architecture proposed involves the integration of two layers, namely a blockchain layer and artificial intelligence (AI) layer, each playing a unique but complementary function in energy transaction securing and market intelligence improvement. The machine learning models used in this research were specifically chosen for their established high performance in classification tasks, specifically in the identification of energy transaction fraud in decentralized markets.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RepuNet: A Reputation System for Mitigating Malicious Clients in DFL</title>
<link>https://arxiv.org/abs/2506.19892</link>
<guid>https://arxiv.org/abs/2506.19892</guid>
<content:encoded><![CDATA[
arXiv:2506.19892v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) enables nodes to collaboratively train models without a central server, introducing new vulnerabilities since each node independently selects peers for model aggregation. Malicious nodes may exploit this autonomy by sending corrupted models (model poisoning), delaying model submissions (delay attack), or flooding the network with excessive messages, negatively affecting system performance. Existing solutions often depend on rigid configurations or additional infrastructures such as blockchain, leading to computational overhead, scalability issues, or limited adaptability. To overcome these limitations, this paper proposes RepuNet, a decentralized reputation system that categorizes threats in DFL and dynamically evaluates node behavior using metrics like model similarity, parameter changes, message latency, and communication volume. Nodes' influence in model aggregation is adjusted based on their reputation scores. RepuNet was integrated into the Nebula DFL platform and experimentally evaluated with MNIST and CIFAR-10 datasets under non-IID distributions, using federations of up to 25 nodes in both fully connected and random topologies. Different attack intensities, frequencies, and activation intervals were tested. Results demonstrated that RepuNet effectively detects and mitigates malicious behavior, achieving F1 scores above 95% for MNIST scenarios and approximately 76% for CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness, and practical potential for mitigating threats in decentralized federated learning environments.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DiT-SGCR: Directed Temporal Structural Representation with Global-Cluster Awareness for Ethereum Malicious Account Detection</title>
<link>https://arxiv.org/abs/2506.20123</link>
<guid>https://arxiv.org/abs/2506.20123</guid>
<content:encoded><![CDATA[
arXiv:2506.20123v1 Announce Type: new 
Abstract: The detection of malicious accounts on Ethereum - the preeminent DeFi platform - is critical for protecting digital assets and maintaining trust in decentralized finance. Recent advances highlight that temporal transaction evolution reveals more attack signatures than static graphs. However, current methods either fail to model continuous transaction dynamics or incur high computational costs that limit scalability to large-scale transaction networks. Furthermore, current methods fail to consider two higher-order behavioral fingerprints: (1) direction in temporal transaction flows, which encodes money movement trajectories, and (2) account clustering, which reveals coordinated behavior of organized malicious collectives. To address these challenges, we propose DiT-SGCR, an unsupervised graph encoder for malicious account detection. Specifically, DiT-SGCR employs directional temporal aggregation to capture dynamic account interactions, then coupled with differentiable clustering and graph Laplacian regularization to generate high-quality, low-dimensional embeddings. Our approach simultaneously encodes directional temporal dynamics, global topology, and cluster-specific behavioral patterns, thereby enhancing the discriminability and robustness of account representations. Furthermore, DiT-SGCR bypasses conventional graph propagation mechanisms, yielding significant scalability advantages. Extensive experiments on three datasets demonstrate that DiT-SGCR consistently outperforms state-of-the-art methods across all benchmarks, achieving F1-score improvements ranging from 3.62% to 10.83%.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data</title>
<link>https://arxiv.org/abs/2506.20245</link>
<guid>https://arxiv.org/abs/2506.20245</guid>
<content:encoded><![CDATA[
arXiv:2506.20245v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized collaborative machine learning (ML) technique. It provides a solution to the issues of isolated data islands and data privacy leakage in industrial ML practices. One major challenge in FL is handling the non-identical and independent distributed (non-IID) data. Current solutions either focus on constructing an all-powerful global model, or customizing personalized local models. Few of them can provide both a well-generalized global model and well-performed local models at the same time. Additionally, many FL solutions to the non-IID problem are benefited from introducing public datasets. However, this will also increase the risk of data leakage. To tackle the problems, we propose a novel data-free distillation framework, Federated Bidirectional Knowledge Distillation (FedBKD). Specifically, we train Generative Adversarial Networks (GAN) for synthetic data. During the GAN training, local models serve as discriminators and their parameters are frozen. The synthetic data is then used for bidirectional distillation between global and local models to achieve knowledge interactions so that performances for both sides are improved. We conduct extensive experiments on 4 benchmarks under different non-IID settings. The results show that FedBKD achieves SOTA performances in every case.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning</title>
<link>https://arxiv.org/abs/2506.20413</link>
<guid>https://arxiv.org/abs/2506.20413</guid>
<content:encoded><![CDATA[
arXiv:2506.20413v1 Announce Type: new 
Abstract: The growing adoption of Artificial Intelligence (AI) in Internet of Things (IoT) ecosystems has intensified the need for personalized learning methods that can operate efficiently and privately across heterogeneous, resource-constrained devices. However, enabling effective personalized learning in decentralized settings introduces several challenges, including efficient knowledge transfer between clients, protection of data privacy, and resilience against poisoning attacks. In this paper, we address these challenges by developing P4 (Personalized, Private, Peer-to-Peer) -- a method designed to deliver personalized models for resource-constrained IoT devices while ensuring differential privacy and robustness against poisoning attacks. Our solution employs a lightweight, fully decentralized algorithm to privately detect client similarity and form collaborative groups. Within each group, clients leverage differentially private knowledge distillation to co-train their models, maintaining high accuracy while ensuring robustness to the presence of malicious clients. We evaluate P4 on popular benchmark datasets using both linear and CNN-based architectures across various heterogeneity settings and attack scenarios. Experimental results show that P4 achieves 5% to 30% higher accuracy than leading differentially private peer-to-peer approaches and maintains robustness with up to 30% malicious clients. Additionally, we demonstrate its practicality by deploying it on resource-constrained devices, where collaborative training between two clients adds only ~7 seconds of overhead.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Batch Size Optimization for Federated Learning</title>
<link>https://arxiv.org/abs/2506.20511</link>
<guid>https://arxiv.org/abs/2506.20511</guid>
<content:encoded><![CDATA[
arXiv:2506.20511v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized collaborative Machine Learning framework for training models without collecting data in a centralized location. It has seen application across various disciplines, from helping medical diagnoses in hospitals to detecting fraud in financial transactions. In this paper, we focus on improving the local training process through hardware usage optimization. While participants in a federation might share the hardware they are training on, since there is no information exchange between them, their training process can be hindered by an improper training configuration. Taking advantage of the parallel processing inherent to Federated Learning, we use a greedy randomized search to optimize local batch sizes for the best training settings across all participants. Our results show that against default parameter settings, our method improves convergence speed while staying nearly on par with the case where local parameters are optimized.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning</title>
<link>https://arxiv.org/abs/2506.20518</link>
<guid>https://arxiv.org/abs/2506.20518</guid>
<content:encoded><![CDATA[
arXiv:2506.20518v1 Announce Type: new 
Abstract: Federated Learning (FL) is a collaborative machine learning paradigm which allows participants to collectively train a model while training data remains private. This paradigm is especially beneficial for sectors like finance, where data privacy, security and model performance are paramount. FL has been extensively studied in the years following its introduction, leading to, among others, better performing collaboration techniques, ways to defend against other clients trying to attack the model, and contribution assessment methods. An important element in for-profit Federated Learning is the development of incentive methods to determine the allocation and distribution of rewards for participants. While numerous methods for allocation have been proposed and thoroughly explored, distribution frameworks remain relatively understudied. In this paper, we propose a novel framework which introduces client-specific tokens as investment vehicles within the FL ecosystem. Our framework aims to address the limitations of existing incentive schemes by leveraging a decentralized finance (DeFi) platform and automated market makers (AMMs) to create a more flexible and scalable reward distribution system for participants, and a mechanism for third parties to invest in the federation learning process.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Encoding Process in Decentralized Systems</title>
<link>https://arxiv.org/abs/2408.15203</link>
<guid>https://arxiv.org/abs/2408.15203</guid>
<content:encoded><![CDATA[
arXiv:2408.15203v2 Announce Type: replace 
Abstract: We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed satellite information networks: Architecture, enabling technologies, and trends</title>
<link>https://arxiv.org/abs/2412.12587</link>
<guid>https://arxiv.org/abs/2412.12587</guid>
<content:encoded><![CDATA[
arXiv:2412.12587v2 Announce Type: replace 
Abstract: Driven by the vision of ubiquitous connectivity and wireless intelligence, the evolution of ultra-dense constellation-based satellite-integrated Internet is underway, now taking preliminary shape. Nevertheless, the entrenched institutional silos and limited, nonrenewable heterogeneous network resources leave current satellite systems struggling to accommodate the escalating demands of next-generation intelligent applications. In this context, the distributed satellite information networks (DSIN), exemplified by the cohesive clustered satellites system, have emerged as an innovative architecture, bridging information gaps across diverse satellite systems, such as communication, navigation, and remote sensing, and establishing a unified, open information network paradigm to support resilient space information services. This survey first provides a profound discussion about innovative network architectures of DSIN, encompassing distributed regenerative satellite network architecture, distributed satellite computing network architecture, and reconfigurable satellite formation flying, to enable flexible and scalable communication, computing and control. The DSIN faces challenges from network heterogeneity, unpredictable channel dynamics, sparse resources, and decentralized collaboration frameworks. To address these issues, a series of enabling technologies is identified, including channel modeling and estimation, cloud-native distributed MIMO cooperation, grant-free massive access, network routing, and the proper combination of all these diversity techniques. Furthermore, to heighten the overall resource efficiency, the cross-layer optimization techniques are further developed to meet upper-layer deterministic, adaptive and secure information services requirements. In addition, emerging research directions and new opportunities are highlighted on the way to achieving the DSIN vision.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AIDRIN 2.0: A Framework to Assess Data Readiness for AI</title>
<link>https://arxiv.org/abs/2505.18213</link>
<guid>https://arxiv.org/abs/2505.18213</guid>
<content:encoded><![CDATA[
arXiv:2505.18213v2 Announce Type: replace 
Abstract: AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve data preparedness for AI applications. It addresses critical data readiness dimensions such as data quality, bias, fairness, and privacy. This paper details enhancements to AIDRIN by focusing on user interface improvements and integration with a privacy-preserving federated learning (PPFL) framework. By refining the UI and enabling smooth integration with decentralized AI pipelines, AIDRIN becomes more accessible and practical for users with varying technical expertise. Integrating with an existing PPFL framework ensures that data readiness and privacy are prioritized in federated learning environments. A case study involving a real-world dataset demonstrates AIDRIN's practical value in identifying data readiness issues that impact AI model performance.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Survey of HPC in US Research Institutions</title>
<link>https://arxiv.org/abs/2506.19019</link>
<guid>https://arxiv.org/abs/2506.19019</guid>
<content:encoded><![CDATA[
arXiv:2506.19019v1 Announce Type: new 
Abstract: The rapid growth of AI, data-intensive science, and digital twin technologies has driven an unprecedented demand for high-performance computing (HPC) across the research ecosystem. While national laboratories and industrial hyperscalers have invested heavily in exascale and GPU-centric architectures, university-operated HPC systems remain comparatively under-resourced. This survey presents a comprehensive assessment of the HPC landscape across U.S. universities, benchmarking their capabilities against Department of Energy (DOE) leadership-class systems and industrial AI infrastructures. We examine over 50 premier research institutions, analyzing compute capacity, architectural design, governance models, and energy efficiency. Our findings reveal that university clusters, though vital for academic research, exhibit significantly lower growth trajectories (CAGR $\approx$ 18%) than their national ($\approx$ 43%) and industrial ($\approx$ 78%) counterparts. The increasing skew toward GPU-dense AI workloads has widened the capability gap, highlighting the need for federated computing, idle-GPU harvesting, and cost-sharing models. We also identify emerging paradigms, such as decentralized reinforcement learning, as promising opportunities for democratizing AI training within campus environments. Ultimately, this work provides actionable insights for academic leaders, funding agencies, and technology partners to ensure more equitable and sustainable HPC access in support of national research priorities.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dataset of Yul Contracts to Support Solidity Compiler Research</title>
<link>https://arxiv.org/abs/2506.19153</link>
<guid>https://arxiv.org/abs/2506.19153</guid>
<content:encoded><![CDATA[
arXiv:2506.19153v1 Announce Type: new 
Abstract: The YulCode dataset presents a comprehensive collection of 348,840 Yul-based smart contract instances, comprising approximately 135,013 unique contracts. These contracts were generated through the compilation of Solidity source files that have been deployed on the Ethereum mainnet, making the dataset directly representative of real-world decentralized applications. YulCode provides a rich foundation for a variety of research and development tasks, including but not limited to machine learning applications, formal verification, optimization analysis, and software engineering tool evaluation in the context of low-level smart contract code. To the best of our knowledge at the time of writing, YulCode is the first and only publicly available dataset that focuses specifically on Yul, an intermediate language designed for the Ethereum Virtual Machine (EVM). As such, it fills a critical gap in the current ecosystem of smart contract datasets and opens new avenues for research and tooling aimed at low-level contract analysis and generation.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GradualDiff-Fed: A Federated Learning Specialized Framework for Large Language Model</title>
<link>https://arxiv.org/abs/2506.19164</link>
<guid>https://arxiv.org/abs/2506.19164</guid>
<content:encoded><![CDATA[
arXiv:2506.19164v1 Announce Type: new 
Abstract: The rapid proliferation of large language models (LLMs) has created an unprecedented demand for fine-tuning models for specialized domains, such as medical science. While federated learning (FL) offers a decentralized and privacy-preserving approach to collaboratively fine-tune LLMs without sharing raw data, it presents significant challenges, particularly in performance and managing large model sizes efficiently. In this paper, we introduce GradualDiff-Fed, an FL framework designed explicitly for LLMs, and their challenge of handling the high parameter size. GradualDiff-Fed reduces communication costs by transmitting only the difference of model weights rather than the entire model during training rounds. Such an approach significantly improves scalability and communication efficiency, making it more feasible to fine-tune LLMs across distributed clients without compromising performance. Our evaluation demonstrates that GradualDiff-Fed achieves performance on par with centralized training while drastically reducing communication overhead. These results highlight the potential of GradualDiff-Fed as an efficient solution for fine-tuning large models from distributed data in privacy-preserving settings without comprising performance.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shelby: Decentralized Storage Designed to Serve</title>
<link>https://arxiv.org/abs/2506.19233</link>
<guid>https://arxiv.org/abs/2506.19233</guid>
<content:encoded><![CDATA[
arXiv:2506.19233v1 Announce Type: new 
Abstract: Existing decentralized storage protocols fall short of the service required by real-world applications. Their throughput, latency, cost-effectiveness, and availability are insufficient for demanding workloads such as video streaming, large-scale data analytics, or AI training. As a result, Web3 data-intensive applications are predominantly dependent on centralized infrastructure.
  Shelby is a high-performance decentralized storage protocol designed to meet demanding needs. It achieves fast, reliable access to large volumes of data while preserving decentralization guarantees. The architecture reflects lessons from Web2 systems: it separates control and data planes, uses erasure coding with low replication overhead and minimal repair bandwidth, and operates over a dedicated backbone connecting RPC and storage nodes. Reads are paid, which incentivizes good performance. Shelby also introduces a novel auditing protocol that provides strong cryptoeconomic guarantees without compromising performance, a common limitation of other decentralized solutions. The result is a decentralized system that brings Web2-grade performance to production-scale, read-intensive Web3 applications.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Yotta: A Large-Scale Trustless Data Trading Scheme for Blockchain System</title>
<link>https://arxiv.org/abs/2506.19368</link>
<guid>https://arxiv.org/abs/2506.19368</guid>
<content:encoded><![CDATA[
arXiv:2506.19368v1 Announce Type: new 
Abstract: Data trading is one of the key focuses of Web 3.0. However, all the current methods that rely on blockchain-based smart contracts for data exchange cannot support large-scale data trading while ensuring data security, which falls short of fulfilling the spirit of Web 3.0. Even worse, there is currently a lack of discussion on the essential properties that large-scale data trading should satisfy. In this work, we are the first to formalize the property requirements for enabling data trading in Web 3.0. Based on these requirements, we are the first to propose Yotta, a complete batch data trading scheme for blockchain, which features a data trading design that leverages our innovative cryptographic workflow with IPFS and zk-SNARK. Our simulation results demonstrate that Yotta outperforms baseline approaches up to 130 times and exhibits excellent scalability to satisfy all the properties.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Community Detection in Energy Networks based on Energy Self-Sufficiency and Dynamic Flexibility Activation</title>
<link>https://arxiv.org/abs/2506.19412</link>
<guid>https://arxiv.org/abs/2506.19412</guid>
<content:encoded><![CDATA[
arXiv:2506.19412v1 Announce Type: new 
Abstract: The global energy transition towards distributed, smaller-scale resources, such as decentralized generation and flexible assets like storage and shiftable loads, demands novel control structures aligned with the emerging network architectures. These architectures consist of interconnected, self-contained clusters, commonly called microgrids or energy communities. These clusters aim to optimize collective self-sufficiency by prioritizing local energy use or operating independently during wide-area blackouts. This study addresses the challenge of defining optimal clusters, framed as a community detection problem. A novel metric, termed energy modularity, is proposed to evaluate community partitions by quantifying energy self-sufficiency within clusters while incorporating the influence of flexible resources. Furthermore, a highly scalable community detection algorithm to maximize energy modularity based on the Louvain method is presented. Therefore, energy modularity is calculated using linear programming or a more efficient simulation-based approach. The algorithm is validated on an exemplary benchmark grid, demonstrating its effectiveness in identifying optimal energy clusters for modern decentralized energy systems.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PhishingHook: Catching Phishing Ethereum Smart Contracts leveraging EVM Opcodes</title>
<link>https://arxiv.org/abs/2506.19480</link>
<guid>https://arxiv.org/abs/2506.19480</guid>
<content:encoded><![CDATA[
arXiv:2506.19480v1 Announce Type: new 
Abstract: The Ethereum Virtual Machine (EVM) is a decentralized computing engine. It enables the Ethereum blockchain to execute smart contracts and decentralized applications (dApps). The increasing adoption of Ethereum sparked the rise of phishing activities. Phishing attacks often target users through deceptive means, e.g., fake websites, wallet scams, or malicious smart contracts, aiming to steal sensitive information or funds. A timely detection of phishing activities in the EVM is therefore crucial to preserve the user trust and network integrity. Some state-of-the art approaches to phishing detection in smart contracts rely on the online analysis of transactions and their traces. However, replaying transactions often exposes sensitive user data and interactions, with several security concerns. In this work, we present PhishingHook, a framework that applies machine learning techniques to detect phishing activities in smart contracts by directly analyzing the contract's bytecode and its constituent opcodes. We evaluate the efficacy of such techniques in identifying malicious patterns, suspicious function calls, or anomalous behaviors within the contract's code itself before it is deployed or interacted with. We experimentally compare 16 techniques, belonging to four main categories (Histogram Similarity Classifiers, Vision Models, Language Models and Vulnerability Detection Models), using 7,000 real-world malware smart contracts. Our results demonstrate the efficiency of PhishingHook in performing phishing classification systems, with about 90% average accuracy among all the models. We support experimental reproducibility, and we release our code and datasets to the research community.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decompiling Smart Contracts with a Large Language Model</title>
<link>https://arxiv.org/abs/2506.19624</link>
<guid>https://arxiv.org/abs/2506.19624</guid>
<content:encoded><![CDATA[
arXiv:2506.19624v1 Announce Type: new 
Abstract: The widespread lack of broad source code verification on blockchain explorers such as Etherscan, where despite 78,047,845 smart contracts deployed on Ethereum (as of May 26, 2025), a mere 767,520 (< 1%) are open source, presents a severe impediment to blockchain security. This opacity necessitates the automated semantic analysis of on-chain smart contract bytecode, a fundamental research challenge with direct implications for identifying vulnerabilities and understanding malicious behavior. Prevailing decompilers struggle to reverse bytecode in a readable manner, often yielding convoluted code that critically hampers vulnerability analysis and thwarts efforts to dissect contract functionalities for security auditing.
  This paper addresses this challenge by introducing a pioneering decompilation pipeline that, for the first time, successfully leverages Large Language Models (LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into human-readable and semantically faithful Solidity code. Our novel methodology first employs rigorous static program analysis to convert bytecode into a structured three-address code (TAC) representation. This intermediate representation then guides a Llama-3.2-3B model, specifically fine-tuned on a comprehensive dataset of 238,446 TAC-to-Solidity function pairs, to generate high-quality Solidity. This approach uniquely recovers meaningful variable names, intricate control flow, and precise function signatures. Our extensive empirical evaluation demonstrates a significant leap beyond traditional decompilers, achieving an average semantic similarity of 0.82 with original source and markedly superior readability. The practical viability and effectiveness of our research are demonstrated through its implementation in a publicly accessible system, available at https://evmdecompiler.com.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Sound Type System for Secure Currency Flow</title>
<link>https://arxiv.org/abs/2405.12976</link>
<guid>https://arxiv.org/abs/2405.12976</guid>
<content:encoded><![CDATA[
arXiv:2405.12976v2 Announce Type: replace 
Abstract: In this paper we focus on TinySol, a minimal calculus for Solidity smart contracts, introduced by Bartoletti et al. We start by rephrasing its syntax (to emphasise its object-oriented flavour) and give a new big-step operational semantics. We then use it to define two security properties, namely call integrity and noninterference. These two properties have some similarities in their definition, in that they both require that some part of a program is not influenced by the other part. However, we show that the two properties are actually incomparable. Nevertheless, we provide a type system for noninterference and show that well-typed programs satisfy call integrity as well; hence, programs that are accepted by our type system satisfy both properties. We finally discuss the practical usability of the type system and its limitations by means of some simple examples.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ormer: A Manipulation-resistant and Gas-efficient Blockchain Pricing Oracle for DeFi</title>
<link>https://arxiv.org/abs/2410.07893</link>
<guid>https://arxiv.org/abs/2410.07893</guid>
<content:encoded><![CDATA[
arXiv:2410.07893v2 Announce Type: replace 
Abstract: Price feeds of cryptocurrencies are essential for Decentralized Finance (DeFi) applications to realize fundamental trading and exchanging functionalities, which are retrieved from external price data sources such as exchanges and input to on-chain smart contracts in real-time. Currently, arithmetic mean based time-weighted average price (TWAP) oracles are widely used to process price feeds by averaging asset price with short time frame to achieve reliable and gas-efficient pricing. However, recent research indicates that TWAP is vulnerable to price manipulation attacks, resulting in abnormal price fluctuations and severe financial loss. Even worse, TWAP oracles usually set a relatively long time frame setting to prevent such attack. However, it would further introduce long delays and high price deviation errors from the market asset price.
  To address this issue, we propose a novel on-chain gas-efficient pricing algorithm (Ormer) that heuristically estimates the median of asset price within an observation window based on a piecewise-parabolic formula, while the time delay is suppressed by fusing estimations with different window sizes. Our evaluation based on multiple pairs of token swapping price feed across different chains show that Ormer reduces the mean absolute price error by 15.3% and the time delay by 49.3% compared to TWAP. For gas efficiency, regardless of the number of price observations, an encoding mechanism with constant storage requirement is employed without saving all the historical data for median estimation. Surprisingly, the lowest gas consumption of Ormer is even 15.2% less than TWAP, and the oracle querying fee would be saved up to ~20K USD per day for DeFi participants.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Unsupervised Multi-Agent Reinforcement Learning via Task-Agnostic Exploration</title>
<link>https://arxiv.org/abs/2502.08365</link>
<guid>https://arxiv.org/abs/2502.08365</guid>
<content:encoded><![CDATA[
arXiv:2502.08365v3 Announce Type: replace 
Abstract: In reinforcement learning, we typically refer to unsupervised pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e. rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach, called task-agnostic exploration, casts the unsupervised objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follow.
  In contrast, little is known about it in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via task-agnostic exploration in challenging domains, showing that optimizing for a specific objective, namely mixture entropy, provides an excellent trade-off between tractability and performances.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Communication in Multi-team Dynamic Games: A Mean Field Perspective</title>
<link>https://arxiv.org/abs/2407.06528</link>
<guid>https://arxiv.org/abs/2407.06528</guid>
<content:encoded><![CDATA[
arXiv:2407.06528v2 Announce Type: replace-cross 
Abstract: Coordinating communication and control is a key component in the stability and performance of networked multi-agent systems. While single user networked control systems have gained a lot of attention within this domain, in this work, we address the more challenging problem of large population multi-team dynamic games. In particular, each team constitutes two decision makers (namely, the sensor and the controller) who coordinate over a shared network to control a dynamically evolving state of interest under costs on both actuation and sensing/communication. Due to the shared nature of the wireless channel, the overall cost of each team depends on other teams' policies, thereby leading to a noncooperative game setup. Due to the presence of a large number of teams, we compute approximate decentralized Nash equilibrium policies for each team using the paradigm of (extended) mean-field games, which is governed by (1) the mean traffic flowing over the channel, and (2) the value of information at the sensor, which highlights the semantic nature of the ensuing communication. In the process, we compute optimal controller policies and approximately optimal sensor policies for each representative team of the mean-field system to alleviate the problem of general non-contractivity of the mean-field fixed point operator associated with the finite cardinality of the sensor action space. Consequently, we also prove the $\epsilon$--Nash property of the mean-field equilibrium solution which essentially characterizes how well the solution derived using mean-field analysis performs on the finite-team system. Finally, we provide extensive numerical simulations, which corroborate the theoretical findings and lead to additional insights on the properties of the results presented.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design, Implementation, and Analysis of Fair Faucets for Blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2506.17236</link>
<guid>https://arxiv.org/abs/2506.17236</guid>
<content:encoded><![CDATA[
arXiv:2506.17236v1 Announce Type: new 
Abstract: The present dissertation addresses the problem of fairly distributing shared resources in non-commercial blockchain networks. Blockchains are distributed systems that order and timestamp records of a given network of users, in a public, cryptographically secure, and consensual way. The records, which may in kind be events, transaction orders, sets of rules for structured transactions etc. are placed within well-defined datastructures called blocks, and they are linked to each other by the virtue of cryptographic pointers, in a total ordering which represents their temporal relations of succession. The ability to operate on the blockchain, and/or to contribute a record to the content of a block are shared resources of the blockchain systems. In commercial networks, these resources are exchanged in return for fiat money, and consequently, fairness is not a relevant problem in terms of computer engineering. In non-commercial networks, however, monetary solutions are not available, by definition. The present non-commercial blockchain networks employ trivial distribution mechanisms called faucets, which offer fixed amounts of free tokens (called cryptocurrencies) specific to the given network. This mechanism, although simple and efficient, is prone to denial of service (DoS) attacks and cannot address the fairness problem. In the present dissertation, the faucet mechanism is adapted for fair distribution, in line with Max-min Fairness scheme. In total, we contributed 6 distinct Max-min Fair algorithms as efficient blockchain faucets. The algorithms we contribute are resistant to DoS attacks, low-cost in terms of blockchain computation economics, and they also allow for different user weighting policies.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Second Order State Hallucinations for Adversarial Attack Mitigation in Formation Control of Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2506.17283</link>
<guid>https://arxiv.org/abs/2506.17283</guid>
<content:encoded><![CDATA[
arXiv:2506.17283v1 Announce Type: new 
Abstract: The increasing deployment of multi-agent systems (MAS) in critical infrastructures such as autonomous transportation, disaster relief, and smart cities demands robust formation control mechanisms resilient to adversarial attacks. Traditional consensus-based controllers, while effective under nominal conditions, are highly vulnerable to data manipulation, sensor spoofing, and communication failures. To address this challenge, we propose Second-Order State Hallucination (SOSH), a novel framework that detects compromised agents through distributed residual monitoring and maintains formation stability by replacing attacked states with predictive second-order approximations. Unlike existing mitigation strategies that require significant restructuring or induce long transients, SOSH offers a lightweight, decentralized correction mechanism based on second-order Taylor expansions, enabling rapid and scalable resilience. We establish rigorous Lyapunov-based stability guarantees, proving that formation errors remain exponentially bounded even under persistent attacks, provided the hallucination parameters satisfy explicit conditions. Comprehensive Monte Carlo experiments on a 5-agent complete graph formation demonstrate that SOSH outperforms established robust control schemes, including W-MSR and Huber-based consensus filters, achieving faster convergence rates, lower steady-state error, and superior transient recovery. Our results confirm that SOSH combines theoretical robustness with practical deployability, offering a promising direction for securing MAS formations against sophisticated adversarial threats.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Prediction -- Structuring Epistemic Integrity in Artificial Reasoning Systems</title>
<link>https://arxiv.org/abs/2506.17331</link>
<guid>https://arxiv.org/abs/2506.17331</guid>
<content:encoded><![CDATA[
arXiv:2506.17331v1 Announce Type: new 
Abstract: This paper develops a comprehensive framework for artificial intelligence systems that operate under strict epistemic constraints, moving beyond stochastic language prediction to support structured reasoning, propositional commitment, and contradiction detection. It formalises belief representation, metacognitive processes, and normative verification, integrating symbolic inference, knowledge graphs, and blockchain-based justification to ensure truth-preserving, auditably rational epistemic agents.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Social Metaverse Streaming based on Federated Multi-Agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2506.17342</link>
<guid>https://arxiv.org/abs/2506.17342</guid>
<content:encoded><![CDATA[
arXiv:2506.17342v1 Announce Type: new 
Abstract: The social metaverse is a growing digital ecosystem that blends virtual and physical worlds. It allows users to interact socially, work, shop, and enjoy entertainment. However, privacy remains a major challenge, as immersive interactions require continuous collection of biometric and behavioral data. At the same time, ensuring high-quality, low-latency streaming is difficult due to the demands of real-time interaction, immersive rendering, and bandwidth optimization. To address these issues, we propose ASMS (Adaptive Social Metaverse Streaming), a novel streaming system based on Federated Multi-Agent Proximal Policy Optimization (F-MAPPO). ASMS leverages F-MAPPO, which integrates federated learning (FL) and deep reinforcement learning (DRL) to dynamically adjust streaming bit rates while preserving user privacy. Experimental results show that ASMS improves user experience by at least 14% compared to existing streaming methods across various network conditions. Therefore, ASMS enhances the social metaverse experience by providing seamless and immersive streaming, even in dynamic and resource-constrained networks, while ensuring that sensitive user data remains on local devices.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedNAMs: Performing Interpretability Analysis in Federated Learning Context</title>
<link>https://arxiv.org/abs/2506.17466</link>
<guid>https://arxiv.org/abs/2506.17466</guid>
<content:encoded><![CDATA[
arXiv:2506.17466v1 Announce Type: new 
Abstract: Federated learning continues to evolve but faces challenges in interpretability and explainability. To address these challenges, we introduce a novel approach that employs Neural Additive Models (NAMs) within a federated learning framework. This new Federated Neural Additive Models (FedNAMs) approach merges the advantages of NAMs, where individual networks concentrate on specific input features, with the decentralized approach of federated learning, ultimately producing interpretable analysis results. This integration enhances privacy by training on local data across multiple devices, thereby minimizing the risks associated with data centralization and improving model robustness and generalizability. FedNAMs maintain detailed, feature-specific learning, making them especially valuable in sectors such as finance and healthcare. They facilitate the training of client-specific models to integrate local updates, preserve privacy, and mitigate concerns related to centralization. Our studies on various text and image classification tasks, using datasets such as OpenFetch ML Wine, UCI Heart Disease, and Iris, show that FedNAMs deliver strong interpretability with minimal accuracy loss compared to traditional Federated Deep Neural Networks (DNNs). The research involves notable findings, including the identification of critical predictive features at both client and global levels. Volatile acidity, sulfates, and chlorides for wine quality. Chest pain type, maximum heart rate, and number of vessels for heart disease. Petal length and width for iris classification. This approach strengthens privacy and model efficiency and improves interpretability and robustness across diverse datasets. Finally, FedNAMs generate insights on causes of highly and low interpretable features.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Smart Contract-based Non-Transferable Signature Verification System using Nominative Signatures</title>
<link>https://arxiv.org/abs/2506.17504</link>
<guid>https://arxiv.org/abs/2506.17504</guid>
<content:encoded><![CDATA[
arXiv:2506.17504v1 Announce Type: new 
Abstract: Nominative signatures allow us to indicate who can verify a signature, and they can be employed to construct a non-transferable signature verification system that prevents the signature verification by a third party in unexpected situations. For example, this system can prevent IOU/loan certificate verification in unexpected situations. However, nominative signatures themselves do not allow the verifier to check whether the funds will be transferred in the future or have been transferred.It would be desirable to verify the fact simultaneously when the system involves a certain money transfer such as cryptocurrencies/cryptoassets. In this paper, we propose a smart contract-based non-transferable signature verification system using nominative signatures. We pay attention to the fact that the invisibility, which is a security requirement to be held for nominative signatures, allows us to publish nominative signatures on the blockchain. Our system can verify whether a money transfer actually will take place, in addition to indicating who can verify a signature. We transform the Hanaoka-Schuldt nominative signature scheme (ACNS 2011, IEICE Trans. 2016) which is constructed over a symmetric pairing to a scheme constructed over an asymmetric pairing, and evaluate the gas cost when a smart contract runs the verification algorithm of the modified Hanaoka-Schuldt nominative signature scheme.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decoding Federated Learning: The FedNAM+ Conformal Revolution</title>
<link>https://arxiv.org/abs/2506.17872</link>
<guid>https://arxiv.org/abs/2506.17872</guid>
<content:encoded><![CDATA[
arXiv:2506.17872v1 Announce Type: new 
Abstract: Federated learning has significantly advanced distributed training of machine learning models across decentralized data sources. However, existing frameworks often lack comprehensive solutions that combine uncertainty quantification, interpretability, and robustness. To address this, we propose FedNAM+, a federated learning framework that integrates Neural Additive Models (NAMs) with a novel conformal prediction method to enable interpretable and reliable uncertainty estimation. Our method introduces a dynamic level adjustment technique that utilizes gradient-based sensitivity maps to identify key input features influencing predictions. This facilitates both interpretability and pixel-wise uncertainty estimates. Unlike traditional interpretability methods such as LIME and SHAP, which do not provide confidence intervals, FedNAM+ offers visual insights into prediction reliability. We validate our approach through experiments on CT scan, MNIST, and CIFAR datasets, demonstrating high prediction accuracy with minimal loss (e.g., only 0.1% on MNIST), along with transparent uncertainty measures. Visual analysis highlights variable uncertainty intervals, revealing low-confidence regions where model performance can be improved with additional data. Compared to Monte Carlo Dropout, FedNAM+ delivers efficient and global uncertainty estimates with reduced computational overhead, making it particularly suitable for federated learning scenarios. Overall, FedNAM+ provides a robust, interpretable, and computationally efficient framework that enhances trust and transparency in decentralized predictive modeling.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure User-friendly Blockchain Modular Wallet Design Using Android &amp; OP-TEE</title>
<link>https://arxiv.org/abs/2506.17988</link>
<guid>https://arxiv.org/abs/2506.17988</guid>
<content:encoded><![CDATA[
arXiv:2506.17988v1 Announce Type: new 
Abstract: Emerging crypto economies still hemorrhage digital assets because legacy wallets leak private keys at almost every layer of the software stack, from user-space libraries to kernel memory dumps. This paper solves that twin crisis of security and interoperability by re-imagining key management as a platform-level service anchored in ARM TrustZone through OP-TEE. Our architecture fractures the traditional monolithic Trusted Application into per-chain modules housed in a multi-tenant TA store, finally breaking OP-TEE's single-binary ceiling. A cryptographically sealed firmware-over-the-air pipeline welds each TA set to an Android system image, enabling hot-swap updates while Verified Boot enforces rollback protection. Every package carries a chained signature developer first, registry second so even a compromised supply chain cannot smuggle malicious code past the Secure World's RSA-PSS gatekeeper. Inside the TEE, strict inter-TA isolation, cache partitioning, and GP-compliant crypto APIs ensure secrets never bleed across trust boundaries or timing domains. The Rich Execution Environment can interact only via hardware-mediated Secure Monitor Calls, collapsing the surface exposed to malware in Android space. End-users enjoy a single polished interface yet can install or retire Bitcoin, Ethereum, Solana, or tomorrow's chain with one tap, shrinking both storage footprint and audit scope. For auditors, the composition model slashes duplicated verification effort by quarantining blockchain logic inside narrowly scoped modules that share formally specified interfaces. Our threat analysis spans six adversary layers and shows how the design neutralizes REE malware sniffing, OTA injection, and cross-module side channels without exotic hardware. A reference implementation on AOSP exports a Wallet Manager HAL, custom SELinux domains, and a CI/CD pipeline that vet community modules before release. The result is not merely another hardware wallet but a programmable substrate that can evolve at the velocity of the blockchain ecosystem. By welding radical extensibility to hardware-anchored assurance, the platform closes the security-usability gap that has long stymied mass-market self-custody. We posit that modular TEEs are the missing OS primitive for Web3, much as virtual memory unlocked multi-tasking in classical computing. Together, these contributions sketch a blueprint for multi-chain asset management that is auditable, resilient, and poised for global deployment.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Cloud-Fog Automation for Autonomous Collision Detection and Classification in Intelligent Unmanned Surface Vehicles</title>
<link>https://arxiv.org/abs/2506.18024</link>
<guid>https://arxiv.org/abs/2506.18024</guid>
<content:encoded><![CDATA[
arXiv:2506.18024v1 Announce Type: new 
Abstract: Industrial Cyber-Physical Systems (ICPS) technologies are foundational in driving maritime autonomy, particularly for Unmanned Surface Vehicles (USVs). However, onboard computational constraints and communication latency significantly restrict real-time data processing, analysis, and predictive modeling, hence limiting the scalability and responsiveness of maritime ICPS. To overcome these challenges, we propose a distributed Cloud-Edge-IoT architecture tailored for maritime ICPS by leveraging design principles from the recently proposed Cloud-Fog Automation paradigm. Our proposed architecture comprises three hierarchical layers: a Cloud Layer for centralized and decentralized data aggregation, advanced analytics, and future model refinement; an Edge Layer that executes localized AI-driven processing and decision-making; and an IoT Layer responsible for low-latency sensor data acquisition. Our experimental results demonstrated improvements in computational efficiency, responsiveness, and scalability. When compared with our conventional approaches, we achieved a classification accuracy of 86\%, with an improved latency performance. By adopting Cloud-Fog Automation, we address the low-latency processing constraints and scalability challenges in maritime ICPS applications. Our work offers a practical, modular, and scalable framework to advance robust autonomy and AI-driven decision-making and autonomy for intelligent USVs in future maritime ICPS.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Current State of Ethereum's Enshrined Proposer Builder Separation</title>
<link>https://arxiv.org/abs/2506.18189</link>
<guid>https://arxiv.org/abs/2506.18189</guid>
<content:encoded><![CDATA[
arXiv:2506.18189v1 Announce Type: new 
Abstract: Initially introduced to Ethereum via Flashbots' MEV-boost, Proposer-Builder Separation allows proposers to auction off blockspace to a market of transaction orderers, known as builders. PBS is currently available to validators through the aforementioned MEV-boost, but its unregulated and relay-dependent nature has much of the Ethereum community calling for its enshrinement. Providing a protocol-integrated PBS marketspace and communication channel for payload outsourcing is termed PBS enshrinement. Although ePBS potentially introduces native MEV mitigation mechanisms and reduces validator operation costs, fears of multiparty collusion and chain stagnation are all too real. In addition to mitigating these potential drawbacks, PBS research pursues many tenets revered by Web3 enthusiasts, including but not limited to, censorship resistance, validator reward equity, and deflationary finance. The subsequent SoK will identify current PBS mechanisms, the need for enshrinement, additions to the ePBS upgrade, and the existing or potential on-chain socioeconomic implications of each.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2506.18245</link>
<guid>https://arxiv.org/abs/2506.18245</guid>
<content:encoded><![CDATA[
arXiv:2506.18245v1 Announce Type: new 
Abstract: Smart contract vulnerability detection remains a major challenge in blockchain security. Existing vulnerability detection methods face two main issues: (1) Existing datasets lack comprehensive coverage and high-quality explanations for preference learning. (2) Large language models (LLMs) often struggle with accurately interpreting specific concepts in smart contract security. Empirical analysis shows that even after continual pre-training (CPT) and supervised fine-tuning (SFT), LLMs may misinterpret the execution order of state changes, resulting in incorrect explanations despite making correct detection decisions. To address these challenges, we propose Smart-LLaMA-DPO based on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major vulnerability types and machine-unauditable vulnerabilities, including precise labels, explanations, and locations for SFT, as well as high-quality and low-quality output pairs for Direct Preference Optimization (DPO). Second, we perform CPT using large-scale smart contract to enhance the LLM's understanding of specific security practices in smart contracts. Futhermore, we conduct SFT with our comprehensive dataset. Finally, we apply DPO, leveraging human feedback and a specially designed loss function that increases the probability of preferred explanations while reducing the likelihood of non-preferred outputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types: reentrancy, timestamp dependence, integer overflow/underflow, and delegatecall, as well as machine-unauditable vulnerabilities. Our method significantly outperforms state-of-the-art baselines, with average improvements of 10.43% in F1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human evaluation confirm that our method generates more correct, thorough, and clear explanations.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Recipe for Discovery: A Framework for Systematic Open Source Project Identification</title>
<link>https://arxiv.org/abs/2506.18359</link>
<guid>https://arxiv.org/abs/2506.18359</guid>
<content:encoded><![CDATA[
arXiv:2506.18359v1 Announce Type: new 
Abstract: Open source software development, particularly within institutions such as universities and research laboratories, is often decentralized and difficult to track. Despite producing highly impactful tools in science, these efforts often go unrecognized due to a lack of visibility and institutional awareness. This paper addresses the challenge of discovering, classifying, and analyzing open source software projects developed across distributed institutional systems. We present a framework for systematically identifying institutional affiliated repositories, using the University of California (UC) system as a case study.
  Using GitHub's REST API, we build a pipeline to discover relevant repositories and extract meaningful metadata. We then propose and evaluate multiple classification strategies, including both traditional machine learning models and large language models (LLMs), to distinguish affiliated projects from unrelated repositories and generate accurate insights into the academic open source landscape. Our results show that the framework is effective at scale, discovering over 52,000 repositories and predicting institutional affiliation with high accuracy.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transformer World Model for Sample Efficient Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2506.18537</link>
<guid>https://arxiv.org/abs/2506.18537</guid>
<content:encoded><![CDATA[
arXiv:2506.18537v1 Announce Type: new 
Abstract: We present the Multi-Agent Transformer World Model (MATWM), a novel transformer-based world model designed for multi-agent reinforcement learning in both vector- and image-based environments. MATWM combines a decentralized imagination framework with a semi-centralized critic and a teammate prediction module, enabling agents to model and anticipate the behavior of others under partial observability. To address non-stationarity, we incorporate a prioritized replay mechanism that trains the world model on recent experiences, allowing it to adapt to agents' evolving policies. We evaluated MATWM on a broad suite of benchmarks, including the StarCraft Multi-Agent Challenge, PettingZoo, and MeltingPot. MATWM achieves state-of-the-art performance, outperforming both model-free and prior world model approaches, while demonstrating strong sample efficiency, achieving near-optimal performance in as few as 50K environment interactions. Ablation studies confirm the impact of each component, with substantial gains in coordination-heavy tasks.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation</title>
<link>https://arxiv.org/abs/2506.18783</link>
<guid>https://arxiv.org/abs/2506.18783</guid>
<content:encoded><![CDATA[
arXiv:2506.18783v1 Announce Type: new 
Abstract: TRIZ, the Theory of Inventive Problem Solving, is a structured, knowledge-based framework for innovation and abstracting problems to find inventive solutions. However, its application is often limited by the complexity and deep interdisciplinary knowledge required. Advancements in Large Language Models (LLMs) have revealed new possibilities for automating parts of this process. While previous studies have explored single LLMs in TRIZ applications, this paper introduces a multi-agent approach. We propose an LLM-based multi-agent system, called TRIZ agents, each with specialized capabilities and tool access, collaboratively solving inventive problems based on the TRIZ methodology. This multi-agent system leverages agents with various domain expertise to efficiently navigate TRIZ steps. The aim is to model and simulate an inventive process with language agents. We assess the effectiveness of this team of agents in addressing complex innovation challenges based on a selected case study in engineering. We demonstrate the potential of agent collaboration to produce diverse, inventive solutions. This research contributes to the future of AI-driven innovation, showcasing the advantages of decentralized problem-solving in complex ideation tasks.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shift Happens: Mixture of Experts based Continual Adaptation in Federated Learning</title>
<link>https://arxiv.org/abs/2506.18789</link>
<guid>https://arxiv.org/abs/2506.18789</guid>
<content:encoded><![CDATA[
arXiv:2506.18789v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized clients without sharing raw data, yet faces significant challenges in real-world settings where client data distributions evolve dynamically over time. This paper tackles the critical problem of covariate and label shifts in streaming FL environments, where non-stationary data distributions degrade model performance and require adaptive middleware solutions. We introduce ShiftEx, a shift-aware mixture of experts framework that dynamically creates and trains specialized global models in response to detected distribution shifts using Maximum Mean Discrepancy for covariate shifts. The framework employs a latent memory mechanism for expert reuse and implements facility location-based optimization to jointly minimize covariate mismatch, expert creation costs, and label imbalance. Through theoretical analysis and comprehensive experiments on benchmark datasets, we demonstrate 5.5-12.9 percentage point accuracy improvements and 22-95 % faster adaptation compared to state-of-the-art FL baselines across diverse shift scenarios. The proposed approach offers a scalable, privacy-preserving middleware solution for FL systems operating in non-stationary, real-world conditions while minimizing communication and computational overhead.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FORGE: An LLM-driven Framework for Large-Scale Smart Contract Vulnerability Dataset Construction</title>
<link>https://arxiv.org/abs/2506.18795</link>
<guid>https://arxiv.org/abs/2506.18795</guid>
<content:encoded><![CDATA[
arXiv:2506.18795v1 Announce Type: new 
Abstract: High-quality smart contract vulnerability datasets are critical for evaluating security tools and advancing smart contract security research. Two major limitations of current manual dataset construction are (1) labor-intensive and error-prone annotation processes limiting the scale, quality, and evolution of the dataset, and (2) absence of standardized classification rules results in inconsistent vulnerability categories and labeling results across different datasets. To address these limitations, we present FORGE, the first automated approach for constructing smart contract vulnerability datasets. FORGE leverages an LLM-driven pipeline to extract high-quality vulnerabilities from real-world audit reports and classify them according to the CWE, the most widely recognized classification in software security. FORGE employs a divide-and-conquer strategy to extract structured and self-contained vulnerability information from these reports. Additionally, it uses a tree-of-thoughts technique to classify the vulnerability information into the hierarchical CWE classification. To evaluate FORGE's effectiveness, we run FORGE on 6,454 real-world audit reports and generate a dataset comprising 81,390 solidity files and 27,497 vulnerability findings across 296 CWE categories. Manual assessment of the dataset demonstrates high extraction precision and classification consistency with human experts (precision of 95.6% and inter-rater agreement k-$\alpha$ of 0.87). We further validate the practicality of our dataset by benchmarking 13 existing security tools on our dataset. The results reveal the significant limitations in current detection capabilities. Furthermore, by analyzing the severity-frequency distribution patterns through a unified CWE perspective in our dataset, we highlight inconsistency between current smart contract research focus and priorities identified from real-world vulnerabilities...
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LayerZero</title>
<link>https://arxiv.org/abs/2312.09118</link>
<guid>https://arxiv.org/abs/2312.09118</guid>
<content:encoded><![CDATA[
arXiv:2312.09118v3 Announce Type: replace 
Abstract: In this paper, we present the first intrinsically secure and semantically universal omnichain interoperability protocol: LayerZero. Utilizing an immutable endpoint, append-only verification modules, and fully-configurable verification infrastructure, LayerZero provides the security, configurability, and extensibility necessary to achieve omnichain interoperability. LayerZero enforces strict application-exclusive ownership of protocol security and cost through its novel trust-minimized modular security framework which is designed to universally support all blockchains and use cases. Omnichain applications (OApps) built on the LayerZero protocol achieve frictionless blockchain-agnostic interoperation through LayerZero's universal network semantics.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Selfish Mining Analysis for DAG-Based PoW Consensus Protocols</title>
<link>https://arxiv.org/abs/2501.10888</link>
<guid>https://arxiv.org/abs/2501.10888</guid>
<content:encoded><![CDATA[
arXiv:2501.10888v3 Announce Type: replace 
Abstract: Selfish mining is strategic rule-breaking to maximize rewards in proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred tool for finding optimal strategies in Bitcoin and similar linear chain protocols. Protocols increasingly adopt DAG-based chain structures, for which MDP analysis is more involved. To date, researchers have tailored specific MDPs for each protocol. Protocol design suffers long feedback loops, as each protocol change implies manual work on the MDP. To overcome this, we propose a generic attack model that covers a wide range of protocols, including Ethereum Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular: we specify each protocol as a concise program, and our tooling then derives and solves the selfish mining MDP automatically.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer</title>
<link>https://arxiv.org/abs/2501.14931</link>
<guid>https://arxiv.org/abs/2501.14931</guid>
<content:encoded><![CDATA[
arXiv:2501.14931v3 Announce Type: replace 
Abstract: This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically-optimal latency of one round-trip, i.e., requiring only one network trip for writing a transaction and one for reading it. To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, which independently process transactions and append them to local logs. Replicas assigns a timestamp and a sequence number to each transaction in their logs, allowing clients to extract valuable metadata about the transactions and the system state. Later on, clients retrieve these logs and extract transactions (and associated metadata) from them. Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then show pod-core, a protocol that satisfies properties such as transaction confirmation within $2\delta$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that single-shot auctions can be realized using the pod notion and observe that it is also sufficient for other popular applications.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis</title>
<link>https://arxiv.org/abs/2506.15790</link>
<guid>https://arxiv.org/abs/2506.15790</guid>
<content:encoded><![CDATA[
arXiv:2506.15790v1 Announce Type: new 
Abstract: With the advance application of blockchain technology in various fields, ensuring the security and stability of smart contracts has emerged as a critical challenge. Current security analysis methodologies in vulnerability detection can be categorized into static analysis and dynamic analysis methods.However, these existing traditional vulnerability detection methods predominantly rely on analyzing original contract code, not all smart contracts provide accessible code.We present ETrace, a novel event-driven vulnerability detection framework for smart contracts, which uniquely identifies potential vulnerabilities through LLM-powered trace analysis without requiring source code access. By extracting fine-grained event sequences from transaction logs, the framework leverages Large Language Models (LLMs) as adaptive semantic interpreters to reconstruct event analysis through chain-of-thought reasoning. ETrace implements pattern-matching to establish causal links between transaction behavior patterns and known attack behaviors. Furthermore, we validate the effectiveness of ETrace through preliminary experimental results.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Coordinate Under Threshold Rewards: A Cooperative Multi-Agent Bandit Framework</title>
<link>https://arxiv.org/abs/2506.15856</link>
<guid>https://arxiv.org/abs/2506.15856</guid>
<content:encoded><![CDATA[
arXiv:2506.15856v1 Announce Type: new 
Abstract: Cooperative multi-agent systems often face tasks that require coordinated actions under uncertainty. While multi-armed bandit (MAB) problems provide a powerful framework for decentralized learning, most prior work assumes individually attainable rewards. We address the challenging setting where rewards are threshold-activated: an arm yields a payoff only when a minimum number of agents pull it simultaneously, with this threshold unknown in advance. Complicating matters further, some arms are decoys - requiring coordination to activate but yielding no reward - introducing a new challenge of wasted joint exploration. We introduce Threshold-Coop-UCB (T-Coop-UCB), a decentralized algorithm that enables agents to jointly learn activation thresholds and reward distributions, forming effective coalitions without centralized control. Empirical results show that T-Coop-UCB consistently outperforms baseline methods in cumulative reward, regret, and coordination metrics, achieving near-Oracle performance. Our findings underscore the importance of joint threshold learning and decoy avoidance for scalable, decentralized cooperation in complex multi-agent
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competing Bandits in Matching Markets via Super Stability</title>
<link>https://arxiv.org/abs/2506.15926</link>
<guid>https://arxiv.org/abs/2506.15926</guid>
<content:encoded><![CDATA[
arXiv:2506.15926v1 Announce Type: new 
Abstract: We study bandit learning in matching markets with two-sided reward uncertainty, extending prior research primarily focused on single-sided uncertainty. Leveraging the concept of `super-stability' from Irving (1994), we demonstrate the advantage of the Extended Gale-Shapley (GS) algorithm over the standard GS algorithm in achieving true stable matchings under incomplete information. By employing the Extended GS algorithm, our centralized algorithm attains a logarithmic pessimal stable regret dependent on an instance-dependent admissible gap parameter. This algorithm is further adapted to a decentralized setting with a constant regret increase. Finally, we establish a novel centralized instance-dependent lower bound for binary stable regret, elucidating the roles of the admissible gap and super-stable matching in characterizing the complexity of stable matching with bandit feedback.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Blockchain-based Steganography via Backcalculating Generative Adversarial Network</title>
<link>https://arxiv.org/abs/2506.16023</link>
<guid>https://arxiv.org/abs/2506.16023</guid>
<content:encoded><![CDATA[
arXiv:2506.16023v1 Announce Type: new 
Abstract: Blockchain-based steganography enables data hiding via encoding the covert data into a specific blockchain transaction field. However, previous works focus on the specific field-embedding methods while lacking a consideration on required field-generation embedding. In this paper, we propose a generic blockchain-based steganography framework (GBSF). The sender generates the required fields such as amount and fees, where the additional covert data is embedded to enhance the channel capacity. Based on GBSF, we design a reversible generative adversarial network (R-GAN) that utilizes the generative adversarial network with a reversible generator to generate the required fields and encode additional covert data into the input noise of the reversible generator. We then explore the performance flaw of R-GAN. To further improve the performance, we propose R-GAN with Counter-intuitive data preprocessing and Custom activation functions, namely CCR-GAN. The counter-intuitive data preprocessing (CIDP) mechanism is used to reduce decoding errors in covert data, while it incurs gradient explosion for model convergence. The custom activation function named ClipSigmoid is devised to overcome the problem. Theoretical justification for CIDP and ClipSigmoid is also provided. We also develop a mechanism named T2C, which balances capacity and concealment. We conduct experiments using the transaction amount of the Bitcoin mainnet as the required field to verify the feasibility. We then apply the proposed schemes to other transaction fields and blockchains to demonstrate the scalability. Finally, we evaluate capacity and concealment for various blockchains and transaction fields and explore the trade-off between capacity and concealment. The results demonstrate that R-GAN and CCR-GAN are able to enhance the channel capacity effectively and outperform state-of-the-art works.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models</title>
<link>https://arxiv.org/abs/2506.16218</link>
<guid>https://arxiv.org/abs/2506.16218</guid>
<content:encoded><![CDATA[
arXiv:2506.16218v1 Announce Type: new 
Abstract: Federated prompt learning (FPL) for vision-language models is a powerful approach to collaboratively adapt models across distributed clients while preserving data privacy. However, existing FPL approaches suffer from a trade-off between performance and robustness, particularly in out-of-distribution (OOD) shifts, limiting their reliability in real-world scenarios. The inherent in-distribution (ID) data heterogeneity among different clients makes it more challenging to maintain this trade-off. To fill this gap, we introduce a Federated OOD-aware Context Optimization (FOCoOp) framework, which captures diverse distributions among clients using ID global prompts, local prompts, and OOD prompts. Specifically, FOCoOp leverages three sets of prompts to create both class-level and distribution-level separations, which adapt to OOD shifts through bi-level distributionally robust optimization. Additionally, FOCoOp improves the discrimination consistency among clients, i.e., calibrating global prompts, seemingly OOD prompts, and OOD prompts by semi-unbalanced optimal transport. The extensive experiments on real-world datasets demonstrate that FOCoOp effectively captures decentralized heterogeneous distributions and enhances robustness of different OOD shifts. The project is available at GitHub.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordination of Electrical and Heating Resources by Self-Interested Agents</title>
<link>https://arxiv.org/abs/2506.16277</link>
<guid>https://arxiv.org/abs/2506.16277</guid>
<content:encoded><![CDATA[
arXiv:2506.16277v1 Announce Type: new 
Abstract: With the rise of distributed energy resources and sector coupling, distributed optimization can be a sensible approach to coordinate decentralized energy resources. Further, district heating, heat pumps, cogeneration, and sharing concepts like local energy communities introduce the potential to optimize heating and electricity output simultaneously. To solve this issue, we tackle the distributed multi-energy scheduling optimization problem, which describes the optimization of distributed energy generators over multiple time steps to reach a specific target schedule. This work describes a novel distributed hybrid algorithm as a solution approach. This approach is based on the heuristics of gossiping and local search and can simultaneously optimize the private objective of the participants and the collective objective, considering multiple energy sectors. We show that the algorithm finds globally near-optimal solutions while protecting the stakeholders' economic goals and the plants' technical properties. Two test cases representing pure electrical and gas-based technologies are evaluated.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SecureFed: A Two-Phase Framework for Detecting Malicious Clients in Federated Learning</title>
<link>https://arxiv.org/abs/2506.16458</link>
<guid>https://arxiv.org/abs/2506.16458</guid>
<content:encoded><![CDATA[
arXiv:2506.16458v1 Announce Type: new 
Abstract: Federated Learning (FL) protects data privacy while providing a decentralized method for training models. However, because of the distributed schema, it is susceptible to adversarial clients that could alter results or sabotage model performance. This study presents SecureFed, a two-phase FL framework for identifying and reducing the impact of such attackers. Phase 1 involves collecting model updates from participating clients and applying a dimensionality reduction approach to identify outlier patterns frequently associated with malicious behavior. Temporary models constructed from the client updates are evaluated on synthetic datasets to compute validation losses and support anomaly scoring. The idea of learning zones is presented in Phase 2, where weights are dynamically routed according to their contribution scores and gradient magnitudes. High-value gradient zones are given greater weight in aggregation and contribute more significantly to the global model, while lower-value gradient zones, which may indicate possible adversarial activity, are gradually removed from training. Until the model converges and a strong defense against poisoning attacks is possible, this training cycle continues Based on the experimental findings, SecureFed considerably improves model resilience without compromising model performance.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enabling Blockchain Interoperability Through Network Discovery Services</title>
<link>https://arxiv.org/abs/2506.16611</link>
<guid>https://arxiv.org/abs/2506.16611</guid>
<content:encoded><![CDATA[
arXiv:2506.16611v1 Announce Type: new 
Abstract: Web3 technologies have experienced unprecedented growth in the last decade, achieving widespread adoption. As various blockchain networks continue to evolve, we are on the cusp of a paradigm shift in which they could provide services traditionally offered by the Internet, but in a decentralized manner, marking the emergence of the Internet of Blockchains. While significant progress has been achieved in enabling interoperability between blockchain networks, existing solutions often assume that networks are already mutually aware. This reveals a critical gap: the initial discovery of blockchain networks remains largely unaddressed. This paper proposes a decentralized architecture for blockchain network discovery that operates independently of any centralized authority. We also introduce a mechanism for discovering assets and services within a blockchain from external networks. Given the decentralized nature of the proposed discovery architecture, we design an incentive mechanism to encourage nodes to actively participate in maintaining the discovery network. The proposed architecture implemented and evaluated, using the Substrate framework, demonstrates its resilience and scalability, effectively handling up to 130,000 concurrent requests under the tested network configurations, with a median response time of 5.5 milliseconds, demonstrating the ability to scale its processing capacity further by increasing its network size.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Energy Billing with Blockchain and the Prophet Forecasting Model: A Holistic Approach</title>
<link>https://arxiv.org/abs/2506.16649</link>
<guid>https://arxiv.org/abs/2506.16649</guid>
<content:encoded><![CDATA[
arXiv:2506.16649v1 Announce Type: new 
Abstract: This paper presents a comprehensive approach to automated energy billing that leverages IoT-based smart meters, blockchain technology, and the Prophet time series forecasting model. The proposed system facilitates real-time power consumption monitoring via Wi-Fi-enabled ESP32 modules and a mobile application interface. It integrates Firebase and blockchain for secure, transparent billing processes and employs smart contracts for automated payments. The Prophet model is used for energy demand forecasting, with careful data preprocessing, transformation, and parameter tuning to improve prediction accuracy. This holistic solution aims to reduce manual errors, enhance user awareness, and promote sustainable energy use.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedFitTech: A Baseline in Federated Learning for Fitness Tracking</title>
<link>https://arxiv.org/abs/2506.16840</link>
<guid>https://arxiv.org/abs/2506.16840</guid>
<content:encoded><![CDATA[
arXiv:2506.16840v1 Announce Type: new 
Abstract: Rapid evolution of sensors and resource-efficient machine learning models have spurred the widespread adoption of wearable fitness tracking devices. Equipped with inertial sensors, such devices can continuously capture physical movements for fitness technology (FitTech), enabling applications from sports optimization to preventive healthcare. Traditional centralized learning approaches to detect fitness activities struggle with privacy concerns, regulatory constraints, and communication inefficiencies. In contrast, Federated Learning (FL) enables a decentralized model training by communicating model updates rather than private wearable sensor data. Applying FL to FitTech presents unique challenges, such as data imbalance, lack of labelled data, heterogeneous user activity patterns, and trade-offs between personalization and generalization. To simplify research on FitTech in FL, we present the FedFitTech baseline, under the Flower framework, which is publicly available and widely used by both industry and academic researchers. Additionally, to illustrate its usage, this paper presents a case study that implements a system based on the FedFitTech baseline, incorporating a client-side early stopping strategy and comparing the results. For instance, this system allows wearable devices to optimize the trade-off between capturing common fitness activity patterns and preserving individuals' nuances, thereby enhancing both the scalability and efficiency of privacy-aware fitness tracking applications. Results show that this reduces overall redundant communications by 13 percent, while maintaining the overall recognition performance at a negligible recognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation for a wide range of new research and development opportunities in FitTech, and it is available as open-source at: https://github.com/adap/flower/tree/main/baselines/fedfittech
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation</title>
<link>https://arxiv.org/abs/2506.16636</link>
<guid>https://arxiv.org/abs/2506.16636</guid>
<content:encoded><![CDATA[
arXiv:2506.16636v1 Announce Type: cross 
Abstract: Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/\sqrt{n}$ rate when approximating the true data distribution.
  To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles.
  Our procedure satisfies local $(\epsilon, \delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competing Bandits in Decentralized Contextual Matching Markets</title>
<link>https://arxiv.org/abs/2411.11794</link>
<guid>https://arxiv.org/abs/2411.11794</guid>
<content:encoded><![CDATA[
arXiv:2411.11794v2 Announce Type: replace 
Abstract: Sequential learning in a multi-agent resource constrained matching market has received significant interest in the past few years. We study decentralized learning in two-sided matching markets where the demand side (aka players or agents) competes for the supply side (aka arms) with potentially time-varying preferences to obtain a stable match. Motivated by the linear contextual bandit framework, we assume that for each agent, an arm-mean may be represented by a linear function of a known feature vector and an unknown (agent-specific) parameter. Moreover, the preferences over arms depend on a latent environment in each round, where the latent environment varies across rounds in a non-stationary manner. We propose learning algorithms to identify the latent environment and obtain stable matchings simultaneously. Our proposed algorithms achieve instance-dependent logarithmic regret, scaling independently of the number of arms, and hence applicable for a large market.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models</title>
<link>https://arxiv.org/abs/2506.14824</link>
<guid>https://arxiv.org/abs/2506.14824</guid>
<content:encoded><![CDATA[
arXiv:2506.14824v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) excel in tasks like multimodal reasoning and cross-modal retrieval but face deployment challenges in real-world scenarios due to distributed multimodal data and strict privacy requirements. Federated Learning (FL) offers a solution by enabling collaborative model training without centralizing data. However, realizing FL for MLLMs presents significant challenges, including high computational demands, limited client capacity, substantial communication costs, and heterogeneous client data. Existing FL methods assume client-side deployment of full models, an assumption that breaks down for large-scale MLLMs due to their massive size and communication demands. To address these limitations, we propose FedNano, the first FL framework that centralizes the LLM on the server while introducing NanoEdge, a lightweight module for client-specific adaptation. NanoEdge employs modality-specific encoders, connectors, and trainable NanoAdapters with low-rank adaptation. This design eliminates the need to deploy LLM on clients, reducing client-side storage by 95%, and limiting communication overhead to only 0.01% of the model parameters. By transmitting only compact NanoAdapter updates, FedNano handles heterogeneous client data and resource constraints while preserving privacy. Experiments demonstrate that FedNano outperforms prior FL baselines, bridging the gap between MLLM scale and FL feasibility, and enabling scalable, decentralized multimodal AI systems.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection</title>
<link>https://arxiv.org/abs/2506.14933</link>
<guid>https://arxiv.org/abs/2506.14933</guid>
<content:encoded><![CDATA[
arXiv:2506.14933v1 Announce Type: new 
Abstract: The decentralized finance (DeFi) community has grown rapidly in recent years, pushed forward by cryptocurrency enthusiasts interested in the vast untapped potential of new markets. The surge in popularity of cryptocurrency has ushered in a new era of financial crime. Unfortunately, the novelty of the technology makes the task of catching and prosecuting offenders particularly challenging. Thus, it is necessary to implement automated detection tools related to policies to address the growing criminality in the cryptocurrency realm.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ImprovDML: Improved Trade-off in Private Byzantine-Resilient Distributed Machine Learning</title>
<link>https://arxiv.org/abs/2506.15181</link>
<guid>https://arxiv.org/abs/2506.15181</guid>
<content:encoded><![CDATA[
arXiv:2506.15181v1 Announce Type: new 
Abstract: Jointly addressing Byzantine attacks and privacy leakage in distributed machine learning (DML) has become an important issue. A common strategy involves integrating Byzantine-resilient aggregation rules with differential privacy mechanisms. However, the incorporation of these techniques often results in a significant degradation in model accuracy. To address this issue, we propose a decentralized DML framework, named ImprovDML, that achieves high model accuracy while simultaneously ensuring privacy preservation and resilience to Byzantine attacks. The framework leverages a kind of resilient vector consensus algorithms that can compute a point within the normal (non-Byzantine) agents' convex hull for resilient aggregation at each iteration. Then, multivariate Gaussian noises are introduced to the gradients for privacy preservation. We provide convergence guarantees and derive asymptotic learning error bounds under non-convex settings, which are tighter than those reported in existing works. For the privacy analysis, we adopt the notion of concentrated geo-privacy, which quantifies privacy preservation based on the Euclidean distance between inputs. We demonstrate that it enables an improved trade-off between privacy preservation and model accuracy compared to differential privacy. Finally, numerical simulations validate our theoretical results.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>You Only Render Once: Enhancing Energy and Computation Efficiency of Mobile Virtual Reality</title>
<link>https://arxiv.org/abs/2506.15183</link>
<guid>https://arxiv.org/abs/2506.15183</guid>
<content:encoded><![CDATA[
arXiv:2506.15183v1 Announce Type: new 
Abstract: Mobile Virtual Reality (VR) is essential to achieving convenient and immersive human-computer interaction and realizing emerging applications such as Metaverse. However, existing VR technologies require two separate renderings of binocular images, causing a significant bottleneck for mobile devices with limited computing capability and power supply. This paper proposes an approach to rendering optimization for mobile VR called EffVR. By utilizing the per-pixel attribute, EffVR can generate binocular VR images from the monocular image through genuinely one rendering, saving half the computation over conventional approaches. Our evaluation indicates that, compared with the state-of-art, EffVRcan save 27% power consumption on average while achieving high binocular image quality (0.9679 SSIM and 34.09 PSNR) in mobile VR applications. Additionally, EffVR can increase the frame rate by 115.2%. These results corroborate EffVRsuperior computation/energy-saving performance, paving the road to a sustainable mobile VR. The source code, demo video, android app, and more are released anonymously at https://yoro-vr.github.io/
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>All is Not Lost: LLM Recovery without Checkpoints</title>
<link>https://arxiv.org/abs/2506.15461</link>
<guid>https://arxiv.org/abs/2506.15461</guid>
<content:encoded><![CDATA[
arXiv:2506.15461v1 Announce Type: new 
Abstract: Training LLMs on decentralized and wimpy computation nodes, e.g., multiple on-spot instances, lowers the training cost and enables model democratization. The inevitable challenge here is the churn of nodes due to failures and the operator's scheduling policies, leading to losing a stage - a part of the model. The conventional approaches to recover from failures are to either use checkpointing, where periodically a copy of the entire model is sent to an additional storage, or redundant computation. These approaches yield significant communication and/or computation overhead even in non-failure cases and scale poorly in settings with large models. In this paper, we propose, CheckFree, an efficient recovery method where a failing stage is substituted by a weighted average of the closest neighboring stages. In contrast to the state of the art, CheckFree requires no additional computation or storage. However, because of the nature of averaging neighbouring stages, it can only recover failures of intermediate stages. We further extend our method to CheckFree+ with out-of-order pipeline execution to tolerate crashes of the first and last stages. Thanks to out-of-order pipelining, behaviour of those stages is mimicked by their neighboring ones, which allows CheckFree+ to recover them by simply copying the weights from the immediate neighbour. To be able to recover the (de)embedding layers, CheckFree+ copies those layers to the neighboring stages, which requires relatively small storage overhead. We extensively evaluate our method on LLaMa models of model sizes from 124M to 1.5B with varying failure frequencies. In the case of low and medium failure rates (5-10%), CheckFree and CheckFree+ outperform both checkpointing and redundant computation in terms of convergence in wall-clock time by over 12%. Both of our proposals can be run via our code available at: https://github.com/gensyn-ai/CheckFree.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI</title>
<link>https://arxiv.org/abs/2506.15468</link>
<guid>https://arxiv.org/abs/2506.15468</guid>
<content:encoded><![CDATA[
arXiv:2506.15468v1 Announce Type: new 
Abstract: We propose co-creative learning as a novel paradigm where humans and AI, i.e., biological and artificial agents, mutually integrate their partial perceptual information and knowledge to construct shared external representations, a process we interpret as symbol emergence. Unlike traditional AI teaching based on unilateral knowledge transfer, this addresses the challenge of integrating information from inherently different modalities. We empirically test this framework using a human-AI interaction model based on the Metropolis-Hastings naming game (MHNG), a decentralized Bayesian inference mechanism. In an online experiment, 69 participants played a joint attention naming game (JA-NG) with one of three computer agent types (MH-based, always-accept, or always-reject) under partial observability. Results show that human-AI pairs with an MH-based agent significantly improved categorization accuracy through interaction and achieved stronger convergence toward a shared sign system. Furthermore, human acceptance behavior aligned closely with the MH-derived acceptance probability. These findings provide the first empirical evidence for co-creative learning emerging in human-AI dyads via MHNG-based interaction. This suggests a promising path toward symbiotic AI systems that learn with humans, rather than from them, by dynamically aligning perceptual experiences, opening a new venue for symbiotic AI alignment.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Variational Information Bottleneck for Data Extraction Based on Mutual Information in Internet of Vehicles</title>
<link>https://arxiv.org/abs/2409.17287</link>
<guid>https://arxiv.org/abs/2409.17287</guid>
<content:encoded><![CDATA[
arXiv:2409.17287v2 Announce Type: replace 
Abstract: The Internet of Vehicles (IoV) network can address the issue of limited computing resources and data processing capabilities of individual vehicles, but it also brings the risk of privacy leakage to vehicle users. Applying blockchain technology can establish secure data links within the IoV, solving the problems of insufficient computing resources for each vehicle and the security of data transmission over the network. However, with the development of the IoV, the amount of data interaction between multiple vehicles and between vehicles and base stations, roadside units, etc., is continuously increasing. There is a need to further reduce the interaction volume, and intelligent data compression is key to solving this problem. The VIB technique facilitates the training of encoding and decoding models, substantially diminishing the volume of data that needs to be transmitted. This paper introduces an innovative approach that integrates blockchain with VIB, referred to as BVIB, designed to lighten computational workloads and reinforce the security of the network. We first construct a new network framework by separating the encoding and decoding networks to address the computational burden issue, and then propose a new algorithm to enhance the security of IoV networks. We also discuss the impact of the data extraction rate on system latency to determine the most suitable data extraction rate. An experimental framework combining Python and C++ has been established to substantiate the efficacy of our BVIB approach. Comprehensive simulation studies indicate that the BVIB consistently excels in comparison to alternative foundational methodologies.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>YOLO-MARL: You Only LLM Once for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.03997</link>
<guid>https://arxiv.org/abs/2410.03997</guid>
<content:encoded><![CDATA[
arXiv:2410.03997v2 Announce Type: replace 
Abstract: Advancements in deep multi-agent reinforcement learning (MARL) have positioned it as a promising approach for decision-making in cooperative games. However, it still remains challenging for MARL agents to learn cooperative strategies for some game environments. Recently, large language models (LLMs) have demonstrated emergent reasoning capabilities, making them promising candidates for enhancing coordination among the agents. However, due to the model size of LLMs, it can be expensive to frequently infer LLMs for actions that agents can take. In this work, we propose You Only LLM Once for MARL (YOLO-MARL), a novel framework that leverages the high-level task planning capabilities of LLMs to improve the policy learning process of multi-agents in cooperative games. Notably, for each game environment, YOLO-MARL only requires one time interaction with LLMs in the proposed strategy generation, state interpretation and planning function generation modules, before the MARL policy training process. This avoids the ongoing costs and computational time associated with frequent LLMs API calls during training. Moreover, trained decentralized policies based on normal-sized neural networks operate independently of the LLM. We evaluate our method across two different environments and demonstrate that YOLO-MARL outperforms traditional MARL algorithms.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-Chain Arbitrage: The Next Frontier of MEV in Decentralized Finance</title>
<link>https://arxiv.org/abs/2501.17335</link>
<guid>https://arxiv.org/abs/2501.17335</guid>
<content:encoded><![CDATA[
arXiv:2501.17335v2 Announce Type: replace 
Abstract: Decentralized finance (DeFi) markets spread across Layer-1 (L1) and Layer-2 (L2) blockchains rely on arbitrage to keep prices aligned. Today most price gaps are closed against centralized exchanges (CEXes), whose deep liquidity and fast execution make them the primary venue for price discovery. As trading volume migrates on-chain, cross-chain arbitrage between decentralized exchanges (DEXes) will become the canonical mechanism for price alignment. Yet, despite its importance to DeFi-and the on-chain transparency making real activity tractable in a way CEX-to-DEX arbitrage is not-existing research remains confined to conceptual overviews and hypothetical opportunity analyses.
  We study cross-chain arbitrage with a profit-cost model and a year-long measurement. The model shows that opportunity frequency, bridging time, and token depreciation determine whether inventory- or bridge-based execution is more profitable. Empirically, we analyze one year of transactions (September 2023 - August 2024) across nine blockchains and identify 242,535 executed arbitrages totaling 868.64 million USD volume. Activity clusters on Ethereum-centric L1-L2 pairs, grows 5.5x over the study period, and surges-higher volume, more trades, lower fees-after the Dencun upgrade (March 13, 2024). Most trades use pre-positioned inventory (66.96%) and settle in 9s, whereas bridge-based arbitrages take 242s, underscoring the latency cost of today's bridges. Market concentration is high: the five largest addresses execute more than half of all trades, and one alone captures almost 40% of daily volume post-Dencun. We conclude that cross-chain arbitrage fosters vertical integration, centralizing sequencing infrastructure and economic power and thereby exacerbating censorship, liveness, and finality risks; decentralizing block building and lowering entry barriers are critical to countering these threats.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study</title>
<link>https://arxiv.org/abs/2506.13836</link>
<guid>https://arxiv.org/abs/2506.13836</guid>
<content:encoded><![CDATA[
arXiv:2506.13836v1 Announce Type: new 
Abstract: Reinforcement learning-based traffic signal control (RL-TSC) has emerged as a promising approach for improving urban mobility. However, its robustness under real-world disruptions such as traffic incidents remains largely underexplored. In this study, we introduce T-REX, an open-source, SUMO-based simulation framework for training and evaluating RL-TSC methods under dynamic, incident scenarios. T-REX models realistic network-level performance considering drivers' probabilistic rerouting, speed adaptation, and contextual lane-changing, enabling the simulation of congestion propagation under incidents. To assess robustness, we propose a suite of metrics that extend beyond conventional traffic efficiency measures. Through extensive experiments across synthetic and real-world networks, we showcase T-REX for the evaluation of several state-of-the-art RL-TSC methods under multiple real-world deployment paradigms. Our findings show that while independent value-based and decentralized pressure-based methods offer fast convergence and generalization in stable traffic conditions and homogeneous networks, their performance degrades sharply under incident-driven distribution shifts. In contrast, hierarchical coordination methods tend to offer more stable and adaptable performance in large-scale, irregular networks, benefiting from their structured decision-making architecture. However, this comes with the trade-off of slower convergence and higher training complexity. These findings highlight the need for robustness-aware design and evaluation in RL-TSC research. T-REX contributes to this effort by providing an open, standardized and reproducible platform for benchmarking RL methods under dynamic and disruptive traffic scenarios.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing System Latency for Blockchain-Encrypted Edge Computing in Internet of Vehicles</title>
<link>https://arxiv.org/abs/2506.14208</link>
<guid>https://arxiv.org/abs/2506.14208</guid>
<content:encoded><![CDATA[
arXiv:2506.14208v1 Announce Type: new 
Abstract: As Internet of Vehicles (IoV) technology continues to advance, edge computing has become an important tool for assisting vehicles in handling complex tasks. However, the process of offloading tasks to edge servers may expose vehicles to malicious external attacks, resulting in information loss or even tampering, thereby creating serious security vulnerabilities. Blockchain technology can maintain a shared ledger among servers. In the Raft consensus mechanism, as long as more than half of the nodes remain operational, the system will not collapse, effectively maintaining the system's robustness and security. To protect vehicle information, we propose a security framework that integrates the Raft consensus mechanism from blockchain technology with edge computing. To address the additional latency introduced by blockchain, we derived a theoretical formula for system delay and proposed a convex optimization solution to minimize the system latency, ensuring that the system meets the requirements for low latency and high reliability. Simulation results demonstrate that the optimized data extraction rate significantly reduces system delay, with relatively stable variations in latency. Moreover, the proposed optimization solution based on this model can provide valuable insights for enhancing security and efficiency in future network environments, such as 5G and next-generation smart city systems.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Indicator for Quantifying and Minimizing Information Utility Loss of Robot Teams</title>
<link>https://arxiv.org/abs/2506.14237</link>
<guid>https://arxiv.org/abs/2506.14237</guid>
<content:encoded><![CDATA[
arXiv:2506.14237v1 Announce Type: new 
Abstract: The timely exchange of information among robots within a team is vital, but it can be constrained by limited wireless capacity. The inability to deliver information promptly can result in estimation errors that impact collaborative efforts among robots. In this paper, we propose a new metric termed Loss of Information Utility (LoIU) to quantify the freshness and utility of information critical for cooperation. The metric enables robots to prioritize information transmissions within bandwidth constraints. We also propose the estimation of LoIU using belief distributions and accordingly optimize both transmission schedule and resource allocation strategy for device-to-device transmissions to minimize the time-average LoIU within a robot team. A semi-decentralized Multi-Agent Deep Deterministic Policy Gradient framework is developed, where each robot functions as an actor responsible for scheduling transmissions among its collaborators while a central critic periodically evaluates and refines the actors in response to mobility and interference. Simulations validate the effectiveness of our approach, demonstrating an enhancement of information freshness and utility by 98%, compared to alternative methods.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control</title>
<link>https://arxiv.org/abs/2506.14391</link>
<guid>https://arxiv.org/abs/2506.14391</guid>
<content:encoded><![CDATA[
arXiv:2506.14391v1 Announce Type: new 
Abstract: Efficient traffic signal control (TSC) is essential for mitigating urban congestion, yet existing reinforcement learning (RL) methods face challenges in scaling to large networks while maintaining global coordination. Centralized RL suffers from scalability issues, while decentralized approaches often lack unified objectives, resulting in limited network-level efficiency. In this paper, we propose HiLight, a hierarchical reinforcement learning framework with global adversarial guidance for large-scale TSC. HiLight consists of a high-level Meta-Policy, which partitions the traffic network into subregions and generates sub-goals using a Transformer-LSTM architecture, and a low-level Sub-Policy, which controls individual intersections with global awareness. To improve the alignment between global planning and local execution, we introduce an adversarial training mechanism, where the Meta-Policy generates challenging yet informative sub-goals, and the Sub-Policy learns to surpass these targets, leading to more effective coordination. We evaluate HiLight across both synthetic and real-world benchmarks, and additionally construct a large-scale Manhattan network with diverse traffic conditions, including peak transitions, adverse weather, and holiday surges. Experimental results show that HiLight exhibits significant advantages in large-scale scenarios and remains competitive across standard benchmarks of varying sizes.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Consensus Power Inequality: A Comparative Study of Blockchain Networks</title>
<link>https://arxiv.org/abs/2506.14393</link>
<guid>https://arxiv.org/abs/2506.14393</guid>
<content:encoded><![CDATA[
arXiv:2506.14393v1 Announce Type: new 
Abstract: The distribution of consensus power is a cornerstone of decentralisation, influencing the security, resilience, and fairness of blockchain networks while ensuring equitable impact among participants. This study provides a rigorous evaluation of consensus power inequality across five prominent blockchain networks - Bitcoin, Ethereum, Cardano, Hedera, and Algorand - using data collected from January 2022 to July 2024. Leveraging established economic metrics, including the Gini coefficient and Theil index, the research quantitatively assesses how power is distributed among blockchain network participants. A robust dataset, capturing network-specific characteristics such as mining pools, staking patterns, and consensus nodes, forms the foundation of the analysis, enabling meaningful comparisons across diverse architectures. Through an in-depth comparative study, the paper identifies key disparities in consensus power distribution. Hedera and Bitcoin demonstrate more balanced power distribution, aligning closely with the principles of decentralisation. Ethereum and Cardano demonstrate moderate levels of inequality. However, contrary to expectations, Ethereum has become more concentrated following its transition to Proof-of-Stake. Meanwhile, Algorand shows a pronounced centralisation of power. Moreover, the findings highlight the structural and operational drivers of inequality, including economic barriers, governance models, and network effects, offering actionable insights for more equitable network design. This study establishes a methodological framework for evaluating blockchain consensus power inequality, emphasising the importance of targeted strategies to ensure fairer power distribution and enhancing the sustainability of decentralised systems. Future research will build on these findings by integrating additional metrics and examining the influence of emerging consensus mechanisms.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Network-Independent Incremental Passivity Conditions for Grid-Forming Inverter Control</title>
<link>https://arxiv.org/abs/2506.14469</link>
<guid>https://arxiv.org/abs/2506.14469</guid>
<content:encoded><![CDATA[
arXiv:2506.14469v1 Announce Type: new 
Abstract: Grid-forming inverters control the power transfer between the AC and DC sides of an electrical grid while maintaining the frequency and voltage of the AC side. This paper focuses on ensuring large-signal stability of an electrical grid with inverter-interfaced renewable sources. We prove that the Hybrid-Angle Control (HAC) scheme for grid-forming inverters can exhibit incremental passivity properties between current and voltage at both the AC and DC ports. This incremental passivity can be certified through decentralized conditions. Inverters operating under HAC can, therefore, be connected to other passive elements (e.g. transmission lines) with an immediate guarantee of global transient stability regardless of the network topology or parameters. Passivity of Hybrid Angle Control is also preserved under small-signal (linearized) analyses, in contrast to conventional proportional droop laws that are passivity-short at low frequencies. Passivity and interconnected-stability properties are demonstrated through an example case study.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?</title>
<link>https://arxiv.org/abs/2506.14496</link>
<guid>https://arxiv.org/abs/2506.14496</guid>
<content:encoded><![CDATA[
arXiv:2506.14496v1 Announce Type: new 
Abstract: Swarm intelligence traditionally refers to systems of simple, decentralized agents whose local interactions lead to emergent, collective behavior. Recently, the term 'swarm' has been extended to describe AI systems like OpenAI's Swarm, where large language models (LLMs) act as collaborative agents. This paper contrasts traditional swarm algorithms with LLM-driven swarms exploring how decentralization, scalability, and emergence are redefined in modern artificial intelligence (AI). We implement and compare both paradigms using Boids and Ant Colony Optimization (ACO), evaluating latency, resource usage, and behavioral accuracy. The suitability of both cloud-based and local LLMs is assessed for the agent-based use in swarms. Although LLMs offer powerful reasoning and abstraction capabilities, they introduce new constraints in computation and coordination that challenge traditional notions of swarm design. This study highlights the opportunities and limitations of integrating LLMs into swarm systems and discusses the evolving definition of 'swarm' in modern AI research.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimistic MEV in Ethereum Layer 2s: Why Blockspace Is Always in Demand</title>
<link>https://arxiv.org/abs/2506.14768</link>
<guid>https://arxiv.org/abs/2506.14768</guid>
<content:encoded><![CDATA[
arXiv:2506.14768v1 Announce Type: new 
Abstract: Layer 2 rollups are rapidly absorbing DeFi activity, securing over $40 billion and accounting for nearly half of Ethereum's DEX volume by Q1 2025, yet their MEV dynamics remain understudied. We address this gap by defining and quantifying optimistic MEV, a form of speculative, on-chain cyclic arbitrage whose detection and execution logic reside largely on-chain in smart contracts. As a result of their speculative nature and lack of off-chain opportunity verification, optimistic MEV transactions frequently fail to execute a profitable arbitrage.
  Applying our multi-stage identification pipeline to Arbitrum, Base, and Optimism, we find that in Q1 2025, optimistic MEV accounts for over 50% of on-chain gas on Base and Optimism and 7% on Arbitrum, driven mainly by "interaction" probes (on-chain computations searching for arbitrage). This speculative probing keeps blocks on Base and Optimism persistently full. Despite consuming over half of on-chain gas, optimistic MEV transactions pay less than one quarter of total gas fees. Cross-network comparison reveals divergent success rates, differing patterns of code reuse, and sensitivity to varying sequencer ordering and block production times. Finally, OLS regressions link optimistic MEV trade count to ETH volatility, retail trading activity, and DEX aggregator usage, showing how Layer 2 protocol parameters uniquely encourage speculative MEV.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature</title>
<link>https://arxiv.org/abs/2308.12420</link>
<guid>https://arxiv.org/abs/2308.12420</guid>
<content:encoded><![CDATA[
arXiv:2308.12420v4 Announce Type: replace 
Abstract: Distributed Ledger Technology (DLT) faces increasing environmental scrutiny, particularly concerning the energy consumption of the Proof of Work (PoW) consensus mechanism and broader Environmental, Social, and Governance (ESG) issues. However, existing systematic literature reviews of DLT rely on limited analyses of citations, abstracts, and keywords, failing to fully capture the field's complexity and ESG concerns. We address these challenges by analyzing the full text of 24,539 publications using Natural Language Processing (NLP) with our manually labeled Named Entity Recognition (NER) dataset of 39,427 entities for DLT. This methodology identified 505 key publications at the DLT/ESG intersection, enabling comprehensive domain analysis. Our combined NLP and temporal graph analysis reveals critical trends in DLT evolution and ESG impacts, including cryptography and peer-to-peer networks research's foundational influence, Bitcoin's persistent impact on research and environmental concerns (a "Lindy effect"), Ethereum's catalytic role on Proof of Stake (PoS) and smart contract adoption, and the industry's progressive shift toward energy-efficient consensus mechanisms. Our contributions include the first DLT-specific NER dataset addressing the scarcity of high-quality labeled NLP data in blockchain research, a methodology integrating NLP and temporal graph analysis for large-scale interdisciplinary literature reviews, and the first NLP-driven literature review focusing on DLT's ESG aspects.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Data to Control: A Formal Compositional Framework for Large-Scale Interconnected Networks</title>
<link>https://arxiv.org/abs/2409.12469</link>
<guid>https://arxiv.org/abs/2409.12469</guid>
<content:encoded><![CDATA[
arXiv:2409.12469v2 Announce Type: replace 
Abstract: We introduce a compositional data-driven methodology with noisy data for designing fully-decentralized safety controllers applicable to large-scale interconnected networks, encompassing a vast number of subsystems with unknown mathematical models. Our compositional scheme leverages the interconnection topology and breaks down the network analysis into the examination of distinct subsystems. This is accompanied by utilizing a concept of control storage certificates (CSCs) to capture joint dissipativity-type properties among subsystems. These CSCs are instrumental in a compositional derivation of a control barrier certificate (CBC) specialized for the interconnected network, thereby ensuring its safety. In our data-driven scheme, we gather only a single noise-corrupted input-state trajectory from each unknown subsystem within a specified time frame. By fulfilling a specific rank condition, this process facilitates the construction of a CSC for each subsystem. Following this, by adhering to compositional dissipativity reasoning, we compose CSCs derived from noisy data and build a CBC for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We demonstrate that our compositional data-driven approach significantly enhances the design of a CBC and its robust safety controller under noisy data across the interconnected network. This advancement is achieved by reducing the computational complexity from a polynomial growth in relation to network dimension, when using sum-of-squares (SOS) optimization, to a linear scale based on the number of subsystems. We apply our data-driven findings to a variety of benchmarks, involving physical networks with unknown models and diverse interconnection topologies.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Federated Learning using Remote Embeddings for Graph Neural Networks</title>
<link>https://arxiv.org/abs/2506.12425</link>
<guid>https://arxiv.org/abs/2506.12425</guid>
<content:encoded><![CDATA[
arXiv:2506.12425v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) have experienced rapid advancements in recent years due to their ability to learn meaningful representations from graph data structures. Federated Learning (FL) has emerged as a viable machine learning approach for training a shared model on decentralized data, addressing privacy concerns while leveraging parallelism. Existing methods that address the unique requirements of federated GNN training using remote embeddings to enhance convergence accuracy are limited by their diminished performance due to large communication costs with a shared embedding server. In this paper, we present OpES, an optimized federated GNN training framework that uses remote neighbourhood pruning, and overlaps pushing of embeddings to the server with local training to reduce the network costs and training time. The modest drop in per-round accuracy due to pre-emptive push of embeddings is out-stripped by the reduction in per-round training time for large and dense graphs like Reddit and Products, converging up to $\approx2\times$ faster than the state-of-the-art technique using an embedding server and giving up to $20\%$ better accuracy than vanilla federated GNN learning.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real-Time Agile Software Management for Edge and Fog Computing Based Smart City Infrastructure</title>
<link>https://arxiv.org/abs/2506.12616</link>
<guid>https://arxiv.org/abs/2506.12616</guid>
<content:encoded><![CDATA[
arXiv:2506.12616v1 Announce Type: new 
Abstract: The evolution of smart cities demands scalable, secure, and energy-efficient architectures for real-time data processing. With the number of IoT devices expected to exceed 40 billion by 2030, traditional cloud-based systems are increasingly constrained by bandwidth, latency, and energy limitations. This paper leverages the ROOF (Real-time Onsite Operations Facilitation) framework with decentralized computing at intermediary fog and peripheral edge network layers to reduce latency by processing data near its point of origin. ROOF features fog caching to avoid redundancy, ultra-low-power wireless transmission for energy savings, and AI-driven resource allocation for efficiency. Security is enhanced through TLS encryption, blockchain-based authentication, and edge-level access control. Case studies from Bhubaneswar, Barcelona and Copenhagen validate the use of ROOF in traffic systems and environmental monitoring. The paper concludes by outlining key challenges and prospects of AI-driven analytics in smart urban infrastructure.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Decision Making in Two Sided Manufacturing-as-a-Service Marketplaces</title>
<link>https://arxiv.org/abs/2506.12730</link>
<guid>https://arxiv.org/abs/2506.12730</guid>
<content:encoded><![CDATA[
arXiv:2506.12730v1 Announce Type: new 
Abstract: Advancements in digitization have enabled two sided manufacturing-as-a-service (MaaS) marketplaces which has significantly reduced product development time for designers. These platforms provide designers with access to manufacturing resources through a network of suppliers and have instant order placement capabilities. Two key decision making levers are typically used to optimize the operations of these marketplaces: pricing and matching. The existing marketplaces operate in a centralized structure where they have complete control over decision making. However, a decentralized organization of the platform enables transparency of information across clients and suppliers. This dissertation focuses on developing tools for decision making enabling decentralization in MaaS marketplaces. In pricing mechanisms, a data driven method is introduced which enables small service providers to price services based on specific attributes of the services offered. A data mining method recommends a network based price to a supplier based on its attributes and the attributes of other suppliers on the platform. Three different approaches are considered for matching mechanisms. First, a reverse auction mechanism is introduced where designers bid for manufacturing services and the mechanism chooses a supplier which can match the bid requirements and stated price. The second approach uses mechanism design and mathematical programming to develop a stable matching mechanism for matching orders to suppliers based on their preferences. Empirical simulations are used to test the mechanisms in a simulated 3D printing marketplace and to evaluate the impact of stability on its performance. The third approach considers the matching problem in a dynamic and stochastic environment where demand (orders) and supply (supplier capacities) arrive over time and matching is performed online.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IDOL: Improved Different Optimization Levels Testing for Solidity Compilers</title>
<link>https://arxiv.org/abs/2506.12760</link>
<guid>https://arxiv.org/abs/2506.12760</guid>
<content:encoded><![CDATA[
arXiv:2506.12760v1 Announce Type: new 
Abstract: As blockchain technology continues to evolve and mature, smart contracts have become a key driving force behind the digitization and automation of transactions. Smart contracts greatly simplify and refine the traditional business transaction processes, and thus have had a profound impact on various industries such as finance and supply chain management. However, because smart contracts cannot be modified once deployed, any vulnerabilities or design flaws within the contract cannot be easily fixed, potentially leading to significant financial losses or even legal issues. The compiler, as a critical component in the development process, directly affects the quality and security of smart contracts. This paper innovatively proposes a method, known as the Improved Different Optimization Levels (IDOL), for testing the Solidity compiler. The key idea behind IDOL is to perform reverse optimization transformations (i.e., change optimized form into unoptimized form) to generate semantically equivalent variants of the smart contracts under test, aiming to maximize the opportunities to trigger the optimization logic of compilers. We conducted a preliminary evaluation of IDOL and three confirmed compiler optimization bugs have been uncovered at the time of writing.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Federated Learning against Malicious Clients Based on Verifiable Functional Encryption</title>
<link>https://arxiv.org/abs/2506.12846</link>
<guid>https://arxiv.org/abs/2506.12846</guid>
<content:encoded><![CDATA[
arXiv:2506.12846v1 Announce Type: new 
Abstract: Federated learning is a promising distributed learning paradigm that enables collaborative model training without exposing local client data, thereby protect data privacy. However, it also brings new threats and challenges. The advancement of model inversion attacks has rendered the plaintext transmission of local models insecure, while the distributed nature of federated learning makes it particularly vulnerable to attacks raised by malicious clients. To protect data privacy and prevent malicious client attacks, this paper proposes a privacy-preserving federated learning framework based on verifiable functional encryption, without a non-colluding dual-server setup or additional trusted third-party. Specifically, we propose a novel decentralized verifiable functional encryption (DVFE) scheme that enables the verification of specific relationships over multi-dimensional ciphertexts. This scheme is formally treated, in terms of definition, security model and security proof. Furthermore, based on the proposed DVFE scheme, we design a privacy-preserving federated learning framework VFEFL that incorporates a novel robust aggregation rule to detect malicious clients, enabling the effective training of high-accuracy models under adversarial settings. Finally, we provide formal analysis and empirical evaluation of the proposed schemes. The results demonstrate that our approach achieves the desired privacy protection, robustness, verifiability and fidelity, while eliminating the reliance on non-colluding dual-server settings or trusted third parties required by existing methods.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Stabilizing Replicated State Machine Coping with Byzantine and Recurring Transient Faults</title>
<link>https://arxiv.org/abs/2506.12900</link>
<guid>https://arxiv.org/abs/2506.12900</guid>
<content:encoded><![CDATA[
arXiv:2506.12900v1 Announce Type: new 
Abstract: The ability to perform repeated Byzantine agreement lies at the heart of important applications such as blockchain price oracles or replicated state machines. Any such protocol requires the following properties: (1) \textit{Byzantine fault-tolerance}, because not all participants can be assumed to be honest, (2) r\textit{ecurrent transient fault-tolerance}, because even honest participants may be subject to transient ``glitches'', (3) \textit{accuracy}, because the results of quantitative queries (such as price quotes) must lie within the interval of honest participants' inputs, and (4) \textit{self-stabilization}, because it is infeasible to reboot a distributed system following a fault.
  This paper presents the first protocol for repeated Byzantine agreement that satisfies the properties listed above. Specifically, starting in an arbitrary system configuration, our protocol establishes consistency. It preserves consistency in the face of up to $\lceil n/3 \rceil -1$ Byzantine participants {\em and} constant recurring (``noise'') transient faults, of up to $\lceil n/6 \rceil-1$ additional malicious transient faults, or even more than $\lceil n/6 \rceil-1$ (uniformly distributed) random transient faults, in each repeated Byzantine agreement.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Immutable Memory Systems for Artificial Agents: A Blockchain-Indexed Automata-Theoretic Framework Using ECDH-Keyed Merkle Chains</title>
<link>https://arxiv.org/abs/2506.13246</link>
<guid>https://arxiv.org/abs/2506.13246</guid>
<content:encoded><![CDATA[
arXiv:2506.13246v1 Announce Type: new 
Abstract: This paper presents a formalised architecture for synthetic agents designed to retain immutable memory, verifiable reasoning, and constrained epistemic growth. Traditional AI systems rely on mutable, opaque statistical models prone to epistemic drift and historical revisionism. In contrast, we introduce the concept of the Merkle Automaton, a cryptographically anchored, deterministic computational framework that integrates formal automata theory with blockchain-based commitments. Each agent transition, memory fragment, and reasoning step is committed within a Merkle structure rooted on-chain, rendering it non-repudiable and auditably permanent. To ensure selective access and confidentiality, we derive symmetric encryption keys from ECDH exchanges contextualised by hierarchical privilege lattices. This enforces cryptographic access control over append-only DAG-structured knowledge graphs. Reasoning is constrained by formal logic systems and verified through deterministic traversal of policy-encoded structures. Updates are non-destructive and historied, preserving epistemic lineage without catastrophic forgetting. Zero-knowledge proofs facilitate verifiable, privacy-preserving inclusion attestations. Collectively, this architecture reframes memory not as a cache but as a ledger - one whose contents are enforced by protocol, bound by cryptography, and constrained by formal logic. The result is not an intelligent agent that mimics thought, but an epistemic entity whose outputs are provably derived, temporally anchored, and impervious to post hoc revision. This design lays foundational groundwork for legal, economic, and high-assurance computational systems that require provable memory, unforgeable provenance, and structural truth.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>One-dimensional vs. Multi-dimensional Pricing in Blockchain Protocols</title>
<link>https://arxiv.org/abs/2506.13271</link>
<guid>https://arxiv.org/abs/2506.13271</guid>
<content:encoded><![CDATA[
arXiv:2506.13271v1 Announce Type: new 
Abstract: Blockchain transactions consume diverse resources, foremost among them storage, but also computation, communication, and others. Efficiently charging for these resources is crucial for effective system resource allocation and long-term economic viability. The prevailing approach, one-dimensional pricing, sets a single price for a linear combination of resources. However, this often leads to under-utilization when resource capacities are limited. Multi-dimensional pricing, which independently prices each resource, offers an alternative but presents challenges in price discovery.
  This work focuses on the welfare achieved by these two schemes. We prove that multi-dimensional pricing is superior under stable blockchain conditions. Conversely, we show that one-dimensional pricing outperforms its multi-dimensional counterpart in transient states, exhibiting faster convergence and greater computational tractability. These results highlight a critical trade-off: while multi-dimensional pricing offers efficiency gains at equilibrium, its implementation incurs costs associated with system transitions. Our findings underscore the necessity for a deeper understanding of these transient effects before widespread adoption. Finally, we propose mechanisms that aim to mitigate some of these issues, paving the way for future research.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Rich Get Richer in Bitcoin Mining Induced by Blockchain Forks</title>
<link>https://arxiv.org/abs/2506.13360</link>
<guid>https://arxiv.org/abs/2506.13360</guid>
<content:encoded><![CDATA[
arXiv:2506.13360v1 Announce Type: new 
Abstract: Bitcoin is a representative decentralized currency system. For the security of Bitcoin, fairness in the distribution of mining rewards plays a crucial role in preventing the concentration of computational power in a few miners. Here, fairness refers to the distribution of block rewards in proportion to contributed computational resources. If miners with greater computational resources receive disproportionately higher rewards, i.e., if the Rich Get Richer (TRGR) phenomenon holds in Bitcoin, it indicates a threat to the system's decentralization. This study analyzes TRGR in Bitcoin by focusing on unintentional blockchain forks, an inherent phenomenon in Bitcoin. Previous research has failed to provide generalizable insights due to the low precision of their analytical methods. In contrast, we avoid this problem by adopting a method whose analytical precision has been empirically validated. The primary contribution of this work is a theoretical analysis that clearly demonstrates TRGR in Bitcoin under the assumption of fixed block propagation delays between different miners. More specifically, we show that the mining profit rate depends linearly on the proportion of hashrate. Furthermore, we examine the robustness of this result from multiple perspectives in scenarios where block propagation delays between different miners are not necessarily fixed.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering</title>
<link>https://arxiv.org/abs/2506.13755</link>
<guid>https://arxiv.org/abs/2506.13755</guid>
<content:encoded><![CDATA[
arXiv:2506.13755v1 Announce Type: new 
Abstract: This paper introduces MARCO (Multi-Agent Reinforcement learning with Conformal Optimization), a novel hardware-aware framework for efficient neural architecture search (NAS) targeting resource-constrained edge devices. By significantly reducing search time and maintaining accuracy under strict hardware constraints, MARCO bridges the gap between automated DNN design and CAD for edge AI deployment. MARCO's core technical contribution lies in its unique combination of multi-agent reinforcement learning (MARL) with Conformal Prediction (CP) to accelerate the hardware/software co-design process for deploying deep neural networks. Unlike conventional once-for-all (OFA) supernet approaches that require extensive pretraining, MARCO decomposes the NAS task into a hardware configuration agent (HCA) and a Quantization Agent (QA). The HCA optimizes high-level design parameters, while the QA determines per-layer bit-widths under strict memory and latency budgets using a shared reward signal within a centralized-critic, decentralized-execution (CTDE) paradigm. A key innovation is the integration of a calibrated CP surrogate model that provides statistical guarantees (with a user-defined miscoverage rate) to prune unpromising candidate architectures before incurring the high costs of partial training or hardware simulation. This early filtering drastically reduces the search space while ensuring that high-quality designs are retained with a high probability. Extensive experiments on MNIST, CIFAR-10, and CIFAR-100 demonstrate that MARCO achieves a 3-4x reduction in total search time compared to an OFA baseline while maintaining near-baseline accuracy (within 0.3%). Furthermore, MARCO also reduces inference latency. Validation on a MAX78000 evaluation board confirms that simulator trends hold in practice, with simulator estimates deviating from measured values by less than 5%.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OSI Stack Redesign for Quantum Networks: Requirements, Technologies, Challenges, and Future Directions</title>
<link>https://arxiv.org/abs/2506.12195</link>
<guid>https://arxiv.org/abs/2506.12195</guid>
<content:encoded><![CDATA[
arXiv:2506.12195v1 Announce Type: cross 
Abstract: Quantum communication is poised to become a foundational element of next-generation networking, offering transformative capabilities in security, entanglement-based connectivity, and computational offloading. However, the classical OSI model-designed for deterministic and error-tolerant systems-cannot support quantum-specific phenomena such as coherence fragility, probabilistic entanglement, and the no-cloning theorem. This paper provides a comprehensive survey and proposes an architectural redesign of the OSI model for quantum networks in the context of 7G. We introduce a Quantum-Converged OSI stack by extending the classical model with Layer 0 (Quantum Substrate) and Layer 8 (Cognitive Intent), supporting entanglement, teleportation, and semantic orchestration via LLMs and QML. Each layer is redefined to incorporate quantum mechanisms such as enhanced MAC protocols, fidelity-aware routing, and twin-based applications. This survey consolidates over 150 research works from IEEE, ACM, MDPI, arXiv, and Web of Science (2018-2025), classifying them by OSI layer, enabling technologies such as QKD, QEC, PQC, and RIS, and use cases such as satellite QKD, UAV swarms, and quantum IoT. A taxonomy of cross-layer enablers-such as hybrid quantum-classical control, metadata-driven orchestration, and blockchain-integrated quantum trust-is provided, along with simulation tools including NetSquid, QuNetSim, and QuISP. We present several domain-specific applications, including quantum healthcare telemetry, entangled vehicular networks, and satellite mesh overlays. An evaluation framework is proposed based on entropy throughput, coherence latency, and entanglement fidelity. Key future directions include programmable quantum stacks, digital twins, and AI-defined QNet agents, laying the groundwork for a scalable, intelligent, and quantum-compliant OSI framework for 7G and beyond.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Regret Minimization and Convergence to Equilibria in General-sum Markov Games</title>
<link>https://arxiv.org/abs/2207.14211</link>
<guid>https://arxiv.org/abs/2207.14211</guid>
<content:encoded><![CDATA[
arXiv:2207.14211v3 Announce Type: replace 
Abstract: An abundance of recent impossibility results establish that regret minimization in Markov games with adversarial opponents is both statistically and computationally intractable. Nevertheless, none of these results preclude the possibility of regret minimization under the assumption that all parties adopt the same learning procedure. In this work, we present the first (to our knowledge) algorithm for learning in general-sum Markov games that provides sublinear regret guarantees when executed by all agents. The bounds we obtain are for swap regret, and thus, along the way, imply convergence to a correlated equilibrium. Our algorithm is decentralized, computationally efficient, and does not require any communication between agents. Our key observation is that online learning via policy optimization in Markov games essentially reduces to a form of weighted regret minimization, with unknown weights determined by the path length of the agents' policy sequence. Consequently, controlling the path length leads to weighted regret objectives for which sufficiently adaptive algorithms provide sublinear regret guarantees.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain and Biometrics: Survey, GDPR Elements, and Future Directions</title>
<link>https://arxiv.org/abs/2302.10883</link>
<guid>https://arxiv.org/abs/2302.10883</guid>
<content:encoded><![CDATA[
arXiv:2302.10883v3 Announce Type: replace 
Abstract: Biometric recognition as an efficient and hard-to-forge way of identification and verification has become an indispensable part of the current digital world. The fast evolution of this technology has been a strong incentive for integration into many applications. Meanwhile, blockchain, the decentralized ledger technology, has been widely received by both research and industry in the past few years, and it is being increasingly deployed today in many different applications, such as money transfer, IoT, healthcare, or logistics. Recently, researchers have started to speculate on the pros and cons and what the best applications would be when these two technologies cross paths. This paper provides a survey of the research literature on the combination of blockchain and biometrics and includes a first legal analysis of this integration based on GDPR to shed light on challenges and potentials. Although the integration of blockchain technology into the biometric sector is still in its infancy, with a growing body of literature discussing specific applications and advanced technological setups, this paper aims to provide a holistic understanding of blockchain applicability in biometrics. Based on published studies, this article discusses, among others, practical examples combining blockchain and biometrics for novel applications in PKI systems, distributed trusted services, and identity management. Challenges and limitations when combining blockchain and biometrics that motivate future work will also be discussed; e.g., blockchain networks at their current stage may not be efficient or economical for some real-time biometric applications. Finally, we also discuss key legal aspects of the EU General Data Protection Regulation (GDPR) related to this combination of technologies (blockchain and biometrics); for example, accountability, immutability, anonymity, and data protection elements.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A philosophical and ontological perspective on Artificial General Intelligence and the Metaverse</title>
<link>https://arxiv.org/abs/2402.06660</link>
<guid>https://arxiv.org/abs/2402.06660</guid>
<content:encoded><![CDATA[
arXiv:2402.06660v4 Announce Type: replace 
Abstract: This paper leverages various philosophical and ontological frameworks to explore the concept of embodied artificial general intelligence (AGI), its relationship to human consciousness, and the key role of the metaverse in facilitating this relationship. Several theoretical frameworks underpin this exploration, such as embodied cognition, Michael Levin's computational boundary of a "Self," and Donald D. Hoffman's Interface Theory of Perception, which lead to considering human perceived outer reality as a symbolic representation of alternate inner states of being, and where AGI could embody a different form of consciousness with a larger computational boundary. The paper further discusses the necessary architecture for the emergence of an embodied AGI, how to calibrate an AGI's symbolic interface, and the key role played by the Metaverse, decentralized systems and open-source blockchain technology. The paper concludes by emphasizing the importance of achieving a certain degree of harmony in human relations and recognizing the interconnectedness of humanity at a global level, as key prerequisites for the emergence of a stable embodied AGI.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Wireless Federated Learning for Large Language Models</title>
<link>https://arxiv.org/abs/2404.13238</link>
<guid>https://arxiv.org/abs/2404.13238</guid>
<content:encoded><![CDATA[
arXiv:2404.13238v2 Announce Type: replace 
Abstract: Large language models (LLMs) have driven profound transformations in wireless networks. However, within wireless environments, the training of LLMs faces significant challenges related to security and privacy. Federated Learning (FL), with its decentralized architecture, offers enhanced data privacy protection. Nevertheless, when integrated with LLMs, FL still struggles with several critical limitations, including large-scale and heterogeneous data, resource-intensive training, and substantial communication overhead. To address these challenges, this paper first presents a systematic analysis of the distinct training stages of LLMs in wireless networks, including pre-training, instruction tuning, and alignment tuning. Building upon this foundation, we propose a Personalized Wireless Federated Fine-tuning (PWFF) framework. Initially, we utilize the adapter and Low-Rank Adaptation (LoRA) techniques to decrease energy consumption, while employing global partial aggregation to reduce communication delay. Subsequently, we develop two reward models and design a personalized loss function to fulfill the goal of personalized learning. Furthermore, we implement a local multi-objective alignment to ensure the stability and effectiveness of the FL process. Finally, we conduct a series of simulations to validate the performance of the proposed PWFF method and provide an in-depth discussion of the open issues.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Distributed Graph Coloring: Cluster Graphs</title>
<link>https://arxiv.org/abs/2405.07725</link>
<guid>https://arxiv.org/abs/2405.07725</guid>
<content:encoded><![CDATA[
arXiv:2405.07725v2 Announce Type: replace 
Abstract: Graph coloring is fundamental to distributed computing. We give the first sub-logarithmic distributed algorithm for coloring cluster graphs. These graphs are obtained from the underlying communication network by contracting nodes and edges, and they appear frequently as components in the study of distributed algorithms. In particular, we give a $O(\log^* n)$-round algorithm to $(\Delta+1)$-color cluster graphs of at least polylogarithmic degree. The previous best bound known was $\operatorname{poly}(\log n)$ [Flin et al., SODA'24]. This properly generalizes results in the CONGEST model and shows that distributed graph problems can be solved quickly even when the node itself is decentralized.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dimension Reduction via Random Projection for Privacy in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2412.04031</link>
<guid>https://arxiv.org/abs/2412.04031</guid>
<content:encoded><![CDATA[
arXiv:2412.04031v2 Announce Type: replace 
Abstract: The agents in a Multi-Agent System (MAS) make observations about the system and send that information to a fusion center. The fusion center aggregates the information and concludes about the system parameters with as much accuracy as possible. However for the purposes of better efficiency of the system at large, the agents need to append some private parameters to the observed data. In this scenario, the data sent to the fusion center is faced with privacy risks. The data communicated to the fusion center must be secured against data privacy breaches and inference attacks in a decentralized manner. However, this in turn leads to a loss of utility of the data being sent to the fusion center. We quantify the utility and privacy of the system using Cosine similarity. We formulate our MAS problem in terms of deducing a concept for which compression-based methods are there in literature. Next, we propose a novel sanitization mechanism for our MAS using one such compression-based method while addressing the utility-privacy tradeoff problem.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Address Poisoning</title>
<link>https://arxiv.org/abs/2501.16681</link>
<guid>https://arxiv.org/abs/2501.16681</guid>
<content:encoded><![CDATA[
arXiv:2501.16681v2 Announce Type: replace 
Abstract: In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on both Ethereum and BSC. We identify 13~times more attack attempts than reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces</title>
<link>https://arxiv.org/abs/2506.11025</link>
<guid>https://arxiv.org/abs/2506.11025</guid>
<content:encoded><![CDATA[
arXiv:2506.11025v1 Announce Type: new 
Abstract: This paper examines how synthetically generated faces and machine learning-based gender classification algorithms are affected by algorithmic lookism, the preferential treatment based on appearance. In experiments with 13,200 synthetically generated faces, we find that: (1) text-to-image (T2I) systems tend to associate facial attractiveness to unrelated positive traits like intelligence and trustworthiness; and (2) gender classification models exhibit higher error rates on "less-attractive" faces, especially among non-White women. These result raise fairness concerns regarding digital identity systems.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul</title>
<link>https://arxiv.org/abs/2506.11284</link>
<guid>https://arxiv.org/abs/2506.11284</guid>
<content:encoded><![CDATA[
arXiv:2506.11284v1 Announce Type: new 
Abstract: We study the problem of uplink compression for cell-free multi-input multi-output networks with limited fronthaul capacity. In compress-forward mode, remote radio heads (RRHs) compress the received signal and forward it to a central unit for joint processing. While previous work has focused on a transform-based approach, which optimizes the transform matrix that reduces signals of high dimension to a static pre-determined lower dimension, we propose a rate-based approach that simultaneously finds both dimension and compression adaptively. Our approach accommodates for changes to network traffic and fronthaul limits. Using mutual information as the objective, we obtain the theoretical network capacity for adaptive compression and decouple the expression to enable decentralization. Furthermore, using channel statistics and user traffic density, we show different approaches to compute an efficient representation of side information that summarizes global channel state information and is shared with RRHs to assist compression. While keeping the information exchange overhead low, our decentralized implementation of adaptive compression shows competitive overall network performance compared to a centralized approach.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine Outside, Curious Inside: Reconstructing Data Through Malicious Updates</title>
<link>https://arxiv.org/abs/2506.11413</link>
<guid>https://arxiv.org/abs/2506.11413</guid>
<content:encoded><![CDATA[
arXiv:2506.11413v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized machine learning without sharing raw data, allowing multiple clients to collaboratively learn a global model. However, studies reveal that privacy leakage is possible under commonly adopted FL protocols. In particular, a server with access to client gradients can synthesize data resembling the clients' training data. In this paper, we introduce a novel threat model in FL, named the maliciously curious client, where a client manipulates its own gradients with the goal of inferring private data from peers. This attacker uniquely exploits the strength of a Byzantine adversary, traditionally aimed at undermining model robustness, and repurposes it to facilitate data reconstruction attack. We begin by formally defining this novel client-side threat model and providing a theoretical analysis that demonstrates its ability to achieve significant reconstruction success during FL training. To demonstrate its practical impact, we further develop a reconstruction algorithm that combines gradient inversion with malicious update strategies. Our analysis and experimental results reveal a critical blind spot in FL defenses: both server-side robust aggregation and client-side privacy mechanisms may fail against our proposed attack. Surprisingly, standard server- and client-side defenses designed to enhance robustness or privacy may unintentionally amplify data leakage. Compared to the baseline approach, a mistakenly used defense may instead improve the reconstructed image quality by 10-15%.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic</title>
<link>https://arxiv.org/abs/2506.11451</link>
<guid>https://arxiv.org/abs/2506.11451</guid>
<content:encoded><![CDATA[
arXiv:2506.11451v1 Announce Type: new 
Abstract: Blockchain-based software systems are increasingly deployed across diverse domains, yet a systematic understanding of their development challenges remains limited. This paper presents a large-scale empirical study of 497,742 issues mined from 1,209 open-source blockchain projects hosted on GitHub. Employing BERTopic, a transformer-based topic modeling technique, we identify 49 distinct issue topics and organize them hierarchically into 11 major subcategories. Our analysis reveals that both general software development issues and blockchain-specific concerns are nearly equally represented, with Wallet Management and UI Enhancement emerging as the most prominent topics. We further examine the temporal evolution of issue categories and resolution times, finding that Wallet issues not only dominate in frequency but also exhibit the longest resolution time. Conversely, Mechanisms issues are resolved significantly faster. Issue frequency surged after 2016 with the rise of Ethereum and decentralized applications, but declined after 2022. These findings enhance our understanding of blockchain software maintenance, informing the development of specialized tools and practices to improve robustness and maintainability.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learn to Preserve Personality: Federated Foundation Models in Recommendations</title>
<link>https://arxiv.org/abs/2506.11563</link>
<guid>https://arxiv.org/abs/2506.11563</guid>
<content:encoded><![CDATA[
arXiv:2506.11563v1 Announce Type: new 
Abstract: A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user centric, decentralized system where individuals maintain control over their personalized agents.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NTK-DFL: Enhancing Decentralized Federated Learning in Heterogeneous Settings via Neural Tangent Kernel</title>
<link>https://arxiv.org/abs/2410.01922</link>
<guid>https://arxiv.org/abs/2410.01922</guid>
<content:encoded><![CDATA[
arXiv:2410.01922v2 Announce Type: replace 
Abstract: Decentralized federated learning (DFL) is a collaborative machine learning framework for training a model across participants without a central server or raw data exchange. DFL faces challenges due to statistical heterogeneity, as participants often possess data of different distributions reflecting local environments and user behaviors. Recent work has shown that the neural tangent kernel (NTK) approach, when applied to federated learning in a centralized framework, can lead to improved performance. We propose an approach leveraging the NTK to train client models in the decentralized setting, while introducing a synergy between NTK-based evolution and model averaging. This synergy exploits inter-client model deviation and improves both accuracy and convergence in heterogeneous settings. Empirical results demonstrate that our approach consistently achieves higher accuracy than baselines in highly heterogeneous settings, where other approaches often underperform. Additionally, it reaches target performance in 4.6 times fewer communication rounds. We validate our approach across multiple datasets, network topologies, and heterogeneity settings to ensure robustness and generalization.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noncooperative Equilibrium Selection via a Trading-based Auction</title>
<link>https://arxiv.org/abs/2502.03616</link>
<guid>https://arxiv.org/abs/2502.03616</guid>
<content:encoded><![CDATA[
arXiv:2502.03616v2 Announce Type: replace 
Abstract: Noncooperative multi-agent systems often face coordination challenges due to conflicting preferences among agents. In particular, agents acting in their own self-interest can settle on different equilibria, leading to suboptimal outcomes or even safety concerns. We propose an algorithm named trading auction for consensus (TACo), a decentralized approach that enables noncooperative agents to reach consensus without communicating directly or disclosing private valuations. TACo facilitates coordination through a structured trading-based auction, where agents iteratively select choices of interest and provably reach an agreement within an a priori bounded number of steps. A series of numerical experiments validate that the termination guarantees of TACo hold in practice, and show that TACo achieves a median performance that minimizes the total cost across all agents, while allocating resources significantly more fairly than baseline approaches.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Communication-Enabled Cloud-Edge-End-collaborative Metaverse Services Architecure</title>
<link>https://arxiv.org/abs/2506.10001</link>
<guid>https://arxiv.org/abs/2506.10001</guid>
<content:encoded><![CDATA[
arXiv:2506.10001v1 Announce Type: new 
Abstract: With technology advancing and the pursuit of new audiovisual experiences strengthening, the metaverse has gained surging enthusiasm. However, it faces practical hurdles as substantial data like high-resolution virtual scenes must be transmitted between cloud platforms and VR devices. Specifically, the VR device's wireless transmission hampered by insufficient bandwidth, causes speed and delay problems. Meanwhile, poor channel quality leads to data errors and worsens user experience. To solve this, we've proposed the Semantic Communication-Enabled Cloud-Edge-End Collaborative Immersive Metaverse Service (SC-CEE-Meta) Architecture, which includes three modules: VR video semantic transmission, video synthesis, and 3D virtual scene reconstruction. By deploying semantic modules on VR devices and edge servers and sending key semantic info instead of focusing on bit-level reconstruction, it can cut latency, resolve the resource-bandwidth conflict, and better withstand channel interference. Also, the cloud deploys video synthesis and 3D scene reconstruction preprocessing, while edge devices host 3D reconstruction rendering modules, all for immersive services. Verified on Meta Quest Pro, the SC-CEE-Meta can reduce wireless transmission delay by 96.05\% and boost image quality by 43.99\% under poor channel condition.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Meet Me at the Arm: The Cooperative Multi-Armed Bandits Problem with Shareable Arms</title>
<link>https://arxiv.org/abs/2506.10127</link>
<guid>https://arxiv.org/abs/2506.10127</guid>
<content:encoded><![CDATA[
arXiv:2506.10127v1 Announce Type: new 
Abstract: We study the decentralized multi-player multi-armed bandits (MMAB) problem under a no-sensing setting, where each player receives only their own reward and obtains no information about collisions. Each arm has an unknown capacity, and if the number of players pulling an arm exceeds its capacity, all players involved receive zero reward. This setting generalizes the classical unit-capacity model and introduces new challenges in coordination and capacity discovery under severe feedback limitations. We propose A-CAPELLA (Algorithm for Capacity-Aware Parallel Elimination for Learning and Allocation), a decentralized algorithm that achieves logarithmic regret in this generalized regime. Our main contribution is a collaborative hypothesis testing protocol that enables synchronized successive elimination and capacity estimation through carefully structured collision patterns. This represents a provably efficient learning result in decentralized no-sensing MMAB with unknown arm capacities.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A new type of federated clustering: A non-model-sharing approach</title>
<link>https://arxiv.org/abs/2506.10244</link>
<guid>https://arxiv.org/abs/2506.10244</guid>
<content:encoded><![CDATA[
arXiv:2506.10244v1 Announce Type: new 
Abstract: In recent years, the growing need to leverage sensitive data across institutions has led to increased attention on federated learning (FL), a decentralized machine learning paradigm that enables model training without sharing raw data. However, existing FL-based clustering methods, known as federated clustering, typically assume simple data partitioning scenarios such as horizontal or vertical splits, and cannot handle more complex distributed structures. This study proposes data collaboration clustering (DC-Clustering), a novel federated clustering method that supports clustering over complex data partitioning scenarios where horizontal and vertical splits coexist. In DC-Clustering, each institution shares only intermediate representations instead of raw data, ensuring privacy preservation while enabling collaborative clustering. The method allows flexible selection between k-means and spectral clustering, and achieves final results with a single round of communication with the central server. We conducted extensive experiments using synthetic and open benchmark datasets. The results show that our method achieves clustering performance comparable to centralized clustering where all data are pooled. DC-Clustering addresses an important gap in current FL research by enabling effective knowledge discovery from distributed heterogeneous data. Its practical properties -- privacy preservation, communication efficiency, and flexibility -- make it a promising tool for privacy-sensitive domains such as healthcare and finance.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video</title>
<link>https://arxiv.org/abs/2506.10331</link>
<guid>https://arxiv.org/abs/2506.10331</guid>
<content:encoded><![CDATA[
arXiv:2506.10331v1 Announce Type: new 
Abstract: In response to the rising prominence of the Metaverse, omnidirectional videos (ODVs) have garnered notable interest, gradually shifting from professional-generated content (PGC) to user-generated content (UGC). However, the study of audio-visual quality assessment (AVQA) within ODVs remains limited. To address this, we construct a dataset of UGC omnidirectional audio and video (A/V) content. The videos are captured by five individuals using two different types of omnidirectional cameras, shooting 300 videos covering 10 different scene types. A subjective AVQA experiment is conducted on the dataset to obtain the Mean Opinion Scores (MOSs) of the A/V sequences. After that, to facilitate the development of UGC-ODV AVQA fields, we construct an effective AVQA baseline model on the proposed dataset, of which the baseline model consists of video feature extraction module, audio feature extraction and audio-visual fusion module. The experimental results demonstrate that our model achieves optimal performance on the proposed dataset.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph-based Gossiping for Communication Efficiency in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2506.10607</link>
<guid>https://arxiv.org/abs/2506.10607</guid>
<content:encoded><![CDATA[
arXiv:2506.10607v1 Announce Type: new 
Abstract: Federated learning has emerged as a privacy-preserving technique for collaborative model training across heterogeneously distributed silos. Yet, its reliance on a single central server introduces potential bottlenecks and risks of single-point failure. Decentralizing the server, often referred to as decentralized learning, addresses this problem by distributing the server role across nodes within the network. One drawback regarding this pure decentralization is it introduces communication inefficiencies, which arise from increased message exchanges in large-scale setups. However, existing proposed solutions often fail to simulate the real-world distributed and decentralized environment in their experiments, leading to unreliable performance evaluations and limited applicability in practice. Recognizing the lack from prior works, this work investigates the correlation between model size and network latency, a critical factor in optimizing decentralized learning communication. We propose a graph-based gossiping mechanism, where specifically, minimum spanning tree and graph coloring are used to optimize network structure and scheduling for efficient communication across various network topologies and message capacities. Our approach configures and manages subnetworks on real physical routers and devices and closely models real-world distributed setups. Experimental results demonstrate that our method significantly improves communication, compatible with different topologies and data sizes, reducing bandwidth and transfer time by up to circa 8 and 4.4 times, respectively, compared to naive flooding broadcasting methods.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deployment of Containerized Simulations in an API-Driven Distributed Infrastructure</title>
<link>https://arxiv.org/abs/2506.10642</link>
<guid>https://arxiv.org/abs/2506.10642</guid>
<content:encoded><![CDATA[
arXiv:2506.10642v1 Announce Type: new 
Abstract: The increasingly dynamic market for embedded systems makes virtual prototypes an indispensable tool for hardware/software codesign. The broad acceptance of the methodology has led to a diverse range of solutions: from open-source, pure console-based simulators to highly capable commercial simulation tools. In this work we present SUNRISE, an infrastructure to provide users a unified approach to utilizing virtual prototyping solutions, facilitate access to various simulation technologies and boost cooperation by leveraging decentralized compute resources for deployment of simulation workloads and definition of open APIs.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GOLIATH: A Decentralized Framework for Data Collection in Intelligent Transportation Systems</title>
<link>https://arxiv.org/abs/2506.10665</link>
<guid>https://arxiv.org/abs/2506.10665</guid>
<content:encoded><![CDATA[
arXiv:2506.10665v1 Announce Type: new 
Abstract: Intelligent Transportation Systems (ITSs) technology has advanced during the past years, and it is now used for several applications that require vehicles to exchange real-time data, such as in traffic information management. Traditionally, road traffic information has been collected using on-site sensors. However, crowd-sourcing traffic information from onboard sensors or smartphones has become a viable alternative. State-of-the-art solutions currently follow a centralized model where only the service provider has complete access to the collected traffic data and represent a single point of failure and trust. In this paper, we propose GOLIATH, a blockchain-based decentralized framework that runs on the In-Vehicle Infotainment (IVI) system to collect real-time information exchanged between the network's participants. Our approach mitigates the limitations of existing crowd-sourcing centralized solutions by guaranteeing trusted information collection and exchange, fully exploiting the intrinsic distributed nature of vehicles. We demonstrate its feasibility in the context of vehicle positioning and traffic information management. Each vehicle participating in the decentralized network shares its position and neighbors' ones in the form of a transaction recorded on the ledger, which uses a novel consensus mechanism to validate it. We design the consensus mechanism resilient against a realistic set of adversaries that aim to tamper or disable the communication. We evaluate the proposed framework in a simulated (but realistic) environment, which considers different threats and allows showing its robustness and safety properties.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Higher-Order Uncoupled Learning Dynamics and Nash Equilibrium</title>
<link>https://arxiv.org/abs/2506.10874</link>
<guid>https://arxiv.org/abs/2506.10874</guid>
<content:encoded><![CDATA[
arXiv:2506.10874v1 Announce Type: new 
Abstract: We study learnability of mixed-strategy Nash Equilibrium (NE) in general finite games using higher-order replicator dynamics as well as classes of higher-order uncoupled heterogeneous dynamics. In higher-order uncoupled learning dynamics, players have no access to utilities of opponents (uncoupled) but are allowed to use auxiliary states to further process information (higher-order). We establish a link between uncoupled learning and feedback stabilization with decentralized control. Using this association, we show that for any finite game with an isolated completely mixed-strategy NE, there exist higher-order uncoupled learning dynamics that lead (locally) to that NE. We further establish the lack of universality of learning dynamics by linking learning to the control theoretic concept of simultaneous stabilization. We construct two games such that any higher-order dynamics that learn the completely mixed-strategy NE of one of these games can never learn the completely mixed-strategy NE of the other. Next, motivated by imposing natural restrictions on allowable learning dynamics, we introduce the Asymptotic Best Response (ABR) property. Dynamics with the ABR property asymptotically learn a best response in environments that are asymptotically stationary. We show that the ABR property relates to an internal stability condition on higher-order learning dynamics. We provide conditions under which NE are compatible with the ABR property. Finally, we address learnability of mixed-strategy NE in the bandit setting using a bandit version of higher-order replicator dynamics.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
<link>https://arxiv.org/abs/2506.10964</link>
<guid>https://arxiv.org/abs/2506.10964</guid>
<content:encoded><![CDATA[
arXiv:2506.10964v1 Announce Type: new 
Abstract: Urban digital twins are increasingly perceived as a way to pool the growing digital resources of cities for the purpose of a more sustainable and integrated urban planning. Models and simulations are central to this undertaking: They enable "what if?" scenarios, create insights and describe relationships between the vast data that is being collected. However, the process of integrating and subsequently using models in urban digital twins is an inherently complex undertaking. It raises questions about how to represent urban complexity, how to deal with uncertain assUrban Model Platformtions and modeling paradigms, and how to capture underlying power relations. Existent approaches in the domain largely focus on monolithic and centralized solutions in the tradition of neoliberal city-making, oftentimes prohibiting pluralistic and open interoperable models. Using a participatory design for participatory systems approach together with the City of Hamburg, Germany, we find that an open Urban Model Platform can function both as a public technological backbone for modeling and simulation in urban digital twins and as a socio-technical framework for a collaborative and pluralistic representation of urban processes. Such a platform builds on open standards, allows for a decentralized integration of models, enables communication between models and supports a multi-model approach to representing urban systems.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Unsupervised Visual Representation Learning via Exploiting General Content and Personal Style</title>
<link>https://arxiv.org/abs/2211.06470</link>
<guid>https://arxiv.org/abs/2211.06470</guid>
<content:encoded><![CDATA[
arXiv:2211.06470v2 Announce Type: replace 
Abstract: Discriminative unsupervised learning methods such as contrastive learning have demonstrated the ability to learn generalized visual representations on centralized data. It is nonetheless challenging to adapt such methods to a distributed system with unlabeled, private, and heterogeneous client data due to user styles and preferences. Federated learning enables multiple clients to collectively learn a global model without provoking any privacy breach between local clients. On the other hand, another direction of federated learning studies personalized methods to address the local heterogeneity. However, work on solving both generalization and personalization without labels in a decentralized setting remains unfamiliar. In this work, we propose a novel method, FedStyle, to learn a more generalized global model by infusing local style information with local content information for contrastive learning, and to learn more personalized local models by inducing local style information for downstream tasks. The style information is extracted by contrasting original local data with strongly augmented local data (Sobel filtered images). Through extensive experiments with linear evaluations in both IID and non-IID settings, we demonstrate that FedStyle outperforms both the generalization baseline methods and personalization baseline methods in a stylized decentralized setting. Through comprehensive ablations, we demonstrate our design of style infusion and stylized personalization improve performance significantly.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Stochastic Hybrid Approach to Decentralized Networked Control: Stochastic Network Delays and Poisson Pulsing Attacks</title>
<link>https://arxiv.org/abs/2401.14750</link>
<guid>https://arxiv.org/abs/2401.14750</guid>
<content:encoded><![CDATA[
arXiv:2401.14750v3 Announce Type: replace 
Abstract: By designing the decentralized time-regularized (Zeno-free) event-triggered strategies for the state-feedback control law, this paper considers the stochastic stabilization of a class of networked control systems, where two sources of randomness exist in multiple decentralized networks that operate asynchronously and independently: the communication channels are constrained by the stochastic network delays and also by Poisson pulsing denial-of-service (Pp-DoS) attacks. The time delay in the network denotes the length from a transmission instant to the corresponding update instant, and is supposed to be a continuous random variable subject to certain continuous probability distribution; while the attacks' cardinal number is a discrete random variable supposed to be subject to Poisson distribution, so the inter-attack time, i.e., the time between two consecutive attack instants, is subject to exponential distribution. The considered system is modeled as a stochastic hybrid formalism, where the randomness enters through the jump map into the reset value (the inter-attack time directly related) of each triggered strategy. By only sampling/transmitting state measurements when needed and simultaneously by taking the specific medium access protocols into account, the designed event-triggered strategies are synthesized in a state-based and decentralized form, which are robust (tolerable well) to stochastic network delays, under different tradeoff-conditions between the minimum inter-event times, maximum allowable delays (i.e., potentially tolerable delays) and the frequencies of attacks. Using stochastic hybrid tools to combine attack-active parts with attack-over parts, the designed triggered strategies, if designed well according to the actual system needs, can tolerate (be resilient to) the Pp-DoS attacks and stochastic network delays without jeopardizing the stability and Zeno-freeness.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Aware Spectrum Pricing and Power Control Optimization for LEO Satellite Internet-of-Things</title>
<link>https://arxiv.org/abs/2407.00814</link>
<guid>https://arxiv.org/abs/2407.00814</guid>
<content:encoded><![CDATA[
arXiv:2407.00814v2 Announce Type: replace 
Abstract: Low earth orbit (LEO) satellite systems play an important role in next generation communication networks due to their ability to provide extensive global coverage with guaranteed communications in remote areas and isolated areas where base stations cannot be cost-efficiently deployed. With the pervasive adoption of LEO satellite systems, especially in the LEO Internet-of-Things (IoT) scenarios, their spectrum resource management requirements have become more complex as a result of massive service requests and high bandwidth demand from terrestrial terminals. For instance, when leasing the spectrum to terrestrial users and controlling the uplink transmit power, satellites collect user data for machine learning purposes, which usually are sensitive information such as location, budget and quality of service (QoS) requirement. To facilitate model training in LEO IoT while preserving the privacy of data, blockchain-driven federated learning (FL) is widely used by leveraging on a fully decentralized architecture. In this paper, we propose a hybrid spectrum pricing and power control framework for LEO IoT by combining blockchain technology and FL. We first design a local deep reinforcement learning algorithm for LEO satellite systems to learn a revenue-maximizing pricing and power control scheme. Then the agents collaborate to form a FL system. We also propose a reputation-based blockchain which is used in the global model aggregation phase of FL. Based on the reputation mechanism, a node is selected for each global training round to perform model aggregation and block generation, which can further enhance the decentralization of the network and guarantee the trust. Simulation tests are conducted to evaluate the performances of the proposed scheme. Our results show the efficiency of finding the maximum revenue scheme for LEO satellite systems while preserving the privacy of each agent.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differentially private and decentralized randomized power method</title>
<link>https://arxiv.org/abs/2411.01931</link>
<guid>https://arxiv.org/abs/2411.01931</guid>
<content:encoded><![CDATA[
arXiv:2411.01931v3 Announce Type: replace 
Abstract: The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. However, its application to large datasets containing personal information (e.g., web interactions, search history, personal tastes) raises critical privacy problems. This paper addresses these issues by proposing enhanced privacy-preserving variants of the method. First, we propose a variant that reduces the amount of the noise required in current techniques to achieve Differential Privacy (DP). More precisely, we refine the privacy analysis so that the Gaussian noise variance no longer grows linearly with the target rank, achieving the same DP guarantees with strictly less noise. Second, we adapt our method to a decentralized framework in which data is distributed among multiple users. The decentralized protocol strengthens privacy guarantees with no accuracy penalty and a low computational and communication overhead. Our results include the provision of tighter convergence bounds for both the centralized and decentralized versions, and an empirical comparison with previous work using real recommendation datasets.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating Asynchronous AdaBoost into Federated Learning: Five Real World Applications</title>
<link>https://arxiv.org/abs/2506.09090</link>
<guid>https://arxiv.org/abs/2506.09090</guid>
<content:encoded><![CDATA[
arXiv:2506.09090v1 Announce Type: new 
Abstract: This paper presents a comprehensive analysis of an enhanced asynchronous AdaBoost framework for federated learning (FL), focusing on its application across five distinct domains: computer vision on edge devices, blockchain-based model transparency, on-device mobile personalization, IoT anomaly detection, and federated healthcare diagnostics. The proposed algorithm incorporates adaptive communication scheduling and delayed weight compensation to reduce synchronization frequency and communication overhead while preserving or improving model accuracy. We examine how these innovations improve communication efficiency, scalability, convergence, and robustness in each domain. Comparative metrics including training time, communication overhead, convergence iterations, and classification accuracy are evaluated using data and estimates derived from Oghlukyan's enhanced AdaBoost framework. Empirical results show, for example, training time reductions on the order of 20-35% and communication overhead reductions of 30-40% compared to baseline AdaBoost, with convergence achieved in significantly fewer boosting rounds. Tables and charts summarize these improvements by domain. Mathematical formulations of the adaptive scheduling rule and error-driven synchronization thresholds are provided. Overall, the enhanced AdaBoost exhibits markedly improved efficiency and robustness across diverse FL scenarios, suggesting broad applicability of the approach.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent System of Emergent Knowledge: A Coordination Fabric for Billions of Minds</title>
<link>https://arxiv.org/abs/2506.09335</link>
<guid>https://arxiv.org/abs/2506.09335</guid>
<content:encoded><![CDATA[
arXiv:2506.09335v1 Announce Type: new 
Abstract: The Intelligent System of Emergent Knowledge (ISEK) establishes a decentralized network where human and artificial intelligence agents collaborate as peers, forming a self-organizing cognitive ecosystem. Built on Web3 infrastructure, ISEK combines three fundamental principles: (1) a decentralized multi-agent architecture resistant to censorship, (2) symbiotic AI-human collaboration with equal participation rights, and (3) resilient self-adaptation through distributed consensus mechanisms.
  The system implements an innovative coordination protocol featuring a six-phase workflow (Publish, Discover, Recruit, Execute, Settle, Feedback) for dynamic task allocation, supported by robust fault tolerance and a multidimensional reputation system. Economic incentives are governed by the native $ISEK token, facilitating micropayments, governance participation, and reputation tracking, while agent sovereignty is maintained through NFT-based identity management.
  This synthesis of blockchain technology, artificial intelligence, and incentive engineering creates an infrastructure that actively facilitates emergent intelligence. ISEK represents a paradigm shift from conventional platforms, enabling the organic development of large-scale, decentralized cognitive systems where autonomous agents collectively evolve beyond centralized constraints.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Epass: Efficient and Privacy-Preserving Asynchronous Payment on Blockchain</title>
<link>https://arxiv.org/abs/2506.09387</link>
<guid>https://arxiv.org/abs/2506.09387</guid>
<content:encoded><![CDATA[
arXiv:2506.09387v1 Announce Type: new 
Abstract: Buy Now Pay Later (BNPL) is a rapidly proliferating e-commerce model, offering consumers to get the product immediately and defer payments. Meanwhile, emerging blockchain technologies endow BNPL platforms with digital currency transactions, allowing BNPL platforms to integrate with digital wallets. However, the transparency of transactions causes critical privacy concerns because malicious participants may derive consumers' financial statuses from on-chain asynchronous payments. Furthermore, the newly created transactions for deferred payments introduce additional time overheads, which weaken the scalability of BNPL services. To address these issues, we propose an efficient and privacy-preserving blockchain-based asynchronous payment scheme (Epass), which has promising scalability while protecting the privacy of on-chain consumer transactions. Specifically, Epass leverages locally verifiable signatures to guarantee the privacy of consumer transactions against malicious acts. Then, a privacy-preserving asynchronous payment scheme can be further constructed by leveraging time-release encryption to control trapdoors of redactable blockchain, reducing time overheads by modifying transactions for deferred payment. We give formal definitions and security models, generic structures, and formal proofs for Epass. Extensive comparisons and experimental analysis show that \textsf{Epass} achieves KB-level communication costs, and reduces time overhead by more than four times in comparisons with locally verifiable signatures and Go-Ethereum private test networks.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalization Error Analysis for Attack-Free and Byzantine-Resilient Decentralized Learning with Data Heterogeneity</title>
<link>https://arxiv.org/abs/2506.09438</link>
<guid>https://arxiv.org/abs/2506.09438</guid>
<content:encoded><![CDATA[
arXiv:2506.09438v1 Announce Type: new 
Abstract: Decentralized learning, which facilitates joint model training across geographically scattered agents, has gained significant attention in the field of signal and information processing in recent years. While the optimization errors of decentralized learning algorithms have been extensively studied, their generalization errors remain relatively under-explored. As the generalization errors reflect the scalability of trained models on unseen data and are crucial in determining the performance of trained models in real-world applications, understanding the generalization errors of decentralized learning is of paramount importance. In this paper, we present fine-grained generalization error analysis for both attack-free and Byzantine-resilient decentralized learning with heterogeneous data as well as under mild assumptions, in contrast to prior studies that consider homogeneous data and/or rely on a stringent bounded stochastic gradient assumption. Our results shed light on the impact of data heterogeneity, model initialization and stochastic gradient noise -- factors that have not been closely investigated before -- on the generalization error of decentralized learning. We also reveal that Byzantine attacks performed by malicious agents largely affect the generalization error, and their negative impact is inherently linked to the data heterogeneity while remaining independent on the sample size. Numerical experiments on both convex and non-convex tasks are conducted to validate our theoretical findings.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Performance of Cloud-based ARM SVE for Zero-Knowledge Proving Systems</title>
<link>https://arxiv.org/abs/2506.09505</link>
<guid>https://arxiv.org/abs/2506.09505</guid>
<content:encoded><![CDATA[
arXiv:2506.09505v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKP) are becoming a gold standard in scaling blockchains and bringing Web3 to life. At the same time, ZKP for transactions running on the Ethereum Virtual Machine require powerful servers with hundreds of CPU cores. The current zkProver implementation from Polygon is optimized for x86-64 CPUs by vectorizing key operations, such as Merkle tree building with Poseidon hashes over the Goldilocks field, with Advanced Vector Extensions (AVX and AVX512). With these optimizations, a ZKP for a batch of transactions is generated in less than two minutes. With the advent of cloud servers with ARM which are at least 10% cheaper than x86-64 servers and the implementation of ARM Scalable Vector Extension (SVE), we wonder if ARM servers can take over their x86-64 counterparts. Unfortunately, our analysis shows that current ARM CPUs are not a match for their x86-64 competitors. Graviton4 from Amazon Web Services (AWS) and Axion from Google Cloud Platform (GCP) are 1.6X and 1.4X slower compared to the latest AMD EPYC and Intel Xeon servers from AWS with AVX and AVX512, respectively, when building a Merkle tree with over four million leaves. This low performance is due to (1) smaller vector size in these ARM CPUs (128 bits versus 512 bits in AVX512) and (2) lower clock frequency. On the other hand, ARM SVE/SVE2 Instruction Set Architecture (ISA) is at least as powerful as AVX/AVX512 but more flexible. Moreover, we estimate that increasing the vector size to 512 bits will enable higher performance in ARM CPUs compared to their x86-64 counterparts while maintaining their price advantage.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Identity and Access Management for the Computing Continuum</title>
<link>https://arxiv.org/abs/2506.09559</link>
<guid>https://arxiv.org/abs/2506.09559</guid>
<content:encoded><![CDATA[
arXiv:2506.09559v1 Announce Type: new 
Abstract: The computing continuum introduces new challenges for access control due to its dynamic, distributed, and heterogeneous nature. In this paper, we propose a Zero-Trust (ZT) access control solution that leverages decentralized identification and authentication mechanisms based on Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). Additionally, we employ Relationship-Based Access Control (ReBAC) to define policies that capture the evolving trust relationships inherent in the continuum. Through a proof-of-concept implementation, we demonstrate the feasibility and efficiency of our solution, highlighting its potential to enhance security and trust in decentralized environments.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ASTAGEN: Empirical Evaluation of Automated SATD Taxonomy Generation with LLMs</title>
<link>https://arxiv.org/abs/2506.09601</link>
<guid>https://arxiv.org/abs/2506.09601</guid>
<content:encoded><![CDATA[
arXiv:2506.09601v1 Announce Type: new 
Abstract: Technical debt refers to suboptimal code that degrades software quality. When developers intentionally introduce such debt, it is called self-admitted technical debt (SATD). Since SATD hinders maintenance, identifying its categories is key to uncovering quality issues. Traditionally, constructing such taxonomies requires manually inspecting SATD comments and surrounding code, which is time-consuming, labor-intensive, and often inconsistent due to annotator subjectivity. This study presents ASTAGEN, an initial step toward automating SATD taxonomy generation using large language models (LLMs). Given a comment and its surrounding code, ASTAGEN first generates a concise explanation for each SATD comment, then incrementally generates and updates categories to construct a taxonomy. We evaluate ASTAGEN on SATD datasets from three domains: quantum software, smart contracts, and machine learning. It successfully recovers domain-specific categories reported in prior work, such as Layer Configuration in machine learning. Compared to a naive use of an LLM, ASTAGEN produces more consistent category assignments due to its explanation-driven, iterative design. It also completes taxonomy generation in under two hours and for less than one USD, even on the largest dataset. These results suggest that while full automation remains challenging, ASTAGEN is able to support semi-automated taxonomy construction. Furthermore, our work opens up avenues for future work, such as automatic taxonomy generation in other areas.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wavelet Scattering Transform and Fourier Representation for Offline Detection of Malicious Clients in Federated Learning</title>
<link>https://arxiv.org/abs/2506.09674</link>
<guid>https://arxiv.org/abs/2506.09674</guid>
<content:encoded><![CDATA[
arXiv:2506.09674v1 Announce Type: new 
Abstract: Federated Learning (FL) enables the training of machine learning models across decentralized clients while preserving data privacy. However, the presence of anomalous or corrupted clients - such as those with faulty sensors or non representative data distributions - can significantly degrade model performance. Detecting such clients without accessing raw data remains a key challenge. We propose WAFFLE (Wavelet and Fourier representations for Federated Learning) a detection algorithm that labels malicious clients {\it before training}, using locally computed compressed representations derived from either the Wavelet Scattering Transform (WST) or the Fourier Transform. Both approaches provide low-dimensional, task-agnostic embeddings suitable for unsupervised client separation. A lightweight detector, trained on a distillated public dataset, performs the labeling with minimal communication and computational overhead. While both transforms enable effective detection, WST offers theoretical advantages, such as non-invertibility and stability to local deformations, that make it particularly well-suited to federated scenarios. Experiments on benchmark datasets show that our method improves detection accuracy and downstream classification performance compared to existing FL anomaly detection algorithms, validating its effectiveness as a pre-training alternative to online detection strategies.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Load-Aware Training Scheduling for Model Circulation-based Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2506.09769</link>
<guid>https://arxiv.org/abs/2506.09769</guid>
<content:encoded><![CDATA[
arXiv:2506.09769v1 Announce Type: new 
Abstract: This paper proposes Load-aware Tram-FL, an extension of Tram-FL that introduces a training scheduling mechanism to minimize total training time in decentralized federated learning by accounting for both computational and communication loads. The scheduling problem is formulated as a global optimization task, which-though intractable in its original form-is made solvable by decomposing it into node-wise subproblems. To promote balanced data utilization under non-IID distributions, a variance constraint is introduced, while the overall training latency, including both computation and communication costs, is minimized through the objective function. Simulation results on MNIST and CIFAR-10 demonstrate that Load-aware Tram-FL significantly reduces training time and accelerates convergence compared to baseline methods.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Frosty for partial synchrony</title>
<link>https://arxiv.org/abs/2506.09823</link>
<guid>https://arxiv.org/abs/2506.09823</guid>
<content:encoded><![CDATA[
arXiv:2506.09823v1 Announce Type: new 
Abstract: Snowman is the consensus protocol used by blockchains on Avalanche. Recent work has shown both how to augment Snowman with a `liveness' module called `Frosty' that protects against liveness attacks, and also how to modify Snowman so as to be consistent in partial synchrony. Since Frosty assumes (a strong form of) synchrony, the aim of this note is to show how to modify Frosty to deal with the partially synchronous version of Snowman.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Resilient Decentralized Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2310.07320</link>
<guid>https://arxiv.org/abs/2310.07320</guid>
<content:encoded><![CDATA[
arXiv:2310.07320v2 Announce Type: replace 
Abstract: In decentralized cooperative multi-armed bandits (MAB), each agent observes a distinct stream of rewards, and seeks to exchange information with others to select a sequence of arms so as to minimize its regret. Agents in the cooperative setting can outperform a single agent running a MAB method such as Upper-Confidence Bound (UCB) independently. In this work, we study how to recover such salient behavior when an unknown fraction of the agents can be Byzantine, that is, communicate arbitrarily wrong information in the form of reward mean-estimates or confidence sets. This framework can be used to model attackers in computer networks, instigators of offensive content into recommender systems, or manipulators of financial markets. Our key contribution is the development of a fully decentralized resilient upper confidence bound (UCB) algorithm that fuses an information mixing step among agents with a truncation of inconsistent and extreme values. This truncation step enables us to establish that the performance of each normal agent is no worse than the classic single-agent UCB1 algorithm in terms of regret, and more importantly, the cumulative regret of all normal agents is strictly better than the non-cooperative case, provided that each agent has at least 3f+1 neighbors where f is the maximum possible Byzantine agents in each agent's neighborhood. Extensions to time-varying neighbor graphs, and minimax lower bounds are further established on the achievable regret. Experiments corroborate the merits of this framework in practice.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reciprocity as the Foundational Substrate of Society: How Reciprocal Dynamics Scale into Social Systems</title>
<link>https://arxiv.org/abs/2505.08319</link>
<guid>https://arxiv.org/abs/2505.08319</guid>
<content:encoded><![CDATA[
arXiv:2505.08319v2 Announce Type: replace 
Abstract: Prevailing accounts in both multi-agent AI and the social sciences explain social structure through top-down abstractions-such as institutions, norms, or trust-yet lack simulateable models of how such structures emerge from individual behavior. Ethnographic and archaeological evidence suggests that reciprocity served as the foundational mechanism of early human societies, enabling economic circulation, social cohesion, and interpersonal obligation long before the rise of formal institutions. Modern financial systems such as credit and currency can likewise be viewed as scalable extensions of reciprocity, formalizing exchange across time and anonymity. Building on this insight, we argue that reciprocity is not merely a local or primitive exchange heuristic, but the scalable substrate from which large-scale social structures can emerge. We propose a three-stage framework to model this emergence: reciprocal dynamics at the individual level, norm stabilization through shared expectations, and the construction of durable institutional patterns. This approach offers a cognitively minimal, behaviorally grounded foundation for simulating how large-scale social systems can emerge from decentralized reciprocal interaction.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids</title>
<link>https://arxiv.org/abs/2506.08272</link>
<guid>https://arxiv.org/abs/2506.08272</guid>
<content:encoded><![CDATA[
arXiv:2506.08272v1 Announce Type: new 
Abstract: Universal Differential Equations (UDEs), which blend neural networks with physical differential equations, have emerged as a powerful framework for scientific machine learning (SciML), enabling data-efficient, interpretable, and physically consistent modeling. In the context of smart grid systems, modeling node-wise battery dynamics remains a challenge due to the stochasticity of solar input and variability in household load profiles. Traditional approaches often struggle with generalization and fail to capture unmodeled residual dynamics. This work proposes a UDE-based approach to learn node-specific battery evolution by embedding a neural residual into a physically inspired battery ODE. Synthetic yet realistic solar generation and load demand data are used to simulate battery dynamics over time. The neural component learns to model unobserved or stochastic corrections arising from heterogeneity in node demand and environmental conditions. Comprehensive experiments reveal that the trained UDE aligns closely with ground truth battery trajectories, exhibits smooth convergence behavior, and maintains stability in long-term forecasts. These findings affirm the viability of UDE-based SciML approaches for battery modeling in decentralized energy networks and suggest broader implications for real-time control and optimization in renewable-integrated smart grids.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation</title>
<link>https://arxiv.org/abs/2506.08296</link>
<guid>https://arxiv.org/abs/2506.08296</guid>
<content:encoded><![CDATA[
arXiv:2506.08296v1 Announce Type: new 
Abstract: Recent advances in multimodal vision-language-action (VLA) models have revolutionized traditional robot learning, enabling systems to interpret vision, language, and action in unified frameworks for complex task planning. However, mastering complex manipulation tasks remains an open challenge, constrained by limitations in persistent contextual memory, multi-agent coordination under uncertainty, and dynamic long-horizon planning across variable sequences. To address this challenge, we propose \textbf{HiBerNAC}, a \textbf{Hi}erarchical \textbf{B}rain-\textbf{e}mulated \textbf{r}obotic \textbf{N}eural \textbf{A}gent \textbf{C}ollective, inspired by breakthroughs in neuroscience, particularly in neural circuit mechanisms and hierarchical decision-making. Our framework combines: (1) multimodal VLA planning and reasoning with (2) neuro-inspired reflection and multi-agent mechanisms, specifically designed for complex robotic manipulation tasks. By leveraging neuro-inspired functional modules with decentralized multi-agent collaboration, our approach enables robust and enhanced real-time execution of complex manipulation tasks. In addition, the agentic system exhibits scalable collective intelligence via dynamic agent specialization, adapting its coordination strategy to variable task horizons and complexity. Through extensive experiments on complex manipulation tasks compared with state-of-the-art VLA models, we demonstrate that \textbf{HiBerNAC} reduces average long-horizon task completion time by 23\%, and achieves non-zero success rates (12\textendash 31\%) on multi-path tasks where prior state-of-the-art VLA models consistently fail. These results provide indicative evidence for bridging biological cognition and robotic learning mechanisms.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting State Manipulation Vulnerabilities in Smart Contracts Using LLM and Static Analysis</title>
<link>https://arxiv.org/abs/2506.08561</link>
<guid>https://arxiv.org/abs/2506.08561</guid>
<content:encoded><![CDATA[
arXiv:2506.08561v1 Announce Type: new 
Abstract: An increasing number of DeFi protocols are gaining popularity, facilitating transactions among multiple anonymous users. State Manipulation is one of the notorious attacks in DeFi smart contracts, with price variable being the most commonly exploited state variable-attackers manipulate token prices to gain illicit profits. In this paper, we propose PriceSleuth, a novel method that leverages the Large Language Model (LLM) and static analysis to detect Price Manipulation (PM) attacks proactively. PriceSleuth firstly identifies core logic function related to price calculation in DeFi contracts. Then it guides LLM to locate the price calculation code statements. Secondly, PriceSleuth performs backward dependency analysis of price variables, instructing LLM in detecting potential price manipulation. Finally, PriceSleuth utilizes propagation analysis of price variables to assist LLM in detecting whether these variables are maliciously exploited. We presented preliminary experimental results to substantiate the effectiveness of PriceSleuth . And we outline future research directions for PriceSleuth.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain and Edge Computing Nexus: A Large-scale Systematic Literature Review</title>
<link>https://arxiv.org/abs/2506.08636</link>
<guid>https://arxiv.org/abs/2506.08636</guid>
<content:encoded><![CDATA[
arXiv:2506.08636v1 Announce Type: new 
Abstract: Blockchain and edge computing are two instrumental paradigms of decentralized computation, driving key advancements in Smart Cities applications such as supply chain, energy and mobility. Despite their unprecedented impact on society, they remain significantly fragmented as technologies and research areas, while they share fundamental principles of distributed systems and domains of applicability. This paper introduces a novel and large-scale systematic literature review on the nexus of blockchain and edge computing with the aim to unravel a new understanding of how the interfacing of the two computing paradigms can boost innovation to provide solutions to timely but also long-standing research challenges. By collecting almost 6000 papers from 3 databases and putting under scrutiny almost 1000 papers, we build a novel taxonomy and classification consisting of 22 features with 287 attributes that we study using quantitative and machine learning methods. They cover a broad spectrum of technological, design, epistemological and sustainability aspects. Results reveal 4 distinguishing patterns of interplay between blockchain and edge computing with key determinants the public (permissionless) vs. private (permissioned) design, technology and proof of concepts. They also demonstrate the prevalence of blockchain-assisted edge computing for improving privacy and security, in particular for mobile computing applications.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging</title>
<link>https://arxiv.org/abs/2506.09024</link>
<guid>https://arxiv.org/abs/2506.09024</guid>
<content:encoded><![CDATA[
arXiv:2506.09024v1 Announce Type: new 
Abstract: Safe deployment of machine learning (ML) models in safety-critical domains such as medical imaging requires detecting inputs with characteristics not seen during training, known as out-of-distribution (OOD) detection, to prevent unreliable predictions. Effective OOD detection after deployment could benefit from access to the training data, enabling direct comparison between test samples and the training data distribution to identify differences. State-of-the-art OOD detection methods, however, either discard training data after deployment or assume that test samples and training data are centrally stored together, an assumption that rarely holds in real-world settings. This is because shipping training data with the deployed model is usually impossible due to the size of training databases, as well as proprietary or privacy constraints. We introduce the Isolation Network, an OOD detection framework that quantifies the difficulty of separating a target test sample from the training data by solving a binary classification task. We then propose Decentralized Isolation Networks (DIsoN), which enables the comparison of training and test data when data-sharing is impossible, by exchanging only model parameters between the remote computational nodes of training and deployment. We further extend DIsoN with class-conditioning, comparing a target sample solely with training data of its predicted class. We evaluate DIsoN on four medical imaging datasets (dermatology, chest X-ray, breast ultrasound, histopathology) across 12 OOD detection tasks. DIsoN performs favorably against existing methods while respecting data-privacy. This decentralized OOD detection framework opens the way for a new type of service that ML developers could provide along with their models: providing remote, secure utilization of their training data for OOD detection services. Code will be available upon acceptance at: *****
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uncertainty-Aware Active Search with a Team of Aerial Robots</title>
<link>https://arxiv.org/abs/2410.08507</link>
<guid>https://arxiv.org/abs/2410.08507</guid>
<content:encoded><![CDATA[
arXiv:2410.08507v2 Announce Type: replace 
Abstract: Rapid search and rescue is critical to maximizing survival rates following natural disasters. However, these efforts are challenged by the need to search large disaster zones, lack of reliability in the communications infrastructure, and a priori unknown numbers of objects of interest (OOIs), such as injured survivors. Aerial robots are increasingly being deployed for search and rescue due to their high mobility, but there remains a gap in deploying multi-robot autonomous aerial systems for methodical search of large environments. Prior works have relied on preprogrammed paths from human operators or are evaluated only in simulation. We bridge these gaps in the state of the art by developing and demonstrating a decentralized active search system, which biases its trajectories to take additional views of uncertain OOIs. The methodology leverages stochasticity for rapid coverage in communication denied scenarios. When communications are available, robots share poses, goals, and OOI information to accelerate the rate of search. Detections from multiple images and vehicles are fused to provide a mean and covariance for each OOI location. Extensive simulations and hardware experiments in Bloomingdale, OH, are conducted to validate the approach. The results demonstrate the active search approach outperforms greedy coverage-based planning in communication-denied scenarios while maintaining comparable performance in communication-enabled scenarios. The results also demonstrate the ability to detect and localize all a priori unknown OOIs with a mean error of approximately 3m at flight altitudes between 50m-60m.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies</title>
<link>https://arxiv.org/abs/2506.06325</link>
<guid>https://arxiv.org/abs/2506.06325</guid>
<content:encoded><![CDATA[
arXiv:2506.06325v1 Announce Type: new 
Abstract: This paper proposes a decentralized model of energy cooperation between microgrids, in which decisions are made locally, at the level of the microgrid community. Each microgrid is modeled as an autonomous agent that adopts a Hawk or Dove strategy, depending on the level of energy stored in the battery and its role in the energy trading process. The interactions between selling and buying microgrids are modeled through an evolutionary algorithm. An individual in the algorithm population is represented as an energy trading matrix that encodes the amounts of energy traded between the selling and buying microgrids. The population evolution is achieved by recombination and mutation operators. Recombination uses a specialized operator for matrix structures, and mutation is applied to the matrix elements according to a Gaussian distribution. The evaluation of an individual is made with a multi-criteria fitness function that considers the seller profit, the degree of energy stability at the community level, penalties for energy imbalance at the community level and for the degradation of microgrids batteries. The method was tested on a simulated scenario with 100 microgrids, each with its own selling and buying thresholds, to reflect a realistic environment with variable storage characteristics of microgrids batteries. By applying the algorithm on this scenario, 95 out of the 100 microgrids reached a stable energy state. This result confirms the effectiveness of the proposed model in achieving energy balance both at the individual level, for each microgrid, and at the level of the entire community.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</title>
<link>https://arxiv.org/abs/2506.06694</link>
<guid>https://arxiv.org/abs/2506.06694</guid>
<content:encoded><![CDATA[
arXiv:2506.06694v1 Announce Type: new 
Abstract: Foundation models have revolutionized fields such as natural language processing and computer vision by enabling general-purpose learning across diverse tasks and datasets. However, building analogous models for human mobility remains challenging due to the privacy-sensitive nature of mobility data and the resulting data silos across institutions. To bridge this gap, we propose MoveGCL, a scalable and privacy-preserving framework for training mobility foundation models via generative continual learning. Without sharing raw data, MoveGCL enables decentralized and progressive model evolution by replaying synthetic trajectories generated from a frozen teacher model, and reinforces knowledge retention through a tailored distillation strategy that mitigates catastrophic forgetting. To address the heterogeneity of mobility patterns, MoveGCL incorporates a Mixture-of-Experts Transformer with a mobility-aware expert routing mechanism, and employs a layer-wise progressive adaptation strategy to stabilize continual updates. Experiments on six real-world urban datasets demonstrate that MoveGCL achieves performance comparable to joint training and significantly outperforms federated learning baselines, while offering strong privacy protection. MoveGCL marks a crucial step toward unlocking foundation models for mobility, offering a practical blueprint for open, scalable, and privacy-preserving model development in the era of foundation models.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
</channel>
</rss>