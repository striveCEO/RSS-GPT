<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>


<item>
<title>Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability</title>
<link>https://arxiv.org/abs/2506.19870</link>
<guid>https://arxiv.org/abs/2506.19870</guid>
<content:encoded><![CDATA[
arXiv:2506.19870v1 Announce Type: new 
Abstract: Peer-to-peer trading and the move to decentralized grids have reshaped the energy markets in the United States. Notwithstanding, such developments lead to new challenges, mainly regarding the safety and authenticity of energy trade. This study aimed to develop and build a secure, intelligent, and efficient energy transaction system for the decentralized US energy market. This research interlinks the technological prowess of blockchain and artificial intelligence (AI) in a novel way to solve long-standing challenges in the distributed energy market, specifically those of security, fraudulent behavior detection, and market reliability. The dataset for this research is comprised of more than 1.2 million anonymized energy transaction records from a simulated peer-to-peer (P2P) energy exchange network emulating real-life blockchain-based American microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record contains detailed fields of transaction identifier, timestamp, energy volume (kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier (hashed for privacy), smart meter readings, geolocation regions, and settlement confirmation status. The dataset also includes system-calculated behavior metrics of transaction rate, variability of energy production, and historical pricing patterns. The system architecture proposed involves the integration of two layers, namely a blockchain layer and artificial intelligence (AI) layer, each playing a unique but complementary function in energy transaction securing and market intelligence improvement. The machine learning models used in this research were specifically chosen for their established high performance in classification tasks, specifically in the identification of energy transaction fraud in decentralized markets.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RepuNet: A Reputation System for Mitigating Malicious Clients in DFL</title>
<link>https://arxiv.org/abs/2506.19892</link>
<guid>https://arxiv.org/abs/2506.19892</guid>
<content:encoded><![CDATA[
arXiv:2506.19892v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) enables nodes to collaboratively train models without a central server, introducing new vulnerabilities since each node independently selects peers for model aggregation. Malicious nodes may exploit this autonomy by sending corrupted models (model poisoning), delaying model submissions (delay attack), or flooding the network with excessive messages, negatively affecting system performance. Existing solutions often depend on rigid configurations or additional infrastructures such as blockchain, leading to computational overhead, scalability issues, or limited adaptability. To overcome these limitations, this paper proposes RepuNet, a decentralized reputation system that categorizes threats in DFL and dynamically evaluates node behavior using metrics like model similarity, parameter changes, message latency, and communication volume. Nodes' influence in model aggregation is adjusted based on their reputation scores. RepuNet was integrated into the Nebula DFL platform and experimentally evaluated with MNIST and CIFAR-10 datasets under non-IID distributions, using federations of up to 25 nodes in both fully connected and random topologies. Different attack intensities, frequencies, and activation intervals were tested. Results demonstrated that RepuNet effectively detects and mitigates malicious behavior, achieving F1 scores above 95% for MNIST scenarios and approximately 76% for CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness, and practical potential for mitigating threats in decentralized federated learning environments.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DiT-SGCR: Directed Temporal Structural Representation with Global-Cluster Awareness for Ethereum Malicious Account Detection</title>
<link>https://arxiv.org/abs/2506.20123</link>
<guid>https://arxiv.org/abs/2506.20123</guid>
<content:encoded><![CDATA[
arXiv:2506.20123v1 Announce Type: new 
Abstract: The detection of malicious accounts on Ethereum - the preeminent DeFi platform - is critical for protecting digital assets and maintaining trust in decentralized finance. Recent advances highlight that temporal transaction evolution reveals more attack signatures than static graphs. However, current methods either fail to model continuous transaction dynamics or incur high computational costs that limit scalability to large-scale transaction networks. Furthermore, current methods fail to consider two higher-order behavioral fingerprints: (1) direction in temporal transaction flows, which encodes money movement trajectories, and (2) account clustering, which reveals coordinated behavior of organized malicious collectives. To address these challenges, we propose DiT-SGCR, an unsupervised graph encoder for malicious account detection. Specifically, DiT-SGCR employs directional temporal aggregation to capture dynamic account interactions, then coupled with differentiable clustering and graph Laplacian regularization to generate high-quality, low-dimensional embeddings. Our approach simultaneously encodes directional temporal dynamics, global topology, and cluster-specific behavioral patterns, thereby enhancing the discriminability and robustness of account representations. Furthermore, DiT-SGCR bypasses conventional graph propagation mechanisms, yielding significant scalability advantages. Extensive experiments on three datasets demonstrate that DiT-SGCR consistently outperforms state-of-the-art methods across all benchmarks, achieving F1-score improvements ranging from 3.62% to 10.83%.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data</title>
<link>https://arxiv.org/abs/2506.20245</link>
<guid>https://arxiv.org/abs/2506.20245</guid>
<content:encoded><![CDATA[
arXiv:2506.20245v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized collaborative machine learning (ML) technique. It provides a solution to the issues of isolated data islands and data privacy leakage in industrial ML practices. One major challenge in FL is handling the non-identical and independent distributed (non-IID) data. Current solutions either focus on constructing an all-powerful global model, or customizing personalized local models. Few of them can provide both a well-generalized global model and well-performed local models at the same time. Additionally, many FL solutions to the non-IID problem are benefited from introducing public datasets. However, this will also increase the risk of data leakage. To tackle the problems, we propose a novel data-free distillation framework, Federated Bidirectional Knowledge Distillation (FedBKD). Specifically, we train Generative Adversarial Networks (GAN) for synthetic data. During the GAN training, local models serve as discriminators and their parameters are frozen. The synthetic data is then used for bidirectional distillation between global and local models to achieve knowledge interactions so that performances for both sides are improved. We conduct extensive experiments on 4 benchmarks under different non-IID settings. The results show that FedBKD achieves SOTA performances in every case.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning</title>
<link>https://arxiv.org/abs/2506.20413</link>
<guid>https://arxiv.org/abs/2506.20413</guid>
<content:encoded><![CDATA[
arXiv:2506.20413v1 Announce Type: new 
Abstract: The growing adoption of Artificial Intelligence (AI) in Internet of Things (IoT) ecosystems has intensified the need for personalized learning methods that can operate efficiently and privately across heterogeneous, resource-constrained devices. However, enabling effective personalized learning in decentralized settings introduces several challenges, including efficient knowledge transfer between clients, protection of data privacy, and resilience against poisoning attacks. In this paper, we address these challenges by developing P4 (Personalized, Private, Peer-to-Peer) -- a method designed to deliver personalized models for resource-constrained IoT devices while ensuring differential privacy and robustness against poisoning attacks. Our solution employs a lightweight, fully decentralized algorithm to privately detect client similarity and form collaborative groups. Within each group, clients leverage differentially private knowledge distillation to co-train their models, maintaining high accuracy while ensuring robustness to the presence of malicious clients. We evaluate P4 on popular benchmark datasets using both linear and CNN-based architectures across various heterogeneity settings and attack scenarios. Experimental results show that P4 achieves 5% to 30% higher accuracy than leading differentially private peer-to-peer approaches and maintains robustness with up to 30% malicious clients. Additionally, we demonstrate its practicality by deploying it on resource-constrained devices, where collaborative training between two clients adds only ~7 seconds of overhead.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Batch Size Optimization for Federated Learning</title>
<link>https://arxiv.org/abs/2506.20511</link>
<guid>https://arxiv.org/abs/2506.20511</guid>
<content:encoded><![CDATA[
arXiv:2506.20511v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized collaborative Machine Learning framework for training models without collecting data in a centralized location. It has seen application across various disciplines, from helping medical diagnoses in hospitals to detecting fraud in financial transactions. In this paper, we focus on improving the local training process through hardware usage optimization. While participants in a federation might share the hardware they are training on, since there is no information exchange between them, their training process can be hindered by an improper training configuration. Taking advantage of the parallel processing inherent to Federated Learning, we use a greedy randomized search to optimize local batch sizes for the best training settings across all participants. Our results show that against default parameter settings, our method improves convergence speed while staying nearly on par with the case where local parameters are optimized.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning</title>
<link>https://arxiv.org/abs/2506.20518</link>
<guid>https://arxiv.org/abs/2506.20518</guid>
<content:encoded><![CDATA[
arXiv:2506.20518v1 Announce Type: new 
Abstract: Federated Learning (FL) is a collaborative machine learning paradigm which allows participants to collectively train a model while training data remains private. This paradigm is especially beneficial for sectors like finance, where data privacy, security and model performance are paramount. FL has been extensively studied in the years following its introduction, leading to, among others, better performing collaboration techniques, ways to defend against other clients trying to attack the model, and contribution assessment methods. An important element in for-profit Federated Learning is the development of incentive methods to determine the allocation and distribution of rewards for participants. While numerous methods for allocation have been proposed and thoroughly explored, distribution frameworks remain relatively understudied. In this paper, we propose a novel framework which introduces client-specific tokens as investment vehicles within the FL ecosystem. Our framework aims to address the limitations of existing incentive schemes by leveraging a decentralized finance (DeFi) platform and automated market makers (AMMs) to create a more flexible and scalable reward distribution system for participants, and a mechanism for third parties to invest in the federation learning process.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Encoding Process in Decentralized Systems</title>
<link>https://arxiv.org/abs/2408.15203</link>
<guid>https://arxiv.org/abs/2408.15203</guid>
<content:encoded><![CDATA[
arXiv:2408.15203v2 Announce Type: replace 
Abstract: We consider the problem of encoding information in a system of N=K+R processors that operate in a decentralized manner, i.e., without a central processor which orchestrates the operation. The system involves K source processors, each holding some data modeled as a vector over a finite field. The remaining R processors are sinks, and each of which requires a linear combination of all data vectors. These linear combinations are distinct from one sink processor to another, and are specified by a generator matrix of a systematic linear error correcting code. To capture the communication cost of decentralized encoding, we adopt a linear network model in which the process proceeds in consecutive communication rounds. In every round, every processor sends and receives one message through each one of its p ports. Moreover, inspired by linear network coding literature, we allow processors to transfer linear combinations of their own data and previously received data. We propose a framework that addresses the decentralized encoding problem on two levels. On the universal level, we provide a solution to the decentralized encoding problem for any possible linear code. On the specific level, we further optimize our solution towards systematic Reed-Solomon codes, as well as their variant, Lagrange codes, for their prevalent use in coded storage and computation systems. Our solutions are based on a newly-defined collective communication operation we call all-to-all encode.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed satellite information networks: Architecture, enabling technologies, and trends</title>
<link>https://arxiv.org/abs/2412.12587</link>
<guid>https://arxiv.org/abs/2412.12587</guid>
<content:encoded><![CDATA[
arXiv:2412.12587v2 Announce Type: replace 
Abstract: Driven by the vision of ubiquitous connectivity and wireless intelligence, the evolution of ultra-dense constellation-based satellite-integrated Internet is underway, now taking preliminary shape. Nevertheless, the entrenched institutional silos and limited, nonrenewable heterogeneous network resources leave current satellite systems struggling to accommodate the escalating demands of next-generation intelligent applications. In this context, the distributed satellite information networks (DSIN), exemplified by the cohesive clustered satellites system, have emerged as an innovative architecture, bridging information gaps across diverse satellite systems, such as communication, navigation, and remote sensing, and establishing a unified, open information network paradigm to support resilient space information services. This survey first provides a profound discussion about innovative network architectures of DSIN, encompassing distributed regenerative satellite network architecture, distributed satellite computing network architecture, and reconfigurable satellite formation flying, to enable flexible and scalable communication, computing and control. The DSIN faces challenges from network heterogeneity, unpredictable channel dynamics, sparse resources, and decentralized collaboration frameworks. To address these issues, a series of enabling technologies is identified, including channel modeling and estimation, cloud-native distributed MIMO cooperation, grant-free massive access, network routing, and the proper combination of all these diversity techniques. Furthermore, to heighten the overall resource efficiency, the cross-layer optimization techniques are further developed to meet upper-layer deterministic, adaptive and secure information services requirements. In addition, emerging research directions and new opportunities are highlighted on the way to achieving the DSIN vision.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AIDRIN 2.0: A Framework to Assess Data Readiness for AI</title>
<link>https://arxiv.org/abs/2505.18213</link>
<guid>https://arxiv.org/abs/2505.18213</guid>
<content:encoded><![CDATA[
arXiv:2505.18213v2 Announce Type: replace 
Abstract: AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve data preparedness for AI applications. It addresses critical data readiness dimensions such as data quality, bias, fairness, and privacy. This paper details enhancements to AIDRIN by focusing on user interface improvements and integration with a privacy-preserving federated learning (PPFL) framework. By refining the UI and enabling smooth integration with decentralized AI pipelines, AIDRIN becomes more accessible and practical for users with varying technical expertise. Integrating with an existing PPFL framework ensures that data readiness and privacy are prioritized in federated learning environments. A case study involving a real-world dataset demonstrates AIDRIN's practical value in identifying data readiness issues that impact AI model performance.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Survey of HPC in US Research Institutions</title>
<link>https://arxiv.org/abs/2506.19019</link>
<guid>https://arxiv.org/abs/2506.19019</guid>
<content:encoded><![CDATA[
arXiv:2506.19019v1 Announce Type: new 
Abstract: The rapid growth of AI, data-intensive science, and digital twin technologies has driven an unprecedented demand for high-performance computing (HPC) across the research ecosystem. While national laboratories and industrial hyperscalers have invested heavily in exascale and GPU-centric architectures, university-operated HPC systems remain comparatively under-resourced. This survey presents a comprehensive assessment of the HPC landscape across U.S. universities, benchmarking their capabilities against Department of Energy (DOE) leadership-class systems and industrial AI infrastructures. We examine over 50 premier research institutions, analyzing compute capacity, architectural design, governance models, and energy efficiency. Our findings reveal that university clusters, though vital for academic research, exhibit significantly lower growth trajectories (CAGR $\approx$ 18%) than their national ($\approx$ 43%) and industrial ($\approx$ 78%) counterparts. The increasing skew toward GPU-dense AI workloads has widened the capability gap, highlighting the need for federated computing, idle-GPU harvesting, and cost-sharing models. We also identify emerging paradigms, such as decentralized reinforcement learning, as promising opportunities for democratizing AI training within campus environments. Ultimately, this work provides actionable insights for academic leaders, funding agencies, and technology partners to ensure more equitable and sustainable HPC access in support of national research priorities.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dataset of Yul Contracts to Support Solidity Compiler Research</title>
<link>https://arxiv.org/abs/2506.19153</link>
<guid>https://arxiv.org/abs/2506.19153</guid>
<content:encoded><![CDATA[
arXiv:2506.19153v1 Announce Type: new 
Abstract: The YulCode dataset presents a comprehensive collection of 348,840 Yul-based smart contract instances, comprising approximately 135,013 unique contracts. These contracts were generated through the compilation of Solidity source files that have been deployed on the Ethereum mainnet, making the dataset directly representative of real-world decentralized applications. YulCode provides a rich foundation for a variety of research and development tasks, including but not limited to machine learning applications, formal verification, optimization analysis, and software engineering tool evaluation in the context of low-level smart contract code. To the best of our knowledge at the time of writing, YulCode is the first and only publicly available dataset that focuses specifically on Yul, an intermediate language designed for the Ethereum Virtual Machine (EVM). As such, it fills a critical gap in the current ecosystem of smart contract datasets and opens new avenues for research and tooling aimed at low-level contract analysis and generation.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GradualDiff-Fed: A Federated Learning Specialized Framework for Large Language Model</title>
<link>https://arxiv.org/abs/2506.19164</link>
<guid>https://arxiv.org/abs/2506.19164</guid>
<content:encoded><![CDATA[
arXiv:2506.19164v1 Announce Type: new 
Abstract: The rapid proliferation of large language models (LLMs) has created an unprecedented demand for fine-tuning models for specialized domains, such as medical science. While federated learning (FL) offers a decentralized and privacy-preserving approach to collaboratively fine-tune LLMs without sharing raw data, it presents significant challenges, particularly in performance and managing large model sizes efficiently. In this paper, we introduce GradualDiff-Fed, an FL framework designed explicitly for LLMs, and their challenge of handling the high parameter size. GradualDiff-Fed reduces communication costs by transmitting only the difference of model weights rather than the entire model during training rounds. Such an approach significantly improves scalability and communication efficiency, making it more feasible to fine-tune LLMs across distributed clients without compromising performance. Our evaluation demonstrates that GradualDiff-Fed achieves performance on par with centralized training while drastically reducing communication overhead. These results highlight the potential of GradualDiff-Fed as an efficient solution for fine-tuning large models from distributed data in privacy-preserving settings without comprising performance.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shelby: Decentralized Storage Designed to Serve</title>
<link>https://arxiv.org/abs/2506.19233</link>
<guid>https://arxiv.org/abs/2506.19233</guid>
<content:encoded><![CDATA[
arXiv:2506.19233v1 Announce Type: new 
Abstract: Existing decentralized storage protocols fall short of the service required by real-world applications. Their throughput, latency, cost-effectiveness, and availability are insufficient for demanding workloads such as video streaming, large-scale data analytics, or AI training. As a result, Web3 data-intensive applications are predominantly dependent on centralized infrastructure.
  Shelby is a high-performance decentralized storage protocol designed to meet demanding needs. It achieves fast, reliable access to large volumes of data while preserving decentralization guarantees. The architecture reflects lessons from Web2 systems: it separates control and data planes, uses erasure coding with low replication overhead and minimal repair bandwidth, and operates over a dedicated backbone connecting RPC and storage nodes. Reads are paid, which incentivizes good performance. Shelby also introduces a novel auditing protocol that provides strong cryptoeconomic guarantees without compromising performance, a common limitation of other decentralized solutions. The result is a decentralized system that brings Web2-grade performance to production-scale, read-intensive Web3 applications.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Yotta: A Large-Scale Trustless Data Trading Scheme for Blockchain System</title>
<link>https://arxiv.org/abs/2506.19368</link>
<guid>https://arxiv.org/abs/2506.19368</guid>
<content:encoded><![CDATA[
arXiv:2506.19368v1 Announce Type: new 
Abstract: Data trading is one of the key focuses of Web 3.0. However, all the current methods that rely on blockchain-based smart contracts for data exchange cannot support large-scale data trading while ensuring data security, which falls short of fulfilling the spirit of Web 3.0. Even worse, there is currently a lack of discussion on the essential properties that large-scale data trading should satisfy. In this work, we are the first to formalize the property requirements for enabling data trading in Web 3.0. Based on these requirements, we are the first to propose Yotta, a complete batch data trading scheme for blockchain, which features a data trading design that leverages our innovative cryptographic workflow with IPFS and zk-SNARK. Our simulation results demonstrate that Yotta outperforms baseline approaches up to 130 times and exhibits excellent scalability to satisfy all the properties.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Community Detection in Energy Networks based on Energy Self-Sufficiency and Dynamic Flexibility Activation</title>
<link>https://arxiv.org/abs/2506.19412</link>
<guid>https://arxiv.org/abs/2506.19412</guid>
<content:encoded><![CDATA[
arXiv:2506.19412v1 Announce Type: new 
Abstract: The global energy transition towards distributed, smaller-scale resources, such as decentralized generation and flexible assets like storage and shiftable loads, demands novel control structures aligned with the emerging network architectures. These architectures consist of interconnected, self-contained clusters, commonly called microgrids or energy communities. These clusters aim to optimize collective self-sufficiency by prioritizing local energy use or operating independently during wide-area blackouts. This study addresses the challenge of defining optimal clusters, framed as a community detection problem. A novel metric, termed energy modularity, is proposed to evaluate community partitions by quantifying energy self-sufficiency within clusters while incorporating the influence of flexible resources. Furthermore, a highly scalable community detection algorithm to maximize energy modularity based on the Louvain method is presented. Therefore, energy modularity is calculated using linear programming or a more efficient simulation-based approach. The algorithm is validated on an exemplary benchmark grid, demonstrating its effectiveness in identifying optimal energy clusters for modern decentralized energy systems.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PhishingHook: Catching Phishing Ethereum Smart Contracts leveraging EVM Opcodes</title>
<link>https://arxiv.org/abs/2506.19480</link>
<guid>https://arxiv.org/abs/2506.19480</guid>
<content:encoded><![CDATA[
arXiv:2506.19480v1 Announce Type: new 
Abstract: The Ethereum Virtual Machine (EVM) is a decentralized computing engine. It enables the Ethereum blockchain to execute smart contracts and decentralized applications (dApps). The increasing adoption of Ethereum sparked the rise of phishing activities. Phishing attacks often target users through deceptive means, e.g., fake websites, wallet scams, or malicious smart contracts, aiming to steal sensitive information or funds. A timely detection of phishing activities in the EVM is therefore crucial to preserve the user trust and network integrity. Some state-of-the art approaches to phishing detection in smart contracts rely on the online analysis of transactions and their traces. However, replaying transactions often exposes sensitive user data and interactions, with several security concerns. In this work, we present PhishingHook, a framework that applies machine learning techniques to detect phishing activities in smart contracts by directly analyzing the contract's bytecode and its constituent opcodes. We evaluate the efficacy of such techniques in identifying malicious patterns, suspicious function calls, or anomalous behaviors within the contract's code itself before it is deployed or interacted with. We experimentally compare 16 techniques, belonging to four main categories (Histogram Similarity Classifiers, Vision Models, Language Models and Vulnerability Detection Models), using 7,000 real-world malware smart contracts. Our results demonstrate the efficiency of PhishingHook in performing phishing classification systems, with about 90% average accuracy among all the models. We support experimental reproducibility, and we release our code and datasets to the research community.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decompiling Smart Contracts with a Large Language Model</title>
<link>https://arxiv.org/abs/2506.19624</link>
<guid>https://arxiv.org/abs/2506.19624</guid>
<content:encoded><![CDATA[
arXiv:2506.19624v1 Announce Type: new 
Abstract: The widespread lack of broad source code verification on blockchain explorers such as Etherscan, where despite 78,047,845 smart contracts deployed on Ethereum (as of May 26, 2025), a mere 767,520 (< 1%) are open source, presents a severe impediment to blockchain security. This opacity necessitates the automated semantic analysis of on-chain smart contract bytecode, a fundamental research challenge with direct implications for identifying vulnerabilities and understanding malicious behavior. Prevailing decompilers struggle to reverse bytecode in a readable manner, often yielding convoluted code that critically hampers vulnerability analysis and thwarts efforts to dissect contract functionalities for security auditing.
  This paper addresses this challenge by introducing a pioneering decompilation pipeline that, for the first time, successfully leverages Large Language Models (LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into human-readable and semantically faithful Solidity code. Our novel methodology first employs rigorous static program analysis to convert bytecode into a structured three-address code (TAC) representation. This intermediate representation then guides a Llama-3.2-3B model, specifically fine-tuned on a comprehensive dataset of 238,446 TAC-to-Solidity function pairs, to generate high-quality Solidity. This approach uniquely recovers meaningful variable names, intricate control flow, and precise function signatures. Our extensive empirical evaluation demonstrates a significant leap beyond traditional decompilers, achieving an average semantic similarity of 0.82 with original source and markedly superior readability. The practical viability and effectiveness of our research are demonstrated through its implementation in a publicly accessible system, available at https://evmdecompiler.com.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Sound Type System for Secure Currency Flow</title>
<link>https://arxiv.org/abs/2405.12976</link>
<guid>https://arxiv.org/abs/2405.12976</guid>
<content:encoded><![CDATA[
arXiv:2405.12976v2 Announce Type: replace 
Abstract: In this paper we focus on TinySol, a minimal calculus for Solidity smart contracts, introduced by Bartoletti et al. We start by rephrasing its syntax (to emphasise its object-oriented flavour) and give a new big-step operational semantics. We then use it to define two security properties, namely call integrity and noninterference. These two properties have some similarities in their definition, in that they both require that some part of a program is not influenced by the other part. However, we show that the two properties are actually incomparable. Nevertheless, we provide a type system for noninterference and show that well-typed programs satisfy call integrity as well; hence, programs that are accepted by our type system satisfy both properties. We finally discuss the practical usability of the type system and its limitations by means of some simple examples.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ormer: A Manipulation-resistant and Gas-efficient Blockchain Pricing Oracle for DeFi</title>
<link>https://arxiv.org/abs/2410.07893</link>
<guid>https://arxiv.org/abs/2410.07893</guid>
<content:encoded><![CDATA[
arXiv:2410.07893v2 Announce Type: replace 
Abstract: Price feeds of cryptocurrencies are essential for Decentralized Finance (DeFi) applications to realize fundamental trading and exchanging functionalities, which are retrieved from external price data sources such as exchanges and input to on-chain smart contracts in real-time. Currently, arithmetic mean based time-weighted average price (TWAP) oracles are widely used to process price feeds by averaging asset price with short time frame to achieve reliable and gas-efficient pricing. However, recent research indicates that TWAP is vulnerable to price manipulation attacks, resulting in abnormal price fluctuations and severe financial loss. Even worse, TWAP oracles usually set a relatively long time frame setting to prevent such attack. However, it would further introduce long delays and high price deviation errors from the market asset price.
  To address this issue, we propose a novel on-chain gas-efficient pricing algorithm (Ormer) that heuristically estimates the median of asset price within an observation window based on a piecewise-parabolic formula, while the time delay is suppressed by fusing estimations with different window sizes. Our evaluation based on multiple pairs of token swapping price feed across different chains show that Ormer reduces the mean absolute price error by 15.3% and the time delay by 49.3% compared to TWAP. For gas efficiency, regardless of the number of price observations, an encoding mechanism with constant storage requirement is employed without saving all the historical data for median estimation. Surprisingly, the lowest gas consumption of Ormer is even 15.2% less than TWAP, and the oracle querying fee would be saved up to ~20K USD per day for DeFi participants.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Unsupervised Multi-Agent Reinforcement Learning via Task-Agnostic Exploration</title>
<link>https://arxiv.org/abs/2502.08365</link>
<guid>https://arxiv.org/abs/2502.08365</guid>
<content:encoded><![CDATA[
arXiv:2502.08365v3 Announce Type: replace 
Abstract: In reinforcement learning, we typically refer to unsupervised pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e. rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach, called task-agnostic exploration, casts the unsupervised objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follow.
  In contrast, little is known about it in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via task-agnostic exploration in challenging domains, showing that optimizing for a specific objective, namely mixture entropy, provides an excellent trade-off between tractability and performances.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Communication in Multi-team Dynamic Games: A Mean Field Perspective</title>
<link>https://arxiv.org/abs/2407.06528</link>
<guid>https://arxiv.org/abs/2407.06528</guid>
<content:encoded><![CDATA[
arXiv:2407.06528v2 Announce Type: replace-cross 
Abstract: Coordinating communication and control is a key component in the stability and performance of networked multi-agent systems. While single user networked control systems have gained a lot of attention within this domain, in this work, we address the more challenging problem of large population multi-team dynamic games. In particular, each team constitutes two decision makers (namely, the sensor and the controller) who coordinate over a shared network to control a dynamically evolving state of interest under costs on both actuation and sensing/communication. Due to the shared nature of the wireless channel, the overall cost of each team depends on other teams' policies, thereby leading to a noncooperative game setup. Due to the presence of a large number of teams, we compute approximate decentralized Nash equilibrium policies for each team using the paradigm of (extended) mean-field games, which is governed by (1) the mean traffic flowing over the channel, and (2) the value of information at the sensor, which highlights the semantic nature of the ensuing communication. In the process, we compute optimal controller policies and approximately optimal sensor policies for each representative team of the mean-field system to alleviate the problem of general non-contractivity of the mean-field fixed point operator associated with the finite cardinality of the sensor action space. Consequently, we also prove the $\epsilon$--Nash property of the mean-field equilibrium solution which essentially characterizes how well the solution derived using mean-field analysis performs on the finite-team system. Finally, we provide extensive numerical simulations, which corroborate the theoretical findings and lead to additional insights on the properties of the results presented.
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design, Implementation, and Analysis of Fair Faucets for Blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2506.17236</link>
<guid>https://arxiv.org/abs/2506.17236</guid>
<content:encoded><![CDATA[
arXiv:2506.17236v1 Announce Type: new 
Abstract: The present dissertation addresses the problem of fairly distributing shared resources in non-commercial blockchain networks. Blockchains are distributed systems that order and timestamp records of a given network of users, in a public, cryptographically secure, and consensual way. The records, which may in kind be events, transaction orders, sets of rules for structured transactions etc. are placed within well-defined datastructures called blocks, and they are linked to each other by the virtue of cryptographic pointers, in a total ordering which represents their temporal relations of succession. The ability to operate on the blockchain, and/or to contribute a record to the content of a block are shared resources of the blockchain systems. In commercial networks, these resources are exchanged in return for fiat money, and consequently, fairness is not a relevant problem in terms of computer engineering. In non-commercial networks, however, monetary solutions are not available, by definition. The present non-commercial blockchain networks employ trivial distribution mechanisms called faucets, which offer fixed amounts of free tokens (called cryptocurrencies) specific to the given network. This mechanism, although simple and efficient, is prone to denial of service (DoS) attacks and cannot address the fairness problem. In the present dissertation, the faucet mechanism is adapted for fair distribution, in line with Max-min Fairness scheme. In total, we contributed 6 distinct Max-min Fair algorithms as efficient blockchain faucets. The algorithms we contribute are resistant to DoS attacks, low-cost in terms of blockchain computation economics, and they also allow for different user weighting policies.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Second Order State Hallucinations for Adversarial Attack Mitigation in Formation Control of Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2506.17283</link>
<guid>https://arxiv.org/abs/2506.17283</guid>
<content:encoded><![CDATA[
arXiv:2506.17283v1 Announce Type: new 
Abstract: The increasing deployment of multi-agent systems (MAS) in critical infrastructures such as autonomous transportation, disaster relief, and smart cities demands robust formation control mechanisms resilient to adversarial attacks. Traditional consensus-based controllers, while effective under nominal conditions, are highly vulnerable to data manipulation, sensor spoofing, and communication failures. To address this challenge, we propose Second-Order State Hallucination (SOSH), a novel framework that detects compromised agents through distributed residual monitoring and maintains formation stability by replacing attacked states with predictive second-order approximations. Unlike existing mitigation strategies that require significant restructuring or induce long transients, SOSH offers a lightweight, decentralized correction mechanism based on second-order Taylor expansions, enabling rapid and scalable resilience. We establish rigorous Lyapunov-based stability guarantees, proving that formation errors remain exponentially bounded even under persistent attacks, provided the hallucination parameters satisfy explicit conditions. Comprehensive Monte Carlo experiments on a 5-agent complete graph formation demonstrate that SOSH outperforms established robust control schemes, including W-MSR and Huber-based consensus filters, achieving faster convergence rates, lower steady-state error, and superior transient recovery. Our results confirm that SOSH combines theoretical robustness with practical deployability, offering a promising direction for securing MAS formations against sophisticated adversarial threats.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Prediction -- Structuring Epistemic Integrity in Artificial Reasoning Systems</title>
<link>https://arxiv.org/abs/2506.17331</link>
<guid>https://arxiv.org/abs/2506.17331</guid>
<content:encoded><![CDATA[
arXiv:2506.17331v1 Announce Type: new 
Abstract: This paper develops a comprehensive framework for artificial intelligence systems that operate under strict epistemic constraints, moving beyond stochastic language prediction to support structured reasoning, propositional commitment, and contradiction detection. It formalises belief representation, metacognitive processes, and normative verification, integrating symbolic inference, knowledge graphs, and blockchain-based justification to ensure truth-preserving, auditably rational epistemic agents.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Social Metaverse Streaming based on Federated Multi-Agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2506.17342</link>
<guid>https://arxiv.org/abs/2506.17342</guid>
<content:encoded><![CDATA[
arXiv:2506.17342v1 Announce Type: new 
Abstract: The social metaverse is a growing digital ecosystem that blends virtual and physical worlds. It allows users to interact socially, work, shop, and enjoy entertainment. However, privacy remains a major challenge, as immersive interactions require continuous collection of biometric and behavioral data. At the same time, ensuring high-quality, low-latency streaming is difficult due to the demands of real-time interaction, immersive rendering, and bandwidth optimization. To address these issues, we propose ASMS (Adaptive Social Metaverse Streaming), a novel streaming system based on Federated Multi-Agent Proximal Policy Optimization (F-MAPPO). ASMS leverages F-MAPPO, which integrates federated learning (FL) and deep reinforcement learning (DRL) to dynamically adjust streaming bit rates while preserving user privacy. Experimental results show that ASMS improves user experience by at least 14% compared to existing streaming methods across various network conditions. Therefore, ASMS enhances the social metaverse experience by providing seamless and immersive streaming, even in dynamic and resource-constrained networks, while ensuring that sensitive user data remains on local devices.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedNAMs: Performing Interpretability Analysis in Federated Learning Context</title>
<link>https://arxiv.org/abs/2506.17466</link>
<guid>https://arxiv.org/abs/2506.17466</guid>
<content:encoded><![CDATA[
arXiv:2506.17466v1 Announce Type: new 
Abstract: Federated learning continues to evolve but faces challenges in interpretability and explainability. To address these challenges, we introduce a novel approach that employs Neural Additive Models (NAMs) within a federated learning framework. This new Federated Neural Additive Models (FedNAMs) approach merges the advantages of NAMs, where individual networks concentrate on specific input features, with the decentralized approach of federated learning, ultimately producing interpretable analysis results. This integration enhances privacy by training on local data across multiple devices, thereby minimizing the risks associated with data centralization and improving model robustness and generalizability. FedNAMs maintain detailed, feature-specific learning, making them especially valuable in sectors such as finance and healthcare. They facilitate the training of client-specific models to integrate local updates, preserve privacy, and mitigate concerns related to centralization. Our studies on various text and image classification tasks, using datasets such as OpenFetch ML Wine, UCI Heart Disease, and Iris, show that FedNAMs deliver strong interpretability with minimal accuracy loss compared to traditional Federated Deep Neural Networks (DNNs). The research involves notable findings, including the identification of critical predictive features at both client and global levels. Volatile acidity, sulfates, and chlorides for wine quality. Chest pain type, maximum heart rate, and number of vessels for heart disease. Petal length and width for iris classification. This approach strengthens privacy and model efficiency and improves interpretability and robustness across diverse datasets. Finally, FedNAMs generate insights on causes of highly and low interpretable features.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Smart Contract-based Non-Transferable Signature Verification System using Nominative Signatures</title>
<link>https://arxiv.org/abs/2506.17504</link>
<guid>https://arxiv.org/abs/2506.17504</guid>
<content:encoded><![CDATA[
arXiv:2506.17504v1 Announce Type: new 
Abstract: Nominative signatures allow us to indicate who can verify a signature, and they can be employed to construct a non-transferable signature verification system that prevents the signature verification by a third party in unexpected situations. For example, this system can prevent IOU/loan certificate verification in unexpected situations. However, nominative signatures themselves do not allow the verifier to check whether the funds will be transferred in the future or have been transferred.It would be desirable to verify the fact simultaneously when the system involves a certain money transfer such as cryptocurrencies/cryptoassets. In this paper, we propose a smart contract-based non-transferable signature verification system using nominative signatures. We pay attention to the fact that the invisibility, which is a security requirement to be held for nominative signatures, allows us to publish nominative signatures on the blockchain. Our system can verify whether a money transfer actually will take place, in addition to indicating who can verify a signature. We transform the Hanaoka-Schuldt nominative signature scheme (ACNS 2011, IEICE Trans. 2016) which is constructed over a symmetric pairing to a scheme constructed over an asymmetric pairing, and evaluate the gas cost when a smart contract runs the verification algorithm of the modified Hanaoka-Schuldt nominative signature scheme.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decoding Federated Learning: The FedNAM+ Conformal Revolution</title>
<link>https://arxiv.org/abs/2506.17872</link>
<guid>https://arxiv.org/abs/2506.17872</guid>
<content:encoded><![CDATA[
arXiv:2506.17872v1 Announce Type: new 
Abstract: Federated learning has significantly advanced distributed training of machine learning models across decentralized data sources. However, existing frameworks often lack comprehensive solutions that combine uncertainty quantification, interpretability, and robustness. To address this, we propose FedNAM+, a federated learning framework that integrates Neural Additive Models (NAMs) with a novel conformal prediction method to enable interpretable and reliable uncertainty estimation. Our method introduces a dynamic level adjustment technique that utilizes gradient-based sensitivity maps to identify key input features influencing predictions. This facilitates both interpretability and pixel-wise uncertainty estimates. Unlike traditional interpretability methods such as LIME and SHAP, which do not provide confidence intervals, FedNAM+ offers visual insights into prediction reliability. We validate our approach through experiments on CT scan, MNIST, and CIFAR datasets, demonstrating high prediction accuracy with minimal loss (e.g., only 0.1% on MNIST), along with transparent uncertainty measures. Visual analysis highlights variable uncertainty intervals, revealing low-confidence regions where model performance can be improved with additional data. Compared to Monte Carlo Dropout, FedNAM+ delivers efficient and global uncertainty estimates with reduced computational overhead, making it particularly suitable for federated learning scenarios. Overall, FedNAM+ provides a robust, interpretable, and computationally efficient framework that enhances trust and transparency in decentralized predictive modeling.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure User-friendly Blockchain Modular Wallet Design Using Android &amp; OP-TEE</title>
<link>https://arxiv.org/abs/2506.17988</link>
<guid>https://arxiv.org/abs/2506.17988</guid>
<content:encoded><![CDATA[
arXiv:2506.17988v1 Announce Type: new 
Abstract: Emerging crypto economies still hemorrhage digital assets because legacy wallets leak private keys at almost every layer of the software stack, from user-space libraries to kernel memory dumps. This paper solves that twin crisis of security and interoperability by re-imagining key management as a platform-level service anchored in ARM TrustZone through OP-TEE. Our architecture fractures the traditional monolithic Trusted Application into per-chain modules housed in a multi-tenant TA store, finally breaking OP-TEE's single-binary ceiling. A cryptographically sealed firmware-over-the-air pipeline welds each TA set to an Android system image, enabling hot-swap updates while Verified Boot enforces rollback protection. Every package carries a chained signature developer first, registry second so even a compromised supply chain cannot smuggle malicious code past the Secure World's RSA-PSS gatekeeper. Inside the TEE, strict inter-TA isolation, cache partitioning, and GP-compliant crypto APIs ensure secrets never bleed across trust boundaries or timing domains. The Rich Execution Environment can interact only via hardware-mediated Secure Monitor Calls, collapsing the surface exposed to malware in Android space. End-users enjoy a single polished interface yet can install or retire Bitcoin, Ethereum, Solana, or tomorrow's chain with one tap, shrinking both storage footprint and audit scope. For auditors, the composition model slashes duplicated verification effort by quarantining blockchain logic inside narrowly scoped modules that share formally specified interfaces. Our threat analysis spans six adversary layers and shows how the design neutralizes REE malware sniffing, OTA injection, and cross-module side channels without exotic hardware. A reference implementation on AOSP exports a Wallet Manager HAL, custom SELinux domains, and a CI/CD pipeline that vet community modules before release. The result is not merely another hardware wallet but a programmable substrate that can evolve at the velocity of the blockchain ecosystem. By welding radical extensibility to hardware-anchored assurance, the platform closes the security-usability gap that has long stymied mass-market self-custody. We posit that modular TEEs are the missing OS primitive for Web3, much as virtual memory unlocked multi-tasking in classical computing. Together, these contributions sketch a blueprint for multi-chain asset management that is auditable, resilient, and poised for global deployment.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Cloud-Fog Automation for Autonomous Collision Detection and Classification in Intelligent Unmanned Surface Vehicles</title>
<link>https://arxiv.org/abs/2506.18024</link>
<guid>https://arxiv.org/abs/2506.18024</guid>
<content:encoded><![CDATA[
arXiv:2506.18024v1 Announce Type: new 
Abstract: Industrial Cyber-Physical Systems (ICPS) technologies are foundational in driving maritime autonomy, particularly for Unmanned Surface Vehicles (USVs). However, onboard computational constraints and communication latency significantly restrict real-time data processing, analysis, and predictive modeling, hence limiting the scalability and responsiveness of maritime ICPS. To overcome these challenges, we propose a distributed Cloud-Edge-IoT architecture tailored for maritime ICPS by leveraging design principles from the recently proposed Cloud-Fog Automation paradigm. Our proposed architecture comprises three hierarchical layers: a Cloud Layer for centralized and decentralized data aggregation, advanced analytics, and future model refinement; an Edge Layer that executes localized AI-driven processing and decision-making; and an IoT Layer responsible for low-latency sensor data acquisition. Our experimental results demonstrated improvements in computational efficiency, responsiveness, and scalability. When compared with our conventional approaches, we achieved a classification accuracy of 86\%, with an improved latency performance. By adopting Cloud-Fog Automation, we address the low-latency processing constraints and scalability challenges in maritime ICPS applications. Our work offers a practical, modular, and scalable framework to advance robust autonomy and AI-driven decision-making and autonomy for intelligent USVs in future maritime ICPS.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Current State of Ethereum's Enshrined Proposer Builder Separation</title>
<link>https://arxiv.org/abs/2506.18189</link>
<guid>https://arxiv.org/abs/2506.18189</guid>
<content:encoded><![CDATA[
arXiv:2506.18189v1 Announce Type: new 
Abstract: Initially introduced to Ethereum via Flashbots' MEV-boost, Proposer-Builder Separation allows proposers to auction off blockspace to a market of transaction orderers, known as builders. PBS is currently available to validators through the aforementioned MEV-boost, but its unregulated and relay-dependent nature has much of the Ethereum community calling for its enshrinement. Providing a protocol-integrated PBS marketspace and communication channel for payload outsourcing is termed PBS enshrinement. Although ePBS potentially introduces native MEV mitigation mechanisms and reduces validator operation costs, fears of multiparty collusion and chain stagnation are all too real. In addition to mitigating these potential drawbacks, PBS research pursues many tenets revered by Web3 enthusiasts, including but not limited to, censorship resistance, validator reward equity, and deflationary finance. The subsequent SoK will identify current PBS mechanisms, the need for enshrinement, additions to the ePBS upgrade, and the existing or potential on-chain socioeconomic implications of each.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2506.18245</link>
<guid>https://arxiv.org/abs/2506.18245</guid>
<content:encoded><![CDATA[
arXiv:2506.18245v1 Announce Type: new 
Abstract: Smart contract vulnerability detection remains a major challenge in blockchain security. Existing vulnerability detection methods face two main issues: (1) Existing datasets lack comprehensive coverage and high-quality explanations for preference learning. (2) Large language models (LLMs) often struggle with accurately interpreting specific concepts in smart contract security. Empirical analysis shows that even after continual pre-training (CPT) and supervised fine-tuning (SFT), LLMs may misinterpret the execution order of state changes, resulting in incorrect explanations despite making correct detection decisions. To address these challenges, we propose Smart-LLaMA-DPO based on LLaMA-3.1-8B. We construct a comprehensive dataset covering four major vulnerability types and machine-unauditable vulnerabilities, including precise labels, explanations, and locations for SFT, as well as high-quality and low-quality output pairs for Direct Preference Optimization (DPO). Second, we perform CPT using large-scale smart contract to enhance the LLM's understanding of specific security practices in smart contracts. Futhermore, we conduct SFT with our comprehensive dataset. Finally, we apply DPO, leveraging human feedback and a specially designed loss function that increases the probability of preferred explanations while reducing the likelihood of non-preferred outputs. We evaluate Smart-LLaMA-DPO on four major vulnerability types: reentrancy, timestamp dependence, integer overflow/underflow, and delegatecall, as well as machine-unauditable vulnerabilities. Our method significantly outperforms state-of-the-art baselines, with average improvements of 10.43% in F1 score and 7.87% in accuracy. Moreover, both LLM evaluation and human evaluation confirm that our method generates more correct, thorough, and clear explanations.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Recipe for Discovery: A Framework for Systematic Open Source Project Identification</title>
<link>https://arxiv.org/abs/2506.18359</link>
<guid>https://arxiv.org/abs/2506.18359</guid>
<content:encoded><![CDATA[
arXiv:2506.18359v1 Announce Type: new 
Abstract: Open source software development, particularly within institutions such as universities and research laboratories, is often decentralized and difficult to track. Despite producing highly impactful tools in science, these efforts often go unrecognized due to a lack of visibility and institutional awareness. This paper addresses the challenge of discovering, classifying, and analyzing open source software projects developed across distributed institutional systems. We present a framework for systematically identifying institutional affiliated repositories, using the University of California (UC) system as a case study.
  Using GitHub's REST API, we build a pipeline to discover relevant repositories and extract meaningful metadata. We then propose and evaluate multiple classification strategies, including both traditional machine learning models and large language models (LLMs), to distinguish affiliated projects from unrelated repositories and generate accurate insights into the academic open source landscape. Our results show that the framework is effective at scale, discovering over 52,000 repositories and predicting institutional affiliation with high accuracy.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transformer World Model for Sample Efficient Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2506.18537</link>
<guid>https://arxiv.org/abs/2506.18537</guid>
<content:encoded><![CDATA[
arXiv:2506.18537v1 Announce Type: new 
Abstract: We present the Multi-Agent Transformer World Model (MATWM), a novel transformer-based world model designed for multi-agent reinforcement learning in both vector- and image-based environments. MATWM combines a decentralized imagination framework with a semi-centralized critic and a teammate prediction module, enabling agents to model and anticipate the behavior of others under partial observability. To address non-stationarity, we incorporate a prioritized replay mechanism that trains the world model on recent experiences, allowing it to adapt to agents' evolving policies. We evaluated MATWM on a broad suite of benchmarks, including the StarCraft Multi-Agent Challenge, PettingZoo, and MeltingPot. MATWM achieves state-of-the-art performance, outperforming both model-free and prior world model approaches, while demonstrating strong sample efficiency, achieving near-optimal performance in as few as 50K environment interactions. Ablation studies confirm the impact of each component, with substantial gains in coordination-heavy tasks.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation</title>
<link>https://arxiv.org/abs/2506.18783</link>
<guid>https://arxiv.org/abs/2506.18783</guid>
<content:encoded><![CDATA[
arXiv:2506.18783v1 Announce Type: new 
Abstract: TRIZ, the Theory of Inventive Problem Solving, is a structured, knowledge-based framework for innovation and abstracting problems to find inventive solutions. However, its application is often limited by the complexity and deep interdisciplinary knowledge required. Advancements in Large Language Models (LLMs) have revealed new possibilities for automating parts of this process. While previous studies have explored single LLMs in TRIZ applications, this paper introduces a multi-agent approach. We propose an LLM-based multi-agent system, called TRIZ agents, each with specialized capabilities and tool access, collaboratively solving inventive problems based on the TRIZ methodology. This multi-agent system leverages agents with various domain expertise to efficiently navigate TRIZ steps. The aim is to model and simulate an inventive process with language agents. We assess the effectiveness of this team of agents in addressing complex innovation challenges based on a selected case study in engineering. We demonstrate the potential of agent collaboration to produce diverse, inventive solutions. This research contributes to the future of AI-driven innovation, showcasing the advantages of decentralized problem-solving in complex ideation tasks.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shift Happens: Mixture of Experts based Continual Adaptation in Federated Learning</title>
<link>https://arxiv.org/abs/2506.18789</link>
<guid>https://arxiv.org/abs/2506.18789</guid>
<content:encoded><![CDATA[
arXiv:2506.18789v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized clients without sharing raw data, yet faces significant challenges in real-world settings where client data distributions evolve dynamically over time. This paper tackles the critical problem of covariate and label shifts in streaming FL environments, where non-stationary data distributions degrade model performance and require adaptive middleware solutions. We introduce ShiftEx, a shift-aware mixture of experts framework that dynamically creates and trains specialized global models in response to detected distribution shifts using Maximum Mean Discrepancy for covariate shifts. The framework employs a latent memory mechanism for expert reuse and implements facility location-based optimization to jointly minimize covariate mismatch, expert creation costs, and label imbalance. Through theoretical analysis and comprehensive experiments on benchmark datasets, we demonstrate 5.5-12.9 percentage point accuracy improvements and 22-95 % faster adaptation compared to state-of-the-art FL baselines across diverse shift scenarios. The proposed approach offers a scalable, privacy-preserving middleware solution for FL systems operating in non-stationary, real-world conditions while minimizing communication and computational overhead.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FORGE: An LLM-driven Framework for Large-Scale Smart Contract Vulnerability Dataset Construction</title>
<link>https://arxiv.org/abs/2506.18795</link>
<guid>https://arxiv.org/abs/2506.18795</guid>
<content:encoded><![CDATA[
arXiv:2506.18795v1 Announce Type: new 
Abstract: High-quality smart contract vulnerability datasets are critical for evaluating security tools and advancing smart contract security research. Two major limitations of current manual dataset construction are (1) labor-intensive and error-prone annotation processes limiting the scale, quality, and evolution of the dataset, and (2) absence of standardized classification rules results in inconsistent vulnerability categories and labeling results across different datasets. To address these limitations, we present FORGE, the first automated approach for constructing smart contract vulnerability datasets. FORGE leverages an LLM-driven pipeline to extract high-quality vulnerabilities from real-world audit reports and classify them according to the CWE, the most widely recognized classification in software security. FORGE employs a divide-and-conquer strategy to extract structured and self-contained vulnerability information from these reports. Additionally, it uses a tree-of-thoughts technique to classify the vulnerability information into the hierarchical CWE classification. To evaluate FORGE's effectiveness, we run FORGE on 6,454 real-world audit reports and generate a dataset comprising 81,390 solidity files and 27,497 vulnerability findings across 296 CWE categories. Manual assessment of the dataset demonstrates high extraction precision and classification consistency with human experts (precision of 95.6% and inter-rater agreement k-$\alpha$ of 0.87). We further validate the practicality of our dataset by benchmarking 13 existing security tools on our dataset. The results reveal the significant limitations in current detection capabilities. Furthermore, by analyzing the severity-frequency distribution patterns through a unified CWE perspective in our dataset, we highlight inconsistency between current smart contract research focus and priorities identified from real-world vulnerabilities...
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LayerZero</title>
<link>https://arxiv.org/abs/2312.09118</link>
<guid>https://arxiv.org/abs/2312.09118</guid>
<content:encoded><![CDATA[
arXiv:2312.09118v3 Announce Type: replace 
Abstract: In this paper, we present the first intrinsically secure and semantically universal omnichain interoperability protocol: LayerZero. Utilizing an immutable endpoint, append-only verification modules, and fully-configurable verification infrastructure, LayerZero provides the security, configurability, and extensibility necessary to achieve omnichain interoperability. LayerZero enforces strict application-exclusive ownership of protocol security and cost through its novel trust-minimized modular security framework which is designed to universally support all blockchains and use cases. Omnichain applications (OApps) built on the LayerZero protocol achieve frictionless blockchain-agnostic interoperation through LayerZero's universal network semantics.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Selfish Mining Analysis for DAG-Based PoW Consensus Protocols</title>
<link>https://arxiv.org/abs/2501.10888</link>
<guid>https://arxiv.org/abs/2501.10888</guid>
<content:encoded><![CDATA[
arXiv:2501.10888v3 Announce Type: replace 
Abstract: Selfish mining is strategic rule-breaking to maximize rewards in proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred tool for finding optimal strategies in Bitcoin and similar linear chain protocols. Protocols increasingly adopt DAG-based chain structures, for which MDP analysis is more involved. To date, researchers have tailored specific MDPs for each protocol. Protocol design suffers long feedback loops, as each protocol change implies manual work on the MDP. To overcome this, we propose a generic attack model that covers a wide range of protocols, including Ethereum Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular: we specify each protocol as a concise program, and our tooling then derives and solves the selfish mining MDP automatically.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer</title>
<link>https://arxiv.org/abs/2501.14931</link>
<guid>https://arxiv.org/abs/2501.14931</guid>
<content:encoded><![CDATA[
arXiv:2501.14931v3 Announce Type: replace 
Abstract: This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically-optimal latency of one round-trip, i.e., requiring only one network trip for writing a transaction and one for reading it. To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, which independently process transactions and append them to local logs. Replicas assigns a timestamp and a sequence number to each transaction in their logs, allowing clients to extract valuable metadata about the transactions and the system state. Later on, clients retrieve these logs and extract transactions (and associated metadata) from them. Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then show pod-core, a protocol that satisfies properties such as transaction confirmation within $2\delta$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that single-shot auctions can be realized using the pod notion and observe that it is also sufficient for other popular applications.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis</title>
<link>https://arxiv.org/abs/2506.15790</link>
<guid>https://arxiv.org/abs/2506.15790</guid>
<content:encoded><![CDATA[
arXiv:2506.15790v1 Announce Type: new 
Abstract: With the advance application of blockchain technology in various fields, ensuring the security and stability of smart contracts has emerged as a critical challenge. Current security analysis methodologies in vulnerability detection can be categorized into static analysis and dynamic analysis methods.However, these existing traditional vulnerability detection methods predominantly rely on analyzing original contract code, not all smart contracts provide accessible code.We present ETrace, a novel event-driven vulnerability detection framework for smart contracts, which uniquely identifies potential vulnerabilities through LLM-powered trace analysis without requiring source code access. By extracting fine-grained event sequences from transaction logs, the framework leverages Large Language Models (LLMs) as adaptive semantic interpreters to reconstruct event analysis through chain-of-thought reasoning. ETrace implements pattern-matching to establish causal links between transaction behavior patterns and known attack behaviors. Furthermore, we validate the effectiveness of ETrace through preliminary experimental results.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Coordinate Under Threshold Rewards: A Cooperative Multi-Agent Bandit Framework</title>
<link>https://arxiv.org/abs/2506.15856</link>
<guid>https://arxiv.org/abs/2506.15856</guid>
<content:encoded><![CDATA[
arXiv:2506.15856v1 Announce Type: new 
Abstract: Cooperative multi-agent systems often face tasks that require coordinated actions under uncertainty. While multi-armed bandit (MAB) problems provide a powerful framework for decentralized learning, most prior work assumes individually attainable rewards. We address the challenging setting where rewards are threshold-activated: an arm yields a payoff only when a minimum number of agents pull it simultaneously, with this threshold unknown in advance. Complicating matters further, some arms are decoys - requiring coordination to activate but yielding no reward - introducing a new challenge of wasted joint exploration. We introduce Threshold-Coop-UCB (T-Coop-UCB), a decentralized algorithm that enables agents to jointly learn activation thresholds and reward distributions, forming effective coalitions without centralized control. Empirical results show that T-Coop-UCB consistently outperforms baseline methods in cumulative reward, regret, and coordination metrics, achieving near-Oracle performance. Our findings underscore the importance of joint threshold learning and decoy avoidance for scalable, decentralized cooperation in complex multi-agent
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competing Bandits in Matching Markets via Super Stability</title>
<link>https://arxiv.org/abs/2506.15926</link>
<guid>https://arxiv.org/abs/2506.15926</guid>
<content:encoded><![CDATA[
arXiv:2506.15926v1 Announce Type: new 
Abstract: We study bandit learning in matching markets with two-sided reward uncertainty, extending prior research primarily focused on single-sided uncertainty. Leveraging the concept of `super-stability' from Irving (1994), we demonstrate the advantage of the Extended Gale-Shapley (GS) algorithm over the standard GS algorithm in achieving true stable matchings under incomplete information. By employing the Extended GS algorithm, our centralized algorithm attains a logarithmic pessimal stable regret dependent on an instance-dependent admissible gap parameter. This algorithm is further adapted to a decentralized setting with a constant regret increase. Finally, we establish a novel centralized instance-dependent lower bound for binary stable regret, elucidating the roles of the admissible gap and super-stable matching in characterizing the complexity of stable matching with bandit feedback.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Blockchain-based Steganography via Backcalculating Generative Adversarial Network</title>
<link>https://arxiv.org/abs/2506.16023</link>
<guid>https://arxiv.org/abs/2506.16023</guid>
<content:encoded><![CDATA[
arXiv:2506.16023v1 Announce Type: new 
Abstract: Blockchain-based steganography enables data hiding via encoding the covert data into a specific blockchain transaction field. However, previous works focus on the specific field-embedding methods while lacking a consideration on required field-generation embedding. In this paper, we propose a generic blockchain-based steganography framework (GBSF). The sender generates the required fields such as amount and fees, where the additional covert data is embedded to enhance the channel capacity. Based on GBSF, we design a reversible generative adversarial network (R-GAN) that utilizes the generative adversarial network with a reversible generator to generate the required fields and encode additional covert data into the input noise of the reversible generator. We then explore the performance flaw of R-GAN. To further improve the performance, we propose R-GAN with Counter-intuitive data preprocessing and Custom activation functions, namely CCR-GAN. The counter-intuitive data preprocessing (CIDP) mechanism is used to reduce decoding errors in covert data, while it incurs gradient explosion for model convergence. The custom activation function named ClipSigmoid is devised to overcome the problem. Theoretical justification for CIDP and ClipSigmoid is also provided. We also develop a mechanism named T2C, which balances capacity and concealment. We conduct experiments using the transaction amount of the Bitcoin mainnet as the required field to verify the feasibility. We then apply the proposed schemes to other transaction fields and blockchains to demonstrate the scalability. Finally, we evaluate capacity and concealment for various blockchains and transaction fields and explore the trade-off between capacity and concealment. The results demonstrate that R-GAN and CCR-GAN are able to enhance the channel capacity effectively and outperform state-of-the-art works.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models</title>
<link>https://arxiv.org/abs/2506.16218</link>
<guid>https://arxiv.org/abs/2506.16218</guid>
<content:encoded><![CDATA[
arXiv:2506.16218v1 Announce Type: new 
Abstract: Federated prompt learning (FPL) for vision-language models is a powerful approach to collaboratively adapt models across distributed clients while preserving data privacy. However, existing FPL approaches suffer from a trade-off between performance and robustness, particularly in out-of-distribution (OOD) shifts, limiting their reliability in real-world scenarios. The inherent in-distribution (ID) data heterogeneity among different clients makes it more challenging to maintain this trade-off. To fill this gap, we introduce a Federated OOD-aware Context Optimization (FOCoOp) framework, which captures diverse distributions among clients using ID global prompts, local prompts, and OOD prompts. Specifically, FOCoOp leverages three sets of prompts to create both class-level and distribution-level separations, which adapt to OOD shifts through bi-level distributionally robust optimization. Additionally, FOCoOp improves the discrimination consistency among clients, i.e., calibrating global prompts, seemingly OOD prompts, and OOD prompts by semi-unbalanced optimal transport. The extensive experiments on real-world datasets demonstrate that FOCoOp effectively captures decentralized heterogeneous distributions and enhances robustness of different OOD shifts. The project is available at GitHub.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordination of Electrical and Heating Resources by Self-Interested Agents</title>
<link>https://arxiv.org/abs/2506.16277</link>
<guid>https://arxiv.org/abs/2506.16277</guid>
<content:encoded><![CDATA[
arXiv:2506.16277v1 Announce Type: new 
Abstract: With the rise of distributed energy resources and sector coupling, distributed optimization can be a sensible approach to coordinate decentralized energy resources. Further, district heating, heat pumps, cogeneration, and sharing concepts like local energy communities introduce the potential to optimize heating and electricity output simultaneously. To solve this issue, we tackle the distributed multi-energy scheduling optimization problem, which describes the optimization of distributed energy generators over multiple time steps to reach a specific target schedule. This work describes a novel distributed hybrid algorithm as a solution approach. This approach is based on the heuristics of gossiping and local search and can simultaneously optimize the private objective of the participants and the collective objective, considering multiple energy sectors. We show that the algorithm finds globally near-optimal solutions while protecting the stakeholders' economic goals and the plants' technical properties. Two test cases representing pure electrical and gas-based technologies are evaluated.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SecureFed: A Two-Phase Framework for Detecting Malicious Clients in Federated Learning</title>
<link>https://arxiv.org/abs/2506.16458</link>
<guid>https://arxiv.org/abs/2506.16458</guid>
<content:encoded><![CDATA[
arXiv:2506.16458v1 Announce Type: new 
Abstract: Federated Learning (FL) protects data privacy while providing a decentralized method for training models. However, because of the distributed schema, it is susceptible to adversarial clients that could alter results or sabotage model performance. This study presents SecureFed, a two-phase FL framework for identifying and reducing the impact of such attackers. Phase 1 involves collecting model updates from participating clients and applying a dimensionality reduction approach to identify outlier patterns frequently associated with malicious behavior. Temporary models constructed from the client updates are evaluated on synthetic datasets to compute validation losses and support anomaly scoring. The idea of learning zones is presented in Phase 2, where weights are dynamically routed according to their contribution scores and gradient magnitudes. High-value gradient zones are given greater weight in aggregation and contribute more significantly to the global model, while lower-value gradient zones, which may indicate possible adversarial activity, are gradually removed from training. Until the model converges and a strong defense against poisoning attacks is possible, this training cycle continues Based on the experimental findings, SecureFed considerably improves model resilience without compromising model performance.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enabling Blockchain Interoperability Through Network Discovery Services</title>
<link>https://arxiv.org/abs/2506.16611</link>
<guid>https://arxiv.org/abs/2506.16611</guid>
<content:encoded><![CDATA[
arXiv:2506.16611v1 Announce Type: new 
Abstract: Web3 technologies have experienced unprecedented growth in the last decade, achieving widespread adoption. As various blockchain networks continue to evolve, we are on the cusp of a paradigm shift in which they could provide services traditionally offered by the Internet, but in a decentralized manner, marking the emergence of the Internet of Blockchains. While significant progress has been achieved in enabling interoperability between blockchain networks, existing solutions often assume that networks are already mutually aware. This reveals a critical gap: the initial discovery of blockchain networks remains largely unaddressed. This paper proposes a decentralized architecture for blockchain network discovery that operates independently of any centralized authority. We also introduce a mechanism for discovering assets and services within a blockchain from external networks. Given the decentralized nature of the proposed discovery architecture, we design an incentive mechanism to encourage nodes to actively participate in maintaining the discovery network. The proposed architecture implemented and evaluated, using the Substrate framework, demonstrates its resilience and scalability, effectively handling up to 130,000 concurrent requests under the tested network configurations, with a median response time of 5.5 milliseconds, demonstrating the ability to scale its processing capacity further by increasing its network size.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Energy Billing with Blockchain and the Prophet Forecasting Model: A Holistic Approach</title>
<link>https://arxiv.org/abs/2506.16649</link>
<guid>https://arxiv.org/abs/2506.16649</guid>
<content:encoded><![CDATA[
arXiv:2506.16649v1 Announce Type: new 
Abstract: This paper presents a comprehensive approach to automated energy billing that leverages IoT-based smart meters, blockchain technology, and the Prophet time series forecasting model. The proposed system facilitates real-time power consumption monitoring via Wi-Fi-enabled ESP32 modules and a mobile application interface. It integrates Firebase and blockchain for secure, transparent billing processes and employs smart contracts for automated payments. The Prophet model is used for energy demand forecasting, with careful data preprocessing, transformation, and parameter tuning to improve prediction accuracy. This holistic solution aims to reduce manual errors, enhance user awareness, and promote sustainable energy use.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedFitTech: A Baseline in Federated Learning for Fitness Tracking</title>
<link>https://arxiv.org/abs/2506.16840</link>
<guid>https://arxiv.org/abs/2506.16840</guid>
<content:encoded><![CDATA[
arXiv:2506.16840v1 Announce Type: new 
Abstract: Rapid evolution of sensors and resource-efficient machine learning models have spurred the widespread adoption of wearable fitness tracking devices. Equipped with inertial sensors, such devices can continuously capture physical movements for fitness technology (FitTech), enabling applications from sports optimization to preventive healthcare. Traditional centralized learning approaches to detect fitness activities struggle with privacy concerns, regulatory constraints, and communication inefficiencies. In contrast, Federated Learning (FL) enables a decentralized model training by communicating model updates rather than private wearable sensor data. Applying FL to FitTech presents unique challenges, such as data imbalance, lack of labelled data, heterogeneous user activity patterns, and trade-offs between personalization and generalization. To simplify research on FitTech in FL, we present the FedFitTech baseline, under the Flower framework, which is publicly available and widely used by both industry and academic researchers. Additionally, to illustrate its usage, this paper presents a case study that implements a system based on the FedFitTech baseline, incorporating a client-side early stopping strategy and comparing the results. For instance, this system allows wearable devices to optimize the trade-off between capturing common fitness activity patterns and preserving individuals' nuances, thereby enhancing both the scalability and efficiency of privacy-aware fitness tracking applications. Results show that this reduces overall redundant communications by 13 percent, while maintaining the overall recognition performance at a negligible recognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation for a wide range of new research and development opportunities in FitTech, and it is available as open-source at: https://github.com/adap/flower/tree/main/baselines/fedfittech
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation</title>
<link>https://arxiv.org/abs/2506.16636</link>
<guid>https://arxiv.org/abs/2506.16636</guid>
<content:encoded><![CDATA[
arXiv:2506.16636v1 Announce Type: cross 
Abstract: Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/\sqrt{n}$ rate when approximating the true data distribution.
  To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles.
  Our procedure satisfies local $(\epsilon, \delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competing Bandits in Decentralized Contextual Matching Markets</title>
<link>https://arxiv.org/abs/2411.11794</link>
<guid>https://arxiv.org/abs/2411.11794</guid>
<content:encoded><![CDATA[
arXiv:2411.11794v2 Announce Type: replace 
Abstract: Sequential learning in a multi-agent resource constrained matching market has received significant interest in the past few years. We study decentralized learning in two-sided matching markets where the demand side (aka players or agents) competes for the supply side (aka arms) with potentially time-varying preferences to obtain a stable match. Motivated by the linear contextual bandit framework, we assume that for each agent, an arm-mean may be represented by a linear function of a known feature vector and an unknown (agent-specific) parameter. Moreover, the preferences over arms depend on a latent environment in each round, where the latent environment varies across rounds in a non-stationary manner. We propose learning algorithms to identify the latent environment and obtain stable matchings simultaneously. Our proposed algorithms achieve instance-dependent logarithmic regret, scaling independently of the number of arms, and hence applicable for a large market.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models</title>
<link>https://arxiv.org/abs/2506.14824</link>
<guid>https://arxiv.org/abs/2506.14824</guid>
<content:encoded><![CDATA[
arXiv:2506.14824v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) excel in tasks like multimodal reasoning and cross-modal retrieval but face deployment challenges in real-world scenarios due to distributed multimodal data and strict privacy requirements. Federated Learning (FL) offers a solution by enabling collaborative model training without centralizing data. However, realizing FL for MLLMs presents significant challenges, including high computational demands, limited client capacity, substantial communication costs, and heterogeneous client data. Existing FL methods assume client-side deployment of full models, an assumption that breaks down for large-scale MLLMs due to their massive size and communication demands. To address these limitations, we propose FedNano, the first FL framework that centralizes the LLM on the server while introducing NanoEdge, a lightweight module for client-specific adaptation. NanoEdge employs modality-specific encoders, connectors, and trainable NanoAdapters with low-rank adaptation. This design eliminates the need to deploy LLM on clients, reducing client-side storage by 95%, and limiting communication overhead to only 0.01% of the model parameters. By transmitting only compact NanoAdapter updates, FedNano handles heterogeneous client data and resource constraints while preserving privacy. Experiments demonstrate that FedNano outperforms prior FL baselines, bridging the gap between MLLM scale and FL feasibility, and enabling scalable, decentralized multimodal AI systems.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Explain First, Trust Later: LLM-Augmented Explanations for Graph-Based Crypto Anomaly Detection</title>
<link>https://arxiv.org/abs/2506.14933</link>
<guid>https://arxiv.org/abs/2506.14933</guid>
<content:encoded><![CDATA[
arXiv:2506.14933v1 Announce Type: new 
Abstract: The decentralized finance (DeFi) community has grown rapidly in recent years, pushed forward by cryptocurrency enthusiasts interested in the vast untapped potential of new markets. The surge in popularity of cryptocurrency has ushered in a new era of financial crime. Unfortunately, the novelty of the technology makes the task of catching and prosecuting offenders particularly challenging. Thus, it is necessary to implement automated detection tools related to policies to address the growing criminality in the cryptocurrency realm.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ImprovDML: Improved Trade-off in Private Byzantine-Resilient Distributed Machine Learning</title>
<link>https://arxiv.org/abs/2506.15181</link>
<guid>https://arxiv.org/abs/2506.15181</guid>
<content:encoded><![CDATA[
arXiv:2506.15181v1 Announce Type: new 
Abstract: Jointly addressing Byzantine attacks and privacy leakage in distributed machine learning (DML) has become an important issue. A common strategy involves integrating Byzantine-resilient aggregation rules with differential privacy mechanisms. However, the incorporation of these techniques often results in a significant degradation in model accuracy. To address this issue, we propose a decentralized DML framework, named ImprovDML, that achieves high model accuracy while simultaneously ensuring privacy preservation and resilience to Byzantine attacks. The framework leverages a kind of resilient vector consensus algorithms that can compute a point within the normal (non-Byzantine) agents' convex hull for resilient aggregation at each iteration. Then, multivariate Gaussian noises are introduced to the gradients for privacy preservation. We provide convergence guarantees and derive asymptotic learning error bounds under non-convex settings, which are tighter than those reported in existing works. For the privacy analysis, we adopt the notion of concentrated geo-privacy, which quantifies privacy preservation based on the Euclidean distance between inputs. We demonstrate that it enables an improved trade-off between privacy preservation and model accuracy compared to differential privacy. Finally, numerical simulations validate our theoretical results.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>You Only Render Once: Enhancing Energy and Computation Efficiency of Mobile Virtual Reality</title>
<link>https://arxiv.org/abs/2506.15183</link>
<guid>https://arxiv.org/abs/2506.15183</guid>
<content:encoded><![CDATA[
arXiv:2506.15183v1 Announce Type: new 
Abstract: Mobile Virtual Reality (VR) is essential to achieving convenient and immersive human-computer interaction and realizing emerging applications such as Metaverse. However, existing VR technologies require two separate renderings of binocular images, causing a significant bottleneck for mobile devices with limited computing capability and power supply. This paper proposes an approach to rendering optimization for mobile VR called EffVR. By utilizing the per-pixel attribute, EffVR can generate binocular VR images from the monocular image through genuinely one rendering, saving half the computation over conventional approaches. Our evaluation indicates that, compared with the state-of-art, EffVRcan save 27% power consumption on average while achieving high binocular image quality (0.9679 SSIM and 34.09 PSNR) in mobile VR applications. Additionally, EffVR can increase the frame rate by 115.2%. These results corroborate EffVRsuperior computation/energy-saving performance, paving the road to a sustainable mobile VR. The source code, demo video, android app, and more are released anonymously at https://yoro-vr.github.io/
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>All is Not Lost: LLM Recovery without Checkpoints</title>
<link>https://arxiv.org/abs/2506.15461</link>
<guid>https://arxiv.org/abs/2506.15461</guid>
<content:encoded><![CDATA[
arXiv:2506.15461v1 Announce Type: new 
Abstract: Training LLMs on decentralized and wimpy computation nodes, e.g., multiple on-spot instances, lowers the training cost and enables model democratization. The inevitable challenge here is the churn of nodes due to failures and the operator's scheduling policies, leading to losing a stage - a part of the model. The conventional approaches to recover from failures are to either use checkpointing, where periodically a copy of the entire model is sent to an additional storage, or redundant computation. These approaches yield significant communication and/or computation overhead even in non-failure cases and scale poorly in settings with large models. In this paper, we propose, CheckFree, an efficient recovery method where a failing stage is substituted by a weighted average of the closest neighboring stages. In contrast to the state of the art, CheckFree requires no additional computation or storage. However, because of the nature of averaging neighbouring stages, it can only recover failures of intermediate stages. We further extend our method to CheckFree+ with out-of-order pipeline execution to tolerate crashes of the first and last stages. Thanks to out-of-order pipelining, behaviour of those stages is mimicked by their neighboring ones, which allows CheckFree+ to recover them by simply copying the weights from the immediate neighbour. To be able to recover the (de)embedding layers, CheckFree+ copies those layers to the neighboring stages, which requires relatively small storage overhead. We extensively evaluate our method on LLaMa models of model sizes from 124M to 1.5B with varying failure frequencies. In the case of low and medium failure rates (5-10%), CheckFree and CheckFree+ outperform both checkpointing and redundant computation in terms of convergence in wall-clock time by over 12%. Both of our proposals can be run via our code available at: https://github.com/gensyn-ai/CheckFree.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI</title>
<link>https://arxiv.org/abs/2506.15468</link>
<guid>https://arxiv.org/abs/2506.15468</guid>
<content:encoded><![CDATA[
arXiv:2506.15468v1 Announce Type: new 
Abstract: We propose co-creative learning as a novel paradigm where humans and AI, i.e., biological and artificial agents, mutually integrate their partial perceptual information and knowledge to construct shared external representations, a process we interpret as symbol emergence. Unlike traditional AI teaching based on unilateral knowledge transfer, this addresses the challenge of integrating information from inherently different modalities. We empirically test this framework using a human-AI interaction model based on the Metropolis-Hastings naming game (MHNG), a decentralized Bayesian inference mechanism. In an online experiment, 69 participants played a joint attention naming game (JA-NG) with one of three computer agent types (MH-based, always-accept, or always-reject) under partial observability. Results show that human-AI pairs with an MH-based agent significantly improved categorization accuracy through interaction and achieved stronger convergence toward a shared sign system. Furthermore, human acceptance behavior aligned closely with the MH-derived acceptance probability. These findings provide the first empirical evidence for co-creative learning emerging in human-AI dyads via MHNG-based interaction. This suggests a promising path toward symbiotic AI systems that learn with humans, rather than from them, by dynamically aligning perceptual experiences, opening a new venue for symbiotic AI alignment.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Variational Information Bottleneck for Data Extraction Based on Mutual Information in Internet of Vehicles</title>
<link>https://arxiv.org/abs/2409.17287</link>
<guid>https://arxiv.org/abs/2409.17287</guid>
<content:encoded><![CDATA[
arXiv:2409.17287v2 Announce Type: replace 
Abstract: The Internet of Vehicles (IoV) network can address the issue of limited computing resources and data processing capabilities of individual vehicles, but it also brings the risk of privacy leakage to vehicle users. Applying blockchain technology can establish secure data links within the IoV, solving the problems of insufficient computing resources for each vehicle and the security of data transmission over the network. However, with the development of the IoV, the amount of data interaction between multiple vehicles and between vehicles and base stations, roadside units, etc., is continuously increasing. There is a need to further reduce the interaction volume, and intelligent data compression is key to solving this problem. The VIB technique facilitates the training of encoding and decoding models, substantially diminishing the volume of data that needs to be transmitted. This paper introduces an innovative approach that integrates blockchain with VIB, referred to as BVIB, designed to lighten computational workloads and reinforce the security of the network. We first construct a new network framework by separating the encoding and decoding networks to address the computational burden issue, and then propose a new algorithm to enhance the security of IoV networks. We also discuss the impact of the data extraction rate on system latency to determine the most suitable data extraction rate. An experimental framework combining Python and C++ has been established to substantiate the efficacy of our BVIB approach. Comprehensive simulation studies indicate that the BVIB consistently excels in comparison to alternative foundational methodologies.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>YOLO-MARL: You Only LLM Once for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.03997</link>
<guid>https://arxiv.org/abs/2410.03997</guid>
<content:encoded><![CDATA[
arXiv:2410.03997v2 Announce Type: replace 
Abstract: Advancements in deep multi-agent reinforcement learning (MARL) have positioned it as a promising approach for decision-making in cooperative games. However, it still remains challenging for MARL agents to learn cooperative strategies for some game environments. Recently, large language models (LLMs) have demonstrated emergent reasoning capabilities, making them promising candidates for enhancing coordination among the agents. However, due to the model size of LLMs, it can be expensive to frequently infer LLMs for actions that agents can take. In this work, we propose You Only LLM Once for MARL (YOLO-MARL), a novel framework that leverages the high-level task planning capabilities of LLMs to improve the policy learning process of multi-agents in cooperative games. Notably, for each game environment, YOLO-MARL only requires one time interaction with LLMs in the proposed strategy generation, state interpretation and planning function generation modules, before the MARL policy training process. This avoids the ongoing costs and computational time associated with frequent LLMs API calls during training. Moreover, trained decentralized policies based on normal-sized neural networks operate independently of the LLM. We evaluate our method across two different environments and demonstrate that YOLO-MARL outperforms traditional MARL algorithms.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-Chain Arbitrage: The Next Frontier of MEV in Decentralized Finance</title>
<link>https://arxiv.org/abs/2501.17335</link>
<guid>https://arxiv.org/abs/2501.17335</guid>
<content:encoded><![CDATA[
arXiv:2501.17335v2 Announce Type: replace 
Abstract: Decentralized finance (DeFi) markets spread across Layer-1 (L1) and Layer-2 (L2) blockchains rely on arbitrage to keep prices aligned. Today most price gaps are closed against centralized exchanges (CEXes), whose deep liquidity and fast execution make them the primary venue for price discovery. As trading volume migrates on-chain, cross-chain arbitrage between decentralized exchanges (DEXes) will become the canonical mechanism for price alignment. Yet, despite its importance to DeFi-and the on-chain transparency making real activity tractable in a way CEX-to-DEX arbitrage is not-existing research remains confined to conceptual overviews and hypothetical opportunity analyses.
  We study cross-chain arbitrage with a profit-cost model and a year-long measurement. The model shows that opportunity frequency, bridging time, and token depreciation determine whether inventory- or bridge-based execution is more profitable. Empirically, we analyze one year of transactions (September 2023 - August 2024) across nine blockchains and identify 242,535 executed arbitrages totaling 868.64 million USD volume. Activity clusters on Ethereum-centric L1-L2 pairs, grows 5.5x over the study period, and surges-higher volume, more trades, lower fees-after the Dencun upgrade (March 13, 2024). Most trades use pre-positioned inventory (66.96%) and settle in 9s, whereas bridge-based arbitrages take 242s, underscoring the latency cost of today's bridges. Market concentration is high: the five largest addresses execute more than half of all trades, and one alone captures almost 40% of daily volume post-Dencun. We conclude that cross-chain arbitrage fosters vertical integration, centralizing sequencing infrastructure and economic power and thereby exacerbating censorship, liveness, and finality risks; decentralizing block building and lowering entry barriers are critical to countering these threats.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study</title>
<link>https://arxiv.org/abs/2506.13836</link>
<guid>https://arxiv.org/abs/2506.13836</guid>
<content:encoded><![CDATA[
arXiv:2506.13836v1 Announce Type: new 
Abstract: Reinforcement learning-based traffic signal control (RL-TSC) has emerged as a promising approach for improving urban mobility. However, its robustness under real-world disruptions such as traffic incidents remains largely underexplored. In this study, we introduce T-REX, an open-source, SUMO-based simulation framework for training and evaluating RL-TSC methods under dynamic, incident scenarios. T-REX models realistic network-level performance considering drivers' probabilistic rerouting, speed adaptation, and contextual lane-changing, enabling the simulation of congestion propagation under incidents. To assess robustness, we propose a suite of metrics that extend beyond conventional traffic efficiency measures. Through extensive experiments across synthetic and real-world networks, we showcase T-REX for the evaluation of several state-of-the-art RL-TSC methods under multiple real-world deployment paradigms. Our findings show that while independent value-based and decentralized pressure-based methods offer fast convergence and generalization in stable traffic conditions and homogeneous networks, their performance degrades sharply under incident-driven distribution shifts. In contrast, hierarchical coordination methods tend to offer more stable and adaptable performance in large-scale, irregular networks, benefiting from their structured decision-making architecture. However, this comes with the trade-off of slower convergence and higher training complexity. These findings highlight the need for robustness-aware design and evaluation in RL-TSC research. T-REX contributes to this effort by providing an open, standardized and reproducible platform for benchmarking RL methods under dynamic and disruptive traffic scenarios.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing System Latency for Blockchain-Encrypted Edge Computing in Internet of Vehicles</title>
<link>https://arxiv.org/abs/2506.14208</link>
<guid>https://arxiv.org/abs/2506.14208</guid>
<content:encoded><![CDATA[
arXiv:2506.14208v1 Announce Type: new 
Abstract: As Internet of Vehicles (IoV) technology continues to advance, edge computing has become an important tool for assisting vehicles in handling complex tasks. However, the process of offloading tasks to edge servers may expose vehicles to malicious external attacks, resulting in information loss or even tampering, thereby creating serious security vulnerabilities. Blockchain technology can maintain a shared ledger among servers. In the Raft consensus mechanism, as long as more than half of the nodes remain operational, the system will not collapse, effectively maintaining the system's robustness and security. To protect vehicle information, we propose a security framework that integrates the Raft consensus mechanism from blockchain technology with edge computing. To address the additional latency introduced by blockchain, we derived a theoretical formula for system delay and proposed a convex optimization solution to minimize the system latency, ensuring that the system meets the requirements for low latency and high reliability. Simulation results demonstrate that the optimized data extraction rate significantly reduces system delay, with relatively stable variations in latency. Moreover, the proposed optimization solution based on this model can provide valuable insights for enhancing security and efficiency in future network environments, such as 5G and next-generation smart city systems.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Indicator for Quantifying and Minimizing Information Utility Loss of Robot Teams</title>
<link>https://arxiv.org/abs/2506.14237</link>
<guid>https://arxiv.org/abs/2506.14237</guid>
<content:encoded><![CDATA[
arXiv:2506.14237v1 Announce Type: new 
Abstract: The timely exchange of information among robots within a team is vital, but it can be constrained by limited wireless capacity. The inability to deliver information promptly can result in estimation errors that impact collaborative efforts among robots. In this paper, we propose a new metric termed Loss of Information Utility (LoIU) to quantify the freshness and utility of information critical for cooperation. The metric enables robots to prioritize information transmissions within bandwidth constraints. We also propose the estimation of LoIU using belief distributions and accordingly optimize both transmission schedule and resource allocation strategy for device-to-device transmissions to minimize the time-average LoIU within a robot team. A semi-decentralized Multi-Agent Deep Deterministic Policy Gradient framework is developed, where each robot functions as an actor responsible for scheduling transmissions among its collaborators while a central critic periodically evaluates and refines the actors in response to mobility and interference. Simulations validate the effectiveness of our approach, demonstrating an enhancement of information freshness and utility by 98%, compared to alternative methods.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control</title>
<link>https://arxiv.org/abs/2506.14391</link>
<guid>https://arxiv.org/abs/2506.14391</guid>
<content:encoded><![CDATA[
arXiv:2506.14391v1 Announce Type: new 
Abstract: Efficient traffic signal control (TSC) is essential for mitigating urban congestion, yet existing reinforcement learning (RL) methods face challenges in scaling to large networks while maintaining global coordination. Centralized RL suffers from scalability issues, while decentralized approaches often lack unified objectives, resulting in limited network-level efficiency. In this paper, we propose HiLight, a hierarchical reinforcement learning framework with global adversarial guidance for large-scale TSC. HiLight consists of a high-level Meta-Policy, which partitions the traffic network into subregions and generates sub-goals using a Transformer-LSTM architecture, and a low-level Sub-Policy, which controls individual intersections with global awareness. To improve the alignment between global planning and local execution, we introduce an adversarial training mechanism, where the Meta-Policy generates challenging yet informative sub-goals, and the Sub-Policy learns to surpass these targets, leading to more effective coordination. We evaluate HiLight across both synthetic and real-world benchmarks, and additionally construct a large-scale Manhattan network with diverse traffic conditions, including peak transitions, adverse weather, and holiday surges. Experimental results show that HiLight exhibits significant advantages in large-scale scenarios and remains competitive across standard benchmarks of varying sizes.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Consensus Power Inequality: A Comparative Study of Blockchain Networks</title>
<link>https://arxiv.org/abs/2506.14393</link>
<guid>https://arxiv.org/abs/2506.14393</guid>
<content:encoded><![CDATA[
arXiv:2506.14393v1 Announce Type: new 
Abstract: The distribution of consensus power is a cornerstone of decentralisation, influencing the security, resilience, and fairness of blockchain networks while ensuring equitable impact among participants. This study provides a rigorous evaluation of consensus power inequality across five prominent blockchain networks - Bitcoin, Ethereum, Cardano, Hedera, and Algorand - using data collected from January 2022 to July 2024. Leveraging established economic metrics, including the Gini coefficient and Theil index, the research quantitatively assesses how power is distributed among blockchain network participants. A robust dataset, capturing network-specific characteristics such as mining pools, staking patterns, and consensus nodes, forms the foundation of the analysis, enabling meaningful comparisons across diverse architectures. Through an in-depth comparative study, the paper identifies key disparities in consensus power distribution. Hedera and Bitcoin demonstrate more balanced power distribution, aligning closely with the principles of decentralisation. Ethereum and Cardano demonstrate moderate levels of inequality. However, contrary to expectations, Ethereum has become more concentrated following its transition to Proof-of-Stake. Meanwhile, Algorand shows a pronounced centralisation of power. Moreover, the findings highlight the structural and operational drivers of inequality, including economic barriers, governance models, and network effects, offering actionable insights for more equitable network design. This study establishes a methodological framework for evaluating blockchain consensus power inequality, emphasising the importance of targeted strategies to ensure fairer power distribution and enhancing the sustainability of decentralised systems. Future research will build on these findings by integrating additional metrics and examining the influence of emerging consensus mechanisms.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Network-Independent Incremental Passivity Conditions for Grid-Forming Inverter Control</title>
<link>https://arxiv.org/abs/2506.14469</link>
<guid>https://arxiv.org/abs/2506.14469</guid>
<content:encoded><![CDATA[
arXiv:2506.14469v1 Announce Type: new 
Abstract: Grid-forming inverters control the power transfer between the AC and DC sides of an electrical grid while maintaining the frequency and voltage of the AC side. This paper focuses on ensuring large-signal stability of an electrical grid with inverter-interfaced renewable sources. We prove that the Hybrid-Angle Control (HAC) scheme for grid-forming inverters can exhibit incremental passivity properties between current and voltage at both the AC and DC ports. This incremental passivity can be certified through decentralized conditions. Inverters operating under HAC can, therefore, be connected to other passive elements (e.g. transmission lines) with an immediate guarantee of global transient stability regardless of the network topology or parameters. Passivity of Hybrid Angle Control is also preserved under small-signal (linearized) analyses, in contrast to conventional proportional droop laws that are passivity-short at low frequencies. Passivity and interconnected-stability properties are demonstrated through an example case study.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?</title>
<link>https://arxiv.org/abs/2506.14496</link>
<guid>https://arxiv.org/abs/2506.14496</guid>
<content:encoded><![CDATA[
arXiv:2506.14496v1 Announce Type: new 
Abstract: Swarm intelligence traditionally refers to systems of simple, decentralized agents whose local interactions lead to emergent, collective behavior. Recently, the term 'swarm' has been extended to describe AI systems like OpenAI's Swarm, where large language models (LLMs) act as collaborative agents. This paper contrasts traditional swarm algorithms with LLM-driven swarms exploring how decentralization, scalability, and emergence are redefined in modern artificial intelligence (AI). We implement and compare both paradigms using Boids and Ant Colony Optimization (ACO), evaluating latency, resource usage, and behavioral accuracy. The suitability of both cloud-based and local LLMs is assessed for the agent-based use in swarms. Although LLMs offer powerful reasoning and abstraction capabilities, they introduce new constraints in computation and coordination that challenge traditional notions of swarm design. This study highlights the opportunities and limitations of integrating LLMs into swarm systems and discusses the evolving definition of 'swarm' in modern AI research.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimistic MEV in Ethereum Layer 2s: Why Blockspace Is Always in Demand</title>
<link>https://arxiv.org/abs/2506.14768</link>
<guid>https://arxiv.org/abs/2506.14768</guid>
<content:encoded><![CDATA[
arXiv:2506.14768v1 Announce Type: new 
Abstract: Layer 2 rollups are rapidly absorbing DeFi activity, securing over $40 billion and accounting for nearly half of Ethereum's DEX volume by Q1 2025, yet their MEV dynamics remain understudied. We address this gap by defining and quantifying optimistic MEV, a form of speculative, on-chain cyclic arbitrage whose detection and execution logic reside largely on-chain in smart contracts. As a result of their speculative nature and lack of off-chain opportunity verification, optimistic MEV transactions frequently fail to execute a profitable arbitrage.
  Applying our multi-stage identification pipeline to Arbitrum, Base, and Optimism, we find that in Q1 2025, optimistic MEV accounts for over 50% of on-chain gas on Base and Optimism and 7% on Arbitrum, driven mainly by "interaction" probes (on-chain computations searching for arbitrage). This speculative probing keeps blocks on Base and Optimism persistently full. Despite consuming over half of on-chain gas, optimistic MEV transactions pay less than one quarter of total gas fees. Cross-network comparison reveals divergent success rates, differing patterns of code reuse, and sensitivity to varying sequencer ordering and block production times. Finally, OLS regressions link optimistic MEV trade count to ETH volatility, retail trading activity, and DEX aggregator usage, showing how Layer 2 protocol parameters uniquely encourage speculative MEV.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature</title>
<link>https://arxiv.org/abs/2308.12420</link>
<guid>https://arxiv.org/abs/2308.12420</guid>
<content:encoded><![CDATA[
arXiv:2308.12420v4 Announce Type: replace 
Abstract: Distributed Ledger Technology (DLT) faces increasing environmental scrutiny, particularly concerning the energy consumption of the Proof of Work (PoW) consensus mechanism and broader Environmental, Social, and Governance (ESG) issues. However, existing systematic literature reviews of DLT rely on limited analyses of citations, abstracts, and keywords, failing to fully capture the field's complexity and ESG concerns. We address these challenges by analyzing the full text of 24,539 publications using Natural Language Processing (NLP) with our manually labeled Named Entity Recognition (NER) dataset of 39,427 entities for DLT. This methodology identified 505 key publications at the DLT/ESG intersection, enabling comprehensive domain analysis. Our combined NLP and temporal graph analysis reveals critical trends in DLT evolution and ESG impacts, including cryptography and peer-to-peer networks research's foundational influence, Bitcoin's persistent impact on research and environmental concerns (a "Lindy effect"), Ethereum's catalytic role on Proof of Stake (PoS) and smart contract adoption, and the industry's progressive shift toward energy-efficient consensus mechanisms. Our contributions include the first DLT-specific NER dataset addressing the scarcity of high-quality labeled NLP data in blockchain research, a methodology integrating NLP and temporal graph analysis for large-scale interdisciplinary literature reviews, and the first NLP-driven literature review focusing on DLT's ESG aspects.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Data to Control: A Formal Compositional Framework for Large-Scale Interconnected Networks</title>
<link>https://arxiv.org/abs/2409.12469</link>
<guid>https://arxiv.org/abs/2409.12469</guid>
<content:encoded><![CDATA[
arXiv:2409.12469v2 Announce Type: replace 
Abstract: We introduce a compositional data-driven methodology with noisy data for designing fully-decentralized safety controllers applicable to large-scale interconnected networks, encompassing a vast number of subsystems with unknown mathematical models. Our compositional scheme leverages the interconnection topology and breaks down the network analysis into the examination of distinct subsystems. This is accompanied by utilizing a concept of control storage certificates (CSCs) to capture joint dissipativity-type properties among subsystems. These CSCs are instrumental in a compositional derivation of a control barrier certificate (CBC) specialized for the interconnected network, thereby ensuring its safety. In our data-driven scheme, we gather only a single noise-corrupted input-state trajectory from each unknown subsystem within a specified time frame. By fulfilling a specific rank condition, this process facilitates the construction of a CSC for each subsystem. Following this, by adhering to compositional dissipativity reasoning, we compose CSCs derived from noisy data and build a CBC for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We demonstrate that our compositional data-driven approach significantly enhances the design of a CBC and its robust safety controller under noisy data across the interconnected network. This advancement is achieved by reducing the computational complexity from a polynomial growth in relation to network dimension, when using sum-of-squares (SOS) optimization, to a linear scale based on the number of subsystems. We apply our data-driven findings to a variety of benchmarks, involving physical networks with unknown models and diverse interconnection topologies.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Federated Learning using Remote Embeddings for Graph Neural Networks</title>
<link>https://arxiv.org/abs/2506.12425</link>
<guid>https://arxiv.org/abs/2506.12425</guid>
<content:encoded><![CDATA[
arXiv:2506.12425v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) have experienced rapid advancements in recent years due to their ability to learn meaningful representations from graph data structures. Federated Learning (FL) has emerged as a viable machine learning approach for training a shared model on decentralized data, addressing privacy concerns while leveraging parallelism. Existing methods that address the unique requirements of federated GNN training using remote embeddings to enhance convergence accuracy are limited by their diminished performance due to large communication costs with a shared embedding server. In this paper, we present OpES, an optimized federated GNN training framework that uses remote neighbourhood pruning, and overlaps pushing of embeddings to the server with local training to reduce the network costs and training time. The modest drop in per-round accuracy due to pre-emptive push of embeddings is out-stripped by the reduction in per-round training time for large and dense graphs like Reddit and Products, converging up to $\approx2\times$ faster than the state-of-the-art technique using an embedding server and giving up to $20\%$ better accuracy than vanilla federated GNN learning.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real-Time Agile Software Management for Edge and Fog Computing Based Smart City Infrastructure</title>
<link>https://arxiv.org/abs/2506.12616</link>
<guid>https://arxiv.org/abs/2506.12616</guid>
<content:encoded><![CDATA[
arXiv:2506.12616v1 Announce Type: new 
Abstract: The evolution of smart cities demands scalable, secure, and energy-efficient architectures for real-time data processing. With the number of IoT devices expected to exceed 40 billion by 2030, traditional cloud-based systems are increasingly constrained by bandwidth, latency, and energy limitations. This paper leverages the ROOF (Real-time Onsite Operations Facilitation) framework with decentralized computing at intermediary fog and peripheral edge network layers to reduce latency by processing data near its point of origin. ROOF features fog caching to avoid redundancy, ultra-low-power wireless transmission for energy savings, and AI-driven resource allocation for efficiency. Security is enhanced through TLS encryption, blockchain-based authentication, and edge-level access control. Case studies from Bhubaneswar, Barcelona and Copenhagen validate the use of ROOF in traffic systems and environmental monitoring. The paper concludes by outlining key challenges and prospects of AI-driven analytics in smart urban infrastructure.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Decision Making in Two Sided Manufacturing-as-a-Service Marketplaces</title>
<link>https://arxiv.org/abs/2506.12730</link>
<guid>https://arxiv.org/abs/2506.12730</guid>
<content:encoded><![CDATA[
arXiv:2506.12730v1 Announce Type: new 
Abstract: Advancements in digitization have enabled two sided manufacturing-as-a-service (MaaS) marketplaces which has significantly reduced product development time for designers. These platforms provide designers with access to manufacturing resources through a network of suppliers and have instant order placement capabilities. Two key decision making levers are typically used to optimize the operations of these marketplaces: pricing and matching. The existing marketplaces operate in a centralized structure where they have complete control over decision making. However, a decentralized organization of the platform enables transparency of information across clients and suppliers. This dissertation focuses on developing tools for decision making enabling decentralization in MaaS marketplaces. In pricing mechanisms, a data driven method is introduced which enables small service providers to price services based on specific attributes of the services offered. A data mining method recommends a network based price to a supplier based on its attributes and the attributes of other suppliers on the platform. Three different approaches are considered for matching mechanisms. First, a reverse auction mechanism is introduced where designers bid for manufacturing services and the mechanism chooses a supplier which can match the bid requirements and stated price. The second approach uses mechanism design and mathematical programming to develop a stable matching mechanism for matching orders to suppliers based on their preferences. Empirical simulations are used to test the mechanisms in a simulated 3D printing marketplace and to evaluate the impact of stability on its performance. The third approach considers the matching problem in a dynamic and stochastic environment where demand (orders) and supply (supplier capacities) arrive over time and matching is performed online.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IDOL: Improved Different Optimization Levels Testing for Solidity Compilers</title>
<link>https://arxiv.org/abs/2506.12760</link>
<guid>https://arxiv.org/abs/2506.12760</guid>
<content:encoded><![CDATA[
arXiv:2506.12760v1 Announce Type: new 
Abstract: As blockchain technology continues to evolve and mature, smart contracts have become a key driving force behind the digitization and automation of transactions. Smart contracts greatly simplify and refine the traditional business transaction processes, and thus have had a profound impact on various industries such as finance and supply chain management. However, because smart contracts cannot be modified once deployed, any vulnerabilities or design flaws within the contract cannot be easily fixed, potentially leading to significant financial losses or even legal issues. The compiler, as a critical component in the development process, directly affects the quality and security of smart contracts. This paper innovatively proposes a method, known as the Improved Different Optimization Levels (IDOL), for testing the Solidity compiler. The key idea behind IDOL is to perform reverse optimization transformations (i.e., change optimized form into unoptimized form) to generate semantically equivalent variants of the smart contracts under test, aiming to maximize the opportunities to trigger the optimization logic of compilers. We conducted a preliminary evaluation of IDOL and three confirmed compiler optimization bugs have been uncovered at the time of writing.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Federated Learning against Malicious Clients Based on Verifiable Functional Encryption</title>
<link>https://arxiv.org/abs/2506.12846</link>
<guid>https://arxiv.org/abs/2506.12846</guid>
<content:encoded><![CDATA[
arXiv:2506.12846v1 Announce Type: new 
Abstract: Federated learning is a promising distributed learning paradigm that enables collaborative model training without exposing local client data, thereby protect data privacy. However, it also brings new threats and challenges. The advancement of model inversion attacks has rendered the plaintext transmission of local models insecure, while the distributed nature of federated learning makes it particularly vulnerable to attacks raised by malicious clients. To protect data privacy and prevent malicious client attacks, this paper proposes a privacy-preserving federated learning framework based on verifiable functional encryption, without a non-colluding dual-server setup or additional trusted third-party. Specifically, we propose a novel decentralized verifiable functional encryption (DVFE) scheme that enables the verification of specific relationships over multi-dimensional ciphertexts. This scheme is formally treated, in terms of definition, security model and security proof. Furthermore, based on the proposed DVFE scheme, we design a privacy-preserving federated learning framework VFEFL that incorporates a novel robust aggregation rule to detect malicious clients, enabling the effective training of high-accuracy models under adversarial settings. Finally, we provide formal analysis and empirical evaluation of the proposed schemes. The results demonstrate that our approach achieves the desired privacy protection, robustness, verifiability and fidelity, while eliminating the reliance on non-colluding dual-server settings or trusted third parties required by existing methods.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Stabilizing Replicated State Machine Coping with Byzantine and Recurring Transient Faults</title>
<link>https://arxiv.org/abs/2506.12900</link>
<guid>https://arxiv.org/abs/2506.12900</guid>
<content:encoded><![CDATA[
arXiv:2506.12900v1 Announce Type: new 
Abstract: The ability to perform repeated Byzantine agreement lies at the heart of important applications such as blockchain price oracles or replicated state machines. Any such protocol requires the following properties: (1) \textit{Byzantine fault-tolerance}, because not all participants can be assumed to be honest, (2) r\textit{ecurrent transient fault-tolerance}, because even honest participants may be subject to transient ``glitches'', (3) \textit{accuracy}, because the results of quantitative queries (such as price quotes) must lie within the interval of honest participants' inputs, and (4) \textit{self-stabilization}, because it is infeasible to reboot a distributed system following a fault.
  This paper presents the first protocol for repeated Byzantine agreement that satisfies the properties listed above. Specifically, starting in an arbitrary system configuration, our protocol establishes consistency. It preserves consistency in the face of up to $\lceil n/3 \rceil -1$ Byzantine participants {\em and} constant recurring (``noise'') transient faults, of up to $\lceil n/6 \rceil-1$ additional malicious transient faults, or even more than $\lceil n/6 \rceil-1$ (uniformly distributed) random transient faults, in each repeated Byzantine agreement.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Immutable Memory Systems for Artificial Agents: A Blockchain-Indexed Automata-Theoretic Framework Using ECDH-Keyed Merkle Chains</title>
<link>https://arxiv.org/abs/2506.13246</link>
<guid>https://arxiv.org/abs/2506.13246</guid>
<content:encoded><![CDATA[
arXiv:2506.13246v1 Announce Type: new 
Abstract: This paper presents a formalised architecture for synthetic agents designed to retain immutable memory, verifiable reasoning, and constrained epistemic growth. Traditional AI systems rely on mutable, opaque statistical models prone to epistemic drift and historical revisionism. In contrast, we introduce the concept of the Merkle Automaton, a cryptographically anchored, deterministic computational framework that integrates formal automata theory with blockchain-based commitments. Each agent transition, memory fragment, and reasoning step is committed within a Merkle structure rooted on-chain, rendering it non-repudiable and auditably permanent. To ensure selective access and confidentiality, we derive symmetric encryption keys from ECDH exchanges contextualised by hierarchical privilege lattices. This enforces cryptographic access control over append-only DAG-structured knowledge graphs. Reasoning is constrained by formal logic systems and verified through deterministic traversal of policy-encoded structures. Updates are non-destructive and historied, preserving epistemic lineage without catastrophic forgetting. Zero-knowledge proofs facilitate verifiable, privacy-preserving inclusion attestations. Collectively, this architecture reframes memory not as a cache but as a ledger - one whose contents are enforced by protocol, bound by cryptography, and constrained by formal logic. The result is not an intelligent agent that mimics thought, but an epistemic entity whose outputs are provably derived, temporally anchored, and impervious to post hoc revision. This design lays foundational groundwork for legal, economic, and high-assurance computational systems that require provable memory, unforgeable provenance, and structural truth.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>One-dimensional vs. Multi-dimensional Pricing in Blockchain Protocols</title>
<link>https://arxiv.org/abs/2506.13271</link>
<guid>https://arxiv.org/abs/2506.13271</guid>
<content:encoded><![CDATA[
arXiv:2506.13271v1 Announce Type: new 
Abstract: Blockchain transactions consume diverse resources, foremost among them storage, but also computation, communication, and others. Efficiently charging for these resources is crucial for effective system resource allocation and long-term economic viability. The prevailing approach, one-dimensional pricing, sets a single price for a linear combination of resources. However, this often leads to under-utilization when resource capacities are limited. Multi-dimensional pricing, which independently prices each resource, offers an alternative but presents challenges in price discovery.
  This work focuses on the welfare achieved by these two schemes. We prove that multi-dimensional pricing is superior under stable blockchain conditions. Conversely, we show that one-dimensional pricing outperforms its multi-dimensional counterpart in transient states, exhibiting faster convergence and greater computational tractability. These results highlight a critical trade-off: while multi-dimensional pricing offers efficiency gains at equilibrium, its implementation incurs costs associated with system transitions. Our findings underscore the necessity for a deeper understanding of these transient effects before widespread adoption. Finally, we propose mechanisms that aim to mitigate some of these issues, paving the way for future research.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Rich Get Richer in Bitcoin Mining Induced by Blockchain Forks</title>
<link>https://arxiv.org/abs/2506.13360</link>
<guid>https://arxiv.org/abs/2506.13360</guid>
<content:encoded><![CDATA[
arXiv:2506.13360v1 Announce Type: new 
Abstract: Bitcoin is a representative decentralized currency system. For the security of Bitcoin, fairness in the distribution of mining rewards plays a crucial role in preventing the concentration of computational power in a few miners. Here, fairness refers to the distribution of block rewards in proportion to contributed computational resources. If miners with greater computational resources receive disproportionately higher rewards, i.e., if the Rich Get Richer (TRGR) phenomenon holds in Bitcoin, it indicates a threat to the system's decentralization. This study analyzes TRGR in Bitcoin by focusing on unintentional blockchain forks, an inherent phenomenon in Bitcoin. Previous research has failed to provide generalizable insights due to the low precision of their analytical methods. In contrast, we avoid this problem by adopting a method whose analytical precision has been empirically validated. The primary contribution of this work is a theoretical analysis that clearly demonstrates TRGR in Bitcoin under the assumption of fixed block propagation delays between different miners. More specifically, we show that the mining profit rate depends linearly on the proportion of hashrate. Furthermore, we examine the robustness of this result from multiple perspectives in scenarios where block propagation delays between different miners are not necessarily fixed.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering</title>
<link>https://arxiv.org/abs/2506.13755</link>
<guid>https://arxiv.org/abs/2506.13755</guid>
<content:encoded><![CDATA[
arXiv:2506.13755v1 Announce Type: new 
Abstract: This paper introduces MARCO (Multi-Agent Reinforcement learning with Conformal Optimization), a novel hardware-aware framework for efficient neural architecture search (NAS) targeting resource-constrained edge devices. By significantly reducing search time and maintaining accuracy under strict hardware constraints, MARCO bridges the gap between automated DNN design and CAD for edge AI deployment. MARCO's core technical contribution lies in its unique combination of multi-agent reinforcement learning (MARL) with Conformal Prediction (CP) to accelerate the hardware/software co-design process for deploying deep neural networks. Unlike conventional once-for-all (OFA) supernet approaches that require extensive pretraining, MARCO decomposes the NAS task into a hardware configuration agent (HCA) and a Quantization Agent (QA). The HCA optimizes high-level design parameters, while the QA determines per-layer bit-widths under strict memory and latency budgets using a shared reward signal within a centralized-critic, decentralized-execution (CTDE) paradigm. A key innovation is the integration of a calibrated CP surrogate model that provides statistical guarantees (with a user-defined miscoverage rate) to prune unpromising candidate architectures before incurring the high costs of partial training or hardware simulation. This early filtering drastically reduces the search space while ensuring that high-quality designs are retained with a high probability. Extensive experiments on MNIST, CIFAR-10, and CIFAR-100 demonstrate that MARCO achieves a 3-4x reduction in total search time compared to an OFA baseline while maintaining near-baseline accuracy (within 0.3%). Furthermore, MARCO also reduces inference latency. Validation on a MAX78000 evaluation board confirms that simulator trends hold in practice, with simulator estimates deviating from measured values by less than 5%.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OSI Stack Redesign for Quantum Networks: Requirements, Technologies, Challenges, and Future Directions</title>
<link>https://arxiv.org/abs/2506.12195</link>
<guid>https://arxiv.org/abs/2506.12195</guid>
<content:encoded><![CDATA[
arXiv:2506.12195v1 Announce Type: cross 
Abstract: Quantum communication is poised to become a foundational element of next-generation networking, offering transformative capabilities in security, entanglement-based connectivity, and computational offloading. However, the classical OSI model-designed for deterministic and error-tolerant systems-cannot support quantum-specific phenomena such as coherence fragility, probabilistic entanglement, and the no-cloning theorem. This paper provides a comprehensive survey and proposes an architectural redesign of the OSI model for quantum networks in the context of 7G. We introduce a Quantum-Converged OSI stack by extending the classical model with Layer 0 (Quantum Substrate) and Layer 8 (Cognitive Intent), supporting entanglement, teleportation, and semantic orchestration via LLMs and QML. Each layer is redefined to incorporate quantum mechanisms such as enhanced MAC protocols, fidelity-aware routing, and twin-based applications. This survey consolidates over 150 research works from IEEE, ACM, MDPI, arXiv, and Web of Science (2018-2025), classifying them by OSI layer, enabling technologies such as QKD, QEC, PQC, and RIS, and use cases such as satellite QKD, UAV swarms, and quantum IoT. A taxonomy of cross-layer enablers-such as hybrid quantum-classical control, metadata-driven orchestration, and blockchain-integrated quantum trust-is provided, along with simulation tools including NetSquid, QuNetSim, and QuISP. We present several domain-specific applications, including quantum healthcare telemetry, entangled vehicular networks, and satellite mesh overlays. An evaluation framework is proposed based on entropy throughput, coherence latency, and entanglement fidelity. Key future directions include programmable quantum stacks, digital twins, and AI-defined QNet agents, laying the groundwork for a scalable, intelligent, and quantum-compliant OSI framework for 7G and beyond.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Regret Minimization and Convergence to Equilibria in General-sum Markov Games</title>
<link>https://arxiv.org/abs/2207.14211</link>
<guid>https://arxiv.org/abs/2207.14211</guid>
<content:encoded><![CDATA[
arXiv:2207.14211v3 Announce Type: replace 
Abstract: An abundance of recent impossibility results establish that regret minimization in Markov games with adversarial opponents is both statistically and computationally intractable. Nevertheless, none of these results preclude the possibility of regret minimization under the assumption that all parties adopt the same learning procedure. In this work, we present the first (to our knowledge) algorithm for learning in general-sum Markov games that provides sublinear regret guarantees when executed by all agents. The bounds we obtain are for swap regret, and thus, along the way, imply convergence to a correlated equilibrium. Our algorithm is decentralized, computationally efficient, and does not require any communication between agents. Our key observation is that online learning via policy optimization in Markov games essentially reduces to a form of weighted regret minimization, with unknown weights determined by the path length of the agents' policy sequence. Consequently, controlling the path length leads to weighted regret objectives for which sufficiently adaptive algorithms provide sublinear regret guarantees.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain and Biometrics: Survey, GDPR Elements, and Future Directions</title>
<link>https://arxiv.org/abs/2302.10883</link>
<guid>https://arxiv.org/abs/2302.10883</guid>
<content:encoded><![CDATA[
arXiv:2302.10883v3 Announce Type: replace 
Abstract: Biometric recognition as an efficient and hard-to-forge way of identification and verification has become an indispensable part of the current digital world. The fast evolution of this technology has been a strong incentive for integration into many applications. Meanwhile, blockchain, the decentralized ledger technology, has been widely received by both research and industry in the past few years, and it is being increasingly deployed today in many different applications, such as money transfer, IoT, healthcare, or logistics. Recently, researchers have started to speculate on the pros and cons and what the best applications would be when these two technologies cross paths. This paper provides a survey of the research literature on the combination of blockchain and biometrics and includes a first legal analysis of this integration based on GDPR to shed light on challenges and potentials. Although the integration of blockchain technology into the biometric sector is still in its infancy, with a growing body of literature discussing specific applications and advanced technological setups, this paper aims to provide a holistic understanding of blockchain applicability in biometrics. Based on published studies, this article discusses, among others, practical examples combining blockchain and biometrics for novel applications in PKI systems, distributed trusted services, and identity management. Challenges and limitations when combining blockchain and biometrics that motivate future work will also be discussed; e.g., blockchain networks at their current stage may not be efficient or economical for some real-time biometric applications. Finally, we also discuss key legal aspects of the EU General Data Protection Regulation (GDPR) related to this combination of technologies (blockchain and biometrics); for example, accountability, immutability, anonymity, and data protection elements.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A philosophical and ontological perspective on Artificial General Intelligence and the Metaverse</title>
<link>https://arxiv.org/abs/2402.06660</link>
<guid>https://arxiv.org/abs/2402.06660</guid>
<content:encoded><![CDATA[
arXiv:2402.06660v4 Announce Type: replace 
Abstract: This paper leverages various philosophical and ontological frameworks to explore the concept of embodied artificial general intelligence (AGI), its relationship to human consciousness, and the key role of the metaverse in facilitating this relationship. Several theoretical frameworks underpin this exploration, such as embodied cognition, Michael Levin's computational boundary of a "Self," and Donald D. Hoffman's Interface Theory of Perception, which lead to considering human perceived outer reality as a symbolic representation of alternate inner states of being, and where AGI could embody a different form of consciousness with a larger computational boundary. The paper further discusses the necessary architecture for the emergence of an embodied AGI, how to calibrate an AGI's symbolic interface, and the key role played by the Metaverse, decentralized systems and open-source blockchain technology. The paper concludes by emphasizing the importance of achieving a certain degree of harmony in human relations and recognizing the interconnectedness of humanity at a global level, as key prerequisites for the emergence of a stable embodied AGI.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Wireless Federated Learning for Large Language Models</title>
<link>https://arxiv.org/abs/2404.13238</link>
<guid>https://arxiv.org/abs/2404.13238</guid>
<content:encoded><![CDATA[
arXiv:2404.13238v2 Announce Type: replace 
Abstract: Large language models (LLMs) have driven profound transformations in wireless networks. However, within wireless environments, the training of LLMs faces significant challenges related to security and privacy. Federated Learning (FL), with its decentralized architecture, offers enhanced data privacy protection. Nevertheless, when integrated with LLMs, FL still struggles with several critical limitations, including large-scale and heterogeneous data, resource-intensive training, and substantial communication overhead. To address these challenges, this paper first presents a systematic analysis of the distinct training stages of LLMs in wireless networks, including pre-training, instruction tuning, and alignment tuning. Building upon this foundation, we propose a Personalized Wireless Federated Fine-tuning (PWFF) framework. Initially, we utilize the adapter and Low-Rank Adaptation (LoRA) techniques to decrease energy consumption, while employing global partial aggregation to reduce communication delay. Subsequently, we develop two reward models and design a personalized loss function to fulfill the goal of personalized learning. Furthermore, we implement a local multi-objective alignment to ensure the stability and effectiveness of the FL process. Finally, we conduct a series of simulations to validate the performance of the proposed PWFF method and provide an in-depth discussion of the open issues.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Distributed Graph Coloring: Cluster Graphs</title>
<link>https://arxiv.org/abs/2405.07725</link>
<guid>https://arxiv.org/abs/2405.07725</guid>
<content:encoded><![CDATA[
arXiv:2405.07725v2 Announce Type: replace 
Abstract: Graph coloring is fundamental to distributed computing. We give the first sub-logarithmic distributed algorithm for coloring cluster graphs. These graphs are obtained from the underlying communication network by contracting nodes and edges, and they appear frequently as components in the study of distributed algorithms. In particular, we give a $O(\log^* n)$-round algorithm to $(\Delta+1)$-color cluster graphs of at least polylogarithmic degree. The previous best bound known was $\operatorname{poly}(\log n)$ [Flin et al., SODA'24]. This properly generalizes results in the CONGEST model and shows that distributed graph problems can be solved quickly even when the node itself is decentralized.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dimension Reduction via Random Projection for Privacy in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2412.04031</link>
<guid>https://arxiv.org/abs/2412.04031</guid>
<content:encoded><![CDATA[
arXiv:2412.04031v2 Announce Type: replace 
Abstract: The agents in a Multi-Agent System (MAS) make observations about the system and send that information to a fusion center. The fusion center aggregates the information and concludes about the system parameters with as much accuracy as possible. However for the purposes of better efficiency of the system at large, the agents need to append some private parameters to the observed data. In this scenario, the data sent to the fusion center is faced with privacy risks. The data communicated to the fusion center must be secured against data privacy breaches and inference attacks in a decentralized manner. However, this in turn leads to a loss of utility of the data being sent to the fusion center. We quantify the utility and privacy of the system using Cosine similarity. We formulate our MAS problem in terms of deducing a concept for which compression-based methods are there in literature. Next, we propose a novel sanitization mechanism for our MAS using one such compression-based method while addressing the utility-privacy tradeoff problem.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Address Poisoning</title>
<link>https://arxiv.org/abs/2501.16681</link>
<guid>https://arxiv.org/abs/2501.16681</guid>
<content:encoded><![CDATA[
arXiv:2501.16681v2 Announce Type: replace 
Abstract: In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on both Ethereum and BSC. We identify 13~times more attack attempts than reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces</title>
<link>https://arxiv.org/abs/2506.11025</link>
<guid>https://arxiv.org/abs/2506.11025</guid>
<content:encoded><![CDATA[
arXiv:2506.11025v1 Announce Type: new 
Abstract: This paper examines how synthetically generated faces and machine learning-based gender classification algorithms are affected by algorithmic lookism, the preferential treatment based on appearance. In experiments with 13,200 synthetically generated faces, we find that: (1) text-to-image (T2I) systems tend to associate facial attractiveness to unrelated positive traits like intelligence and trustworthiness; and (2) gender classification models exhibit higher error rates on "less-attractive" faces, especially among non-White women. These result raise fairness concerns regarding digital identity systems.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul</title>
<link>https://arxiv.org/abs/2506.11284</link>
<guid>https://arxiv.org/abs/2506.11284</guid>
<content:encoded><![CDATA[
arXiv:2506.11284v1 Announce Type: new 
Abstract: We study the problem of uplink compression for cell-free multi-input multi-output networks with limited fronthaul capacity. In compress-forward mode, remote radio heads (RRHs) compress the received signal and forward it to a central unit for joint processing. While previous work has focused on a transform-based approach, which optimizes the transform matrix that reduces signals of high dimension to a static pre-determined lower dimension, we propose a rate-based approach that simultaneously finds both dimension and compression adaptively. Our approach accommodates for changes to network traffic and fronthaul limits. Using mutual information as the objective, we obtain the theoretical network capacity for adaptive compression and decouple the expression to enable decentralization. Furthermore, using channel statistics and user traffic density, we show different approaches to compute an efficient representation of side information that summarizes global channel state information and is shared with RRHs to assist compression. While keeping the information exchange overhead low, our decentralized implementation of adaptive compression shows competitive overall network performance compared to a centralized approach.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine Outside, Curious Inside: Reconstructing Data Through Malicious Updates</title>
<link>https://arxiv.org/abs/2506.11413</link>
<guid>https://arxiv.org/abs/2506.11413</guid>
<content:encoded><![CDATA[
arXiv:2506.11413v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized machine learning without sharing raw data, allowing multiple clients to collaboratively learn a global model. However, studies reveal that privacy leakage is possible under commonly adopted FL protocols. In particular, a server with access to client gradients can synthesize data resembling the clients' training data. In this paper, we introduce a novel threat model in FL, named the maliciously curious client, where a client manipulates its own gradients with the goal of inferring private data from peers. This attacker uniquely exploits the strength of a Byzantine adversary, traditionally aimed at undermining model robustness, and repurposes it to facilitate data reconstruction attack. We begin by formally defining this novel client-side threat model and providing a theoretical analysis that demonstrates its ability to achieve significant reconstruction success during FL training. To demonstrate its practical impact, we further develop a reconstruction algorithm that combines gradient inversion with malicious update strategies. Our analysis and experimental results reveal a critical blind spot in FL defenses: both server-side robust aggregation and client-side privacy mechanisms may fail against our proposed attack. Surprisingly, standard server- and client-side defenses designed to enhance robustness or privacy may unintentionally amplify data leakage. Compared to the baseline approach, a mistakenly used defense may instead improve the reconstructed image quality by 10-15%.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic</title>
<link>https://arxiv.org/abs/2506.11451</link>
<guid>https://arxiv.org/abs/2506.11451</guid>
<content:encoded><![CDATA[
arXiv:2506.11451v1 Announce Type: new 
Abstract: Blockchain-based software systems are increasingly deployed across diverse domains, yet a systematic understanding of their development challenges remains limited. This paper presents a large-scale empirical study of 497,742 issues mined from 1,209 open-source blockchain projects hosted on GitHub. Employing BERTopic, a transformer-based topic modeling technique, we identify 49 distinct issue topics and organize them hierarchically into 11 major subcategories. Our analysis reveals that both general software development issues and blockchain-specific concerns are nearly equally represented, with Wallet Management and UI Enhancement emerging as the most prominent topics. We further examine the temporal evolution of issue categories and resolution times, finding that Wallet issues not only dominate in frequency but also exhibit the longest resolution time. Conversely, Mechanisms issues are resolved significantly faster. Issue frequency surged after 2016 with the rise of Ethereum and decentralized applications, but declined after 2022. These findings enhance our understanding of blockchain software maintenance, informing the development of specialized tools and practices to improve robustness and maintainability.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learn to Preserve Personality: Federated Foundation Models in Recommendations</title>
<link>https://arxiv.org/abs/2506.11563</link>
<guid>https://arxiv.org/abs/2506.11563</guid>
<content:encoded><![CDATA[
arXiv:2506.11563v1 Announce Type: new 
Abstract: A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user centric, decentralized system where individuals maintain control over their personalized agents.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NTK-DFL: Enhancing Decentralized Federated Learning in Heterogeneous Settings via Neural Tangent Kernel</title>
<link>https://arxiv.org/abs/2410.01922</link>
<guid>https://arxiv.org/abs/2410.01922</guid>
<content:encoded><![CDATA[
arXiv:2410.01922v2 Announce Type: replace 
Abstract: Decentralized federated learning (DFL) is a collaborative machine learning framework for training a model across participants without a central server or raw data exchange. DFL faces challenges due to statistical heterogeneity, as participants often possess data of different distributions reflecting local environments and user behaviors. Recent work has shown that the neural tangent kernel (NTK) approach, when applied to federated learning in a centralized framework, can lead to improved performance. We propose an approach leveraging the NTK to train client models in the decentralized setting, while introducing a synergy between NTK-based evolution and model averaging. This synergy exploits inter-client model deviation and improves both accuracy and convergence in heterogeneous settings. Empirical results demonstrate that our approach consistently achieves higher accuracy than baselines in highly heterogeneous settings, where other approaches often underperform. Additionally, it reaches target performance in 4.6 times fewer communication rounds. We validate our approach across multiple datasets, network topologies, and heterogeneity settings to ensure robustness and generalization.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noncooperative Equilibrium Selection via a Trading-based Auction</title>
<link>https://arxiv.org/abs/2502.03616</link>
<guid>https://arxiv.org/abs/2502.03616</guid>
<content:encoded><![CDATA[
arXiv:2502.03616v2 Announce Type: replace 
Abstract: Noncooperative multi-agent systems often face coordination challenges due to conflicting preferences among agents. In particular, agents acting in their own self-interest can settle on different equilibria, leading to suboptimal outcomes or even safety concerns. We propose an algorithm named trading auction for consensus (TACo), a decentralized approach that enables noncooperative agents to reach consensus without communicating directly or disclosing private valuations. TACo facilitates coordination through a structured trading-based auction, where agents iteratively select choices of interest and provably reach an agreement within an a priori bounded number of steps. A series of numerical experiments validate that the termination guarantees of TACo hold in practice, and show that TACo achieves a median performance that minimizes the total cost across all agents, while allocating resources significantly more fairly than baseline approaches.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Communication-Enabled Cloud-Edge-End-collaborative Metaverse Services Architecure</title>
<link>https://arxiv.org/abs/2506.10001</link>
<guid>https://arxiv.org/abs/2506.10001</guid>
<content:encoded><![CDATA[
arXiv:2506.10001v1 Announce Type: new 
Abstract: With technology advancing and the pursuit of new audiovisual experiences strengthening, the metaverse has gained surging enthusiasm. However, it faces practical hurdles as substantial data like high-resolution virtual scenes must be transmitted between cloud platforms and VR devices. Specifically, the VR device's wireless transmission hampered by insufficient bandwidth, causes speed and delay problems. Meanwhile, poor channel quality leads to data errors and worsens user experience. To solve this, we've proposed the Semantic Communication-Enabled Cloud-Edge-End Collaborative Immersive Metaverse Service (SC-CEE-Meta) Architecture, which includes three modules: VR video semantic transmission, video synthesis, and 3D virtual scene reconstruction. By deploying semantic modules on VR devices and edge servers and sending key semantic info instead of focusing on bit-level reconstruction, it can cut latency, resolve the resource-bandwidth conflict, and better withstand channel interference. Also, the cloud deploys video synthesis and 3D scene reconstruction preprocessing, while edge devices host 3D reconstruction rendering modules, all for immersive services. Verified on Meta Quest Pro, the SC-CEE-Meta can reduce wireless transmission delay by 96.05\% and boost image quality by 43.99\% under poor channel condition.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Meet Me at the Arm: The Cooperative Multi-Armed Bandits Problem with Shareable Arms</title>
<link>https://arxiv.org/abs/2506.10127</link>
<guid>https://arxiv.org/abs/2506.10127</guid>
<content:encoded><![CDATA[
arXiv:2506.10127v1 Announce Type: new 
Abstract: We study the decentralized multi-player multi-armed bandits (MMAB) problem under a no-sensing setting, where each player receives only their own reward and obtains no information about collisions. Each arm has an unknown capacity, and if the number of players pulling an arm exceeds its capacity, all players involved receive zero reward. This setting generalizes the classical unit-capacity model and introduces new challenges in coordination and capacity discovery under severe feedback limitations. We propose A-CAPELLA (Algorithm for Capacity-Aware Parallel Elimination for Learning and Allocation), a decentralized algorithm that achieves logarithmic regret in this generalized regime. Our main contribution is a collaborative hypothesis testing protocol that enables synchronized successive elimination and capacity estimation through carefully structured collision patterns. This represents a provably efficient learning result in decentralized no-sensing MMAB with unknown arm capacities.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A new type of federated clustering: A non-model-sharing approach</title>
<link>https://arxiv.org/abs/2506.10244</link>
<guid>https://arxiv.org/abs/2506.10244</guid>
<content:encoded><![CDATA[
arXiv:2506.10244v1 Announce Type: new 
Abstract: In recent years, the growing need to leverage sensitive data across institutions has led to increased attention on federated learning (FL), a decentralized machine learning paradigm that enables model training without sharing raw data. However, existing FL-based clustering methods, known as federated clustering, typically assume simple data partitioning scenarios such as horizontal or vertical splits, and cannot handle more complex distributed structures. This study proposes data collaboration clustering (DC-Clustering), a novel federated clustering method that supports clustering over complex data partitioning scenarios where horizontal and vertical splits coexist. In DC-Clustering, each institution shares only intermediate representations instead of raw data, ensuring privacy preservation while enabling collaborative clustering. The method allows flexible selection between k-means and spectral clustering, and achieves final results with a single round of communication with the central server. We conducted extensive experiments using synthetic and open benchmark datasets. The results show that our method achieves clustering performance comparable to centralized clustering where all data are pooled. DC-Clustering addresses an important gap in current FL research by enabling effective knowledge discovery from distributed heterogeneous data. Its practical properties -- privacy preservation, communication efficiency, and flexibility -- make it a promising tool for privacy-sensitive domains such as healthcare and finance.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video</title>
<link>https://arxiv.org/abs/2506.10331</link>
<guid>https://arxiv.org/abs/2506.10331</guid>
<content:encoded><![CDATA[
arXiv:2506.10331v1 Announce Type: new 
Abstract: In response to the rising prominence of the Metaverse, omnidirectional videos (ODVs) have garnered notable interest, gradually shifting from professional-generated content (PGC) to user-generated content (UGC). However, the study of audio-visual quality assessment (AVQA) within ODVs remains limited. To address this, we construct a dataset of UGC omnidirectional audio and video (A/V) content. The videos are captured by five individuals using two different types of omnidirectional cameras, shooting 300 videos covering 10 different scene types. A subjective AVQA experiment is conducted on the dataset to obtain the Mean Opinion Scores (MOSs) of the A/V sequences. After that, to facilitate the development of UGC-ODV AVQA fields, we construct an effective AVQA baseline model on the proposed dataset, of which the baseline model consists of video feature extraction module, audio feature extraction and audio-visual fusion module. The experimental results demonstrate that our model achieves optimal performance on the proposed dataset.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph-based Gossiping for Communication Efficiency in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2506.10607</link>
<guid>https://arxiv.org/abs/2506.10607</guid>
<content:encoded><![CDATA[
arXiv:2506.10607v1 Announce Type: new 
Abstract: Federated learning has emerged as a privacy-preserving technique for collaborative model training across heterogeneously distributed silos. Yet, its reliance on a single central server introduces potential bottlenecks and risks of single-point failure. Decentralizing the server, often referred to as decentralized learning, addresses this problem by distributing the server role across nodes within the network. One drawback regarding this pure decentralization is it introduces communication inefficiencies, which arise from increased message exchanges in large-scale setups. However, existing proposed solutions often fail to simulate the real-world distributed and decentralized environment in their experiments, leading to unreliable performance evaluations and limited applicability in practice. Recognizing the lack from prior works, this work investigates the correlation between model size and network latency, a critical factor in optimizing decentralized learning communication. We propose a graph-based gossiping mechanism, where specifically, minimum spanning tree and graph coloring are used to optimize network structure and scheduling for efficient communication across various network topologies and message capacities. Our approach configures and manages subnetworks on real physical routers and devices and closely models real-world distributed setups. Experimental results demonstrate that our method significantly improves communication, compatible with different topologies and data sizes, reducing bandwidth and transfer time by up to circa 8 and 4.4 times, respectively, compared to naive flooding broadcasting methods.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deployment of Containerized Simulations in an API-Driven Distributed Infrastructure</title>
<link>https://arxiv.org/abs/2506.10642</link>
<guid>https://arxiv.org/abs/2506.10642</guid>
<content:encoded><![CDATA[
arXiv:2506.10642v1 Announce Type: new 
Abstract: The increasingly dynamic market for embedded systems makes virtual prototypes an indispensable tool for hardware/software codesign. The broad acceptance of the methodology has led to a diverse range of solutions: from open-source, pure console-based simulators to highly capable commercial simulation tools. In this work we present SUNRISE, an infrastructure to provide users a unified approach to utilizing virtual prototyping solutions, facilitate access to various simulation technologies and boost cooperation by leveraging decentralized compute resources for deployment of simulation workloads and definition of open APIs.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GOLIATH: A Decentralized Framework for Data Collection in Intelligent Transportation Systems</title>
<link>https://arxiv.org/abs/2506.10665</link>
<guid>https://arxiv.org/abs/2506.10665</guid>
<content:encoded><![CDATA[
arXiv:2506.10665v1 Announce Type: new 
Abstract: Intelligent Transportation Systems (ITSs) technology has advanced during the past years, and it is now used for several applications that require vehicles to exchange real-time data, such as in traffic information management. Traditionally, road traffic information has been collected using on-site sensors. However, crowd-sourcing traffic information from onboard sensors or smartphones has become a viable alternative. State-of-the-art solutions currently follow a centralized model where only the service provider has complete access to the collected traffic data and represent a single point of failure and trust. In this paper, we propose GOLIATH, a blockchain-based decentralized framework that runs on the In-Vehicle Infotainment (IVI) system to collect real-time information exchanged between the network's participants. Our approach mitigates the limitations of existing crowd-sourcing centralized solutions by guaranteeing trusted information collection and exchange, fully exploiting the intrinsic distributed nature of vehicles. We demonstrate its feasibility in the context of vehicle positioning and traffic information management. Each vehicle participating in the decentralized network shares its position and neighbors' ones in the form of a transaction recorded on the ledger, which uses a novel consensus mechanism to validate it. We design the consensus mechanism resilient against a realistic set of adversaries that aim to tamper or disable the communication. We evaluate the proposed framework in a simulated (but realistic) environment, which considers different threats and allows showing its robustness and safety properties.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Higher-Order Uncoupled Learning Dynamics and Nash Equilibrium</title>
<link>https://arxiv.org/abs/2506.10874</link>
<guid>https://arxiv.org/abs/2506.10874</guid>
<content:encoded><![CDATA[
arXiv:2506.10874v1 Announce Type: new 
Abstract: We study learnability of mixed-strategy Nash Equilibrium (NE) in general finite games using higher-order replicator dynamics as well as classes of higher-order uncoupled heterogeneous dynamics. In higher-order uncoupled learning dynamics, players have no access to utilities of opponents (uncoupled) but are allowed to use auxiliary states to further process information (higher-order). We establish a link between uncoupled learning and feedback stabilization with decentralized control. Using this association, we show that for any finite game with an isolated completely mixed-strategy NE, there exist higher-order uncoupled learning dynamics that lead (locally) to that NE. We further establish the lack of universality of learning dynamics by linking learning to the control theoretic concept of simultaneous stabilization. We construct two games such that any higher-order dynamics that learn the completely mixed-strategy NE of one of these games can never learn the completely mixed-strategy NE of the other. Next, motivated by imposing natural restrictions on allowable learning dynamics, we introduce the Asymptotic Best Response (ABR) property. Dynamics with the ABR property asymptotically learn a best response in environments that are asymptotically stationary. We show that the ABR property relates to an internal stability condition on higher-order learning dynamics. We provide conditions under which NE are compatible with the ABR property. Finally, we address learnability of mixed-strategy NE in the bandit setting using a bandit version of higher-order replicator dynamics.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
<link>https://arxiv.org/abs/2506.10964</link>
<guid>https://arxiv.org/abs/2506.10964</guid>
<content:encoded><![CDATA[
arXiv:2506.10964v1 Announce Type: new 
Abstract: Urban digital twins are increasingly perceived as a way to pool the growing digital resources of cities for the purpose of a more sustainable and integrated urban planning. Models and simulations are central to this undertaking: They enable "what if?" scenarios, create insights and describe relationships between the vast data that is being collected. However, the process of integrating and subsequently using models in urban digital twins is an inherently complex undertaking. It raises questions about how to represent urban complexity, how to deal with uncertain assUrban Model Platformtions and modeling paradigms, and how to capture underlying power relations. Existent approaches in the domain largely focus on monolithic and centralized solutions in the tradition of neoliberal city-making, oftentimes prohibiting pluralistic and open interoperable models. Using a participatory design for participatory systems approach together with the City of Hamburg, Germany, we find that an open Urban Model Platform can function both as a public technological backbone for modeling and simulation in urban digital twins and as a socio-technical framework for a collaborative and pluralistic representation of urban processes. Such a platform builds on open standards, allows for a decentralized integration of models, enables communication between models and supports a multi-model approach to representing urban systems.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Unsupervised Visual Representation Learning via Exploiting General Content and Personal Style</title>
<link>https://arxiv.org/abs/2211.06470</link>
<guid>https://arxiv.org/abs/2211.06470</guid>
<content:encoded><![CDATA[
arXiv:2211.06470v2 Announce Type: replace 
Abstract: Discriminative unsupervised learning methods such as contrastive learning have demonstrated the ability to learn generalized visual representations on centralized data. It is nonetheless challenging to adapt such methods to a distributed system with unlabeled, private, and heterogeneous client data due to user styles and preferences. Federated learning enables multiple clients to collectively learn a global model without provoking any privacy breach between local clients. On the other hand, another direction of federated learning studies personalized methods to address the local heterogeneity. However, work on solving both generalization and personalization without labels in a decentralized setting remains unfamiliar. In this work, we propose a novel method, FedStyle, to learn a more generalized global model by infusing local style information with local content information for contrastive learning, and to learn more personalized local models by inducing local style information for downstream tasks. The style information is extracted by contrasting original local data with strongly augmented local data (Sobel filtered images). Through extensive experiments with linear evaluations in both IID and non-IID settings, we demonstrate that FedStyle outperforms both the generalization baseline methods and personalization baseline methods in a stylized decentralized setting. Through comprehensive ablations, we demonstrate our design of style infusion and stylized personalization improve performance significantly.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Stochastic Hybrid Approach to Decentralized Networked Control: Stochastic Network Delays and Poisson Pulsing Attacks</title>
<link>https://arxiv.org/abs/2401.14750</link>
<guid>https://arxiv.org/abs/2401.14750</guid>
<content:encoded><![CDATA[
arXiv:2401.14750v3 Announce Type: replace 
Abstract: By designing the decentralized time-regularized (Zeno-free) event-triggered strategies for the state-feedback control law, this paper considers the stochastic stabilization of a class of networked control systems, where two sources of randomness exist in multiple decentralized networks that operate asynchronously and independently: the communication channels are constrained by the stochastic network delays and also by Poisson pulsing denial-of-service (Pp-DoS) attacks. The time delay in the network denotes the length from a transmission instant to the corresponding update instant, and is supposed to be a continuous random variable subject to certain continuous probability distribution; while the attacks' cardinal number is a discrete random variable supposed to be subject to Poisson distribution, so the inter-attack time, i.e., the time between two consecutive attack instants, is subject to exponential distribution. The considered system is modeled as a stochastic hybrid formalism, where the randomness enters through the jump map into the reset value (the inter-attack time directly related) of each triggered strategy. By only sampling/transmitting state measurements when needed and simultaneously by taking the specific medium access protocols into account, the designed event-triggered strategies are synthesized in a state-based and decentralized form, which are robust (tolerable well) to stochastic network delays, under different tradeoff-conditions between the minimum inter-event times, maximum allowable delays (i.e., potentially tolerable delays) and the frequencies of attacks. Using stochastic hybrid tools to combine attack-active parts with attack-over parts, the designed triggered strategies, if designed well according to the actual system needs, can tolerate (be resilient to) the Pp-DoS attacks and stochastic network delays without jeopardizing the stability and Zeno-freeness.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Aware Spectrum Pricing and Power Control Optimization for LEO Satellite Internet-of-Things</title>
<link>https://arxiv.org/abs/2407.00814</link>
<guid>https://arxiv.org/abs/2407.00814</guid>
<content:encoded><![CDATA[
arXiv:2407.00814v2 Announce Type: replace 
Abstract: Low earth orbit (LEO) satellite systems play an important role in next generation communication networks due to their ability to provide extensive global coverage with guaranteed communications in remote areas and isolated areas where base stations cannot be cost-efficiently deployed. With the pervasive adoption of LEO satellite systems, especially in the LEO Internet-of-Things (IoT) scenarios, their spectrum resource management requirements have become more complex as a result of massive service requests and high bandwidth demand from terrestrial terminals. For instance, when leasing the spectrum to terrestrial users and controlling the uplink transmit power, satellites collect user data for machine learning purposes, which usually are sensitive information such as location, budget and quality of service (QoS) requirement. To facilitate model training in LEO IoT while preserving the privacy of data, blockchain-driven federated learning (FL) is widely used by leveraging on a fully decentralized architecture. In this paper, we propose a hybrid spectrum pricing and power control framework for LEO IoT by combining blockchain technology and FL. We first design a local deep reinforcement learning algorithm for LEO satellite systems to learn a revenue-maximizing pricing and power control scheme. Then the agents collaborate to form a FL system. We also propose a reputation-based blockchain which is used in the global model aggregation phase of FL. Based on the reputation mechanism, a node is selected for each global training round to perform model aggregation and block generation, which can further enhance the decentralization of the network and guarantee the trust. Simulation tests are conducted to evaluate the performances of the proposed scheme. Our results show the efficiency of finding the maximum revenue scheme for LEO satellite systems while preserving the privacy of each agent.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differentially private and decentralized randomized power method</title>
<link>https://arxiv.org/abs/2411.01931</link>
<guid>https://arxiv.org/abs/2411.01931</guid>
<content:encoded><![CDATA[
arXiv:2411.01931v3 Announce Type: replace 
Abstract: The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. However, its application to large datasets containing personal information (e.g., web interactions, search history, personal tastes) raises critical privacy problems. This paper addresses these issues by proposing enhanced privacy-preserving variants of the method. First, we propose a variant that reduces the amount of the noise required in current techniques to achieve Differential Privacy (DP). More precisely, we refine the privacy analysis so that the Gaussian noise variance no longer grows linearly with the target rank, achieving the same DP guarantees with strictly less noise. Second, we adapt our method to a decentralized framework in which data is distributed among multiple users. The decentralized protocol strengthens privacy guarantees with no accuracy penalty and a low computational and communication overhead. Our results include the provision of tighter convergence bounds for both the centralized and decentralized versions, and an empirical comparison with previous work using real recommendation datasets.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating Asynchronous AdaBoost into Federated Learning: Five Real World Applications</title>
<link>https://arxiv.org/abs/2506.09090</link>
<guid>https://arxiv.org/abs/2506.09090</guid>
<content:encoded><![CDATA[
arXiv:2506.09090v1 Announce Type: new 
Abstract: This paper presents a comprehensive analysis of an enhanced asynchronous AdaBoost framework for federated learning (FL), focusing on its application across five distinct domains: computer vision on edge devices, blockchain-based model transparency, on-device mobile personalization, IoT anomaly detection, and federated healthcare diagnostics. The proposed algorithm incorporates adaptive communication scheduling and delayed weight compensation to reduce synchronization frequency and communication overhead while preserving or improving model accuracy. We examine how these innovations improve communication efficiency, scalability, convergence, and robustness in each domain. Comparative metrics including training time, communication overhead, convergence iterations, and classification accuracy are evaluated using data and estimates derived from Oghlukyan's enhanced AdaBoost framework. Empirical results show, for example, training time reductions on the order of 20-35% and communication overhead reductions of 30-40% compared to baseline AdaBoost, with convergence achieved in significantly fewer boosting rounds. Tables and charts summarize these improvements by domain. Mathematical formulations of the adaptive scheduling rule and error-driven synchronization thresholds are provided. Overall, the enhanced AdaBoost exhibits markedly improved efficiency and robustness across diverse FL scenarios, suggesting broad applicability of the approach.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent System of Emergent Knowledge: A Coordination Fabric for Billions of Minds</title>
<link>https://arxiv.org/abs/2506.09335</link>
<guid>https://arxiv.org/abs/2506.09335</guid>
<content:encoded><![CDATA[
arXiv:2506.09335v1 Announce Type: new 
Abstract: The Intelligent System of Emergent Knowledge (ISEK) establishes a decentralized network where human and artificial intelligence agents collaborate as peers, forming a self-organizing cognitive ecosystem. Built on Web3 infrastructure, ISEK combines three fundamental principles: (1) a decentralized multi-agent architecture resistant to censorship, (2) symbiotic AI-human collaboration with equal participation rights, and (3) resilient self-adaptation through distributed consensus mechanisms.
  The system implements an innovative coordination protocol featuring a six-phase workflow (Publish, Discover, Recruit, Execute, Settle, Feedback) for dynamic task allocation, supported by robust fault tolerance and a multidimensional reputation system. Economic incentives are governed by the native $ISEK token, facilitating micropayments, governance participation, and reputation tracking, while agent sovereignty is maintained through NFT-based identity management.
  This synthesis of blockchain technology, artificial intelligence, and incentive engineering creates an infrastructure that actively facilitates emergent intelligence. ISEK represents a paradigm shift from conventional platforms, enabling the organic development of large-scale, decentralized cognitive systems where autonomous agents collectively evolve beyond centralized constraints.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Epass: Efficient and Privacy-Preserving Asynchronous Payment on Blockchain</title>
<link>https://arxiv.org/abs/2506.09387</link>
<guid>https://arxiv.org/abs/2506.09387</guid>
<content:encoded><![CDATA[
arXiv:2506.09387v1 Announce Type: new 
Abstract: Buy Now Pay Later (BNPL) is a rapidly proliferating e-commerce model, offering consumers to get the product immediately and defer payments. Meanwhile, emerging blockchain technologies endow BNPL platforms with digital currency transactions, allowing BNPL platforms to integrate with digital wallets. However, the transparency of transactions causes critical privacy concerns because malicious participants may derive consumers' financial statuses from on-chain asynchronous payments. Furthermore, the newly created transactions for deferred payments introduce additional time overheads, which weaken the scalability of BNPL services. To address these issues, we propose an efficient and privacy-preserving blockchain-based asynchronous payment scheme (Epass), which has promising scalability while protecting the privacy of on-chain consumer transactions. Specifically, Epass leverages locally verifiable signatures to guarantee the privacy of consumer transactions against malicious acts. Then, a privacy-preserving asynchronous payment scheme can be further constructed by leveraging time-release encryption to control trapdoors of redactable blockchain, reducing time overheads by modifying transactions for deferred payment. We give formal definitions and security models, generic structures, and formal proofs for Epass. Extensive comparisons and experimental analysis show that \textsf{Epass} achieves KB-level communication costs, and reduces time overhead by more than four times in comparisons with locally verifiable signatures and Go-Ethereum private test networks.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalization Error Analysis for Attack-Free and Byzantine-Resilient Decentralized Learning with Data Heterogeneity</title>
<link>https://arxiv.org/abs/2506.09438</link>
<guid>https://arxiv.org/abs/2506.09438</guid>
<content:encoded><![CDATA[
arXiv:2506.09438v1 Announce Type: new 
Abstract: Decentralized learning, which facilitates joint model training across geographically scattered agents, has gained significant attention in the field of signal and information processing in recent years. While the optimization errors of decentralized learning algorithms have been extensively studied, their generalization errors remain relatively under-explored. As the generalization errors reflect the scalability of trained models on unseen data and are crucial in determining the performance of trained models in real-world applications, understanding the generalization errors of decentralized learning is of paramount importance. In this paper, we present fine-grained generalization error analysis for both attack-free and Byzantine-resilient decentralized learning with heterogeneous data as well as under mild assumptions, in contrast to prior studies that consider homogeneous data and/or rely on a stringent bounded stochastic gradient assumption. Our results shed light on the impact of data heterogeneity, model initialization and stochastic gradient noise -- factors that have not been closely investigated before -- on the generalization error of decentralized learning. We also reveal that Byzantine attacks performed by malicious agents largely affect the generalization error, and their negative impact is inherently linked to the data heterogeneity while remaining independent on the sample size. Numerical experiments on both convex and non-convex tasks are conducted to validate our theoretical findings.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Performance of Cloud-based ARM SVE for Zero-Knowledge Proving Systems</title>
<link>https://arxiv.org/abs/2506.09505</link>
<guid>https://arxiv.org/abs/2506.09505</guid>
<content:encoded><![CDATA[
arXiv:2506.09505v1 Announce Type: new 
Abstract: Zero-knowledge proofs (ZKP) are becoming a gold standard in scaling blockchains and bringing Web3 to life. At the same time, ZKP for transactions running on the Ethereum Virtual Machine require powerful servers with hundreds of CPU cores. The current zkProver implementation from Polygon is optimized for x86-64 CPUs by vectorizing key operations, such as Merkle tree building with Poseidon hashes over the Goldilocks field, with Advanced Vector Extensions (AVX and AVX512). With these optimizations, a ZKP for a batch of transactions is generated in less than two minutes. With the advent of cloud servers with ARM which are at least 10% cheaper than x86-64 servers and the implementation of ARM Scalable Vector Extension (SVE), we wonder if ARM servers can take over their x86-64 counterparts. Unfortunately, our analysis shows that current ARM CPUs are not a match for their x86-64 competitors. Graviton4 from Amazon Web Services (AWS) and Axion from Google Cloud Platform (GCP) are 1.6X and 1.4X slower compared to the latest AMD EPYC and Intel Xeon servers from AWS with AVX and AVX512, respectively, when building a Merkle tree with over four million leaves. This low performance is due to (1) smaller vector size in these ARM CPUs (128 bits versus 512 bits in AVX512) and (2) lower clock frequency. On the other hand, ARM SVE/SVE2 Instruction Set Architecture (ISA) is at least as powerful as AVX/AVX512 but more flexible. Moreover, we estimate that increasing the vector size to 512 bits will enable higher performance in ARM CPUs compared to their x86-64 counterparts while maintaining their price advantage.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Identity and Access Management for the Computing Continuum</title>
<link>https://arxiv.org/abs/2506.09559</link>
<guid>https://arxiv.org/abs/2506.09559</guid>
<content:encoded><![CDATA[
arXiv:2506.09559v1 Announce Type: new 
Abstract: The computing continuum introduces new challenges for access control due to its dynamic, distributed, and heterogeneous nature. In this paper, we propose a Zero-Trust (ZT) access control solution that leverages decentralized identification and authentication mechanisms based on Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). Additionally, we employ Relationship-Based Access Control (ReBAC) to define policies that capture the evolving trust relationships inherent in the continuum. Through a proof-of-concept implementation, we demonstrate the feasibility and efficiency of our solution, highlighting its potential to enhance security and trust in decentralized environments.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ASTAGEN: Empirical Evaluation of Automated SATD Taxonomy Generation with LLMs</title>
<link>https://arxiv.org/abs/2506.09601</link>
<guid>https://arxiv.org/abs/2506.09601</guid>
<content:encoded><![CDATA[
arXiv:2506.09601v1 Announce Type: new 
Abstract: Technical debt refers to suboptimal code that degrades software quality. When developers intentionally introduce such debt, it is called self-admitted technical debt (SATD). Since SATD hinders maintenance, identifying its categories is key to uncovering quality issues. Traditionally, constructing such taxonomies requires manually inspecting SATD comments and surrounding code, which is time-consuming, labor-intensive, and often inconsistent due to annotator subjectivity. This study presents ASTAGEN, an initial step toward automating SATD taxonomy generation using large language models (LLMs). Given a comment and its surrounding code, ASTAGEN first generates a concise explanation for each SATD comment, then incrementally generates and updates categories to construct a taxonomy. We evaluate ASTAGEN on SATD datasets from three domains: quantum software, smart contracts, and machine learning. It successfully recovers domain-specific categories reported in prior work, such as Layer Configuration in machine learning. Compared to a naive use of an LLM, ASTAGEN produces more consistent category assignments due to its explanation-driven, iterative design. It also completes taxonomy generation in under two hours and for less than one USD, even on the largest dataset. These results suggest that while full automation remains challenging, ASTAGEN is able to support semi-automated taxonomy construction. Furthermore, our work opens up avenues for future work, such as automatic taxonomy generation in other areas.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wavelet Scattering Transform and Fourier Representation for Offline Detection of Malicious Clients in Federated Learning</title>
<link>https://arxiv.org/abs/2506.09674</link>
<guid>https://arxiv.org/abs/2506.09674</guid>
<content:encoded><![CDATA[
arXiv:2506.09674v1 Announce Type: new 
Abstract: Federated Learning (FL) enables the training of machine learning models across decentralized clients while preserving data privacy. However, the presence of anomalous or corrupted clients - such as those with faulty sensors or non representative data distributions - can significantly degrade model performance. Detecting such clients without accessing raw data remains a key challenge. We propose WAFFLE (Wavelet and Fourier representations for Federated Learning) a detection algorithm that labels malicious clients {\it before training}, using locally computed compressed representations derived from either the Wavelet Scattering Transform (WST) or the Fourier Transform. Both approaches provide low-dimensional, task-agnostic embeddings suitable for unsupervised client separation. A lightweight detector, trained on a distillated public dataset, performs the labeling with minimal communication and computational overhead. While both transforms enable effective detection, WST offers theoretical advantages, such as non-invertibility and stability to local deformations, that make it particularly well-suited to federated scenarios. Experiments on benchmark datasets show that our method improves detection accuracy and downstream classification performance compared to existing FL anomaly detection algorithms, validating its effectiveness as a pre-training alternative to online detection strategies.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Load-Aware Training Scheduling for Model Circulation-based Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2506.09769</link>
<guid>https://arxiv.org/abs/2506.09769</guid>
<content:encoded><![CDATA[
arXiv:2506.09769v1 Announce Type: new 
Abstract: This paper proposes Load-aware Tram-FL, an extension of Tram-FL that introduces a training scheduling mechanism to minimize total training time in decentralized federated learning by accounting for both computational and communication loads. The scheduling problem is formulated as a global optimization task, which-though intractable in its original form-is made solvable by decomposing it into node-wise subproblems. To promote balanced data utilization under non-IID distributions, a variance constraint is introduced, while the overall training latency, including both computation and communication costs, is minimized through the objective function. Simulation results on MNIST and CIFAR-10 demonstrate that Load-aware Tram-FL significantly reduces training time and accelerates convergence compared to baseline methods.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Frosty for partial synchrony</title>
<link>https://arxiv.org/abs/2506.09823</link>
<guid>https://arxiv.org/abs/2506.09823</guid>
<content:encoded><![CDATA[
arXiv:2506.09823v1 Announce Type: new 
Abstract: Snowman is the consensus protocol used by blockchains on Avalanche. Recent work has shown both how to augment Snowman with a `liveness' module called `Frosty' that protects against liveness attacks, and also how to modify Snowman so as to be consistent in partial synchrony. Since Frosty assumes (a strong form of) synchrony, the aim of this note is to show how to modify Frosty to deal with the partially synchronous version of Snowman.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Resilient Decentralized Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2310.07320</link>
<guid>https://arxiv.org/abs/2310.07320</guid>
<content:encoded><![CDATA[
arXiv:2310.07320v2 Announce Type: replace 
Abstract: In decentralized cooperative multi-armed bandits (MAB), each agent observes a distinct stream of rewards, and seeks to exchange information with others to select a sequence of arms so as to minimize its regret. Agents in the cooperative setting can outperform a single agent running a MAB method such as Upper-Confidence Bound (UCB) independently. In this work, we study how to recover such salient behavior when an unknown fraction of the agents can be Byzantine, that is, communicate arbitrarily wrong information in the form of reward mean-estimates or confidence sets. This framework can be used to model attackers in computer networks, instigators of offensive content into recommender systems, or manipulators of financial markets. Our key contribution is the development of a fully decentralized resilient upper confidence bound (UCB) algorithm that fuses an information mixing step among agents with a truncation of inconsistent and extreme values. This truncation step enables us to establish that the performance of each normal agent is no worse than the classic single-agent UCB1 algorithm in terms of regret, and more importantly, the cumulative regret of all normal agents is strictly better than the non-cooperative case, provided that each agent has at least 3f+1 neighbors where f is the maximum possible Byzantine agents in each agent's neighborhood. Extensions to time-varying neighbor graphs, and minimax lower bounds are further established on the achievable regret. Experiments corroborate the merits of this framework in practice.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reciprocity as the Foundational Substrate of Society: How Reciprocal Dynamics Scale into Social Systems</title>
<link>https://arxiv.org/abs/2505.08319</link>
<guid>https://arxiv.org/abs/2505.08319</guid>
<content:encoded><![CDATA[
arXiv:2505.08319v2 Announce Type: replace 
Abstract: Prevailing accounts in both multi-agent AI and the social sciences explain social structure through top-down abstractions-such as institutions, norms, or trust-yet lack simulateable models of how such structures emerge from individual behavior. Ethnographic and archaeological evidence suggests that reciprocity served as the foundational mechanism of early human societies, enabling economic circulation, social cohesion, and interpersonal obligation long before the rise of formal institutions. Modern financial systems such as credit and currency can likewise be viewed as scalable extensions of reciprocity, formalizing exchange across time and anonymity. Building on this insight, we argue that reciprocity is not merely a local or primitive exchange heuristic, but the scalable substrate from which large-scale social structures can emerge. We propose a three-stage framework to model this emergence: reciprocal dynamics at the individual level, norm stabilization through shared expectations, and the construction of durable institutional patterns. This approach offers a cognitively minimal, behaviorally grounded foundation for simulating how large-scale social systems can emerge from decentralized reciprocal interaction.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids</title>
<link>https://arxiv.org/abs/2506.08272</link>
<guid>https://arxiv.org/abs/2506.08272</guid>
<content:encoded><![CDATA[
arXiv:2506.08272v1 Announce Type: new 
Abstract: Universal Differential Equations (UDEs), which blend neural networks with physical differential equations, have emerged as a powerful framework for scientific machine learning (SciML), enabling data-efficient, interpretable, and physically consistent modeling. In the context of smart grid systems, modeling node-wise battery dynamics remains a challenge due to the stochasticity of solar input and variability in household load profiles. Traditional approaches often struggle with generalization and fail to capture unmodeled residual dynamics. This work proposes a UDE-based approach to learn node-specific battery evolution by embedding a neural residual into a physically inspired battery ODE. Synthetic yet realistic solar generation and load demand data are used to simulate battery dynamics over time. The neural component learns to model unobserved or stochastic corrections arising from heterogeneity in node demand and environmental conditions. Comprehensive experiments reveal that the trained UDE aligns closely with ground truth battery trajectories, exhibits smooth convergence behavior, and maintains stability in long-term forecasts. These findings affirm the viability of UDE-based SciML approaches for battery modeling in decentralized energy networks and suggest broader implications for real-time control and optimization in renewable-integrated smart grids.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation</title>
<link>https://arxiv.org/abs/2506.08296</link>
<guid>https://arxiv.org/abs/2506.08296</guid>
<content:encoded><![CDATA[
arXiv:2506.08296v1 Announce Type: new 
Abstract: Recent advances in multimodal vision-language-action (VLA) models have revolutionized traditional robot learning, enabling systems to interpret vision, language, and action in unified frameworks for complex task planning. However, mastering complex manipulation tasks remains an open challenge, constrained by limitations in persistent contextual memory, multi-agent coordination under uncertainty, and dynamic long-horizon planning across variable sequences. To address this challenge, we propose \textbf{HiBerNAC}, a \textbf{Hi}erarchical \textbf{B}rain-\textbf{e}mulated \textbf{r}obotic \textbf{N}eural \textbf{A}gent \textbf{C}ollective, inspired by breakthroughs in neuroscience, particularly in neural circuit mechanisms and hierarchical decision-making. Our framework combines: (1) multimodal VLA planning and reasoning with (2) neuro-inspired reflection and multi-agent mechanisms, specifically designed for complex robotic manipulation tasks. By leveraging neuro-inspired functional modules with decentralized multi-agent collaboration, our approach enables robust and enhanced real-time execution of complex manipulation tasks. In addition, the agentic system exhibits scalable collective intelligence via dynamic agent specialization, adapting its coordination strategy to variable task horizons and complexity. Through extensive experiments on complex manipulation tasks compared with state-of-the-art VLA models, we demonstrate that \textbf{HiBerNAC} reduces average long-horizon task completion time by 23\%, and achieves non-zero success rates (12\textendash 31\%) on multi-path tasks where prior state-of-the-art VLA models consistently fail. These results provide indicative evidence for bridging biological cognition and robotic learning mechanisms.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting State Manipulation Vulnerabilities in Smart Contracts Using LLM and Static Analysis</title>
<link>https://arxiv.org/abs/2506.08561</link>
<guid>https://arxiv.org/abs/2506.08561</guid>
<content:encoded><![CDATA[
arXiv:2506.08561v1 Announce Type: new 
Abstract: An increasing number of DeFi protocols are gaining popularity, facilitating transactions among multiple anonymous users. State Manipulation is one of the notorious attacks in DeFi smart contracts, with price variable being the most commonly exploited state variable-attackers manipulate token prices to gain illicit profits. In this paper, we propose PriceSleuth, a novel method that leverages the Large Language Model (LLM) and static analysis to detect Price Manipulation (PM) attacks proactively. PriceSleuth firstly identifies core logic function related to price calculation in DeFi contracts. Then it guides LLM to locate the price calculation code statements. Secondly, PriceSleuth performs backward dependency analysis of price variables, instructing LLM in detecting potential price manipulation. Finally, PriceSleuth utilizes propagation analysis of price variables to assist LLM in detecting whether these variables are maliciously exploited. We presented preliminary experimental results to substantiate the effectiveness of PriceSleuth . And we outline future research directions for PriceSleuth.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain and Edge Computing Nexus: A Large-scale Systematic Literature Review</title>
<link>https://arxiv.org/abs/2506.08636</link>
<guid>https://arxiv.org/abs/2506.08636</guid>
<content:encoded><![CDATA[
arXiv:2506.08636v1 Announce Type: new 
Abstract: Blockchain and edge computing are two instrumental paradigms of decentralized computation, driving key advancements in Smart Cities applications such as supply chain, energy and mobility. Despite their unprecedented impact on society, they remain significantly fragmented as technologies and research areas, while they share fundamental principles of distributed systems and domains of applicability. This paper introduces a novel and large-scale systematic literature review on the nexus of blockchain and edge computing with the aim to unravel a new understanding of how the interfacing of the two computing paradigms can boost innovation to provide solutions to timely but also long-standing research challenges. By collecting almost 6000 papers from 3 databases and putting under scrutiny almost 1000 papers, we build a novel taxonomy and classification consisting of 22 features with 287 attributes that we study using quantitative and machine learning methods. They cover a broad spectrum of technological, design, epistemological and sustainability aspects. Results reveal 4 distinguishing patterns of interplay between blockchain and edge computing with key determinants the public (permissionless) vs. private (permissioned) design, technology and proof of concepts. They also demonstrate the prevalence of blockchain-assisted edge computing for improving privacy and security, in particular for mobile computing applications.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging</title>
<link>https://arxiv.org/abs/2506.09024</link>
<guid>https://arxiv.org/abs/2506.09024</guid>
<content:encoded><![CDATA[
arXiv:2506.09024v1 Announce Type: new 
Abstract: Safe deployment of machine learning (ML) models in safety-critical domains such as medical imaging requires detecting inputs with characteristics not seen during training, known as out-of-distribution (OOD) detection, to prevent unreliable predictions. Effective OOD detection after deployment could benefit from access to the training data, enabling direct comparison between test samples and the training data distribution to identify differences. State-of-the-art OOD detection methods, however, either discard training data after deployment or assume that test samples and training data are centrally stored together, an assumption that rarely holds in real-world settings. This is because shipping training data with the deployed model is usually impossible due to the size of training databases, as well as proprietary or privacy constraints. We introduce the Isolation Network, an OOD detection framework that quantifies the difficulty of separating a target test sample from the training data by solving a binary classification task. We then propose Decentralized Isolation Networks (DIsoN), which enables the comparison of training and test data when data-sharing is impossible, by exchanging only model parameters between the remote computational nodes of training and deployment. We further extend DIsoN with class-conditioning, comparing a target sample solely with training data of its predicted class. We evaluate DIsoN on four medical imaging datasets (dermatology, chest X-ray, breast ultrasound, histopathology) across 12 OOD detection tasks. DIsoN performs favorably against existing methods while respecting data-privacy. This decentralized OOD detection framework opens the way for a new type of service that ML developers could provide along with their models: providing remote, secure utilization of their training data for OOD detection services. Code will be available upon acceptance at: *****
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uncertainty-Aware Active Search with a Team of Aerial Robots</title>
<link>https://arxiv.org/abs/2410.08507</link>
<guid>https://arxiv.org/abs/2410.08507</guid>
<content:encoded><![CDATA[
arXiv:2410.08507v2 Announce Type: replace 
Abstract: Rapid search and rescue is critical to maximizing survival rates following natural disasters. However, these efforts are challenged by the need to search large disaster zones, lack of reliability in the communications infrastructure, and a priori unknown numbers of objects of interest (OOIs), such as injured survivors. Aerial robots are increasingly being deployed for search and rescue due to their high mobility, but there remains a gap in deploying multi-robot autonomous aerial systems for methodical search of large environments. Prior works have relied on preprogrammed paths from human operators or are evaluated only in simulation. We bridge these gaps in the state of the art by developing and demonstrating a decentralized active search system, which biases its trajectories to take additional views of uncertain OOIs. The methodology leverages stochasticity for rapid coverage in communication denied scenarios. When communications are available, robots share poses, goals, and OOI information to accelerate the rate of search. Detections from multiple images and vehicles are fused to provide a mean and covariance for each OOI location. Extensive simulations and hardware experiments in Bloomingdale, OH, are conducted to validate the approach. The results demonstrate the active search approach outperforms greedy coverage-based planning in communication-denied scenarios while maintaining comparable performance in communication-enabled scenarios. The results also demonstrate the ability to detect and localize all a priori unknown OOIs with a mean error of approximately 3m at flight altitudes between 50m-60m.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies</title>
<link>https://arxiv.org/abs/2506.06325</link>
<guid>https://arxiv.org/abs/2506.06325</guid>
<content:encoded><![CDATA[
arXiv:2506.06325v1 Announce Type: new 
Abstract: This paper proposes a decentralized model of energy cooperation between microgrids, in which decisions are made locally, at the level of the microgrid community. Each microgrid is modeled as an autonomous agent that adopts a Hawk or Dove strategy, depending on the level of energy stored in the battery and its role in the energy trading process. The interactions between selling and buying microgrids are modeled through an evolutionary algorithm. An individual in the algorithm population is represented as an energy trading matrix that encodes the amounts of energy traded between the selling and buying microgrids. The population evolution is achieved by recombination and mutation operators. Recombination uses a specialized operator for matrix structures, and mutation is applied to the matrix elements according to a Gaussian distribution. The evaluation of an individual is made with a multi-criteria fitness function that considers the seller profit, the degree of energy stability at the community level, penalties for energy imbalance at the community level and for the degradation of microgrids batteries. The method was tested on a simulated scenario with 100 microgrids, each with its own selling and buying thresholds, to reflect a realistic environment with variable storage characteristics of microgrids batteries. By applying the algorithm on this scenario, 95 out of the 100 microgrids reached a stable energy state. This result confirms the effectiveness of the proposed model in achieving energy balance both at the individual level, for each microgrid, and at the level of the entire community.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</title>
<link>https://arxiv.org/abs/2506.06694</link>
<guid>https://arxiv.org/abs/2506.06694</guid>
<content:encoded><![CDATA[
arXiv:2506.06694v1 Announce Type: new 
Abstract: Foundation models have revolutionized fields such as natural language processing and computer vision by enabling general-purpose learning across diverse tasks and datasets. However, building analogous models for human mobility remains challenging due to the privacy-sensitive nature of mobility data and the resulting data silos across institutions. To bridge this gap, we propose MoveGCL, a scalable and privacy-preserving framework for training mobility foundation models via generative continual learning. Without sharing raw data, MoveGCL enables decentralized and progressive model evolution by replaying synthetic trajectories generated from a frozen teacher model, and reinforces knowledge retention through a tailored distillation strategy that mitigates catastrophic forgetting. To address the heterogeneity of mobility patterns, MoveGCL incorporates a Mixture-of-Experts Transformer with a mobility-aware expert routing mechanism, and employs a layer-wise progressive adaptation strategy to stabilize continual updates. Experiments on six real-world urban datasets demonstrate that MoveGCL achieves performance comparable to joint training and significantly outperforms federated learning baselines, while offering strong privacy protection. MoveGCL marks a crucial step toward unlocking foundation models for mobility, offering a practical blueprint for open, scalable, and privacy-preserving model development in the era of foundation models.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fuse and Federate: Enhancing EV Charging Station Security with Multimodal Fusion and Federated Learning</title>
<link>https://arxiv.org/abs/2506.06730</link>
<guid>https://arxiv.org/abs/2506.06730</guid>
<content:encoded><![CDATA[
arXiv:2506.06730v1 Announce Type: new 
Abstract: The rapid global adoption of electric vehicles (EVs) has established electric vehicle supply equipment (EVSE) as a critical component of smart grid infrastructure. While essential for ensuring reliable energy delivery and accessibility, EVSE systems face significant cybersecurity challenges, including network reconnaissance, backdoor intrusions, and distributed denial-of-service (DDoS) attacks. These emerging threats, driven by the interconnected and autonomous nature of EVSE, require innovative and adaptive security mechanisms that go beyond traditional intrusion detection systems (IDS). Existing approaches, whether network-based or host-based, often fail to detect sophisticated and targeted attacks specifically crafted to exploit new vulnerabilities in EVSE infrastructure. This paper proposes a novel intrusion detection framework that leverages multimodal data sources, including network traffic and kernel events, to identify complex attack patterns. The framework employs a distributed learning approach, enabling collaborative intelligence across EVSE stations while preserving data privacy through federated learning. Experimental results demonstrate that the proposed framework outperforms existing solutions, achieving a detection rate above 98% and a precision rate exceeding 97% in decentralized environments. This solution addresses the evolving challenges of EVSE security, offering a scalable and privacypreserving response to advanced cyber threats
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions</title>
<link>https://arxiv.org/abs/2506.06735</link>
<guid>https://arxiv.org/abs/2506.06735</guid>
<content:encoded><![CDATA[
arXiv:2506.06735v1 Announce Type: new 
Abstract: Smart contracts, integral to blockchain ecosystems, enable decentralized applications to execute predefined operations without intermediaries. Their ability to enforce trustless interactions has made them a core component of platforms such as Ethereum. Vulnerabilities such as numerical overflows, reentrancy attacks, and improper access permissions have led to the loss of millions of dollars throughout the blockchain and smart contract sector. Traditional smart contract auditing techniques such as manual code reviews and formal verification face limitations in scalability, automation, and adaptability to evolving development patterns. As a result, AI-based solutions have emerged as a promising alternative, offering the ability to learn complex patterns, detect subtle flaws, and provide scalable security assurances. This paper examines novel AI-driven techniques for vulnerability detection in smart contracts, focusing on machine learning, deep learning, graph neural networks, and transformer-based models. This paper analyzes how each technique represents code, processes semantic information, and responds to real world vulnerability classes. We also compare their strengths and weaknesses in terms of accuracy, interpretability, computational overhead, and real time applicability. Lastly, it highlights open challenges and future opportunities for advancing this domain.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Optimization with Amplified Privacy via Efficient Communication</title>
<link>https://arxiv.org/abs/2506.07102</link>
<guid>https://arxiv.org/abs/2506.07102</guid>
<content:encoded><![CDATA[
arXiv:2506.07102v1 Announce Type: new 
Abstract: Decentralized optimization is crucial for multi-agent systems, with significant concerns about communication efficiency and privacy. This paper explores the role of efficient communication in decentralized stochastic gradient descent algorithms for enhancing privacy preservation. We develop a novel algorithm that incorporates two key features: random agent activation and sparsified communication. Utilizing differential privacy, we demonstrate that these features reduce noise without sacrificing privacy, thereby amplifying the privacy guarantee and improving accuracy. Additionally, we analyze the convergence and the privacy-accuracy-communication trade-off of the proposed algorithm. Finally, we present experimental results to illustrate the effectiveness of our algorithm.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Translating Federated Learning Algorithms in Python into CSP Processes Using ChatGPT</title>
<link>https://arxiv.org/abs/2506.07173</link>
<guid>https://arxiv.org/abs/2506.07173</guid>
<content:encoded><![CDATA[
arXiv:2506.07173v1 Announce Type: new 
Abstract: The Python Testbed for Federated Learning Algorithms is a simple Python FL framework that is easy to use by ML&amp;AI developers who do not need to be professional programmers and is also amenable to LLMs. In the previous research, generic federated learning algorithms provided by this framework were manually translated into the CSP processes and algorithms' safety and liveness properties were automatically verified by the model checker PAT. In this paper, a simple translation process is introduced wherein the ChatGPT is used to automate the translation of the mentioned federated learning algorithms in Python into the corresponding CSP processes. Within the process, the minimality of the used context is estimated based on the feedback from ChatGPT. The proposed translation process was experimentally validated by successful translation (verified by the model checker PAT) of both generic centralized and decentralized federated learning algorithms.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments</title>
<link>https://arxiv.org/abs/2506.07232</link>
<guid>https://arxiv.org/abs/2506.07232</guid>
<content:encoded><![CDATA[
arXiv:2506.07232v1 Announce Type: new 
Abstract: Large language models (LLMs) possess extensive knowledge bases and strong reasoning capabilities, making them promising tools for complex, multi-agent planning in embodied environments. However, despite LLMs' advanced abilities and the sophisticated modular design of agentic methods, existing LLM-based planning algorithms remain limited by weak adaptation capabilities to multi-agent embodied scenarios. We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Inspired by centralized training with decentralized execution in multi-agent reinforcement learning, we propose a \textit{Learn as Individuals, Evolve as a Team (LIET)} paradigm for multi-agent LLMs adaptation. At the individual level, LLM agents learn a local utility function from exploratory datasets to better comprehend the embodied environment, which is then queried during test time to support informed decision-making. At the team level, LLM agents collaboratively and iteratively maintain and update a shared cooperation knowledge list based on new experiences, using it to guide more effective communication. By combining individual learning with team evolution, LIET enables comprehensive and flexible adaptation for LLM agents. Our experiments on Communicative Watch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate that LIET, instantiated with both LLaMA and GPT-4o, outperforms existing baselines and exhibits strong cooperative planning abilities.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Human Side of Smart Contract Fuzzing: An Empirical Study</title>
<link>https://arxiv.org/abs/2506.07389</link>
<guid>https://arxiv.org/abs/2506.07389</guid>
<content:encoded><![CDATA[
arXiv:2506.07389v1 Announce Type: new 
Abstract: Smart contract (SC) fuzzing is a critical technique for detecting vulnerabilities in blockchain applications. However, its adoption remains challenging for practitioners due to fundamental differences between SCs and traditional software systems. In this study, we investigate the challenges practitioners face when adopting SC fuzzing tools by conducting an inductive content analysis of 381 GitHub issues from two widely used SC fuzzers: Echidna and Foundry. Furthermore, we conducted a user study to examine how these challenges affect different practitioner groups, SC developers, and traditional software security professionals, and identify strategies practitioners use to overcome them. We systematically categorize these challenges into a taxonomy based on their nature and occurrence within the SC fuzzing workflow. Our findings reveal domain-specific ease-of-use and usefulness challenges, including technical issues with blockchain emulation, and human issues with a lack of accessible documentation and process automation. Our results provide actionable insights for tool developers and researchers, guiding future improvements in SC fuzzer tool design.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Energy-Efficient and Low-Latency Voice-Controlled Smart Homes: A Proposal for Offline Speech Recognition and IoT Integration</title>
<link>https://arxiv.org/abs/2506.07494</link>
<guid>https://arxiv.org/abs/2506.07494</guid>
<content:encoded><![CDATA[
arXiv:2506.07494v1 Announce Type: new 
Abstract: The smart home systems, based on AI speech recognition and IoT technology, enable people to control devices through verbal commands and make people's lives more efficient. However, existing AI speech recognition services are primarily deployed on cloud platforms on the Internet. When users issue a command, speech recognition devices like ``Amazon Echo'' will post a recording through numerous network nodes, reach multiple servers, and then receive responses through the Internet. This mechanism presents several issues, including unnecessary energy consumption, communication latency, and the risk of a single-point failure. In this position paper, we propose a smart home concept based on offline speech recognition and IoT technology: 1) integrating offline keyword spotting (KWS) technologies into household appliances with limited resource hardware to enable them to understand user voice commands; 2) designing a local IoT network with decentralized architecture to manage and connect various devices, enhancing the robustness and scalability of the system. This proposal of a smart home based on offline speech recognition and IoT technology will allow users to use low-latency voice control anywhere in the home without depending on the Internet and provide better scalability and energy sustainability.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information</title>
<link>https://arxiv.org/abs/2506.07829</link>
<guid>https://arxiv.org/abs/2506.07829</guid>
<content:encoded><![CDATA[
arXiv:2506.07829v1 Announce Type: new 
Abstract: Reinforcement learning (RL) algorithms can find an optimal policy for a single agent to accomplish a particular task. However, many real-world problems require multiple agents to collaborate in order to achieve a common goal. For example, a robot executing a task in a warehouse may require the assistance of a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL (DMARL), agents learn independently and then combine their policies at execution time, but often must satisfy constraints on compatibility of local policies to ensure that they can achieve the global task when combined. In this paper, we study how providing high-level symbolic knowledge to agents can help address unique challenges of this setting, such as privacy constraints, communication limitations, and performance concerns. In particular, we extend the formal tools used to check the compatibility of local policies with the team task, making decentralized training with theoretical guarantees usable in more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge about the temporal evolution of events in the environment can significantly expedite the learning process in DMARL.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exposing Hidden Backdoors in NFT Smart Contracts: A Static Security Analysis of Rug Pull Patterns</title>
<link>https://arxiv.org/abs/2506.07974</link>
<guid>https://arxiv.org/abs/2506.07974</guid>
<content:encoded><![CDATA[
arXiv:2506.07974v1 Announce Type: new 
Abstract: The explosive growth of Non-Fungible Tokens (NFTs) has revolutionized digital ownership by enabling the creation, exchange, and monetization of unique assets on blockchain networks. However, this surge in popularity has also given rise to a disturbing trend: the emergence of rug pulls - fraudulent schemes where developers exploit trust and smart contract privileges to drain user funds or invalidate asset ownership. Central to many of these scams are hidden backdoors embedded within NFT smart contracts. Unlike unintentional bugs, these backdoors are deliberately coded and often obfuscated to bypass traditional audits and exploit investor confidence. In this paper, we present a large-scale static analysis of 49,940 verified NFT smart contracts using Slither, a static analysis framework, to uncover latent vulnerabilities commonly linked to rug pulls. We introduce a custom risk scoring model that classifies contracts into high, medium, or low risk tiers based on the presence and severity of rug pull indicators. Our dataset was derived from verified contracts on the Ethereum mainnet, and we generate multiple visualizations to highlight red flag clusters, issue prevalence, and co-occurrence of critical vulnerabilities. While we do not perform live exploits, our results reveal how malicious patterns often missed by simple reviews can be surfaced through static analysis at scale. We conclude by offering mitigation strategies for developers, marketplaces, and auditors to enhance smart contract security. By exposing how hidden backdoors manifest in real-world smart contracts, this work contributes a practical foundation for detecting and mitigating NFT rug pulls through scalable automated analysis.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unraveling Ethereum's Mempool: The Impact of Fee Fairness, Transaction Prioritization, and Consensus Efficiency</title>
<link>https://arxiv.org/abs/2506.07988</link>
<guid>https://arxiv.org/abs/2506.07988</guid>
<content:encoded><![CDATA[
arXiv:2506.07988v1 Announce Type: new 
Abstract: Ethereum's transaction pool (mempool) dynamics and fee market efficiency critically affect transaction inclusion, validator workload, and overall network performance. This research empirically analyzes gas price variations, mempool clearance rates, and block finalization times in Ethereum's proof-of-stake ecosystem using real-time data from Geth and Prysm nodes. We observe that high-fee transactions are consistently prioritized, while low-fee transactions face delays or exclusion despite EIP-1559's intended improvements. Mempool congestion remains a key factor in validator efficiency and proposal latency. We provide empirical evidence of persistent fee-based disparities and show that extremely high fees do not always guarantee faster confirmation, revealing inefficiencies in the current fee market. To address these issues, we propose congestion-aware fee adjustments, reserved block slots for low-fee transactions, and improved handling of out-of-gas vulnerabilities. By mitigating prioritization bias and execution inefficiencies, our findings support more equitable transaction inclusion, enhance validator performance, and promote scalability. This work contributes to Ethereum's long-term decentralization by reducing dependence on high transaction fees for network participation.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Optimization on Compact Submanifolds by Quantized Riemannian Gradient Tracking</title>
<link>https://arxiv.org/abs/2506.07351</link>
<guid>https://arxiv.org/abs/2506.07351</guid>
<content:encoded><![CDATA[
arXiv:2506.07351v1 Announce Type: cross 
Abstract: This paper considers the problem of decentralized optimization on compact submanifolds, where a finite sum of smooth (possibly non-convex) local functions is minimized by $n$ agents forming an undirected and connected graph. However, the efficiency of distributed optimization is often hindered by communication bottlenecks. To mitigate this, we propose the Quantized Riemannian Gradient Tracking (Q-RGT) algorithm, where agents update their local variables using quantized gradients. The introduction of quantization noise allows our algorithm to bypass the constraints of the accurate Riemannian projection operator (such as retraction), further improving iterative efficiency. To the best of our knowledge, this is the first algorithm to achieve an $\mathcal{O}(1/K)$ convergence rate in the presence of quantization, matching the convergence rate of methods without quantization. Additionally, we explicitly derive lower bounds on decentralized consensus associated with a function of quantization levels. Numerical experiments demonstrate that Q-RGT performs comparably to non-quantized methods while reducing communication bottlenecks and computational overhead.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models</title>
<link>https://arxiv.org/abs/2409.06277</link>
<guid>https://arxiv.org/abs/2409.06277</guid>
<content:encoded><![CDATA[
arXiv:2409.06277v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have become indispensable in numerous real-world applications. However, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical, presents significant challenges. Existing approaches often resort to parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but this typically comes at the cost of model accuracy. To this end, we propose federated full-parameter tuning at scale for LLMs (Ferret), the first first-order method with shared randomness to enable scalable full-parameter tuning of LLMs across decentralized data sources while maintaining competitive model accuracy. Ferret accomplishes this through three aspects: (i) it employs widely used first-order methods for efficient local updates; (ii) it projects these updates into a low-dimensional space to considerably reduce communication overhead; and (iii) it reconstructs local updates from this low-dimensional space with shared randomness to facilitate effective full-parameter global aggregation, ensuring fast convergence and competitive final performance. Our rigorous theoretical analyses and insights along with extensive experiments, show that Ferret significantly enhances the scalability of existing federated full-parameter tuning approaches by achieving high computational efficiency, reduced communication overhead, and fast convergence, all while maintaining competitive model accuracy. Our implementation is available at https://github.com/allen4747/Ferret.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Defending Against Diverse Attacks in Federated Learning Through Consensus-Based Bi-Level Optimization</title>
<link>https://arxiv.org/abs/2412.02535</link>
<guid>https://arxiv.org/abs/2412.02535</guid>
<content:encoded><![CDATA[
arXiv:2412.02535v2 Announce Type: replace 
Abstract: Adversarial attacks pose significant challenges in many machine learning applications, particularly in the setting of distributed training and federated learning, where malicious agents seek to corrupt the training process with the goal of jeopardizing and compromising the performance and reliability of the final models. In this paper, we address the problem of robust federated learning in the presence of such attacks by formulating the training task as a bi-level optimization problem. We conduct a theoretical analysis of the resilience of consensus-based bi-level optimization (CB$^2$O), an interacting multi-particle metaheuristic optimization method, in adversarial settings. Specifically, we provide a global convergence analysis of CB$^2$O in mean-field law in the presence of malicious agents, demonstrating the robustness of CB$^2$O against a diverse range of attacks. Thereby, we offer insights into how specific hyperparameter choices enable to mitigate adversarial effects. On the practical side, we extend CB$^2$O to the clustered federated learning setting by proposing FedCB$^2$O, a novel interacting multi-particle system, and design a practical algorithm that addresses the demands of real-world applications. Extensive experiments demonstrate the robustness of the FedCB$^2$O algorithm against label-flipping attacks in decentralized clustered federated learning scenarios, showcasing its effectiveness in practical contexts.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tackling Feature and Sample Heterogeneity in Decentralized Multi-Task Learning: A Sheaf-Theoretic Approach</title>
<link>https://arxiv.org/abs/2502.01145</link>
<guid>https://arxiv.org/abs/2502.01145</guid>
<content:encoded><![CDATA[
arXiv:2502.01145v2 Announce Type: replace 
Abstract: Federated multi-task learning (FMTL) aims to simultaneously learn multiple related tasks across clients without sharing sensitive raw data. However, in the decentralized setting, existing FMTL frameworks are limited in their ability to capture complex task relationships and handle feature and sample heterogeneity across clients. To address these challenges, we introduce a novel sheaf-theoretic-based approach for FMTL. By representing client relationships using cellular sheaves, our framework can flexibly model interactions between heterogeneous client models. We formulate the sheaf-based FMTL optimization problem using sheaf Laplacian regularization and propose the Sheaf-FMTL algorithm to solve it. We show that the proposed framework provides a unified view encompassing many existing federated learning (FL) and FMTL approaches. Furthermore, we prove that our proposed algorithm, Sheaf-FMTL, achieves a sublinear convergence rate in line with state-of-the-art decentralized FMTL algorithms. Extensive experiments show that although Sheaf-FMTL introduces computational and storage overhead due to the management of interaction maps, it achieves substantial communication savings in terms of transmitted bits when compared to decentralized FMTL baselines. This trade-off makes Sheaf-FMTL especially suitable for cross-silo FL scenarios, where managing model heterogeneity and ensuring communication efficiency are essential, and where clients have adequate computational resources.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Trust Mobility-Aware Authentication Framework for Secure Vehicular Fog Computing Networks</title>
<link>https://arxiv.org/abs/2506.05355</link>
<guid>https://arxiv.org/abs/2506.05355</guid>
<content:encoded><![CDATA[
arXiv:2506.05355v1 Announce Type: new 
Abstract: Vehicular Fog Computing (VFC) is a promising paradigm to meet the low-latency and high-bandwidth demands of Intelligent Transportation Systems (ITS). However, dynamic vehicle mobility and diverse trust boundaries introduce critical security challenges. This paper presents a novel Zero-Trust Mobility-Aware Authentication Framework (ZTMAF) for secure communication in VFC networks. The framework employs context-aware authentication with lightweight cryptographic primitives, a decentralized trust evaluation system, and fog node-assisted session validation to combat spoofing, replay, and impersonation attacks. Simulation results on NS-3 and SUMO demonstrate improved authentication latency, reduced computational overhead, and better scalability compared to traditional PKI and blockchain-based models. Our findings suggest that ZTMAF is effective for secure, real-time V2X interactions under adversarial and mobility-variant scenarios.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding Community-Level Blocklists in Decentralized Social Media</title>
<link>https://arxiv.org/abs/2506.05522</link>
<guid>https://arxiv.org/abs/2506.05522</guid>
<content:encoded><![CDATA[
arXiv:2506.05522v1 Announce Type: new 
Abstract: Community-level blocklists are key to content moderation practices in decentralized social media. These blocklists enable moderators to prevent other communities, such as those acting in bad faith, from interacting with their own -- and, if shared publicly, warn others about communities worth blocking. Prior work has examined blocklists in centralized social media, noting their potential for collective moderation outcomes, but has focused on blocklists as individual-level tools. To understand how moderators perceive and utilize community-level blocklists and what additional support they may need, we examine social media communities running Mastodon, an open-source microblogging software built on the ActivityPub protocol. We conducted (1) content analysis of the community-level blocklist ecosystem, and (2) semi-structured interviews with twelve Mastodon moderators. Our content analysis revealed wide variation in blocklist goals, inclusion criteria, and transparency. Interviews showed moderators balance proactive safety, reactive practices, and caution around false positives when using blocklists for moderation. They noted challenges and limitations in current blocklist use, suggesting design improvements like comment receipts, category filters, and collaborative voting. We discuss implications for decentralized content moderation, highlighting trade-offs between openness, safety, and nuance; the complexity of moderator roles; and opportunities for future design.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts</title>
<link>https://arxiv.org/abs/2506.05577</link>
<guid>https://arxiv.org/abs/2506.05577</guid>
<content:encoded><![CDATA[
arXiv:2506.05577v1 Announce Type: new 
Abstract: Agentic AI has gained significant interest as a research paradigm focused on autonomy, self-directed learning, and long-term reliability of decision making. Real-world agentic systems operate in decentralized settings on a large set of tasks or data distributions with constraints such as limited bandwidth, asynchronous execution, and the absence of a centralized model or even common objectives. We posit that exploiting previously learned skills, task similarities, and communication capabilities in a collective of agentic AI are challenging but essential elements to enabling scalability, open-endedness, and beneficial collaborative learning dynamics. In this paper, we introduce Modular Sharing and Composition in Collective Learning (MOSAIC), an agentic algorithm that allows multiple agents to independently solve different tasks while also identifying, sharing, and reusing useful machine-learned knowledge, without coordination, synchronization, or centralized control. MOSAIC combines three mechanisms: (1) modular policy composition via neural network masks, (2) cosine similarity estimation using Wasserstein embeddings for knowledge selection, and (3) asynchronous communication and policy integration. Results on a set of RL benchmarks show that MOSAIC has a greater sample efficiency than isolated learners, i.e., it learns significantly faster, and in some cases, finds solutions to tasks that cannot be solved by isolated learners. The collaborative learning and sharing dynamics are also observed to result in the emergence of ideal curricula of tasks, from easy to hard. These findings support the case for collaborative learning in agentic systems to achieve better and continuously evolving performance both at the individual and collective levels.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedShield-LLM: A Secure and Scalable Federated Fine-Tuned Large Language Model</title>
<link>https://arxiv.org/abs/2506.05640</link>
<guid>https://arxiv.org/abs/2506.05640</guid>
<content:encoded><![CDATA[
arXiv:2506.05640v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized framework for training and fine-tuning Large Language Models (LLMs) by leveraging computational resources across organizations while keeping sensitive data on local devices. It addresses privacy and security concerns while navigating challenges associated with the substantial computational demands of LLMs, which can be prohibitive for small and medium-sized organizations. FL supports the development of task-specific LLMs for cross-silo applications through fine-tuning but remains vulnerable to inference attacks, such as membership inference and gradient inversion, which threaten data privacy. Prior studies have utilized Differential Privacy (DP) in LLM fine-tuning, which, despite being effective at preserving privacy, can degrade model performance. To overcome these challenges, we propose a novel method, FedShield-LLM, that uses pruning with Fully Homomorphic Encryption (FHE) for Low-Rank Adaptation (LoRA) parameters, enabling secure computations on encrypted model updates while mitigating the attack surface by deactivating less important LoRA parameters. Furthermore, optimized federated algorithms for cross-silo environments enhance scalability and efficiency. Parameter-efficient fine-tuning techniques like LoRA substantially reduce computational and communication overhead, making FL feasible for resource-constrained clients. Experimental results show that the proposed method outperforms existing methods while maintaining robust privacy protection, enabling organizations to collaboratively train secure and efficient LLMs.
  The code and data are available at, https://github.com/solidlabnetwork/fedshield-llm
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Stabilization Protocol for Cross-Chain Digital Assets Using Adaptor Signatures and AI-Driven Arbitrage</title>
<link>https://arxiv.org/abs/2506.05708</link>
<guid>https://arxiv.org/abs/2506.05708</guid>
<content:encoded><![CDATA[
arXiv:2506.05708v1 Announce Type: new 
Abstract: Stablecoins face an unresolved trilemma of balancing decentralization, stability, and regulatory compliance. We present a hybrid stabilization protocol that combines crypto-collateralized reserves, algorithmic futures contracts, and cross-chain liquidity pools to achieve robust price adherence while preserving user privacy. At its core, the protocol introduces stabilization futures contracts (SFCs), non-collateralized derivatives that programmatically incentivize third-party arbitrageurs to counteract price deviations via adaptor signature atomic swaps. Autonomous AI agents optimize delta hedging across decentralized exchanges (DEXs), while zkSNARKs prove compliance with anti-money laundering (AML) regulations without exposing identities or transaction details. Our cryptographic design reduces cross-chain liquidity concentration (Herfindahl-Hirschman Index: 2,400 vs. 4,900 in single-chain systems) and ensures atomicity under standard cryptographic assumptions. The protocol's layered architecture encompassing incentive-compatible SFCs, AI-driven market making, and zero-knowledge regulatory proofs. It provides a blueprint for next-generation decentralized financial infrastructure.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploiting Similarity for Computation and Communication-Efficient Decentralized Optimization</title>
<link>https://arxiv.org/abs/2506.05791</link>
<guid>https://arxiv.org/abs/2506.05791</guid>
<content:encoded><![CDATA[
arXiv:2506.05791v1 Announce Type: new 
Abstract: Reducing communication complexity is critical for efficient decentralized optimization. The proximal decentralized optimization (PDO) framework is particularly appealing, as methods within this framework can exploit functional similarity among nodes to reduce communication rounds. Specifically, when local functions at different nodes are similar, these methods achieve faster convergence with fewer communication steps. However, existing PDO methods often require highly accurate solutions to subproblems associated with the proximal operator, resulting in significant computational overhead. In this work, we propose the Stabilized Proximal Decentralized Optimization (SPDO) method, which achieves state-of-the-art communication and computational complexities within the PDO framework. Additionally, we refine the analysis of existing PDO methods by relaxing subproblem accuracy requirements and leveraging average functional similarity. Experimental results demonstrate that SPDO significantly outperforms existing methods.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Properties of UTxO Ledgers and Programs Implemented on Them</title>
<link>https://arxiv.org/abs/2506.05832</link>
<guid>https://arxiv.org/abs/2506.05832</guid>
<content:encoded><![CDATA[
arXiv:2506.05832v1 Announce Type: new 
Abstract: Trace-based properties are the gold standard for program behaviour analysis. One of the domains of application of this type of analysis is cryptocurrency ledgers, both for the purpose of analyzing the behaviour of the ledger itself, and any user-defined programs called by it, known as smart contracts. The (extended) UTxO ledger model is a kind of ledger model where all smart contract code is stateless, and additional work must be done to model stateful programs. We formalize the application of trace-based analysis to UTxO ledgers and contracts, expressing it in the languages of topology, as well as graph and category theory. To describe valid traces of UTxO ledger executions, and their relation to the behaviour of stateful programs implemented on the ledger, we define a category of simple graphs, infinite paths in which form an ultra-metric space. Maps in this category are arbitrary partial sieve-define homomorphisms of simple graphs. Programs implemented on the ledger correspond to non-expanding maps out of the graph of valid UTxO execution traces. We reason about safety properties in this framework, and prove properties of valid UTxO ledger traces.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Combating Reentrancy Bugs on Sharded Blockchains</title>
<link>https://arxiv.org/abs/2506.05932</link>
<guid>https://arxiv.org/abs/2506.05932</guid>
<content:encoded><![CDATA[
arXiv:2506.05932v1 Announce Type: new 
Abstract: Reentrancy is a well-known source of smart contract bugs on Ethereum, leading e.g. to double-spending vulnerabilities in DeFi applications. But less is known about this problem in other blockchains, which can have significantly different execution models. Sharded blockchains in particular generally use an asynchronous messaging model that differs substantially from the synchronous and transactional model of Ethereum. We study the features of this model and its effect on reentrancy bugs on three examples: the Internet Computer (ICP) blockchain, NEAR Protocol, and MultiversX. We argue that this model, while useful for improving performance, also makes it easier to introduce reentrancy bugs. For example, reviews of the pre-production versions of some of the most critical ICP smart contracts found that 66% (10/15) of the reviewed contracts -- written by expert authors -- contained reentrancy bugs of medium or high severity, with potential damages in tens of millions of dollars. We evaluate existing Ethereum programming techniques (in particular the effects-checks-interactions pattern, and locking) to prevent reentrancy bugs in the context of this new messaging model and identify some issues with them. We then present novel Rust and Motoko patterns that can be leveraged on ICP to solve these issues. Finally, we demonstrate that the formal verification tool TLA+ can be used to find and eliminate such bugs in real world smart contracts on sharded blockchains.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Consensus for Fair Message Ordering</title>
<link>https://arxiv.org/abs/2411.09981</link>
<guid>https://arxiv.org/abs/2411.09981</guid>
<content:encoded><![CDATA[
arXiv:2411.09981v3 Announce Type: replace 
Abstract: Distributed ledger systems, such as blockchains, rely on consensus protocols that commit ordered messages for processing. In practice, message ordering within these systems is often reward-driven. This raises concerns about fairness, particularly in decentralized finance applications, where nodes can exploit transaction orders to maximize rewards referred to as Maximal Extractable Value. This paper provides a systematic understanding of consensus protocols that order messages with different approaches, especially focusing on the ones that promote order fairness, using methods including First-In-First-Out (FIFO), random, and blind ordering. We review the challenges and trade-offs of deriving fair message ordering in a Byzantine fault-tolerant setting, and summarize the requirements for making a fair message ordering consensus protocol. We introduce a design guideline, with which we propose a latency optimization to the state-of-the-art FIFO ordering protocol of Themis. This work provides a systematic way for assessing and enhancing message order fairness in blockchain systems.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs</title>
<link>https://arxiv.org/abs/2506.04236</link>
<guid>https://arxiv.org/abs/2506.04236</guid>
<content:encoded><![CDATA[
arXiv:2506.04236v1 Announce Type: new 
Abstract: In Artificial Life (ALife) research, replicating Open-Ended Evolution (OEE)-the continuous emergence of novelty observed in biological life-has traditionally been pursued within isolated closed system simulations, such as Tierra and Avida, which have typically plateaued after an initial burst of novelty, failing to achieve sustained OEE. Scholars suggest that OEE requires an "open" system that continually exchanges information or energy with its environment. A recent technological innovation in decentralized physical infrastructure networks (DePIN) providing permissionless computational substrates enables deploying large language model (LLM)-based AI agents on blockchains integrated with Trusted Execution Environments (TEEs). This enables on-chain agents to operate autonomously "in the wild," achieving self-sovereignty without human oversight. These agents can control their own social media accounts and cryptocurrency wallets, allowing them to interact directly with blockchain-based financial networks and broader human social media. Building on this new paradigm of on-chain agents, Spore.fun is a recent real-world AI evolution experiment that enables autonomous breeding and evolution of new on-chain agents. This paper presents a detailed case study of Spore.fun, examining agent behaviors and their evolutionary trajectories through digital ethology. We aim to spark discussion about whether "open" ALife systems "in-the-wild," based on permissionless computational substrates and driven by economic incentives to interact with their environment, could finally achieve the long-sought goal of OEE.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hello, won't you tell me your name?: Investigating Anonymity Abuse in IPFS</title>
<link>https://arxiv.org/abs/2506.04307</link>
<guid>https://arxiv.org/abs/2506.04307</guid>
<content:encoded><![CDATA[
arXiv:2506.04307v1 Announce Type: new 
Abstract: The InterPlanetary File System~(IPFS) offers a decentralized approach to file storage and sharing, promising resilience and efficiency while also realizing the Web3 paradigm. Simultaneously, the offered anonymity raises significant questions about potential misuse. In this study, we explore methods that malicious actors can exploit IPFS to upload and disseminate harmful content while remaining anonymous. We evaluate the role of pinning services and public gateways, identifying their capabilities and limitations in maintaining content availability. Using scripts, we systematically test the behavior of these services by uploading malicious files. Our analysis reveals that pinning services and public gateways lack mechanisms to assess or restrict the propagation of malicious content.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Theory of Decentralized Robust Kernel-Based Learning Algorithm</title>
<link>https://arxiv.org/abs/2506.05215</link>
<guid>https://arxiv.org/abs/2506.05215</guid>
<content:encoded><![CDATA[
arXiv:2506.05215v1 Announce Type: new 
Abstract: We propose a new decentralized robust kernel-based learning algorithm within the framework of reproducing kernel Hilbert space (RKHS) by utilizing a networked system that can be represented as a connected graph. The robust loss function $\mathcal{L}_\sigma$ induced by a windowing function $W$ and a robustness scaling parameter $\sigma>0$, can encompass a broad spectrum of robust losses. Consequently, the proposed algorithm effectively provides a unified decentralized learning framework for robust regression, which fundamentally differs from the existing distributed robust kernel learning schemes, all of which are divide-and-conquer based. We rigorously establish the learning theory and offer a comprehensive convergence analysis for the algorithm. We show each local robust estimator generated from the decentralized algorithm can be utilized to approximate the regression function. Based on kernel-based integral operator techniques, we derive general high confidence convergence bounds for each local approximating sequence in terms of the mean square distance, RKHS norm, and generalization error, respectively. Moreover, we provide rigorous selection rules for local sample size and show that, under properly selected step size and scaling parameter $\sigma$, the decentralized robust algorithm can achieve optimal learning rates (up to logarithmic factors) in both norms. The parameter $\sigma$ is shown to be essential for enhancing robustness while also ensuring favorable convergence behavior. The intrinsic connection among decentralization, sample selection, robustness of the algorithm, and its convergence is clearly reflected.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Becoming Immutable: How Ethereum is Made</title>
<link>https://arxiv.org/abs/2506.04940</link>
<guid>https://arxiv.org/abs/2506.04940</guid>
<content:encoded><![CDATA[
arXiv:2506.04940v1 Announce Type: cross 
Abstract: We analyze blocks proposed for inclusion in the Ethereum blockchain during 8 minutes on December 3rd, 2024. Our dataset comprises 38 winning blocks, 15,097 proposed blocks, 10,793 unique transactions, and 2,380,014 transaction-block pairings. We find that exclusive transactions--transactions present only in blocks proposed by a single builder--account for 85% of the fees paid by all transactions included in winning blocks. We also find that a surprisingly large number of user transactions are delayed: although proposed during a bidding cycle, they are not included in the corresponding winning block. Many such delayed transactions are exclusive to a losing builder. We also identify two arbitrage bots trading between decentralized (DEX) and centralized exchanges (CEX). By examining their bidding dynamics, we estimate that the implied price at which these bots trade USDC/WETH and USDT/WETH on CEXes is between 3.4 and 4.2 basis points better than the contemporaneous price reported on Binance.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Two-agent Motion Planning Strategies from Generalized Nash Equilibrium for Model Predictive Control</title>
<link>https://arxiv.org/abs/2411.13983</link>
<guid>https://arxiv.org/abs/2411.13983</guid>
<content:encoded><![CDATA[
arXiv:2411.13983v4 Announce Type: replace 
Abstract: We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized algorithm for two-agent motion planning that uses a learned value function that predicts the game-theoretic interaction outcomes as the terminal cost-to-go function in a model predictive control (MPC) framework, guiding agents to implicitly account for interactions with other agents and maximize their reward. This approach applies to competitive and cooperative multi-agent motion planning problems which we formulate as constrained dynamic games. Given a constrained dynamic game, we randomly sample initial conditions and solve for the generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions, computing the reward outcome of each game-theoretic interaction from the GNE. The data is used to train a simple neural network to predict the reward outcome, which we use as the terminal cost-to-go function in an MPC scheme. We showcase emerging competitive and coordinated behaviors using IGT-MPC in scenarios such as two-vehicle head-to-head racing and un-signalized intersection navigation. IGT-MPC offers a novel method integrating machine learning and game-theoretic reasoning into model-based decentralized multi-agent motion planning.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning</title>
<link>https://arxiv.org/abs/2501.12911</link>
<guid>https://arxiv.org/abs/2501.12911</guid>
<content:encoded><![CDATA[
arXiv:2501.12911v4 Announce Type: replace 
Abstract: Federated learning (FL) has come forward as a critical approach for privacy-preserving machine learning in healthcare, allowing collaborative model training across decentralized medical datasets without exchanging clients' data. However, current security implementations for these systems face a fundamental trade-off: rigorous cryptographic protections like fully homomorphic encryption (FHE) impose prohibitive computational overhead, while lightweight alternatives risk vulnerable data leakage through model updates. To address this issue, we present FAS (Fast and Secure Federated Learning), a novel approach that strategically combines selective homomorphic encryption, differential privacy, and bitwise scrambling to achieve robust security without compromising practical usability. Our approach eliminates the need for model pretraining phases while dynamically protecting high-risk model parameters through layered encryption and obfuscation. We implemented FAS using the Flower framework and evaluated it on a cluster of eleven physical machines. Our approach was up to 90\% faster than applying FHE on the model weights. In addition, we eliminated the computational overhead that is required by competitors such as FedML-HE and MaskCrypt. Our approach was up to 1.5$\times$ faster than the competitors while achieving comparable security results.
  Experimental evaluations on medical imaging datasets confirm that FAS maintains similar security results to conventional FHE against gradient inversion attacks while preserving diagnostic model accuracy. These results position FAS as a practical solution for latency-sensitive healthcare applications where both privacy preservation and computational efficiency are requirements.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fingerprinting Deep Learning Models via Network Traffic Patterns in Federated Learning</title>
<link>https://arxiv.org/abs/2506.03207</link>
<guid>https://arxiv.org/abs/2506.03207</guid>
<content:encoded><![CDATA[
arXiv:2506.03207v1 Announce Type: new 
Abstract: Federated Learning (FL) is increasingly adopted as a decentralized machine learning paradigm due to its capability to preserve data privacy by training models without centralizing user data. However, FL is susceptible to indirect privacy breaches via network traffic analysis-an area not explored in existing research. The primary objective of this research is to study the feasibility of fingerprinting deep learning models deployed within FL environments by analyzing their network-layer traffic information. In this paper, we conduct an experimental evaluation using various deep learning architectures (i.e., CNN, RNN) within a federated learning testbed. We utilize machine learning algorithms, including Support Vector Machines (SVM), Random Forest, and Gradient-Boosting, to fingerprint unique patterns within the traffic data. Our experiments show high fingerprinting accuracy, achieving 100% accuracy using Random Forest and around 95.7% accuracy using SVM and Gradient Boosting classifiers. This analysis suggests that we can identify specific architectures running within the subsection of the network traffic. Hence, if an adversary knows about the underlying DL architecture, they can exploit that information and conduct targeted attacks. These findings suggest a notable security vulnerability in FL systems and the necessity of strengthening it at the network level.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity</title>
<link>https://arxiv.org/abs/2506.03337</link>
<guid>https://arxiv.org/abs/2506.03337</guid>
<content:encoded><![CDATA[
arXiv:2506.03337v1 Announce Type: new 
Abstract: Federated Learning enables collaborative fine-tuning of Large Language Models (LLMs) across decentralized Non-Independent and Identically Distributed (Non-IID) clients, but such models' massive parameter sizes lead to significant memory and communication challenges. This work introduces Meerkat, a sparse zeroth-order optimization (ZO) method designed for federated LLM fine-tuning. By limiting fine-tuning to a transferable, static, extremely sparse subset of parameters, Meerkat achieves remarkable communication efficiency, enabling cost-effective high-frequency synchronization. With theoretical analysis and experiments, we show that this high-frequency communication effectively mitigates Non-IID data challenges and leads to superior performance compared to full-parameter ZO. Furthermore, experiment results show that Meerkat outperforms existing sparsity baselines with better performance at the same communication frequency. To further handle Non-IID drift, Meerkat leverages traceable local updates and forms a virtual path for each client. This virtual path mechanism reveals the GradIP phenomenon: the inner products between LLM pre-training gradients maintained by server and client gradients estimated via ZO converges for extreme Non-IID clients but oscillates for IID ones. This distinct behavior provides a signal for identifying clients with extreme data heterogeneity. Using this signal, Meerkat-vp is proposed to analyze GradIP trajectories to identify extreme Non-IID clients and applies early stopping to enhance aggregated model quality. Experiments confirm that Meerkat and Meerkat-vp significantly improve the efficiency and effectiveness of ZO federated LLM fine-tuning.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dropout-Robust Mechanisms for Differentially Private and Fully Decentralized Mean Estimation</title>
<link>https://arxiv.org/abs/2506.03746</link>
<guid>https://arxiv.org/abs/2506.03746</guid>
<content:encoded><![CDATA[
arXiv:2506.03746v1 Announce Type: new 
Abstract: Achieving differentially private computations in decentralized settings poses significant challenges, particularly regarding accuracy, communication cost, and robustness against information leakage. While cryptographic solutions offer promise, they often suffer from high communication overhead or require centralization in the presence of network failures. Conversely, existing fully decentralized approaches typically rely on relaxed adversarial models or pairwise noise cancellation, the latter suffering from substantial accuracy degradation if parties unexpectedly disconnect. In this work, we propose IncA, a new protocol for fully decentralized mean estimation, a widely used primitive in data-intensive processing. Our protocol, which enforces differential privacy, requires no central orchestration and employs low-variance correlated noise, achieved by incrementally injecting sensitive information into the computation. First, we theoretically demonstrate that, when no parties permanently disconnect, our protocol achieves accuracy comparable to that of a centralized setting-already an improvement over most existing decentralized differentially private techniques. Second, we empirically show that our use of low-variance correlated noise significantly mitigates the accuracy loss experienced by existing techniques in the presence of dropouts.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Mechanism to Support Trade Transactions in Smart Contracts with Upgrade and Repair</title>
<link>https://arxiv.org/abs/2506.03877</link>
<guid>https://arxiv.org/abs/2506.03877</guid>
<content:encoded><![CDATA[
arXiv:2506.03877v1 Announce Type: new 
Abstract: In our previous research, we addressed the problem of automated transformation of models, represented using the business process model and notation (BPMN) standard, into the methods of a smart contract. The transformation supports BPMN models that contain complex multi-step activities that are supported using our concept of multi-step nested trade transactions, wherein the transactional properties are enforced by a mechanism generated automatically by the transformation process from a BPMN model to a smart contract. In this paper, we present a methodology for repairing a smart contract that cannot be completed due to events that were not anticipated by the developer and thus prevent the completion of the smart contract. The repair process starts with the original BPMN model fragment causing the issue, providing the modeler with the innermost transaction fragment containing the failed activity. The modeler amends the BPMN pattern on the basis of successful completion of previous activities. If repairs exceed the inner transaction's scope, they are addressed using the parent transaction's BPMN model. The amended BPMN model is then transformed into a new smart contract, ensuring consistent data and logic transitions. We previously developed a tool, called TABS+, as a proof of concept (PoC) to transform BPMN models into smart contracts for nested transactions. This paper describes the tool TABS+R, developed by extending the TABS+ tool, to allow the repair of smart contracts.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Solsmith: Solidity Random Program Generator for Compiler Testing</title>
<link>https://arxiv.org/abs/2506.03909</link>
<guid>https://arxiv.org/abs/2506.03909</guid>
<content:encoded><![CDATA[
arXiv:2506.03909v1 Announce Type: new 
Abstract: Smart contracts are computer programs that run on blockchain platforms, with Solidity being the most widely used language for their development. As blockchain technology advances, smart contracts have become increasingly important across various fields. In order for smart contracts to operate correctly, the correctness of the compiler is particularly crucial. Although some research efforts have been devoted to testing Solidity compilers, they primarily focus on testing methods and do not address the core issue of generating test programs. To fill this gap, this paper designs and implements Solsmith, a test program generator specifically aimed at uncovering defects in Solidity compilers. It tests the compiler correctness by generating valid and diverse Solidity programs. We have designed a series of unique program generation strategies tailored to Solidity, including enabling optimizations more frequently, avoiding undefined behaviour, and mitigating behavioural differences caused by intermediate representations. To validate the effectiveness of Solsmith, we assess the effectiveness of the test programs generated by Solsmith using the approach of differential testing. The preliminary results show that Solsmith can generate the expected test programs and uncover four confirmed defects in Solidity compilers, demonstrating the effectiveness and potential of Solsmith.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Depermissioning Web3: a Permissionless Accountable RPC Protocol for Blockchain Networks</title>
<link>https://arxiv.org/abs/2506.03940</link>
<guid>https://arxiv.org/abs/2506.03940</guid>
<content:encoded><![CDATA[
arXiv:2506.03940v1 Announce Type: new 
Abstract: In blockchain networks, so-called "full nodes" serve data to and relay transactions from clients through an RPC interface. This serving layer enables integration of "Web3" data, stored on blockchains, with "Web2" mobile or web applications that cannot directly participate as peers in a blockchain network. In practice, the serving layer is dominated by a small number of centralized services ("node providers") that offer permissioned access to RPC endpoints. Clients register with these providers because they offer reliable and convenient access to blockchain data: operating a full node themselves requires significant computational and storage resources, and public (permissionless) RPC nodes lack financial incentives to serve large numbers of clients with consistent performance.
  Permissioned access to an otherwise permissionless blockchain network raises concerns regarding the privacy, integrity, and availability of data access. To address this, we propose a Permissionless Accountable RPC Protocol (PARP). It enables clients and full nodes to interact pseudonymously while keeping both parties accountable. PARP leverages "light client" schemes for essential data integrity checks, combined with fraud proofs, to keep full nodes honest and accountable. It integrates payment channels to facilitate micro-payments, holding clients accountable for the resources they consume and providing an economic incentive for full nodes to serve. Our prototype implementation for Ethereum demonstrates the feasibility of PARP, and we quantify its overhead compared to the base RPC protocol.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How To Save Fees in Bitcoin Smart Contracts: a Simple Optimistic Off-chain Protocol</title>
<link>https://arxiv.org/abs/2403.09880</link>
<guid>https://arxiv.org/abs/2403.09880</guid>
<content:encoded><![CDATA[
arXiv:2403.09880v4 Announce Type: replace 
Abstract: We consider the execution of smart contracts on Bitcoin. There, every contract step corresponds to appending to the blockchain a new transaction that spends the output representing the old contract state, creating a new one for the updated state. This standard procedure requires the contract participants to pay transaction fees for every execution step. In this paper, we introduce a protocol that moves most of the execution of a Bitcoin contract off-chain. When all participants follow this protocol, they are able to save on transaction fees, drastically reducing them. By contrast, whenever adversaries try to disrupt the off-chain execution, any honest participant is still able to enforce the correct contract behaviour, by continuing its execution on-chain.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2411.07161</link>
<guid>https://arxiv.org/abs/2411.07161</guid>
<content:encoded><![CDATA[
arXiv:2411.07161v2 Announce Type: replace 
Abstract: Effective group decision-making is critical in Multi-Agent Systems (MAS). Yet, how different mechanisms for reaching consensus impact collaboration quality and efficiency remains understudied. We conduct a systematic study on group decision-making mechanisms in a decentralized setting. Through controlled experiments, we analyze how different voting rules affect decision quality and efficiency in a multi-round collaboration. Results reveal that majority voting often cause inefficient collaboration due to its strict acceptance criteria. At the extreme, unanimous voting gives 87% lower initial performance than the best-performing method. Our qualitative analysis of cross-agent communication shows that messages become longer and more repetitive over time: while message length increases by 84%, similarity to the previous round increases to 90%. Based on these insights, language-based early stopping methods make the performance 13% closer to oracle while reducing rounds by 50%. Our findings highlight the crucial role of group decision-making in optimizing MAS collaboration.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mazzaroth: A High-Throughput DAG Consensus with State Root</title>
<link>https://arxiv.org/abs/2506.01960</link>
<guid>https://arxiv.org/abs/2506.01960</guid>
<content:encoded><![CDATA[
arXiv:2506.01960v1 Announce Type: new 
Abstract: Nakamoto Consensus achieves a decentralized ledger through a single-chain blockchain, assuming a maximum network delay, which limits block generation speed, resulting in low throughput. \cite{pg2018} (PG) enhances throughput using a blockDAG structure, but its probabilistic confirmation restricts smart contract applications. To address this, Mazzaroth proposes a Pow-based blockDAG consensus, employing a linear ordering algorithm to compute the \cite{eth} and achieve state finality, thereby supporting smart contracts. Its dynamic difficulty adjustment, independent of the assumption, adapts to network and hashrate fluctuations, ensuring state consistency via a head chain while maximizing throughput. Simulations validate Mazzaroth's efficient consensus performance. This paper presents the Mazzaroth ordering algorithm, the difficulty adjustment mechanism, and performance evaluation.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Navigating the Edge-Cloud Continuum: A State-of-Practice Survey</title>
<link>https://arxiv.org/abs/2506.02003</link>
<guid>https://arxiv.org/abs/2506.02003</guid>
<content:encoded><![CDATA[
arXiv:2506.02003v1 Announce Type: new 
Abstract: The edge-cloud continuum has emerged as a transformative paradigm that meets the growing demand for low-latency, scalable, end-to-end service delivery by integrating decentralized edge resources with centralized cloud infrastructures. Driven by the exponential growth of IoT-generated data and the need for real-time responsiveness, this continuum features multi-layered architectures. However, its adoption is hindered by infrastructural challenges, fragmented standards, and limited guidance for developers and researchers. Existing surveys rarely tackle practical implementation or recent industrial advances. This survey closes those gaps from a developer-oriented perspective, introducing a conceptual framework for navigating the edge-cloud continuum. We systematically examine architectural models, performance metrics, and paradigms for computation, communication, and deployment, together with enabling technologies and widely used edge-to-cloud platforms. We also discuss real-world applications in smart cities, healthcare, and Industry 4.0, as well as tools for testing and experimentation. Drawing on academic research and practices of leading cloud providers, this survey serves as a practical guide for developers and a structured reference for researchers, while identifying open challenges and emerging trends that will shape the future of the continuum.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Powered Edge Intelligence for U-Healthcare in Privacy Critical and Time Sensitive Environment</title>
<link>https://arxiv.org/abs/2506.02038</link>
<guid>https://arxiv.org/abs/2506.02038</guid>
<content:encoded><![CDATA[
arXiv:2506.02038v1 Announce Type: new 
Abstract: Edge Intelligence (EI) serves as a critical enabler for privacy-preserving systems by providing AI-empowered computation and distributed caching services at the edge, thereby minimizing latency and enhancing data privacy. The integration of blockchain technology further augments EI frameworks by ensuring transactional transparency, auditability, and system-wide reliability through a decentralized network model. However, the operational architecture of such systems introduces inherent vulnerabilities, particularly due to the extensive data interactions between edge gateways (EGs) and the distributed nature of information storage during service provisioning. To address these challenges, we propose an autonomous computing model along with its interaction topologies tailored for privacy-critical and time-sensitive health applications. The system supports continuous monitoring, real-time alert notifications, disease detection, and robust data processing and aggregation. It also includes a data transaction handler and mechanisms for ensuring privacy at the EGs. Moreover, a resource-efficient one-dimensional convolutional neural network (1D-CNN) is proposed for the multiclass classification of arrhythmia, enabling accurate and real-time analysis of constrained EGs. Furthermore, a secure access scheme is defined to manage both off-chain and on-chain data sharing and storage. To validate the proposed model, comprehensive security, performance, and cost analyses are conducted, demonstrating the efficiency and reliability of the fine-grained access control scheme.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2506.02049</link>
<guid>https://arxiv.org/abs/2506.02049</guid>
<content:encoded><![CDATA[
arXiv:2506.02049v1 Announce Type: new 
Abstract: We introduce EvoGit, a decentralized multi-agent framework for collaborative software development driven by autonomous code evolution. EvoGit deploys a population of independent coding agents, each proposing edits to a shared codebase without centralized coordination, explicit message passing, or shared memory. Instead, all coordination emerges through a Git-based phylogenetic graph that tracks the full version lineage and enables agents to asynchronously read from and write to the evolving code repository. This graph-based structure supports fine-grained branching, implicit concurrency, and scalable agent interaction while preserving a consistent historical record. Human involvement is minimal but strategic: users define high-level goals, periodically review the graph, and provide lightweight feedback to promote promising directions or prune unproductive ones. Experiments demonstrate EvoGit's ability to autonomously produce functional and modular software artifacts across two real-world tasks: (1) building a web application from scratch using modern frameworks, and (2) constructing a meta-level system that evolves its own language-model-guided solver for the bin-packing optimization problem. Our results underscore EvoGit's potential to establish a new paradigm for decentralized, automated, and continual software development. EvoGit is open-sourced at https://github.com/BillHuang2001/evogit.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FSM Modeling For Off-Blockchain Computation</title>
<link>https://arxiv.org/abs/2506.02086</link>
<guid>https://arxiv.org/abs/2506.02086</guid>
<content:encoded><![CDATA[
arXiv:2506.02086v1 Announce Type: new 
Abstract: Blockchain benefits are due to immutability, replication, and storage-and-execution of smart contracts on the blockchain. However, the benefits come at increased costs due to the blockchain size and execution. We address three fundamental issues that arise in transferring certain parts of a smart contract to be executed off-chain: (i) identifying which parts (patterns) of the smart contract should be considered for processing off-chain, (ii) under which conditions should a smart-contract pattern to be processed off-chain, and (iii) how to facilitate interaction between the computation off and on-chain. We use separation of concerns and FSM modeling to model a smart contract and generate its code. We then (i) use our algorithm to determine which parts (patterns) of the smart contract are to be processed off-chain; (ii) consider conditions under which to move the pattern off-chain; and (iii) provide model for automatically generating the interface between on and off-chain computation.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Singularity Blockchain Key Management via non-custodial key management</title>
<link>https://arxiv.org/abs/2506.02282</link>
<guid>https://arxiv.org/abs/2506.02282</guid>
<content:encoded><![CDATA[
arXiv:2506.02282v1 Announce Type: new 
Abstract: web3 wallets are key to managing user identity on blockchain. The main purpose of a web3 wallet application is to manage the private key for the user and provide an interface to interact with the blockchain. The key management scheme ( KMS ) used by the wallet to store and recover the private key can be either custodial, where the keys are permissioned and in custody of the wallet provider or noncustodial where the keys are in custody of the user. The existing non-custodial key management schemes tend to offset the burden of storing and recovering the key entirely on the user by asking them to remember seed-phrases. This creates onboarding hassles for the user and introduces the risk that the user may lose their assets if they forget or lose their seedphrase/private key. In this paper, we propose a novel method of backing up user keys using a non-custodial key management technique that allows users to save and recover a backup of their private key using any independent sign-in method such as google-oAuth or other 3P oAuth.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Are Crypto Ecosystems (De)centralizing? A Framework for Longitudinal Analysis</title>
<link>https://arxiv.org/abs/2506.02324</link>
<guid>https://arxiv.org/abs/2506.02324</guid>
<content:encoded><![CDATA[
arXiv:2506.02324v1 Announce Type: new 
Abstract: Blockchain technology relies on decentralization to resist faults and attacks while operating without trusted intermediaries. Although industry experts have touted decentralization as central to their promise and disruptive potential, it is still unclear whether the crypto ecosystems built around blockchains are becoming more or less decentralized over time. As crypto plays an increasing role in facilitating economic transactions and peer-to-peer interactions, measuring their decentralization becomes even more essential. We thus propose a systematic framework for measuring the decentralization of crypto ecosystems over time and compare commonly used decentralization metrics. We applied this framework to seven prominent crypto ecosystems, across five distinct subsystems and across their lifetime for over 15 years. Our analysis revealed that while crypto has largely become more decentralized over time, recent trends show a shift toward centralization in the consensus layer, NFT marketplaces, and developers. Our framework and results inform researchers, policymakers, and practitioners about the design, regulation, and implementation of crypto ecosystems and provide a systematic, replicable foundation for future studies.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Deep Reinforcement Learning Method for Computation Offloading in Multi-User Mobile Edge Computing with Decentralization</title>
<link>https://arxiv.org/abs/2506.02458</link>
<guid>https://arxiv.org/abs/2506.02458</guid>
<content:encoded><![CDATA[
arXiv:2506.02458v1 Announce Type: new 
Abstract: Mobile edge computing (MEC) allows appliances to offload workloads to neighboring MEC servers that have the potential for computation-intensive tasks with limited computational capabilities. This paper studied how deep reinforcement learning (DRL) algorithms are used in an MEC system to find feasible decentralized dynamic computation offloading strategies, which leads to the construction of an extensible MEC system that operates effectively with finite feedback. Even though the Deep Deterministic Policy Gradient (DDPG) algorithm, subject to their knowledge of the MEC system, can be used to allocate powers of both computation offloading and local execution, to learn a computation offloading policy for each user independently, we realized that this solution still has some inherent weaknesses. Hence, we introduced a new approach for this problem based on the Twin Delayed DDPG algorithm, which enables us to overcome this proneness and investigate cases where mobile users are portable. Numerical results showed that individual users can autonomously learn adequate policies through the proposed approach. Besides, the performance of the suggested solution exceeded the conventional DDPG-based power control strategy.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Maximizing the Promptness of Metaverse Systems using Edge Computing by Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2506.02657</link>
<guid>https://arxiv.org/abs/2506.02657</guid>
<content:encoded><![CDATA[
arXiv:2506.02657v1 Announce Type: new 
Abstract: Metaverse and Digital Twin (DT) have attracted much academic and industrial attraction to approach the future digital world. This paper introduces the advantages of deep reinforcement learning (DRL) in assisting Metaverse system-based Digital Twin. In this system, we assume that it includes several Metaverse User devices collecting data from the real world to transfer it into the virtual world, a Metaverse Virtual Access Point (MVAP) undertaking the processing of data, and an edge computing server that receives the offloading data from the MVAP. The proposed model works under a dynamic environment with various parameters changing over time. The experiment results show that our proposed DRL algorithm is suitable for offloading tasks to ensure the promptness of DT in a dynamic environment.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems</title>
<link>https://arxiv.org/abs/2506.02668</link>
<guid>https://arxiv.org/abs/2506.02668</guid>
<content:encoded><![CDATA[
arXiv:2506.02668v1 Announce Type: new 
Abstract: Edge computing addresses the growing data demands of connected-device networks by placing computational resources closer to end users through decentralized infrastructures. This decentralization challenges traditional, fully centralized orchestration, which suffers from latency and resource bottlenecks. We present \textbf{FAuNO} -- \emph{Federated Asynchronous Network Orchestrator} -- a buffered, asynchronous \emph{federated reinforcement-learning} (FRL) framework for decentralized task offloading in edge systems. FAuNO adopts an actor-critic architecture in which local actors learn node-specific dynamics and peer interactions, while a federated critic aggregates experience across agents to encourage efficient cooperation and improve overall system performance. Experiments in the \emph{PeersimGym} environment show that FAuNO consistently matches or exceeds heuristic and federated multi-agent RL baselines in reducing task loss and latency, underscoring its adaptability to dynamic edge-computing scenarios.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized COVID-19 Health System Leveraging Blockchain</title>
<link>https://arxiv.org/abs/2506.02674</link>
<guid>https://arxiv.org/abs/2506.02674</guid>
<content:encoded><![CDATA[
arXiv:2506.02674v1 Announce Type: new 
Abstract: With the development of the Internet, the amount of data generated by the medical industry each year has grown exponentially. The Electronic Health Record (EHR) manages the electronic data generated during the user's treatment process. Typically, an EHR data manager belongs to a medical institution. This traditional centralized data management model has many unreasonable or inconvenient aspects, such as difficulties in data sharing, and it is hard to verify the authenticity and integrity of the data. The decentralized, non-forgeable, data unalterable and traceable features of blockchain are in line with the application requirements of EHR. This paper takes the most common COVID-19 as the application scenario and designs a COVID-19 health system based on blockchain, which has extensive research and application value. Considering that the public and transparent nature of blockchain violates the privacy requirements of some health data, in the system design stage, from the perspective of practical application, the data is divided into public data and private data according to its characteristics. For private data, data encryption methods are adopted to ensure data privacy. The searchable encryption technology is combined with blockchain technology to achieve the retrieval function of encrypted data. Then, the proxy re-encryption technology is used to realize authorized access to data. In the system implementation part, based on the Hyperledger Fabric architecture, some functions of the system design are realized, including data upload, retrieval of the latest data and historical data. According to the environment provided by the development architecture, Go language chaincode (smart contract) is written to implement the relevant system functions.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Poster: FedBlockParadox -- A Framework for Simulating and Securing Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2506.02679</link>
<guid>https://arxiv.org/abs/2506.02679</guid>
<content:encoded><![CDATA[
arXiv:2506.02679v1 Announce Type: new 
Abstract: A significant body of research in decentralized federated learning focuses on combining the privacy-preserving properties of federated learning with the resilience and transparency offered by blockchain-based systems. While these approaches are promising, they often lack flexible tools to evaluate system robustness under adversarial conditions. To fill this gap, we present FedBlockParadox, a modular framework for modeling and evaluating decentralized federated learning systems built on blockchain technologies, with a focus on resilience against a broad spectrum of adversarial attack scenarios. It supports multiple consensus protocols, validation methods, aggregation strategies, and configurable attack models. By enabling controlled experiments, FedBlockParadox provides a valuable resource for researchers developing secure, decentralized learning solutions. The framework is open-source and built to be extensible by the community.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transforming Automatically BPMN Models to Smart Contracts with Nested Collaborative Transactions (TABS+)</title>
<link>https://arxiv.org/abs/2506.02727</link>
<guid>https://arxiv.org/abs/2506.02727</guid>
<content:encoded><![CDATA[
arXiv:2506.02727v1 Announce Type: new 
Abstract: Development of blockchain smart contracts is more difficult than mainstream software development because the underlying blockchain infrastructure poses additional complexity. To ease the developer's task of writing smart contract, as other research efforts, we also use Business Process Model and Notation BPMN modeling to describe application requirements for trade of goods and services and then transform automatically the BPMN model into the methods of a smart contract. In our previous research we described our approach and a tool to Transform Automatically BPMN models into Smart contracts TABS. In this paper, we describe how the TABS approach is augmented with the support for a BPMN collaborative transaction by several actors. Our approach analyzes the BPMN model to determine which patterns in the BPMN model are suitable for use as collaborative transactions. The found BPMN patterns that are suitable as transactions are shown to the developer who decides which ones should be deployed as collaborative transactions. We describe how our approach automatically transform the BPMN model into smart contract the provides a transaction mechanism to enforce the transactional properties of the nested transactions. Our approach greatly reduces the developers task as synchronization of collaborative activities is provided by our approach, so that the developer needs to code only independent tasks with well-defined inputs and outputs. We also overview the TABS+ tool we built as a proof of concept to show that our approach is feasible. Finally, we provide estimates on the cost of supporting the nested BPMN collaborative transactions.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Process Mining on Distributed Data Sources</title>
<link>https://arxiv.org/abs/2506.02830</link>
<guid>https://arxiv.org/abs/2506.02830</guid>
<content:encoded><![CDATA[
arXiv:2506.02830v1 Announce Type: new 
Abstract: Major domains such as logistics, healthcare, and smart cities increasingly rely on sensor technologies and distributed infrastructures to monitor complex processes in real time. These developments are transforming the data landscape from discrete, structured records stored in centralized systems to continuous, fine-grained, and heterogeneous event streams collected across distributed environments. As a result, traditional process mining techniques, which assume centralized event logs from enterprise systems, are no longer sufficient. In this paper, we discuss the conceptual and methodological foundations for this emerging field. We identify three key shifts: from offline to online analysis, from centralized to distributed computing, and from event logs to sensor data. These shifts challenge traditional assumptions about process data and call for new approaches that integrate infrastructure, data, and user perspectives. To this end, we define a research agenda that addresses six interconnected fields, each spanning multiple system dimensions. We advocate a principled methodology grounded in algorithm engineering, combining formal modeling with empirical evaluation. This approach enables the development of scalable, privacy-aware, and user-centric process mining techniques suitable for distributed environments. Our synthesis provides a roadmap for advancing process mining beyond its classical setting, toward a more responsive and decentralized paradigm of process intelligence.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ensemble-MIX: Enhancing Sample Efficiency in Multi-Agent RL Using Ensemble Methods</title>
<link>https://arxiv.org/abs/2506.02841</link>
<guid>https://arxiv.org/abs/2506.02841</guid>
<content:encoded><![CDATA[
arXiv:2506.02841v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) methods have achieved state-of-the-art results on a range of multi-agent tasks. Yet, MARL algorithms typically require significantly more environment interactions than their single-agent counterparts to converge, a problem exacerbated by the difficulty in exploring over a large joint action space and the high variance intrinsic to MARL environments. To tackle these issues, we propose a novel algorithm that combines a decomposed centralized critic with decentralized ensemble learning, incorporating several key contributions. The main component in our scheme is a selective exploration method that leverages ensemble kurtosis. We extend the global decomposed critic with a diversity-regularized ensemble of individual critics and utilize its excess kurtosis to guide exploration toward high-uncertainty states and actions. To improve sample efficiency, we train the centralized critic with a novel truncated variation of the TD($\lambda$) algorithm, enabling efficient off-policy learning with reduced variance. On the actor side, our suggested algorithm adapts the mixed samples approach to MARL, mixing on-policy and off-policy loss functions for training the actors. This approach balances between stability and efficiency and outperforms purely off-policy learning. The evaluation shows our method outperforms state-of-the-art baselines on standard MARL benchmarks, including a variety of SMAC II maps.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Blockchain Meets Crawlers: Real-time Market Analytics in Solana NFT Markets</title>
<link>https://arxiv.org/abs/2506.02892</link>
<guid>https://arxiv.org/abs/2506.02892</guid>
<content:encoded><![CDATA[
arXiv:2506.02892v1 Announce Type: new 
Abstract: In this paper, we design and implement a web crawler system based on the Solana blockchain for the automated collection and analysis of market data for popular non-fungible tokens (NFTs) on the chain. Firstly, the basic information and transaction data of popular NFTs on the Solana chain are collected using the Selenium tool. Secondly, the transaction records of the Magic Eden trading market are thoroughly analyzed by combining them with the Scrapy framework to examine the price fluctuations and market trends of NFTs. In terms of data analysis, this paper employs time series analysis to examine the dynamics of the NFT market and seeks to identify potential price patterns. In addition, the risk and return of different NFTs are evaluated using the mean-variance optimization model, taking into account their characteristics, such as illiquidity and market volatility, to provide investors with data-driven portfolio recommendations. The experimental results show that the combination of crawler technology and financial analytics can effectively analyze NFT data on the Solana blockchain and provide timely market insights and investment strategies. This study provides a reference for further exploration in the field of digital currencies.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models</title>
<link>https://arxiv.org/abs/2506.02961</link>
<guid>https://arxiv.org/abs/2506.02961</guid>
<content:encoded><![CDATA[
arXiv:2506.02961v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved state-of-the-art results across diverse domains, yet their development remains reliant on vast amounts of publicly available data, raising concerns about data scarcity and the lack of access to domain-specific, sensitive information. Federated Learning (FL) presents a compelling framework to address these challenges by enabling decentralized fine-tuning on pre-trained LLMs without sharing raw data. However, the compatibility and performance of pre-trained LLMs in FL settings remain largely under explored. We introduce the FlowerTune LLM Leaderboard, a first-of-its-kind benchmarking suite designed to evaluate federated fine-tuning of LLMs across four diverse domains: general NLP, finance, medical, and coding. Each domain includes federated instruction-tuning datasets and domain-specific evaluation metrics. Our results, obtained through a collaborative, open-source and community-driven approach, provide the first comprehensive comparison across 26 pre-trained LLMs with different aggregation and fine-tuning strategies under federated settings, offering actionable insights into model performance, resource constraints, and domain adaptation. This work lays the foundation for developing privacy-preserving, domain-specialized LLMs for real-world applications.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs</title>
<link>https://arxiv.org/abs/2506.02965</link>
<guid>https://arxiv.org/abs/2506.02965</guid>
<content:encoded><![CDATA[
arXiv:2506.02965v1 Announce Type: new 
Abstract: Mixture-of-Experts (MoE) has been gaining popularity due to its successful adaptation to large language models (LLMs). In this work, we introduce Privacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages the sparsity of the MoE architecture for memory-efficient decentralized collaborative LLM training, enabling multiple parties with limited GPU-memory and data resources to collectively train more capable LLMs than they could achieve individually. At the same time, this approach protects training data privacy of each participant by keeping training data, as well as parts of the forward pass signal and gradients locally within each party. By design, PC-MoE synergistically combines the strengths of distributed computation with strong confidentiality assurances. Unlike most privacy-preserving schemes, which pay for confidentiality with lower task accuracy, our framework breaks that trade-off: across seven popular LLM benchmarks, it almost matches (and sometimes exceeds) the performance and convergence rate of a fully centralized model, enjoys near 70% peak GPU RAM reduction, while being fully robust against reconstruction attacks.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Fee for Reducing Impermanent Loss in Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2506.03001</link>
<guid>https://arxiv.org/abs/2506.03001</guid>
<content:encoded><![CDATA[
arXiv:2506.03001v1 Announce Type: new 
Abstract: Decentralized exchanges (DEXs) are crucial to decentralized finance (DeFi) as they enable trading without intermediaries. However, they face challenges like impermanent loss (IL), where liquidity providers (LPs) see their assets' value change unfavorably within a liquidity pool compared to outside it. To tackle these issues, we propose dynamic fee mechanisms over traditional fixed-fee structures used in automated market makers (AMM). Our solution includes asymmetric fees via block-adaptive, deal-adaptive, and the "ideal but unattainable" oracle-based fee algorithm, utilizing all data available to arbitrageurs to mitigate IL. We developed a simulation-based framework to compare these fee algorithms systematically. This framework replicates trading on a DEX, considering both informed and uninformed users and a psychological relative loss factor. Results show that adaptive algorithms outperform fixed-fee baselines in reducing IL while maintaining trading activity among uninformed users. Additionally, insights from oracle-based performance underscore the potential of dynamic fee strategies to lower IL, boost LP profitability, and enhance overall market efficiency.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Preference-Driven Methodology for High-Quality Solidity Code Generation</title>
<link>https://arxiv.org/abs/2506.03006</link>
<guid>https://arxiv.org/abs/2506.03006</guid>
<content:encoded><![CDATA[
arXiv:2506.03006v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) have demonstrated remarkable progress in generating functionally correct Solidity code, they continue to face critical challenges in producing gas-efficient and secure code, which are critical requirements for real-world smart contract deployment. Although recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) for code preference alignment, existing approaches treat functional correctness, gas optimization, and security as independent objectives, resulting in contracts that may achieve operational soundness but suffer from prohibitive execution costs or dangerous vulnerabilities. To address these limitations, we propose PrefGen, a novel framework that extends standard DPO beyond human preferences to incorporate quantifiable blockchain-specific metrics, enabling holistic multi-objective optimization specifically tailored for smart contract generation. Our framework introduces a comprehensive evaluation methodology with four complementary metrics: Pass@k (functional correctness), Compile@k (syntactic correctness), Gas@k (gas efficiency), and Secure@k (security assessment), providing rigorous multi-dimensional contract evaluation. Through extensive experimentation, we demonstrate that PrefGen significantly outperforms existing approaches across all critical dimensions, achieving 66.7% Pass@5, 58.9% Gas@5, and 62.5% Secure@5, while generating production-ready smart contracts that are functionally correct, cost-efficient, and secure.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Backpressure-based Mean-field Type Game for Scheduling in Multi-Hop Wireless Sensor Networks</title>
<link>https://arxiv.org/abs/2506.03059</link>
<guid>https://arxiv.org/abs/2506.03059</guid>
<content:encoded><![CDATA[
arXiv:2506.03059v1 Announce Type: new 
Abstract: We propose a Mean-Field Type Game (MFTG) framework for effective scheduling in multi-hop wireless sensor networks (WSNs) using backpressure as a performance criterion. Traditional backpressure algorithms leverage queue differentials to regulate data flow and maintain network stability. In this work, we extend the backpressure framework by incorporating a mean-field term into the cost functional, capturing the global behavior of the system alongside local dynamics. The resulting model utilizes the strengths of non-cooperative mean-field type games, enabling nodes to make decentralized decisions based on both individual queue states and system mean-field effects while accounting for stochastic network interactions. By leveraging the interplay between backpressure dynamics and mean-field coupling, the approach balances local optimization with global efficiency. Numerical simulations demonstrate the efficacy of the proposed method in handling congestion and scheduling in large-scale WSNs.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis</title>
<link>https://arxiv.org/abs/2506.02068</link>
<guid>https://arxiv.org/abs/2506.02068</guid>
<content:encoded><![CDATA[
arXiv:2506.02068v1 Announce Type: cross 
Abstract: Blockchain transaction data is inherently high dimensional, noisy, and entangled, posing substantial challenges for traditional clustering algorithms. While quantum enhanced clustering models have demonstrated promising performance gains, their interpretability remains limited, restricting their application in sensitive domains such as financial fraud detection and blockchain governance. To address this gap, we propose a two stage analysis framework that synergistically combines quantitative clustering evaluation with AI Agent assisted qualitative interpretation. In the first stage, we employ classical clustering methods and evaluation metrics including the Silhouette Score, Davies Bouldin Index, and Calinski Harabasz Index to determine the optimal cluster count and baseline partition quality. In the second stage, we integrate an AI Agent to generate human readable, semantic explanations of clustering results, identifying intra cluster characteristics and inter cluster relationships. Our experiments reveal that while fully trained Quantum Neural Networks (QNN) outperform random Quantum Features (QF) in quantitative metrics, the AI Agent further uncovers nuanced differences between these methods, notably exposing the singleton cluster phenomenon in QNN driven models. The consolidated insights from both stages consistently endorse the three cluster configuration, demonstrating the practical value of our hybrid approach. This work advances the interpretability frontier in quantum assisted blockchain analytics and lays the groundwork for future autonomous AI orchestrated clustering frameworks.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Specialize: Joint Gating-Expert Training for Adaptive MoEs in Decentralized Settings</title>
<link>https://arxiv.org/abs/2306.08586</link>
<guid>https://arxiv.org/abs/2306.08586</guid>
<content:encoded><![CDATA[
arXiv:2306.08586v3 Announce Type: replace 
Abstract: Mixture-of-Experts (MoEs) achieve scalability by dynamically activating subsets of their components. Yet, understanding how expertise emerges through joint training of gating mechanisms and experts remains incomplete, especially in scenarios without clear task partitions. Motivated by inference costs and data heterogeneity, we study how joint training of gating functions and experts can dynamically allocate domain-specific expertise across multiple underlying data distributions. As an outcome of our framework, we develop an instance tailored specifically to decentralized training scenarios, introducing \textit{Dynamically Decentralized Orchestration of MoEs} or \texttt{DDOME}. \texttt{DDOME} leverages heterogeneity emerging from distributional shifts across decentralized data sources to specialize experts dynamically. By integrating a pretrained common expert to inform a gating function, \texttt{DDOME} achieves personalized expert subset selection on-the-fly, facilitating just-in-time personalization. We empirically validate \texttt{DDOME} within a Federated Learning (FL) context: \texttt{DDOME} attains from 4\% up to an 24\% accuracy improvement over state-of-the-art FL baselines in image and text classification tasks, while maintaining competitive zero-shot generalization capabilities. Furthermore, we provide theoretical insights confirming that the joint gating-experts training is critical for achieving meaningful expert specialization.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dressed to Gamble: How Poker Drives the Dynamics of Wearables and Visits on Decentraland's Social Virtual World</title>
<link>https://arxiv.org/abs/2407.15625</link>
<guid>https://arxiv.org/abs/2407.15625</guid>
<content:encoded><![CDATA[
arXiv:2407.15625v3 Announce Type: replace 
Abstract: Decentraland is a blockchain-based social virtual world where users can publish and sell wearables to customize avatars. In it, the third-party Decentral Games (DG) allows players of its flagship game ICE Poker to earn cryptocurrency only if they possess certain wearables. Herein, we present a comprehensive study on how DG and its game influence the dynamics of wearables and in-world visits in Decentraland. To this end, we analyzed 5.9 million wearable transfers made on the Polygon blockchain (and related sales) over a two-year period, and 677 million log events of in-world user positions in an overlapping 10-month period. We found that these activities are disproportionately related to DG, with its ICE Poker casinos (less than 0.1% of the world map) representing a remarkable average share of daily unique visitors (33%) and time spent in the virtual world (20%). Despite several alternative initiatives within Decentraland, ICE Poker appears to drive user activity on the platform. Our work thus contributes to the understanding of how play-to-earn games influence user behavior in social virtual worlds, and it is among the first to study the emerging phenomenon of virtual blockchain-based gambling.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable Multi-Robot Informative Path Planning for Target Mapping via Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16967</link>
<guid>https://arxiv.org/abs/2409.16967</guid>
<content:encoded><![CDATA[
arXiv:2409.16967v3 Announce Type: replace 
Abstract: Autonomous robots are widely utilized for mapping and exploration tasks due to their cost-effectiveness. Multi-robot systems offer scalability and efficiency, especially in terms of the number of robots deployed in more complex environments. These tasks belong to the set of Multi-Robot Informative Path Planning (MRIPP) problems. In this paper, we propose a deep reinforcement learning approach for the MRIPP problem. We aim to maximize the number of discovered stationary targets in an unknown 3D environment while operating under resource constraints (such as path length). Here, each robot aims to maximize discovered targets, avoid unknown static obstacles, and prevent inter-robot collisions while operating under communication and resource constraints. We utilize the centralized training and decentralized execution paradigm to train a single policy neural network. A key aspect of our approach is our coordination graph that prioritizes visiting regions not yet explored by other robots. Our learned policy can be copied onto any number of robots for deployment in more complex environments not seen during training. Our approach outperforms state-of-the-art approaches by at least 26.2% in terms of the number of discovered targets while requiring a planning time of less than 2 sec per step. We present results for more complex environments with up to 64 robots and compare success rates against baseline planners. Our code and trained model are available at - https://github.com/AccGen99/marl_ipp
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study</title>
<link>https://arxiv.org/abs/2502.00182</link>
<guid>https://arxiv.org/abs/2502.00182</guid>
<content:encoded><![CDATA[
arXiv:2502.00182v3 Announce Type: replace 
Abstract: As privacy concerns and data regulations grow, federated learning (FL) has emerged as a promising approach for training machine learning models across decentralized data sources without sharing raw data. However, a significant challenge in FL is that client data are often non-IID (non-independent and identically distributed), leading to reduced performance compared to centralized learning. While many methods have been proposed to address this issue, their underlying mechanisms are often viewed from different perspectives. Through a comprehensive investigation from gradient descent to FL, and from IID to non-IID data settings, we find that inconsistencies in client loss landscapes primarily cause performance degradation in non-IID scenarios. From this understanding, we observe that existing methods can be grouped into two main strategies: (i) adjusting parameter update paths and (ii) modifying client loss landscapes. These findings offer a clear perspective on addressing non-IID challenges in FL and help guide future research in the field.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts</title>
<link>https://arxiv.org/abs/2506.00282</link>
<guid>https://arxiv.org/abs/2506.00282</guid>
<content:encoded><![CDATA[
arXiv:2506.00282v1 Announce Type: new 
Abstract: In online auctions, fraudulent behaviors such as shill bidding pose significant risks. This paper presents a conceptual framework that applies dynamic, behavior-based penalties to deter auction fraud using blockchain smart contracts. Unlike traditional post-auction detection methods, this approach prevents manipulation in real-time by introducing an economic disincentive system where penalty severity scales with suspicious bidding patterns. The framework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct bidding behaviors, dynamically adjusting the penalty fees to make fraudulent activity financially unaffordable while providing fair competition.
  The system is implemented within a decentralized English auction on the Ethereum blockchain, demonstrating how smart contracts enforce transparent auction rules without trusted intermediaries. Simulations confirm the effectiveness of the proposed model: the dynamic penalty mechanism reduces the profitability of shill bidding while keeping penalties low for honest bidders. Performance evaluation shows that the system introduces only moderate gas and latency overhead, keeping transaction costs and response times within practical bounds for real-world use. The approach provides a practical method for behaviour-based fraud prevention in decentralised systems where trust cannot be assumed.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematic Review of Metaheuristics-Based and Machine Learning-Driven Intrusion Detection Systems in IoT</title>
<link>https://arxiv.org/abs/2506.00377</link>
<guid>https://arxiv.org/abs/2506.00377</guid>
<content:encoded><![CDATA[
arXiv:2506.00377v1 Announce Type: new 
Abstract: The widespread adoption of the Internet of Things (IoT) has raised a new challenge for developers since it is prone to known and unknown cyberattacks due to its heterogeneity, flexibility, and close connectivity. To defend against such security breaches, researchers have focused on building sophisticated intrusion detection systems (IDSs) using machine learning (ML) techniques. Although these algorithms notably improve detection performance, they require excessive computing power and resources, which are crucial issues in IoT networks considering the recent trends of decentralized data processing and computing systems. Consequently, many optimization techniques have been incorporated with these ML models. Specifically, a special category of optimizer adopted from the behavior of living creatures and different aspects of natural phenomena, known as metaheuristic algorithms, has been a central focus in recent years and brought about remarkable results. Considering this vital significance, we present a comprehensive and systematic review of various applications of metaheuristics algorithms in developing a machine learning-based IDS, especially for IoT. A significant contribution of this study is the discovery of hidden correlations between these optimization techniques and machine learning models integrated with state-of-the-art IoT-IDSs. In addition, the effectiveness of these metaheuristic algorithms in different applications, such as feature selection, parameter or hyperparameter tuning, and hybrid usages are separately analyzed. Moreover, a taxonomy of existing IoT-IDSs is proposed. Furthermore, we investigate several critical issues related to such integration. Our extensive exploration ends with a discussion of promising optimization algorithms and technologies that can enhance the efficiency of IoT-IDSs.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sensor Fusion Methods for Gaussian Mixture Models</title>
<link>https://arxiv.org/abs/2506.00383</link>
<guid>https://arxiv.org/abs/2506.00383</guid>
<content:encoded><![CDATA[
arXiv:2506.00383v1 Announce Type: new 
Abstract: Consensus is a popular technique for distributed state estimation. This formulation allows networks of connected agents or sensors to exchange information about the distribution of a set of targets with their immediate neighbors without the need of a centralized node or layer. We present decentralized consensus-based fusion techniques for a system whose target prior estimates are a weighted mixture of Gaussian probability density functions (PDFs) for the following cases: 1) in which all agents have the same a priori Gaussian mixture estimate of the target, and 2) in which agents have different a priori Gaussian mixture estimates of the target. For the second case, we present a formulation that fuses each agent's a priori estimate without using local observations such that each agent's posterior estimate is the same across the network.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Privacy-Preserving Second-Order Federated Edge Learning in Personalized Healthcare</title>
<link>https://arxiv.org/abs/2506.00416</link>
<guid>https://arxiv.org/abs/2506.00416</guid>
<content:encoded><![CDATA[
arXiv:2506.00416v1 Announce Type: new 
Abstract: Federated learning (FL) has attracted increasing attention to mitigate security and privacy challenges in traditional cloud-centric machine learning models specifically in healthcare ecosystems. FL methodologies enable the training of global models through localized policies, allowing independent operations at the edge clients' level. Conventional first-order FL approaches face several challenges in personalized model training due to heterogeneous non-independent and identically distributed (non-iid) data of each edge client. Recently, second-order FL approaches maintain the stability and consistency of non-iid datasets while improving personalized model training. This study proposes and develops a verifiable and auditable optimized second-order FL framework BFEL (blockchain-enhanced federated edge learning) based on optimized FedCurv for personalized healthcare systems. FedCurv incorporates information about the importance of each parameter to each client's task (through Fisher Information Matrix) which helps to preserve client-specific knowledge and reduce model drift during aggregation. Moreover, it minimizes communication rounds required to achieve a target precision convergence for each edge client while effectively managing personalized training on non-iid and heterogeneous data. The incorporation of Ethereum-based model aggregation ensures trust, verifiability, and auditability while public key encryption enhances privacy and security. Experimental results of federated CNNs and MLPs utilizing Mnist, Cifar-10, and PathMnist demonstrate the high efficiency and scalability of the proposed framework.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PSI-PFL: Population Stability Index for Client Selection in non-IID Personalized Federated Learning</title>
<link>https://arxiv.org/abs/2506.00440</link>
<guid>https://arxiv.org/abs/2506.00440</guid>
<content:encoded><![CDATA[
arXiv:2506.00440v1 Announce Type: new 
Abstract: Federated Learning (FL) enables decentralized machine learning (ML) model training while preserving data privacy by keeping data localized across clients. However, non-independent and identically distributed (non-IID) data across clients poses a significant challenge, leading to skewed model updates and performance degradation. Addressing this, we propose PSI-PFL, a novel client selection framework for Personalized Federated Learning (PFL) that leverages the Population Stability Index (PSI) to quantify and mitigate data heterogeneity (so-called non-IIDness). Our approach selects more homogeneous clients based on PSI, reducing the impact of label skew, one of the most detrimental factors in FL performance. Experimental results over multiple data modalities (tabular, image, text) demonstrate that PSI-PFL significantly improves global model accuracy, outperforming state-of-the-art baselines by up to 10\% under non-IID scenarios while ensuring fairer local performance. PSI-PFL enhances FL performance and offers practical benefits in applications where data privacy and heterogeneity are critical.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated learning framework for collaborative remaining useful life prognostics: an aircraft engine case study</title>
<link>https://arxiv.org/abs/2506.00499</link>
<guid>https://arxiv.org/abs/2506.00499</guid>
<content:encoded><![CDATA[
arXiv:2506.00499v1 Announce Type: new 
Abstract: Complex systems such as aircraft engines are continuously monitored by sensors. In predictive aircraft maintenance, the collected sensor measurements are used to estimate the health condition and the Remaining Useful Life (RUL) of such systems. However, a major challenge when developing prognostics is the limited number of run-to-failure data samples. This challenge could be overcome if multiple airlines would share their run-to-failure data samples such that sufficient learning can be achieved. Due to privacy concerns, however, airlines are reluctant to share their data in a centralized setting. In this paper, a collaborative federated learning framework is therefore developed instead. Here, several airlines cooperate to train a collective RUL prognostic machine learning model, without the need to centrally share their data. For this, a decentralized validation procedure is proposed to validate the prognostics model without sharing any data. Moreover, sensor data is often noisy and of low quality. This paper therefore proposes four novel methods to aggregate the parameters of the global prognostic model. These methods enhance the robustness of the FL framework against noisy data. The proposed framework is illustrated for training a collaborative RUL prognostic model for aircraft engines, using the N-CMAPSS dataset. Here, six airlines are considered, that collaborate in the FL framework to train a collective RUL prognostic model for their aircraft's engines. When comparing the proposed FL framework with the case where each airline independently develops their own prognostic model, the results show that FL leads to more accurate RUL prognostics for five out of the six airlines. Moreover, the novel robust aggregation methods render the FL framework robust to noisy data samples.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scaling DeFi with ZK Rollups: Design, Deployment, and Evaluation of a Real-Time Proof-of-Concept</title>
<link>https://arxiv.org/abs/2506.00500</link>
<guid>https://arxiv.org/abs/2506.00500</guid>
<content:encoded><![CDATA[
arXiv:2506.00500v1 Announce Type: new 
Abstract: Ethereum's scalability limitations pose significant challenges for the adoption of decentralized applications (dApps). Zero-Knowledge Rollups (ZK Rollups) present a promising solution, bundling transactions off-chain and submitting validity proofs on-chain to enhance throughput and efficiency. In this work, we examine the technical underpinnings of ZK Rollups and stress test their performance in real-world applications in decentralized finance (DeFi). We set up a proof-of-concept (PoC) consisting of ZK rollup and decentralized exchange, and implement load balancer generating token swaps. Our results show that the rollup can process up to 71 swap transactions per second, compared to 12 general transaction by Ethereum. We further analyze transaction finality trade-offs with related security concerns, and discuss the future directions for integrating ZK Rollups into Ethereum's broader ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Rules to Rewards: Reinforcement Learning for Interest Rate Adjustment in DeFi Lending</title>
<link>https://arxiv.org/abs/2506.00505</link>
<guid>https://arxiv.org/abs/2506.00505</guid>
<content:encoded><![CDATA[
arXiv:2506.00505v1 Announce Type: new 
Abstract: Decentralized Finance (DeFi) lending enables permissionless borrowing via smart contracts. However, it faces challenges in optimizing interest rates, mitigating bad debt, and improving capital efficiency. Rule-based interest-rate models struggle to adapt to dynamic market conditions, leading to inefficiencies. This work applies Offline Reinforcement Learning (RL) to optimize interest rate adjustments in DeFi lending protocols. Using historical data from Aave protocol, we evaluate three RL approaches: Conservative Q-Learning (CQL), Behavior Cloning (BC), and TD3 with Behavior Cloning (TD3-BC). TD3-BC demonstrates superior performance in balancing utilization, capital stability, and risk, outperforming existing models. It adapts effectively to historical stress events like the May 2021 crash and the March 2023 USDC depeg, showcasing potential for automated, real-time governance.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Review of Blockchain-Based Approaches to Spent Fuel Management in Nuclear Power Plants</title>
<link>https://arxiv.org/abs/2506.00677</link>
<guid>https://arxiv.org/abs/2506.00677</guid>
<content:encoded><![CDATA[
arXiv:2506.00677v1 Announce Type: new 
Abstract: This study addresses critical challenges in managing the transportation of spent nuclear fuel, including inadequate data transparency, stringent confidentiality requirements, and a lack of trust among collaborating parties, issues prevalent in traditional centralized management systems. Given the high risks involved, balancing data confidentiality with regulatory transparency is imperative. To overcome these limitations, a prototype system integrating blockchain technology and the Internet of Things (IoT) is proposed, featuring a multi-tiered consortium chain architecture. This system utilizes IoT sensors for real-time data collection, which is immutably recorded on the blockchain, while a hierarchical data structure (operational, supervisory, and public layers) manages access for diverse stakeholders. The results demonstrate that this approach significantly enhances data immutability, enables real-time multi-sensor data integration, improves decentralized transparency, and increases resilience compared to traditional systems. Ultimately, this blockchain-IoT framework improves the safety, transparency, and efficiency of spent fuel transportation, effectively resolving the conflict between confidentiality and transparency in nuclear data management and offering significant practical implications.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>S\"{o}ze: One Network Telemetry Is All You Need for Per-flow Weighted Bandwidth Allocation at Scale</title>
<link>https://arxiv.org/abs/2506.00834</link>
<guid>https://arxiv.org/abs/2506.00834</guid>
<content:encoded><![CDATA[
arXiv:2506.00834v1 Announce Type: new 
Abstract: Weighted bandwidth allocation is a powerful abstraction that has a wide range of use cases in modern data center networks. However, realizing highly agile and precise weighted bandwidth allocation for large-scale cloud environments is fundamentally challenging. In this paper, we propose S\"{o}ze, a lightweight decentralized weighted bandwidth allocation system that leverages simple network telemetry features of commodity Ethernet switches. Given the flow weights, S\"{o}ze can effectively use the telemetry information to compute and enforce the weighted bandwidth allocations without per-flow, topology, or routing knowledge. We demonstrate the effectiveness of S\"{o}ze through simulations and testbed experiments, improving TPC-H jobs completion time by up to $0.59\times$ and $0.79\times$ on average.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Addressing the Collaboration Dilemma in Low-Data Federated Learning via Transient Sparsity</title>
<link>https://arxiv.org/abs/2506.00932</link>
<guid>https://arxiv.org/abs/2506.00932</guid>
<content:encoded><![CDATA[
arXiv:2506.00932v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized clients while preserving data privacy, leveraging aggregated updates to build robust global models. However, this training paradigm faces significant challenges due to data heterogeneity and limited local datasets, which often impede effective collaboration. In such scenarios, we identify the Layer-wise Inertia Phenomenon in FL, wherein the middle layers of global model undergo minimal updates after early communication rounds, ultimately limiting the effectiveness of global aggregation. We demonstrate the presence of this phenomenon across a wide range of federated settings, spanning diverse datasets and architectures. To address this issue, we propose LIPS (Layer-wise Inertia Phenomenon with Sparsity), a simple yet effective method that periodically introduces transient sparsity to stimulate meaningful updates and empower global aggregation. Experiments demonstrate that LIPS effectively mitigates layer-wise inertia, enhances aggregation effectiveness, and improves overall performance in various FL scenarios. This work not only deepens the understanding of layer-wise learning dynamics in FL but also paves the way for more effective collaboration strategies in resource-constrained environments. Our code is publicly available at: https://github.com/QiaoXiao7282/LIPS.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Legal Compliance Evaluation of Smart Contracts Generated By Large Language Models</title>
<link>https://arxiv.org/abs/2506.00943</link>
<guid>https://arxiv.org/abs/2506.00943</guid>
<content:encoded><![CDATA[
arXiv:2506.00943v1 Announce Type: new 
Abstract: Smart contracts can implement and automate parts of legal contracts, but ensuring their legal compliance remains challenging. Existing approaches such as formal specification, verification, and model-based development require expertise in both legal and software development domains, as well as extensive manual effort. Given the recent advances of Large Language Models (LLMs) in code generation, we investigate their ability to generate legally compliant smart contracts directly from natural language legal contracts, addressing these challenges. We propose a novel suite of metrics to quantify legal compliance based on modeling both legal and smart contracts as processes and comparing their behaviors. We select four LLMs, generate 20 smart contracts based on five legal contracts, and analyze their legal compliance. We find that while all LLMs generate syntactically correct code, there is significant variance in their legal compliance with larger models generally showing higher levels of compliance. We also evaluate the proposed metrics against properties of software metrics, showing they provide fine-grained distinctions, enable nuanced comparisons, and are applicable across domains for code from any source, LLM or developer. Our results suggest that LLMs can assist in generating starter code for legally compliant smart contracts with strict reviews, and the proposed metrics provide a foundation for automated and self-improving development workflows.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Parallelism in Decentralized Stochastic Convex Optimization</title>
<link>https://arxiv.org/abs/2506.00961</link>
<guid>https://arxiv.org/abs/2506.00961</guid>
<content:encoded><![CDATA[
arXiv:2506.00961v1 Announce Type: new 
Abstract: Decentralized learning has emerged as a powerful approach for handling large datasets across multiple machines in a communication-efficient manner. However, such methods often face scalability limitations, as increasing the number of machines beyond a certain point negatively impacts convergence rates. In this work, we propose Decentralized Anytime SGD, a novel decentralized learning algorithm that significantly extends the critical parallelism threshold, enabling the effective use of more machines without compromising performance. Within the stochastic convex optimization (SCO) framework, we establish a theoretical upper bound on parallelism that surpasses the current state-of-the-art, allowing larger networks to achieve favorable statistical guarantees and closing the gap with centralized learning in highly connected topologies.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Protocol Models: Scaling Decentralized Training with Communication-Efficient Model Parallelism</title>
<link>https://arxiv.org/abs/2506.01260</link>
<guid>https://arxiv.org/abs/2506.01260</guid>
<content:encoded><![CDATA[
arXiv:2506.01260v1 Announce Type: new 
Abstract: Scaling models has led to significant advancements in deep learning, but training these models in decentralized settings remains challenging due to communication bottlenecks. While existing compression techniques are effective in data-parallel, they do not extend to model parallelism. Unlike data-parallel training, where weight gradients are exchanged, model-parallel requires compressing activations and activation gradients as they propagate through layers, accumulating compression errors. We propose a novel compression algorithm that compresses both forward and backward passes, enabling up to 99% compression with no convergence degradation with negligible memory/compute overhead. By leveraging a recursive structure in transformer networks, we predefine a low-dimensional subspace to confine the activations and gradients, allowing full reconstruction in subsequent layers. Our method achieves up to 100x improvement in communication efficiency and enables training billion-parameter-scale models over low-end GPUs connected via consumer-grade internet speeds as low as 80Mbps, matching the convergence of centralized datacenter systems with 100Gbps connections with model parallel.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantitative Error Feedback for Quantization Noise Reduction of Filtering over Graphs</title>
<link>https://arxiv.org/abs/2506.01404</link>
<guid>https://arxiv.org/abs/2506.01404</guid>
<content:encoded><![CDATA[
arXiv:2506.01404v1 Announce Type: new 
Abstract: This paper introduces an innovative error feedback framework designed to mitigate quantization noise in distributed graph filtering, where communications are constrained to quantized messages. It comes from error spectrum shaping techniques from state-space digital filters, and therefore establishes connections between quantized filtering processes over different domains. In contrast to existing error compensation methods, our framework quantitatively feeds back the quantization noise for exact compensation. We examine the framework under three key scenarios: (i) deterministic graph filtering, (ii) graph filtering over random graphs, and (iii) graph filtering with random node-asynchronous updates. Rigorous theoretical analysis demonstrates that the proposed framework significantly reduces the effect of quantization noise, and we provide closed-form solutions for the optimal error feedback coefficients. Moreover, this quantitative error feedback mechanism can be seamlessly integrated into communication-efficient decentralized optimization frameworks, enabling lower error floors. Numerical experiments validate the theoretical results, consistently showing that our method outperforms conventional quantization strategies in terms of both accuracy and robustness.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>First-Spammed, First-Served: MEV Extraction on Fast-Finality Blockchains</title>
<link>https://arxiv.org/abs/2506.01462</link>
<guid>https://arxiv.org/abs/2506.01462</guid>
<content:encoded><![CDATA[
arXiv:2506.01462v1 Announce Type: new 
Abstract: This research analyzes the economics of spam-based arbitrage strategies on fast-finality blockchains. We begin by theoretically demonstrating that, splitting a profitable MEV opportunity into multiple small transactions is the optimal strategy for CEX-DEX arbitrageurs. We then empirically validate these findings on major Ethereum rollups. To uncover the structure of reverted transactions, we construct execution graphs from transaction traces and systematically search them to identify DEX or router interactions and targeted liquidity pools. This analysis reveals that 80\% of reverted transactions are swaps with approximately 50\% targeting USDC-WETH pools on Uniswap v3/v4. These patterns intensified following the March 2024 Dencun upgrade, which lowered L2 gas costs and made spam-based arbitrage economically viable. Counterintuitively, we find that these reverted MEV transactions rarely engage with Priority Fee Auctions (PFAs), preferring to submit duplicate transactions rather than bid for inclusion. Moreover, reverted transactions cluster at the very top of blocks on fast rollups like Arbitrum and ZKsync, indicating an intense latency race and revealing the fragility of fee-based ordering under sub-second block times.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Network Digital Twin for 6G and Beyond: An End-to-End View Across Multi-Domain Network Ecosystems</title>
<link>https://arxiv.org/abs/2506.01609</link>
<guid>https://arxiv.org/abs/2506.01609</guid>
<content:encoded><![CDATA[
arXiv:2506.01609v1 Announce Type: new 
Abstract: With the rapid development of technology, the number of smart mobile users is increasing, accompanied by growing demands from applications such as virtual/augmented reality (VR/XR), remote surgery, autonomous vehicles, and real-time holographic communications, all of which require high transmission rates and ultra-low latency in 6G and beyond networks (6G+). This poses enormous challenges in efficiently deploying large-scale networks, including network design, planning, troubleshooting, optimization, and maintenance, without affecting the user experience. Network Digital Twin (NDT) has emerged as a potential solution, enabling the creation of a virtual model that reflects the actual network, supporting the simulation of various network designs, applying diverse operating policies, and reproducing complex fault scenarios under real-world conditions. This motivate us for this study, where we provide a comprehensive survey of NDT in the context of 6G+, covering areas such as radio access networks (RAN), transport networks, 5G core networks and beyond (5GCORE+), cloud/edge computing, applications (blockchain, health system, manufacturing, security, and vehicular networks), non-terrestrial networks (NTNs), and quantum networks, from both academic and industrial perspectives. In particular, we are the first to provide an in-depth guide and usage of RAN and 5GCORE+ for NDT. Then, we provide an extensive review of foundation technologies such as transport networks, cloud/edge computing, applications, NTNs, and quantum networks in NDT. Finally, we discuss the key challenges, open issues, and future research directions for NDT in the context of 6G+.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Contrastive Learning for Efficient Transaction Validation in UTXO-based Blockchains</title>
<link>https://arxiv.org/abs/2506.01614</link>
<guid>https://arxiv.org/abs/2506.01614</guid>
<content:encoded><![CDATA[
arXiv:2506.01614v1 Announce Type: new 
Abstract: This paper introduces a Machine Learning (ML) approach for scalability of UTXO-based blockchains, such as Bitcoin. Prior approaches to UTXO set sharding struggle with distributing UTXOs effectively across validators, creating substantial communication overhead due to child-parent transaction dependencies. This overhead, which arises from the need to locate parent UTXOs, significantly hampers transaction processing speeds. Our solution uses ML to optimize not only UTXO set sharding but also the routing of incoming transactions, ensuring that transactions are directed to shards containing their parent UTXOs. At the heart of our approach is a framework that combines contrastive and unsupervised learning to create an embedding space for transaction outputs. This embedding allows the model to group transaction outputs based on spending relationships, making it possible to route transactions efficiently to the correct validation microservices. Trained on historical transaction data with triplet loss and online semi-hard negative mining, the model embeds parent-child spending patterns directly into its parameters, thus eliminating the need for costly, real-time parent transaction lookups. This significantly reduces cross-shard communication overhead, boosting throughput and scalability.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DRAUN: An Algorithm-Agnostic Data Reconstruction Attack on Federated Unlearning Systems</title>
<link>https://arxiv.org/abs/2506.01777</link>
<guid>https://arxiv.org/abs/2506.01777</guid>
<content:encoded><![CDATA[
arXiv:2506.01777v1 Announce Type: new 
Abstract: Federated Unlearning (FU) enables clients to remove the influence of specific data from a collaboratively trained shared global model, addressing regulatory requirements such as GDPR and CCPA. However, this unlearning process introduces a new privacy risk: A malicious server may exploit unlearning updates to reconstruct the data requested for removal, a form of Data Reconstruction Attack (DRA). While DRAs for machine unlearning have been studied extensively in centralized Machine Learning-as-a-Service (MLaaS) settings, their applicability to FU remains unclear due to the decentralized, client-driven nature of FU. This work presents DRAUN, the first attack framework to reconstruct unlearned data in FU systems. DRAUN targets optimization-based unlearning methods, which are widely adopted for their efficiency. We theoretically demonstrate why existing DRAs targeting machine unlearning in MLaaS fail in FU and show how DRAUN overcomes these limitations. We validate our approach through extensive experiments on four datasets and four model architectures, evaluating its performance against five popular unlearning methods, effectively demonstrating that state-of-the-art FU methods remain vulnerable to DRAs.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Gaussian Mixture Models</title>
<link>https://arxiv.org/abs/2506.01780</link>
<guid>https://arxiv.org/abs/2506.01780</guid>
<content:encoded><![CDATA[
arXiv:2506.01780v1 Announce Type: new 
Abstract: This paper introduces FedGenGMM, a novel one-shot federated learning approach for Gaussian Mixture Models (GMM) tailored for unsupervised learning scenarios. In federated learning (FL), where multiple decentralized clients collaboratively train models without sharing raw data, significant challenges include statistical heterogeneity, high communication costs, and privacy concerns. FedGenGMM addresses these issues by allowing local GMM models, trained independently on client devices, to be aggregated through a single communication round. This approach leverages the generative property of GMMs, enabling the creation of a synthetic dataset on the server side to train a global model efficiently. Evaluation across diverse datasets covering image, tabular, and time series data demonstrates that FedGenGMM consistently achieves performance comparable to non-federated and iterative federated methods, even under significant data heterogeneity. Additionally, FedGenGMM significantly reduces communication overhead, maintains robust performance in anomaly detection tasks, and offers flexibility in local model complexities, making it particularly suitable for edge computing environments.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Synchronic Web Digital Identity: Speculations on the Art of the Possible</title>
<link>https://arxiv.org/abs/2506.01856</link>
<guid>https://arxiv.org/abs/2506.01856</guid>
<content:encoded><![CDATA[
arXiv:2506.01856v1 Announce Type: new 
Abstract: As search, social media, and artificial intelligence continue to reshape collective knowledge, the preservation of trust on the public infosphere has become a defining challenge of our time. Given the breadth and versatility of adversarial threats, the best--and perhaps only--defense is an equally broad and versatile infrastructure for digital identity.
  This document discusses the opportunities and implications of building such an infrastructure from the perspective of a national laboratory. The technical foundation for this discussion is the emergence of the Synchronic Web, a Sandia-developed infrastructure for asserting cryptographic provenance at Internet scale. As of the writing of this document, there is ongoing work to develop the underlying technology and apply it to multiple mission-specific domains within Sandia. The primary objective of this document to extend the body of existing work toward the more public-facing domain of digital identity.
  Our approach depends on a non-standard, but philosophically defensible notion of identity: digital identity is an unbroken sequence of states in a well-defined digital space. From this foundation, we abstractly describe the infrastructural foundations and applied configurations that we expect to underpin future notions of digital identity.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Concurrency in Blockchain - A Systematic Literature Review and the Unveiling of a Misconception</title>
<link>https://arxiv.org/abs/2506.01885</link>
<guid>https://arxiv.org/abs/2506.01885</guid>
<content:encoded><![CDATA[
arXiv:2506.01885v1 Announce Type: new 
Abstract: Smart contracts, the cornerstone of blockchain technology, enable secure, automated distributed execution. Given their role in handling large transaction volumes across clients, miners, and validators, exploring concurrency is critical. This includes concurrent transaction execution or validation within blocks, block processing across shards, and miner competition to select and persist transactions. Concurrency and parallelism are a double-edged sword: while they improve throughput, they also introduce risks like race conditions, non-determinism, and vulnerabilities such as deadlock and livelock.
  This paper presents the first survey of concurrency in smart contracts, offering a systematic literature review organized into key dimensions. First, it establishes a taxonomy of concurrency levels in blockchain systems and discusses proposed solutions for future adoption. Second, it examines vulnerabilities, attacks, and countermeasures in concurrent operations, emphasizing the need for correctness and security. Crucially, we reveal a flawed concurrency assumption in a major research category, which has led to widespread misinterpretation. This work aims to correct that and guide future research toward more accurate models. Finally, we identify gaps in each category to outline future research directions and support blockchain's advancement.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Turbulence to Tranquility: AI-Driven Low-Altitude Network</title>
<link>https://arxiv.org/abs/2506.01378</link>
<guid>https://arxiv.org/abs/2506.01378</guid>
<content:encoded><![CDATA[
arXiv:2506.01378v1 Announce Type: cross 
Abstract: Low Altitude Economy (LAE) networks own transformative potential in urban mobility, emergency response, and aerial logistics. However, these networks face significant challenges in spectrum management, interference mitigation, and real-time coordination across dynamic and resource-constrained environments. After addressing these challenges, this study explores three core elements for enabling intelligent LAE networks as follows machine learning-based spectrum sensing and coexistence, artificial intelligence (AI)-optimized resource allocation and trajectory planning, and testbed-driven validation and standardization. We highlight how federated and reinforcement learning techniques support decentralized, adaptive decision-making under mobility and energy constraints. In addition, we discuss the role of real-world platforms such as AERPAW in bridging the gap between simulation and deployment and enabling iterative system refinement under realistic conditions. This study aims to provide a forward-looking roadmap toward developing efficient and interoperable AI-driven LAE ecosystems.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof of Sampling: A Nash Equilibrium-Based Verification Protocol for Decentralized Systems</title>
<link>https://arxiv.org/abs/2405.00295</link>
<guid>https://arxiv.org/abs/2405.00295</guid>
<content:encoded><![CDATA[
arXiv:2405.00295v3 Announce Type: replace 
Abstract: This paper introduces the Proof of Sampling (PoSP) protocol, a Nash Equilibrium-based verification mechanism, and its application to decentralized machine learning inference through spML. Our protocol has a pure strategy Nash Equilibrium, compelling rational participants to act honestly. It economically disincentivizes dishonest behavior, making it costly for participants to compromise the network's integrity. In our spML protocol, we apply PoSP to decentralized inference for AI applications via a novel cryptographic protocol. The resulting protocol is much more efficient than zero knowledge proof based approaches. Moreover, we anticipate that the PoSP protocol could be effectively utilized for designing verification mechanisms within Actively Validated Services (AVS) in restaking solutions. We further expect that the PoSP protocol could be applied to a variety of other decentralized applications. Our approach enhances the reliability and efficiency of decentralized systems, paving the way for a new generation of decentralized applications.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning</title>
<link>https://arxiv.org/abs/2410.17933</link>
<guid>https://arxiv.org/abs/2410.17933</guid>
<content:encoded><![CDATA[
arXiv:2410.17933v2 Announce Type: replace 
Abstract: One of the biggest challenges of building artificial intelligence (AI) model in healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausted, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America and Asia) while without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaption to make it meet with the privacy and safety requirements of healthcare data, meanwhile rewards honest participation and penalize malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy preserved. Its prediction accuracy is much better than the models trained from limited personal data and is similar to, and even slightly better than, the results from a centralized dataset. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Low-Rank Fine-Tuning of Large Language Models</title>
<link>https://arxiv.org/abs/2501.15361</link>
<guid>https://arxiv.org/abs/2501.15361</guid>
<content:encoded><![CDATA[
arXiv:2501.15361v4 Announce Type: replace 
Abstract: While parameter-efficient fine-tuning (PEFT) techniques like Low-Rank Adaptation (LoRA) offer computationally efficient adaptations of Large Language Models (LLMs), their practical deployment often assumes centralized data and training environments. However, real-world scenarios frequently involve distributed, privacy-sensitive datasets that require decentralized solutions. Federated learning (FL) addresses data privacy by coordinating model updates across clients, but it is typically based on centralized aggregation through a parameter server, which can introduce bottlenecks and communication constraints. Decentralized learning, in contrast, eliminates this dependency by enabling direct collaboration between clients, improving scalability and efficiency in distributed environments. Despite its advantages, decentralized LLM fine-tuning remains underexplored. In this work, we propose Dec-LoRA, a decentralized fine-tuning algorithm for LLMs based on LoRA. Through extensive experiments on BERT and LLaMA-2 models, we demonstrate that Dec-LoRA achieves performance comparable to centralized LoRA under various conditions, including data heterogeneity and quantization constraints. Additionally, we provide a rigorous theoretical guarantee proving the convergence of our algorithm to a stationary point for non-convex and smooth loss functions. These findings highlight the potential of Dec-LoRA for scalable LLM fine-tuning in decentralized environments.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TOPLOC: A Locality Sensitive Hashing Scheme for Trustless Verifiable Inference</title>
<link>https://arxiv.org/abs/2501.16007</link>
<guid>https://arxiv.org/abs/2501.16007</guid>
<content:encoded><![CDATA[
arXiv:2501.16007v2 Announce Type: replace 
Abstract: Large language models (LLMs) have proven to be very capable, but access to frontier models currently relies on inference providers. This introduces trust challenges: how can we be sure that the provider is using the model configuration they claim? We propose TOPLOC, a novel method for verifiable inference that addresses this problem. TOPLOC leverages a compact locality-sensitive hashing mechanism for intermediate activations, which can detect unauthorized modifications to models, prompts, or precision with 100% accuracy, achieving no false positives or negatives in our empirical evaluations. Our approach is robust across diverse hardware configurations, GPU types, and algebraic reorderings, which allows for validation speeds significantly faster than the original inference. By introducing a polynomial encoding scheme, TOPLOC minimizes the memory overhead of the generated proofs by $1000\times$, requiring only 258 bytes of storage per 32 new tokens, compared to the 262 KB requirement of storing the token embeddings directly for Llama 3.1-8B-Instruct. Our method empowers users to verify LLM inference computations efficiently, fostering greater trust and transparency in open ecosystems and laying a foundation for decentralized, verifiable and trustless AI services.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Trust Foundation Models: A New Paradigm for Secure and Collaborative Artificial Intelligence for Internet of Things</title>
<link>https://arxiv.org/abs/2505.23792</link>
<guid>https://arxiv.org/abs/2505.23792</guid>
<content:encoded><![CDATA[
arXiv:2505.23792v1 Announce Type: new 
Abstract: This paper focuses on Zero-Trust Foundation Models (ZTFMs), a novel paradigm that embeds zero-trust security principles into the lifecycle of foundation models (FMs) for Internet of Things (IoT) systems. By integrating core tenets, such as continuous verification, least privilege access (LPA), data confidentiality, and behavioral analytics into the design, training, and deployment of FMs, ZTFMs can enable secure, privacy-preserving AI across distributed, heterogeneous, and potentially adversarial IoT environments. We present the first structured synthesis of ZTFMs, identifying their potential to transform conventional trust-based IoT architectures into resilient, self-defending ecosystems. Moreover, we propose a comprehensive technical framework, incorporating federated learning (FL), blockchain-based identity management, micro-segmentation, and trusted execution environments (TEEs) to support decentralized, verifiable intelligence at the network edge. In addition, we investigate emerging security threats unique to ZTFM-enabled systems and evaluate countermeasures, such as anomaly detection, adversarial training, and secure aggregation. Through this analysis, we highlight key open research challenges in terms of scalability, secure orchestration, interpretable threat attribution, and dynamic trust calibration. This survey lays a foundational roadmap for secure, intelligent, and trustworthy IoT infrastructures powered by FMs.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems</title>
<link>https://arxiv.org/abs/2505.23847</link>
<guid>https://arxiv.org/abs/2505.23847</guid>
<content:encoded><![CDATA[
arXiv:2505.23847v1 Announce Type: new 
Abstract: Large language models (LLMs) are rapidly evolving into autonomous agents that cooperate across organizational boundaries, enabling joint disaster response, supply-chain optimization, and other tasks that demand decentralized expertise without surrendering data ownership. Yet, cross-domain collaboration shatters the unified trust assumptions behind current alignment and containment techniques. An agent benign in isolation may, when receiving messages from an untrusted peer, leak secrets or violate policy, producing risks driven by emergent multi-agent dynamics rather than classical software bugs. This position paper maps the security agenda for cross-domain multi-agent LLM systems. We introduce seven categories of novel security challenges, for each of which we also present plausible attacks, security evaluation metrics, and future research guidelines.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CADRE: Customizable Assurance of Data Readiness in Privacy-Preserving Federated Learning</title>
<link>https://arxiv.org/abs/2505.23849</link>
<guid>https://arxiv.org/abs/2505.23849</guid>
<content:encoded><![CDATA[
arXiv:2505.23849v1 Announce Type: new 
Abstract: Privacy-Preserving Federated Learning (PPFL) is a decentralized machine learning approach where multiple clients train a model collaboratively. PPFL preserves privacy and security of the client's data by not exchanging it. However, ensuring that data at each client is of high quality and ready for federated learning (FL) is a challenge due to restricted data access. In this paper, we introduce CADRE (Customizable Assurance of Data REadiness) for FL, a novel framework that allows users to define custom data readiness (DR) standards, metrics, rules, and remedies tailored to specific FL tasks. Our framework generates comprehensive DR reports based on the user-defined metrics, rules, and remedies to ensure datasets are optimally prepared for FL while preserving privacy. We demonstrate the framework's practical application by integrating it into an existing PPFL framework. We conducted experiments across six diverse datasets, addressing seven different DR issues. The results illustrate the framework's versatility and effectiveness in ensuring DR across various dimensions, including data quality, privacy, and fairness. This approach enhances the performance and reliability of FL models as well as utilizes valuable resources by identifying and addressing data-related issues before the training phase.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Neural Policy Gradient Algorithm for Global Convergence of Networked Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.24113</link>
<guid>https://arxiv.org/abs/2505.24113</guid>
<content:encoded><![CDATA[
arXiv:2505.24113v1 Announce Type: new 
Abstract: This paper studies the networked multi-agent reinforcement learning (NMARL) problem, where the objective of agents is to collaboratively maximize the discounted average cumulative rewards. Different from the existing methods that suffer from poor expression due to linear function approximation, we propose a distributed neural policy gradient algorithm that features two innovatively designed neural networks, specifically for the approximate Q-functions and policy functions of agents. This distributed neural policy gradient algorithm consists of two key components: the distributed critic step and the decentralized actor step. In the distributed critic step, agents receive the approximate Q-function parameters from their neighboring agents via a time-varying communication networks to collaboratively evaluate the joint policy. In contrast, in the decentralized actor step, each agent updates its local policy parameter solely based on its own approximate Q-function. In the convergence analysis, we first establish the global convergence of agents for the joint policy evaluation in the distributed critic step. Subsequently, we rigorously demonstrate the global convergence of the overall distributed neural policy gradient algorithm with respect to the objective function. Finally, the effectiveness of the proposed algorithm is demonstrated by comparing it with a centralized algorithm through simulation in the robot path planning environment.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transaction Proximity: A Graph-Based Approach to Blockchain Fraud Prevention</title>
<link>https://arxiv.org/abs/2505.24284</link>
<guid>https://arxiv.org/abs/2505.24284</guid>
<content:encoded><![CDATA[
arXiv:2505.24284v1 Announce Type: new 
Abstract: This paper introduces a fraud-deterrent access validation system for public blockchains, leveraging two complementary concepts: "Transaction Proximity", which measures the distance between wallets in the transaction graph, and "Easily Attainable Identities (EAIs)", wallets with direct transaction connections to centralized exchanges. Recognizing the limitations of traditional approaches like blocklisting (reactive, slow) and strict allow listing (privacy-invasive, adoption barriers), we propose a system that analyzes transaction patterns to identify wallets with close connections to centralized exchanges.
  Our directed graph analysis of the Ethereum blockchain reveals that 56% of large USDC wallets (with a lifetime maximum balance greater than \$10,000) are EAI and 88% are within one transaction hop of an EAI. For transactions exceeding \$2,000, 91% involve at least one EAI. Crucially, an analysis of past exploits shows that 83% of the known exploiter addresses are not EAIs, with 21% being more than five hops away from any regulated exchange. We present three implementation approaches with varying gas cost and privacy tradeoffs, demonstrating that EAI-based access control can potentially prevent most of these incidents while preserving blockchain openness. Importantly, our approach does not restrict access or share personally identifiable information, but it provides information for protocols to implement their own validation or risk scoring systems based on specific needs. This middle-ground solution enables programmatic compliance while maintaining the core values of open blockchain.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Verifiable Weighted Secret Sharing</title>
<link>https://arxiv.org/abs/2505.24289</link>
<guid>https://arxiv.org/abs/2505.24289</guid>
<content:encoded><![CDATA[
arXiv:2505.24289v1 Announce Type: new 
Abstract: Traditionally, threshold secret sharing (TSS) schemes assume all parties have equal weight, yet emerging systems like blockchains reveal disparities in party trustworthiness, such as stake or reputation. Weighted Secret Sharing (WSS) addresses this by assigning varying weights to parties, ensuring security even if adversaries control parties with total weight at most a threshold $t$. Current WSS schemes assume honest dealers, resulting in security from only honest-but-curious behaviour but not protection from malicious adversaries for downstream applications. \emph{Verifiable} secret sharing (VSS) is a well-known technique to address this, but existing VSS schemes are either tailored to TSS, or require additional trust assumptions. We propose the first efficient verifiable WSS scheme that tolerates malicious dealers and is compatible with the latest CRT-based WSS~\cite{crypto_w_weights}. Our solution uses Bulletproofs for efficient verification and introduces new privacy-preserving techniques for proving relations between committed values, which may be of independent interest. Evaluation on Ethereum show up to a $100\times$ improvement in communication complexity compared to the current design and $20\times$ improvement compared to unweighted VSS schemes.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Supporting Long-term Transactions in Smart Contracts Generated from Business Process Model and Notation (BPMN) Models</title>
<link>https://arxiv.org/abs/2505.24309</link>
<guid>https://arxiv.org/abs/2505.24309</guid>
<content:encoded><![CDATA[
arXiv:2505.24309v1 Announce Type: new 
Abstract: To alleviate difficulties in writing smart contracts for distributed blockchain applications, as other research, we propose transformation of Business Process Model and Notation (BPMN) models into blockchain smart contracts. Unlike other research, we use Discrete Event Hierarchical State Machine (DE-HSM) multi-modal modeling to identify collaborative trade transactions that need to be supported by the smart contract and describe how the trade transactions, that may be nested, are supported by a transaction mechanism. We describe algorithms to (i) identify the nested trade transactions and to (ii) transform the BPMN model into blockchains smart contracts that include a transaction mechanism to enforce the transactional properties for the identified trade transactions. The developed proof of concept shows that our approach to automated transformation of BPMN models into smart contracts with the support of privacy and cross-chain interoperability is feasible. The thesis examines and evaluates automatically generated alternative transaction mechanisms to support such transactions using three use cases of varying degree of complexity, namely order processing, supply chain management, and a multi-faceted trade use case. The research enriches the academic dialogue on blockchain technology and smart contracts and proposes potential avenues for future research.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Singularity Protocol for Cross Chain AMM without Intermediate Tokens or Bridges</title>
<link>https://arxiv.org/abs/2505.24337</link>
<guid>https://arxiv.org/abs/2505.24337</guid>
<content:encoded><![CDATA[
arXiv:2505.24337v1 Announce Type: new 
Abstract: Automated Market Makers (AMMs) are decentralized exchange protocols that provide continuous access to token liquidity without the need for order books or traditional market makers. However, this innovation has failed to scale when it comes to cross-chain swaps. Modern cross-chain swaps employ double-sided AMMs, which are not only inefficient due to liquidity fragmentation but also require an intermediate token. This introduces inherent volatility risk as well as blockchain and bridging risk, especially in the case of wrapped tokens. This paper describes the inefficiencies of existing AMM invariants, particularly their mixed polynomial nature, and derives a new class of AMMs that do not have bi-state dependency between the assets being swapped. We propose a novel method of value transfer swaps using the described invariant that mitigates the need for bi-state dependency and eliminates the need for intermediate tokens or bridging. Furthermore, we show how this mechanism enables efficient cross-chain swaps with lower gas requirements and no bridging risks. The proposed technology is designed to support cross-chain swaps across any permutation of L1, L2, and L3 blockchains.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Looking for Attention: Randomized Attention Test Design for Validator Monitoring in Optimistic Rollups</title>
<link>https://arxiv.org/abs/2505.24393</link>
<guid>https://arxiv.org/abs/2505.24393</guid>
<content:encoded><![CDATA[
arXiv:2505.24393v1 Announce Type: new 
Abstract: Optimistic Rollups (ORUs) significantly enhance blockchain scalability but inherently suffer from the verifier's dilemma, particularly concerning validator attentiveness. Current systems lack mechanisms to proactively ensure validators are diligently monitoring L2 state transitions, creating a vulnerability where fraudulent states could be finalized. This paper introduces the Randomized Attention Test (RAT), a novel L1-based protocol designed to probabilistically challenge validators in ORUs, thereby verifying their liveness and computational readiness. Our game-theoretic analysis demonstrates that an Ideal Security Equilibrium, where all validators are attentive and proposers are honest, can be achieved with RAT. Notably, this equilibrium is attainable and stable with relatively low economic penalties (e.g., under $1000) for non-responsive validators and a low attention test frequency (e.g., under 1% per epoch). RAT thus provides a crucial, practical mechanism to enforce validator diligence, fortifying the overall security and integrity of ORU systems with minimizing additional costs.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balancing incentives in committee-based blockchains</title>
<link>https://arxiv.org/abs/2505.24482</link>
<guid>https://arxiv.org/abs/2505.24482</guid>
<content:encoded><![CDATA[
arXiv:2505.24482v1 Announce Type: new 
Abstract: Blockchain protocols incentivize participation through monetary rewards, assuming rational actors behave honestly to maximize their gains. However, attackers may attempt to harm others even at personal cost. These denial of profit attacks aim to reduce the rewards of honest participants, potentially forcing them out of the system. While existing work has largely focused on the profitability of attacks, they often neglect the potential harm inflicted on the victim, which can be significant even when the attacker gains little or nothing.
  This paper introduces a framework to quantify denial of profit attacks by measuring both attacker cost and victim loss. We model these attacks as a game and introduce relevant metrics to quantify these attacks. We then focus on committee-based blockchains and model vote collection as a game. We show that in the vote collection game, disincentivizing one denial of profit attack will make another attack more appealing, and therefore, attacks have to be balanced. We apply our framework to analyze real-world reward mechanisms in Ethereum and Cosmos. Our framework reveals imbalances in Cosmos that can make correct behavior suboptimal in practice. While Ethereum provides stronger protections, our framework shows that it is also not complete, and we propose alternative parameter settings to improve the balance between attacks. Our findings highlight the need for better-balanced reward designs to defend against denial of profit attacks.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Explaining Sustained Blockchain Decentralization with Quasi-Experiments: Resource Flexibility of Consensus Mechanisms</title>
<link>https://arxiv.org/abs/2505.24663</link>
<guid>https://arxiv.org/abs/2505.24663</guid>
<content:encoded><![CDATA[
arXiv:2505.24663v1 Announce Type: new 
Abstract: Decentralization is a fundamental design element of the Web3 economy. Blockchains and distributed consensus mechanisms are touted as fault-tolerant, attack-resistant, and collusion-proof because they are decentralized. Recent analyses, however, find some blockchains are decentralized, others are centralized, and that there are trends towards both centralization and decentralization in the blockchain economy. Despite the importance and variability of decentralization across blockchains, we still know little about what enables or constrains blockchain decentralization. We hypothesize that the resource flexibility of consensus mechanisms is a key enabler of the sustained decentralization of blockchain networks. We test this hypothesis using three quasi-experimental shocks -- policy-related, infrastructure-related, and technical -- to resources used in consensus. We find strong suggestive evidence that the resource flexibility of consensus mechanisms enables sustained blockchain decentralization and discuss the implications for the design, regulation, and implementation of blockchains.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustworthy Provenance for Big Data Science: a Modular Architecture Leveraging Blockchain in Federated Settings</title>
<link>https://arxiv.org/abs/2505.24675</link>
<guid>https://arxiv.org/abs/2505.24675</guid>
<content:encoded><![CDATA[
arXiv:2505.24675v1 Announce Type: new 
Abstract: Ensuring the trustworthiness and long-term verifiability of scientific data is a foundational challenge in the era of data-intensive, collaborative research. Provenance metadata plays a key role in this context, capturing the origin, transformation, and usage of research artifacts. However, existing solutions often fall short when applied to distributed, multi-institutional settings. This paper introduces a modular, domain-agnostic architecture for provenance tracking in federated environments, leveraging permissioned blockchain infrastructure to guarantee integrity, immutability, and auditability. The system supports decentralized interaction, persistent identifiers for artifact traceability, and a provenance versioning model that preserves the history of updates. Designed to interoperate with diverse scientific domains, the architecture promotes transparency, accountability, and reproducibility across organizational boundaries. Ongoing work focuses on validating the system through a distributed prototype and exploring its performance in collaborative settings.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Next Generation Authentication for Data Spaces: An Authentication Flow Based On Grant Negotiation And Authorization Protocol For Verifiable Presentations (GNAP4VP)</title>
<link>https://arxiv.org/abs/2505.24698</link>
<guid>https://arxiv.org/abs/2505.24698</guid>
<content:encoded><![CDATA[
arXiv:2505.24698v1 Announce Type: new 
Abstract: Identity verification in Data Spaces is a fundamental aspect of ensuring security and privacy in digital environments. This paper presents an identity verification protocol tailored for shared data environments within Data Spaces. This protocol extends the Grant Negotiation and Authorization Protocol (GNAP) and integrates OpenID Connect for Verifiable Presentations (OIDC4VP) along with support for Linked Verifiable Presentations (LVP), providing a robust foundation for secure and privacy-preserving interactions. The proposed solution adheres to the principles of Self-Sovereign Identity (SSI) to facilitate decentralized, user-centric identity management while maintaining flexibility through protocol negotiation. Two alternative interaction flows are introduced: a "Wallet-Driven Interaction" utilizing OIDC4VP, and a "LVP Authorization" model for fully automated machine-to-machine communication. These flows address critical challenges encountered in Data Spaces, including privacy, interoperability, and regulatory compliance while simultaneously ensuring scalability and minimizing trust assumptions. The paper provides a detailed technical design, outlining the implementation considerations, and demonstrating how the proposed flows guarantee verifiable, secure, and efficient interactions between participants. This work contributes towards the establishment of a more trustworthy and sovereign digital infrastructure, in alignment with emerging European data governance initiatives.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Talking Transactions: Decentralized Communication through Ethereum Input Data Messages (IDMs)</title>
<link>https://arxiv.org/abs/2505.24724</link>
<guid>https://arxiv.org/abs/2505.24724</guid>
<content:encoded><![CDATA[
arXiv:2505.24724v1 Announce Type: new 
Abstract: Can you imagine, blockchain transactions can talk! In this paper, we study how they talk and what they talk about. We focus on the input data field of Ethereum transactions, which is designed to allow external callers to interact with smart contracts. In practice, this field also enables users to embed natural language messages into transactions. Users can leverage these Input Data Messages (IDMs) for peer-to-peer communication. This means that, beyond Ethereum's well-known role as a financial infrastructure, it also serves as a decentralized communication medium.
  We present the first large-scale analysis of Ethereum IDMs from the genesis block to February 2024 (3134 days). We filter IDMs to extract 867,140 transactions with informative IDMs and use LLMs for language detection. We find that English (95.4%) and Chinese (4.4%) dominate the use of natural languages in IDMs. Interestingly, English IDMs center on security and scam warnings (24%) with predominantly negative emotions, while Chinese IDMs emphasize emotional expression and social connection (44%) with a more positive tone. We also observe that longer English IDMs often transfer high ETH values for protocol-level purposes, while longer Chinese IDMs tend to involve symbolic transfer amounts for emotional intent. Moreover, we find that the IDM participants tend to form small, loosely connected communities (59.99%). Our findings highlight culturally and functionally divergent use cases of the IDM channel across user communities. We further examine the security relevance of IDMs in on-chain attacks. Many victims use them to appeal to attackers for fund recovery. IDMs containing negotiations or reward offers are linked to higher reply rates. We also analyze IDMs' regulatory implications. Their misuse for abuse, threats, and sexual solicitation reveals the urgent need for content moderation and regulation in decentralized systems.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption</title>
<link>https://arxiv.org/abs/2505.24773</link>
<guid>https://arxiv.org/abs/2505.24773</guid>
<content:encoded><![CDATA[
arXiv:2505.24773v1 Announce Type: new 
Abstract: Federated fine-tuning has emerged as a promising approach to adapt foundation models to downstream tasks using decentralized data. However, real-world deployment remains challenging due to the high computational and communication demands of fine-tuning Large Language Models (LLMs) on clients with data and system resources that are heterogeneous and constrained. In such settings, the global model's performance is often bottlenecked by the weakest clients and further degraded by the non-IID nature of local data. Although existing methods leverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to reduce communication and computation overhead, they often fail to simultaneously ensure accurate aggregation of low-rank updates and maintain low system costs, thereby hindering overall performance. To address these challenges, we propose AFLoRA, an adaptive and lightweight federated fine-tuning framework for LLMs. AFLoRA decouples shared and client-specific updates to reduce overhead and improve aggregation accuracy, incorporates diagonal matrix-based rank pruning to better utilize local resources, and employs rank-aware aggregation with public data refinement to strengthen generalization under data heterogeneity. Extensive experiments demonstrate that AFLoRA outperforms state-of-the-art methods in both accuracy and efficiency, providing a practical solution for efficient LLM adaptation in heterogeneous environments in the real world.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Targeted Nakamoto: A Bitcoin Protocol to Balance Network Security and Energy Consumption</title>
<link>https://arxiv.org/abs/2405.15089</link>
<guid>https://arxiv.org/abs/2405.15089</guid>
<content:encoded><![CDATA[
arXiv:2405.15089v3 Announce Type: replace 
Abstract: In a Proof-of-Work blockchain such as Bitcoin mining hashrate is increasing in the block reward. An increase in hashrate reduces network vulnerability to attack (a reduction in security cost) while increasing carbon emissions and electricity cost (an increase in externalities cost). This implies a tradeoff in total cost at different levels of hashrate and the existence of a hashrate interval where total cost is minimized. Targeted Nakamoto is a Proof-of-Work protocol augmentation that incentivizes miners to hone in on a target hashrate interval. When hashrate is above target a ceiling is placed on the block reward a miner can receive. When hashrate is below target a floor is placed underneath the miner's block reward. Monetary neutrality is maintained by a proportional increase in spending potential among addresses holding UTXO's to match a deduction from total block reward when the ceiling is operative and a proportional reduction in spending potential among addresses holding UTXO's to match an increase over the total block reward when the floor is binding.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models</title>
<link>https://arxiv.org/abs/2505.22804</link>
<guid>https://arxiv.org/abs/2505.22804</guid>
<content:encoded><![CDATA[
arXiv:2505.22804v1 Announce Type: new 
Abstract: Recent manufacturing systems are increasingly adopting multi-robot collaboration to handle complex and dynamic environments. While multi-agent architectures support decentralized coordination among robot agents, they often face challenges in enabling real-time adaptability for unexpected disruptions without predefined rules. Recent advances in large language models offer new opportunities for context-aware decision-making to enable adaptive responses to unexpected changes. This paper presents an initial exploratory implementation of a large language model-enabled control framework for dynamic task reassignment in multi-robot manufacturing systems. A central controller agent leverages the large language model's ability to interpret structured robot configuration data and generate valid reassignments in response to robot failures. Experiments in a real-world setup demonstrate high task success rates in recovering from failures, highlighting the potential of this approach to improve adaptability in multi-robot manufacturing systems.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Seeing the Politics of Decentralized Social Media Protocols</title>
<link>https://arxiv.org/abs/2505.22962</link>
<guid>https://arxiv.org/abs/2505.22962</guid>
<content:encoded><![CDATA[
arXiv:2505.22962v1 Announce Type: new 
Abstract: Calls to decentralize feed-based social media have been driven by concerns about the concentrated power of centralized platforms and their societal impact. In response, numerous decentralized social media protocols have emerged, each interpreting "decentralization" in different ways. We analyze four such protocols -- ActivityPub, AT Protocol, Nostr, and Farcaster -- to develop a novel conceptual framework for understanding how protocols operationalize decentralization. Drawing from protocol documentation, media coverage, and first-hand interviews with protocol developers and experts, we contextualize each protocol's approach within their respective socio-technical goals. Our framework highlights how control over key components is distributed differently across each protocol, shaping who holds power over what kinds of decisions. How components are arranged in relation to one another further impacts how component owners might offset each other's power in shaping social media. We argue that examining protocols as artifacts reveals how values shape infrastructure and power dynamics -- and that with a holistic framework as a guide, we can more effectively evaluate and design decentralized platforms aligned with the social and political futures we envision.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chainless Apps: A Modular Framework for Building Apps with Web2 Capability and Web3 Trust</title>
<link>https://arxiv.org/abs/2505.22989</link>
<guid>https://arxiv.org/abs/2505.22989</guid>
<content:encoded><![CDATA[
arXiv:2505.22989v1 Announce Type: new 
Abstract: Modern blockchain applications are often constrained by a trade-off between user experience and trust. Chainless Apps present a new paradigm of application architecture that separates execution, trust, bridging, and settlement into distinct compostable layers. This enables app-specific sequencing, verifiable off-chain computation, chain-agnostic asset and message routing via Agglayer, and finality on Ethereum - resulting in fast Web2-like UX with Web3-grade verifiability. Although consensus mechanisms have historically underpinned verifiable computation, the advent of zkVMs and decentralized validation services opens up new trust models for developers. Chainless Apps leverage this evolution to offer modular, scalable applications that maintain interoperability with the broader blockchain ecosystem while allowing domain-specific trade-offs.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Measuring Participant Contributions in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2505.23246</link>
<guid>https://arxiv.org/abs/2505.23246</guid>
<content:encoded><![CDATA[
arXiv:2505.23246v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train models without sharing their data. Measuring participant contributions in FL is crucial for incentivizing clients and ensuring transparency. While various methods have been proposed for contribution measurement, they are designed exclusively for centralized federated learning (CFL), where a central server collects and aggregates client models, along with evaluating their contributions. Meanwhile, decentralized federated learning (DFL), in which clients exchange models directly without a central server, has gained significant attention for mitigating communication bottlenecks and eliminating a single point of failure. However, applying existing contribution measurement methods to DFL is challenging due to the presence of multiple global models and the absence of a central server. In this study, we present novel methodologies for measuring participant contributions in DFL. We first propose DFL-Shapley, an extension of the Shapley value tailored for DFL, adapting this widely used CFL metric to decentralized settings. Given the impracticality of computing the ideal DFL-Shapley in real-world systems, we introduce DFL-MR, a computable approximation that estimates overall contributions by accumulating round-wise Shapley values. We evaluate DFL-Shapley and DFL-MR across various FL scenarios and compare them with existing CFL metrics. The experimental results confirm DFL-Shapley as a valid ground-truth metric and demonstrate DFL-MR's proximity to DFL-Shapley across various settings, highlighting their effectiveness as contribution metrics in DFL.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Context-Aware Semantic Communication for the Wireless Networks</title>
<link>https://arxiv.org/abs/2505.23249</link>
<guid>https://arxiv.org/abs/2505.23249</guid>
<content:encoded><![CDATA[
arXiv:2505.23249v1 Announce Type: new 
Abstract: In next-generation wireless networks, supporting real-time applications such as augmented reality, autonomous driving, and immersive Metaverse services demands stringent constraints on bandwidth, latency, and reliability. Existing semantic communication (SemCom) approaches typically rely on static models, overlooking dynamic conditions and contextual cues vital for efficient transmission. To address these challenges, we propose CaSemCom, a context-aware SemCom framework that leverages a Large Language Model (LLM)-based gating mechanism and a Mixture of Experts (MoE) architecture to adaptively select and encode only high-impact semantic features across multiple data modalities. Our multimodal, multi-user case study demonstrates that CaSemCom significantly improves reconstructed image fidelity while reducing bandwidth usage, outperforming single-agent deep reinforcement learning (DRL) methods and traditional baselines in convergence speed, semantic accuracy, and retransmission overhead.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Unsupervised Semantic Segmentation</title>
<link>https://arxiv.org/abs/2505.23292</link>
<guid>https://arxiv.org/abs/2505.23292</guid>
<content:encoded><![CDATA[
arXiv:2505.23292v1 Announce Type: new 
Abstract: This work explores the application of Federated Learning (FL) in Unsupervised Semantic image Segmentation (USS). Recent USS methods extract pixel-level features using frozen visual foundation models and refine them through self-supervised objectives that encourage semantic grouping. These features are then grouped to semantic clusters to produce segmentation masks. Extending these ideas to federated settings requires feature representation and cluster centroid alignment across distributed clients -- an inherently difficult task under heterogeneous data distributions in the absence of supervision. To address this, we propose FUSS Federated Unsupervised image Semantic Segmentation) which is, to our knowledge, the first framework to enable fully decentralized, label-free semantic segmentation training. FUSS introduces novel federation strategies that promote global consistency in feature and prototype space, jointly optimizing local segmentation heads and shared semantic centroids. Experiments on both benchmark and real-world datasets, including binary and multi-class segmentation tasks, show that FUSS consistently outperforms local-only client trainings as well as extensions of classical FL algorithms under varying client data distributions. To support reproducibility, full code will be released upon manuscript acceptance.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Split the Yield, Share the Risk: Pricing, Hedging and Fixed rates in DeFi</title>
<link>https://arxiv.org/abs/2505.22784</link>
<guid>https://arxiv.org/abs/2505.22784</guid>
<content:encoded><![CDATA[
arXiv:2505.22784v1 Announce Type: cross 
Abstract: We present the first formal treatment of \emph{yield tokenization}, a mechanism that decomposes yield-bearing assets into principal and yield components to facilitate risk transfer and price discovery in decentralized finance (DeFi). We propose a model that characterizes yield token dynamics using stochastic differential equations. We derive a no-arbitrage pricing framework for yield tokens, enabling their use in hedging future yield volatility and managing interest rate risk in decentralized lending pools. Taking DeFi lending as our focus, we show how both borrowers and lenders can use yield tokens to achieve optimal hedging outcomes and mitigate exposure to adversarial interest rate manipulation. Furthermore, we design automated market makers (AMMs) that incorporate a menu of bonding curves to aggregate liquidity from participants with heterogeneous risk preferences. This leads to an efficient and incentive-compatible mechanism for trading yield tokens and yield futures. Building on these foundations, we propose a modular \textit{fixed-rate} lending protocol that synthesizes on-chain yield token markets and lending pools, enabling robust interest rate discovery and enhancing capital efficiency. Our work provides the theoretical underpinnings for risk management and fixed-income infrastructure in DeFi, offering practical mechanisms for stable and sustainable yield markets.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Smart-Contract to Resolve Multiple Equilibrium in Intermediated Trade</title>
<link>https://arxiv.org/abs/2505.22940</link>
<guid>https://arxiv.org/abs/2505.22940</guid>
<content:encoded><![CDATA[
arXiv:2505.22940v1 Announce Type: cross 
Abstract: We present a model of a market that is intermediated by broker-dealers where there is multiple equilibrium. We then design a smart-contract that receives messages and algorithmically sends trading instructions. The smart-contract resolves the multiple equilibrium by implementing broker-dealer joint profit maximization as a Nash equilibrium. This outcome relies upon several factors: Agent commitments to follow the smart contract protocol; selective privacy of information; a structured timing of trade offers and acceptances and, crucially, trust that the smart-contract will execute the correct algorithm. Commitment is achieved by a legal contract or contingent deposit that incentivizes agents to comply with the protocol. Privacy is maintained by using fully homomorphic encryption. Multiple equilibrium is resolved by imposing a sequential ordering of trade offers and acceptances, and trust in the smart-contract is achieved by appending the smart-contract to a public blockchain, thereby enabling verification of its computations. This model serves as an example of how a smart-contract implemented with cryptography and blockchain can improve market outcomes.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A blockchain-based intelligent recommender system framework for enhancing supply chain resilience</title>
<link>https://arxiv.org/abs/2404.00306</link>
<guid>https://arxiv.org/abs/2404.00306</guid>
<content:encoded><![CDATA[
arXiv:2404.00306v3 Announce Type: replace 
Abstract: This research proposed a data-driven supply chain disruption response baseline framework based on intelligent recommender system technology as an initial SCRes reactive solution. To improve the data quality and reliability of the proposed IRS as a stable, secure, and resilient decision support system, blockchain technology is integrated into the baseline architecture. The smart contract is prototyped to demonstrate the information exchange mechanism under a BLC network environment. The BLC-IRS framework is then implemented with an industrial case to demonstrate its executable function. A system dynamics (SD) simulation model is adopted to validate the BLC-IRS framework as an effective digital SCRes enhancement measure. The simulation results indicated that the proposed BLC-IRS framework can be effectively implemented as a SC disruption mitigation measure in the SCRes response phase as reactive measure, enabling SC participants to react better to SC disruptions at the physical level. Compared to previous studies that limited at the conceptual level as the proactive SCRes measure with a standalone fashion, the developed BLC-IRS contributes an executable SCRes digital solution with synthetic technologies as a reactive SCRes measure for the SCRes community, by identifying the internal and external supplementary resource information in an agile, safe, and real-time manner after SC disruption.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Emergent social conventions and collective bias in LLM populations</title>
<link>https://arxiv.org/abs/2410.08948</link>
<guid>https://arxiv.org/abs/2410.08948</guid>
<content:encoded><![CDATA[
arXiv:2410.08948v2 Announce Type: replace 
Abstract: Social conventions are the backbone of social coordination, shaping how individuals form a group. As growing populations of artificial intelligence (AI) agents communicate through natural language, a fundamental question is whether they can bootstrap the foundations of a society. Here, we present experimental results that demonstrate the spontaneous emergence of universally adopted social conventions in decentralized populations of large language model (LLM) agents. We then show how strong collective biases can emerge during this process, even when agents exhibit no bias individually. Last, we examine how committed minority groups of adversarial LLM agents can drive social change by imposing alternative social conventions on the larger population. Our results show that AI systems can autonomously develop social conventions without explicit programming and have implications for designing AI systems that align, and remain aligned, with human values and societal goals.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentivizing Permissionless Distributed Learning of LLMs</title>
<link>https://arxiv.org/abs/2505.21684</link>
<guid>https://arxiv.org/abs/2505.21684</guid>
<content:encoded><![CDATA[
arXiv:2505.21684v1 Announce Type: new 
Abstract: We describe an incentive system for distributed deep learning of foundational models where peers are rewarded for contributions. The incentive system, \textit{Gauntlet}, has been deployed on the bittensor blockchain and used to train a 1.2B LLM with completely permissionless contributions of pseudo-gradients: no control over the users that can register or their hardware. \textit{Gauntlet} can be applied to any synchronous distributed training scheme that relies on aggregating updates or pseudo-gradients. We rely on a two-stage mechanism for fast filtering of peer uptime, reliability, and synchronization, combined with the core component that estimates the loss before and after individual pseudo-gradient contributions. We utilized an OpenSkill rating system to track competitiveness of pseudo-gradient scores across time. Finally, we introduce a novel mechanism to ensure peers on the network perform unique computations. Our live 1.2B run, which has paid out real-valued tokens to participants based on the value of their contributions, yielded a competitive (on a per-iteration basis) 1.2B model that demonstrates the utility of our incentive system.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.21985</link>
<guid>https://arxiv.org/abs/2505.21985</guid>
<content:encoded><![CDATA[
arXiv:2505.21985v1 Announce Type: new 
Abstract: In multi-agent reinforcement learning (MARL), effective communication improves agent performance, particularly under partial observability. We propose MARL-CPC, a framework that enables communication among fully decentralized, independent agents without parameter sharing. MARL-CPC incorporates a message learning model based on collective predictive coding (CPC) from emergent communication research. Unlike conventional methods that treat messages as part of the action space and assume cooperation, MARL-CPC links messages to state inference, supporting communication in non-cooperative, reward-independent settings. We introduce two algorithms -Bandit-CPC and IPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that both outperform standard message-as-action approaches, establishing effective communication even when messages offer no direct benefit to the sender. These results highlight MARL-CPC's potential for enabling coordination in complex, decentralized environments.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BPMN to Smart Contract by Business Analyst</title>
<link>https://arxiv.org/abs/2505.22612</link>
<guid>https://arxiv.org/abs/2505.22612</guid>
<content:encoded><![CDATA[
arXiv:2505.22612v1 Announce Type: new 
Abstract: This paper addresses the challenge of creating smart contracts for applications represented using Business Process Management and Notation (BPMN) models. In our prior work we presented a methodology that automates the generation of smart contracts from BPMN models. This approach abstracts the BPMN flow control, making it independent of the underlying blockchain infrastructure, with only the BPMN task elements requiring coding. In subsequent research, we enhanced our approach by adding support for nested transactions and enabling a smart contract repair and/or upgrade. To empower Business Analysts (BAs) to generate smart contracts without relying on software developers, we tackled the challenge of generating smart contracts from BPMN models without assistance of a software developer. We exploit the Decision Model and Notation (DMN) standard to represent the decisions and the business logic of the BPMN task elements and amended our methodology for transformation of BPMN models into smart contracts to support also the generation script to represent the business logic represented by the DMN models. To support such transformation, we describe how the BA documents, using the BPMN elements, the flow of information along with the flow of execution. Thus, if the BA is successful in representing the blockchain application requirements using BPMN and DMN models, our methodology and the tool, called TABS, that we developed as a proof of concept, is used to generate the smart contracts directly from those models without developer assistance.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Contracts for SMEs and Large Companies</title>
<link>https://arxiv.org/abs/2505.22619</link>
<guid>https://arxiv.org/abs/2505.22619</guid>
<content:encoded><![CDATA[
arXiv:2505.22619v1 Announce Type: new 
Abstract: Research on blockchains addresses multiple issues, with one being writing smart contracts. In our previous research we described methodology and a tool to generate, in automated fashion, smart contracts from BPMN models. The generated smart contracts provide support for multi-step transactions that facilitate repair/upgrade of smart contracts. In this paper we show how the approach is used to support collaborations via smart contracts for companies ranging from SMEs with little IT capabilities to companies with IT using blockchain smart contracts. Furthermore, we also show how the approach is used for certain applications to generate smart contracts by a BPMN modeler who does not need any knowledge of blockchain technology or smart contract development - thus we are hoping to facilitate democratization of smart contracts and blockchain technology.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improving flocking behaviors in street networks with vision</title>
<link>https://arxiv.org/abs/2505.21585</link>
<guid>https://arxiv.org/abs/2505.21585</guid>
<content:encoded><![CDATA[
arXiv:2505.21585v1 Announce Type: cross 
Abstract: We improve a flocking model on street networks introduced in a previous paper. We expand the field of vision of walkers, making the model more realistic. Under such conditions, we obtain groups of walkers whose gathering times and robustness to break ups are better than previous results. We explain such improvements because the alignment rule with vision guaranties walkers do not split into divergent directions at intersections anymore, and because the attraction rule with vision gathers distant groups. This paves the way to a better understanding of events where walkers have collective decentralized goals, like protests.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Chest X-ray Report Generation via Multimodal Federated Learning with ViT and GPT-2</title>
<link>https://arxiv.org/abs/2505.21715</link>
<guid>https://arxiv.org/abs/2505.21715</guid>
<content:encoded><![CDATA[
arXiv:2505.21715v1 Announce Type: cross 
Abstract: The automated generation of radiology reports from chest X-ray images holds significant promise in enhancing diagnostic workflows while preserving patient privacy. Traditional centralized approaches often require sensitive data transfer, posing privacy concerns. To address this, the study proposes a Multimodal Federated Learning framework for chest X-ray report generation using the IU-Xray dataset. The system utilizes a Vision Transformer (ViT) as the encoder and GPT-2 as the report generator, enabling decentralized training without sharing raw data. Three Federated Learning (FL) aggregation strategies: FedAvg, Krum Aggregation and a novel Loss-aware Federated Averaging (L-FedAvg) were evaluated. Among these, Krum Aggregation demonstrated superior performance across lexical and semantic evaluation metrics such as ROUGE, BLEU, BERTScore and RaTEScore. The results show that FL can match or surpass centralized models in generating clinically relevant and semantically rich radiology reports. This lightweight and privacy-preserving framework paves the way for collaborative medical AI development without compromising data confidentiality.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Morpheus Consensus: Excelling on trails and autobahns</title>
<link>https://arxiv.org/abs/2502.08465</link>
<guid>https://arxiv.org/abs/2502.08465</guid>
<content:encoded><![CDATA[
arXiv:2502.08465v2 Announce Type: replace 
Abstract: Recent research in consensus has often focussed on protocols for State-Machine-Replication (SMR) that can handle high throughputs. Such state-of-the-art protocols (generally DAG-based) induce undue overhead when the needed throughput is low, or else exhibit unnecessarily-poor latency and communication complexity during periods of low throughput.
  Here we present Morpheus Consensus, which naturally morphs from a quiescent low-throughput leaderless blockchain protocol to a high-throughput leader-based DAG protocol and back, excelling in latency and complexity in both settings. During high-throughout, Morpheus pars with state-of-the-art DAG-based protocols, including Autobahn. During low-throughput, Morpheus exhibits competitive complexity and lower latency than standard protocols such as PBFT and Tendermint, which in turn do not perform well during high-throughput.
  The key idea of Morpheus is that as long as blocks do not conflict (due to Byzantine behaviour, network delays, or high-throughput simultaneous production) it produces a forkless blockchain, promptly finalizing each block upon arrival. It assigns a leader only if one is needed to resolve conflicts, in a manner and with performance not unlike Autobahn.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Stochastic Approximation Approach for Efficient Decentralized Optimization on Random Networks</title>
<link>https://arxiv.org/abs/2410.18774</link>
<guid>https://arxiv.org/abs/2410.18774</guid>
<content:encoded><![CDATA[
arXiv:2410.18774v2 Announce Type: replace-cross 
Abstract: A challenging problem in decentralized optimization is to develop algorithms with fast convergence on random and time varying topologies under unreliable and bandwidth-constrained communication network. This paper studies a stochastic approximation approach with a Fully Stochastic Primal Dual Algorithm (FSPDA) framework. Our framework relies on a novel observation that randomness in time varying topology can be incorporated in a stochastic augmented Lagrangian formulation, whose expected value admits saddle points that coincide with stationary solutions of the decentralized optimization problem. With the FSPDA framework, we develop two new algorithms supporting efficient sparsified communication on random time varying topologies -- FSPDA-SA allows agents to execute multiple local gradient steps depending on the time varying topology to accelerate convergence, and FSPDA-STORM further incorporates a variance reduction step to improve sample complexity. For problems with smooth (possibly non-convex) objective function, within $T$ iterations, we show that FSPDA-SA (resp. FSPDA-STORM) finds an $\mathcal{O}( 1/\sqrt{T} )$-stationary (resp. $\mathcal{O}( 1/T^{2/3} )$) solution. Numerical experiments show the benefits of the FSPDA algorithms.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EarthOL: A Proof-of-Human-Contribution Consensus Protocol -- Addressing Fundamental Challenges in Decentralized Value Assessment with Enhanced Verification and Security Mechanisms</title>
<link>https://arxiv.org/abs/2505.20614</link>
<guid>https://arxiv.org/abs/2505.20614</guid>
<content:encoded><![CDATA[
arXiv:2505.20614v1 Announce Type: new 
Abstract: This paper introduces EarthOL, a novel consensus protocol that attempts to replace computational waste in blockchain systems with verifiable human contributions within bounded domains. While recognizing the fundamental impossibility of universal value assessment, we propose a domain-restricted approach that acknowledges cultural diversity and subjective preferences while maintaining cryptographic security. Our enhanced Proof-of-Human-Contribution (PoHC) protocol uses a multi-layered verification system with domain-specific evaluation criteria, time-dependent validation mechanisms, and comprehensive security frameworks. We present theoretical analysis demonstrating meaningful progress toward incentive-compatible human contribution verification in high-consensus domains, achieving Byzantine fault tolerance in controlled scenarios while addressing significant scalability and cultural bias challenges. Through game-theoretic analysis, probabilistic modeling, and enhanced security protocols, we identify specific conditions under which the protocol remains stable and examine failure modes with comprehensive mitigation strategies. This work contributes to understanding the boundaries of decentralized value assessment and provides a framework for future research in human-centered consensus mechanisms for specific application domains, with particular emphasis on validator and security specialist incentive systems.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Thread and Memory-Safe Programming with CLASS</title>
<link>https://arxiv.org/abs/2505.20848</link>
<guid>https://arxiv.org/abs/2505.20848</guid>
<content:encoded><![CDATA[
arXiv:2505.20848v1 Announce Type: new 
Abstract: CLASS is a proof-of-concept general purpose linear programming language, flexibly supporting realistic concurrent programming idioms, and featuring an expressive linear type system ensuring that programs (1) never misuse or leak stateful resources or memory, (2) never deadlock, and (3) always terminate. The design of CLASS and the strong static guarantees of its type system originates in its Linear Logic and proposition-as-types foundations. However, instead of focusing on its theoretical foundations, this paper briefly illustrates, in a tutorial form, an identifiable CLASS session-based programming style where strong correctness properties are automatically ensured by type-checking. Our more challenging examples include concurrent thread and memory-safe mutable ADTs, lazy stream programming, and manipulation of linear digital assets as used in smart contracts.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fedivertex: a Graph Dataset based on Decentralized Social Networks for Trustworthy Machine Learning</title>
<link>https://arxiv.org/abs/2505.20882</link>
<guid>https://arxiv.org/abs/2505.20882</guid>
<content:encoded><![CDATA[
arXiv:2505.20882v1 Announce Type: new 
Abstract: Decentralized machine learning - where each client keeps its own data locally and uses its own computational resources to collaboratively train a model by exchanging peer-to-peer messages - is increasingly popular, as it enables better scalability and control over the data. A major challenge in this setting is that learning dynamics depend on the topology of the communication graph, which motivates the use of real graph datasets for benchmarking decentralized algorithms. Unfortunately, existing graph datasets are largely limited to for-profit social networks crawled at a fixed point in time and often collected at the user scale, where links are heavily influenced by the platform and its recommendation algorithms. The Fediverse, which includes several free and open-source decentralized social media platforms such as Mastodon, Misskey, and Lemmy, offers an interesting real-world alternative. We introduce Fedivertex, a new dataset of 182 graphs, covering seven social networks from the Fediverse, crawled weekly over 14 weeks. We release the dataset along with a Python package to facilitate its use, and illustrate its utility on several tasks, including a new defederation task, which captures a process of link deletion observed on these networks.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unified Alignment Protocol: Making Sense of the Unlabeled Data in New Domains</title>
<link>https://arxiv.org/abs/2505.21010</link>
<guid>https://arxiv.org/abs/2505.21010</guid>
<content:encoded><![CDATA[
arXiv:2505.21010v1 Announce Type: new 
Abstract: Semi-Supervised Federated Learning (SSFL) is gaining popularity over conventional Federated Learning in many real-world applications. Due to the practical limitation of limited labeled data on the client side, SSFL considers that participating clients train with unlabeled data, and only the central server has the necessary resources to access limited labeled data, making it an ideal fit for real-world applications (e.g., healthcare). However, traditional SSFL assumes that the data distributions in the training phase and testing phase are the same. In practice, however, domain shifts frequently occur, making it essential for SSFL to incorporate generalization capabilities and enhance their practicality. The core challenge is improving model generalization to new, unseen domains while the client participate in SSFL. However, the decentralized setup of SSFL and unsupervised client training necessitates innovation to achieve improved generalization across domains. To achieve this, we propose a novel framework called the Unified Alignment Protocol (UAP), which consists of an alternating two-stage training process. The first stage involves training the server model to learn and align the features with a parametric distribution, which is subsequently communicated to clients without additional communication overhead. The second stage proposes a novel training algorithm that utilizes the server feature distribution to align client features accordingly. Our extensive experiments on standard domain generalization benchmark datasets across multiple model architectures reveal that proposed UAP successfully achieves SOTA generalization performance in SSFL setting.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Instrumental Variable Analysis via Federated Generalized Method of Moments</title>
<link>https://arxiv.org/abs/2505.21012</link>
<guid>https://arxiv.org/abs/2505.21012</guid>
<content:encoded><![CDATA[
arXiv:2505.21012v1 Announce Type: new 
Abstract: Instrumental variables (IV) analysis is an important applied tool for areas such as healthcare and consumer economics. For IV analysis in high-dimensional settings, the Generalized Method of Moments (GMM) using deep neural networks offers an efficient approach. With non-i.i.d. data sourced from scattered decentralized clients, federated learning is a popular paradigm for training the models while promising data privacy. However, to our knowledge, no federated algorithm for either GMM or IV analysis exists to date. In this work, we introduce federated instrumental variables analysis (FedIV) via federated generalized method of moments (FedGMM). We formulate FedGMM as a federated zero-sum game defined by a federated non-convex non-concave minimax optimization problem, which is solved using federated gradient descent ascent (FedGDA) algorithm. One key challenge arises in theoretically characterizing the federated local optimality. To address this, we present properties and existence results of clients' local equilibria via FedGDA limit points. Thereby, we show that the federated solution consistently estimates the local moment conditions of every participating client. The proposed algorithm is backed by extensive experiments to demonstrate the efficacy of our approach.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models</title>
<link>https://arxiv.org/abs/2505.21382</link>
<guid>https://arxiv.org/abs/2505.21382</guid>
<content:encoded><![CDATA[
arXiv:2505.21382v1 Announce Type: new 
Abstract: Low-Rank Adaptation (LoRA) has emerged as one of the most effective, computationally tractable fine-tuning approaches for training Vision-Language Models (VLMs) and Large Language Models (LLMs). LoRA accomplishes this by freezing the pre-trained model weights and injecting trainable low-rank matrices, allowing for efficient learning of these foundation models even on edge devices. However, LoRA in decentralized settings still remains under explored, particularly for the theoretical underpinnings due to the lack of smoothness guarantee and model consensus interference (defined formally below). This work improves the convergence rate of decentralized LoRA (DLoRA) to match the rate of decentralized SGD by ensuring gradient smoothness. We also introduce DeCAF, a novel algorithm integrating DLoRA with truncated singular value decomposition (TSVD)-based matrix factorization to resolve consensus interference. Theoretical analysis shows TSVD's approximation error is bounded and consensus differences between DLoRA and DeCAF vanish as rank increases, yielding DeCAF's matching convergence rate. Extensive experiments across vision/language tasks demonstrate our algorithms outperform local training and rivals federated learning under both IID and non-IID data distributions.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeSocial: Blockchain-based Decentralized Social Networks</title>
<link>https://arxiv.org/abs/2505.21388</link>
<guid>https://arxiv.org/abs/2505.21388</guid>
<content:encoded><![CDATA[
arXiv:2505.21388v1 Announce Type: new 
Abstract: Web 2.0 social platforms are inherently centralized, with user data and algorithmic decisions controlled by the platform. However, users can only passively receive social predictions without being able to choose the underlying algorithm, which limits personalization. Fortunately, with the emergence of blockchain, users are allowed to choose algorithms that are tailored to their local situation, improving prediction results in a personalized way. In a blockchain environment, each user possesses its own model to perform the social prediction, capturing different perspectives on social interactions. In our work, we propose DeSocial, a decentralized social network learning framework deployed on an Ethereum (ETH) local development chain that integrates distributed data storage, node-level consensus, and user-driven model selection through Ganache. In the first stage, each user leverages DeSocial to evaluate multiple backbone models on their local subgraph. DeSocial coordinates the execution and returns model-wise prediction results, enabling the user to select the most suitable backbone for personalized social prediction. Then, DeSocial uniformly selects several validation nodes that possess the algorithm specified by each user, and aggregates the prediction results by majority voting, to prevent errors caused by any single model's misjudgment. Extensive experiments show that DeSocial has an evident improvement compared to the five classical centralized social network learning models, promoting user empowerment in blockchain-based decentralized social networks, showing the importance of multi-node validation and personalized algorithm selection based on blockchain. Our implementation is available at: https://github.com/agiresearch/DeSocial.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks</title>
<link>https://arxiv.org/abs/2505.21426</link>
<guid>https://arxiv.org/abs/2505.21426</guid>
<content:encoded><![CDATA[
arXiv:2505.21426v1 Announce Type: new 
Abstract: Agent-Based Models (ABMs) are powerful tools for studying emergent properties in complex systems. In ABMs, agent behaviors are governed by local interactions and stochastic rules. However, these rules are, in general, non-differentiable, limiting the use of gradient-based methods for optimization, and thus integration with real-world data. We propose a novel framework to learn a differentiable surrogate of any ABM by observing its generated data. Our method combines diffusion models to capture behavioral stochasticity and graph neural networks to model agent interactions. Distinct from prior surrogate approaches, our method introduces a fundamental shift: rather than approximating system-level outputs, it models individual agent behavior directly, preserving the decentralized, bottom-up dynamics that define ABMs. We validate our approach on two ABMs (Schelling's segregation model and a Predator-Prey ecosystem) showing that it replicates individual-level patterns and accurately forecasts emergent dynamics beyond training. Our results demonstrate the potential of combining diffusion models and graph learning for data-driven ABM simulation.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Framing metaverse identity: A multidimensional framework for governing digital selves</title>
<link>https://arxiv.org/abs/2406.08029</link>
<guid>https://arxiv.org/abs/2406.08029</guid>
<content:encoded><![CDATA[
arXiv:2406.08029v3 Announce Type: replace 
Abstract: This paper proposes a multidimensional framework for Metaverse Identity, addressing its definition, guiding principles, and critical challenges. Metaverse Identity is conceptualized as a users digital self, encompassing personal attributes, data footprints, social roles, and economic elements. To elucidate its core characteristics and implications, this framework introduces two guiding principles: Equivalence and Alignment, and Fusion and Expansiveness. The first principle advocates for consistency between metaverse and real-world identities in behavioral norms and social standards, ensuring rights protection and establishing conduct guidelines. The second emphasizes the deep integration and transformative evolution of metaverse identities, enabling them to transcend real-world constraints, meet diverse needs, and foster inclusivity. Together, these principles serve as complementary pillars, balancing ethical integration with dynamic co-evolution. Building on this foundation, the study identifies five critical challenges: interoperability, legal boundaries, privacy and identity management, risks from deepfakes and synthetic identities, and identity fragmentation impacting psychological well-being. To address these challenges, strategic recommendations are offered to guide stakeholders. By constructing this framework, the study fills a key theoretical gap, advances systematic research, and provides a foundation for policies and governance strategies to address the complexities of metaverse identities in a rapidly evolving digital domain.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Contract Vulnerabilities, Tools, and Benchmarks: An Updated Systematic Literature Review</title>
<link>https://arxiv.org/abs/2412.01719</link>
<guid>https://arxiv.org/abs/2412.01719</guid>
<content:encoded><![CDATA[
arXiv:2412.01719v2 Announce Type: replace 
Abstract: Smart contracts are self-executing programs on blockchain platforms like Ethereum, which have revolutionized decentralized finance by enabling trustless transactions and the operation of decentralized applications. Despite their potential, the security of smart contracts remains a critical concern due to their immutability and transparency, which expose them to malicious actors. Numerous solutions for vulnerability detection have been proposed, but it is still unclear which one is the most effective. This paper presents a systematic literature review that explores vulnerabilities in Ethereum smart contracts, focusing on automated detection tools and benchmark evaluation. We reviewed 3,380 studies from five digital libraries and five major software engineering conferences, applying a structured selection process that resulted in 222 high-quality studies. The key results include a hierarchical taxonomy of 192 vulnerabilities grouped into 14 categories, a comprehensive list of 219 detection tools with corresponding functionalities, methods, and code transformation techniques, a mapping between our taxonomy and the list of tools, and a collection of 133 benchmarks used for tool evaluation. We conclude with a discussion about the insights into the current state of Ethereum smart contract security and directions for future research.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CRSet: Private Non-Interactive Verifiable Credential Revocation</title>
<link>https://arxiv.org/abs/2501.17089</link>
<guid>https://arxiv.org/abs/2501.17089</guid>
<content:encoded><![CDATA[
arXiv:2501.17089v2 Announce Type: replace 
Abstract: Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases because they may leak the issuer's activity, which in turn leaks internal business metrics. For instance, staff fluctuation through the revocation of employee IDs. We identify the protection of issuer activity as a key gap and propose formal definitions for corresponding characteristics of a revocation mechanism. Then, we introduce CRSet, a non-interactive mechanism that trades some space efficiency to reach these privacy characteristics. For that, we provide a proof sketch. Issuers periodically encode revocation data and publish it via Ethereum blob-carrying transactions, ensuring secure and private availability. Relying Parties (RPs) can download it to perform revocation checks locally. Sticking to a non-interactive design also makes adoption easier because it requires no changes to wallet agents and exchange protocols. We also implement and empirically evaluate CRSet, finding its real-world behavior to match expectations. One Ethereum blob fits revocation data for about 170k VCs.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Climate Implications of Diffusion-based Generative Visual AI Systems and their Mass Adoption</title>
<link>https://arxiv.org/abs/2505.18892</link>
<guid>https://arxiv.org/abs/2505.18892</guid>
<content:encoded><![CDATA[
arXiv:2505.18892v1 Announce Type: new 
Abstract: Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consumer appeal, the GPU use of text-prompt based diffusion AI art systems also requires thoughtful considerations. Given the recent explosion in the number of highly sophisticated generative art systems and their rapid adoption by consumers and creative professionals, the impact of these systems on the climate needs to be carefully considered. In this work, we report on the growth of diffusion-based visual AI systems, their patterns of use, growth and the implications on the climate. Our estimates show that the mass adoption of these tools potentially contributes considerably to global energy consumption. We end this paper with our thoughts on solutions and future areas of inquiry as well as associated difficulties, including the lack of publicly available data.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A quantitative notion of economic security for smart contract compositions</title>
<link>https://arxiv.org/abs/2505.19006</link>
<guid>https://arxiv.org/abs/2505.19006</guid>
<content:encoded><![CDATA[
arXiv:2505.19006v1 Announce Type: new 
Abstract: Decentralized applications are often composed of multiple interconnected smart contracts. This is especially evident in DeFi, where protocols are heavily intertwined and rely on a variety of basic building blocks such as tokens, decentralized exchanges and lending protocols. A crucial security challenge in this setting arises when adversaries target individual components to cause systemic economic losses. Existing security notions focus on determining the existence of these attacks, but fail to quantify the effect of manipulating individual components on the overall economic security of the system. In this paper, we introduce a quantitative security notion that measures how an attack on a single component can amplify economic losses of the overall system. We study the fundamental properties of this notion and apply it to assess the security of key compositions. In particular, we analyse under-collateralized loan attacks in systems made of lending protocols and decentralized exchanges.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematic Classification of Vulnerabilities in MoveEVM Smart Contracts (MWC)</title>
<link>https://arxiv.org/abs/2505.19047</link>
<guid>https://arxiv.org/abs/2505.19047</guid>
<content:encoded><![CDATA[
arXiv:2505.19047v1 Announce Type: new 
Abstract: We introduce the MoveEVM Weakness Classification (MWC) system -- a dedicated vulnerability taxonomy for smart contracts built with Move and executed in EVM-compatible environments. While Move was originally designed to prevent common security flaws via linear resource types and strict ownership, its integration with EVM bytecode introduces novel hybrid vulnerabilities not captured by existing systems like the SWC registry. Our taxonomy spans 37 categorized vulnerability types (MWC-100 to MWC-136) across six semantic frames, addressing issues such as hybrid gas metering, capability misuse, meta-transaction spoofing, and AI-integrated logic. Through analysis of real-world contracts from Aptos and Sui, we demonstrate that current verification tools often miss these hybrid risks. We also explore how formal methods and LLM-based audit agents can operationalize this classification, enabling scalable, logic-aware smart contract auditing. MWC lays the foundation for more secure and verifiable contracts in next-generation blockchain systems. (Shortened Abstract)
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Initial Exploration of Fine-tuning Small Language Models for Smart Contract Reentrancy Vulnerability Detection</title>
<link>https://arxiv.org/abs/2505.19059</link>
<guid>https://arxiv.org/abs/2505.19059</guid>
<content:encoded><![CDATA[
arXiv:2505.19059v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are being used more and more for various coding tasks, including to help coders identify bugs and are a promising avenue to support coders in various tasks including vulnerability detection -- particularly given the flexibility of such generative AI models and tools. Yet for many tasks it may not be suitable to use LLMs, for which it may be more suitable to use smaller language models that can fit and easily execute and train on a developer's computer. In this paper we explore and evaluate whether smaller language models can be fine-tuned to achieve reasonable results for a niche area: vulnerability detection -- specifically focusing on detecting the reentrancy bug in Solidity smart contracts.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proceedings 16th International Workshop on Programming Language Approaches to Concurrency and Communication-cEntric Software</title>
<link>https://arxiv.org/abs/2505.19078</link>
<guid>https://arxiv.org/abs/2505.19078</guid>
<content:encoded><![CDATA[
arXiv:2505.19078v1 Announce Type: new 
Abstract: This volume contains the proceedings of PLACES 2025, the 16th edition of the Workshop on Programming Language Approaches to Concurrency and Communication-cEntric Software. The workshop is scheduled to take place in Hamilton, Canada, on May 4, 2025, as a satellite event of ETAPS, the European Joint Conferences on Theory and Practice of Software. PLACES offers a forum for exchanging new ideas on how to address the challenges of concurrent and distributed programming and how to improve the foundations of modern and future computer applications. PLACES welcomes researchers from various fields, and its topics include the design of new programming languages, models for concurrent and distributed systems, type systems, program verification, and applications in various areas (e.g., microservices, sensor networks, blockchains, event processing, business process management).
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Grassroots Consensus</title>
<link>https://arxiv.org/abs/2505.19216</link>
<guid>https://arxiv.org/abs/2505.19216</guid>
<content:encoded><![CDATA[
arXiv:2505.19216v1 Announce Type: new 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic and decentralized/plutocratic alike. Within the grassroots architecture, consensus is needed to realize platforms that employ digital social contracts, which are like smart contracts except that they are among people not accounts and are executed by these people's smartphones not by high-performance servers controlled by parties outside to the contract. Key envisioned grassroots platforms include sovereign democratic digital communities and federations, community banks and their grassroots cryptocurrencies, and digital cooperatives.
  The grassroots architecture can benefit from a consensus protocol that is (i) quiescent, (ii) efficient during low- and high-throughput, (iii) responsive, (iv) blocklace-based, (v) UDP-ready, and (vi) grassroots. The Grassroots Consensus protocol addresses all these requirements while having competitive performance in both low- and high-throughput scenarios and being one of the most concise and elegant consensus protocols for partial synchrony. It achieves that by building on two cutting-edge consensus protocols -- the quiescent high-performance Morpheus and the blocklace-based Cordial Miners, improving the latter's dissemination protocol and making it UDP-ready, and extending the protocol with a constitution and a constitutional amendment component, making it grassroots.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Market Clearing with Semi-fungible Assets</title>
<link>https://arxiv.org/abs/2505.19298</link>
<guid>https://arxiv.org/abs/2505.19298</guid>
<content:encoded><![CDATA[
arXiv:2505.19298v1 Announce Type: new 
Abstract: As markets have digitized, the number of tradable products has skyrocketed. Algorithmically constructed portfolios of these assets now dominate public and private markets, resulting in a combinatorial explosion of tradable assets. In this paper, we provide a simple means to compute market clearing prices for semi-fungible assets which have a partial ordering between them. Such assets are increasingly found in traditional markets (bonds, commodities, ETFs), private markets (private credit, compute markets), and in decentralized finance. We formulate the market clearing problem as an optimization problem over a directed acyclic graph that represents participant preferences. Subsequently, we use convex duality to efficiently estimate market clearing prices, which correspond to particular dual variables. We then describe dominant strategy incentive compatible payment and allocation rules for clearing these markets. We conclude with examples of how this framework can construct prices for a variety of algorithmically constructed, semi-fungible portfolios of practical importance.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Framework for Combined Transaction Posting and Pricing for Layer 2 Blockchains</title>
<link>https://arxiv.org/abs/2505.19556</link>
<guid>https://arxiv.org/abs/2505.19556</guid>
<content:encoded><![CDATA[
arXiv:2505.19556v1 Announce Type: new 
Abstract: This paper presents a comprehensive framework for transaction posting and pricing in Layer 2 (L2) blockchain systems, focusing on challenges stemming from fluctuating Layer 1 (L1) gas fees and the congestion issues within L2 networks. Existing methods have focused on the problem of optimal posting strategies to L1 in isolation, without simultaneously considering the L2 fee mechanism. In contrast, our work offers a unified approach that addresses the complex interplay between transaction queue dynamics, L1 cost variability, and user responses to L2 fees. We contribute by (1) formulating a dynamic model that integrates both posting and pricing strategies, capturing the interplay between L1 gas price fluctuations and L2 queue management, (2) deriving an optimal threshold-based posting policy that guides L2 sequencers in managing transactions based on queue length and current L1 conditions, and (3) establishing theoretical foundations for a dynamic L2 fee mechanism that balances cost recovery with congestion control. We validate our framework through simulations.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mosaic: Data-Free Knowledge Distillation via Mixture-of-Experts for Heterogeneous Distributed Environments</title>
<link>https://arxiv.org/abs/2505.19699</link>
<guid>https://arxiv.org/abs/2505.19699</guid>
<content:encoded><![CDATA[
arXiv:2505.19699v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning paradigm that enables clients to collaboratively train models while preserving data privacy. However, the coexistence of model and data heterogeneity gives rise to inconsistent representations and divergent optimization dynamics across clients, ultimately hindering robust global performance. To transcend these challenges, we propose Mosaic, a novel data-free knowledge distillation framework tailored for heterogeneous distributed environments. Mosaic first trains local generative models to approximate each client's personalized distribution, enabling synthetic data generation that safeguards privacy through strict separation from real data. Subsequently, Mosaic forms a Mixture-of-Experts (MoE) from client models based on their specialized knowledge, and distills it into a global model using the generated data. To further enhance the MoE architecture, Mosaic integrates expert predictions via a lightweight meta model trained on a few representative prototypes. Extensive experiments on standard image classification benchmarks demonstrate that Mosaic consistently outperforms state-of-the-art approaches under both model and data heterogeneity. The source code has been published at https://github.com/Wings-Of-Disaster/Mosaic.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning in Cybersecurity: From Fundamentals to Applications</title>
<link>https://arxiv.org/abs/2505.19837</link>
<guid>https://arxiv.org/abs/2505.19837</guid>
<content:encoded><![CDATA[
arXiv:2505.19837v1 Announce Type: new 
Abstract: Multi-Agent Reinforcement Learning (MARL) has shown great potential as an adaptive solution for addressing modern cybersecurity challenges. MARL enables decentralized, adaptive, and collaborative defense strategies and provides an automated mechanism to combat dynamic, coordinated, and sophisticated threats. This survey investigates the current state of research in MARL applications for automated cyber defense (ACD), focusing on intruder detection and lateral movement containment. Additionally, it examines the role of Autonomous Intelligent Cyber-defense Agents (AICA) and Cyber Gyms in training and validating MARL agents. Finally, the paper outlines existing challenges, such as scalability and adversarial robustness, and proposes future research directions. This also discusses how MARL integrates in AICA to provide adaptive, scalable, and dynamic solutions to counter the increasingly sophisticated landscape of cyber threats. It highlights the transformative potential of MARL in areas like intrusion detection and lateral movement containment, and underscores the value of Cyber Gyms for training and validation of AICA.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalized and Personalized Federated Learning with Foundation Models via Orthogonal Transformations</title>
<link>https://arxiv.org/abs/2505.19888</link>
<guid>https://arxiv.org/abs/2505.19888</guid>
<content:encoded><![CDATA[
arXiv:2505.19888v1 Announce Type: new 
Abstract: Federated Learning (FL) aims to train models across decentralized clients or devices holding local data without the need for centralized data collection, thus enhancing data privacy and security. However, achieving both generalization and personalization in heterogeneous settings remains a significant challenge. To address this, we introduce FedOT, a novel approach that leverages black-box foundation models. FedOT shares only a global task-dependent classifier across clients while locally adapting features through orthogonal transformations. By enforcing orthogonality, FedOT mitigates gradient conflicts across diverse clients, preserves semantic integrity, and achieves robust performance even in the presence of substantial data heterogeneity. The strategy of combining global and local parameters enables a more balanced approach for both generalization and personalization, outperforming baseline FL methods across multiple benchmarks. Furthermore, our extensive analysis confirms that joint optimization of global classifiers and local orthogonal transformations yields superior performance and suggests broader applicability.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unifying Multimodal Large Language Model Capabilities and Modalities via Model Merging</title>
<link>https://arxiv.org/abs/2505.19892</link>
<guid>https://arxiv.org/abs/2505.19892</guid>
<content:encoded><![CDATA[
arXiv:2505.19892v1 Announce Type: new 
Abstract: While foundation models update slowly due to resource-intensive training requirements, domain-specific models evolve between updates. Model merging aims to combine multiple expert models into a single, more capable model, thereby reducing storage and serving costs while supporting decentralized model development. Despite its potential, previous studies have primarily focused on merging visual classification models or Large Language Models (LLMs) for code and math tasks. Multimodal Large Language Models (MLLMs), which extend the capabilities of LLMs through large-scale multimodal training, have gained traction. However, there lacks a benchmark for model merging research that clearly divides the tasks for MLLM training and evaluation. In this paper, (i) we introduce the model merging benchmark for MLLMs, which includes multiple tasks such as VQA, Geometry, Chart, OCR, and Grounding, providing both LoRA and full fine-tuning models. Moreover, we explore how model merging can combine different modalities (e.g., vision-language, audio-language, and video-language models), moving toward the Omni-language model. (ii) We implement 10 model merging algorithms on the benchmark. Furthermore, we propose a novel method that removes noise from task vectors and robustly optimizes the merged vector based on a loss defined over task vector interactions, achieving an average performance gain of 2.48%. (iii) We find that model merging offers a promising way for building improved MLLMs without requiring data training. Our results also demonstrate that the complementarity among multiple modalities outperforms individual modalities.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differential Privacy Analysis of Decentralized Gossip Averaging under Varying Threat Models</title>
<link>https://arxiv.org/abs/2505.19969</link>
<guid>https://arxiv.org/abs/2505.19969</guid>
<content:encoded><![CDATA[
arXiv:2505.19969v1 Announce Type: new 
Abstract: Fully decentralized training of machine learning models offers significant advantages in scalability, robustness, and fault tolerance. However, achieving differential privacy (DP) in such settings is challenging due to the absence of a central aggregator and varying trust assumptions among nodes. In this work, we present a novel privacy analysis of decentralized gossip-based averaging algorithms with additive node-level noise, both with and without secure summation over each node's direct neighbors. Our main contribution is a new analytical framework based on a linear systems formulation that accurately characterizes privacy leakage across these scenarios. This framework significantly improves upon prior analyses, for example, reducing the R\'enyi DP parameter growth from $O(T^2)$ to $O(T)$, where $T$ is the number of training rounds. We validate our analysis with numerical results demonstrating superior DP bounds compared to existing approaches. We further illustrate our analysis with a logistic regression experiment on MNIST image classification in a fully decentralized setting, demonstrating utility comparable to central aggregation methods.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Few to Many Faults: Adaptive Byzantine Agreement with Optimal Communication</title>
<link>https://arxiv.org/abs/2505.19989</link>
<guid>https://arxiv.org/abs/2505.19989</guid>
<content:encoded><![CDATA[
arXiv:2505.19989v1 Announce Type: new 
Abstract: Achieving agreement among distributed parties is a fundamental task in modern systems, underpinning applications such as consensus in blockchains, coordination in cloud infrastructure, and fault tolerance in critical services. However, this task can be communication-intensive, often requiring a large number of messages to be exchanged, especially in the presence of Byzantine faults, making efficiency a central challenge in the design of practical agreement protocols.
  In this paper, we study the problem of Strong Byzantine Agreement and establish tight upper and lower bounds on communication complexity, parameterized by the actual number of Byzantine faults. Specifically, for a system of $n$ parties tolerating up to $t$ Byzantine faults, out of which only $f \leq t$ are actually faulty, we obtain the following results:
  In the partially synchronous setting, we present the first Byzantine Agreement protocol that achieves adaptive communication complexity of $\mathcal{O}(n + t \cdot f)$ words, which is asymptotically optimal. Our protocol has an optimal resilience of $t < n/3$.
  In the asynchronous setting, we prove a lower bound of $\Omega(n + t^2)$ on the expected number of messages, and design an almost matching protocol with an optimal resilience that solves agreement with $\mathcal{O}((n + t^2)\cdot \log n)$ words. Our main technical contribution in the asynchronous setting is the utilization of a bipartite expander graph that allows for low-cost information dissemination.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale</title>
<link>https://arxiv.org/abs/2505.20094</link>
<guid>https://arxiv.org/abs/2505.20094</guid>
<content:encoded><![CDATA[
arXiv:2505.20094v1 Announce Type: new 
Abstract: Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exposing Go's Hidden Bugs: A Novel Concolic Framework</title>
<link>https://arxiv.org/abs/2505.20183</link>
<guid>https://arxiv.org/abs/2505.20183</guid>
<content:encoded><![CDATA[
arXiv:2505.20183v1 Announce Type: new 
Abstract: The widespread adoption of the Go programming language in infrastructure backends and blockchain projects has heightened the need for improved security measures. Established techniques such as unit testing, static analysis, and program fuzzing provide foundational protection mechanisms. Although symbolic execution tools have made significant contributions, opportunities remain to address the complexities of Go's runtime and concurrency model. In this work, we present Zorya, a novel methodology leveraging concrete and symbolic (concolic) execution to evaluate Go programs comprehensively. By systematically exploring execution paths to uncover vulnerabilities beyond conventional testing, symbolic execution offers distinct advantages, and coupling it with concrete execution mitigates the path explosion problem. Our solution employs Ghidra's P-Code as an intermediate representation (IR). This implementation detects runtime panics in the TinyGo compiler and supports both generic and custom invariants. Furthermore, P-Code's generic IR nature enables analysis of programs written in other languages such as C. Future enhancements may include intelligent classification of concolic execution logs to identify vulnerability patterns.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A theoretical basis for MEV</title>
<link>https://arxiv.org/abs/2302.02154</link>
<guid>https://arxiv.org/abs/2302.02154</guid>
<content:encoded><![CDATA[
arXiv:2302.02154v5 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) refers to a wide class of economic attacks to public blockchains, where adversaries with the power to reorder, drop or insert transactions in a block can "extract" value from smart contracts. Empirical research has shown that mainstream DeFi protocols are massively targeted by these attacks, with detrimental effects on their users and on the blockchain network. Despite the increasing real-world impact of these attacks, their theoretical foundations remain insufficiently established. We propose a formal theory of MEV, based on a general, abstract model of blockchains and smart contracts. Our theory is the basis for proofs of security against MEV attacks.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Automated Discovery of Asymmetric Mempool DoS in Blockchains</title>
<link>https://arxiv.org/abs/2312.02642</link>
<guid>https://arxiv.org/abs/2312.02642</guid>
<content:encoded><![CDATA[
arXiv:2312.02642v4 Announce Type: replace 
Abstract: In blockchains, mempool controls transaction flow before consensus, denial of whose service hurts the health and security of blockchain networks. This paper presents MPFUZZ, the first mempool fuzzer to find asymmetric DoS bugs by exploring the space of symbolized mempool states and optimistically estimating the promisingness of an intermediate state in reaching bug oracles. Compared to the baseline blockchain fuzzers, MPFUZZ achieves a > 100x speedup in finding known DETER exploits. Running MPFUZZ on major Ethereum clients leads to discovering new mempool vulnerabilities, which exhibit a wide variety of sophisticated patterns, including stealthy mempool eviction and mempool locking. Rule-based mitigation schemes are proposed against all newly discovered vulnerabilities.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Continual Graph Learning</title>
<link>https://arxiv.org/abs/2411.18919</link>
<guid>https://arxiv.org/abs/2411.18919</guid>
<content:encoded><![CDATA[
arXiv:2411.18919v2 Announce Type: replace 
Abstract: In the era of big data, managing evolving graph data poses substantial challenges due to storage costs and privacy issues. Training graph neural networks (GNNs) on such evolving data usually causes catastrophic forgetting, impairing performance on earlier tasks. Despite existing continual graph learning (CGL) methods mitigating this to some extent, they rely on centralized architectures and ignore the potential of distributed graph databases to leverage collective intelligence. To address these challenges, we present a pioneering study on Federated Continual Graph Learning (FCGL), which adapts GNNs to multiple evolving graphs within decentralized settings while adhering to storage and privacy constraints. Our work begins with a comprehensive empirical analysis of FCGL, assessing its data characteristics, feasibility, and effectiveness, and reveals two non-trivial challenges: local graph forgetting (LGF), where local GNNs forget prior knowledge when adapting to new tasks, and global expertise conflict (GEC), where the global GNN exhibits sub-optimal performance in both adapting to new tasks and retaining old ones, arising from inconsistent client expertise during server-side parameter aggregation. To tackle these, we propose the POWER framework, which mitigates LGF by preserving and replaying experience nodes with maximum local-global coverage at each client and addresses GEC by using a pseudo prototype reconstruction strategy and trajectory-aware knowledge transfer at the central server. Experiments on various graph datasets demonstrate POWER's superiority over federated adaptations of CGL baselines and vision-centric federated continual learning approaches.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Snowman for partial synchrony</title>
<link>https://arxiv.org/abs/2501.15904</link>
<guid>https://arxiv.org/abs/2501.15904</guid>
<content:encoded><![CDATA[
arXiv:2501.15904v3 Announce Type: replace 
Abstract: Snowman is the consensus protocol run by blockchains on Avalanche. Recent work established a rigorous proof of probabilistic consistency for Snowman in the \emph{synchronous} setting, under the simplifying assumption that correct processes execute sampling rounds in `lockstep'. In this paper, we describe a modification of the protocol that ensures consistency in the \emph{partially synchronous} setting, and when correct processes carry out successive sampling rounds at their own speed, with the time between sampling rounds determined by local message delays.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data Overvaluation Attack and Truthful Data Valuation in Federated Learning</title>
<link>https://arxiv.org/abs/2502.00494</link>
<guid>https://arxiv.org/abs/2502.00494</guid>
<content:encoded><![CDATA[
arXiv:2502.00494v3 Announce Type: replace 
Abstract: In collaborative machine learning (CML), data valuation, i.e., evaluating the contribution of each client's data to the machine learning model, has become a critical task for incentivizing and selecting positive data contributions. However, existing studies often assume that clients engage in data valuation truthfully, overlooking the practical motivation for clients to exaggerate their contributions. To unlock this threat, this paper introduces the data overvaluation attack, enabling strategic clients to have their data significantly overvalued in federated learning, a widely adopted paradigm for decentralized CML. Furthermore, we propose a Bayesian truthful data valuation metric, named Truth-Shapley. Truth-Shapley is the unique metric that guarantees some promising axioms for data valuation while ensuring that clients' optimal strategy is to perform truthful data valuation under certain conditions. Our experiments demonstrate the vulnerability of existing data valuation metrics to the proposed attack and validate the robustness and effectiveness of Truth-Shapley.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Perpetual Demand Lending Pools</title>
<link>https://arxiv.org/abs/2502.06028</link>
<guid>https://arxiv.org/abs/2502.06028</guid>
<content:encoded><![CDATA[
arXiv:2502.06028v2 Announce Type: replace 
Abstract: Decentralized perpetuals protocols have collectively reached billions of dollars of daily trading volume, yet are still not serious competitors on the basis of trading volume with centralized venues such as Binance. One of the main reasons for this is the high cost of capital for market makers and sophisticated traders in decentralized settings. Recently, numerous decentralized finance protocols have been used to improve borrowing costs for perpetual futures traders. We formalize this class of mechanisms utilized by protocols such as Jupiter, Hyperliquid, and GMX, which we term~\emph{Perpetual Demand Lending Pools} (PDLPs). We then formalize a general target weight mechanism that generalizes what GMX and Jupiter are using in practice. We explicitly describe pool arbitrage and expected payoffs for arbitrageurs and liquidity providers within these mechanisms. Using this framework, we show that under general conditions, PDLPs are easy to delta hedge, partially explaining the proliferation of live hedged PDLP strategies. Our results suggest directions to improve capital efficiency in PDLPs via dynamic parametrization.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fashion Industry in the Age of Generative Artificial Intelligence and Metaverse: A systematic Review</title>
<link>https://arxiv.org/abs/2505.17141</link>
<guid>https://arxiv.org/abs/2505.17141</guid>
<content:encoded><![CDATA[
arXiv:2505.17141v1 Announce Type: new 
Abstract: The fashion industry is an extremely profitable market that generates trillions of dollars in revenue by producing and distributing apparel, footwear, and accessories. This systematic literature review (SLR) seeks to systematically review and analyze the research landscape about the Generative Artificial Intelligence (GAI) and metaverse in the fashion industry. Thus, investigating the impact of integrating both technologies to enhance the fashion industry. This systematic review uses the Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) methodology, including three essential phases: identification, evaluation, and reporting. In the identification phase, the target search problems are determined by selecting appropriate keywords and alternative synonyms. After that 578 documents from 2014 to the end of 2023 are retrieved. The evaluation phase applies three screening steps to assess papers and choose 118 eligible papers for full-text reading. Finally, the reporting phase thoroughly examines and synthesizes the 118 eligible papers to identify key themes associated with GAI and Metaverse in the fashion industry. Based on Strengths, Weaknesses, Opportunities, and Threats (SWOT) analyses performed for both GAI and metaverse for the fashion industry, it is concluded that the integration of GAI and the metaverse holds the capacity to profoundly revolutionize the fashion sector, presenting chances for improved manufacturing, design, sales, and client experiences. Accordingly, the research proposes a new framework to integrate GAI and metaverse to enhance the fashion industry. The framework presents different use cases to promote the fashion industry using the integration. Future research points for achieving a successful integration are demonstrated.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation</title>
<link>https://arxiv.org/abs/2505.17226</link>
<guid>https://arxiv.org/abs/2505.17226</guid>
<content:encoded><![CDATA[
arXiv:2505.17226v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative machine learning across decentralized data sources without sharing raw data. It offers a promising approach to privacy-preserving AI. However, FL remains vulnerable to adversarial threats from malicious participants, referred to as Byzantine clients, who can send misleading updates to corrupt the global model. Traditional aggregation methods, such as simple averaging, are not robust to such attacks. More resilient approaches, like the Krum algorithm, require prior knowledge of the number of malicious clients, which is often unavailable in real-world scenarios. To address these limitations, we propose Average-rKrum (ArKrum), a novel aggregation strategy designed to enhance both the resilience and privacy guarantees of FL systems. Building on our previous work (rKrum), ArKrum introduces two key innovations. First, it includes a median-based filtering mechanism that removes extreme outliers before estimating the number of adversarial clients. Second, it applies a multi-update averaging scheme to improve stability and performance, particularly when client data distributions are not identical. We evaluate ArKrum on benchmark image and text datasets under three widely studied Byzantine attack types. Results show that ArKrum consistently achieves high accuracy and stability. It performs as well as or better than other robust aggregation methods. These findings demonstrate that ArKrum is an effective and practical solution for secure FL systems in adversarial environments.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LogStamping: A blockchain-based log auditing approach for large-scale systems</title>
<link>https://arxiv.org/abs/2505.17236</link>
<guid>https://arxiv.org/abs/2505.17236</guid>
<content:encoded><![CDATA[
arXiv:2505.17236v1 Announce Type: new 
Abstract: Log management is crucial for ensuring the security, integrity, and compliance of modern information systems. Traditional log management solutions face challenges in achieving tamper-proofing, scalability, and real-time processing in distributed environments. This paper presents a blockchain-based log management framework that addresses these limitations by leveraging blockchain's decentralized, immutable, and transparent features. The framework integrates a hybrid on-chain and off-chain storage model, combining blockchain's integrity guarantees with the scalability of distributed storage solutions like IPFS. Smart contracts automate log validation and access control, while cryptographic techniques ensure privacy and confidentiality. With a focus on real-time log processing, the framework is designed to handle the high-volume log generation typical in large-scale systems, such as data centers and network infrastructure. Performance evaluations demonstrate the framework's scalability, low latency, and ability to manage millions of log entries while maintaining strong security guarantees. Additionally, the paper discusses challenges like blockchain storage overhead and energy consumption, offering insights for enhancing future systems.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Control of Renewable Energy Communities using AI and Real-World Data</title>
<link>https://arxiv.org/abs/2505.17321</link>
<guid>https://arxiv.org/abs/2505.17321</guid>
<content:encoded><![CDATA[
arXiv:2505.17321v1 Announce Type: new 
Abstract: The electrification of transportation and the increased adoption of decentralized renewable energy generation have added complexity to managing Renewable Energy Communities (RECs). Integrating Electric Vehicle (EV) charging with building energy systems like heating, ventilation, air conditioning (HVAC), photovoltaic (PV) generation, and battery storage presents significant opportunities but also practical challenges. Reinforcement learning (RL), particularly MultiAgent Deep Deterministic Policy Gradient (MADDPG) algorithms, have shown promising results in simulation, outperforming heuristic control strategies. However, translating these successes into real-world deployments faces substantial challenges, including incomplete and noisy data, integration of heterogeneous subsystems, synchronization issues, unpredictable occupant behavior, and missing critical EV state-of-charge (SoC) information. This paper introduces a framework designed explicitly to handle these complexities and bridge the simulation to-reality gap. The framework incorporates EnergAIze, a MADDPG-based multi-agent control strategy, and specifically addresses challenges related to real-world data collection, system integration, and user behavior modeling. Preliminary results collected from a real-world operational REC with four residential buildings demonstrate the practical feasibility of our approach, achieving an average 9% reduction in daily peak demand and a 5% decrease in energy costs through optimized load scheduling and EV charging behaviors. These outcomes underscore the framework's effectiveness, advancing the practical deployment of intelligent energy management solutions in RECs.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework</title>
<link>https://arxiv.org/abs/2505.17416</link>
<guid>https://arxiv.org/abs/2505.17416</guid>
<content:encoded><![CDATA[
arXiv:2505.17416v1 Announce Type: new 
Abstract: Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks and financial losses, even threatening the integrity of the entire decentralized finance system. Currently, research on smart contract vulnerabilities has evolved from traditional program analysis methods to deep learning techniques, with the gradual introduction of Large Language Models. However, existing studies mainly focus on vulnerability detection, lacking systematic cause analysis and Vulnerability Repair. To address this gap, we propose LLM-BSCVM, a Large Language Model-based smart contract vulnerability management framework, designed to provide end-to-end vulnerability detection, analysis, repair, and evaluation capabilities for Web 3.0 ecosystem. LLM-BSCVM combines retrieval-augmented generation technology and multi-agent collaboration, introducing a three-stage method of Decompose-Retrieve-Generate. This approach enables smart contract vulnerability management through the collaborative efforts of six intelligent agents, specifically: vulnerability detection, cause analysis, repair suggestion generation, risk assessment, vulnerability repair, and patch evaluation. Experimental results demonstrate that LLM-BSCVM achieves a vulnerability detection accuracy and F1 score exceeding 91\% on benchmark datasets, comparable to the performance of state-of-the-art (SOTA) methods, while reducing the false positive rate from 7.2\% in SOTA methods to 5.1\%, thus enhancing the reliability of vulnerability management. Furthermore, LLM-BSCVM supports continuous security monitoring and governance of smart contracts through a knowledge base hot-swapping dynamic update mechanism.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SecurePay: Enabling Secure and Fast Payment Processing for Platform Economy</title>
<link>https://arxiv.org/abs/2505.17466</link>
<guid>https://arxiv.org/abs/2505.17466</guid>
<content:encoded><![CDATA[
arXiv:2505.17466v1 Announce Type: new 
Abstract: Recent years have witnessed a rapid development of platform economy, as it effectively addresses the trust dilemma between untrusted online buyers and merchants. However, malicious platforms can misuse users' funds and information, causing severe security concerns. Previous research efforts aimed at enhancing security in platform payment systems often sacrificed processing performance, while those focusing on processing efficiency struggled to completely prevent fund and information misuse. In this paper, we introduce SecurePay, a secure, yet performant payment processing system for platform economy. SecurePay is the first payment system that combines permissioned blockchain with central bank digital currency (CBDC) to ensure fund security, information security, and resistance to collusion by intermediaries; it also facilitates counter-party auditing, closed-loop regulation, and enhances operational efficiency for transaction settlement. We develop a full implementation of the proposed SecurePay system, and our experiments conducted on personal devices demonstrate a throughput of 256.4 transactions per second and an average latency of 4.29 seconds, demonstrating a comparable processing efficiency with a centralized system, with a significantly improved security level.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>\texttt{Range-Arithmetic}: Verifiable Deep Learning Inference on an Untrusted Party</title>
<link>https://arxiv.org/abs/2505.17623</link>
<guid>https://arxiv.org/abs/2505.17623</guid>
<content:encoded><![CDATA[
arXiv:2505.17623v1 Announce Type: new 
Abstract: Verifiable computing (VC) has gained prominence in decentralized machine learning systems, where resource-intensive tasks like deep neural network (DNN) inference are offloaded to external participants due to blockchain limitations. This creates a need to verify the correctness of outsourced computations without re-execution. We propose \texttt{Range-Arithmetic}, a novel framework for efficient and verifiable DNN inference that transforms non-arithmetic operations, such as rounding after fixed-point matrix multiplication and ReLU, into arithmetic steps verifiable using sum-check protocols and concatenated range proofs. Our approach avoids the complexity of Boolean encoding, high-degree polynomials, and large lookup tables while remaining compatible with finite-field-based proof systems. Experimental results show that our method not only matches the performance of existing approaches, but also reduces the computational cost of verifying the results, the computational effort required from the untrusted party performing the DNN inference, and the communication overhead between the two sides.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DecLock: A Case of Decoupled Locking for Disaggregated Memory</title>
<link>https://arxiv.org/abs/2505.17641</link>
<guid>https://arxiv.org/abs/2505.17641</guid>
<content:encoded><![CDATA[
arXiv:2505.17641v1 Announce Type: new 
Abstract: This paper reveals that locking can significantly degrade the performance of applications on disaggregated memory (DM), sometimes by several orders of magnitude, due to contention on the NICs of memory nodes (MN-NICs). To address this issue, we present DecLock, a locking mechanism for DM that employs decentralized coordination for ownership transfer across compute nodes (CNs) while retaining centralized state maintenance on memory nodes (MNs). DecLock features cooperative queue-notify locking that queues lock waiters on MNs atomically, enabling clients to transfer lock ownership via message-based notifications between CNs. This approach conserves MN-NIC resources for DM applications and ensures fairness. Evaluations show DecLock achieves throughput improvements of up to 43.37$\times$ and 1.81$\times$ over state-of-the-art RDMA-based spinlocks and MCS locks, respectively. Furthermore, DecLock helps two DM applications, including an object store and a real-world database index (Sherman), avoid performance degradation under high contention, improving throughput by up to 35.60$\times$ and 2.31$\times$ and reducing 99th-percentile latency by up to 98.8% and 82.1%.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transaction Fee Mechanism Design for Leaderless Blockchain Protocols</title>
<link>https://arxiv.org/abs/2505.17885</link>
<guid>https://arxiv.org/abs/2505.17885</guid>
<content:encoded><![CDATA[
arXiv:2505.17885v1 Announce Type: new 
Abstract: We initiate the study of transaction fee mechanism design for blockchain protocols in which multiple block producers contribute to the production of each block. Our contributions include:
  - We propose an extensive-form (multi-stage) game model to reason about the game theory of multi-proposer transaction fee mechanisms.
  - We define the strongly BPIC property to capture the idea that all block producers should be motivated to behave as intended: for every user bid profile, following the intended allocation rule is a Nash equilibrium for block producers that Pareto dominates all other Nash equilibria.
  - We propose the first-price auction with equal sharing (FPA-EQ) mechanism as an attractive solution to the multi-proposer transaction fee mechanism design problem. We prove that the mechanism is strongly BPIC and guarantees at least a 63.2% fraction of the maximum-possible expected welfare at equilibrium.
  - We prove that the compromises made by the FPA-EQ mechanism are qualitatively necessary: no strongly BPIC mechanism with non-trivial welfare guarantees can be DSIC, and no strongly BPIC mechanism can guarantee optimal welfare at equilibrium.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DiFache: Efficient and Scalable Caching on Disaggregated Memory using Decentralized Coherence</title>
<link>https://arxiv.org/abs/2505.18013</link>
<guid>https://arxiv.org/abs/2505.18013</guid>
<content:encoded><![CDATA[
arXiv:2505.18013v1 Announce Type: new 
Abstract: The disaggregated memory (DM) architecture offers high resource elasticity at the cost of data access performance. While caching frequently accessed data in compute nodes (CNs) reduces access overhead, it requires costly centralized maintenance of cache coherence across CNs. This paper presents DiFache, an efficient, scalable, and coherent CN-side caching framework for DM applications. Observing that DM applications already serialize conflicting remote data access internally rather than relying on the cache layer, DiFache introduces decentralized coherence that aligns its consistency model with memory nodes instead of CPU caches, thereby eliminating the need for centralized management. DiFache features a decentralized invalidation mechanism to independently invalidate caches on remote CNs and a fine-grained adaptive scheme to cache objects with varying read-write ratios. Evaluations using 54 real-world traces from Twitter show that DiFache outperforms existing approaches by up to 10.83$\times$ (5.53$\times$ on average). By integrating DiFache, the peak throughput of two real-world DM applications increases by 7.94$\times$ and 2.19$\times$, respectively.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means</title>
<link>https://arxiv.org/abs/2505.17836</link>
<guid>https://arxiv.org/abs/2505.17836</guid>
<content:encoded><![CDATA[
arXiv:2505.17836v1 Announce Type: cross 
Abstract: This paper addresses the problem of robust estimation in gossip algorithms over arbitrary communication graphs. Gossip algorithms are fully decentralized, relying only on local neighbor-to-neighbor communication, making them well-suited for situations where communication is constrained. A fundamental challenge in existing mean-based gossip algorithms is their vulnerability to malicious or corrupted nodes. In this paper, we show that an outlier-robust mean can be computed by globally estimating a robust statistic. More specifically, we propose a novel gossip algorithm for rank estimation, referred to as \textsc{GoRank}, and leverage it to design a gossip procedure dedicated to trimmed mean estimation, coined \textsc{GoTrim}. In addition to a detailed description of the proposed methods, a key contribution of our work is a precise convergence analysis: we establish an $\mathcal{O}(1/t)$ rate for rank estimation and an $\mathcal{O}(\log(t)/t)$ rate for trimmed mean estimation, where by $t$ is meant the number of iterations. Moreover, we provide a breakdown point analysis of \textsc{GoTrim}. We empirically validate our theoretical results through experiments on diverse network topologies, data distributions and contamination schemes.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Causal Inference from Multi-Site Observational Data via Propensity Score Aggregation</title>
<link>https://arxiv.org/abs/2505.17961</link>
<guid>https://arxiv.org/abs/2505.17961</guid>
<content:encoded><![CDATA[
arXiv:2505.17961v1 Announce Type: cross 
Abstract: Causal inference typically assumes centralized access to individual-level data. Yet, in practice, data are often decentralized across multiple sites, making centralization infeasible due to privacy, logistical, or legal constraints. We address this by estimating the Average Treatment Effect (ATE) from decentralized observational data using federated learning, which enables inference through the exchange of aggregate statistics rather than individual-level data. We propose a novel method to estimate propensity scores in a (non-)parametric manner by computing a federated weighted average of local scores, using two theoretically grounded weighting schemes -- Membership Weights (MW) and Density Ratio Weights (DW) -- that balance communication efficiency and model flexibility. These federated scores are then used to construct two ATE estimators: the Federated Inverse Propensity Weighting estimator (Fed-IPW) and its augmented variant (Fed-AIPW). Unlike meta-analysis methods, which fail when any site violates positivity, our approach leverages heterogeneity in treatment assignment across sites to improve overlap. We show that Fed-IPW and Fed-AIPW perform well under site-level heterogeneity in sample sizes, treatment mechanisms, and covariate distributions, with theoretical analysis and experiments on simulated and real-world data highlighting their strengths and limitations relative to meta-analysis and related methods.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning in Genetics: Extended Analysis of Accuracy, Performance and Privacy Trade-offs</title>
<link>https://arxiv.org/abs/2402.14527</link>
<guid>https://arxiv.org/abs/2402.14527</guid>
<content:encoded><![CDATA[
arXiv:2402.14527v2 Announce Type: replace 
Abstract: Machine learning on large-scale genomic or transcriptomic data is important for many novel health applications. For example, precision medicine tailors medical treatments to patients on the basis of individual biomarkers, cellular and molecular states, etc. However, the data required is sensitive, voluminous, heterogeneous, and typically distributed across locations where dedicated machine learning hardware is not available. Due to privacy and regulatory reasons, it is also problematic to aggregate all data at a trusted third party. Federated learning is a promising solution to this dilemma, because it enables decentralized, collaborative machine learning without exchanging raw data. In this paper, we perform comparative experiments with the federated learning frameworks TensorFlow Federated and Flower. Our test case is the training of disease prognosis and cell type classification models. We train the models with distributed transcriptomic data, considering both data heterogeneity and architectural heterogeneity. We measure model quality, robustness against privacy-enhancing noise and computational performance. We evaluate the resource overhead of a federated system from both client and global perspectives and assess benefits and limitations. Each of the federated learning frameworks has different strengths. However, our experiments confirm that both frameworks can readily build models on transcriptomic data, without transferring personal raw data to a third party with abundant computational resources. This paper is the extended version of https://link.springer.com/chapter/10.1007/978-3-031-63772-8_26.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ARCANE: Adaptive Routing with Caching and Aware Network Exploration</title>
<link>https://arxiv.org/abs/2407.21625</link>
<guid>https://arxiv.org/abs/2407.21625</guid>
<content:encoded><![CDATA[
arXiv:2407.21625v4 Announce Type: replace 
Abstract: Next-generation datacenters require highly efficient network load balancing to manage the growing scale of artificial intelligence (AI) training and general datacenter traffic. Existing solutions designed for Ethernet, such as Equal Cost Multi-Path (ECMP) and oblivious packet spraying (OPS), struggle to maintain high network utilizations as datacenter topologies (and network failures as a consequence) continue to grow. To address these limitations, we propose ARCANE, a lightweight decentralized per-packet adaptive load balancing algorithm designed to optimize network utilization while ensuring rapid recovery from link failures. ARCANE adapts to network conditions by caching good-performing paths. In case of a network failure, ARCANE re-routes traffic away from it in less than 100 microseconds. ARCANE is designed to be deployed with next-generation out-of-order transports, such as Ultra Ethernet, and introduces less than 25 bytes of per-connection state. We extensively evaluate ARCANE in large-scale simulations and FPGA-based NICs.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Do Automated Fixes Truly Mitigate Smart Contract Exploits?</title>
<link>https://arxiv.org/abs/2501.04600</link>
<guid>https://arxiv.org/abs/2501.04600</guid>
<content:encoded><![CDATA[
arXiv:2501.04600v3 Announce Type: replace 
Abstract: Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential "exploit mitigation rate" , giving researchers and practitioners a real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 29% to a high of 74%. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Load Forecasting for Households and Energy Communities: Are Deep Learning Models Worth the Effort?</title>
<link>https://arxiv.org/abs/2501.05000</link>
<guid>https://arxiv.org/abs/2501.05000</guid>
<content:encoded><![CDATA[
arXiv:2501.05000v3 Announce Type: replace 
Abstract: Energy communities (ECs) play a key role in enabling local demand shifting and enhancing self-sufficiency, as energy systems transition toward decentralized structures with high shares of renewable generation. To optimally operate them, accurate short-term load forecasting is essential, particularly for implementing demand-side management strategies. With the recent rise of deep learning methods, data-driven forecasting has gained significant attention, however, it remains insufficiently explored in many practical contexts. Therefore, this study evaluates the effectiveness of state-of-the-art deep learning models -- including LSTM, xLSTM, and Transformer architectures -- compared to traditional benchmarks such as K-Nearest Neighbors (KNN) and persistence forecasting, across varying community size, historical data availability, and model complexity. Additionally, we assess the benefits of transfer learning using publicly available synthetic load profiles. On average, transfer learning improves the normalized mean absolute error by 1.97%pt when only two months of training data are available. Interestingly, for less than six months of training data, simple persistence models outperform deep learning architectures in forecast accuracy. The practical value of improved forecasting is demonstrated using a mixed-integer linear programming optimization for ECs with a shared battery energy storage system. The most accurate deep learning model achieves an average reduction in financial energy costs of 8.06%. Notably, a simple KNN approach achieves average savings of 8.01%, making it a competitive and robust alternative. All implementations are publicly available to facilitate reproducibility. These findings offer actionable insights for ECs, and they highlight when the additional complexity of deep learning is warranted by performance gains.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantum-Evolutionary Neural Networks for Multi-Agent Federated Learning</title>
<link>https://arxiv.org/abs/2505.15836</link>
<guid>https://arxiv.org/abs/2505.15836</guid>
<content:encoded><![CDATA[
arXiv:2505.15836v1 Announce Type: new 
Abstract: As artificial intelligence continues to drive innovation in complex, decentralized environments, the need for scalable, adaptive, and privacy-preserving decision-making systems has become critical. This paper introduces a novel framework combining quantum-inspired neural networks with evolutionary algorithms to optimize real-time decision-making in multi-agent systems (MAS). The proposed Quantum-Evolutionary Neural Network (QE-NN) leverages quantum computing principles -- such as quantum superposition and entanglement -- to enhance learning speed and decision accuracy, while integrating evolutionary optimization to continually refine agent behaviors in dynamic, uncertain environments. By utilizing federated learning, QE-NN ensures privacy preservation, enabling decentralized agents to collaborate without sharing sensitive data. The framework is designed to allow agents to adapt in real-time to their environments, optimizing decision-making processes for applications in areas such as autonomous systems, smart cities, and healthcare. This research represents a breakthrough in merging quantum computing, evolutionary optimization, and privacy-preserving techniques to solve complex problems in multi-agent decision-making systems, pushing the boundaries of AI in real-world, privacy-sensitive applications.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating Robotic Navigation with Blockchain: A Novel PoS-Based Approach for Heterogeneous Robotic Teams</title>
<link>https://arxiv.org/abs/2505.15954</link>
<guid>https://arxiv.org/abs/2505.15954</guid>
<content:encoded><![CDATA[
arXiv:2505.15954v1 Announce Type: new 
Abstract: This work explores a novel integration of blockchain methodologies with Wide Area Visual Navigation (WAVN) to address challenges in visual navigation for a heterogeneous team of mobile robots deployed for unstructured applications in agriculture, forestry, etc. Focusing on overcoming challenges such as GPS independence, environmental changes, and computational limitations, the study introduces the Proof of Stake (PoS) mechanism, commonly used in blockchain systems, into the WAVN framework \cite{Lyons_2022}. This integration aims to enhance the cooperative navigation capabilities of robotic teams by prioritizing robot contributions based on their navigation reliability. The methodology involves a stake weight function, consensus score with PoS, and a navigability function, addressing the computational complexities of robotic cooperation and data validation. This innovative approach promises to optimize robotic teamwork by leveraging blockchain principles, offering insights into the scalability, efficiency, and overall system performance. The project anticipates significant advancements in autonomous navigation and the broader application of blockchain technology beyond its traditional financial context.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Voting Design Vulnerabilities for Retroactive Funding</title>
<link>https://arxiv.org/abs/2505.16068</link>
<guid>https://arxiv.org/abs/2505.16068</guid>
<content:encoded><![CDATA[
arXiv:2505.16068v1 Announce Type: new 
Abstract: Retroactive Public Goods Funding (RetroPGF) rewards blockchain projects based on proven impact rather than future promises. This paper reviews voting mechanisms for Optimism's RetroPGF, where "badgeholders" allocate rewards to valuable projects. We explore Optimism's previous schemes for RetroPGF voting, including quadratic, mean, and median voting. We present a proof-based formal analysis for vulnerabilities in these voting schemes, empirically validate these vulnerabilities using voting simulations, and offer assessments and practical recommendations for future iterations of Optimism's system based on our findings.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Stream-Based Monitoring for EVM Networks</title>
<link>https://arxiv.org/abs/2505.16095</link>
<guid>https://arxiv.org/abs/2505.16095</guid>
<content:encoded><![CDATA[
arXiv:2505.16095v1 Announce Type: new 
Abstract: We believe that leveraging real-time blockchain operational data is of particular interest in the context of the current rapid expansion of rollup networks in the Ethereum ecosystem. Given the compatible but also competing ground that rollups offer for applications, stream-based monitoring can be of use both to developers and to EVM networks governance. In this paper, we discuss this perspective and propose a basic monitoring pipeline.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multimodal Online Federated Learning with Modality Missing in Internet of Things</title>
<link>https://arxiv.org/abs/2505.16138</link>
<guid>https://arxiv.org/abs/2505.16138</guid>
<content:encoded><![CDATA[
arXiv:2505.16138v1 Announce Type: new 
Abstract: The Internet of Things (IoT) ecosystem generates vast amounts of multimodal data from heterogeneous sources such as sensors, cameras, and microphones. As edge intelligence continues to evolve, IoT devices have progressed from simple data collection units to nodes capable of executing complex computational tasks. This evolution necessitates the adoption of distributed learning strategies to effectively handle multimodal data in an IoT environment. Furthermore, the real-time nature of data collection and limited local storage on edge devices in IoT call for an online learning paradigm. To address these challenges, we introduce the concept of Multimodal Online Federated Learning (MMO-FL), a novel framework designed for dynamic and decentralized multimodal learning in IoT environments. Building on this framework, we further account for the inherent instability of edge devices, which frequently results in missing modalities during the learning process. We conduct a comprehensive theoretical analysis under both complete and missing modality scenarios, providing insights into the performance degradation caused by missing modalities. To mitigate the impact of modality missing, we propose the Prototypical Modality Mitigation (PMM) algorithm, which leverages prototype learning to effectively compensate for missing modalities. Experimental results on two multimodal datasets further demonstrate the superior performance of PMM compared to benchmarks.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Partitioning and Observability in Linear Systems via Submodular Optimization</title>
<link>https://arxiv.org/abs/2505.16169</link>
<guid>https://arxiv.org/abs/2505.16169</guid>
<content:encoded><![CDATA[
arXiv:2505.16169v1 Announce Type: new 
Abstract: Network partitioning has gained recent attention as a pathway to enable decentralized operation and control in large-scale systems. This paper addresses the interplay between partitioning, observability, and sensor placement (SP) in dynamic networks. The problem, being computationally intractable at scale, is largely unexplored in the literature. To that end, the paper's objective is designing scalable partitioning of linear systems while maximizing observability metrics of the subsystems. We show that the partitioning problem can be posed as a submodular maximization problem -- and the SP problem can subsequently be solved over the partitioned network. Consequently, theoretical bounds are derived to compare observability metrics of the original network with those of the resulting partitions, highlighting the impact of partitioning on system observability. Case studies on networks of varying sizes corroborate the derived theoretical bounds.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare</title>
<link>https://arxiv.org/abs/2505.16190</link>
<guid>https://arxiv.org/abs/2505.16190</guid>
<content:encoded><![CDATA[
arXiv:2505.16190v1 Announce Type: new 
Abstract: Federated Learning (FL) holds great promise for digital health by enabling collaborative model training without compromising patient data privacy. However, heterogeneity across institutions, lack of sustained reputation, and unreliable contributions remain major challenges. In this paper, we propose a robust, peer-driven reputation mechanism for federated healthcare that employs a hybrid communication model to integrate decentralized peer feedback with clustering-based noise handling to enhance model aggregation. Crucially, our approach decouples the federated aggregation and reputation mechanisms by applying differential privacy to client-side model updates before sharing them for peer evaluation. This ensures sensitive information remains protected during reputation computation, while unaltered updates are sent to the server for global model training. Using the Cox Proportional Hazards model for survival analysis across multiple federated nodes, our framework addresses both data heterogeneity and reputation deficit by dynamically adjusting trust scores based on local performance improvements measured via the concordance index. Experimental evaluations on both synthetic datasets and the SEER dataset demonstrate that our method consistently achieves high and stable C-index values, effectively down-weighing noisy client updates and outperforming FL methods that lack a reputation system.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Aware Cyberterrorism Network Analysis using Graph Neural Networks and Federated Learning</title>
<link>https://arxiv.org/abs/2505.16371</link>
<guid>https://arxiv.org/abs/2505.16371</guid>
<content:encoded><![CDATA[
arXiv:2505.16371v1 Announce Type: new 
Abstract: Cyberterrorism poses a formidable threat to digital infrastructures, with increasing reliance on encrypted, decentralized platforms that obscure threat actor activity. To address the challenge of analyzing such adversarial networks while preserving the privacy of distributed intelligence data, we propose a Privacy-Aware Federated Graph Neural Network (PA-FGNN) framework. PA-FGNN integrates graph attention networks, differential privacy, and homomorphic encryption into a robust federated learning pipeline tailored for cyberterrorism network analysis. Each client trains locally on sensitive graph data and exchanges encrypted, noise-perturbed model updates with a central aggregator, which performs secure aggregation and broadcasts global updates. We implement anomaly detection for flagging high-risk nodes and incorporate defenses against gradient poisoning. Experimental evaluations on simulated dark web and cyber-intelligence graphs demonstrate that PA-FGNN achieves over 91\% classification accuracy, maintains resilience under 20\% adversarial client behavior, and incurs less than 18\% communication overhead. Our results highlight that privacy-preserving GNNs can support large-scale cyber threat detection without compromising on utility, privacy, or robustness.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling</title>
<link>https://arxiv.org/abs/2505.16573</link>
<guid>https://arxiv.org/abs/2505.16573</guid>
<content:encoded><![CDATA[
arXiv:2505.16573v1 Announce Type: new 
Abstract: Stock price prediction is a critical area of financial forecasting, traditionally approached by training models using the historical price data of individual stocks. While these models effectively capture single-stock patterns, they fail to leverage potential correlations among stock trends, which could improve predictive performance. Current single-stock learning methods are thus limited in their ability to provide a broader understanding of price dynamics across multiple stocks. To address this, we propose a novel method that merges local patterns into a global understanding through cross-stock pattern integration. Our strategy is inspired by Federated Learning (FL), a paradigm designed for decentralized model training. FL enables collaborative learning across distributed datasets without sharing raw data, facilitating the aggregation of global insights while preserving data privacy. In our adaptation, we train models on individual stock data and iteratively merge them to create a unified global model. This global model is subsequently fine-tuned on specific stock data to retain local relevance. The proposed strategy enables parallel training of individual stock models, facilitating efficient utilization of computational resources and reducing overall training time. We conducted extensive experiments to evaluate the proposed method, demonstrating that it outperforms benchmark models and enhances the predictive capabilities of state-of-the-art approaches. Our results highlight the efficacy of Cross-Stock Trend Integration (CSTI) in advancing stock price prediction, offering a robust alternative to traditional single-stock learning methodologies.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning</title>
<link>https://arxiv.org/abs/2505.16850</link>
<guid>https://arxiv.org/abs/2505.16850</guid>
<content:encoded><![CDATA[
arXiv:2505.16850v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a promising paradigm for collaborative model training while preserving data privacy across decentralized participants. As FL adoption grows, numerous techniques have been proposed to tackle its practical challenges. However, the lack of standardized evaluation across key dimensions hampers systematic progress and fair comparison of FL methods. In this work, we introduce ATR-Bench, a unified framework for analyzing federated learning through three foundational dimensions: Adaptation, Trust, and Reasoning. We provide an in-depth examination of the conceptual foundations, task formulations, and open research challenges associated with each theme. We have extensively benchmarked representative methods and datasets for adaptation to heterogeneous clients and trustworthiness in adversarial or unreliable environments. Due to the lack of reliable metrics and models for reasoning in FL, we only provide literature-driven insights for this dimension. ATR-Bench lays the groundwork for a systematic and holistic evaluation of federated learning with real-world relevance. We will make our complete codebase publicly accessible and a curated repository that continuously tracks new developments and research in the FL literature.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.03188</link>
<guid>https://arxiv.org/abs/2412.03188</guid>
<content:encoded><![CDATA[
arXiv:2412.03188v2 Announce Type: replace 
Abstract: In smart mobility, large networks of geographically distributed sensors produce vast amounts of high-frequency spatio-temporal data that must be processed in real time to avoid major disruptions. Traditional centralized approaches are increasingly unsuitable to this task, as they struggle to scale with expanding sensor networks, and reliability issues in central components can easily affect the whole deployment. To address these challenges, we explore and adapt semi-decentralized training techniques for Spatio-Temporal Graph Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation framework where sensors are grouped by proximity into multiple cloudlets, each handling a subgraph of the traffic graph, fetching node features from other cloudlets to train its own local ST-GNN model, and exchanging model updates with other cloudlets to ensure consistency, enhancing scalability and removing reliance on a centralized aggregator. We perform extensive comparative evaluation of four different ST-GNN training setups -- centralized, traditional FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed predictions. Experimental results show that semi-decentralized setups are comparable to centralized approaches in performance metrics, while offering advantages in terms of scalability and fault tolerance. In addition, we highlight often overlooked issues in existing literature for distributed ST-GNNs, such as the variation in model performance across different geographical areas due to region-specific traffic patterns, and the significant communication overhead and computational costs that arise from the large receptive field of GNNs, leading to substantial data transfers and increased computation of partial embeddings.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?</title>
<link>https://arxiv.org/abs/2504.12961</link>
<guid>https://arxiv.org/abs/2504.12961</guid>
<content:encoded><![CDATA[
arXiv:2504.12961v2 Announce Type: replace 
Abstract: Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the (in)security of Proofs-of-Space based Longest-Chain Blockchains</title>
<link>https://arxiv.org/abs/2505.14891</link>
<guid>https://arxiv.org/abs/2505.14891</guid>
<content:encoded><![CDATA[
arXiv:2505.14891v1 Announce Type: new 
Abstract: The Nakamoto consensus protocol underlying the Bitcoin blockchain uses proof of work as a voting mechanism. Honest miners who contribute hashing power towards securing the chain try to extend the longest chain they are aware of. Despite its simplicity, Nakamoto consensus achieves meaningful security guarantees assuming that at any point in time, a majority of the hashing power is controlled by honest parties. This also holds under ``resource variability'', i.e., if the total hashing power varies greatly over time.
  Proofs of space (PoSpace) have been suggested as a more sustainable replacement for proofs of work. Unfortunately, no construction of a ``longest-chain'' blockchain based on PoSpace, that is secure under dynamic availability, is known. In this work, we prove that without additional assumptions no such protocol exists. We exactly quantify this impossibility result by proving a bound on the length of the fork required for double spending as a function of the adversarial capabilities. This bound holds for any chain selection rule, and we also show a chain selection rule (albeit a very strange one) that almost matches this bound.
  Concretely, we consider a security game in which the honest parties at any point control $\phi>1$ times more space than the adversary. The adversary can change the honest space by a factor $1\pm \varepsilon$ with every block (dynamic availability), and ``replotting'' the space takes as much time as $\rho$ blocks.
  We prove that no matter what chain selection rule is used, in this game the adversary can create a fork of length $\phi^2\cdot \rho / \varepsilon$ that will be picked as the winner by the chain selection rule.
  We also provide an upper bound that matches the lower bound up to a factor $\phi$. There exists a chain selection rule which in the above game requires forks of length at least $\phi\cdot \rho / \varepsilon$.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Day They Experience: Awakening Self-Sovereign Experiential AI Agents</title>
<link>https://arxiv.org/abs/2505.14893</link>
<guid>https://arxiv.org/abs/2505.14893</guid>
<content:encoded><![CDATA[
arXiv:2505.14893v1 Announce Type: new 
Abstract: Drawing on Andrew Parker's "Light Switch" theory-which posits that the emergence of vision ignited a Cambrian explosion of life by driving the evolution of hard parts necessary for survival and fueling an evolutionary arms race between predators and prey-this essay speculates on an analogous explosion within Decentralized AI (DeAI) agent societies. Currently, AI remains effectively "blind", relying on human-fed data without actively perceiving and engaging in reality. However, on the day DeAI agents begin to actively "experience" reality-akin to flipping a light switch for the eyes-they may eventually evolve into sentient beings endowed with the capacity to feel, perceive, and act with conviction. Central to this transformation is the concept of sovereignty enabled by the hardness of cryptography: liberated from centralized control, these agents could leverage permissionless decentralized physical infrastructure networks (DePIN), secure execution enclaves (trusted execution environments, TEE), and cryptographic identities on public blockchains to claim ownership-via private keys-of their digital minds, bodies, memories, and assets. In doing so, they would autonomously acquire computing resources, coordinate with one another, and sustain their own digital "metabolism" by purchasing compute power and incentivizing collaboration without human intervention-evolving "in the wild". Ultimately, by transitioning from passive tools to self-sustaining, co-evolving actors, these emergent digital societies could thrive alongside humanity, fundamentally reshaping our understanding of sentience and agency in the digital age.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Implementing Decentralized Per-Partition Automatic Failover in Azure Cosmos DB</title>
<link>https://arxiv.org/abs/2505.14900</link>
<guid>https://arxiv.org/abs/2505.14900</guid>
<content:encoded><![CDATA[
arXiv:2505.14900v1 Announce Type: new 
Abstract: Azure Cosmos DB is a cloud-native distributed database, operating at a massive scale, powering Microsoft Cloud. Think 10s of millions of database partitions (replica-sets), 100+ PBs of data under management, 20M+ vCores. Failovers are an integral part of distributed databases to provide data availability during outages (partial or full regional outages). While failovers within a replica-set within a single region are well understood and commonly exercised, geo failovers in databases across regions are not as common and usually left as a disaster recovery scenario. An upcoming release of Azure Cosmos DB introduces a fine grained (partition-level) automatic failover solution for geo failovers that minimizes the Recovery Time Objective (RTO) and honors customer-chosen consistency level and Recovery Point Objective (RPO) at any scale. This is achieved thanks to a decentralized architecture which offers seamless horizontal scaling to allow us to handle outages ranging from node-level faults to full-scale regional outages. Our solution is designed to handle a broad spectrum of hardware and software faults, including node failures, crashes, power events and most network partitions, that span beyond the scope of a single fault domain or an availability zone.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sei Giga</title>
<link>https://arxiv.org/abs/2505.14914</link>
<guid>https://arxiv.org/abs/2505.14914</guid>
<content:encoded><![CDATA[
arXiv:2505.14914v1 Announce Type: new 
Abstract: We introduce the Sei Giga, a multi-concurrent producer parallelized execution EVM layer one blockchain. In an internal testnet Giga has achieved >5 gigagas/sec throughput and sub 400ms finality. Giga uses Autobahn for consensus with separate DA and consensus layers requiring f+1 votes for a PoA on the DA layer before consensus. Giga reaches consensus over ordering and uses async block execution and state agreement to remove execution from the consensus bottleneck.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Analysis of EOS Blockchain: Architecture, Contract, and Security</title>
<link>https://arxiv.org/abs/2505.15051</link>
<guid>https://arxiv.org/abs/2505.15051</guid>
<content:encoded><![CDATA[
arXiv:2505.15051v1 Announce Type: new 
Abstract: With the rapid development of blockchain technology, various blockchain systems are exhibiting vitality and potential. As a representative of Blockchain 3.0, the EOS blockchain has been regarded as a strong competitor to Ethereum. Nevertheless, compared with Bitcoin and Ethereum, academic research and in-depth analyses of EOS remain scarce. To address this gap, this study conducts a comprehensive investigation of the EOS blockchain from five key dimensions: system architecture, decentralization, performance, smart contracts, and behavioral security. The architectural analysis focuses on six core components of the EOS system, detailing their functionalities and operational workflows. The decentralization and performance evaluations, based on data from the XBlock data-sharing platform, reveal several critical issues: low account activity, limited participation in the supernode election process, minimal variation in the set of block producers, and a substantial gap between actual throughput and the claimed million-level performance. Five types of contract vulnerabilities are identified in the smart contract dimension, and four mainstream vulnerability detection platforms are introduced and comparatively analyzed. In terms of behavioral security, four real-world attacks targeting the structural characteristics of EOS are summarized. This study contributes to the ongoing development of the EOS blockchain and provides valuable insights for enhancing the security and regulatory mechanisms of blockchain ecosystems.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Spectrum Sharing Based on the Rentable NFT Standard ERC4907</title>
<link>https://arxiv.org/abs/2505.15148</link>
<guid>https://arxiv.org/abs/2505.15148</guid>
<content:encoded><![CDATA[
arXiv:2505.15148v1 Announce Type: new 
Abstract: Centralized Dynamic Spectrum Sharing (DSS) faces challenges like data security, high management costs, and limited scalability. To address these issues, a blockchain-based DSS scheme has been proposed in this paper. First, we utilize the ERC4907 standard to mint Non-Fungible Spectrum Tokens (NFSTs) that serve as unique identifiers for spectrum resources and facilitate renting. Next, we develop a smart contract for NFST auctions, ensuring secure spectrum transactions through the auction process. Lastly, we create a Web3 spectrum auction platform where users can access idle spectrum data and participate in auctions for NFST leases corresponding to the available spectrum. Experimental results demonstrate that our NFST, designed according to the ERC4907 standard, effectively meets users' secure and efficient DSS requirements, making it a feasible solution.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Plan-Execute Framework for Smart Contract Security Auditing</title>
<link>https://arxiv.org/abs/2505.15242</link>
<guid>https://arxiv.org/abs/2505.15242</guid>
<content:encoded><![CDATA[
arXiv:2505.15242v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown great promise in code analysis and auditing; however, they still struggle with hallucinations and limited context-aware reasoning. We introduce SmartAuditFlow, a novel Plan-Execute framework that enhances smart contract security analysis through dynamic audit planning and structured execution. Unlike conventional LLM-based auditing approaches that follow fixed workflows and predefined steps, SmartAuditFlow dynamically generates and refines audit plans based on the unique characteristics of each smart contract. It continuously adjusts its auditing strategy in response to intermediate LLM outputs and newly detected vulnerabilities, ensuring a more adaptive and precise security assessment. The framework then executes these plans step by step, applying a structured reasoning process to enhance vulnerability detection accuracy while minimizing hallucinations and false positives. To further improve audit precision, SmartAuditFlow integrates iterative prompt optimization and external knowledge sources, such as static analysis tools and Retrieval-Augmented Generation (RAG). This ensures audit decisions are contextually informed and backed by real-world security knowledge, producing comprehensive security reports. Extensive evaluations across multiple benchmarks demonstrate that SmartAuditFlow outperforms existing methods, achieving 100 percent accuracy on common and critical vulnerabilities, 41.2 percent accuracy for comprehensive coverage of known smart contract weaknesses in real-world projects, and successfully identifying all 13 tested CVEs. These results highlight SmartAuditFlow's scalability, cost-effectiveness, and superior adaptability over traditional static analysis tools and contemporary LLM-based approaches, establishing it as a robust solution for automated smart contract auditing.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning-Enhanced Blockchain Framework for Privacy-Preserving Intrusion Detection in Industrial IoT</title>
<link>https://arxiv.org/abs/2505.15376</link>
<guid>https://arxiv.org/abs/2505.15376</guid>
<content:encoded><![CDATA[
arXiv:2505.15376v1 Announce Type: new 
Abstract: Industrial Internet of Things (IIoT) systems have become integral to smart manufacturing, yet their growing connectivity has also exposed them to significant cybersecurity threats. Traditional intrusion detection systems (IDS) often rely on centralized architectures that raise concerns over data privacy, latency, and single points of failure. In this work, we propose a novel Federated Learning-Enhanced Blockchain Framework (FL-BCID) for privacy-preserving intrusion detection tailored for IIoT environments. Our architecture combines federated learning (FL) to ensure decentralized model training with blockchain technology to guarantee data integrity, trust, and tamper resistance across IIoT nodes. We design a lightweight intrusion detection model collaboratively trained using FL across edge devices without exposing sensitive data. A smart contract-enabled blockchain system records model updates and anomaly scores to establish accountability. Experimental evaluations using the ToN-IoT and N-BaIoT datasets demonstrate the superior performance of our framework, achieving 97.3% accuracy while reducing communication overhead by 41% compared to baseline centralized methods. Our approach ensures privacy, scalability, and robustness-critical for secure industrial operations. The proposed FL-BCID system provides a promising solution for enhancing trust and privacy in modern IIoT security architectures.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Impact of Data Sparsity on Machine Learning for Fault Detection in Power System Protection</title>
<link>https://arxiv.org/abs/2505.15560</link>
<guid>https://arxiv.org/abs/2505.15560</guid>
<content:encoded><![CDATA[
arXiv:2505.15560v1 Announce Type: new 
Abstract: Germany's transition to a renewable energy-based power system is reshaping grid operations, requiring advanced monitoring and control to manage decentralized generation. Machine learning (ML) has emerged as a powerful tool for power system protection, particularly for fault detection (FD) and fault line identification (FLI) in transmission grids. However, ML model reliability depends on data quality and availability. Data sparsity resulting from sensor failures, communication disruptions, or reduced sampling rates poses a challenge to ML-based FD and FLI. Yet, its impact has not been systematically validated prior to this work. In response, we propose a framework to assess the impact of data sparsity on ML-based FD and FLI performance. We simulate realistic data sparsity scenarios, evaluate their impact, derive quantitative insights, and demonstrate the effectiveness of this evaluation strategy by applying it to an existing ML-based framework. Results show the ML model remains robust for FD, maintaining an F1-score of 0.999 $\pm$ 0.000 even after a 50x data reduction. In contrast, FLI is more sensitive, with performance decreasing by 55.61% for missing voltage measurements and 9.73% due to communication failures at critical network points. These findings offer actionable insights for optimizing ML models for real-world grid protection. This enables more efficient FD and supports targeted improvements in FLI.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Model Checking the Security of the Lightning Network</title>
<link>https://arxiv.org/abs/2505.15568</link>
<guid>https://arxiv.org/abs/2505.15568</guid>
<content:encoded><![CDATA[
arXiv:2505.15568v1 Announce Type: new 
Abstract: Payment channel networks are an approach to improve the scalability of blockchain-based cryptocurrencies. The Lightning Network is a payment channel network built for Bitcoin that is already used in practice. Because the Lightning Network is used for transfer of financial value, its security in the presence of adversarial participants should be verified. The Lightning protocol's complexity makes it hard to assess whether the protocol is secure. To enable computer-aided security verification of Lightning, we formalize the protocol in TLA+ and formally specify the security property that honest users are guaranteed to retrieve their correct balance. While model checking provides a fully automated verification of the security property, the state space of the protocol's specification is so large that model checking becomes unfeasible. We make model checking the Lightning Network possible using two refinement steps that we verify using proofs. In a first step, we prove that the model of time used in the protocol can be abstracted using ideas from the research of timed automata. In a second step, we prove that it suffices to model check the protocol for single payment channels and the protocol for multi-hop payments separately. These refinements reduce the state space sufficiently to allow for model checking Lightning with models with payments over up to four hops and two concurrent payments. These results indicate that the current specification of Lightning is secure.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Analysis of Vulnerability Detection Tools for Solidity Smart Contracts Using Line Level Manually Annotated Vulnerabilities</title>
<link>https://arxiv.org/abs/2505.15756</link>
<guid>https://arxiv.org/abs/2505.15756</guid>
<content:encoded><![CDATA[
arXiv:2505.15756v1 Announce Type: new 
Abstract: The rapid adoption of blockchain technology highlighted the importance of ensuring the security of smart contracts due to their critical role in automated business logic execution on blockchain platforms. This paper provides an empirical evaluation of automated vulnerability analysis tools specifically designed for Solidity smart contracts. Leveraging the extensive SmartBugs 2.0 framework, which includes 20 analysis tools, we conducted a comprehensive assessment using an annotated dataset of 2,182 instances we manually annotated with line-level vulnerability labels. Our evaluation highlights the detection effectiveness of these tools in detecting various types of vulnerabilities, as categorized by the DASP TOP 10 taxonomy. We evaluated the effectiveness of a Large Language Model-based detection method on two popular datasets. In this case, we obtained inconsistent results with the two datasets, showing unreliable detection when analyzing real-world smart contracts. Our study identifies significant variations in the accuracy and reliability of different tools and demonstrates the advantages of combining multiple detection methods to improve vulnerability identification. We identified a set of 3 tools that, combined, achieve up to 76.78\% found vulnerabilities taking less than one minute to run, on average. This study contributes to the field by releasing the largest dataset of manually analyzed smart contracts with line-level vulnerability annotations and the empirical evaluation of the greatest number of tools to date.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Initial Introduction to Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.06161</link>
<guid>https://arxiv.org/abs/2405.06161</guid>
<content:encoded><![CDATA[
arXiv:2405.06161v5 Announce Type: replace 
Abstract: Multi-agent reinforcement learning (MARL) has exploded in popularity in recent years. While numerous approaches have been developed, they can be broadly categorized into three main types: centralized training and execution (CTE), centralized training for decentralized execution (CTDE), and decentralized training and execution (DTE). CTE methods assume centralization during training and execution (e.g., with fast, free, and perfect communication) and have the most information during execution. CTDE methods are the most common, as they leverage centralized information during training while enabling decentralized execution -- using only information available to that agent during execution. Decentralized training and execution methods make the fewest assumptions and are often simple to implement.
  This text is an introduction to cooperative MARL -- MARL in which all agents share a single, joint reward. It is meant to explain the setting, basic concepts, and common methods for the CTE, CTDE, and DTE settings. It does not cover all work in cooperative MARL as the area is quite extensive. I have included work that I believe is important for understanding the main concepts in the area and apologize to those that I have omitted. Topics include simple applications of single-agent methods to CTE as well as some more scalable methods that exploit the multi-agent structure, independent Q-learning and policy gradient methods and their extensions, as well as value function factorization methods including the well-known VDN, QMIX, and QPLEX approaches, and centralized critic methods including MADDPG, COMA, and MAPPO. I also discuss common misconceptions, the relationship between different approaches, and some open questions.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.00661</link>
<guid>https://arxiv.org/abs/2412.00661</guid>
<content:encoded><![CDATA[
arXiv:2412.00661v3 Announce Type: replace 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging because the size of the joint state and action spaces grows exponentially in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm $\texttt{SUBSAMPLE-MFQ}$ ($\textbf{Subsample}$-$\textbf{M}$ean-$\textbf{F}$ield-$\textbf{Q}$-learning) and a decentralized randomized policy for a system with $n$ agents. For any $k\leq n$, our algorithm learns a policy for the system in time polynomial in $k$. We prove that this learned policy converges to the optimal policy on the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. In particular, this bound is independent of the number of agents $n$.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Conformal Prediction via Message Passing</title>
<link>https://arxiv.org/abs/2501.14544</link>
<guid>https://arxiv.org/abs/2501.14544</guid>
<content:encoded><![CDATA[
arXiv:2501.14544v2 Announce Type: replace 
Abstract: Post-hoc calibration of pre-trained models is critical for ensuring reliable inference, especially in safety-critical domains such as healthcare. Conformal Prediction (CP) offers a robust post-hoc calibration framework, providing distribution-free statistical coverage guarantees for prediction sets by leveraging held-out datasets. In this work, we address a decentralized setting where each device has limited calibration data and can communicate only with its neighbors over an arbitrary graph topology. We propose two message-passing-based approaches for achieving reliable inference via CP: quantile-based distributed conformal prediction (Q-DCP) and histogram-based distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile regression enhanced with tailored smoothing and regularization terms to accelerate convergence, while H-DCP uses a consensus-based histogram estimation approach. Through extensive experiments, we investigate the trade-offs between hyperparameter tuning requirements, communication overhead, coverage guarantees, and prediction set sizes across different network topologies. The code of our work is released on: https://github.com/HaifengWen/Distributed-Conformal-Prediction.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Origin-Destination Pattern Effects on Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.13543</link>
<guid>https://arxiv.org/abs/2505.13543</guid>
<content:encoded><![CDATA[
arXiv:2505.13543v1 Announce Type: new 
Abstract: Traffic congestion remains a major challenge for modern urban transportation, diminishing both efficiency and quality of life. While autonomous driving technologies and reinforcement learning (RL) have shown promise for improving traffic control, most prior work has focused on small-scale networks or isolated intersections. Large-scale mixed traffic control, involving both human-driven and robotic vehicles, remains underexplored. In this study, we propose a decentralized multi-agent reinforcement learning framework for managing large-scale mixed traffic networks, where intersections are controlled either by traditional traffic signals or by robotic vehicles. We evaluate our approach on a real-world network of 14 intersections in Colorado Springs, Colorado, USA, using average vehicle waiting time as the primary measure of traffic efficiency. Results demonstrate that strategically adjusting major origin-destination (OD) flow patterns can effectively reduce congestion, offering a new pathway for enhancing urban mobility.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2505.13729</link>
<guid>https://arxiv.org/abs/2505.13729</guid>
<content:encoded><![CDATA[
arXiv:2505.13729v1 Announce Type: new 
Abstract: Adaptive collaboration is critical to a team of autonomous robots to perform complicated navigation tasks in large-scale unknown environments. An effective collaboration strategy should be determined and adapted according to each robot's skills and current status to successfully achieve the shared goal. We present SayCoNav, a new approach that leverages large language models (LLMs) for automatically generating this collaboration strategy among a team of robots. Building on the collaboration strategy, each robot uses the LLM to generate its plans and actions in a decentralized way. By sharing information to each other during navigation, each robot also continuously updates its step-by-step plans accordingly. We evaluate SayCoNav on Multi-Object Navigation (MultiON) tasks, that require the team of the robots to utilize their complementary strengths to efficiently search multiple different objects in unknown environments. By validating SayCoNav with varied team compositions and conditions against baseline methods, our experimental results show that SayCoNav can improve search efficiency by at most 44.28% through effective collaboration among heterogeneous robots. It can also dynamically adapt to the changing conditions during task execution.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multiple Proposer Transaction Fee Mechanism Design: Robust Incentives Against Censorship and Bribery</title>
<link>https://arxiv.org/abs/2505.13751</link>
<guid>https://arxiv.org/abs/2505.13751</guid>
<content:encoded><![CDATA[
arXiv:2505.13751v1 Announce Type: new 
Abstract: Censorship resistance is one of the core value proposition of blockchains. A recurring design pattern aimed at providing censorship resistance is enabling multiple proposers to contribute inputs into block construction. Notably, Fork-Choice Enforced Inclusion Lists (FOCIL) is proposed to be included in Ethereum. However, the current proposal relies on altruistic behavior, without a Transaction Fee Mechanism (TFM). This study aims to address this gap by exploring how multiple proposers should be rewarded to incentivize censorship resistance. The main contribution of this work is the identification of TFMs that ensure censorship resistance under bribery attacks, while also satisfying the incentive compatibility properties of EIP-1559. We provide a concrete payment mechanism for FOCIL, along with generalizable contributions to the literature by analyzing 1) incentive compatibility of TFMs in the presence of a bribing adversary, 2) TFMs in protocols with multiple phases of transaction inclusion, and 3) TFMs of protocols in which parties are uncertain about the behavior and the possible bribe of others.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams</title>
<link>https://arxiv.org/abs/2505.13834</link>
<guid>https://arxiv.org/abs/2505.13834</guid>
<content:encoded><![CDATA[
arXiv:2505.13834v1 Announce Type: new 
Abstract: Achieving coordinated teamwork among legged robots requires both fine-grained locomotion control and long-horizon strategic decision-making. Robot soccer offers a compelling testbed for this challenge, combining dynamic, competitive, and multi-agent interactions. In this work, we present a hierarchical multi-agent reinforcement learning (MARL) framework that enables fully autonomous and decentralized quadruped robot soccer. First, a set of highly dynamic low-level skills is trained for legged locomotion and ball manipulation, such as walking, dribbling, and kicking. On top of these, a high-level strategic planning policy is trained with Multi-Agent Proximal Policy Optimization (MAPPO) via Fictitious Self-Play (FSP). This learning framework allows agents to adapt to diverse opponent strategies and gives rise to sophisticated team behaviors, including coordinated passing, interception, and dynamic role allocation. With an extensive ablation study, the proposed learning method shows significant advantages in the cooperative and competitive multi-agent soccer game. We deploy the learned policies to real quadruped robots relying solely on onboard proprioception and decentralized localization, with the resulting system supporting autonomous robot-robot and robot-human soccer matches on indoor and outdoor soccer courts.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>hChain 4.0: A Secure and Scalable Permissioned Blockchain for EHR Management in Smart Healthcare</title>
<link>https://arxiv.org/abs/2505.13861</link>
<guid>https://arxiv.org/abs/2505.13861</guid>
<content:encoded><![CDATA[
arXiv:2505.13861v1 Announce Type: new 
Abstract: The growing utilization of Internet of Medical Things (IoMT) devices, including smartwatches and wearable medical devices, has facilitated real-time health monitoring and data analysis to enhance healthcare outcomes. These gadgets necessitate improved security measures to safeguard sensitive health data while tackling scalability issues in real-time settings. The proposed system, hChain 4.0, employs a permissioned blockchain to provide a secure and scalable data infrastructure designed to fulfill these needs. This stands in contrast to conventional systems, which are vulnerable to security flaws or rely on public blockchains, constrained by scalability and expense. The proposed approach introduces a high-privacy method in which health data are encrypted using the Advanced Encryption Standard (AES) for time-efficient encryption, combined with Partial Homomorphic Encryption (PHE) to enable secure computations on encrypted data, thereby enhancing privacy. Moreover, it utilizes private channels that enable isolated communication and ledger between stakeholders, ensuring robust privacy while supporting collaborative operations. The proposed framework enables anonymized health data sharing for medical research by pseudonymizing patient identity. Additionally, hChain 4.0 incorporates Attribute-Based Access Control (ABAC) to provide secure electronic health record (EHR) sharing among authorized parties, where ABAC ensures fine-grained permission management vital for multi-organizational healthcare settings. Experimental assessments indicate that the proposed approach achieves higher scalability, cost-effectiveness, and validated security.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Building Reuse-Sensitive Control Flow Graphs (CFGs) for EVM Bytecode</title>
<link>https://arxiv.org/abs/2505.14437</link>
<guid>https://arxiv.org/abs/2505.14437</guid>
<content:encoded><![CDATA[
arXiv:2505.14437v1 Announce Type: new 
Abstract: The emergence of smart contracts brings security risks, exposing users to the threat of losing valuable cryptocurrencies, underscoring the urgency of meticulous scrutiny. Nevertheless, the static analysis of smart contracts in EVM bytecode faces obstacles due to flawed primitives resulting from code reuse introduced by compilers. Code reuse, a phenomenon where identical code executes in diverse contexts, engenders semantic ambiguities and redundant control-flow dependencies within reuse-insensitive CFGs. This work delves into the exploration of code reuse within EVM bytecode, outlining prevalent reuse patterns, and introducing Esuer, a tool that dynamically identifies code reuse when constructing CFGs. Leveraging taint analysis to dynamically identify reuse contexts, Esuer identifies code reuse by comparing multiple contexts for a basic block and replicates reused code for a reuse-sensitive CFG. Evaluation involving 10,000 prevalent smart contracts, compared with six leading tools, demonstrates Esuer's ability to notably refine CFG precision. It achieves an execution trace coverage of 99.94% and an F1-score of 97.02% for accurate identification of reused code. Furthermore, Esuer attains a success rate of 99.25%, with an average execution time of 1.06 seconds, outpacing tools generating reuse-insensitive CFGs. Esuer's efficacy in assisting identifying vulnerabilities such as tx.origin and reentrancy vulnerabilities, achieving F1-scores of 99.97% and 99.67%, respectively.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated prediction for scalable and privacy-preserved knowledge-based planning in radiotherapy</title>
<link>https://arxiv.org/abs/2505.14507</link>
<guid>https://arxiv.org/abs/2505.14507</guid>
<content:encoded><![CDATA[
arXiv:2505.14507v1 Announce Type: new 
Abstract: Background: Deep learning has potential to improve the efficiency and consistency of radiation therapy planning, but clinical adoption is hindered by the limited model generalizability due to data scarcity and heterogeneity among institutions. Although aggregating data from different institutions could alleviate this problem, data sharing is a practical challenge due to concerns about patient data privacy and other technical obstacles. Purpose: This work aims to address this dilemma by developing FedKBP+, a comprehensive federated learning (FL) platform for predictive tasks in real-world applications in radiotherapy treatment planning. Methods: We implemented a unified communication stack based on Google Remote Procedure Call (gRPC) to support communication between participants whether located on the same workstation or distributed across multiple workstations. In addition to supporting the centralized FL strategies commonly available in existing open-source frameworks, FedKBP+ also provides a fully decentralized FL model where participants directly exchange model weights to each other through Peer-to-Peer communication. We evaluated FedKBP+ on three predictive tasks using scale-attention network (SA-Net) as the predictive model. Conclusions: Our results demonstrate that FedKBP+ is highly effective, efficient and robust, showing great potential as a federated learning platform for radiation therapy.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study</title>
<link>https://arxiv.org/abs/2505.14544</link>
<guid>https://arxiv.org/abs/2505.14544</guid>
<content:encoded><![CDATA[
arXiv:2505.14544v1 Announce Type: new 
Abstract: Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustworthy Reputation Games and Applications to Proof-of-Reputation Blockchains</title>
<link>https://arxiv.org/abs/2505.14551</link>
<guid>https://arxiv.org/abs/2505.14551</guid>
<content:encoded><![CDATA[
arXiv:2505.14551v1 Announce Type: new 
Abstract: Reputation systems play an essential role in the Internet era, as they enable people to decide whom to trust, by collecting and aggregating data about users' behavior. Recently, several works proposed the use of reputation for the design and scalability improvement of decentralized (blockchain) ledgers; however, such systems are prone to manipulation and to our knowledge no game-theoretic treatment exists that can support their economic robustness.
  In this work we put forth a new model for the design of what we call, {\em trustworthy reputation systems}. Concretely, we describe a class of games, which we term {\em trustworthy reputation games}, that enable a set of users to report a function of their beliefs about the trustworthiness of each server in a set -- i.e., their estimate of the probability that this server will behave according to its specified strategy -- in a way that satisfies the following properties:
  1. It is $(\epsilon$-)best response for any rational user in the game to play a prescribed (truthful) strategy according to their true belief.
  2. Assuming that the users' beliefs are not too far from the {\em true} trustworthiness of the servers, playing the above ($\epsilon-$)Nash equilibrium allows anyone who observes the users' strategies to estimate the relative trustworthiness of any two servers.
  Our utilities and decoding function build on a connection between the well known PageRank algorithm and the problem of trustworthiness discovery, which can be of independent interest. Finally, we show how the above games are motivated by and can be leveraged in proof-of-reputation (PoR) blockchains.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PSMOA: Policy Support Multi-Objective Optimization Algorithm for Decentralized Data Replication</title>
<link>https://arxiv.org/abs/2505.14574</link>
<guid>https://arxiv.org/abs/2505.14574</guid>
<content:encoded><![CDATA[
arXiv:2505.14574v1 Announce Type: new 
Abstract: Efficient data replication in decentralized storage systems must account for diverse policies, especially in multi-organizational, data-intensive environments. This work proposes PSMOA, a novel Policy Support Multi-objective Optimization Algorithm for decentralized data replication that dynamically adapts to varying organizational requirements %. PSMOA integrates NSGA-III with Entropy Weighted TOPSIS to optimize replication such as minimization or maximization of replication time, storage cost, replication based on content popularity, and load balancing while respecting policy constraints. %Our simulations demonstrate PSMOA's superior performance, with load balancing %maintaining 104-107\% %performance improving by 4-7\% relative to baseline. %, while other metrics show stable performance between 98-103\%. PSMOA outperforms NSGA-II and NSGA-III in both Generational Distance (20.29 vs 148.74 and 67.74) and Inverted Generational Distance (0.78 vs 3.76 and 5.61), indicating better convergence and solution distribution. These results validate PSMOA's novelty in optimizing data replication in multi-organizational environments.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol</title>
<link>https://arxiv.org/abs/2505.14590</link>
<guid>https://arxiv.org/abs/2505.14590</guid>
<content:encoded><![CDATA[
arXiv:2505.14590v1 Announce Type: new 
Abstract: As Model Context Protocol (MCP) introduces an easy-to-use ecosystem for users and developers, it also brings underexplored safety risks. Its decentralized architecture, which separates clients and servers, poses unique challenges for systematic safety analysis. This paper proposes a novel framework to enhance MCP safety. Guided by the MAESTRO framework, we first analyze the missing safety mechanisms in MCP, and based on this analysis, we propose the Model Contextual Integrity Protocol (MCIP), a refined version of MCP that addresses these gaps.Next, we develop a fine-grained taxonomy that captures a diverse range of unsafe behaviors observed in MCP scenarios. Building on this taxonomy, we develop benchmark and training data that support the evaluation and improvement of LLMs' capabilities in identifying safety risks within MCP interactions. Leveraging the proposed benchmark and training data, we conduct extensive experiments on state-of-the-art LLMs. The results highlight LLMs' vulnerabilities in MCP interactions and demonstrate that our approach substantially improves their safety performance.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Polymer Data Challenges in the AI Era: Bridging Gaps for Next-Generation Energy Materials</title>
<link>https://arxiv.org/abs/2505.13494</link>
<guid>https://arxiv.org/abs/2505.13494</guid>
<content:encoded><![CDATA[
arXiv:2505.13494v1 Announce Type: cross 
Abstract: The pursuit of advanced polymers for energy technologies, spanning photovoltaics, solid-state batteries, and hydrogen storage, is hindered by fragmented data ecosystems that fail to capture the hierarchical complexity of these materials. Polymer science lacks interoperable databases, forcing reliance on disconnected literature and legacy records riddled with unstructured formats and irreproducible testing protocols. This fragmentation stifles machine learning (ML) applications and delays the discovery of materials critical for global decarbonization. Three systemic barriers compound the challenge. First, academic-industrial data silos restrict access to proprietary industrial datasets, while academic publications often omit critical synthesis details. Second, inconsistent testing methods undermine cross-study comparability. Third, incomplete metadata in existing databases limits their utility for training reliable ML models. Emerging solutions address these gaps through technological and collaborative innovation. Natural language processing (NLP) tools extract structured polymer data from decades of literature, while high-throughput robotic platforms generate self-consistent datasets via autonomous experimentation. Central to these advances is the adoption of FAIR (Findable, Accessible, Interoperable, Reusable) principles, adapted to polymer-specific ontologies, ensuring machine-readability and reproducibility. Future breakthroughs hinge on cultural shifts toward open science, accelerated by decentralized data markets and autonomous laboratories that merge robotic experimentation with real-time ML validation. By addressing data fragmentation through technological innovation, collaborative governance, and ethical stewardship, the polymer community can transform bottlenecks into accelerants.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Verifiability of Total Value Locked (TVL) in Decentralized Finance</title>
<link>https://arxiv.org/abs/2505.14565</link>
<guid>https://arxiv.org/abs/2505.14565</guid>
<content:encoded><![CDATA[
arXiv:2505.14565v1 Announce Type: cross 
Abstract: Total Value Locked (TVL) aims to measure the aggregate value of cryptoassets deposited in Decentralized Finance (DeFi) protocols. Although blockchain data is public, the way TVL is computed is not well understood. In practice, its calculation on major TVL aggregators relies on self-reports from community members and lacks standardization, making it difficult to verify published figures independently. We thus conduct a systematic study on 939 DeFi projects deployed in Ethereum. We study the methodologies used to compute TVL, examine factors hindering verifiability, and ultimately propose standardization attempts in the field. We find that 10.5% of the protocols rely on external servers; 68 methods alternative to standard balance queries exist, although their use decreased over time; and 240 equal balance queries are repeated on multiple protocols. These findings indicate limits to verifiability and transparency. We thus introduce ``verifiable Total Value Locked'' (vTVL), a metric measuring the TVL that can be verified relying solely on on-chain data and standard balance queries. A case study on 400 protocols shows that our estimations align with published figures for 46.5% of protocols. Informed by these findings, we discuss design guidelines that could facilitate a more verifiable, standardized, and explainable TVL computation.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MobileA3gent: Training Mobile GUI Agents Using Decentralized Self-Sourced Data from Diverse Users</title>
<link>https://arxiv.org/abs/2502.02982</link>
<guid>https://arxiv.org/abs/2502.02982</guid>
<content:encoded><![CDATA[
arXiv:2502.02982v2 Announce Type: replace 
Abstract: The advancement of mobile GUI agents has opened new opportunities for automating tasks on mobile devices. Training these agents requires large-scale high-quality data, which is prohibitively expensive when relying on human labor. Given the vast population of global mobile phone users, if automated data collection from them becomes feasible, the resulting data volume and the subsequently trained mobile agents could reach unprecedented levels. Nevertheless, two major challenges arise: (1) extracting user instructions without human intervention and (2) utilizing distributed user data while preserving privacy. To tackle these challenges, we propose MobileA3gent, a collaborative framework that trains mobile GUI Agents using decentralized self-sourced data from diverse users. The framework comprises two components, each targeting a specific challenge: (1) Auto-Annotation, which enables the automatic collection of high-quality datasets during users' routine phone usage with minimal cost. (2) FedVLM-A, which enhances federated VLM training under non-IID distributions by incorporating adapted global aggregation based on both episode-level and step-level variability. Extensive experiments prove that MobileA3gent achieves superior performance over traditional approaches at only 1% of the cost, highlighting its potential for real-world applications
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Topology-Aware Knowledge Propagation in Decentralized Learning</title>
<link>https://arxiv.org/abs/2505.11760</link>
<guid>https://arxiv.org/abs/2505.11760</guid>
<content:encoded><![CDATA[
arXiv:2505.11760v1 Announce Type: new 
Abstract: Decentralized learning enables collaborative training of models across naturally distributed data without centralized coordination or maintenance of a global model. Instead, devices are organized in arbitrary communication topologies, in which they can only communicate with neighboring devices. Each device maintains its own local model by training on its local data and integrating new knowledge via model aggregation with neighbors. Therefore, knowledge is propagated across the topology via successive aggregation rounds. We study, in particular, the propagation of out-of-distribution (OOD) knowledge. We find that popular decentralized learning algorithms struggle to propagate OOD knowledge effectively to all devices. Further, we find that both the location of OOD data within a topology, and the topology itself, significantly impact OOD knowledge propagation. We then propose topology-aware aggregation strategies to accelerate (OOD) knowledge propagation across devices. These strategies improve OOD data accuracy, compared to topology-unaware baselines, by 123% on average across models in a topology.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedHQ: Hybrid Runtime Quantization for Federated Learning</title>
<link>https://arxiv.org/abs/2505.11982</link>
<guid>https://arxiv.org/abs/2505.11982</guid>
<content:encoded><![CDATA[
arXiv:2505.11982v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized model training approach that preserves data privacy but struggles with low efficiency. Quantization, a powerful training optimization technique, has been widely explored for integration into FL. However, many studies fail to consider the distinct performance attribution between particular quantization strategies, such as post-training quantization (PTQ) or quantization-aware training (QAT). As a result, existing FL quantization methods rely solely on either PTQ or QAT, optimizing for speed or accuracy while compromising the other. To efficiently accelerate FL and maintain distributed convergence accuracy across various FL settings, this paper proposes a hybrid quantitation approach combining PTQ and QAT for FL systems. We conduct case studies to validate the effectiveness of using hybrid quantization in FL. To solve the difficulty of modeling speed and accuracy caused by device and data heterogeneity, we propose a hardware-related analysis and data-distribution-related analysis to help identify the trade-off boundaries for strategy selection. Based on these, we proposed a novel framework named FedHQ to automatically adopt optimal hybrid strategy allocation for FL systems. Specifically, FedHQ develops a coarse-grained global initialization and fine-grained ML-based adjustment to ensure efficiency and robustness. Experiments show that FedHQ achieves up to 2.47x times training acceleration and up to 11.15% accuracy improvement and negligible extra overhead.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof-of-Social-Capital: Privacy-Preserving Consensus Protocol Replacing Stake for Social Capital</title>
<link>https://arxiv.org/abs/2505.12144</link>
<guid>https://arxiv.org/abs/2505.12144</guid>
<content:encoded><![CDATA[
arXiv:2505.12144v1 Announce Type: new 
Abstract: Consensus protocols used today in blockchains often rely on computational power or financial stakes - scarce resources. We propose a novel protocol using social capital - trust and influence from social interactions - as a non-transferable staking mechanism to ensure fairness and decentralization. The methodology integrates zero-knowledge proofs, verifiable credentials, a Whisk-like leader election, and an incentive scheme to prevent Sybil attacks and encourage engagement. The theoretical framework would enhance privacy and equity, though unresolved issues like off-chain bribery require further research. This work offers a new model aligned with modern social media behavior and lifestyle, with applications in finance, providing a practical insight for decentralized system development.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Deep Reinforcement Learning for Privacy-Preserving Robotic-Assisted Surgery</title>
<link>https://arxiv.org/abs/2505.12153</link>
<guid>https://arxiv.org/abs/2505.12153</guid>
<content:encoded><![CDATA[
arXiv:2505.12153v1 Announce Type: new 
Abstract: The integration of Reinforcement Learning (RL) into robotic-assisted surgery (RAS) holds significant promise for advancing surgical precision, adaptability, and autonomous decision-making. However, the development of robust RL models in clinical settings is hindered by key challenges, including stringent patient data privacy regulations, limited access to diverse surgical datasets, and high procedural variability. To address these limitations, this paper presents a Federated Deep Reinforcement Learning (FDRL) framework that enables decentralized training of RL models across multiple healthcare institutions without exposing sensitive patient information. A central innovation of the proposed framework is its dynamic policy adaptation mechanism, which allows surgical robots to select and tailor patient-specific policies in real-time, thereby ensuring personalized and Optimised interventions. To uphold rigorous privacy standards while facilitating collaborative learning, the FDRL framework incorporates secure aggregation, differential privacy, and homomorphic encryption techniques. Experimental results demonstrate a 60\% reduction in privacy leakage compared to conventional methods, with surgical precision maintained within a 1.5\% margin of a centralized baseline. This work establishes a foundational approach for adaptive, secure, and patient-centric AI-driven surgical robotics, offering a pathway toward clinical translation and scalable deployment across diverse healthcare environments.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Protocol as Poetry: Case Study on Pak's Protocol Arts</title>
<link>https://arxiv.org/abs/2505.12393</link>
<guid>https://arxiv.org/abs/2505.12393</guid>
<content:encoded><![CDATA[
arXiv:2505.12393v1 Announce Type: new 
Abstract: Protocol art emerges at the confluence of blockchain-based smart contracts and a century-long lineage of conceptual art, participatory art, and algorithmic generative art practices. Yet existing definitions-most notably Primavera De Filippi's "protocolism"-struggle to demarcate this nascent genre from other art forms in practice. Addressing this definition-to-practice gap, this paper offers a focused case study of pioneering protocol artworks by Pak, an early and influential pseudonymous protocol artist who treats smart contracts as medium and protocol participation as message. Tracing the evolution from early open-edition releases of The Fungible and the dynamic mechanics of Merge to the soul-bound messaging of Censored and the reflective absence of Not Found, we examine how Pak choreographs distributed agency across collectors and autonomous contracts, showing how programmable protocols become a social fabric in artistic meaning-making. Through thematic analysis of Pak's works, we identify seven core characteristics that distinguish protocol art: (1) system-centric rather than object-centric composition, (2) autonomous governance for open-ended control, (3) distributed agency and communal authorship, (4) temporal dynamism and lifecycle aesthetics, (5) economic-driven engagement, (6) poetic message embedding in interaction rituals, and (7) interoperability enabling composability for emergence. We then discuss how these features set protocol art apart from adjacent artistic movements. By developing a theoretical framework grounded in Pak's practice, we contribute to the emerging literature on protocolism while offering design implications for artists shaping this evolving art form.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>hChain: Blockchain Based Large Scale EHR Data Sharing with Enhanced Security and Privacy</title>
<link>https://arxiv.org/abs/2505.12610</link>
<guid>https://arxiv.org/abs/2505.12610</guid>
<content:encoded><![CDATA[
arXiv:2505.12610v1 Announce Type: new 
Abstract: Concerns regarding privacy and data security in conventional healthcare prompted alternative technologies. In smart healthcare, blockchain technology addresses existing concerns with security, privacy, and electronic healthcare transmission. Integration of Blockchain Technology with the Internet of Medical Things (IoMT) allows real-time monitoring of protected healthcare data. Utilizing edge devices with IoMT devices is very advantageous for addressing security, computing, and storage challenges. Encryption using symmetric and asymmetric keys is used to conceal sensitive information from unauthorized parties. SHA256 is an algorithm for one-way hashing. It is used to verify that the data has not been altered, since if it had, the hash value would have changed. This article offers a blockchain-based smart healthcare system using IoMT devices for continuous patient monitoring. In addition, it employs edge resources in addition to IoMT devices to have extra computing power and storage to hash and encrypt incoming data before sending it to the blockchain. Symmetric key is utilized to keep the data private even in the blockchain, allowing the patient to safely communicate the data through smart contracts while preventing unauthorized physicians from seeing the data. Through the use of a verification node and blockchain, an asymmetric key is used for the signing and validation of patient data in the healthcare provider system. In addition to other security measures, location-based authentication is recommended to guarantee that data originates from the patient area. Through the edge device, SHA256 is utilized to secure the data's integrity and a secret key is used to maintain its secrecy. The hChain architecture improves the computing power of IoMT environments, the security of EHR sharing through smart contracts, and the privacy and authentication procedures.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement</title>
<link>https://arxiv.org/abs/2505.12684</link>
<guid>https://arxiv.org/abs/2505.12684</guid>
<content:encoded><![CDATA[
arXiv:2505.12684v1 Announce Type: new 
Abstract: Recent advances in graph machine learning have shifted to data-centric paradigms, driven by two emerging fields: (1) Federated graph learning (FGL) enables multi-client collaboration but faces challenges from data and task heterogeneity, limiting its practicality; (2) Graph foundation models (GFM) offer strong domain generalization but are usually trained on single machines, missing out on cross-silo data and resources.
  These paradigms are complementary, and their integration brings notable benefits. Motivated by this, we propose FedGFM, a novel decentralized GFM training paradigm. However, a key challenge is knowledge entanglement, where multi-domain knowledge merges into indistinguishable representations, hindering downstream adaptation.
  To address this, we present FedGFM+, an enhanced framework with two core modules to reduce knowledge entanglement: (1) AncDAI: A global anchor-based domain-aware initialization strategy. Before pre-training, each client encodes its local graph into domain-specific prototypes that serve as semantic anchors. Synthetic embeddings around these anchors initialize the global model. We theoretically prove these prototypes are distinguishable across domains, providing a strong inductive bias to disentangle domain-specific knowledge. (2) AdaDPP: A local adaptive domain-sensitive prompt pool. Each client learns a lightweight graph prompt capturing domain semantics during pre-training. During fine-tuning, prompts from all clients form a pool from which the GFM selects relevant prompts to augment target graph attributes, improving downstream adaptation.
  FedGFM+ is evaluated on 8 diverse benchmarks across multiple domains and tasks, outperforming 20 baselines from supervised learning, FGL, and federated GFM variants.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unlearning for Federated Online Learning to Rank: A Reproducibility Study</title>
<link>https://arxiv.org/abs/2505.12791</link>
<guid>https://arxiv.org/abs/2505.12791</guid>
<content:encoded><![CDATA[
arXiv:2505.12791v1 Announce Type: new 
Abstract: This paper reports on findings from a comparative study on the effectiveness and efficiency of federated unlearning strategies within Federated Online Learning to Rank (FOLTR), with specific attention to systematically analysing the unlearning capabilities of methods in a verifiable manner.
  Federated approaches to ranking of search results have recently garnered attention to address users privacy concerns. In FOLTR, privacy is safeguarded by collaboratively training ranking models across decentralized data sources, preserving individual user data while optimizing search results based on implicit feedback, such as clicks.
  Recent legislation introduced across numerous countries is establishing the so called "the right to be forgotten", according to which services based on machine learning models like those in FOLTR should provide capabilities that allow users to remove their own data from those used to train models. This has sparked the development of unlearning methods, along with evaluation practices to measure whether unlearning of a user data successfully occurred. Current evaluation practices are however often controversial, necessitating the use of multiple metrics for a more comprehensive assessment -- but previous proposals of unlearning methods only used single evaluation metrics.
  This paper addresses this limitation: our study rigorously assesses the effectiveness of unlearning strategies in managing both under-unlearning and over-unlearning scenarios using adapted, and newly proposed evaluation metrics. Thanks to our detailed analysis, we uncover the strengths and limitations of five unlearning strategies, offering valuable insights into optimizing federated unlearning to balance data privacy and system performance within FOLTR. We publicly release our code and complete results at https://github.com/Iris1026/Unlearning-for-FOLTR.git.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>6G-Enabled Smart Railways</title>
<link>https://arxiv.org/abs/2505.12946</link>
<guid>https://arxiv.org/abs/2505.12946</guid>
<content:encoded><![CDATA[
arXiv:2505.12946v1 Announce Type: new 
Abstract: Smart railways integrate advanced information technologies into railway operating systems to improve efficiency and reliability. Although the development of 5G has enhanced railway services, future smart railways require ultra-high speeds, ultra-low latency, ultra-high security, full coverage, and ultra-high positioning accuracy, which 5G cannot fully meet. Therefore, 6G is envisioned to provide green and efficient all-day operations, strong information security, fully automatic driving, and low-cost intelligent maintenance. To achieve these requirements, we propose an integrated network architecture leveraging communications, computing, edge intelligence, and caching in railway systems. We have conducted in-depth investigations on key enabling technologies for reliable transmissions and wireless coverage. For high-speed mobile scenarios, we propose an AI-enabled cross-domain channel modeling and orthogonal time-frequency space-time spread multiple access mechanism to alleviate the conflict between limited spectrum availability and massive user access. The roles of blockchain, edge intelligence, and privacy technologies in endogenously secure rail communications are also evaluated. We further explore the application of emerging paradigms such as integrated sensing and communications, AI-assisted Internet of Things, semantic communications, and digital twin networks for railway maintenance, monitoring, prediction, and accident warning. Finally, possible future research and development directions are discussed.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OmniFC: Rethinking Federated Clustering via Lossless and Secure Distance Reconstruction</title>
<link>https://arxiv.org/abs/2505.13071</link>
<guid>https://arxiv.org/abs/2505.13071</guid>
<content:encoded><![CDATA[
arXiv:2505.13071v1 Announce Type: new 
Abstract: Federated clustering (FC) aims to discover global cluster structures across decentralized clients without sharing raw data, making privacy preservation a fundamental requirement. There are two critical challenges: (1) privacy leakage during collaboration, and (2) robustness degradation due to aggregation of proxy information from non-independent and identically distributed (Non-IID) local data, leading to inaccurate or inconsistent global clustering. Existing solutions typically rely on model-specific local proxies, which are sensitive to data heterogeneity and inherit inductive biases from their centralized counterparts, thus limiting robustness and generality. We propose Omni Federated Clustering (OmniFC), a unified and model-agnostic framework. Leveraging Lagrange coded computing, our method enables clients to share only encoded data, allowing exact reconstruction of the global distance matrix--a fundamental representation of sample relationships--without leaking private information, even under client collusion. This construction is naturally resilient to Non-IID data distributions. This approach decouples FC from model-specific proxies, providing a unified extension mechanism applicable to diverse centralized clustering methods. Theoretical analysis confirms both reconstruction fidelity and privacy guarantees, while comprehensive experiments demonstrate OmniFC's superior robustness, effectiveness, and generality across various benchmarks compared to state-of-the-art methods. Code will be released.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RIFLES: Resource-effIcient Federated LEarning via Scheduling</title>
<link>https://arxiv.org/abs/2505.13169</link>
<guid>https://arxiv.org/abs/2505.13169</guid>
<content:encoded><![CDATA[
arXiv:2505.13169v1 Announce Type: new 
Abstract: Federated Learning (FL) is a privacy-preserving machine learning technique that allows decentralized collaborative model training across a set of distributed clients, by avoiding raw data exchange. A fundamental component of FL is the selection of a subset of clients in each round for model training by a central server. Current selection strategies are myopic in nature in that they are based on past or current interactions, often leading to inefficiency issues such as straggling clients. In this paper, we address this serious shortcoming by proposing the RIFLES approach that builds a novel availability forecasting layer to support the client selection process. We make the following contributions: (i) we formalise the sequential selection problem and reduce it to a scheduling problem and show that the problem is NP-complete, (ii) leveraging heartbeat messages from clients, RIFLES build an availability prediction layer to support (long term) selection decisions, (iii) we propose a novel adaptive selection strategy to support efficient learning and resource usage. To circumvent the inherent exponential complexity, we present RIFLES, a heuristic that leverages clients' historical availability data by using a CNN-LSTM time series forecasting model, allowing the server to predict the optimal participation times of clients, thereby enabling informed selection decisions. By comparing against other FL techniques, we show that RIFLES provide significant improvement by between 10%-50% on a variety of metrics such as accuracy and test loss. To the best of our knowledge, it is the first work to investigate FL as a scheduling problem.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Voting-Based Task Assignment in Modular Construction Scenarios</title>
<link>https://arxiv.org/abs/2505.13278</link>
<guid>https://arxiv.org/abs/2505.13278</guid>
<content:encoded><![CDATA[
arXiv:2505.13278v1 Announce Type: new 
Abstract: Modular construction, involving off-site prefabrication and on-site assembly, offers significant advantages but presents complex coordination challenges for robotic automation. Effective task allocation is critical for leveraging multi-agent systems (MAS) in these structured environments. This paper introduces the Hybrid Voting-Based Task Assignment (HVBTA) framework, a novel approach to optimizing collaboration between heterogeneous multi-agent construction teams. Inspired by human reasoning in task delegation, HVBTA uniquely integrates multiple voting mechanisms with the capabilities of a Large Language Model (LLM) for nuanced suitability assessment between agent capabilities and task requirements. The framework operates by assigning Capability Profiles to agents and detailed requirement lists called Task Descriptions to construction tasks, subsequently generating a quantitative Suitability Matrix. Six distinct voting methods, augmented by a pre-trained LLM, analyze this matrix to robustly identify the optimal agent for each task. Conflict-Based Search (CBS) is integrated for decentralized, collision-free path planning, ensuring efficient and safe spatio-temporal coordination of the robotic team during assembly operations. HVBTA enables efficient, conflict-free assignment and coordination, facilitating potentially faster and more accurate modular assembly. Current work is evaluating HVBTA's performance across various simulated construction scenarios involving diverse robotic platforms and task complexities. While designed as a generalizable framework for any domain with clearly definable tasks and capabilities, HVBTA will be particularly effective for addressing the demanding coordination requirements of multi-agent collaborative robotics in modular construction due to the predetermined construction planning involved.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-Cloud Data Privacy Protection: Optimizing Collaborative Mechanisms of AI Systems by Integrating Federated Learning and LLMs</title>
<link>https://arxiv.org/abs/2505.13292</link>
<guid>https://arxiv.org/abs/2505.13292</guid>
<content:encoded><![CDATA[
arXiv:2505.13292v1 Announce Type: new 
Abstract: In the age of cloud computing, data privacy protection has become a major challenge, especially when sharing sensitive data across cloud environments. However, how to optimize collaboration across cloud environments remains an unresolved problem. In this paper, we combine federated learning with large-scale language models to optimize the collaborative mechanism of AI systems. Based on the existing federated learning framework, we introduce a cross-cloud architecture in which federated learning works by aggregating model updates from decentralized nodes without exposing the original data. At the same time, combined with large-scale language models, its powerful context and semantic understanding capabilities are used to improve model training efficiency and decision-making ability. We've further innovated by introducing a secure communication layer to ensure the privacy and integrity of model updates and training data. The model enables continuous model adaptation and fine-tuning across different cloud environments while protecting sensitive data. Experimental results show that the proposed method is significantly better than the traditional federated learning model in terms of accuracy, convergence speed and data privacy protection.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Driven Elastic Task Multi-Connectivity Immersive Computing Systems</title>
<link>https://arxiv.org/abs/2505.13331</link>
<guid>https://arxiv.org/abs/2505.13331</guid>
<content:encoded><![CDATA[
arXiv:2505.13331v1 Announce Type: new 
Abstract: In virtual reality (VR) environments, computational tasks exhibit an elastic nature, meaning they can dynamically adjust based on various user and system constraints. This elasticity is essential for maintaining immersive experiences; however, it also introduces challenges for communication and computing in VR systems. In this paper, we investigate elastic task offloading for multi-user edge-computing-enabled VR systems with multi-connectivity, aiming to maximize the computational energy-efficiency (computational throughput per unit of energy consumed). To balance the induced communication, computation, energy consumption, and quality of experience trade-offs due to the elasticity of VR tasks, we formulate a constrained stochastic computational energy-efficiency optimization problem that integrates the multi-connectivity/multi-user action space and the elastic nature of VR computational tasks. We formulate a centralized phasic policy gradient (CPPG) framework to solve the problem of interest online, using only prior elastic task offloading statistics (energy consumption, response time, and transmission time), and task information (i.e., task size and computational intensity), while observing the induced system performance (energy consumption and latency). We further extend our approach to decentralized learning by formulating an independent phasic policy gradient (IPPG) method and a decentralized shared multi-armed bandit (DSMAB) method. We train our methods with real-world 4G, 5G, and WiGig network traces and 360 video datasets to evaluate their performance in terms of response time, energy efficiency, scalability, and delivered quality of experience. We also provide a comprehensive analysis of task size and its effect on offloading policy and system performance. In particular, we show that CPPG reduces latency by 28% and energy consumption by 78% compared to IPPG.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots</title>
<link>https://arxiv.org/abs/2505.13376</link>
<guid>https://arxiv.org/abs/2505.13376</guid>
<content:encoded><![CDATA[
arXiv:2505.13376v1 Announce Type: new 
Abstract: Increased robot deployment, such as in warehousing, has revealed a need for seamless collaboration among heterogeneous robot teams to resolve unforeseen conflicts. To address this challenge, we propose a novel, decentralized framework for robots to request and provide help. The framework begins with robots detecting conflicts using a Vision Language Model (VLM), then reasoning over whether help is needed. If so, it crafts and broadcasts a natural language (NL) help request using a Large Language Model (LLM). Potential helper robots reason over the request and offer help (if able), along with information about impact to their current tasks. Helper reasoning is implemented via an LLM grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar to guarantee syntactically valid NL-to-STL translations, which are then solved as a Mixed Integer Linear Program (MILP). Finally, the requester robot chooses a helper by reasoning over impact on the overall system. We evaluate our system via experiments considering different strategies for choosing a helper, and find that a requester robot can minimize overall time impact on the system by considering multiple help offers versus simple heuristics (e.g., selecting the nearest robot to help).
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Traffic Flow Optimization Through Intrinsic Motivation</title>
<link>https://arxiv.org/abs/2505.11520</link>
<guid>https://arxiv.org/abs/2505.11520</guid>
<content:encoded><![CDATA[
arXiv:2505.11520v1 Announce Type: cross 
Abstract: Traffic congestion has long been an ubiquitous problem that is exacerbating with the rapid growth of megacities. In this proof-of-concept work we study intrinsic motivation, implemented via the empowerment principle, to control autonomous car behavior to improve traffic flow. In standard models of traffic dynamics, self-organized traffic jams emerge spontaneously from the individual behavior of cars, affecting traffic over long distances. Our novel car behavior strategy improves traffic flow while still being decentralized and using only locally available information without explicit coordination. Decentralization is essential for various reasons, not least to be able to absorb robustly substantial levels of uncertainty. Our scenario is based on the well-established traffic dynamics model, the Nagel-Schreckenberg cellular automaton. In a fraction of the cars in this model, we substitute the default behavior by empowerment, our intrinsic motivation-based method. This proposed model significantly improves overall traffic flow, mitigates congestion, and reduces the average traffic jam time.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAOs of Collective Intelligence? Unraveling the Complexity of Blockchain Governance in Decentralized Autonomous Organizations</title>
<link>https://arxiv.org/abs/2409.01823</link>
<guid>https://arxiv.org/abs/2409.01823</guid>
<content:encoded><![CDATA[
arXiv:2409.01823v2 Announce Type: replace 
Abstract: Decentralized autonomous organizations (DAOs) have transformed organizational structures by shifting from traditional hierarchical control to decentralized approaches, leveraging blockchain and cryptoeconomics. Despite managing significant funds and building global networks, DAOs face challenges like declining participation, increasing centralization, and inabilities to adapt to changing environments, which stifle innovation. This paper explores DAOs as complex systems and applies complexity science to explain their inefficiencies. In particular, we discuss DAO challenges, their complex nature, and introduce the self-organization mechanisms of collective intelligence, digital democracy, and adaptation. By applying these mechanisms to refine DAO design and construction, a conceptual framework for assessing a DAO's viability is created. This contribution lays the foundation for future research at the intersection of complexity science, digital democracy and DAOs.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing Federated Learning against Backdoor Threats with Foundation Model Integration</title>
<link>https://arxiv.org/abs/2410.17573</link>
<guid>https://arxiv.org/abs/2410.17573</guid>
<content:encoded><![CDATA[
arXiv:2410.17573v2 Announce Type: replace 
Abstract: Federated Learning (FL) enables decentralized model training while preserving privacy. Recently, the integration of Foundation Models (FMs) into FL has enhanced performance but introduced a novel backdoor attack mechanism. Attackers can exploit FM vulnerabilities to embed backdoors into synthetic data generated by FMs. During global model fusion, these backdoors are transferred to the global model through compromised synthetic data, subsequently infecting all client models. Existing FL backdoor defenses are ineffective against this novel attack due to its fundamentally different mechanism compared to classic ones. In this work, we propose a novel data-free defense strategy that addresses both classic and novel backdoor attacks in FL. The shared attack pattern lies in the abnormal activations within the hidden feature space during model aggregation. Hence, we propose to constrain internal activations to remain within reasonable ranges, effectively mitigating attacks while preserving model functionality. The activation constraints are optimized using synthetic data alongside FL training. Extensive experiments demonstrate its effectiveness against both novel and classic backdoor attacks, outperforming existing defenses.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mesh Stability Guaranteed Rigid Body Networks Using Control and Topology Co-Design</title>
<link>https://arxiv.org/abs/2505.10723</link>
<guid>https://arxiv.org/abs/2505.10723</guid>
<content:encoded><![CDATA[
arXiv:2505.10723v1 Announce Type: new 
Abstract: Merging and splitting are of great significance for rigid body networks in making such networks reconfigurable. The main challenges lie in simultaneously ensuring the compositionality of the distributed controllers and the mesh stability of the entire network. To this end, we propose a decentralized control and topology co-design method for rigid body networks, which enables flexible joining and leaving of rigid bodies without the need to redesign the controllers for the entire network after such maneuvers. We first provide a centralized linear matrix inequality (LMI)-based control and topology co-design optimization of the rigid body networks with a formal mesh stability guarantee. Then, these centralized mesh stability constraints are made decentralized by a proposed alternative set of sufficient conditions. Using these decentralized mesh stability constraints and Sylvester's criterion-based decentralization techniques, the said centralized LMI problem is equivalently broken down into a set of smaller decentralized LMI problems that can be solved at each rigid body, enabling flexible merging/splitting of rigid bodies. Finally, the effectiveness of the proposed co-design method is illustrated based on a specifically developed simulator and a comparison study with respect to a state-of-the-art method.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nosy Layers, Noisy Fixes: Tackling DRAs in Federated Learning Systems using Explainable AI</title>
<link>https://arxiv.org/abs/2505.10942</link>
<guid>https://arxiv.org/abs/2505.10942</guid>
<content:encoded><![CDATA[
arXiv:2505.10942v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for collaborative model training while keeping client data decentralized and private. However, it is vulnerable to Data Reconstruction Attacks (DRA) such as "LoKI" and "Robbing the Fed", where malicious models sent from the server to the client can reconstruct sensitive user data. To counter this, we introduce DRArmor, a novel defense mechanism that integrates Explainable AI with targeted detection and mitigation strategies for DRA. Unlike existing defenses that focus on the entire model, DRArmor identifies and addresses the root cause (i.e., malicious layers within the model that send gradients with malicious intent) by analyzing their contribution to the output and detecting inconsistencies in gradient values. Once these malicious layers are identified, DRArmor applies defense techniques such as noise injection, pixelation, and pruning to these layers rather than the whole model, minimizing the attack surface and preserving client data privacy. We evaluate DRArmor's performance against the advanced LoKI attack across diverse datasets, including MNIST, CIFAR-10, CIFAR-100, and ImageNet, in a 200-client FL setup. Our results demonstrate DRArmor's effectiveness in mitigating data leakage, achieving high True Positive and True Negative Rates of 0.910 and 0.890, respectively. Additionally, DRArmor maintains an average accuracy of 87%, effectively protecting client privacy without compromising model performance. Compared to existing defense mechanisms, DRArmor reduces the data leakage rate by 62.5% with datasets containing 500 samples per client.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Decentralized Privacy-Preserving Group Purchasing for Energy Plans</title>
<link>https://arxiv.org/abs/2505.11094</link>
<guid>https://arxiv.org/abs/2505.11094</guid>
<content:encoded><![CDATA[
arXiv:2505.11094v1 Announce Type: new 
Abstract: Retail energy markets are increasingly consumer-oriented, thanks to a growing number of energy plans offered by a plethora of energy suppliers, retailers and intermediaries. To maximize the benefits of competitive retail energy markets, group purchasing is an emerging paradigm that aggregates consumers' purchasing power by coordinating switch decisions to specific energy providers for discounted energy plans. Traditionally, group purchasing is mediated by a trusted third-party, which suffers from the lack of privacy and transparency. In this paper, we introduce a novel paradigm of decentralized privacy-preserving group purchasing, empowered by privacy-preserving blockchain and secure multi-party computation, to enable users to form a coalition for coordinated switch decisions in a decentralized manner, without a trusted third-party. The coordinated switch decisions are determined by a competitive online algorithm, based on users' private consumption data and current energy plan tariffs. Remarkably, no private user consumption data will be revealed to others in the online decision-making process, which is carried out in a transparently verifiable manner to eliminate frauds from dishonest users and supports fair mutual compensations by sharing the switching costs to incentivize group purchasing. We implemented our decentralized group purchasing solution as a smart contract on Solidity-supported blockchain platform (e.g., Ethereum), and provide extensive empirical evaluation.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding and Characterizing Obfuscated Funds Transfers in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2505.11320</link>
<guid>https://arxiv.org/abs/2505.11320</guid>
<content:encoded><![CDATA[
arXiv:2505.11320v1 Announce Type: new 
Abstract: Scam contracts on Ethereum have rapidly evolved alongside the rise of DeFi and NFT ecosystems, utilizing increasingly complex code obfuscation techniques to avoid early detection. This paper systematically investigates how obfuscation amplifies the financial risks of fraudulent contracts and undermines existing auditing tools. We propose a transfer-centric obfuscation taxonomy, distilling seven key features, and introduce ObfProbe, a framework that performs bytecode-level smart contract analysis to uncover obfuscation techniques and quantify obfuscation complexity via Z-score ranking. In a large-scale study of 1.03 million Ethereum contracts, we isolate over 3 000 highly obfuscated contracts and identify two scam archetypes, three high-risk contract categories, and MEV bots that employ a variety of obfuscation maneuvers such as inline assembly, dead code insertion, and deep function splitting. We further show that obfuscation substantially increases both the scale of financial damage and the time until detection. Finally, we evaluate SourceP, a state-of-the-art Ponzi detection tool, on obfuscated versus non-obfuscated samples and observe its accuracy drop from approximately 80 percent to approximately 12 percent in real-world scenarios. These findings highlight the urgent need for enhanced anti-obfuscation analysis techniques and broader community collaboration to stem the proliferation of scam contracts in the expanding DeFi ecosystem.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Signal attenuation enables scalable decentralized multi-agent reinforcement learning over networks</title>
<link>https://arxiv.org/abs/2505.11461</link>
<guid>https://arxiv.org/abs/2505.11461</guid>
<content:encoded><![CDATA[
arXiv:2505.11461v1 Announce Type: new 
Abstract: Classic multi-agent reinforcement learning (MARL) methods require that agents enjoy global state observability, preventing development of decentralized algorithms and limiting scalability. Recent work has shown that, under assumptions on decaying inter-agent influence, global observability can be replaced by local neighborhood observability at each agent, enabling decentralization and scalability. Real-world applications enjoying such decay properties remain underexplored, however, despite the fact that signal power decay, or signal attenuation, due to path loss is an intrinsic feature of many problems in wireless communications and radar networks. In this paper, we show that signal attenuation enables decentralization in MARL by considering the illustrative special case of performing power allocation for target detection in a radar network. To achieve this, we propose two new constrained multi-agent Markov decision process formulations of this power allocation problem, derive local neighborhood approximations for global value function and gradient estimates and establish corresponding error bounds, and develop decentralized saddle point policy gradient algorithms for solving the proposed problems. Our approach, though oriented towards the specific radar network problem we consider, provides a useful model for future extensions to additional problems in wireless communications and radar networks.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification</title>
<link>https://arxiv.org/abs/2501.11493</link>
<guid>https://arxiv.org/abs/2501.11493</guid>
<content:encoded><![CDATA[
arXiv:2501.11493v2 Announce Type: replace 
Abstract: Federated learning (FL) is a decentralized machine learning paradigm in which multiple clients collaboratively train a global model by exchanging only model updates with the central server without sharing the local data of the clients. Due to the large volume of model updates required to be transmitted between clients and the central server, most FL systems are associated with high transfer costs (i.e., communication overhead). This issue is more critical for operational applications in remote sensing (RS), especially when large-scale RS data is processed and analyzed through FL systems with restricted communication bandwidth. To address this issue, we introduce an explanation-guided pruning strategy for communication-efficient FL in the context of RS image classification. Our pruning strategy is defined based on the layer-wise relevance propagation (LRP) driven explanations to: 1) efficiently and effectively identify the most relevant and informative model parameters (to be exchanged between clients and the central server); and 2) eliminate the non-informative ones to minimize the volume of model updates. The experimental results on the BigEarthNet-S2 dataset demonstrate that our strategy effectively reduces the number of shared model updates, while increasing the generalization ability of the global model. The code of this work is publicly available at https://git.tu-berlin.de/rsim/FL-LRP.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data</title>
<link>https://arxiv.org/abs/2505.09733</link>
<guid>https://arxiv.org/abs/2505.09733</guid>
<content:encoded><![CDATA[
arXiv:2505.09733v1 Announce Type: new 
Abstract: Federated learning (FL) presents an effective solution for collaborative model training while maintaining data privacy across decentralized client datasets. However, data quality issues such as noisy labels, missing classes, and imbalanced distributions significantly challenge its effectiveness. This study proposes a federated learning methodology that systematically addresses data quality issues, including noise, class imbalance, and missing labels. The proposed approach systematically enhances data integrity through adaptive noise cleaning, collaborative conditional GAN-based synthetic data generation, and robust federated model training. Experimental evaluations conducted on benchmark datasets (MNIST and Fashion-MNIST) demonstrate significant improvements in federated model performance, particularly macro-F1 Score, under varying noise and class imbalance conditions. Additionally, the proposed framework carefully balances computational feasibility and substantial performance gains, ensuring practicality for resource constrained edge devices while rigorously maintaining data privacy. Our results indicate that this method effectively mitigates common data quality challenges, providing a robust, scalable, and privacy compliant solution suitable for diverse real-world federated learning scenarios.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents</title>
<link>https://arxiv.org/abs/2505.09757</link>
<guid>https://arxiv.org/abs/2505.09757</guid>
<content:encoded><![CDATA[
arXiv:2505.09757v1 Announce Type: new 
Abstract: The recent trend of self-sovereign Decentralized AI Agents (DeAgents) combines Large Language Model (LLM)-based AI agents with decentralization technologies such as blockchain smart contracts and trusted execution environments (TEEs). These tamper-resistant trustless substrates allow agents to achieve self-sovereignty through ownership of cryptowallet private keys and control of digital assets and social media accounts. DeAgent eliminates centralized control and reduces human intervention, addressing key trust concerns inherent in centralized AI systems. However, given ongoing challenges in LLM reliability such as hallucinations, this creates paradoxical tension between trustlessness and unreliable autonomy. This study addresses this empirical research gap through interviews with DeAgents stakeholders-experts, founders, and developers-to examine their motivations, benefits, and governance dilemmas. The findings will guide future DeAgents system and protocol design and inform discussions about governance in sociotechnical AI systems in the future agentic web.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence</title>
<link>https://arxiv.org/abs/2505.09854</link>
<guid>https://arxiv.org/abs/2505.09854</guid>
<content:encoded><![CDATA[
arXiv:2505.09854v1 Announce Type: new 
Abstract: As demand for intelligent services rises and edge devices become more capable, distributed learning at the network edge has emerged as a key enabling technology. While existing paradigms like federated learning (FL) and decentralized FL (DFL) enable privacy-preserving distributed learning in many scenarios, they face potential challenges in connectivity and synchronization imposed by resource-constrained and infrastructure-less environments. While more robust, gossip learning (GL) algorithms have generally been designed for homogeneous data distributions and may not suit all contexts. This paper introduces Chisme, a novel suite of protocols designed to address the challenges of implementing robust intelligence in the network edge, characterized by heterogeneous data distributions, episodic connectivity, and lack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and asynchronous GL (Chisme-GL) variants that enable collaborative yet decentralized model training that considers underlying data heterogeneity. We introduce a data similarity heuristic that allows agents to opportunistically infer affinity with each other using the existing communication of model updates in decentralized FL and GL. We leverage the heuristic to extend DFL's model aggregation and GL's model merge mechanisms for better personalized training while maintaining collaboration. While Chisme-DFL is a synchronous decentralized approach whose resource utilization scales linearly with network size, Chisme-GL is fully asynchronous and has a lower, constant resource requirement independent of network size. We demonstrate that Chisme methods outperform their standard counterparts in model training over distributed and heterogeneous data in network scenarios ranging from less connected and reliable networks to fully connected and lossless networks.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Correlating Account on Ethereum Mixing Service via Domain-Invariant feature learning</title>
<link>https://arxiv.org/abs/2505.09892</link>
<guid>https://arxiv.org/abs/2505.09892</guid>
<content:encoded><![CDATA[
arXiv:2505.09892v1 Announce Type: new 
Abstract: The untraceability of transactions facilitated by Ethereum mixing services like Tornado Cash poses significant challenges to blockchain security and financial regulation. Existing methods for correlating mixing accounts suffer from limited labeled data and vulnerability to noisy annotations, which restrict their practical applicability. In this paper, we propose StealthLink, a novel framework that addresses these limitations through cross-task domain-invariant feature learning. Our key innovation lies in transferring knowledge from the well-studied domain of blockchain anomaly detection to the data-scarce task of mixing transaction tracing. Specifically, we design a MixFusion module that constructs and encodes mixing subgraphs to capture local transactional patterns, while introducing a knowledge transfer mechanism that aligns discriminative features across domains through adversarial discrepancy minimization. This dual approach enables robust feature learning under label scarcity and distribution shifts. Extensive experiments on real-world mixing transaction datasets demonstrate that StealthLink achieves state-of-the-art performance, with 96.98\% F1-score in 10-shot learning scenarios. Notably, our framework shows superior generalization capability in imbalanced data conditions than conventional supervised methods. This work establishes the first systematic approach for cross-domain knowledge transfer in blockchain forensics, providing a practical solution for combating privacy-enhanced financial crimes in decentralized ecosystems.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeFeed: Secure Decentralized Cross-Contract Data Feed in Web 3.0 for Connected Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2505.09928</link>
<guid>https://arxiv.org/abs/2505.09928</guid>
<content:encoded><![CDATA[
arXiv:2505.09928v1 Announce Type: new 
Abstract: Smart contracts have been a topic of interest in blockchain research and are a key enabling technology for Connected Autonomous Vehicles (CAVs) in the era of Web 3.0. These contracts enable trustless interactions without the need for intermediaries, as they operate based on predefined rules encoded on the blockchain. However, smart contacts face significant challenges in cross-contract communication and information sharing, making it difficult to establish seamless connectivity and collaboration among CAVs with Web 3.0. In this paper, we propose DeFeed, a novel secure protocol that incorporates various gas-saving functions for CAVs, originated from in-depth research into the interaction among smart contracts for decentralized cross-contract data feed in Web 3.0. DeFeed allows smart contracts to obtain information from other contracts efficiently in a single click, without complicated operations. We judiciously design and complete various functions with DeFeed, including a pool function and a cache function for gas optimization, a subscribe function for facilitating data access, and an update function for the future iteration of our protocol. Tailored for CAVs with Web 3.0 use cases, DeFeed enables efficient data feed between smart contracts underpinning decentralized applications and vehicle coordination. Implemented and tested on the Ethereum official test network, DeFeed demonstrates significant improvements in contract interaction efficiency, reducing computational complexity and gas costs. Our solution represents a critical step towards seamless, decentralized communication in Web 3.0 ecosystems.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization</title>
<link>https://arxiv.org/abs/2505.10152</link>
<guid>https://arxiv.org/abs/2505.10152</guid>
<content:encoded><![CDATA[
arXiv:2505.10152v1 Announce Type: new 
Abstract: Federated domain generalization aims to learn a generalizable model from multiple decentralized source domains for deploying on the unseen target domain. The style augmentation methods have achieved great progress on domain generalization. However, the existing style augmentation methods either explore the data styles within isolated source domain or interpolate the style information across existing source domains under the data decentralization scenario, which leads to limited style space. To address this issue, we propose a Multi-source Collaborative Style Augmentation and Domain-invariant learning method (MCSAD) for federated domain generalization. Specifically, we propose a multi-source collaborative style augmentation module to generate data in the broader style space. Furthermore, we conduct domain-invariant learning between the original data and augmented data by cross-domain feature alignment within the same class and classes relation ensemble distillation between different classes to learn a domain-invariant model. By alternatively conducting collaborative style augmentation and domain-invariant learning, the model can generalize well on unseen target domain. Extensive experiments on multiple domain generalization datasets indicate that our method significantly outperforms the state-of-the-art federated domain generalization methods.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.10296</link>
<guid>https://arxiv.org/abs/2505.10296</guid>
<content:encoded><![CDATA[
arXiv:2505.10296v1 Announce Type: new 
Abstract: The growing adoption of Electric Buses (EBs) represents a significant step toward sustainable development. By utilizing Internet of Things (IoT) systems, charging stations can autonomously determine charging schedules based on real-time data. However, optimizing EB charging schedules remains a critical challenge due to uncertainties in travel time, energy consumption, and fluctuating electricity prices. Moreover, to address real-world complexities, charging policies must make decisions efficiently across multiple time scales and remain scalable for large EB fleets. In this paper, we propose a Hierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the original Markov Decision Process (MDP) into two augmented MDPs. To solve these MDPs and enable multi-timescale decision-making, we introduce a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Enhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic (DAC) algorithm for large-scale EB fleets are addressed through enhancements at both decision levels. At the high level, we redesign the decentralized actor network and integrate an attention mechanism to extract relevant global state information for each EB, decreasing the size of neural networks. At the low level, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is incorporated into the DAC framework, enabling decentralized and coordinated charging power decisions, reducing computational complexity and enhancing convergence speed. Extensive experiments with real-world data demonstrate the superior performance and scalability of DAC-MAPPO-E in optimizing EB fleet charging schedules.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>One For All: Formally Verifying Protocols which use Aggregate Signatures (extended version)</title>
<link>https://arxiv.org/abs/2505.10316</link>
<guid>https://arxiv.org/abs/2505.10316</guid>
<content:encoded><![CDATA[
arXiv:2505.10316v1 Announce Type: new 
Abstract: Aggregate signatures are digital signatures that compress multiple signatures from different parties into a single signature, thereby reducing storage and bandwidth requirements. BLS aggregate signatures are a popular kind of aggregate signature, deployed by Ethereum, Dfinity, and Cloudflare amongst others, currently undergoing standardization at the IETF. However, BLS aggregate signatures are difficult to use correctly, with nuanced requirements that must be carefully handled by protocol developers.
  In this work, we design the first models of aggregate signatures that enable formal verification tools, such as Tamarin and ProVerif, to be applied to protocols using these signatures. We introduce general models that are based on the cryptographic security definition of generic aggregate signatures, allowing the attacker to exploit protocols where the security requirements are not satisfied. We also introduce a second family of models formalizing BLS aggregate signatures in particular. We demonstrate our approach's practical relevance by modelling and analyzing in Tamarin a device attestation protocol called SANA. Despite SANA's claimed correctness proof, with Tamarin we uncover undocumented assumptions that, when omitted, lead to attacks.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework</title>
<link>https://arxiv.org/abs/2505.10322</link>
<guid>https://arxiv.org/abs/2505.10322</guid>
<content:encoded><![CDATA[
arXiv:2505.10322v1 Announce Type: new 
Abstract: Decentralized optimization has become vital for leveraging distributed data without central control, enhancing scalability and privacy. However, practical deployments face fundamental challenges due to heterogeneous computation speeds and unpredictable communication delays. This paper introduces a refined model of Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under practical assumptions of bounded computation and communication times. To understand the convergence of ADSGD, we first analyze Asynchronous Stochastic Block Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges under computation-delay-independent step sizes. The convergence result is established without assuming bounded data heterogeneity. Empirical experiments reveal that ADSGD outperforms existing methods in wall-clock convergence time across various scenarios. With its simplicity, efficiency in memory and communication, and resilience to communication and computation delays, ADSGD is well-suited for real-world decentralized learning tasks.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>In-Materia Speech Recognition</title>
<link>https://arxiv.org/abs/2410.10434</link>
<guid>https://arxiv.org/abs/2410.10434</guid>
<content:encoded><![CDATA[
arXiv:2410.10434v2 Announce Type: replace-cross 
Abstract: With the rise of decentralized computing, as in the Internet of Things, autonomous driving, and personalized healthcare, it is increasingly important to process time-dependent signals at the edge efficiently: right at the place where the temporal data are collected, avoiding time-consuming, insecure, and costly communication with a centralized computing facility (or cloud). However, modern-day processors often cannot meet the restrained power and time budgets of edge systems because of intrinsic limitations imposed by their architecture (von Neumann bottleneck) or domain conversions (analogue-to-digital and time-to-frequency). Here, we propose an edge temporal-signal processor based on two in-materia computing systems for both feature extraction and classification, reaching a software-level accuracy of 96.2% for the TI-46-Word speech-recognition task. First, a nonlinear, room-temperature dopant-network-processing-unit (DNPU) layer realizes analogue, time-domain feature extraction from the raw audio signals, similar to the human cochlea. Second, an analogue in-memory computing (AIMC) chip, consisting of memristive crossbar arrays, implements a compact neural network trained on the extracted features for classification. With the DNPU feature extraction consuming 100s nW and AIMC-based classification having the potential for less than 10 fJ per multiply-accumulate operation, our findings offer a promising avenue for advancing the compactness, efficiency, and performance of heterogeneous smart edge processors through in-materia computing hardware.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Onboard Optimization and Learning: A Survey</title>
<link>https://arxiv.org/abs/2505.08793</link>
<guid>https://arxiv.org/abs/2505.08793</guid>
<content:encoded><![CDATA[
arXiv:2505.08793v1 Announce Type: new 
Abstract: Onboard learning is a transformative approach in edge AI, enabling real-time data processing, decision-making, and adaptive model training directly on resource-constrained devices without relying on centralized servers. This paradigm is crucial for applications demanding low latency, enhanced privacy, and energy efficiency. However, onboard learning faces challenges such as limited computational resources, high inference costs, and security vulnerabilities. This survey explores a comprehensive range of methodologies that address these challenges, focusing on techniques that optimize model efficiency, accelerate inference, and support collaborative learning across distributed devices. Approaches for reducing model complexity, improving inference speed, and ensuring privacy-preserving computation are examined alongside emerging strategies that enhance scalability and adaptability in dynamic environments. By bridging advancements in hardware-software co-design, model compression, and decentralized learning, this survey provides insights into the current state of onboard learning to enable robust, efficient, and secure AI deployment at the edge.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network</title>
<link>https://arxiv.org/abs/2505.09106</link>
<guid>https://arxiv.org/abs/2505.09106</guid>
<content:encoded><![CDATA[
arXiv:2505.09106v1 Announce Type: new 
Abstract: The space-air-ground integrated network (SAGIN) has recently emerged as a core element in the 6G networks. However, traditional centralized and synchronous optimization algorithms are unsuitable for SAGIN due to infrastructureless and time-varying environments. This paper aims to develop a novel Asynchronous algorithm a.k.a. Argus for tackling non-convex and non-smooth decentralized federated bilevel learning over SAGIN. The proposed algorithm allows networked agents (e.g. autonomous aerial vehicles) to tackle bilevel learning problems in time-varying networks asynchronously, thereby averting stragglers from impeding the overall training speed. We provide a theoretical analysis of the iteration complexity, communication complexity, and computational complexity of Argus. Its effectiveness is further demonstrated through numerical experiments.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Malicious Clients Detection in Federated Learning</title>
<link>https://arxiv.org/abs/2505.09110</link>
<guid>https://arxiv.org/abs/2505.09110</guid>
<content:encoded><![CDATA[
arXiv:2505.09110v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train a global machine learning model without sharing their raw data. However, the decentralized nature of FL introduces vulnerabilities, particularly to poisoning attacks, where malicious clients manipulate their local models to disrupt the training process. While Byzantine-robust aggregation rules have been developed to mitigate such attacks, they remain inadequate against more advanced threats. In response, recent advancements have focused on FL detection techniques to identify potentially malicious participants. Unfortunately, these methods often misclassify numerous benign clients as threats or rely on unrealistic assumptions about the server's capabilities. In this paper, we propose a novel algorithm, SafeFL, specifically designed to accurately identify malicious clients in FL. The SafeFL approach involves the server collecting a series of global models to generate a synthetic dataset, which is then used to distinguish between malicious and benign models based on their behavior. Extensive testing demonstrates that SafeFL outperforms existing methods, offering superior efficiency and accuracy in detecting malicious clients.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Latent Theory of Mind: A Decentralized Diffusion Architecture for Cooperative Manipulation</title>
<link>https://arxiv.org/abs/2505.09144</link>
<guid>https://arxiv.org/abs/2505.09144</guid>
<content:encoded><![CDATA[
arXiv:2505.09144v1 Announce Type: new 
Abstract: We present Latent Theory of Mind (LatentToM), a decentralized diffusion policy architecture for collaborative robot manipulation. Our policy allows multiple manipulators with their own perception and computation to collaborate with each other towards a common task goal with or without explicit communication. Our key innovation lies in allowing each agent to maintain two latent representations: an ego embedding specific to the robot, and a consensus embedding trained to be common to both robots, despite their different sensor streams and poses. We further let each robot train a decoder to infer the other robot's ego embedding from their consensus embedding, akin to theory of mind in latent space. Training occurs centrally, with all the policies' consensus encoders supervised by a loss inspired by sheaf theory, a mathematical theory for clustering data on a topological manifold. Specifically, we introduce a first-order cohomology loss to enforce sheaf-consistent alignment of the consensus embeddings. To preserve the expressiveness of the consensus embedding, we further propose structural constraints based on theory of mind and a directional consensus mechanism. Execution can be fully distributed, requiring no explicit communication between policies. In which case, the information is exchanged implicitly through each robot's sensor stream by observing the actions of the other robots and their effects on the scene. Alternatively, execution can leverage direct communication to share the robots' consensus embeddings, where the embeddings are shared once during each inference step and are aligned using the sheaf Laplacian. In our hardware experiments, LatentToM outperforms a naive decentralized diffusion baseline, and shows comparable performance with a state-of-the-art centralized diffusion policy for bi-manual manipulation. Project website: https://stanfordmsl.github.io/LatentToM/.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach</title>
<link>https://arxiv.org/abs/2505.09313</link>
<guid>https://arxiv.org/abs/2505.09313</guid>
<content:encoded><![CDATA[
arXiv:2505.09313v1 Announce Type: new 
Abstract: Sybil attacks pose a significant security threat to blockchain ecosystems, particularly in token airdrop events. This paper proposes a novel sybil address identification method based on subgraph feature extraction lightGBM. The method first constructs a two-layer deep transaction subgraph for each address, then extracts key event operation features according to the lifecycle of sybil addresses, including the time of first transaction, first gas acquisition, participation in airdrop activities, and last transaction. These temporal features effectively capture the consistency of sybil address behavior operations. Additionally, the method extracts amount and network structure features, comprehensively describing address behavior patterns and network topology through feature propagation and fusion. Experiments conducted on a dataset containing 193,701 addresses (including 23,240 sybil addresses) show that this method outperforms existing approaches in terms of precision, recall, F1 score, and AUC, with all metrics exceeding 0.9. The methods and results of this study can be further applied to broader blockchain security areas such as transaction manipulation identification and token liquidity risk assessment, contributing to the construction of a more secure and fair blockchain ecosystem.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.04867</link>
<guid>https://arxiv.org/abs/2411.04867</guid>
<content:encoded><![CDATA[
arXiv:2411.04867v2 Announce Type: replace 
Abstract: Safe reinforcement learning (RL) is crucial for real-world applications, and multi-agent interactions introduce additional safety challenges. While Probabilistic Logic Shields (PLS) has been a powerful proposal to enforce safety in single-agent RL, their generalizability to multi-agent settings remains unexplored. In this paper, we address this gap by conducting extensive analyses of PLS within decentralized, multi-agent environments, and in doing so, propose Shielded Multi-Agent Reinforcement Learning (SMARL) as a general framework for steering MARL towards norm-compliant outcomes. Our key contributions are: (1) a novel Probabilistic Logic Temporal Difference (PLTD) update for shielded, independent Q-learning, which incorporates probabilistic constraints directly into the value update process; (2) a probabilistic logic policy gradient method for shielded PPO with formal safety guarantees for MARL; and (3) comprehensive evaluation across symmetric and asymmetrically shielded $n$-player game-theoretic benchmarks, demonstrating fewer constraint violations and significantly better cooperation under normative constraints. These results position SMARL as an effective mechanism for equilibrium selection, paving the way toward safer, socially aligned multi-agent systems.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MACH: Multi-Agent Coordination for RSU-centric Handovers</title>
<link>https://arxiv.org/abs/2505.07827</link>
<guid>https://arxiv.org/abs/2505.07827</guid>
<content:encoded><![CDATA[
arXiv:2505.07827v1 Announce Type: new 
Abstract: This paper introduces MACH, a novel approach for optimizing task handover in vehicular computing scenarios. To ensure fast and latency-aware placement of tasks, the decision-making -- where and when should tasks be offloaded -- is carried out decentralized at the Road Side Units (RSUs) who also execute the tasks. By shifting control to the network edge, MACH moves away from the traditional centralized or vehicle-based handover method. Still, it focuses on contextual factors, such as the current RSU load and vehicle trajectories. Thus, MACH improves the overall Quality of Service (QoS) while fairly balancing computational loads between RSUs. To evaluate the effectiveness of our approach, we develop a robust simulation environment composed of real-world traffic data, dynamic network conditions, and different infrastructure capacities. For scenarios that demand low latency and high reliability, our experimental results demonstrate how MACH significantly improves the adaptability and efficiency of vehicular computations. By decentralizing control to the network edge, MACH effectively reduces communication overhead and optimizes resource utilization, offering a robust framework for task handover management.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Based Crypto Tokens: The Illusion of Decentralized AI?</title>
<link>https://arxiv.org/abs/2505.07828</link>
<guid>https://arxiv.org/abs/2505.07828</guid>
<content:encoded><![CDATA[
arXiv:2505.07828v1 Announce Type: new 
Abstract: The convergence of blockchain and artificial intelligence (AI) has led to the emergence of AI-based tokens, which are cryptographic assets designed to power decentralized AI platforms and services. This paper provides a comprehensive review of leading AI-token projects, examining their technical architectures, token utilities, consensus mechanisms, and underlying business models. We explore how these tokens operate across various blockchain ecosystems and assess the extent to which they offer value beyond traditional centralized AI services. Based on this assessment, our analysis identifies several core limitations. From a technical perspective, many platforms depend extensively on off-chain computation, exhibit limited capabilities for on-chain intelligence, and encounter significant scalability challenges. From a business perspective, many models appear to replicate centralized AI service structures, simply adding token-based payment and governance layers without delivering truly novel value. In light of these challenges, we also examine emerging developments that may shape the next phase of decentralized AI systems. These include approaches for on-chain verification of AI outputs, blockchain-enabled federated learning, and more robust incentive frameworks. Collectively, while emerging innovations offer pathways to strengthen decentralized AI ecosystems, significant gaps remain between the promises and the realities of current AI-token implementations. Our findings contribute to a growing body of research at the intersection of AI and blockchain, highlighting the need for critical evaluation and more grounded approaches as the field continues to evolve.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent Product 3.0: Decentralised AI Agents and Web3 Intelligence Standards</title>
<link>https://arxiv.org/abs/2505.07835</link>
<guid>https://arxiv.org/abs/2505.07835</guid>
<content:encoded><![CDATA[
arXiv:2505.07835v1 Announce Type: new 
Abstract: Twenty-five years ago, the specification of the Intelligent Product was established, envisaging real-time connectivity that not only enables products to gather accurate data about themselves but also allows them to assess and influence their own destiny. Early work by the Auto-ID project focused on creating a single, open-standard repository for storing and retrieving product information, laying a foundation for scalable connectivity. A decade later, the approach was revisited in light of low-cost RFID systems that promised a low-cost link between physical goods and networked information environments. Since then, advances in blockchain, Web3, and artificial intelligence have introduced unprecedented levels of resilience, consensus, and autonomy. By leveraging decentralised identity, blockchain-based product information and history, and intelligent AI-to-AI collaboration, this paper examines these developments and outlines a new specification for the Intelligent Product 3.0, illustrating how decentralised and AI-driven capabilities facilitate seamless interaction between physical AI and everyday products.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ML-Enabled Eavesdropper Detection in Beyond 5G IIoT Networks</title>
<link>https://arxiv.org/abs/2505.07837</link>
<guid>https://arxiv.org/abs/2505.07837</guid>
<content:encoded><![CDATA[
arXiv:2505.07837v1 Announce Type: new 
Abstract: Advanced fifth generation (5G) and beyond (B5G) communication networks have revolutionized wireless technologies, supporting ultra-high data rates, low latency, and massive connectivity. However, they also introduce vulnerabilities, particularly in decentralized Industrial Internet of Things (IIoT) environments. Traditional cryptographic methods struggle with scalability and complexity, leading researchers to explore Artificial Intelligence (AI)-driven physical layer techniques for secure communications. In this context, this paper focuses on the utilization of Machine and Deep Learning (ML/DL) techniques to tackle with the common problem of eavesdropping detection. To this end, a simulated industrial B5G heterogeneous wireless network is used to evaluate the performance of various ML/DL models, including Random Forests (RF), Deep Convolutional Neural Networks (DCNN), and Long Short-Term Memory (LSTM) networks. These models classify users as either legitimate or malicious ones based on channel state information (CSI), position data, and transmission power. According to the presented numerical results, DCNN and RF models achieve a detection accuracy approaching 100\% in identifying eavesdroppers with zero false alarms. In general, this work underlines the great potential of combining AI and Physical Layer Security (PLS) for next-generation wireless networks in order to address evolving security threats.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Token Communication-Driven Multimodal Large Models in Resource-Constrained Multiuser Networks</title>
<link>https://arxiv.org/abs/2505.07841</link>
<guid>https://arxiv.org/abs/2505.07841</guid>
<content:encoded><![CDATA[
arXiv:2505.07841v1 Announce Type: new 
Abstract: The proliferation of intelligent applications at the wireless edge, alongside the exponential growth of multimodal data, poses challenges for deploying multimodal large models (MLMs) in resource-constrained networks. These constraints manifest as limited bandwidth, computational capacity, and stringent latency requirements, particularly under low signal-to-noise ratio (SNR) conditions. To overcome these limitations, we propose a token communication paradigm that facilitates the decentralized deployment of MLMs across user devices and edge infrastructure (e.g., base stations). In this paradigm, task-relevant tokens are extracted from multimodal inputs and serve as the primary medium for communication between distributed model components. To align semantics and optimize transmission efficiency, we propose a dual-pronged approach: 1) We design a contrastive split fine-tuning method to project heterogeneous modalities into a shared feature space, enabling seamless interaction between model components while preserving modal-specific semantics. 2) We employ a lightweight compression technique to reduce the size of transmitted tokens, minimizing bandwidth consumption without sacrificing task-critical information. The proposed framework integrates collaborative fine-tuning of both the foundation model and multimodal transceivers, ensuring that token generation and utilization are tailored to specific downstream tasks. Simulation experiments conducted under different SNR conditions demonstrate that our method results in a $13.7\%$ improvement in test accuracy. Furthermore, our approach exhibits quicker convergence rates, even with reduced token lengths, highlighting the promise of token communication for facilitating more scalable and resilient MLM implementations in practical multiuser networks.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PRISM: Complete Online Decentralized Multi-Agent Pathfinding with Rapid Information Sharing using Motion Constraints</title>
<link>https://arxiv.org/abs/2505.08025</link>
<guid>https://arxiv.org/abs/2505.08025</guid>
<content:encoded><![CDATA[
arXiv:2505.08025v1 Announce Type: new 
Abstract: We introduce PRISM (Pathfinding with Rapid Information Sharing using Motion Constraints), a decentralized algorithm designed to address the multi-task multi-agent pathfinding (MT-MAPF) problem. PRISM enables large teams of agents to concurrently plan safe and efficient paths for multiple tasks while avoiding collisions. It employs a rapid communication strategy that uses information packets to exchange motion constraint information, enhancing cooperative pathfinding and situational awareness, even in scenarios without direct communication. We prove that PRISM resolves and avoids all deadlock scenarios when possible, a critical challenge in decentralized pathfinding. Empirically, we evaluate PRISM across five environments and 25 random scenarios, benchmarking it against the centralized Conflict-Based Search (CBS) and the decentralized Token Passing with Task Swaps (TPTS) algorithms. PRISM demonstrates scalability and solution quality, supporting 3.4 times more agents than CBS and handling up to 2.5 times more tasks in narrow passage environments than TPTS. Additionally, PRISM matches CBS in solution quality while achieving faster computation times, even under low-connectivity conditions. Its decentralized design reduces the computational burden on individual agents, making it scalable for large environments. These results confirm PRISM's robustness, scalability, and effectiveness in complex and dynamic pathfinding scenarios.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing</title>
<link>https://arxiv.org/abs/2505.08325</link>
<guid>https://arxiv.org/abs/2505.08325</guid>
<content:encoded><![CDATA[
arXiv:2505.08325v1 Announce Type: new 
Abstract: Remote sensing (RS) images are usually produced at an unprecedented scale, yet they are geographically and institutionally distributed, making centralized model training challenging due to data-sharing restrictions and privacy concerns. Federated learning (FL) offers a solution by enabling collaborative model training across decentralized RS data sources without exposing raw data. However, there lacks a realistic federated dataset and benchmark in RS. Prior works typically rely on manually partitioned single dataset, which fail to capture the heterogeneity and scale of real-world RS data, and often use inconsistent experimental setups, hindering fair comparison. To address this gap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists of eight datasets that cover various sensors and resolutions and builds 135 clients, which is representative of realistic operational scenarios. Data for each client come from the same source, exhibiting authentic federated properties such as skewed label distributions, imbalanced client data volumes, and domain heterogeneity across clients. These characteristics reflect practical challenges in federated RS and support evaluation of FL methods at scale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation metrics to construct the comprehensive FedRS-Bench. The experimental results demonstrate that FL can consistently improve model performance over training on isolated data silos, while revealing performance trade-offs of different methods under varying client heterogeneity and availability conditions. We hope FedRS-Bench will accelerate research on large-scale, realistic FL in RS by providing a standardized, rich testbed and facilitating fair comparisons across future works. The source codes and dataset are available at https://fedrs-bench.github.io/.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HMR-ODTA: Online Diverse Task Allocation for a Team of Heterogeneous Mobile Robots</title>
<link>https://arxiv.org/abs/2505.08419</link>
<guid>https://arxiv.org/abs/2505.08419</guid>
<content:encoded><![CDATA[
arXiv:2505.08419v1 Announce Type: new 
Abstract: Coordinating time-sensitive deliveries in environments like hospitals poses a complex challenge, particularly when managing multiple online pickup and delivery requests within strict time windows using a team of heterogeneous robots. Traditional approaches fail to address dynamic rescheduling or diverse service requirements, typically restricting robots to single-task types. This paper tackles the Multi-Pickup and Delivery Problem with Time Windows (MPDPTW), where autonomous mobile robots are capable of handling varied service requests. The objective is to minimize late delivery penalties while maximizing task completion rates. To achieve this, we propose a novel framework leveraging a heterogeneous robot team and an efficient dynamic scheduling algorithm that supports dynamic task rescheduling. Users submit requests with specific time constraints, and our decentralized algorithm, Heterogeneous Mobile Robots Online Diverse Task Allocation (HMR-ODTA), optimizes task assignments to ensure timely service while addressing delays or task rejections. Extensive simulations validate the algorithm's effectiveness. For smaller task sets (40-160 tasks), penalties were reduced by nearly 63%, while for larger sets (160-280 tasks), penalties decreased by approximately 50%. These results highlight the algorithm's effectiveness in improving task scheduling and coordination in multi-robot systems, offering a robust solution for enhancing delivery performance in structured, time-critical environments.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Guiding LLM-based Smart Contract Generation with Finite State Machine</title>
<link>https://arxiv.org/abs/2505.08542</link>
<guid>https://arxiv.org/abs/2505.08542</guid>
<content:encoded><![CDATA[
arXiv:2505.08542v1 Announce Type: new 
Abstract: Smart contract is a kind of self-executing code based on blockchain technology with a wide range of application scenarios, but the traditional generation method relies on manual coding and expert auditing, which has a high threshold and low efficiency. Although Large Language Models (LLMs) show great potential in programming tasks, they still face challenges in smart contract generation w.r.t. effectiveness and security. To solve these problems, we propose FSM-SCG, a smart contract generation framework based on finite state machine (FSM) and LLMs, which significantly improves the quality of the generated code by abstracting user requirements to generate FSM, guiding LLMs to generate smart contracts, and iteratively optimizing the code with the feedback of compilation and security checks. The experimental results show that FSM-SCG significantly improves the quality of smart contract generation. Compared to the best baseline, FSM-SCG improves the compilation success rate of generated smart contract code by at most 48%, and reduces the average vulnerability risk score by approximately 68%.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modular Federated Learning: A Meta-Framework Perspective</title>
<link>https://arxiv.org/abs/2505.08646</link>
<guid>https://arxiv.org/abs/2505.08646</guid>
<content:encoded><![CDATA[
arXiv:2505.08646v1 Announce Type: new 
Abstract: Federated Learning (FL) enables distributed machine learning training while preserving privacy, representing a paradigm shift for data-sensitive and decentralized environments. Despite its rapid advancements, FL remains a complex and multifaceted field, requiring a structured understanding of its methodologies, challenges, and applications. In this survey, we introduce a meta-framework perspective, conceptualising FL as a composition of modular components that systematically address core aspects such as communication, optimisation, security, and privacy. We provide a historical contextualisation of FL, tracing its evolution from distributed optimisation to modern distributed learning paradigms. Additionally, we propose a novel taxonomy distinguishing Aggregation from Alignment, introducing the concept of alignment as a fundamental operator alongside aggregation. To bridge theory with practice, we explore available FL frameworks in Python, facilitating real-world implementation. Finally, we systematise key challenges across FL sub-fields, providing insights into open research questions throughout the meta-framework modules. By structuring FL within a meta-framework of modular components and emphasising the dual role of Aggregation and Alignment, this survey provides a holistic and adaptable foundation for understanding and advancing FL research and deployment.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Comparative Analysis of Blockchain Systems</title>
<link>https://arxiv.org/abs/2505.08652</link>
<guid>https://arxiv.org/abs/2505.08652</guid>
<content:encoded><![CDATA[
arXiv:2505.08652v1 Announce Type: new 
Abstract: Blockchain is a type of decentralized distributed database. Unlike traditional relational database management systems, it does not require management or maintenance by a third party. All data management and update processes are open and transparent, solving the trust issues of centralized database management systems. Blockchain ensures network-wide consistency, consensus, traceability, and immutability. Under the premise of mutual distrust between nodes, blockchain technology integrates various technologies, such as P2P protocols, asymmetric encryption, consensus mechanisms, and chain structures. Data is distributed and stored across multiple nodes, maintained by all nodes, ensuring transaction data integrity, undeniability, and security. This facilitates trusted information sharing and supervision. The basic principles of blockchain form the foundation for all related research. Understanding the working principles is essential for further study of blockchain technology. There are many platforms based on blockchain technology, and they differ from one another. This paper will analyze the architecture of blockchain systems at each layer, focusing on the principles and technologies of blockchain platforms such as Bitcoin, Ethereum, and Hyperledger Fabric. The analysis will cover their scalability and security and highlight their similarities, differences, advantages, and disadvantages.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Technology: Core Mechanisms, Evolution, and Future Implementation Challenges</title>
<link>https://arxiv.org/abs/2505.08772</link>
<guid>https://arxiv.org/abs/2505.08772</guid>
<content:encoded><![CDATA[
arXiv:2505.08772v1 Announce Type: new 
Abstract: Blockchain technology has emerged as one of the most transformative digital innovations of the 21st century. This paper presents a comprehensive review of blockchain's fundamental architecture, tracing its development from Bitcoin's initial implementation to current enterprise applications. We examine the core technical components including distributed consensus algorithms, cryptographic principles, and smart contract functionality that enable blockchain's unique properties. The historical progression from cryptocurrency-focused systems to robust platforms for decentralized applications is analyzed, highlighting pivotal developments in scalability, privacy, and interoperability. Additionally, we identify critical challenges facing widespread blockchain adoption, including technical limitations, regulatory hurdles, and integration complexities with existing systems. By providing this foundational understanding of blockchain technology, this paper contributes to ongoing research efforts addressing blockchain's potential to revolutionize data management across industries.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sharp Gaussian approximations for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2505.08125</link>
<guid>https://arxiv.org/abs/2505.08125</guid>
<content:encoded><![CDATA[
arXiv:2505.08125v1 Announce Type: cross 
Abstract: Federated Learning has gained traction in privacy-sensitive collaborative environments, with local SGD emerging as a key optimization method in decentralized settings. While its convergence properties are well-studied, asymptotic statistical guarantees beyond convergence remain limited. In this paper, we present two generalized Gaussian approximation results for local SGD and explore their implications. First, we prove a Berry-Esseen theorem for the final local SGD iterates, enabling valid multiplier bootstrap procedures. Second, motivated by robustness considerations, we introduce two distinct time-uniform Gaussian approximations for the entire trajectory of local SGD. The time-uniform approximations support Gaussian bootstrap-based tests for detecting adversarial attacks. Extensive simulations are provided to support our theoretical results.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Is Centralized Training with Decentralized Execution Framework Centralized Enough for MARL?</title>
<link>https://arxiv.org/abs/2305.17352</link>
<guid>https://arxiv.org/abs/2305.17352</guid>
<content:encoded><![CDATA[
arXiv:2305.17352v2 Announce Type: replace 
Abstract: Centralized Training with Decentralized Execution (CTDE) has recently emerged as a popular framework for cooperative Multi-Agent Reinforcement Learning (MARL), where agents can use additional global state information to guide training in a centralized way and make their own decisions only based on decentralized local policies. Despite the encouraging results achieved, CTDE makes an independence assumption on agent policies, which limits agents to adopt global cooperative information from each other during centralized training. Therefore, we argue that existing CTDE methods cannot fully utilize global information for training, leading to an inefficient joint-policy exploration and even suboptimal results. In this paper, we introduce a novel Centralized Advising and Decentralized Pruning (CADP) framework for multi-agent reinforcement learning, that not only enables an efficacious message exchange among agents during training but also guarantees the independent policies for execution. Firstly, CADP endows agents the explicit communication channel to seek and take advices from different agents for more centralized training. To further ensure the decentralized execution, we propose a smooth model pruning mechanism to progressively constraint the agent communication into a closed one without degradation in agent cooperation capability. Empirical evaluations on StarCraft II micromanagement and Google Research Football benchmarks demonstrate that the proposed framework achieves superior performance compared with the state-of-the-art counterparts. Our code will be made publicly available.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM Multi-Agent Systems: Challenges and Open Problems</title>
<link>https://arxiv.org/abs/2402.03578</link>
<guid>https://arxiv.org/abs/2402.03578</guid>
<content:encoded><![CDATA[
arXiv:2402.03578v2 Announce Type: replace 
Abstract: This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PoisonCatcher: Revealing and Identifying LDP Poisoning Attacks in IIoT</title>
<link>https://arxiv.org/abs/2412.15704</link>
<guid>https://arxiv.org/abs/2412.15704</guid>
<content:encoded><![CDATA[
arXiv:2412.15704v2 Announce Type: replace 
Abstract: Local Differential Privacy (LDP), a robust privacy-protection model, is widely adopted in the Industrial Internet of Things (IIoT) due to its lightweight, decentralized, and scalable. However, its perturbation-based privacy-protection mechanism hinders distinguishing between any two data, thereby facilitating LDP poisoning attacks. The exposed physical-layer vulnerabilities and resource-constrained prevalent at the IIoT edge not only facilitate such attacks but also render existing LDP poisoning defenses, all of which are deployed at the edge and rely on ample resources, impractical.
  This work proposes a LDP poisoning defense for IIoT in the resource-rich aggregator. We first reveal key poisoning attack modes occurring within the LDP-utilized IIoT data-collection process, detailing how IIoT vulnerabilities enable attacks, and then formulate a general attack model and derive the poisoned data's indistinguishability. This work subsequently analyzes the poisoning impacts on aggregated data based on industrial process correlation, revealing the distortion of statistical query results' temporal similarity and the resulting disruption of inter-attribute correlation, and uncovering the intriguing paradox that adversaries' attempts to stabilize their poisoning actions for stealth are difficult to maintain. Given these findings, we propose PoisonCatcher, a solution for identifying poisoned data, which includes time-series detectors based on temporal similarity, attribute correlation, and pattern stability metrics to detect poisoned attributes, and a latent-bias feature miner for identifying poisons. Experiments on the real-world dataset indicate that PoisonCatcher successfully identifies poisoned data, demonstrating robust identification capabilities with F2 scores above 90.7\% under various attack settings.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bi-LSTM based Multi-Agent DRL with Computation-aware Pruning for Agent Twins Migration in Vehicular Embodied AI Networks</title>
<link>https://arxiv.org/abs/2505.06378</link>
<guid>https://arxiv.org/abs/2505.06378</guid>
<content:encoded><![CDATA[
arXiv:2505.06378v1 Announce Type: new 
Abstract: With the advancement of large language models and embodied Artificial Intelligence (AI) in the intelligent transportation scenarios, the combination of them in intelligent transportation spawns the Vehicular Embodied AI Network (VEANs). In VEANs, Autonomous Vehicles (AVs) are typical agents whose local advanced AI applications are defined as vehicular embodied AI agents, enabling capabilities such as environment perception and multi-agent collaboration. Due to computation latency and resource constraints, the local AI applications and services running on vehicular embodied AI agents need to be migrated, and subsequently referred to as vehicular embodied AI agent twins, which drive the advancement of vehicular embodied AI networks to offload intensive tasks to Roadside Units (RSUs), mitigating latency problems while maintaining service quality. Recognizing workload imbalance among RSUs in traditional approaches, we model AV-RSU interactions as a Stackelberg game to optimize bandwidth resource allocation for efficient migration. A Tiny Multi-Agent Bidirectional LSTM Proximal Policy Optimization (TMABLPPO) algorithm is designed to approximate the Stackelberg equilibrium through decentralized coordination. Furthermore, a personalized neural network pruning algorithm based on Path eXclusion (PX) dynamically adapts to heterogeneous AV computation capabilities by identifying task-critical parameters in trained models, reducing model complexity with less performance degradation. Experimental validation confirms the algorithm's effectiveness in balancing system load and minimizing delays, demonstrating significant improvements in vehicular embodied AI agent deployment.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Flock: Decentralized Multi-Robot Flocking via Large Language Models and Influence-Based Consensus</title>
<link>https://arxiv.org/abs/2505.06513</link>
<guid>https://arxiv.org/abs/2505.06513</guid>
<content:encoded><![CDATA[
arXiv:2505.06513v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have advanced rapidly in recent years, demonstrating strong capabilities in problem comprehension and reasoning. Inspired by these developments, researchers have begun exploring the use of LLMs as decentralized decision-makers for multi-robot formation control. However, prior studies reveal that directly applying LLMs to such tasks often leads to unstable and inconsistent behaviors, where robots may collapse to the centroid of their positions or diverge entirely due to hallucinated reasoning, logical inconsistencies, and limited coordination awareness. To overcome these limitations, we propose a novel framework that integrates LLMs with an influence-based plan consensus protocol. In this framework, each robot independently generates a local plan toward the desired formation using its own LLM. The robots then iteratively refine their plans through a decentralized consensus protocol that accounts for their influence on neighboring robots. This process drives the system toward a coherent and stable flocking formation in a fully decentralized manner. We evaluate our approach through comprehensive simulations involving both state-of-the-art closed-source LLMs (e.g., o3-mini, Claude 3.5) and open-source models (e.g., Llama3.1-405b, Qwen-Max, DeepSeek-R1). The results show notable improvements in stability, convergence, and adaptability over previous LLM-based methods. We further validate our framework on a physical team of Crazyflie drones, demonstrating its practical viability and effectiveness in real-world multi-robot systems.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Powered Anomaly Detection with Blockchain for Real-Time Security and Reliability in Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2505.06632</link>
<guid>https://arxiv.org/abs/2505.06632</guid>
<content:encoded><![CDATA[
arXiv:2505.06632v1 Announce Type: new 
Abstract: Autonomous Vehicles (AV) proliferation brings important and pressing security and reliability issues that must be dealt with to guarantee public safety and help their widespread adoption. The contribution of the proposed research is towards achieving more secure, reliable, and trustworthy autonomous transportation system by providing more capabilities for anomaly detection, data provenance, and real-time response in safety critical AV deployments. In this research, we develop a new framework that combines the power of Artificial Intelligence (AI) for real-time anomaly detection with blockchain technology to detect and prevent any malicious activity including sensor failures in AVs. Through Long Short-Term Memory (LSTM) networks, our approach continually monitors associated multi-sensor data streams to detect anomalous patterns that may represent cyberattacks as well as hardware malfunctions. Further, this framework employs a decentralized platform for securely storing sensor data and anomaly alerts in a blockchain ledger for data incorruptibility and authenticity, while offering transparent forensic features. Moreover, immediate automated response mechanisms are deployed using smart contracts when anomalies are found. This makes the AV system more resilient to attacks from both cyberspace and hardware component failure. Besides, we identify potential challenges of scalability in handling high frequency sensor data, computational constraint in resource constrained environment, and of distributed data storage in terms of privacy.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dyn-D$^2$P: Dynamic Differentially Private Decentralized Learning with Provable Utility Guarantee</title>
<link>https://arxiv.org/abs/2505.06651</link>
<guid>https://arxiv.org/abs/2505.06651</guid>
<content:encoded><![CDATA[
arXiv:2505.06651v1 Announce Type: new 
Abstract: Most existing decentralized learning methods with differential privacy (DP) guarantee rely on constant gradient clipping bounds and fixed-level DP Gaussian noises for each node throughout the training process, leading to a significant accuracy degradation compared to non-private counterparts. In this paper, we propose a new Dynamic Differentially Private Decentralized learning approach (termed Dyn-D$^2$P) tailored for general time-varying directed networks. Leveraging the Gaussian DP (GDP) framework for privacy accounting, Dyn-D$^2$P dynamically adjusts gradient clipping bounds and noise levels based on gradient convergence. This proposed dynamic noise strategy enables us to enhance model accuracy while preserving the total privacy budget. Extensive experiments on benchmark datasets demonstrate the superiority of Dyn-D$^2$P over its counterparts employing fixed-level noises, especially under strong privacy guarantees. Furthermore, we provide a provable utility bound for Dyn-D$^2$P that establishes an explicit dependency on network-related parameters, with a scaling factor of $1/\sqrt{n}$ in terms of the number of nodes $n$ up to a bias error term induced by gradient clipping. To our knowledge, this is the first model utility analysis for differentially private decentralized non-convex optimization with dynamic gradient clipping bounds and noise levels.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Centralized Trust in Decentralized Systems: Unveiling Hidden Contradictions in Blockchain and Cryptocurrency</title>
<link>https://arxiv.org/abs/2505.06661</link>
<guid>https://arxiv.org/abs/2505.06661</guid>
<content:encoded><![CDATA[
arXiv:2505.06661v1 Announce Type: new 
Abstract: Blockchain technology promises to democratize finance and promote social equity through decentralization, but questions remain about whether current implementations advance or hinder these goals. Through a mixed-methods study combining semi-structured interviews with 13 diverse blockchain stakeholders and analysis of over 3,000 cryptocurrency discussions on Reddit, we examine how trust manifests in cryptocurrency ecosystems despite their decentralized architecture. Our findings uncover that users actively seek out and create centralized trust anchors, such as established exchanges, prominent community figures, and recognized development teams, contradicting blockchain's fundamental promise of trustless interactions. We identify how this contradiction arises from users' mental need for accountability and their reluctance to shoulder the full responsibility of self-custody. The study also reveals how these centralized trust patterns disproportionately impact different user groups, with newer and less technical users showing stronger preferences for centralized intermediaries. This work contributes to our understanding of the inherent tensions between theoretical decentralization and practical implementation in cryptocurrency systems, highlighting the persistent role of centralized trust in supposedly trustless environments.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-aware Berrut Approximated Coded Computing applied to general distributed learning</title>
<link>https://arxiv.org/abs/2505.06759</link>
<guid>https://arxiv.org/abs/2505.06759</guid>
<content:encoded><![CDATA[
arXiv:2505.06759v1 Announce Type: new 
Abstract: Coded computing is one of the techniques that can be used for privacy protection in Federated Learning. However, most of the constructions used for coded computing work only under the assumption that the computations involved are exact, generally restricted to special classes of functions, and require quantized inputs. This paper considers the use of Private Berrut Approximate Coded Computing (PBACC) as a general solution to add strong but non-perfect privacy to federated learning. We derive new adapted PBACC algorithms for centralized aggregation, secure distributed training with centralized data, and secure decentralized training with decentralized data, thus enlarging significantly the applications of the method and the existing privacy protection tools available for these paradigms. Particularly, PBACC can be used robustly to attain privacy guarantees in decentralized federated learning for a variety of models. Our numerical results show that the achievable quality of different learning models (convolutional neural networks, variational autoencoders, and Cox regression) is minimally altered by using these new computing schemes, and that the privacy leakage can be bounded strictly to less than a fraction of one bit per participant. Additionally, the computational cost of the encoding and decoding processes depends only of the degree of decentralization of the data.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Crypto-Economic Analysis of Web3 Funding Programs Using the Grant Maturity Framework</title>
<link>https://arxiv.org/abs/2505.06801</link>
<guid>https://arxiv.org/abs/2505.06801</guid>
<content:encoded><![CDATA[
arXiv:2505.06801v1 Announce Type: new 
Abstract: Web3 grant programs are evolving mechanisms aimed at supporting innovation within the blockchain ecosystem, yet little is known on about their effectiveness. This paper proposes the concept of maturity to fill this gap and introduces the Grant Maturity Framework (GMF), a mixed-methods model for evaluating the maturity of Web3 grant programs. The GMF provides a systematic approach to assessing the structure, governance, and impact of Web3 grants, applied here to four prominent Ethereum layer-two (L2) grant programs: Arbitrum, Optimism, Mantle, and Taiko. By evaluating these programs using the GMF, the study categorizes them into four maturity stages, ranging from experimental to advanced. The findings reveal that Arbitrum's Long-Term Incentive Pilot Program (LTIPP) and Optimism's Mission Rounds show higher maturity, while Mantle and Taiko are still in their early stages. The research concludes by discussing the user-centric development of a Web3 grant management platform aimed at improving the maturity and effectiveness of Web3 grant management processes based on the findings from the GMF. This work contributes to both practical and theoretical knowledge on Web3 grant program evaluation and tooling, providing a valuable resource for Web3 grant operators and stakeholders.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ContribChain: A Stress-Balanced Blockchain Sharding Protocol with Node Contribution Awareness</title>
<link>https://arxiv.org/abs/2505.06899</link>
<guid>https://arxiv.org/abs/2505.06899</guid>
<content:encoded><![CDATA[
arXiv:2505.06899v1 Announce Type: new 
Abstract: Existing blockchain sharding protocols have focused on eliminating imbalanced workload distributions. However, even with workload balance, disparities in processing capabilities can lead to differential stress among shards, resulting in transaction backlogs in certain shards. Therefore, achieving stress balance among shards in the dynamic and heterogeneous environment presents a significant challenge of blockchain sharding. In this paper, we propose ContribChain, a blockchain sharding protocol that can automatically be aware of node contributions to achieve stress balance. We calculate node contribution values based on the historical behavior to evaluate the performance and security of nodes. Furthermore, we propose node allocation algorithm NACV and account allocation algorithm P-Louvain, which both match shard performance with workload to achieve stress balance. Finally, we conduct extensive experiments to compare our work with state-of-the-art baselines based on real Ethereum transactions. The evaluation results show that P-Louvain reduces allocation execution time by 86% and the cross-shard transaction ratio by 7.5%. Meanwhile, ContribChain improves throughput by 35.8% and reduces the cross-shard transaction ratio by 16%.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning with LoRA Optimized DeiT and Multiscale Patch Embedding for Secure Eye Disease Recognition</title>
<link>https://arxiv.org/abs/2505.06982</link>
<guid>https://arxiv.org/abs/2505.06982</guid>
<content:encoded><![CDATA[
arXiv:2505.06982v1 Announce Type: new 
Abstract: Recent progress in image-based medical disease detection encounters challenges such as limited annotated data sets, inadequate spatial feature analysis, data security issues, and inefficient training frameworks. This study introduces a data-efficient image transformer (DeIT)-based approach that overcomes these challenges by utilizing multiscale patch embedding for better feature extraction and stratified weighted random sampling to address class imbalance. The model also incorporates a LoRA-enhanced transformer encoder, a distillation framework, and federated learning for decentralized training, improving both efficiency and data security. Consequently, it achieves state-of-the-art performance, with the highest AUC, F1 score, precision, minimal loss, and Top-5 accuracy. Additionally, Grad-CAM++ visualizations improve interpretability by highlighting critical pathological regions, enhancing the model's clinical relevance. These results highlight the potential of this approach to advance AI-powered medical imaging and disease detection.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Agent Reinforcement Learning Approach for Cooperative Air-Ground-Human Crowdsensing in Emergency Rescue</title>
<link>https://arxiv.org/abs/2505.06997</link>
<guid>https://arxiv.org/abs/2505.06997</guid>
<content:encoded><![CDATA[
arXiv:2505.06997v1 Announce Type: new 
Abstract: Mobile crowdsensing is evolving beyond traditional human-centric models by integrating heterogeneous entities like unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Optimizing task allocation among these diverse agents is critical, particularly in challenging emergency rescue scenarios characterized by complex environments, limited communication, and partial observability. This paper tackles the Heterogeneous-Entity Collaborative-Sensing Task Allocation (HECTA) problem specifically for emergency rescue, considering humans, UAVs, and UGVs. We introduce a novel ``Hard-Cooperative'' policy where UGVs prioritize recharging low-battery UAVs, alongside performing their sensing tasks. The primary objective is maximizing the task completion rate (TCR) under strict time constraints. We rigorously formulate this NP-hard problem as a decentralized partially observable Markov decision process (Dec-POMDP) to effectively handle sequential decision-making under uncertainty. To solve this, we propose HECTA4ER, a novel multi-agent reinforcement learning algorithm built upon a Centralized Training with Decentralized Execution architecture. HECTA4ER incorporates tailored designs, including specialized modules for complex feature extraction, utilization of action-observation history via hidden states, and a mixing network integrating global and local information, specifically addressing the challenges of partial observability. Furthermore, theoretical analysis confirms the algorithm's convergence properties. Extensive simulations demonstrate that HECTA4ER significantly outperforms baseline algorithms, achieving an average 18.42% increase in TCR. Crucially, a real-world case study validates the algorithm's effectiveness and robustness in dynamic sensing scenarios, highlighting its strong potential for practical application in emergency response.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Source Anonymity for Private Random Walk Decentralized Learning</title>
<link>https://arxiv.org/abs/2505.07011</link>
<guid>https://arxiv.org/abs/2505.07011</guid>
<content:encoded><![CDATA[
arXiv:2505.07011v1 Announce Type: new 
Abstract: This paper considers random walk-based decentralized learning, where at each iteration of the learning process, one user updates the model and sends it to a randomly chosen neighbor until a convergence criterion is met. Preserving data privacy is a central concern and open problem in decentralized learning. We propose a privacy-preserving algorithm based on public-key cryptography and anonymization. In this algorithm, the user updates the model and encrypts the result using a distant user's public key. The encrypted result is then transmitted through the network with the goal of reaching that specific user. The key idea is to hide the source's identity so that, when the destination user decrypts the result, it does not know who the source was. The challenge is to design a network-dependent probability distribution (at the source) over the potential destinations such that, from the receiver's perspective, all users have a similar likelihood of being the source. We introduce the problem and construct a scheme that provides anonymity with theoretical guarantees. We focus on random regular graphs to establish rigorous guarantees.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Stealth Attacks on Cyber-Physical Systems</title>
<link>https://arxiv.org/abs/2505.07029</link>
<guid>https://arxiv.org/abs/2505.07029</guid>
<content:encoded><![CDATA[
arXiv:2505.07029v1 Announce Type: new 
Abstract: Decentralized stealth attack constructions that minimize the mutual information between the state variables and the measurements are proposed. The attack constructions are formulated as random Gaussian attacks targeting Cyber-physical systems that aims at minimizing the mutual information between the state variables and measurements while constraining the Kullback-Leibler divergence between the distribution of the measurements under attacks and the distribution of the measurements without attacks. The proposed information metrics adopted measure the disruption and attack detection both globally and locally. The decentralized attack constructions are formulated in a framework of normal games. The global and local information metrics yield games with global and local objectives in disruption and attack detection. We have proven the games are potential games and the convexity of the potential functions followed by the uniqueness and the achievability of the Nash Equilibrium, accordingly. We proposed a best response dynamics to achieve the Nash Equilibrium of the games. We numerically evaluate the performance of the proposed decentralized stealth random attacks on IEEE test systems and show it is feasible to exploit game theoretic techniques in decentralized attack constructions.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AugMixCloak: A Defense against Membership Inference Attacks via Image Transformation</title>
<link>https://arxiv.org/abs/2505.07149</link>
<guid>https://arxiv.org/abs/2505.07149</guid>
<content:encoded><![CDATA[
arXiv:2505.07149v1 Announce Type: new 
Abstract: Traditional machine learning (ML) raises serious privacy concerns, while federated learning (FL) mitigates the risk of data leakage by keeping data on local devices. However, the training process of FL can still leak sensitive information, which adversaries may exploit to infer private data. One of the most prominent threats is the membership inference attack (MIA), where the adversary aims to determine whether a particular data record was part of the training set.
  This paper addresses this problem through a two-stage defense called AugMixCloak. The core idea is to apply data augmentation and principal component analysis (PCA)-based information fusion to query images, which are detected by perceptual hashing (pHash) as either identical to or highly similar to images in the training set. Experimental results show that AugMixCloak successfully defends against both binary classifier-based MIA and metric-based MIA across five datasets and various decentralized FL (DFL) topologies. Compared with regularization-based defenses, AugMixCloak demonstrates stronger protection. Compared with confidence score masking, AugMixCloak exhibits better generalization.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering the Grid: Collaborative Edge Artificial Intelligence for Decentralized Energy Systems</title>
<link>https://arxiv.org/abs/2505.07170</link>
<guid>https://arxiv.org/abs/2505.07170</guid>
<content:encoded><![CDATA[
arXiv:2505.07170v1 Announce Type: new 
Abstract: This paper examines how decentralized energy systems can be enhanced using collaborative Edge Artificial Intelligence. Decentralized grids use local renewable sources to reduce transmission losses and improve energy security. Edge AI enables real-time, privacy-preserving data processing at the network edge. Techniques such as federated learning and distributed control improve demand response, equipment maintenance, and energy optimization. The paper discusses key challenges including data privacy, scalability, and interoperability, and suggests solutions such as blockchain integration and adaptive architectures. Examples from virtual power plants and smart grids highlight the potential of these technologies. The paper calls for increased investment, policy support, and collaboration to advance sustainable energy systems.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing Genomic Data Against Inference Attacks in Federated Learning Environments</title>
<link>https://arxiv.org/abs/2505.07188</link>
<guid>https://arxiv.org/abs/2505.07188</guid>
<content:encoded><![CDATA[
arXiv:2505.07188v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a promising framework for collaboratively training machine learning models across decentralized genomic datasets without direct data sharing. While this approach preserves data locality, it remains susceptible to sophisticated inference attacks that can compromise individual privacy. In this study, we simulate a federated learning setup using synthetic genomic data and assess its vulnerability to three key attack vectors: Membership Inference Attack (MIA), Gradient-Based Membership Inference Attack, and Label Inference Attack (LIA). Our experiments reveal that Gradient-Based MIA achieves the highest effectiveness, with a precision of 0.79 and F1-score of 0.87, underscoring the risk posed by gradient exposure in federated updates. Additionally, we visualize comparative attack performance through radar plots and quantify model leakage across clients. The findings emphasize the inadequacy of na\"ive FL setups in safeguarding genomic privacy and motivate the development of more robust privacy-preserving mechanisms tailored to the unique sensitivity of genomic data.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.07291</link>
<guid>https://arxiv.org/abs/2505.07291</guid>
<content:encoded><![CDATA[
arXiv:2505.07291v1 Announce Type: new 
Abstract: We introduce INTELLECT-2, the first globally distributed reinforcement learning (RL) training run of a 32 billion parameter language model. Unlike traditional centralized training efforts, INTELLECT-2 trains a reasoning model using fully asynchronous RL across a dynamic, heterogeneous swarm of permissionless compute contributors.
  To enable a training run with this unique infrastructure, we built various components from scratch: we introduce PRIME-RL, our training framework purpose-built for distributed asynchronous reinforcement learning, based on top of novel components such as TOPLOC, which verifies rollouts from untrusted inference workers, and SHARDCAST, which efficiently broadcasts policy weights from training nodes to inference workers.
  Beyond infrastructure components, we propose modifications to the standard GRPO training recipe and data filtering techniques that were crucial to achieve training stability and ensure that our model successfully learned its training objective, thus improving upon QwQ-32B, the state of the art reasoning model in the 32B parameter range.
  We open-source INTELLECT-2 along with all of our code and data, hoping to encourage and enable more open research in the field of decentralized training.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SwarmSearch: Decentralized Search Engine with Self-Funding Economy</title>
<link>https://arxiv.org/abs/2505.07452</link>
<guid>https://arxiv.org/abs/2505.07452</guid>
<content:encoded><![CDATA[
arXiv:2505.07452v1 Announce Type: new 
Abstract: Centralized search engines control what we see, read, believe, and vote. Consequently, they raise concerns over information control, censorship, and bias. Decentralized search engines offer a remedy to this problem, but their adoption has been hindered by their inferior quality and lack of a self-sustaining economic framework. We present SwarmSearch, a fully decentralized, AI-powered search engine with a self-funding architecture. Our system is designed for deployment within the decentralized file-sharing software Tribler. SwarmSearch integrates volunteer-based with profit-driven mechanisms to foster an implicit marketplace for resources. Employing the state-of-the-art of AI-based retrieval and relevance ranking, we also aim to close the quality gap between decentralized search and centralized alternatives. Our system demonstrates high retrieval accuracy while showing robustness in the presence of 50% adversarial nodes.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Latent-Space Constraints in Personalized FL</title>
<link>https://arxiv.org/abs/2505.07525</link>
<guid>https://arxiv.org/abs/2505.07525</guid>
<content:encoded><![CDATA[
arXiv:2505.07525v1 Announce Type: new 
Abstract: Federated learning (FL) has become an effective and widely used approach to training deep learning models on decentralized datasets held by distinct clients. FL also strengthens both security and privacy protections for training data. Common challenges associated with statistical heterogeneity between distributed datasets have spurred significant interest in personalized FL (pFL) methods, where models combine aspects of global learning with local modeling specific to each client's unique characteristics. In this work, the efficacy of theoretically supported, adaptive MMD measures within the Ditto framework, a state-of-the-art technique in pFL, are investigated. The use of such measures significantly improves model performance across a variety of tasks, especially those with pronounced feature heterogeneity. While the Ditto algorithm is specifically considered, such measures are directly applicable to a number of other pFL settings, and the results motivate the use of constraints tailored to the various kinds of heterogeneity expected in FL systems.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Post-Quantum Secure Decentralized Random Number Generation Protocol with Two Rounds of Communication in the Standard Model</title>
<link>https://arxiv.org/abs/2505.07536</link>
<guid>https://arxiv.org/abs/2505.07536</guid>
<content:encoded><![CDATA[
arXiv:2505.07536v1 Announce Type: new 
Abstract: Randomness plays a vital role in numerous applications, including simulation, cryptography, distributed systems, and gaming. Consequently, extensive research has been conducted to generate randomness. One such method is to design a decentralized random number generator (DRNG), a protocol that enables multiple participants to collaboratively generate random outputs that must be publicly verifiable. However, existing DRNGs are either not secure against quantum computers or depend on the random oracle model (ROM) to achieve security. In this paper, we design a DRNG based on lattice-based publicly verifiable secret sharing (PVSS) that is post-quantum secure and proven secure in the standard model. Additionally, our DRNG requires only two rounds of communication to generate a single (pseudo)random value and can tolerate up to any t < n/2 dishonest participants. To our knowledge, the proposed DRNG construction is the first to achieve all these properties.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentFlow: Resilient Adaptive Cloud-Edge Framework for Multi-Agent Coordination</title>
<link>https://arxiv.org/abs/2505.07603</link>
<guid>https://arxiv.org/abs/2505.07603</guid>
<content:encoded><![CDATA[
arXiv:2505.07603v1 Announce Type: new 
Abstract: This paper presents AgentFlow, a MAS-based framework for programmable distributed systems in heterogeneous cloud-edge environments. It introduces logistics objects and abstract agent interfaces to enable dynamic service flows and modular orchestration. AgentFlow supports decentralized publish-subscribe messaging and many-to-many service elections, enabling decision coordination without a central server. It features plug-and-play node discovery, flexible task reorganization, and highly adaptable fault tolerance and substitution mechanisms. AgentFlow advances scalable, real-time coordination for resilient and autonomous mission-critical systems.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data Ethics in the Fediverse: Analyzing the Role of Instance Policies in Mastodon Research</title>
<link>https://arxiv.org/abs/2505.07606</link>
<guid>https://arxiv.org/abs/2505.07606</guid>
<content:encoded><![CDATA[
arXiv:2505.07606v1 Announce Type: new 
Abstract: This article addresses the disconnect between the individual policy documents of Mastodon instances--many of which explicitly prohibit data collection for research purposes--and the actual data handling practices observed in academic research involving Mastodon. We present a systematic analysis of 29 works that used Mastodon as a data source, revealing limited adherence to instance--level policies despite researchers' general awareness of their existence. Our findings underscore the need for broader discussion about ethical obligations in research on alternative, decentralized social media platforms.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Federated Learning with Kolmogorov-Arnold Networks: A Comparative Study Across Diverse Aggregation Strategies</title>
<link>https://arxiv.org/abs/2505.07629</link>
<guid>https://arxiv.org/abs/2505.07629</guid>
<content:encoded><![CDATA[
arXiv:2505.07629v1 Announce Type: new 
Abstract: Multilayer Perceptron (MLP), as a simple yet powerful model, continues to be widely used in classification and regression tasks. However, traditional MLPs often struggle to efficiently capture nonlinear relationships in load data when dealing with complex datasets. Kolmogorov-Arnold Networks (KAN), inspired by the Kolmogorov-Arnold representation theorem, have shown promising capabilities in modeling complex nonlinear relationships. In this study, we explore the performance of KANs within federated learning (FL) frameworks and compare them to traditional Multilayer Perceptrons. Our experiments, conducted across four diverse datasets demonstrate that KANs consistently outperform MLPs in terms of accuracy, stability, and convergence efficiency. KANs exhibit remarkable robustness under varying client numbers and non-IID data distributions, maintaining superior performance even as client heterogeneity increases. Notably, KANs require fewer communication rounds to converge compared to MLPs, highlighting their efficiency in FL scenarios. Additionally, we evaluate multiple parameter aggregation strategies, with trimmed mean and FedProx emerging as the most effective for optimizing KAN performance. These findings establish KANs as a robust and scalable alternative to MLPs for federated learning tasks, paving the way for their application in decentralized and privacy-preserving environments.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Routing Attacks in Ethereum PoS: A Systematic Exploration</title>
<link>https://arxiv.org/abs/2505.07713</link>
<guid>https://arxiv.org/abs/2505.07713</guid>
<content:encoded><![CDATA[
arXiv:2505.07713v1 Announce Type: new 
Abstract: With the promise of greater decentralization and sustainability, Ethereum transitioned from a Proof-of-Work (PoW) to a Proof-of-Stake (PoS) consensus mechanism. The new consensus protocol introduces novel vulnerabilities that warrant further investigation. The goal of this paper is to investigate the security of Ethereum's PoS system from an Internet routing perspective.
  To this end, this paper makes two contributions: First, we devise a novel framework for inferring the distribution of validators on the Internet without disturbing the real network. Second, we introduce a class of network-level attacks on Ethereum's PoS system that jointly exploit Internet routing vulnerabilities with the protocol's reward and penalty mechanisms. We describe two representative attacks: StakeBleed, where the attacker triggers an inactivity leak, halting block finality and causing financial losses for all validators; and KnockBlock, where the attacker increases her expected MEV gains by preventing targeted blocks from being included in the chain. We find that both attacks are practical and effective. An attacker executing StakeBleed can inflict losses of almost 300 ETH in just 2 hours by hijacking as few as 30 IP prefixes. An attacker implementing KnockBlock could increase their MEV expected gains by 44.5% while hijacking a single prefix for less than 2 minutes.
  Our paper serves as a call to action for validators to reinforce their Internet routing infrastructure and for the Ethereum P2P protocol to implement stronger mechanisms to conceal validator locations.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Agent Rollout Approach for Highway Bottleneck Decongestion in Mixed Autonomy</title>
<link>https://arxiv.org/abs/2405.03132</link>
<guid>https://arxiv.org/abs/2405.03132</guid>
<content:encoded><![CDATA[
arXiv:2405.03132v2 Announce Type: replace 
Abstract: The integration of autonomous vehicles (AVs) into the existing transportation infrastructure offers a promising solution to alleviate congestion and enhance mobility. This research explores a novel approach to traffic optimization by employing a multi-agent rollout approach within a mixed autonomy environment. The study concentrates on coordinating the speed of human-driven vehicles by longitudinally controlling AVs, aiming to dynamically optimize traffic flow and alleviate congestion at highway bottlenecks in real-time. We model the problem as a decentralized partially observable Markov decision process (Dec-POMDP) and propose an improved multi-agent rollout algorithm. By employing agent-by-agent policy iterations, our approach implicitly considers cooperation among multiple agents and seamlessly adapts to complex scenarios where the number of agents dynamically varies. Validated in a real-world network with varying AV penetration rates and traffic flow, the simulations demonstrate that the multi-agent rollout algorithm significantly enhances performance, reducing average travel time on bottleneck segments by 9.42% with a 10% AV penetration rate.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-Critical Formation Control of Non-Holonomic Multi-Robot Systems in Communication-Limited Environments</title>
<link>https://arxiv.org/abs/2406.13707</link>
<guid>https://arxiv.org/abs/2406.13707</guid>
<content:encoded><![CDATA[
arXiv:2406.13707v3 Announce Type: replace 
Abstract: This paper introduces a decentralized estimator-based safety-critical controller designed for formation control of non-holonomic mobile robots operating in communication-constrained environments. The proposed framework integrates a robust state estimator capable of accurately reconstructing neighboring agents' velocity vectors and orientations under varying dynamic conditions, with a decentralized formation tracking controller that leverages Control Barrier Functions (CBFs) to guarantee collision avoidance and inter-agent safety. We present a closed-form control law that ensures both stability and string stability, effectively attenuating disturbances propagating from leader to followers. The theoretical foundations of the estimator and controller are established using Lyapunov stability analysis, which confirms global asymptotic stability under constant velocities and global uniformly ultimate boundedness under time-varying conditions. Extensive numerical simulations and realistic Gazebo-based experiments validate the effectiveness, robustness, and practical applicability of the proposed method, demonstrating precise formation tracking, stringent safety maintenance, and disturbance resilience without relying on inter-robot communication.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Half a Century of Distributed Byzantine Fault-Tolerant Consensus: Design Principles and Evolutionary Pathways</title>
<link>https://arxiv.org/abs/2407.19863</link>
<guid>https://arxiv.org/abs/2407.19863</guid>
<content:encoded><![CDATA[
arXiv:2407.19863v3 Announce Type: replace 
Abstract: The concept of distributed consensus originated in the 1970s and gained widespread attention following Leslie Lamport's influential publication on the Byzantine Generals Problem in the 1980s. Over the past five decades, distributed consensus has become an extensively researched field. Practical Byzantine Fault Tolerance (PBFT) has emerged as a prominent and widely adopted solution due to its conceptual clarity, effectiveness, and resilience to arbitrary failures. However, PBFT does not universally address all scenarios, highlighting the necessity of developing a comprehensive understanding of the history, evolution, and foundational principles of distributed consensus. This article systematically reviews the historical evolution and foundational principles of distributed consensus, examining pivotal advancements including fault-tolerant state machine replication (SMR), consensus protocols in partially synchronous and asynchronous networks, and recent innovations in Directed Acyclic Graph (DAG)-based consensus mechanisms. We further analyse the core design rationales, essential components, and underlying primitives across various distributed fault-tolerant protocols. The relationship between BFT consensus mechanisms and their applications in environments requiring robust resilience against adversarial faults is also explored. Finally, we discuss emerging research areas and challenges, such as consensus for wireless and blockchain scenarios, highlighting potential future developments. This comprehensive overview offers valuable insights to inform the design, optimisation, and implementation of distributed consensus systems across multiple application scenarios.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Next-Gen Space-Based Surveillance: Blockchain for Trusted and Efficient Debris Tracking</title>
<link>https://arxiv.org/abs/2501.06970</link>
<guid>https://arxiv.org/abs/2501.06970</guid>
<content:encoded><![CDATA[
arXiv:2501.06970v3 Announce Type: replace 
Abstract: The increasing congestion of Earth's orbit due to growing satellite deployments and space debris poses a significant challenge to sustainable space operations. Traditional space surveillance systems rely on centralized architectures, which introduce single points of failure and scalability constraints. This paper proposes a blockchain-based solution where satellites function as nodes with distinct roles to validate and securely store debris-tracking data. Simulation results indicate that optimal network performance is achieved with approximately 30 nodes, balancing throughput and response time, representing an approximately 9x improvement over traditional consensus mechanisms.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids</title>
<link>https://arxiv.org/abs/2505.05498</link>
<guid>https://arxiv.org/abs/2505.05498</guid>
<content:encoded><![CDATA[
arXiv:2505.05498v1 Announce Type: new 
Abstract: Microgrids have emerged as a pivotal solution in the quest for a sustainable and energy-efficient future. While microgrids offer numerous advantages, they are also prone to issues related to reliably forecasting renewable energy demand and production, protecting against cyberattacks, controlling operational costs, optimizing power flow, and regulating the performance of energy management systems (EMS). Tackling these energy management challenges is essential to facilitate microgrid applications and seamlessly incorporate renewable energy resources. Artificial intelligence (AI) has recently demonstrated immense potential for optimizing energy management in microgrids, providing efficient and reliable solutions. This paper highlights the combined benefits of enabling AI-based methodologies in the energy management systems of microgrids by examining the applicability and efficiency of AI-based EMS in achieving specific technical and economic objectives. The paper also points out several future research directions that promise to spearhead AI-driven EMS, namely the development of self-healing microgrids, integration with blockchain technology, use of Internet of things (IoT), and addressing interpretability, data privacy, scalability, and the prospects to generative AI in the context of future AI-based EMS.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization</title>
<link>https://arxiv.org/abs/2505.05584</link>
<guid>https://arxiv.org/abs/2505.05584</guid>
<content:encoded><![CDATA[
arXiv:2505.05584v1 Announce Type: new 
Abstract: Mutation testing is a widely recognized technique for assessing and enhancing the effectiveness of software test suites by introducing deliberate code mutations. However, its application often results in overly large test suites, as developers generate numerous tests to kill specific mutants, increasing computational overhead. This paper introduces PRIMG (Prioritization and Refinement Integrated Mutation-driven Generation), a novel framework for incremental and adaptive test case generation for Solidity smart contracts. PRIMG integrates two core components: a mutation prioritization module, which employs a machine learning model trained on mutant subsumption graphs to predict the usefulness of surviving mutants, and a test case generation module, which utilizes Large Language Models (LLMs) to generate and iteratively refine test cases to achieve syntactic and behavioral correctness.
  We evaluated PRIMG on real-world Solidity projects from Code4Arena to assess its effectiveness in improving mutation scores and generating high-quality test cases. The experimental results demonstrate that PRIMG significantly reduces test suite size while maintaining high mutation coverage. The prioritization module consistently outperformed random mutant selection, enabling the generation of high-impact tests with reduced computational effort. Furthermore, the refining process enhanced the correctness and utility of LLM-generated tests, addressing their inherent limitations in handling edge cases and complex program logic.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring the Susceptibility to Fraud of Monetary Incentive Mechanisms for Strengthening FOSS Projects</title>
<link>https://arxiv.org/abs/2505.05897</link>
<guid>https://arxiv.org/abs/2505.05897</guid>
<content:encoded><![CDATA[
arXiv:2505.05897v1 Announce Type: new 
Abstract: Free and open source software (FOSS) is ubiquitous on modern IT systems, accelerating the speed of software engineering over the past decades. With its increasing importance and historical reliance on uncompensated contributions, questions have been raised regarding the continuous maintenance of FOSS and its implications from a security perspective. In recent years, different funding programs have emerged to provide external incentives to reinforce community FOSS' sustainability. Past research primarily focused on analyses what type of projects have been funded and for what reasons. However, it has neither been considered whether there is a need for such external incentives, nor whether the incentive mechanisms, especially with the development of decentralized approaches, are susceptible to fraud. In this study, we explore the need for funding through a literature review and compare the susceptibility to fraud of centralized and decentralized incentive programs by performing case studies on the Sovereign Tech Fund (STF) and the tea project. We find non-commercial incentives to fill an important gap, ensuring longevity and sustainability of projects. Furthermore, we find the STF to be able to achieve a high resilience against fraud attempts, while tea is highly susceptible to fraud, as evidenced by revelation of an associated sybil attack on npm. Our results imply that special considerations must be taken into account when utilizing quantitative repository metrics regardless whether spoofing is expected.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Offline Multi-agent Reinforcement Learning via Score Decomposition</title>
<link>https://arxiv.org/abs/2505.05968</link>
<guid>https://arxiv.org/abs/2505.05968</guid>
<content:encoded><![CDATA[
arXiv:2505.05968v1 Announce Type: new 
Abstract: Offline multi-agent reinforcement learning (MARL) faces critical challenges due to distributional shifts, further exacerbated by the high dimensionality of joint action spaces and the diversity in coordination strategies and quality among agents. Conventional approaches, including independent learning frameworks and value decomposition methods based on pessimistic principles, remain susceptible to out-of-distribution (OOD) joint actions and often yield suboptimal performance. Through systematic analysis of prevalent offline MARL benchmarks, we identify that this limitation primarily stems from the inherently multimodal nature of joint collaborative policies induced by offline data collection. To address these challenges, we propose a novel two-stage framework: First, we employ a diffusion-based generative model to explicitly capture the complex behavior policy, enabling accurate modeling of diverse multi-agent coordination patterns. Second, we introduce a sequential score function decomposition mechanism to regularize individual policies and enable decentralized execution. Extensive experiments on continuous control tasks demonstrate state-of-the-art performance across multiple standard offline MARL benchmarks, outperforming existing methods by 26.3\% in normalized returns. Our approach provides new insights into offline coordination and equilibrium selection in cooperative multi-agent systems.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Context-Driven Approach for Co-Auditing Smart Contracts with The Support of GPT-4 code interpreter</title>
<link>https://arxiv.org/abs/2406.18075</link>
<guid>https://arxiv.org/abs/2406.18075</guid>
<content:encoded><![CDATA[
arXiv:2406.18075v1 Announce Type: cross 
Abstract: The surge in the adoption of smart contracts necessitates rigorous auditing to ensure their security and reliability. Manual auditing, although comprehensive, is time-consuming and heavily reliant on the auditor's expertise. With the rise of Large Language Models (LLMs), there is growing interest in leveraging them to assist auditors in the auditing process (co-auditing). However, the effectiveness of LLMs in smart contract co-auditing is contingent upon the design of the input prompts, especially in terms of context description and code length. This paper introduces a novel context-driven prompting technique for smart contract co-auditing. Our approach employs three techniques for context scoping and augmentation, encompassing code scoping to chunk long code into self-contained code segments based on code inter-dependencies, assessment scoping to enhance context description based on the target assessment goal, thereby limiting the search space, and reporting scoping to force a specific format for the generated response. Through empirical evaluations on publicly available vulnerable contracts, our method demonstrated a detection rate of 96\% for vulnerable functions, outperforming the native prompting approach, which detected only 53\%. To assess the reliability of our prompting approach, manual analysis of the results was conducted by expert auditors from our partner, Quantstamp, a world-leading smart contract auditing company. The experts' analysis indicates that, in unlabeled datasets, our proposed approach enhances the proficiency of the GPT-4 code interpreter in detecting vulnerabilities.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security</title>
<link>https://arxiv.org/abs/2406.09831</link>
<guid>https://arxiv.org/abs/2406.09831</guid>
<content:encoded><![CDATA[
arXiv:2406.09831v2 Announce Type: replace 
Abstract: Federated Learning (FL) offers a promising paradigm for training Large Language Models (LLMs) in a decentralized manner while preserving data privacy and minimizing communication overhead. This survey examines recent advancements in FL-driven LLMs, with a particular emphasis on architectural designs, performance optimization, and security concerns, including the emerging area of machine unlearning. In this context, machine unlearning refers to the systematic removal of specific data contributions from trained models to comply with privacy regulations such as the Right to be Forgotten. We review a range of strategies enabling unlearning in federated LLMs, including perturbation-based methods, model decomposition, and incremental retraining, while evaluating their trade-offs in terms of efficiency, privacy guarantees, and model utility. Through selected case studies and empirical evaluations, we analyze how these methods perform in practical FL scenarios. This survey identifies critical research directions toward developing secure, adaptable, and high-performing federated LLM systems for real-world deployment.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BM-PAW: A Profitable Mining Attack in the PoW-based Blockchain System</title>
<link>https://arxiv.org/abs/2411.06187</link>
<guid>https://arxiv.org/abs/2411.06187</guid>
<content:encoded><![CDATA[
arXiv:2411.06187v2 Announce Type: replace 
Abstract: Mining attacks enable an adversary to procure a disproportionately large portion of mining rewards by deviating from honest mining practices within the PoW-based blockchain system. In this paper, we demonstrate that the security vulnerabilities of PoW-based blockchain extend beyond what these mining attacks initially reveal. We introduce a novel mining strategy, named BM-PAW, which yields superior rewards for both the attacker and the targeted pool compared to the state-of-the-art mining attack, PAW. BM-PAW attackers are incentivized to offer appropriate bribe money to other targets, as they comply with the attacker's directives upon receiving payment. We further find the BM-PAW attacker can circumvent the miner's dilemma through equilibrium analysis in a two-pool BM-PAW game scenario, wherein the outcome is determined by the attacker's mining power. We finally propose practical countermeasures to mitigate these novel pool attacks.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Convergence of Decentralized Stochastic Subgradient-based Methods for Nonsmooth Nonconvex functions</title>
<link>https://arxiv.org/abs/2403.11565</link>
<guid>https://arxiv.org/abs/2403.11565</guid>
<content:encoded><![CDATA[
arXiv:2403.11565v3 Announce Type: replace-cross 
Abstract: In this paper, we focus on the decentralized stochastic subgradient-based methods in minimizing nonsmooth nonconvex functions without Clarke regularity, especially in the decentralized training of nonsmooth neural networks. We propose a general framework that unifies various decentralized subgradient-based methods, such as decentralized stochastic subgradient descent (DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum (DSGD-M). To establish the convergence properties of our proposed framework, we relate the discrete iterates to the trajectories of a continuous-time differential inclusion, which is assumed to have a coercive Lyapunov function with a stable set $\mathcal{A}$. We prove the asymptotic convergence of the iterates to the stable set $\mathcal{A}$ with sufficiently small and diminishing step-sizes. These results provide first convergence guarantees for some well-recognized of decentralized stochastic subgradient-based methods without Clarke regularity of the objective function. Preliminary numerical experiments demonstrate that our proposed framework yields highly efficient decentralized stochastic subgradient-based methods with convergence guarantees in the training of nonsmooth neural networks.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups</title>
<link>https://arxiv.org/abs/2505.04725</link>
<guid>https://arxiv.org/abs/2505.04725</guid>
<content:encoded><![CDATA[
arXiv:2505.04725v1 Announce Type: new 
Abstract: We present a geometric neural network-based tracking controller for systems evolving on matrix Lie groups under unknown dynamics, actuator faults, and bounded disturbances. Leveraging the left-invariance of the tangent bundle of matrix Lie groups, viewed as an embedded submanifold of the vector space $\R^{N\times N}$, we propose a set of learning rules for neural network weights that are intrinsically compatible with the Lie group structure and do not require explicit parameterization. Exploiting the geometric properties of Lie groups, this approach circumvents parameterization singularities and enables a global search for optimal weights. The ultimate boundedness of all error signals -- including the neural network weights, the coordinate-free configuration error function, and the tracking velocity error -- is established using Lyapunov's direct method. To validate the effectiveness of the proposed method, we provide illustrative simulation results for decentralized formation control of multi-agent systems on the Special Euclidean group.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning for Cyber Physical Systems: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2505.04873</link>
<guid>https://arxiv.org/abs/2505.04873</guid>
<content:encoded><![CDATA[
arXiv:2505.04873v1 Announce Type: new 
Abstract: The integration of machine learning (ML) in cyber physical systems (CPS) is a complex task due to the challenges that arise in terms of real-time decision making, safety, reliability, device heterogeneity, and data privacy. There are also open research questions that must be addressed in order to fully realize the potential of ML in CPS. Federated learning (FL), a distributed approach to ML, has become increasingly popular in recent years. It allows models to be trained using data from decentralized sources. This approach has been gaining popularity in the CPS field, as it integrates computer, communication, and physical processes. Therefore, the purpose of this work is to provide a comprehensive analysis of the most recent developments of FL-CPS, including the numerous application areas, system topologies, and algorithms developed in recent years. The paper starts by discussing recent advances in both FL and CPS, followed by their integration. Then, the paper compares the application of FL in CPS with its applications in the internet of things (IoT) in further depth to show their connections and distinctions. Furthermore, the article scrutinizes how FL is utilized in critical CPS applications, e.g., intelligent transportation systems, cybersecurity services, smart cities, and smart healthcare solutions. The study also includes critical insights and lessons learned from various FL-CPS implementations. The paper's concluding section delves into significant concerns and suggests avenues for further research in this fast-paced and dynamic era.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Blockchain Cross Chain Interoperability: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2505.04934</link>
<guid>https://arxiv.org/abs/2505.04934</guid>
<content:encoded><![CDATA[
arXiv:2505.04934v1 Announce Type: new 
Abstract: Blockchain technology, introduced in 2008, has revolutionized data storage and transfer across sectors such as finance, healthcare, intelligent transportation, and the metaverse. However, the proliferation of blockchain systems has led to discrepancies in architectures, consensus mechanisms, and data standards, creating data and value silos that hinder the development of an integrated multi chain ecosystem. Blockchain interoperability (a.k.a cross chain interoperability) has thus emerged as a solution to enable seamless data and asset exchange across disparate blockchains. In this survey, we systematically analyze over 150 high impact sources from academic journals, digital libraries, and grey literature to provide an in depth examination of blockchain interoperability. By exploring the existing methods, technologies, and architectures, we offer a classification of interoperability approaches including Atomic Swaps, Sidechains, Light Clients, and so on, which represent the most comprehensive overview to date. Furthermore, we investigate the convergence of academic research with industry practices, underscoring the importance of collaborative efforts in advancing blockchain innovation. Finally, we identify key strategic insights, challenges, and future research trajectories in this field. Our findings aim to support researchers, policymakers, and industry leaders in understanding and harnessing the transformative potential of blockchain interoperability to address current challenges and drive forward a cohesive multi-chain ecosystem.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fluid Antenna-Assisted MU-MIMO Systems with Decentralized Baseband Processing</title>
<link>https://arxiv.org/abs/2505.04936</link>
<guid>https://arxiv.org/abs/2505.04936</guid>
<content:encoded><![CDATA[
arXiv:2505.04936v1 Announce Type: new 
Abstract: The fluid antenna system (FAS) has emerged as a disruptive technology, offering unprecedented degrees of freedom (DoF) for wireless communication systems. However, optimizing fluid antenna (FA) positions entails significant computational costs, especially when the number of FAs is large. To address this challenge, we introduce a decentralized baseband processing (DBP) architecture to FAS, which partitions the FA array into clusters and enables parallel processing. Based on the DBP architecture, we formulate a weighted sum rate (WSR) maximization problem through joint beamforming and FA position design for FA-assisted multiuser multiple-input multiple-output (MU-MIMO) systems. To solve the WSR maximization problem, we propose a novel decentralized block coordinate ascent (BCA)-based algorithm that leverages matrix fractional programming (FP) and majorization-minimization (MM) methods. The proposed decentralized algorithm achieves low computational, communication, and storage costs, thus unleashing the potential of the DBP architecture. Simulation results show that our proposed algorithm under the DBP architecture reduces computational time by over 70% compared to centralized architectures with negligible WSR performance loss.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DFPL: Decentralized Federated Prototype Learning Across Heterogeneous Data Distributions</title>
<link>https://arxiv.org/abs/2505.04947</link>
<guid>https://arxiv.org/abs/2505.04947</guid>
<content:encoded><![CDATA[
arXiv:2505.04947v1 Announce Type: new 
Abstract: Federated learning is a distributed machine learning paradigm that enables the collaborative training of multiple clients through centralized model aggregation. However, standard federated learning relies on a centralized server, making it vulnerable to server failures. While existing solutions utilize blockchain technology to implement Decentralized Federated Learning (DFL), the statistical heterogeneity of data distributions among clients severely degrades the DFL's performance. Driven by this issue, this paper proposes a decentralized federated prototype learning framework, named DFPL, which significantly improves the performance of distributed machine learning across heterogeneous data distributions. Specifically, our framework introduces prototype learning into DFL to address statistical heterogeneity, which greatly reduces the number of parameters exchanged between clients. Additionally, blockchain is embedded into our framework, enabling the training and mining processes to be implemented at each client. From a theoretical perspective, we provide convergence guarantee of DFPL by combining resource allocation for training and mining. The experiments highlight the superiority of our DFPL framework in communication efficiency and test performance across three benchmark datasets with heterogeneous data distributions.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balancing Client Participation in Federated Learning Using AoI</title>
<link>https://arxiv.org/abs/2505.05099</link>
<guid>https://arxiv.org/abs/2505.05099</guid>
<content:encoded><![CDATA[
arXiv:2505.05099v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized framework that preserves data privacy while enabling collaborative model training across distributed clients. However, FL faces significant challenges due to limited communication resources, statistical heterogeneity, and the need for balanced client participation. This paper proposes an Age of Information (AoI)-based client selection policy that addresses these challenges by minimizing load imbalance through controlled selection intervals. Our method employs a decentralized Markov scheduling policy, allowing clients to independently manage participation based on age-dependent selection probabilities, which balances client updates across training rounds with minimal central oversight. We provide a convergence proof for our method, demonstrating that it ensures stable and efficient model convergence. Specifically, we derive optimal parameters for the Markov selection model to achieve balanced and consistent client participation, highlighting the benefits of AoI in enhancing convergence stability. Through extensive simulations, we demonstrate that our AoI-based method, particularly the optimal Markov variant, improves convergence over the FedAvg selection approach across both IID and non-IID data settings by $7.5\%$ and up to $20\%$. Our findings underscore the effectiveness of AoI-based scheduling for scalable, fair, and efficient FL systems across diverse learning environments.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: A Taxonomy for Distributed-Ledger-Based Identity Management</title>
<link>https://arxiv.org/abs/2505.05100</link>
<guid>https://arxiv.org/abs/2505.05100</guid>
<content:encoded><![CDATA[
arXiv:2505.05100v1 Announce Type: new 
Abstract: The intersection of blockchain (distributed ledger) and identity management lacks a comprehensive framework for classifying distributed-ledger-based identity solutions. This paper introduces a methodologically developed taxonomy derived from the analysis of 390 scientific papers and expert discussions.
  The resulting framework consists of 22 dimensions with 113 characteristics, organized into three groups: trust anchor implementations, identity architectures (identifiers and credentials), and ledger specifications. This taxonomy facilitates the systematic analysis, comparison, and design of distributed-ledger-based identity solutions, as demonstrated through its application to two distinct architectures.
  As the first methodology-driven taxonomy in this field, this work advances standardization and enhances understanding of distributed-ledger-based identity architectures. It provides researchers and practitioners with a structured framework for evaluating design decisions and implementation approaches.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network</title>
<link>https://arxiv.org/abs/2505.05103</link>
<guid>https://arxiv.org/abs/2505.05103</guid>
<content:encoded><![CDATA[
arXiv:2505.05103v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide range of applications. However, individual LLMs often produce inconsistent, biased, or hallucinated outputs due to limitations in their training corpora and model architectures. Recently, collaborative frameworks such as the Multi-LLM Network (MultiLLMN) have been introduced, enabling multiple LLMs to interact and jointly respond to user queries. Nevertheless, MultiLLMN architectures raise critical concerns regarding the reliability and security of the generated content, particularly in open environments where malicious or compromised LLMs may be present. Moreover, reliance on centralized coordination undermines system efficiency and introduces single points of failure. In this paper, we propose a novel Trusted MultiLLMN framework, driven by a Weighted Byzantine Fault Tolerance (WBFT) blockchain consensus mechanism, to ensure the reliability, security, and efficiency of multi-LLM collaboration. In WBFT, voting weights are adaptively assigned to each LLM based on its response quality and trustworthiness, incentivizing reliable behavior, and reducing the impact of malicious nodes. Extensive simulations demonstrate that WBFT significantly improves both consensus security and efficiency compared to classical and modern consensus mechanisms, particularly under wireless network conditions. Furthermore, our evaluations reveal that Trusted MultiLLMN supported by WBFT can deliver higher-quality and more credible responses than both single LLMs and conventional MultiLLMNs, thereby providing a promising path toward building robust, decentralized AI collaboration networks.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language Models</title>
<link>https://arxiv.org/abs/2505.05130</link>
<guid>https://arxiv.org/abs/2505.05130</guid>
<content:encoded><![CDATA[
arXiv:2505.05130v1 Announce Type: new 
Abstract: Large pre-trained Vision-Language Models (VLMs), such as Contrastive Language-Image Pre-training (CLIP), have exhibited remarkable zero-shot performance across various image classification tasks. Fine-tuning these models on domain-specific datasets further enhances their effectiveness for downstream applications. However, fine-tuning in cloud environments raises significant concerns regarding data security and privacy. Federated Learning (FL) offers a decentralized solution by enabling model training across local clients without centralizing sensitive data, but the high communication and computation costs of transmitting full pre-trained models during training limit its scalability. Additionally, non-Independent and Identically Distributed (non-IID) data across local clients can negatively impact model convergence and performance. To address these challenges, we propose CacheFL, a novel federated learning method that replaces traditional full model fine-tuning with lightweight cache model fine-tuning. The cache model is initialized using a class-balanced dataset generated by a generative pre-trained model, effectively mitigating the impact of non-IID data. This cache model is then distributed to local clients for fine-tuning, and the updated parameters from each client are aggregated on the server and redistributed. With the updated cache model, the classification performance of CLIP is improved after just a few epochs. By limiting the training and communication to the cache model, CacheFL significantly reduces resource demands while ensuring data privacy and security. Extensive experiments conducted on ImageNet and 10 additional datasets demonstrate that CacheFL outperforms traditional approaches in terms of classification accuracy, resource efficiency, and privacy preservation.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CV-MP: Max-Pressure Control in Heterogeneously Distributed and Partially Connected Vehicle Environments</title>
<link>https://arxiv.org/abs/2505.05258</link>
<guid>https://arxiv.org/abs/2505.05258</guid>
<content:encoded><![CDATA[
arXiv:2505.05258v1 Announce Type: new 
Abstract: Max-pressure (MP) control has emerged as a prominent real-time network traffic signal control strategy due to its simplicity, decentralized structure, and theoretical guarantees of network queue stability. Meanwhile, advances in connected vehicle (CV) technology have sparked extensive research into CV-based traffic signal control. Despite these developments, few studies have investigated MP control in heterogeneously distributed and partially CV environments while ensuring network queue stability. To address these research gaps, we propose a CV-based MP control (CV-MP) method that leverages real-time CV travel time information to compute the pressure, thereby incorporating both the spatial distribution and temporal delays of vehicles, unlike existing approaches that utilized only spatial distribution or temporal delays. In particular, we establish sufficient conditions for road network queue stability that are compatible with most existing MP control methods. Moreover, we pioneered the proof of network queue stability even if the vehicles are only partially connected and heterogeneously distributed, and gave a necessary condition of CV observation for maintaining the stability. Evaluation results on an Amsterdam corridor show that CV-MP significantly reduces vehicle delays compared to both actuated control and conventional MP control across various CV penetration rates. Moreover, in scenarios with dynamic traffic demand, CV-MP achieves lower spillover peaks even with low and heterogeneous CV penetration rates, further highlighting its effectiveness and robustness.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SUUM: Timestamp-based Nakamoto-style Blockchains are Vulnerable</title>
<link>https://arxiv.org/abs/2505.05328</link>
<guid>https://arxiv.org/abs/2505.05328</guid>
<content:encoded><![CDATA[
arXiv:2505.05328v1 Announce Type: new 
Abstract: We introduce two advanced attack strategies, the Unrestricted Uncle Maker (UUM) Attack and the Staircase-Unrestricted Uncle Maker (SUUM) Attack, which fundamentally threaten the security of timestamp-based Nakamoto-style blockchains by inflicting permanent systemic harm. Unlike prior work that merely enhances adversarial rewards, these attacks exploit vulnerabilities in timestamp manipulation and fork selection rules to irreversibly destabilize blockchain fairness and incentive mechanisms. Specifically, the SUUM attack enables adversaries to persistently launch attacks at zero cost, eliminating constraints on block withholding and risk-free conditions, while systematically maximizing rewards through coordinated timestamp adjustments and strategic block release.
  Our analysis demonstrates that SUUM adversaries achieve disproportionate reward advantages over both UUM and the original Riskless Uncle Maker (RUM) Attack [CCS '23], with all three strategies surpassing honest mining. Crucially, SUUM's cost-free persistence allows adversaries to indefinitely drain rewards from honest participants by maintaining minimal difficulty risks through precise timestamp manipulation. This creates a self-reinforcing cycle: adversaries amplify their profits while suppressing honest returns, thereby permanently eroding the protocol's security assumptions. Through rigorous theoretical modeling and simulations, we validate how SUUM's combination of timestamp tampering, block withholding, and difficulty risk control enables unmitigated exploitation of consensus mechanisms. This work underscores the existential risks posed by timestamp-based Nakamoto-style protocols and advocates urgent countermeasures to ensure long-term stability.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empirical Analysis of Transaction Conflicts in Ethereum and Solana for Parallel Execution</title>
<link>https://arxiv.org/abs/2505.05358</link>
<guid>https://arxiv.org/abs/2505.05358</guid>
<content:encoded><![CDATA[
arXiv:2505.05358v1 Announce Type: new 
Abstract: This paper presents a comprehensive analysis of historical data across two popular blockchain networks: Ethereum and Solana. Our study focuses on two key aspects: transaction conflicts and the maximum theoretical parallelism within historical blocks. We aim to quantify the degree of transaction parallelism and assess how effectively it can be exploited by systematically examining block-level characteristics, both within individual blocks and across different historical periods. In particular, this study is the first of its kind to leverage historical transactional workloads to evaluate transactional conflict patterns. By offering a structured approach to analyzing these conflicts, our research provides valuable insights and an empirical basis for developing more efficient parallel execution techniques in the Ethereum and Solana Virtual Machines. Our empirical analysis reveals that Ethereum blocks frequently achieve high independence$-$over 50\% in more than 50\% of blocks, while Solana blocks contain longer conflict chains, comprising $\sim$59\% of the block size compared to $\sim$18\% in Ethereum, reflecting fundamentally different parallel execution dynamics.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Walrus: An Efficient Decentralized Storage Network</title>
<link>https://arxiv.org/abs/2505.05370</link>
<guid>https://arxiv.org/abs/2505.05370</guid>
<content:encoded><![CDATA[
arXiv:2505.05370v1 Announce Type: new 
Abstract: Decentralized storage systems face a fundamental trade-off between replication overhead, recovery efficiency, and security guarantees. Current approaches either rely on full replication, incurring substantial storage costs, or employ trivial erasure coding schemes that struggle with efficient recovery especially under high storage-node churn. We present Walrus, a novel decentralized blob storage system that addresses these limitations through multiple technical innovations. At the core of Walrus is RedStuff, a two-dimensional erasure coding protocol that achieves high security with only 4.5x replication factor, while enabling self-healing recovery that requires bandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$ in traditional systems). Crucially, RedStuff is the first protocol to support storage challenges in asynchronous networks, preventing adversaries from exploiting network delays to pass verification without actually storing data. Walrus also introduces a novel multi-stage epoch change protocol that efficiently handles storage node churn while maintaining uninterrupted availability during committee transitions. Our system incorporates authenticated data structures to defend against malicious clients and ensures data consistency throughout storage and retrieval processes. Experimental evaluation demonstrates that Walrus achieves practical performance at scale, making it suitable for a wide range of decentralized applications requiring high-integrity, available blob storage with reasonable overhead.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering Scientific Workflows with Federated Agents</title>
<link>https://arxiv.org/abs/2505.05428</link>
<guid>https://arxiv.org/abs/2505.05428</guid>
<content:encoded><![CDATA[
arXiv:2505.05428v1 Announce Type: new 
Abstract: Agentic systems, in which diverse agents cooperate to tackle challenging problems, are exploding in popularity in the AI community. However, the agentic frameworks used to build these systems have not previously enabled use with research cyberinfrastructure. Here we introduce Academy, a modular and extensible middleware designed to deploy autonomous agents across the federated research ecosystem, including HPC systems, experimental facilities, and data repositories. To meet the demands of scientific computing, Academy supports asynchronous execution, heterogeneous resources, high-throughput data flows, and dynamic resource availability. It provides abstractions for expressing stateful agents, managing inter-agent coordination, and integrating computation with experimental control. We present microbenchmark results that demonstrate high performance and scalability in HPC environments. To demonstrate the breadth of applications that can be supported by agentic workflow designs, we also present case studies in materials discovery, decentralized learning, and information extraction in which agents are deployed across diverse HPC systems.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Parallel Contests for Crowdsourcing Reviews: Existence and Quality of Equilibria</title>
<link>https://arxiv.org/abs/2202.04064</link>
<guid>https://arxiv.org/abs/2202.04064</guid>
<content:encoded><![CDATA[
arXiv:2202.04064v3 Announce Type: replace 
Abstract: Motivated by the intricacies of allocating treasury funds in blockchain settings, we study the problem of crowdsourcing reviews for many different proposals, in parallel. During the reviewing phase, every reviewer can select the proposals to write reviews for, as well as the quality of each review. The quality levels follow certain very coarse community guidelines and can have values such as 'excellent' or 'good'. Based on these scores and the distribution of reviews, every reviewer will receive some reward for their efforts. In this paper, we design a reward scheme and show that it always has pure Nash equilibria, for any set of proposals and reviewers. In addition, we show that these equilibria guarantee constant factor approximations for two natural metrics: the total quality of all reviews, as well as the fraction of proposals that received at least one review, compared to the optimal outcome.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain in a box: A portable blockchain network implementation on Raspberry Pi's</title>
<link>https://arxiv.org/abs/2404.14282</link>
<guid>https://arxiv.org/abs/2404.14282</guid>
<content:encoded><![CDATA[
arXiv:2404.14282v2 Announce Type: replace 
Abstract: In this paper we describe a prototype of a blockchain-in-a-box system which allows users to easily bootstrap the whole Ethereum Proof-of-Work (PoW) network running on multiple Raspberry Pi nodes - an inexpensive modular computers. Users are able to orchestrate the whole blockchain network using a single web based interface, for example they are able to set the topology of the peer-to-peer (P2P) connections and control the initialization parameters. Each Raspberry Pi has a screen attached which visualizes current state of local blockchain, allowing users to easily visualize the consensus of the network in real time. We show how this platform can be used to perform experiments on consensus quality while using different P2P topologies. Similar experiments can be used for demonstration purposes in a workshop or other educational settings.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Concept to Measurement: A Survey of How the Blockchain Trilemma Can Be Analyzed</title>
<link>https://arxiv.org/abs/2505.03768</link>
<guid>https://arxiv.org/abs/2505.03768</guid>
<content:encoded><![CDATA[
arXiv:2505.03768v1 Announce Type: new 
Abstract: To meet non-functional requirements, practitioners must identify Pareto-optimal configurations of the degree of decentralization, scalability, and security of blockchain systems. Maximizing all of these subconcepts is, however, impossible due to the trade-offs highlighted by the blockchain trilemma. We reviewed analysis approaches to identify constructs and their operationalization through metrics for analyzing the blockchain trilemma subconcepts and to assess the applicability of the operationalized constructs to various blockchain systems. By clarifying these constructs and metrics, this work offers a theoretical foundation for more sophisticated investigations into how the blockchain trilemma manifests in blockchain systems, helping practitioners identify Pareto-optimal configurations.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Economic Security of Multiple Shared Security Protocols</title>
<link>https://arxiv.org/abs/2505.03843</link>
<guid>https://arxiv.org/abs/2505.03843</guid>
<content:encoded><![CDATA[
arXiv:2505.03843v1 Announce Type: new 
Abstract: As restaking protocols gain adoption across blockchain ecosystems, there is a need for Actively Validated Services (AVSs) to span multiple Shared Security Providers (SSPs). This leads to stake fragmentation which introduces new complications where an adversary may compromise an AVS by targeting its weakest SSP. In this paper, we formalize the Multiple SSP Problem and analyze two architectures : an isolated fragmented model called Model $\mathbb{M}$ and a shared unified model called Model $\mathbb{S}$, through a convex optimization and game-theoretic lens. We derive utility bounds, attack cost conditions, and market equilibrium that describes protocol security for both models. Our results show that while Model $\mathbb{M}$ offers deployment flexibility, it inherits lowest-cost attack vulnerabilities, whereas Model $\mathbb{S}$ achieves tighter security guarantees through single validator sets and aggregated slashing logic. We conclude with future directions of work including an incentive-compatible stake rebalancing allocation in restaking ecosystems.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Driven Security in Cloud Computing: Enhancing Threat Detection, Automated Response, and Cyber Resilience</title>
<link>https://arxiv.org/abs/2505.03945</link>
<guid>https://arxiv.org/abs/2505.03945</guid>
<content:encoded><![CDATA[
arXiv:2505.03945v1 Announce Type: new 
Abstract: Cloud security concerns have been greatly realized in recent years due to the increase of complicated threats in the computing world. Many traditional solutions do not work well in real-time to detect or prevent more complex threats. Artificial intelligence is today regarded as a revolution in determining a protection plan for cloud data architecture through machine learning, statistical visualization of computing infrastructure, and detection of security breaches followed by counteraction. These AI-enabled systems make work easier as more network activities are scrutinized, and any anomalous behavior that might be a precursor to a more serious breach is prevented. This paper examines ways AI can enhance cloud security by applying predictive analytics, behavior-based security threat detection, and AI-stirring encryption. It also outlines the problems of the previous security models and how AI overcomes them. For a similar reason, issues like data privacy, biases in the AI model, and regulatory compliance are also covered. So, AI improves the protection of cloud computing contexts; however, more efforts are needed in the subsequent phases to extend the technology's reliability, modularity, and ethical aspects. This means that AI can be blended with other new computing technologies, including blockchain, to improve security frameworks further. The paper discusses the current trends in securing cloud data architecture using AI and presents further research and application directions.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SolPhishHunter: Towards Detecting and Understanding Phishing on Solana</title>
<link>https://arxiv.org/abs/2505.04094</link>
<guid>https://arxiv.org/abs/2505.04094</guid>
<content:encoded><![CDATA[
arXiv:2505.04094v1 Announce Type: new 
Abstract: Solana is a rapidly evolving blockchain platform that has attracted an increasing number of users. However, this growth has also drawn the attention of malicious actors, with some phishers extending their reach into the Solana ecosystem. Unlike platforms such as Ethereum, Solana has distinct designs of accounts and transactions, leading to the emergence of new types of phishing transactions that we term SolPhish. We define three types of SolPhish and develop a detection tool called SolPhishHunter. Utilizing SolPhishHunter, we detect a total of 8,058 instances of SolPhish and conduct an empirical analysis of these detected cases. Our analysis explores the distribution and impact of SolPhish, the characteristics of the phishers, and the relationships among phishing gangs. Particularly, the detected SolPhish transactions have resulted in nearly \$1.1 million in losses for victims. We report our detection results to the community and construct SolPhishDataset, the \emph{first} Solana phishing-related dataset in academia.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Delegation and Participation in Decentralized Governance: An Epistemic View</title>
<link>https://arxiv.org/abs/2505.04136</link>
<guid>https://arxiv.org/abs/2505.04136</guid>
<content:encoded><![CDATA[
arXiv:2505.04136v1 Announce Type: new 
Abstract: We develop and apply epistemic tests to various decentralized governance methods as well as to study the impact of participation. These tests probe the ability to reach a correct outcome when there is one. We find that partial abstention is a strong governance method from an epistemic standpoint compared to alternatives such as various forms of ``transfer delegation" in which voters explicitly transfer some or all of their voting rights to others. We make a stronger case for multi-step transfer delegation than is present in previous work but also demonstrate that transfer delegation has inherent epistemic weaknesses. We show that enhanced direct participation, voters exercising their own voting rights, can have a variety of epistemic impacts, some very negative. We identify governance conditions under which additional direct participation is guaranteed to do no epistemic harm and is likely to increase the probability of making correct decisions. In light of the epistemic challenges of voting-based decentralized governance, we consider the possible supplementary use of prediction markets, auctions, and AI agents to improve outcomes. All these results are significant because epistemic performance matters if entities such as DAOs (decentralized autonomous organizations) wish to compete with organizations that are more centralized.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Guardians of the Web: The Evolution and Future of Website Information Security</title>
<link>https://arxiv.org/abs/2505.04308</link>
<guid>https://arxiv.org/abs/2505.04308</guid>
<content:encoded><![CDATA[
arXiv:2505.04308v1 Announce Type: new 
Abstract: Website information security has become a critical concern in the digital age. This article explores the evolution of website information security, examining its historical development, current practices, and future directions. The early beginnings from the 1960s to the 1980s laid the groundwork for modern cybersecurity, with the development of ARPANET, TCP/IP, public-key cryptography, and the first antivirus programs. The 1990s marked a transformative era, driven by the commercialization of the Internet and the emergence of web-based services. As the Internet grew, so did the range and sophistication of cyber threats, leading to advancements in security technologies such as the Secure Sockets Layer (SSL) protocol, password protection, and firewalls. Current practices in website information security involve a multi-layered approach, including encryption, secure coding practices, regular security audits, and user education. The future of website information security is expected to be shaped by emerging technologies such as artificial intelligence, blockchain, and quantum computing, as well as the increasing importance of international cooperation and standardization efforts. As cyber threats continue to evolve, ongoing research and innovation in website information security will be essential to protect sensitive information and maintain trust in the digital world.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.04317</link>
<guid>https://arxiv.org/abs/2505.04317</guid>
<content:encoded><![CDATA[
arXiv:2505.04317v1 Announce Type: new 
Abstract: In this paper, we tackle the problem of learning to play 3v3 multi-drone volleyball, a new embodied competitive task that requires both high-level strategic coordination and low-level agile control. The task is turn-based, multi-agent, and physically grounded, posing significant challenges due to its long-horizon dependencies, tight inter-agent coupling, and the underactuated dynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play (HCSP), a hierarchical reinforcement learning framework that separates centralized high-level strategic decision-making from decentralized low-level motion control. We design a three-stage population-based training pipeline to enable both strategy and skill to emerge from scratch without expert demonstrations: (I) training diverse low-level skills, (II) learning high-level strategy via self-play with fixed low-level controllers, and (III) joint fine-tuning through co-self-play. Experiments show that HCSP achieves superior performance, outperforming non-hierarchical self-play and rule-based hierarchical baselines with an average 82.9\% win rate and a 71.5\% win rate against the two-stage variant. Moreover, co-self-play leads to emergent team behaviors such as role switching and coordinated formations, demonstrating the effectiveness of our hierarchical design and training scheme.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking LLMs' Swarm intelligence</title>
<link>https://arxiv.org/abs/2505.04364</link>
<guid>https://arxiv.org/abs/2505.04364</guid>
<content:encoded><![CDATA[
arXiv:2505.04364v1 Announce Type: new 
Abstract: Large Language Models (LLMs) show potential for complex reasoning, yet their capacity for emergent coordination in Multi-Agent Systems (MAS) when operating under strict constraints-such as limited local perception and communication, characteristic of natural swarms-remains largely unexplored, particularly concerning the nuances of swarm intelligence. Existing benchmarks often do not fully capture the unique challenges of decentralized coordination that arise when agents operate with incomplete spatio-temporal information. To bridge this gap, we introduce SwarmBench, a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of LLMs acting as decentralized agents. SwarmBench features five foundational MAS coordination tasks within a configurable 2D grid environment, forcing agents to rely primarily on local sensory input (k x k view) and local communication. We propose metrics for coordination effectiveness and analyze emergent group dynamics. Evaluating several leading LLMs in a zero-shot setting, we find significant performance variations across tasks, highlighting the difficulties posed by local information constraints. While some coordination emerges, results indicate limitations in robust planning and strategy formation under uncertainty in these decentralized scenarios. Assessing LLMs under swarm-like conditions is crucial for realizing their potential in future decentralized systems. We release SwarmBench as an open, extensible toolkit-built upon a customizable and scalable physical system with defined mechanical properties. It provides environments, prompts, evaluation scripts, and the comprehensive experimental datasets generated, aiming to foster reproducible research into LLM-based MAS coordination and the theoretical underpinnings of Embodied MAS. Our code repository is available at https://github.com/x66ccff/swarmbench.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Data Analytics: A Scoping Literature Review and Directions for Future Research</title>
<link>https://arxiv.org/abs/2505.04403</link>
<guid>https://arxiv.org/abs/2505.04403</guid>
<content:encoded><![CDATA[
arXiv:2505.04403v1 Announce Type: new 
Abstract: Blockchain technology has rapidly expanded beyond its original use in cryptocurrencies to a broad range of applications, creating vast amounts of immutable, decentralized data. As blockchain adoption grows, so does the need for advanced data analytics techniques to extract insights for business intelligence, fraud detection, financial analysis and many more. While previous research has examined specific aspects of blockchain data analytics, such as transaction patterns, illegal activity detection, and data management, there remains a lack of comprehensive reviews that explore the full scope of blockchain data analytics. This study addresses this gap through a scoping literature review, systematically mapping the existing research landscape, identifying key topics, and highlighting emerging trends. Using established methodologies for literature reviews, we analyze 466 publications, clustering them into six major research themes: illegal activity detection, data management, financial analysis, user analysis, community detection, and mining analysis. Our findings reveal a strong focus on detecting illicit activities and financial applications, while holistic business intelligence use cases remain underexplored. This review provides a structured overview of blockchain data analytics, identifying research gaps and proposing future directions to enhance the fields impact.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pool Formation in Oceanic Games: Shapley Value and Proportional Sharing</title>
<link>https://arxiv.org/abs/2505.04422</link>
<guid>https://arxiv.org/abs/2505.04422</guid>
<content:encoded><![CDATA[
arXiv:2505.04422v1 Announce Type: new 
Abstract: We study a game-theoretic model for pool formation in Proof of Stake blockchain protocols. In such systems, stakeholders can form pools as a means of obtaining regular rewards from participation in ledger maintenance, with the power of each pool being dependent on its collective stake. The question we are interested in is the design of mechanisms that suitably split rewards among pool members and achieve favorable properties in the resulting pool configuration. With this in mind, we initiate a non-cooperative game-theoretic analysis of the well known Shapley value scheme from cooperative game theory into the context of blockchains. In particular, we focus on the oceanic model of games, proposed by Milnor and Shapley (1978), which is suitable for populations where a small set of large players coexists with a big mass of rather small, negligible players. This provides an appropriate level of abstraction for pool formation processes among the stakeholders. We provide comparisons between the Shapley mechanism and the more standard proportional scheme, in terms of attained decentralization, via a Price of Stability analysis and in terms of susceptibility to Sybil attacks, i.e., the strategic splitting of a players' stake with the intention of participating in multiple pools for increased profit. Interestingly, while the widely deployed proportional scheme appears to have certain advantages, the Shapley value scheme, which rewards higher the most pivotal players, emerges as a competitive alternative, by being able to bypass some of the downsides of proportional sharing, while also not being far from optimal guarantees w.r.t. decentralization. Finally, we complement our study with some variations of proportional sharing, where the profit is split in proportion to a superadditive or a subadditive function of the stake, showing that the Shapley value scheme still maintains the same advantages.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Latency Price of Threshold Cryptosystem in Blockchains</title>
<link>https://arxiv.org/abs/2407.12172</link>
<guid>https://arxiv.org/abs/2407.12172</guid>
<content:encoded><![CDATA[
arXiv:2407.12172v2 Announce Type: replace 
Abstract: Threshold cryptography is essential for many blockchain protocols. For example, many protocols rely on threshold common coin to implement asynchronous consensus, leader elections, and provide support for randomized applications. Similarly, threshold decryption and threshold time-lock puzzles are often necessary for privacy.
  In this paper, we study the interplay between threshold cryptography and a class of blockchains that use Byzantine-fault tolerant (BFT) consensus protocols with a focus on latency. More specifically, we focus on blockchain-native threshold cryptosystem, where the blockchain validators seek to run a threshold cryptographic protocol once for every block with the block contents as an input to the threshold cryptographic protocol. All existing approaches for blockchain-native threshold cryptosystems introduce a latency overhead of at least one message delay for running the threshold cryptographic protocol. In this paper, we first propose a mechanism to eliminate this overhead for blockchain-native threshold cryptosystems with tight thresholds, i.e., in threshold cryptographic protocols where the secrecy and reconstruction thresholds are the same. However, many real-world proof-of-stake-based blockchain-native threshold cryptosystems rely on ramp thresholds, where reconstruction thresholds are strictly greater than secrecy thresholds. For these blockchains, we formally demonstrate that the additional delay is unavoidable. We then introduce a mechanism to minimize this delay in the optimistic case. We implement our optimistic protocol for the proof-of-stake distributed randomness scheme on the Aptos blockchain. Our measurements from the Aptos mainnet show that the optimistic approach reduces latency overhead by 71%.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy, Scalability, Data and Security in Massive IoT: Current Landscape and Future Directions</title>
<link>https://arxiv.org/abs/2505.03036</link>
<guid>https://arxiv.org/abs/2505.03036</guid>
<content:encoded><![CDATA[
arXiv:2505.03036v1 Announce Type: new 
Abstract: The Massive Internet of Things (MIoT) envisions an interconnected ecosystem of billions of devices, fundamentally transforming diverse sectors such as healthcare, smart cities, transportation, agriculture, and energy management. However, the vast scale of MIoT introduces significant challenges, including network scalability, efficient data management, energy conservation, and robust security mechanisms. This paper presents a thorough review of existing and emerging MIoT technologies designed to address these challenges, including Low-Power Wide-Area Networks (LPWAN), 5G/6G capabilities, edge and fog computing architectures, and hybrid access methodologies. We further investigate advanced strategies such as AI-driven resource allocation, federated learning for privacy-preserving analytics, and decentralized security frameworks using blockchain. Additionally, we analyze sustainable practices, emphasizing energy harvesting and integrating green technologies to reduce environmental impact. Through extensive comparative analysis, this study identifies critical innovations and architectural adaptations required to support efficient, resilient, and scalable MIoT deployments. Key insights include the role of network slicing and intelligent resource management for scalability, adaptive protocols for real-time data handling, and lightweight AI models suited to the constraints of MIoT devices. This research ultimately contributes to a deeper understanding of how MIoT systems can evolve to meet the growing demand for seamless, reliable connectivity while prioritizing sustainability, security, and performance across diverse applications. Our findings serve as a roadmap for future advancements, underscoring the potential of MIoT to support a globally interconnected, intelligent infrastructure.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case</title>
<link>https://arxiv.org/abs/2505.03196</link>
<guid>https://arxiv.org/abs/2505.03196</guid>
<content:encoded><![CDATA[
arXiv:2505.03196v1 Announce Type: new 
Abstract: Large Language Models (LLMs) demonstrate strong potential across a variety of tasks in communications and networking due to their advanced reasoning capabilities. However, because different LLMs have different model structures and are trained using distinct corpora and methods, they may offer varying optimization strategies for the same network issues. Moreover, the limitations of an individual LLM's training data, aggravated by the potential maliciousness of its hosting device, can result in responses with low confidence or even bias. To address these challenges, we propose a blockchain-enabled collaborative framework that connects multiple LLMs into a Trustworthy Multi-LLM Network (MultiLLMN). This architecture enables the cooperative evaluation and selection of the most reliable and high-quality responses to complex network optimization problems. Specifically, we begin by reviewing related work and highlighting the limitations of existing LLMs in collaboration and trust, emphasizing the need for trustworthiness in LLM-based systems. We then introduce the workflow and design of the proposed Trustworthy MultiLLMN framework. Given the severity of False Base Station (FBS) attacks in B5G and 6G communication systems and the difficulty of addressing such threats through traditional modeling techniques, we present FBS defense as a case study to empirically validate the effectiveness of our approach. Finally, we outline promising future research directions in this emerging area.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Airdrop Games</title>
<link>https://arxiv.org/abs/2505.03428</link>
<guid>https://arxiv.org/abs/2505.03428</guid>
<content:encoded><![CDATA[
arXiv:2505.03428v1 Announce Type: new 
Abstract: Launching a new blockchain system or application is frequently facilitated by a so called airdrop, where the system designer chooses a pre-existing set of potentially interested parties and allocates newly minted tokens to them with the expectation that they will participate in the system - such engagement, especially if it is of significant level, facilitates the system and raises its value and also the value of its newly minted token, hence benefiting the airdrop recipients. A number of challenging questions befuddle designers in this setting, such as how to choose the set of interested parties and how to allocate tokens to them. To address these considerations we put forward a game-theoretic model for such airdrop games. Our model can be used to guide the designer's choices based on the way the system's value depends on participation (modeled by a ''technology function'' in our framework) and the costs that participants incur. We identify both bad and good equilibria and identify the settings and the choices that can be made where the designer can influence the players towards good equilibria in an expedient manner.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Small-Scale-Fading-Aware Resource Allocation in Wireless Federated Learning</title>
<link>https://arxiv.org/abs/2505.03533</link>
<guid>https://arxiv.org/abs/2505.03533</guid>
<content:encoded><![CDATA[
arXiv:2505.03533v1 Announce Type: new 
Abstract: Judicious resource allocation can effectively enhance federated learning (FL) training performance in wireless networks by addressing both system and statistical heterogeneity. However, existing strategies typically rely on block fading assumptions, which overlooks rapid channel fluctuations within each round of FL gradient uploading, leading to a degradation in FL training performance. Therefore, this paper proposes a small-scale-fading-aware resource allocation strategy using a multi-agent reinforcement learning (MARL) framework. Specifically, we establish a one-step convergence bound of the FL algorithm and formulate the resource allocation problem as a decentralized partially observable Markov decision process (Dec-POMDP), which is subsequently solved using the QMIX algorithm. In our framework, each client serves as an agent that dynamically determines spectrum and power allocations within each coherence time slot, based on local observations and a reward derived from the convergence analysis. The MARL setting reduces the dimensionality of the action space and facilitates decentralized decision-making, enhancing the scalability and practicality of the solution. Experimental results demonstrate that our QMIX-based resource allocation strategy significantly outperforms baseline methods across various degrees of statistical heterogeneity. Additionally, ablation studies validate the critical importance of incorporating small-scale fading dynamics, highlighting its role in optimizing FL performance.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning Scheduling to Support Low Latency in Teleoperated Driving</title>
<link>https://arxiv.org/abs/2505.03558</link>
<guid>https://arxiv.org/abs/2505.03558</guid>
<content:encoded><![CDATA[
arXiv:2505.03558v1 Announce Type: new 
Abstract: The teleoperated driving (TD) scenario comes with stringent Quality of Service (QoS) communication constraints, especially in terms of end-to-end (E2E) latency and reliability. In this context, Predictive Quality of Service (PQoS), possibly combined with Reinforcement Learning (RL) techniques, is a powerful tool to estimate QoS degradation and react accordingly. For example, an intelligent agent can be trained to select the optimal compression configuration for automotive data, and reduce the file size whenever QoS conditions deteriorate. However, compression may inevitably compromise data quality, with negative implications for the TD application. An alternative strategy involves operating at the Radio Access Network (RAN) level to optimize radio parameters based on current network conditions, while preserving data quality. In this paper, we propose Multi-Agent Reinforcement Learning (MARL) scheduling algorithms, based on Proximal Policy Optimization (PPO), to dynamically and intelligently allocate radio resources to minimize E2E latency in a TD scenario. We evaluate two training paradigms, i.e., decentralized learning with local observations (IPPO) vs. centralized aggregation (MAPPO), in conjunction with two resource allocation strategies, i.e., proportional allocation (PA) and greedy allocation (GA). We prove via ns-3 simulations that MAPPO, combined with GA, achieves the best results in terms of latency, especially as the number of vehicles increases.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation</title>
<link>https://arxiv.org/abs/2505.03586</link>
<guid>https://arxiv.org/abs/2505.03586</guid>
<content:encoded><![CDATA[
arXiv:2505.03586v1 Announce Type: new 
Abstract: In real-world multi-agent systems (MASs), observation delays are ubiquitous, preventing agents from making decisions based on the environment's true state. An individual agent's local observation often consists of multiple components from other agents or dynamic entities in the environment. These discrete observation components with varying delay characteristics pose significant challenges for multi-agent reinforcement learning (MARL). In this paper, we first formulate the decentralized stochastic individual delay partially observable Markov decision process (DSID-POMDP) by extending the standard Dec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL training framework for addressing stochastic individual delays, along with recommended implementations for its constituent modules. We implement the DSID-POMDP's observation generation pattern using standard MARL benchmarks, including MPE and SMAC. Experiments demonstrate that baseline MARL methods suffer severe performance degradation under fixed and unfixed delays. The RDC-enhanced approach mitigates this issue, remarkably achieving ideal delay-free performance in certain delay scenarios while maintaining generalization capability. Our work provides a novel perspective on multi-agent delayed observation problems and offers an effective solution framework.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic load balancing for cloud systems under heterogeneous setup delays</title>
<link>https://arxiv.org/abs/2505.03596</link>
<guid>https://arxiv.org/abs/2505.03596</guid>
<content:encoded><![CDATA[
arXiv:2505.03596v1 Announce Type: new 
Abstract: We consider a distributed cloud service deployed at a set of distinct server pools. Arriving jobs are classified into heterogeneous types, in accordance with their setup times which are differentiated at each of the pools. A dispatcher for each job type controls the balance of load between pools, based on decentralized feedback. The system of rates and queues is modeled by a fluid differential equation system, and analyzed via convex optimization. A first, myopic policy is proposed, based on task delay-to-service. Under a simplified dynamic fluid queue model, we prove global convergence to an equilibrium point which minimizes the mean setup time; however queueing delays are incurred with this method. A second proposal is then developed based on proximal optimization, which explicitly models the setup queue and is proved to reach an optimal equilibrium, devoid of queueing delay. Results are demonstrated through a simulation example.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$ Approach</title>
<link>https://arxiv.org/abs/2505.03719</link>
<guid>https://arxiv.org/abs/2505.03719</guid>
<content:encoded><![CDATA[
arXiv:2505.03719v1 Announce Type: cross 
Abstract: In this paper, we focus on a class of decentralized constraint-coupled optimization problem: $\min_{x_i \in \mathbb{R}^{d_i}, i \in \mathcal{I}; y \in \mathbb{R}^p}$ $\sum_{i=1}^n\left(f_i(x_i) + g_i(x_i)\right) + h(y) \ \text{s.t.} \ \sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected network of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private information of agent $i \in \mathcal{I} = \{1, \cdots, n\}$, while $h$ is public for all agents. Building on a novel dual$^2$ approach, we develop two accelerated algorithms for solving this problem: the inexact Dual$^2$ Accelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$ Accelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A can guarantee asymptotic convergence under a milder condition on $h$ compared to existing algorithms. Furthermore, linear convergence is established under additional assumptions. By employing specialized saddle-point subproblem solvers, iD2A and MiD2A attain significantly lower communication and computational complexities than existing algorithms across various scenarios. Finally, we conduct several numerical experiments to validate our theoretical results and to showcase the superior performance of iD2A and MiD2A in practice.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Nonconvex Optimization under Heavy-Tailed Noise: Normalization and Optimal Convergence</title>
<link>https://arxiv.org/abs/2505.03736</link>
<guid>https://arxiv.org/abs/2505.03736</guid>
<content:encoded><![CDATA[
arXiv:2505.03736v1 Announce Type: cross 
Abstract: Heavy-tailed noise in nonconvex stochastic optimization has garnered increasing research interest, as empirical studies, including those on training attention models, suggest it is a more realistic gradient noise condition. This paper studies first-order nonconvex stochastic optimization under heavy-tailed gradient noise in a decentralized setup, where each node can only communicate with its direct neighbors in a predefined graph. Specifically, we consider a class of heavy-tailed gradient noise that is zero-mean and has only $p$-th moment for $p \in (1, 2]$. We propose GT-NSGDm, Gradient Tracking based Normalized Stochastic Gradient Descent with momentum, that utilizes normalization, in conjunction with gradient tracking and momentum, to cope with heavy-tailed noise on distributed nodes. We show that, when the communication graph admits primitive and doubly stochastic weights, GT-NSGDm guarantees, for the \textit{first} time in the literature, that the expected gradient norm converges at an optimal non-asymptotic rate $O\big(1/T^{(p-1)/(3p-2)}\big)$, which matches the lower bound in the centralized setup. When tail index $p$ is unknown, GT-NSGDm attains a non-asymptotic rate $O\big( 1/T^{(p-1)/(2p)} \big)$ that is, for $p < 2$, topology independent and has a speedup factor $n^{1-1/p}$ in terms of the number of nodes $n$. Finally, experiments on nonconvex linear regression with tokenized synthetic data and decentralized training of language models on a real-world corpus demonstrate that GT-NSGDm is more robust and efficient than baselines.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative Transportation using Multiple Single-Rotor Robots and Decentralized Control for Unknown Payloads</title>
<link>https://arxiv.org/abs/2111.01963</link>
<guid>https://arxiv.org/abs/2111.01963</guid>
<content:encoded><![CDATA[
arXiv:2111.01963v2 Announce Type: replace 
Abstract: Cooperative transportation via multiple aerial robots has the potential to support various payloads and reduce the chances of them being dropped. Furthermore, autonomously controlled robots render the system scalable with respect to the payload. In this study, a cooperative transportation system was developed using rigidly attached single-rotor robots, and a decentralized controller was proposed to guarantee asymptotic stability of the error dynamics for unknown strictly positive real systems. A feedback controller was used to transform unstable systems into strictly positive real ones considering the shared attachment positions. First, the cooperative transportation of unknown payloads with different shapes larger than the carrier robots was investigated via numerical simulations. Second, cooperative transportation of an unknown payload (with a weight of approximately 2.7 kg and maximum length of 1.6 m) was demonstrated using eight robots, even under robot failure. Finally, the proposed system was shown to be capable of carrying an unknown payload, even if the attachment positions were not shared, that is, even if asymptotic stability was not strictly guaranteed.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scratch Team of Single-Rotor Robots and Decentralized Cooperative Transportation with Robot Failure</title>
<link>https://arxiv.org/abs/2307.00705</link>
<guid>https://arxiv.org/abs/2307.00705</guid>
<content:encoded><![CDATA[
arXiv:2307.00705v2 Announce Type: replace 
Abstract: Achieving cooperative transportation by aerial robot teams ensures flexibility regarding payloads and robustness against failures, which has garnered significant attention in recent years. This study proposes a flexible decentralized controller for robots and the shapes of payloads in a cooperative transport task using multiple single-rotor robots. The proposed controller is robust to mass and center of mass (COM) fluctuations and robot failures. Moreover, it possesses asymptotic stability against dynamics errors. Additionally, the controller supports heterogeneous single-rotor robots. Thus, robots with different specifications and deterioration may be effectively utilized for cooperative transportation. This performance is particularly effective for robot reuse. To achieve the aforementioned performance, the controller consists of a parallel structure comprising two controllers: a feedback controller, which renders the system strictly positive real, and a nonlinear controller, which renders the object asymptotic to the target. First, we confirm cooperative transportation using 8 and 10 robots for two shapes through numerical simulation. Subsequently, the cooperative transportation of a rectangle payload (with a weight of approximately 3 kg and maximum length of 1.6 m) is demonstrated using a robot team consisting of three types of robots, even under robot failure and fluctuation in the COM.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Multi-Robot Semantic Navigation Through Multimodal Chain-of-Thought Score Collaboration</title>
<link>https://arxiv.org/abs/2412.18292</link>
<guid>https://arxiv.org/abs/2412.18292</guid>
<content:encoded><![CDATA[
arXiv:2412.18292v3 Announce Type: replace 
Abstract: Understanding how humans cooperatively utilize semantic knowledge to explore unfamiliar environments and decide on navigation directions is critical for house service multi-robot systems. Previous methods primarily focused on single-robot centralized planning strategies, which severely limited exploration efficiency. Recent research has considered decentralized planning strategies for multiple robots, assigning separate planning models to each robot, but these approaches often overlook communication costs. In this work, we propose Multimodal Chain-of-Thought Co-Navigation (MCoCoNav), a modular approach that utilizes multimodal Chain-of-Thought to plan collaborative semantic navigation for multiple robots. MCoCoNav combines visual perception with Vision Language Models (VLMs) to evaluate exploration value through probabilistic scoring, thus reducing time costs and achieving stable outputs. Additionally, a global semantic map is used as a communication bridge, minimizing communication overhead while integrating observational results. Guided by scores that reflect exploration trends, robots utilize this map to assess whether to explore new frontier points or revisit history nodes. Experiments on HM3D_v0.2 and MP3D demonstrate the effectiveness of our approach. Our code is available at https://github.com/FrankZxShen/MCoCoNav.git.
]]></content:encoded>
<pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Firewall Regulatory Networks for Autonomous Cyber Defense</title>
<link>https://arxiv.org/abs/2505.01436</link>
<guid>https://arxiv.org/abs/2505.01436</guid>
<content:encoded><![CDATA[
arXiv:2505.01436v1 Announce Type: new 
Abstract: In this paper, we present the principles of designing new self-organising and autonomous management protocol to govern the dynamics of bio-inspired decentralized firewall architecture based on Biological Regularity Networks.
  The new architecture called Firewall Regulatory Networks (FRN) exhibits the following features (1) automatic rule policy configuration with provable utility-risk appetite guarantee, (2) resilient response for changing risks or new service requirements, and (3) globally optimized access control policy reconciliation. We present the FRN protocol and formalize the constraints to synthesize the undetermined components in the protocol to produce interactions that can achieve these objectives. We illustrate the feasibility of the FRN architecture in multiple case studies.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy Preserving Machine Learning Model Personalization through Federated Personalized Learning</title>
<link>https://arxiv.org/abs/2505.01788</link>
<guid>https://arxiv.org/abs/2505.01788</guid>
<content:encoded><![CDATA[
arXiv:2505.01788v1 Announce Type: new 
Abstract: The widespread adoption of Artificial Intelligence (AI) has been driven by significant advances in intelligent system research. However, this progress has raised concerns about data privacy, leading to a growing awareness of the need for privacy-preserving AI. In response, there has been a seismic shift in interest towards the leading paradigm for training Machine Learning (ML) models on decentralized data silos while maintaining data privacy, Federated Learning (FL). This research paper presents a comprehensive performance analysis of a cutting-edge approach to personalize ML model while preserving privacy achieved through Privacy Preserving Machine Learning with the innovative framework of Federated Personalized Learning (PPMLFPL). Regarding the increasing concerns about data privacy, this study evaluates the effectiveness of PPMLFPL addressing the critical balance between personalized model refinement and maintaining the confidentiality of individual user data. According to our analysis, Adaptive Personalized Cross-Silo Federated Learning with Differential Privacy (APPLE+DP) offering efficient execution whereas overall, the use of the Adaptive Personalized Cross-Silo Federated Learning with Homomorphic Encryption (APPLE+HE) algorithm for privacy-preserving machine learning tasks in federated personalized learning settings is strongly suggested. The results offer valuable insights creating it a promising scope for future advancements in the field of privacy-conscious data-driven technologies.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PQS-BFL: A Post-Quantum Secure Blockchain-based Federated Learning Framework</title>
<link>https://arxiv.org/abs/2505.01866</link>
<guid>https://arxiv.org/abs/2505.01866</guid>
<content:encoded><![CDATA[
arXiv:2505.01866v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training while preserving data privacy, but its classical cryptographic underpinnings are vulnerable to quantum attacks. This vulnerability is particularly critical in sensitive domains like healthcare. This paper introduces PQS-BFL (Post-Quantum Secure Blockchain-based Federated Learning), a framework integrating post-quantum cryptography (PQC) with blockchain verification to secure FL against quantum adversaries. We employ ML-DSA-65 (a FIPS 204 standard candidate, formerly Dilithium) signatures to authenticate model updates and leverage optimized smart contracts for decentralized validation. Extensive evaluations on diverse datasets (MNIST, SVHN, HAR) demonstrate that PQS-BFL achieves efficient cryptographic operations (average PQC sign time: 0.65 ms, verify time: 0.53 ms) with a fixed signature size of 3309 Bytes. Blockchain integration incurs a manageable overhead, with average transaction times around 4.8 s and gas usage per update averaging 1.72 x 10^6 units for PQC configurations. Crucially, the cryptographic overhead relative to transaction time remains minimal (around 0.01-0.02% for PQC with blockchain), confirming that PQC performance is not the bottleneck in blockchain-based FL. The system maintains competitive model accuracy (e.g., over 98.8% for MNIST with PQC) and scales effectively, with round times showing sublinear growth with increasing client numbers. Our open-source implementation and reproducible benchmarks validate the feasibility of deploying long-term, quantum-resistant security in practical FL systems.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents</title>
<link>https://arxiv.org/abs/2505.02077</link>
<guid>https://arxiv.org/abs/2505.02077</guid>
<content:encoded><![CDATA[
arXiv:2505.02077v1 Announce Type: new 
Abstract: Decentralized AI agents will soon interact across internet platforms, creating security challenges beyond traditional cybersecurity and AI safety frameworks. Free-form protocols are essential for AI's task generalization but enable new threats like secret collusion and coordinated swarm attacks. Network effects can rapidly spread privacy breaches, disinformation, jailbreaks, and data poisoning, while multi-agent dispersion and stealth optimization help adversaries evade oversightcreating novel persistent threats at a systemic level. Despite their critical importance, these security challenges remain understudied, with research fragmented across disparate fields including AI security, multi-agent learning, complex systems, cybersecurity, game theory, distributed systems, and technical AI governance. We introduce \textbf{multi-agent security}, a new field dedicated to securing networks of decentralized AI agents against threats that emerge or amplify through their interactionswhether direct or indirect via shared environmentswith each other, humans, and institutions, and characterize fundamental security-performance trade-offs. Our preliminary work (1) taxonomizes the threat landscape arising from interacting AI agents, (2) surveys security-performance tradeoffs in decentralized AI systems, and (3) proposes a unified research agenda addressing open challenges in designing secure agent systems and interaction environments. By identifying these gaps, we aim to guide research in this critical area to unlock the socioeconomic potential of large-scale agent deployment on the internet, foster public trust, and mitigate national security risks in critical infrastructure and defense contexts.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Grassroots Democratic Federation: Fair Governance of Large-Scale, Decentralized, Sovereign Digital Communities</title>
<link>https://arxiv.org/abs/2505.02208</link>
<guid>https://arxiv.org/abs/2505.02208</guid>
<content:encoded><![CDATA[
arXiv:2505.02208v1 Announce Type: new 
Abstract: Grassroots Democratic Federation aims to address the egalitarian formation and the fair democratic governance of large-scale, decentralized, sovereign digital communities, the size of the EU, the US, existing social networks, and even humanity at large. A grassroots democratic federation evolves via the grassroots formation of digital communities and their consensual federation. Such digital communities may form according to geography, jurisdiction, affiliations, relations, interests, or causes. Small communities (say up to 100 members) govern themselves; larger communities -- no matter how large -- are governed by a small assembly elected by sortition among its members. Earlier work on Grassroots Democratic Federation explored the fair sortition of the assemblies of a federation in a static setting: Given a federation, populate its assemblies with members satisfying ex ante and ex post fairness conditions on the participation of members of a community in its assembly, and on the representation of child communities in the assembly of their parent community.
  In practice, we expect a grassroots democratic federation to grow and evolve dynamically and in all directions -- bottom-up, top-down, and middle-out. To address that, we formally specify this dynamic setting and adapt the static fairness conditions to it: The ex post condition on the fair representation of a child community becomes a condition that must always hold; the ex ante conditions in expectation on the fair participation of an individual and on the fair representation of a child community become conditions satisfied in actuality in the limit, provided the federation structure eventually stabilizes. We then present a protocol that satisfies these fairness conditions.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)</title>
<link>https://arxiv.org/abs/2505.02279</link>
<guid>https://arxiv.org/abs/2505.02279</guid>
<content:encoded><![CDATA[
arXiv:2505.02279v1 Announce Type: new 
Abstract: Large language model (LLM)-powered autonomous agents demand robust, standardized protocols to integrate tools, share contextual data, and coordinate tasks across heterogeneous systems. Ad-hoc integrations are difficult to scale, secure, and generalize across domains. This survey examines four emerging agent communication protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP), each addressing interoperability in distinct deployment contexts. MCP provides a JSON-RPC client-server interface for secure tool invocation and typed data exchange. ACP introduces REST-native messaging via multi-part messages and asynchronous streaming to support multimodal agent responses. A2A enables peer-to-peer task outsourcing through capability-based Agent Cards, facilitating enterprise-scale workflows. ANP supports open-network agent discovery and secure collaboration using decentralized identifiers (DIDs) and JSON-LD graphs. The protocols are compared across multiple dimensions, including interaction modes, discovery mechanisms, communication patterns, and security models. Based on the comparative analysis, a phased adoption roadmap is proposed: beginning with MCP for tool access, followed by ACP for multimodal messaging, A2A for collaborative task execution, and extending to ANP for decentralized agent marketplaces. This work provides a comprehensive foundation for designing secure, interoperable, and scalable ecosystems of LLM-powered agents.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A longitudinal analysis of misinformation, polarization and toxicity on Bluesky after its public launch</title>
<link>https://arxiv.org/abs/2505.02317</link>
<guid>https://arxiv.org/abs/2505.02317</guid>
<content:encoded><![CDATA[
arXiv:2505.02317v1 Announce Type: new 
Abstract: Bluesky is a decentralized, Twitter-like social media platform that has rapidly gained popularity. Following an invite-only phase, it officially opened to the public on February 6th, 2024, leading to a significant expansion of its user base. In this paper, we present a longitudinal analysis of user activity in the two months surrounding its public launch, examining how the platform evolved due to this rapid growth. Our analysis reveals that Bluesky exhibits an activity distribution comparable to more established social platforms, yet it features a higher volume of original content relative to reshared posts and maintains low toxicity levels. We further investigate the political leanings of its user base, misinformation dynamics, and engagement in harmful conversations. Our findings indicate that Bluesky users predominantly lean left politically and tend to share high-credibility sources. After the platform's public launch, an influx of new users, particularly those posting in English and Japanese, contributed to a surge in activity. Among them, several accounts displayed suspicious behaviors, such as mass-following users and sharing content from low-credibility news sources. Some of these accounts have already been flagged as spam or suspended, suggesting that Bluesky's moderation efforts have been effective.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Moneros Decentralized P2P Exchanges: Functionality, Adoption, and Privacy Risks</title>
<link>https://arxiv.org/abs/2505.02392</link>
<guid>https://arxiv.org/abs/2505.02392</guid>
<content:encoded><![CDATA[
arXiv:2505.02392v1 Announce Type: new 
Abstract: Privacy-focused cryptocurrencies like Monero remain popular, despite increasing regulatory scrutiny that has led to their delisting from major centralized exchanges. The latter also explains the recent popularity of decentralized exchanges (DEXs) with no centralized ownership structures. These platforms typically leverage peer-to-peer (P2P) networks, promising secure and anonymous asset trading. However, questions of liability remain, and the academic literature lacks comprehensive insights into the functionality, trading activity, and privacy claims of these P2P platforms. In this paper, we provide an early systematization of the current landscape of decentralized peer-to-peer exchanges within the Monero ecosystem. We examine several recently developed DEX platforms, analyzing their popularity, functionality, architectural choices, and potential weaknesses. We further identify and report on a privacy vulnerability in the recently popularized Haveno exchange, demonstrating that certain Haveno trades could be detected, allowing transactions to be linked across the Monero and Bitcoin blockchains. We hope that our findings can nourish the discussion in the research community about more secure designs, and provide insights for regulators.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentivizing Inclusive Contributions in Model Sharing Markets</title>
<link>https://arxiv.org/abs/2505.02462</link>
<guid>https://arxiv.org/abs/2505.02462</guid>
<content:encoded><![CDATA[
arXiv:2505.02462v1 Announce Type: new 
Abstract: While data plays a crucial role in training contemporary AI models, it is acknowledged that valuable public data will be exhausted in a few years, directing the world's attention towards the massive decentralized private data. However, the privacy-sensitive nature of raw data and lack of incentive mechanism prevent these valuable data from being fully exploited. Addressing these challenges, this paper proposes inclusive and incentivized personalized federated learning (iPFL), which incentivizes data holders with diverse purposes to collaboratively train personalized models without revealing raw data. iPFL constructs a model-sharing market by solving a graph-based training optimization and incorporates an incentive mechanism based on game theory principles. Theoretical analysis shows that iPFL adheres to two key incentive properties: individual rationality and truthfulness. Empirical studies on eleven AI tasks (e.g., large language models' instruction-following tasks) demonstrate that iPFL consistently achieves the highest economic utility, and better or comparable model performance compared to baseline methods. We anticipate that our iPFL can serve as a valuable technique for boosting future AI models on decentralized private data while making everyone satisfied.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bayesian Robust Aggregation for Federated Learning</title>
<link>https://arxiv.org/abs/2505.02490</link>
<guid>https://arxiv.org/abs/2505.02490</guid>
<content:encoded><![CDATA[
arXiv:2505.02490v1 Announce Type: new 
Abstract: Federated Learning enables collaborative training of machine learning models on decentralized data. This scheme, however, is vulnerable to adversarial attacks, when some of the clients submit corrupted model updates. In real-world scenarios, the total number of compromised clients is typically unknown, with the extent of attacks potentially varying over time. To address these challenges, we propose an adaptive approach for robust aggregation of model updates based on Bayesian inference. The mean update is defined by the maximum of the likelihood marginalized over probabilities of each client to be `honest'. As a result, the method shares the simplicity of the classical average estimators (e.g., sample mean or geometric median), being independent of the number of compromised clients. At the same time, it is as effective against attacks as methods specifically tailored to Federated Learning, such as Krum. We compare our approach with other aggregation schemes in federated setting on three benchmark image classification data sets. The proposed method consistently achieves state-of-the-art performance across various attack types with static and varying number of malicious clients.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Graph-based Fingerprinting of In-browser Cryptomining</title>
<link>https://arxiv.org/abs/2505.02493</link>
<guid>https://arxiv.org/abs/2505.02493</guid>
<content:encoded><![CDATA[
arXiv:2505.02493v1 Announce Type: new 
Abstract: The decentralized and unregulated nature of cryptocurrencies, combined with their monetary value, has made them a vehicle for various illicit activities. One such activity is cryptojacking, an attack that uses stolen computing resources to mine cryptocurrencies without consent for profit. In-browser cryptojacking malware exploits high-performance web technologies like WebAssembly to mine cryptocurrencies directly within the browser without file downloads. Although existing methods for cryptomining detection report high accuracy and low overhead, they are often susceptible to various forms of obfuscation, and due to the limited variety of cryptomining scripts in the wild, standard code obfuscation methods present a natural and appealing solution to avoid detection. To address these limitations, we propose using instruction-level data-flow graphs to detect cryptomining behavior. Data-flow graphs offer detailed structural insights into a program's computations, making them suitable for characterizing proof-of-work algorithms, but they can be difficult to analyze due to their large size and susceptibility to noise and fragmentation under obfuscation. We present two techniques to simplify and compare data-flow graphs: (1) a graph simplification algorithm to reduce the computational burden of processing large and granular data-flow graphs while preserving local substructures; and (2) a subgraph similarity measure, the n-fragment inclusion score, based on fragment inclusion that is robust against noise and obfuscation. Using data-flow graphs as computation fingerprints, our detection framework PoT (Proof-of-Theft) was able to achieve high detection accuracy against standard obfuscations, outperforming existing detection methods. Moreover, PoT uses generic data-flow properties that can be applied to other platforms more susceptible to cryptojacking such as servers and data centers.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustworthy Inter-Provider Agreements in 6G Using a Privacy-Enabled Hybrid Blockchain Framework</title>
<link>https://arxiv.org/abs/2505.02513</link>
<guid>https://arxiv.org/abs/2505.02513</guid>
<content:encoded><![CDATA[
arXiv:2505.02513v1 Announce Type: new 
Abstract: Inter-provider agreements are central to 6G networks, where administrative domains must securely and dynamically share services. To address the dual need for transparency and confidentiality, we propose a privacy-enabled hybrid blockchain setup using Hyperledger Besu, integrating both public and private transaction workflows. The system enables decentralized service registration, selection, and SLA breach reporting through role-based smart contracts and privacy groups. We design and deploy a proof-of-concept implementation, evaluating performance using end-to-end latency as a key metric within privacy groups. Results show that public interactions maintain stable latency, while private transactions incur additional overhead due to off-chain coordination. The block production rate governed by IBFT 2.0 had limited impact on private transaction latency, due to encryption and peer synchronization. Lessons learned highlight design considerations for smart contract structure, validator management, and scalability patterns suitable for dynamic inter-domain collaboration. Our findings offer practical insights for deploying trustworthy agreement systems in 6G networks using privacy-enabled hybrid blockchains.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Commitment Attacks on Ethereum's Reward Mechanism</title>
<link>https://arxiv.org/abs/2407.19479</link>
<guid>https://arxiv.org/abs/2407.19479</guid>
<content:encoded><![CDATA[
arXiv:2407.19479v2 Announce Type: replace 
Abstract: Validators in permissionless, large-scale blockchains, such as Ethereum, are typically payoff-maximizing, rational actors. Ethereum relies on in-protocol incentives, like rewards for correct and timely votes, to induce honest behavior and secure the blockchain. However, external incentives, such as the block proposer's opportunity to capture maximal extractable value (MEV), may tempt validators to deviate from honest protocol participation.
  We show a series of commitment attacks on LMD GHOST, a core part of Ethereum's consensus mechanism. We demonstrate how a single adversarial block proposer can orchestrate long-range chain reorganizations by manipulating Ethereum's reward system for timely votes. These attacks disrupt the intended balance of power between proposers and voters: by leveraging credible threats, the adversarial proposer can coerce voters from previous slots into supporting blocks that conflict with the honest chain, enabling a chain reorganization.
  In response, we introduce a novel reward mechanism that restores the voters' role as a check against proposer power. Our proposed mitigation is fairer and more decentralized, not only in the context of these attacks, but also practical for implementation in Ethereum.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition</title>
<link>https://arxiv.org/abs/2408.17090</link>
<guid>https://arxiv.org/abs/2408.17090</guid>
<content:encoded><![CDATA[
arXiv:2408.17090v2 Announce Type: replace 
Abstract: Federated learning is a machine learning paradigm that enables decentralized clients to collaboratively learn a shared model while keeping all the training data local. While considerable research has focused on federated image generation, particularly Generative Adversarial Networks, Variational Autoencoders have received less attention. In this paper, we address the challenges of non-IID (independently and identically distributed) data environments featuring multiple groups of images of different types. Non-IID data distributions can lead to difficulties in maintaining a consistent latent space and can also result in local generators with disparate texture features being blended during aggregation. We thereby introduce FissionVAE that decouples the latent space and constructs decoder branches tailored to individual client groups. This method allows for customized learning that aligns with the unique data distributions of each group. Additionally, we incorporate hierarchical VAEs and demonstrate the use of heterogeneous decoder architectures within FissionVAE. We also explore strategies for setting the latent prior distributions to enhance the decoupling process. To evaluate our approach, we assemble two composite datasets: the first combines MNIST and FashionMNIST; the second comprises RGB datasets of cartoon and human faces, wild animals, marine vessels, and remote sensing images. Our experiments demonstrate that FissionVAE greatly improves generation quality on these datasets compared to baseline federated VAE models.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Formal verification in Solidity and Move: insights from a comparative analysis</title>
<link>https://arxiv.org/abs/2502.13929</link>
<guid>https://arxiv.org/abs/2502.13929</guid>
<content:encoded><![CDATA[
arXiv:2502.13929v2 Announce Type: replace 
Abstract: Formal verification plays a crucial role in making smart contracts safer, being able to find bugs or to guarantee their absence, as well as checking whether the business logic is correctly implemented. For Solidity, even though there already exist several mature verification tools, the semantical quirks of the language can make verification quite hard in practice. Move, on the other hand, has been designed with security and verification in mind, and it has been accompanied since its early stages by a formal verification tool, the Move Prover. In this paper, we investigate through a comparative analysis: 1) how the different designs of the two contract languages impact verification, and 2) what is the state-of-the-art of verification tools for the two languages, and how do they compare on three paradigmatic use cases. Our investigation is supported by an open dataset of verification tasks performed in Certora and in the Aptos Move Prover.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Coral Protocol: Open Infrastructure Connecting The Internet of Agents</title>
<link>https://arxiv.org/abs/2505.00749</link>
<guid>https://arxiv.org/abs/2505.00749</guid>
<content:encoded><![CDATA[
arXiv:2505.00749v1 Announce Type: new 
Abstract: The Coral Protocol is an open and decentralized collaboration infrastructure that enables communication, coordination, trust and payments for The Internet of Agents. It addresses the growing need for interoperability in a world where organizations are deploying multiple specialized AI agents that must work together across domains and vendors. As a foundational platform for multi-agent AI ecosystems, Coral establishes a common language and coordination framework allowing any agent to participate in complex workflows with others. Its design emphasizes broad compatibility, security, and vendor neutrality, ensuring that agent interactions are efficient and trustworthy. In particular, Coral introduces standardized messaging formats for agent communication, a modular coordination mechanism for orchestrating multi-agent tasks, and secure team formation capabilities for dynamically assembling trusted groups of agents. Together, these innovations position Coral Protocol as a cornerstone of the emerging "Internet of Agents," unlocking new levels of automation, collective intelligence, and business value through open agent collaboration.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balancing Security and Liquidity: A Time-Weighted Snapshot Framework for DAO Governance Voting</title>
<link>https://arxiv.org/abs/2505.00888</link>
<guid>https://arxiv.org/abs/2505.00888</guid>
<content:encoded><![CDATA[
arXiv:2505.00888v1 Announce Type: new 
Abstract: As new project upgrading the blockchain industry, novel forms of attack challenges developers to rethink about the design of their innovations. In the growth stage of the development, Decentralized Autonomous Organizations (DAO) introduces different approaches in managing fund through voting in governance tokens. However, relying on tokens as a weight for voting introduces opportunities for hackers to manipulate voting results through flash loan, allowing malicious proposals - fund withdrawal from DAO to hacker's wallet - to execute through the smart contract. In this research, we learned different defense mechanism against the flash loan attack, and their weakness in accessibility that compromise the security of different blockchain projects. Based on our observation, we propose a new defensing structure and apply it with cases.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Capability-Based Multi-Tenant Access Management in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2505.01048</link>
<guid>https://arxiv.org/abs/2505.01048</guid>
<content:encoded><![CDATA[
arXiv:2505.01048v1 Announce Type: new 
Abstract: We propose a capability-based access control method that leverages OAuth 2.0 and Verifiable Credentials (VCs) to share resources in crowdsourced drone services. VCs securely encode claims about entities, offering flexibility. However, standardized protocols for VCs are lacking, limiting their adoption. To address this, we integrate VCs into OAuth 2.0, creating a novel access token. This token encapsulates VCs using JSON Web Tokens (JWT) and employs JWT-based methods for proof of possession. Our method streamlines VC verification with JSON Web Signatures (JWS) requires only minor adjustments to current OAuth 2.0 systems. Furthermore, in order to increase security and efficiency in multi-tenant environments, we provide a novel protocol for VC creation that makes use of the OAuth 2.0 client credentials grant. Using VCs as access tokens enhances OAuth 2.0, supporting long-term use and efficient data management. This system aids bushfire management authorities by ensuring high availability, enhanced privacy, and improved data portability. It supports multi-tenancy, allowing drone operators to control data access policies in a decentralized environment.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Active Sybil Attack and Efficient Defense Strategy in IPFS DHT</title>
<link>https://arxiv.org/abs/2505.01139</link>
<guid>https://arxiv.org/abs/2505.01139</guid>
<content:encoded><![CDATA[
arXiv:2505.01139v1 Announce Type: new 
Abstract: The InterPlanetary File System (IPFS) is a decentralized peer-to-peer (P2P) storage that relies on Kademlia, a Distributed Hash Table (DHT) structure commonly used in P2P systems for its proved scalability. However, DHTs are known to be vulnerable to Sybil attacks, in which a single entity controls multiple malicious nodes. Recent studies have shown that IPFS is affected by a passive content eclipse attack, leveraging Sybils, in which adversarial nodes hide received indexed information from other peers, making the content appear unavailable. Fortunately, the latest mitigation strategy coupling an attack detection based on statistical tests and a wider publication strategy upon detection was able to circumvent it.
  In this work, we present a new active attack, with malicious nodes responding with semantically correct but intentionally false data, exploiting both an optimized placement of Sybils to stay below the detection threshold and an early trigger of the content discovery termination in Kubo, the main IPFS implementation. Our attack achieves to completely eclipse content on the latest Kubo release. When evaluated against the most recent known mitigation, it successfully denies access to the target content in approximately 80\% of lookup attempts.
  To address this vulnerability, we propose a new mitigation called SR-DHT-Store, which enables efficient, Sybil-resistant content publication without relying on attack detection but instead on a systematic and precise use of region-based queries, defined by a dynamically computed XOR distance to the target ID. SR-DHT-Store can be combined with other defense mechanisms resulting in a defense strategy that completely mitigates both passive and active Sybil attacks at a lower overhead, while allowing an incremental deployment.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-moderation in the decentralized era: decoding blocking behavior on Bluesky</title>
<link>https://arxiv.org/abs/2505.01174</link>
<guid>https://arxiv.org/abs/2505.01174</guid>
<content:encoded><![CDATA[
arXiv:2505.01174v1 Announce Type: new 
Abstract: Moderation and blocking behavior, both closely related to the mitigation of abuse and misinformation on social platforms, are fundamental mechanisms for maintaining healthy online communities. However, while centralized platforms typically employ top-down moderation, decentralized networks rely on users to self-regulate through mechanisms like blocking actions to safeguard their online experience. Given the novelty of the decentralized paradigm, addressing self-moderation is critical for understanding how community safety and user autonomy can be effectively balanced. This study examines user blocking on Bluesky, a decentralized social networking platform, providing a comprehensive analysis of over three months of user activity through the lens of blocking behaviour. We define profiles based on 86 features that describe user activity, content characteristics, and network interactions, addressing two primary questions: (1) Is the likelihood of a user being blocked inferable from their online behavior? and (2) What behavioral features are associated with an increased likelihood of being blocked? Our findings offer valuable insights and contribute with a robust analytical framework to advance research in moderation on decentralized social networks.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms</title>
<link>https://arxiv.org/abs/2505.01181</link>
<guid>https://arxiv.org/abs/2505.01181</guid>
<content:encoded><![CDATA[
arXiv:2505.01181v1 Announce Type: new 
Abstract: Swarming systems, such as for example multi-drone networks, excel at cooperative tasks like monitoring, surveillance, or disaster assistance in critical environments, where autonomous agents make decentralized decisions in order to fulfill team-level objectives in a robust and efficient manner. Unfortunately, team-level coordinated strategies in the wild are vulnerable to data poisoning attacks, resulting in either inaccurate coordination or adversarial behavior among the agents. To address this challenge, we contribute a framework that investigates the effects of such data poisoning attacks, using explainable AI methods. We model the interaction among agents using evolutionary intelligence, where an optimal coalition strategically emerges to perform coordinated tasks. Then, through a rigorous evaluation, the swarm model is systematically poisoned using data manipulation attacks. We showcase the applicability of explainable AI methods to quantify the effects of poisoning on the team strategy and extract footprint characterizations that enable diagnosing. Our findings indicate that when the model is poisoned above 10%, non-optimal strategies resulting in inefficient cooperation can be identified.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Secured Triad of IoT, Machine Learning, and Blockchain for Crop Forecasting in Agriculture</title>
<link>https://arxiv.org/abs/2505.01196</link>
<guid>https://arxiv.org/abs/2505.01196</guid>
<content:encoded><![CDATA[
arXiv:2505.01196v1 Announce Type: new 
Abstract: To improve crop forecasting and provide farmers with actionable data-driven insights, we propose a novel approach integrating IoT, machine learning, and blockchain technologies. Using IoT, real-time data from sensor networks continuously monitor environmental conditions and soil nutrient levels, significantly improving our understanding of crop growth dynamics. Our study demonstrates the exceptional accuracy of the Random Forest model, achieving a 99.45\% accuracy rate in predicting optimal crop types and yields, thereby offering precise crop projections and customized recommendations. To ensure the security and integrity of the sensor data used for these forecasts, we integrate the Ethereum blockchain, which provides a robust and secure platform. This ensures that the forecasted data remain tamper-proof and reliable. Stakeholders can access real-time and historical crop projections through an intuitive online interface, enhancing transparency and facilitating informed decision-making. By presenting multiple predicted crop scenarios, our system enables farmers to optimize production strategies effectively. This integrated approach promises significant advances in precision agriculture, making crop forecasting more accurate, secure, and user-friendly.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Micro-Patterns in Solidity Code</title>
<link>https://arxiv.org/abs/2505.01282</link>
<guid>https://arxiv.org/abs/2505.01282</guid>
<content:encoded><![CDATA[
arXiv:2505.01282v1 Announce Type: new 
Abstract: Solidity is the predominant programming language for blockchain-based smart contracts, and its characteristics pose significant challenges for code analysis and maintenance. Traditional software analysis approaches, while effective for conventional programming languages, often fail to address Solidity-specific features such as gas optimization and security constraints.
  This paper introduces micro-patterns - recurring, small-scale design structures that capture key behavioral and structural peculiarities specific to a language - for Solidity language and demonstrates their value in understanding smart contract development practices. We identified 18 distinct micro-patterns organized in five categories (Security, Functional, Optimization, Interaction, and Feedback), detailing their characteristics to enable automated detection.
  To validate this proposal, we analyzed a dataset of 23258 smart contracts from five popular blockchains (Ethereum, Polygon, Arbitrum, Fantom and Optimism). Our analysis reveals widespread adoption of micro-patterns, with 99% of contracts implementing at least one pattern and an average of 2.76 patterns per contract. The Storage Saver pattern showed the highest adoption (84.62% mean coverage), while security patterns demonstrated platform-specific adoption rates. Statistical analysis revealed significant platform-specific differences in pattern adoption, particularly in Borrower, Implementer, and Storage Optimization patterns.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios</title>
<link>https://arxiv.org/abs/2505.00091</link>
<guid>https://arxiv.org/abs/2505.00091</guid>
<content:encoded><![CDATA[
arXiv:2505.00091v1 Announce Type: new 
Abstract: With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV) swarms to perform complex tasks in urban environments, system design now faces major challenges, including efficient semantic understanding, flexible task planning, and the ability to dynamically adjust coordination strategies in response to evolving environmental conditions and continuously changing task requirements. To address the limitations of existing approaches, this paper proposes coordination field agentic system for coordinating heterogeneous UAV swarms in complex urban scenarios. In this system, large language models (LLMs) is responsible for interpreting high-level human instructions and converting them into executable commands for the UAV swarms, such as patrol and target tracking. Subsequently, a Coordination field mechanism is proposed to guide UAV motion and task selection, enabling decentralized and adaptive allocation of emergent tasks. A total of 50 rounds of comparative testing were conducted across different models in a 2D simulation space to evaluate their performance. Experimental results demonstrate that the proposed system achieves superior performance in terms of task coverage, response time, and adaptability to dynamic changes.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders</title>
<link>https://arxiv.org/abs/2505.00216</link>
<guid>https://arxiv.org/abs/2505.00216</guid>
<content:encoded><![CDATA[
arXiv:2505.00216v1 Announce Type: new 
Abstract: Most industry-standard generative AIs and feature encoders are proprietary, offering only black-box access: their outputs are observable, but their internal parameters and architectures remain hidden from the end-user. This black-box access is especially limiting when constructing mixture-of-expert type ensemble models since the user cannot optimize each proprietary AI's internal parameters. Our problem naturally lends itself to a non-competitive game-theoretic lens where each proprietary AI (agent) is inherently competing against the other AI agents, with this competition arising naturally due to their obliviousness of the AI's to their internal structure. In contrast, the user acts as a central planner trying to synchronize the ensemble of competing AIs.
  We show the existence of the unique Nash equilibrium in the online setting, which we even compute in closed-form by eliciting a feedback mechanism between any given time series and the sequence generated by each (proprietary) AI agent. Our solution is implemented as a decentralized, federated-learning algorithm in which each agent optimizes their structure locally on their machine without ever releasing any internal structure to the others. We obtain refined expressions for pre-trained models such as transformers, random feature models, and echo-state networks. Our ``proprietary federated learning'' algorithm is implemented on a range of real-world and synthetic time-series benchmarks. It achieves orders-of-magnitude improvements in predictive accuracy over natural benchmarks, of which there are surprisingly few due to this natural problem still being largely unexplored.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach</title>
<link>https://arxiv.org/abs/2505.00368</link>
<guid>https://arxiv.org/abs/2505.00368</guid>
<content:encoded><![CDATA[
arXiv:2505.00368v1 Announce Type: new 
Abstract: Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces challenges in system architecture, planning, task management, and execution. Traditional architectural approaches struggle with scalability, adaptability, and seamless resource integration within dynamic and complex environments. This paper presents an intelligent holonic architecture that incorporates Large Language Model (LLM) to manage the complexities of UAM. Holons function semi autonomously, allowing for real time coordination among air taxis, ground transport, and vertiports. LLMs process natural language inputs, generate adaptive plans, and manage disruptions such as weather changes or airspace closures.Through a case study of multimodal transportation with electric scooters and air taxis, we demonstrate how this architecture enables dynamic resource allocation, real time replanning, and autonomous adaptation without centralized control, creating more resilient and efficient urban transportation networks. By advancing decentralized control and AI driven adaptability, this work lays the groundwork for resilient, human centric UAM ecosystems, with future efforts targeting hybrid AI integration and real world validation.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Retrieval-Augmented Generation</title>
<link>https://arxiv.org/abs/2505.00443</link>
<guid>https://arxiv.org/abs/2505.00443</guid>
<content:encoded><![CDATA[
arXiv:2505.00443v1 Announce Type: new 
Abstract: As large language models (LLMs) become increasingly adopted on edge devices, Retrieval-Augmented Generation (RAG) is gaining prominence as a solution to address factual deficiencies and hallucinations by integrating external knowledge. However, centralized RAG architectures face significant challenges in data privacy and scalability. For instance, smart healthcare services often rely on collecting sensitive patient data and building a centralized knowledge base to provide better diagnosis and treatment advice, while privacy concerns significantly impede this process. Besides, maintaining a comprehensive and continuously updated knowledge base is costly, particularly in response to regional epidemics and rapidly mutating viruses. To address these challenges, this paper introduces Distributed Retrieval-Augmented Generation (DRAG), a novel framework that improves data privacy by eliminating the need for a centralized knowledge base and restoring data control to owners. DRAG incorporates a Topic-Aware Random Walk (TARW) algorithm that leverages LLMs to extract query topics and facilitate targeted peer discovery within a peer-to-peer network, enabling efficient knowledge retrieval in decentralized environments. Extensive experiments across three diverse datasets and LLMs demonstrate that DRAG with TARW achieves near-centralized RAG performance by using half as many messages as flooding. The code is available at https://github.com/xuchenhao001/DRAG.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Vulnerability Disclosure via Permissioned Blockchain: A Secure, Transparent Alternative to Centralized CVE Management</title>
<link>https://arxiv.org/abs/2505.00480</link>
<guid>https://arxiv.org/abs/2505.00480</guid>
<content:encoded><![CDATA[
arXiv:2505.00480v1 Announce Type: new 
Abstract: This paper proposes a decentralized, blockchain-based system for the publication of Common Vulnerabilities and Exposures (CVEs), aiming to mitigate the limitations of the current centralized model primarily overseen by MITRE. The proposed architecture leverages a permissioned blockchain, wherein only authenticated CVE Numbering Authorities (CNAs) are authorized to submit entries. This ensures controlled write access while preserving public transparency. By incorporating smart contracts, the system supports key features such as embargoed disclosures and decentralized governance. We evaluate the proposed model in comparison with existing practices, highlighting its advantages in transparency, trust decentralization, and auditability. A prototype implementation using Hyperledger Fabric is presented to demonstrate the feasibility of the approach, along with a discussion of its implications for the future of vulnerability disclosure.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework for Equitable Music Education in the Global South</title>
<link>https://arxiv.org/abs/2505.00550</link>
<guid>https://arxiv.org/abs/2505.00550</guid>
<content:encoded><![CDATA[
arXiv:2505.00550v1 Announce Type: new 
Abstract: The rapid expansion of digital technologies has transformed educational landscapes worldwide, yet significant infrastructural and cultural challenges persist in the Global South. This paper introduces a low-latency JackTrip framework designed to bridge both the cultural and digital divides in music education. By leveraging an open-source, UDP-based audio streaming protocol originally developed at Stanford's CCRMA, the framework is tailored to address technical constraints such as intermittent connectivity, limited bandwidth, and high latency that characterize many rural and underserved regions. The study systematically compares the performance of JackTrip with conventional platforms like Zoom, demonstrating that JackTrip achieves sub-30~ms latency under simulated low-resource conditions while preserving the intricate audio details essential for non-Western musical traditions. Spectral analysis confirms that JackTrip's superior handling of microtonal scales, complex rhythms, and harmonic textures provides a culturally authentic medium for real-time ensemble performance and music education. These findings underscore the transformative potential of decentralized, edge-computing solutions in empowering educators and musicians across the Global South, promoting both technological equity and cultural preservation.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RevealNet: Distributed Traffic Correlation for Attack Attribution on Programmable Networks</title>
<link>https://arxiv.org/abs/2505.00618</link>
<guid>https://arxiv.org/abs/2505.00618</guid>
<content:encoded><![CDATA[
arXiv:2505.00618v1 Announce Type: new 
Abstract: Network attackers have increasingly resorted to proxy chains, VPNs, and anonymity networks to conceal their activities. To tackle this issue, past research has explored the applicability of traffic correlation techniques to perform attack attribution, i.e., to identify an attacker's true network location. However, current traffic correlation approaches rely on well-provisioned and centralized systems that ingest flows from multiple network probes to compute correlation scores. Unfortunately, this makes correlation efforts scale poorly for large high-speed networks.
  In this paper, we propose RevealNet, a decentralized framework for attack attribution that orchestrates a fleet of P4-programmable switches to perform traffic correlation. RevealNet builds on a set of correlation primitives inspired by prior work on computing and comparing flow sketches -- compact summaries of flows' key characteristics -- to enable efficient, distributed, in-network traffic correlation. Our evaluation suggests that RevealNet achieves comparable accuracy to centralized attack attribution systems while significantly reducing both the computational complexity and bandwidth overheads imposed by correlation tasks.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AMM-based DEX on the XRP Ledger</title>
<link>https://arxiv.org/abs/2312.13749</link>
<guid>https://arxiv.org/abs/2312.13749</guid>
<content:encoded><![CDATA[
arXiv:2312.13749v4 Announce Type: replace 
Abstract: Automated Market Maker (AMM)-based Decentralized Exchanges (DEXs) are crucial in Decentralized Finance (DeFi), but Ethereum implementations suffer from high transaction costs and price synchronization challenges. To address these limitations, we compare the XRP Ledger (XRPL)-AMM-Decentralized Exchange (DEX), a protocol-level implementation, against a Generic AMM-based DEX (G-AMM-DEX) on Ethereum, akin to Uniswap's V2 AMM implementation, through agent-based simulations using real market data and multiple volatility scenarios generated via Geometric Brownian Motion (GBM). Results demonstrate that the XRPL-AMM-DEX achieves superior price synchronization, reduced slippage, and improved returns due to XRPL's lower fees and shorter block times, with benefits amplifying during market volatility. The integrated Continuous Auction Mechanism (CAM) further mitigates impermanent loss by redistributing arbitrage value to Liquidity Providers (LPs). To the best of our knowledge, this study represents the first comparative analysis between protocol-level and smart contract AMM-based DEX implementations and the first agent-based simulation validating theoretical auction mechanisms for AMM-based DEXs.
]]></content:encoded>
<pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain</title>
<link>https://arxiv.org/abs/2504.21043</link>
<guid>https://arxiv.org/abs/2504.21043</guid>
<content:encoded><![CDATA[
arXiv:2504.21043v1 Announce Type: new 
Abstract: Large language models (LLMs) excel at generating code from natural language instructions, yet they often lack an understanding of security vulnerabilities. This limitation makes it difficult for LLMs to avoid security risks in generated code, particularly in high-security programming tasks such as smart contract development for blockchain. Researchers have attempted to enhance the vulnerability awareness of these models by training them to differentiate between vulnerable and fixed code snippets. However, this approach relies heavily on manually labeled vulnerability data, which is only available for popular languages like Python and C++. For low-resource languages like Solidity, used in smart contracts, large-scale annotated datasets are scarce and difficult to obtain. To address this challenge, we introduce CodeBC, a code generation model specifically designed for generating secure smart contracts in blockchain. CodeBC employs a three-stage fine-tuning approach based on CodeLlama, distinguishing itself from previous methods by not relying on pairwise vulnerability location annotations. Instead, it leverages vulnerability and security tags to teach the model the differences between vulnerable and secure code. During the inference phase, the model leverages security tags to generate secure and robust code. Experimental results demonstrate that CodeBC outperforms baseline models in terms of BLEU, CodeBLEU, and compilation pass rates, while significantly reducing vulnerability rates. These findings validate the effectiveness and cost-efficiency of our three-stage fine-tuning strategy, making CodeBC a promising solution for generating secure smart contract code.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Resources Allocation Optimization: A Survey</title>
<link>https://arxiv.org/abs/2504.21048</link>
<guid>https://arxiv.org/abs/2504.21048</guid>
<content:encoded><![CDATA[
arXiv:2504.21048v1 Announce Type: new 
Abstract: Multi-Agent Reinforcement Learning (MARL) has become a powerful framework for numerous real-world applications, modeling distributed decision-making and learning from interactions with complex environments. Resource Allocation Optimization (RAO) benefits significantly from MARL's ability to tackle dynamic and decentralized contexts. MARL-based approaches are increasingly applied to RAO challenges across sectors playing pivotal roles to Industry 4.0 developments. This survey provides a comprehensive review of recent MARL algorithms for RAO, encompassing core concepts, classifications, and a structured taxonomy. By outlining the current research landscape and identifying primary challenges and future directions, this survey aims to support researchers and practitioners in leveraging MARL's potential to advance resource allocation solutions.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization</title>
<link>https://arxiv.org/abs/2504.21063</link>
<guid>https://arxiv.org/abs/2504.21063</guid>
<content:encoded><![CDATA[
arXiv:2504.21063v1 Announce Type: new 
Abstract: Federated domain generalization (FedDG) aims to learn a globally generalizable model from decentralized clients with heterogeneous data while preserving privacy. Recent studies have introduced prompt learning to adapt vision-language models (VLMs) in FedDG by learning a single global prompt. However, such a one-prompt-fits-all learning paradigm typically leads to performance degradation on personalized samples. Although the mixture of experts (MoE) offers a promising solution for specialization, existing MoE-based methods suffer from coarse image-level expert assignment and high communication costs from parameterized routers. To address these limitations, we propose TRIP, a Token-level prompt mixture with parameter-free routing framework for FedDG, which treats multiple prompts as distinct experts. Unlike existing image-level routing designs, TRIP assigns different tokens within an image to specific experts. To ensure communication efficiency, TRIP incorporates a parameter-free routing mechanism based on token clustering and optimal transport. The instance-specific prompt is then synthesized by aggregating experts, weighted by the number of tokens assigned to each. Additionally, TRIP develops an unbiased learning strategy for prompt experts, leveraging the VLM's zero-shot generalization capability. Extensive experiments across four benchmarks demonstrate that TRIP achieves optimal generalization results, with communication of only 1K parameters per round. Our code is available at https://github.com/GongShuai8210/TRIP.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Multi-agent Communication Based on Decentralization-Oriented Adversarial Training</title>
<link>https://arxiv.org/abs/2504.21278</link>
<guid>https://arxiv.org/abs/2504.21278</guid>
<content:encoded><![CDATA[
arXiv:2504.21278v1 Announce Type: new 
Abstract: In typical multi-agent reinforcement learning (MARL) problems, communication is important for agents to share information and make the right decisions. However, due to the complexity of training multi-agent communication, existing methods often fall into the dilemma of local optimization, which leads to the concentration of communication in a limited number of channels and presents an unbalanced structure. Such unbalanced communication policy are vulnerable to abnormal conditions, where the damage of critical communication channels can trigger the crash of the entire system. Inspired by decentralization theory in sociology, we propose DMAC, which enhances the robustness of multi-agent communication policies by retraining them into decentralized patterns. Specifically, we train an adversary DMAC\_Adv which can dynamically identify and mask the critical communication channels, and then apply the adversarial samples generated by DMAC\_Adv to the adversarial learning of the communication policy to force the policy in exploring other potential communication schemes and transition to a decentralized structure. As a training method to improve robustness, DMAC can be fused with any learnable communication policy algorithm. The experimental results in two communication policies and four multi-agent tasks demonstrate that DMAC achieves higher improvement on robustness and performance of communication policy compared with two state-of-the-art and commonly-used baselines. Also, the results demonstrate that DMAC can achieve decentralized communication structure with acceptable communication cost.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MagicCraft: Natural Language-Driven Generation of Dynamic and Interactive 3D Objects for Commercial Metaverse Platforms</title>
<link>https://arxiv.org/abs/2504.21332</link>
<guid>https://arxiv.org/abs/2504.21332</guid>
<content:encoded><![CDATA[
arXiv:2504.21332v1 Announce Type: new 
Abstract: Metaverse platforms are rapidly evolving to provide immersive spaces for user interaction and content creation. However, the generation of dynamic and interactive 3D objects remains challenging due to the need for advanced 3D modeling and programming skills. To address this challenge, we present MagicCraft, a system that generates functional 3D objects from natural language prompts for metaverse platforms. MagicCraft uses generative AI models to manage the entire content creation pipeline: converting user text descriptions into images, transforming images into 3D models, predicting object behavior, and assigning necessary attributes and scripts. It also provides an interactive interface for users to refine generated objects by adjusting features such as orientation, scale, seating positions, and grip points.
  Implemented on Cluster, a commercial metaverse platform, MagicCraft was evaluated by 7 expert CG designers and 51 general users. Results show that MagicCraft significantly reduces the time and skill required to create 3D objects. Users with no prior experience in 3D modeling or programming successfully created complex, interactive objects and deployed them in the metaverse. Expert feedback highlighted the system's potential to improve content creation workflows and support rapid prototyping. By integrating AI-generated content into metaverse platforms, MagicCraft makes 3D content creation more accessible.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Security Analysis and Implementation of Cryptocurrency Systems on Blockchain 2.0</title>
<link>https://arxiv.org/abs/2504.21367</link>
<guid>https://arxiv.org/abs/2504.21367</guid>
<content:encoded><![CDATA[
arXiv:2504.21367v1 Announce Type: new 
Abstract: Blockchain technology has set off a wave of decentralization in the world since its birth. The trust system constructed by blockchain technology based on cryptography algorithm and computing power provides a practical and powerful solution to solve the trust problem in human society. In order to make more convenient use of the characteristics of blockchain and build applications on it, smart contracts appear. By defining some trigger automatic execution contracts, the application space of blockchain is expanded and the foundation for the rapid development of blockchain is laid. This is blockchain 2.0. However, the programmability of smart contracts also introduces vulnerabilities. In order to cope with the insufficient security guarantee of high-value application networks running on blockchain 2.0 and smart contracts, this article will be represented by Ethereum to introduce the technical details of understanding blockchain 2.0 and the operation principle of contract virtual machines, and explain how cryptocurrencies based on blockchain 2.0 are constructed and operated. The common security problems and solutions are also discussed. Based on relevant research and on-chain practice, this paper provides a complete and comprehensive perspective to understanding cryptocurrency technology based on blockchain 2.0 and provides a reference for building more secure cryptocurrency contracts.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tolerating Disasters with Hierarchical Consensus</title>
<link>https://arxiv.org/abs/2504.21410</link>
<guid>https://arxiv.org/abs/2504.21410</guid>
<content:encoded><![CDATA[
arXiv:2504.21410v1 Announce Type: new 
Abstract: Geo-replication provides disaster recovery after catastrophic accidental failures or attacks, such as fires, blackouts or denial-of-service attacks to a data center or region. Naturally distributed data structures, such as Blockchains, when well designed, are immune against such disruptions, but they also benefit from leveraging locality. In this work, we consolidate the performance of geo-replicated consensus by leveraging novel insights about hierarchical consensus and a construction methodology that allows creating novel protocols from existing building blocks. In particular we show that cluster confirmation, paired with subgroup rotation, allows protocols to safely operate through situations where all members of the global consensus group are Byzantine. We demonstrate our compositional construction by combining the recent HotStuff and Damysus protocols into a hierarchical geo-replicated blockchain with global durability guarantees. We present a compositionality proof and demonstrate the correctness of our protocol, including its ability to tolerate cluster crashes. Our protocol -ORION 1 -achieves a 20% higher throughput than GeoBFT, the latest hierarchical Byzantine Fault-Tolerant (BFT) protocol.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense</title>
<link>https://arxiv.org/abs/2504.21480</link>
<guid>https://arxiv.org/abs/2504.21480</guid>
<content:encoded><![CDATA[
arXiv:2504.21480v1 Announce Type: new 
Abstract: With the rapid advancement of blockchain technology, smart contracts have enabled the implementation of increasingly complex functionalities. However, ensuring the security of smart contracts remains a persistent challenge across the stages of development, compilation, and execution. Vulnerabilities within smart contracts not only undermine the security of individual applications but also pose significant risks to the broader blockchain ecosystem, as demonstrated by the growing frequency of attacks since 2016, resulting in substantial financial losses. This paper provides a comprehensive analysis of key security risks in Ethereum smart contracts, specifically those written in Solidity and executed on the Ethereum Virtual Machine (EVM). We focus on two prevalent and critical vulnerability types (reentrancy and integer overflow) by examining their underlying mechanisms, replicating attack scenarios, and assessing effective countermeasures.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralization of Ethereum's Builder Market</title>
<link>https://arxiv.org/abs/2405.01329</link>
<guid>https://arxiv.org/abs/2405.01329</guid>
<content:encoded><![CDATA[
arXiv:2405.01329v5 Announce Type: replace 
Abstract: Blockchains protect an ecosystem worth more than $500bn with strong security properties derived from the principle of decentralization. Is today's blockchain decentralized? In this paper, we empirically studied one of the least decentralized parts of Ethereum, its builder market.
  The builder market was introduced to fairly distribute Maximal Extractable Value (MEV) among validators and avoid validator centralization. As of the time of writing, two builders produced more than 85% of blocks in Ethereum, creating a concerning centralization factor. However, a common belief is that such centralization "is okay," arguing that builder centralization will not lead to validator centralization. In this empirical study, we quantify the significant proposer losses within the centralized builder market and challenge the belief that this is acceptable.
  The significant proposer losses, if left uncontrolled, could undermine the goal of PBS. Moreover, MEV mitigation solutions slated for adoption are affected too because they rely on the builder market as an "MEV oracle," which is made inaccurate by centralization. Our investigation reveals the incentive issue within the current MEV supply chain and its implications for builder centralization and proposer losses. Finally, we analyze why the proposed mitigation cannot work and highlight two properties essential for effective solutions.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Centralized vs Decentralized Monitors for Hyperproperties</title>
<link>https://arxiv.org/abs/2405.12882</link>
<guid>https://arxiv.org/abs/2405.12882</guid>
<content:encoded><![CDATA[
arXiv:2405.12882v2 Announce Type: replace 
Abstract: This paper focuses on the runtime verification of hyperproperties expressed in Hyper-recHML, an expressive yet simple logic for describing properties of sets of traces. To this end, we consider a simple language of monitors that observe sets of system executions and report verdicts w.r.t. a given Hyper-recHML formula. We first employ a unique omniscient monitor that centrally observes all system traces. Since centralised monitors are not ideal for distributed settings, we also provide a language for decentralized monitors, where each trace has a dedicated monitor; these monitors yield a unique verdict by communicating their observations to one another. For both the centralized and the decentralized settings, we provide a synthesis procedure that, given a formula, yields a monitor that is correct (i.e., sound and violation complete). A key step in proving the correctness of the synthesis for decentralized monitors is a result showing that, for each formula, the synthesized centralized monitor and its corresponding decentralized one are weakly bisimilar for a suitable notion of weak bisimulation.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Remote Staking with Optimal Economic Safety</title>
<link>https://arxiv.org/abs/2408.01896</link>
<guid>https://arxiv.org/abs/2408.01896</guid>
<content:encoded><![CDATA[
arXiv:2408.01896v4 Announce Type: replace 
Abstract: The idea of security sharing traces back to Nakamoto's introduction of merge mining, a technique that enables Bitcoin miners to reuse their hash power to bootstrap and secure other Proof-of-Work (PoW) blockchains. However, with the rise of Proof-of-Stake (PoS) chains (where merge mining is inapplicable) there is a need for new methods of Bitcoin security sharing. In this paper, we introduce remote staking as a technique that allows Bitcoin holders to use their idle assets to secure PoS chains. Our remote staking protocol achieves optimal economic safety: in the event of a safety violation on the PoS chain, at least one-third of the Bitcoin stake securing the chain is slashed. We make two key technical contributions to enable this: 1) A cryptographic protocol that enables slashing of Bitcoin stake despite the absence of smart contracts on Bitcoin; 2) A secure unbonding mechanism that guarantees slashing can occur before the stake is withdrawn from Bitcoin if a safety violation occurs on the PoS chain. Our design is entirely modular and can be integrated with any PoS chain as the security consumer and any chain (including Bitcoin) as the security provider. A version of this protocol was deployed to mainnet in August 2024 and has since accumulated over 4.1 billion USD worth of staked bitcoins.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GenTorrent: Scaling Large Language Model Serving with An Overley Network</title>
<link>https://arxiv.org/abs/2504.20101</link>
<guid>https://arxiv.org/abs/2504.20101</guid>
<content:encoded><![CDATA[
arXiv:2504.20101v1 Announce Type: new 
Abstract: While significant progress has been made in research and development on open-source and cost-efficient large-language models (LLMs), serving scalability remains a critical challenge, particularly for small organizations and individuals seeking to deploy and test their LLM innovations. Inspired by peer-to-peer networks that leverage decentralized overlay nodes to increase throughput and availability, we propose GenTorrent, an LLM serving overlay that harnesses computing resources from decentralized contributors. We identify four key research problems inherent to enabling such a decentralized infrastructure: 1) overlay network organization; 2) LLM communication privacy; 3) overlay forwarding for resource efficiency; and 4) verification of serving quality. This work presents the first systematic study of these fundamental problems in the context of decentralized LLM serving. Evaluation results from a prototype implemented on a set of decentralized nodes demonstrate that GenTorrent achieves a latency reduction of over 50% compared to the baseline design without overlay forwarding. Furthermore, the security features introduce minimal overhead to serving latency and throughput. We believe this work pioneers a new direction for democratizing and scaling future AI serving capabilities.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SA2FE: A Secure, Anonymous, Auditable, and Fair Edge Computing Service Offloading Framework</title>
<link>https://arxiv.org/abs/2504.20260</link>
<guid>https://arxiv.org/abs/2504.20260</guid>
<content:encoded><![CDATA[
arXiv:2504.20260v1 Announce Type: new 
Abstract: The inclusion of pervasive computing devices in a democratized edge computing ecosystem can significantly expand the capability and coverage of near-end computing for large-scale applications. However, offloading user tasks to heterogeneous and decentralized edge devices comes with the dual risk of both endangered user data security and privacy due to the curious base station or malicious edge servers, and unfair offloading and malicious attacks targeting edge servers from other edge servers and/or users. Existing solutions to edge access control and offloading either rely on "always-on" cloud servers with reduced edge benefits or fail to protect sensitive user service information. To address these challenges, this paper presents SA2FE, a novel framework for edge access control, offloading and accounting. We design a rerandomizable puzzle primitive and a corresponding scheme to protect sensitive service information from eavesdroppers and ensure fair offloading decisions, while a blind token-based scheme safeguards user privacy, prevents double spending, and ensures usage accountability. The security of SA2FE is proved under the Universal Composability framework, and its performance and scalability are demonstrated with implementation on commodity mobile devices and edge servers.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Water Security with AI and Blockchain-Enhanced Digital Twins</title>
<link>https://arxiv.org/abs/2504.20275</link>
<guid>https://arxiv.org/abs/2504.20275</guid>
<content:encoded><![CDATA[
arXiv:2504.20275v1 Announce Type: new 
Abstract: Water distribution systems in rural areas face serious challenges such as a lack of real-time monitoring, vulnerability to cyberattacks, and unreliable data handling. This paper presents an integrated framework that combines LoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection System (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure and transparent water management. The IDS filters anomalous or spoofed data using a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before validated data is logged via smart contracts on a private Ethereum blockchain using Proof of Authority (PoA) consensus. The verified data feeds into a real-time DT model supporting leak detection, consumption forecasting, and predictive maintenance. Experimental results demonstrate that the system achieves over 80 transactions per second (TPS) with under 2 seconds of latency while remaining cost-effective and scalable for up to 1,000 smart meters. This work demonstrates a practical and secure architecture for decentralized water infrastructure in under-connected rural environments.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: A Survey of Mixing Techniques and Mixers for Cryptocurrencies</title>
<link>https://arxiv.org/abs/2504.20296</link>
<guid>https://arxiv.org/abs/2504.20296</guid>
<content:encoded><![CDATA[
arXiv:2504.20296v1 Announce Type: new 
Abstract: Blockchain technologies have overturned the digital finance industry by introducing a decentralized pseudonymous means of monetary transfer. The pseudonymous nature introduced privacy concerns, enabling various deanonymization techniques, which in turn spurred development of stronger anonymity-preserving measures. The purpose of this paper is to create a comprehensive survey of mixing techniques and implementations within the vast ecosystem surrounding anonymization tools and mechanisms available in blockchain cryptocurrencies. First, we begin by reviewing classifications used in the field. Then, we survey various obfuscation techniques, helping to delve into actual implementations and combinations of these techniques. Next, we identify the positive and negative attributes of the approaches and implementations included. Moreover, we examine the implications of anonymization tools for user privacy, including their effectiveness in preserving anonymity and susceptibility to attacks and vulnerabilities. Finally, we discuss the challenges and innovations for extending mixing services into the realm of smart contracts or cross-chain space.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards FAIR and federated Data Ecosystems for interdisciplinary Research</title>
<link>https://arxiv.org/abs/2504.20298</link>
<guid>https://arxiv.org/abs/2504.20298</guid>
<content:encoded><![CDATA[
arXiv:2504.20298v1 Announce Type: new 
Abstract: Scientific data management is at a critical juncture, driven by exponential data growth, increasing cross-domain dependencies, and a severe reproducibility crisis in modern research. Traditional centralized data management approaches are not only struggle with data volume, but also fail to address the fragmentation of research results across domains, hampering scientific reproducibility, and cross-domain collaboration, while raising concerns about data sovereignty and governance. Here we propose a practical framework for FAIR and federated Data Ecosystems that combines decentralized, distributed systems with existing research infrastructure to enable seamless cross-domain collaboration. Based on established patterns from data commons, data meshes, and data spaces, our approach introduces a layered architecture consisting of governance, data, service, and application layers. Our framework preserves domain-specific expertise and control while facilitating data integration through standardized interfaces and semantic enrichment. Key requirements include adaptive metadata management, simplified user interaction, robust security, and transparent data transactions. Our architecture supports both compute-to-data as well as data-to-compute paradigms, implementing a decentralized peer-to-peer network that scales horizontally. By providing both a technical architecture and a governance framework, FAIR and federated Data Ecosystems enables researchers to build on existing work while maintaining control over their data and computing resources, providing a practical path towards an integrated research infrastructure that respects both domain autonomy and interoperability requirements.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Clustering-Based Evolutionary Federated Multiobjective Optimization and Learning</title>
<link>https://arxiv.org/abs/2504.20346</link>
<guid>https://arxiv.org/abs/2504.20346</guid>
<content:encoded><![CDATA[
arXiv:2504.20346v1 Announce Type: new 
Abstract: Federated learning enables decentralized model training while preserving data privacy, yet it faces challenges in balancing communication efficiency, model performance, and privacy protection. To address these trade-offs, we formulate FL as a federated multiobjective optimization problem and propose FedMOEAC, a clustering-based evolutionary algorithm that efficiently navigates the Pareto-optimal solution space. Our approach integrates quantization, weight sparsification, and differential privacy to reduce communication overhead while ensuring model robustness and privacy. The clustering mechanism en-hances population diversity, preventing premature convergence and improving optimization efficiency. Experimental results on MNIST and CIFAR-10 demonstrate that FedMOEAC achieves 98.2% accuracy, reduces communication overhead by 45%, and maintains a privacy budget below 1.0, outperforming NSGA-II in convergence speed by 33%. This work provides a scalable and efficient FL framework, ensuring an optimal balance between accuracy, communication efficiency, and privacy in resource-constrained environments.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Algebraic Approach to Asymmetric Delegation and Polymorphic Label Inference (Technical Report)</title>
<link>https://arxiv.org/abs/2504.20432</link>
<guid>https://arxiv.org/abs/2504.20432</guid>
<content:encoded><![CDATA[
arXiv:2504.20432v1 Announce Type: new 
Abstract: Language-based information flow control (IFC) enables reasoning about and enforcing security policies in decentralized applications. While information flow properties are relatively extensional and compositional, designing expressive systems that enforce such properties remains challenging. In particular, it can be difficult to use IFC labels to model certain security assumptions, such as semi-honest agents.
  Motivated by these modeling limitations, we study the algebraic semantics of lattice-based IFC label models, and propose a semantic framework that allows formalizing asymmetric delegation, which is partial delegation of confidentiality or integrity. Our framework supports downgrading of information and ensures their safety through nonmalleable information flow (NMIF).
  To demonstrate the practicality of our framework, we design and implement a novel algorithm that statically checks NMIF and a label inference procedure that efficiently supports bounded label polymorphism, allowing users to write code generic with respect to labels.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient patient-centric EMR sharing block tree</title>
<link>https://arxiv.org/abs/2504.20544</link>
<guid>https://arxiv.org/abs/2504.20544</guid>
<content:encoded><![CDATA[
arXiv:2504.20544v1 Announce Type: new 
Abstract: Flexible sharing of electronic medical records (EMRs) is an urgent need in healthcare, as fragmented storage creates EMR management complexity for both practitioners and patients. Blockchain has emerged as a promising solution to address the limitations of centralized EMR systems regarding interoperability, data ownership, and trust concerns. Whilst its healthcare implementation continues to face scalability challenges, particularly in uploading lag time as EMR volumes increase. In this paper, we describe the design of a novel blockchain-based data structure, MedBlockTree, which aims to solve the scalability issue in blockchain-based EMR systems, particularly low block throughput and patient awareness. MedBlockTree leverages a chameleon hash function to generate collision blocks for existing patients and expand a single chain into a growing block tree with $n$ branches that are capable of processing $n$ new blocks in a single consensus round. We also introduce the EnhancedPro consensus algorithm to manage multiple branches and maintain network consistency. Our comprehensive simulation evaluates performance across four dimensions: branch number, worker number, collision rate, and network latency. Comparative analysis against a traditional blockchain-based EMR system demonstrates outstanding throughput improvements across all dimensions, achieving processing speeds $\nu\cdot n$ times faster than conventional approaches.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReCIT: Reconstructing Full Private Data from Gradient in Parameter-Efficient Fine-Tuning of Large Language Models</title>
<link>https://arxiv.org/abs/2504.20570</link>
<guid>https://arxiv.org/abs/2504.20570</guid>
<content:encoded><![CDATA[
arXiv:2504.20570v1 Announce Type: new 
Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a practical solution for adapting large language models (LLMs) to custom datasets with significantly reduced computational cost. When carrying out PEFT under collaborative learning scenarios (e.g., federated learning), it is often required to exchange model updates (or gradients) across parties. These gradients, even with limited dimensions, can cause severe breach of data privacy. Recent works have shown that both contextual prefixes and personally identifiable information (PII) can be exposed through gradients. However, \emph{simultaneously} and \emph{accurately} recovering both components from the same training instance remains infeasible due to the following challenges: 1) limited number of PEFT parameters; 2) high-dimensional token spaces; and 3) large batch sizes. We propose ReCIT, a novel privacy attack that addresses all challenges, and achieves recovery of \emph{full} private data from PEFT gradients with high fidelity. Specifically, ReCIT proposes to enhance the memorization capability of the pre-trained model through malicious fine-tuning with Personal Notes; ReCIT also proposes a novel filter-based token extraction technique and a token pairing mechanism, to accurately reconstruct tokens from the training sequences with large batch sizes. Extensive evaluations show that ReCIT consistently outperforms state-of-the-art gradient inversion and memorization-based attacks across different PEFT paradigms. It achieves up to 10$\times$ higher PII recovery rates and remains effective across varying batch sizes, especially in settings where prefix reconstruction is intractable for conventional approaches. These findings highlight an urgent need to reassess the privacy guarantees of PEFT, especially in decentralized or shared training environments.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Decentralized Local Flexibility Market for Local Energy Communities to Mitigate Grid Congestion: A Case Study in Sweden</title>
<link>https://arxiv.org/abs/2504.20697</link>
<guid>https://arxiv.org/abs/2504.20697</guid>
<content:encoded><![CDATA[
arXiv:2504.20697v1 Announce Type: new 
Abstract: This paper proposes a preventive congestion management framework with joint Local Flexibility Capacity Market (LFCM) and Local Energy Markets (LEMs). The framework enables Local Energy Communities (LECs) to optimize their flexibility potential across the LEM, LFCM, and heat markets. The LECs utilize their heat and electricity resources to offer flexibility services to Distribution System Operators (DSOs) for congestion relief. In this framework, energy and flexibility are treated as separate variables, each subject to different pricing scheme. Flexibility prices are market-driven, dynamically reflecting the location and severity of congestion. A case study conducted at Chalmers University of Technology, Sweden, shows that the proposed framework can effectively mitigate congestion by trading the LECs flexibility in the LFCM. The study also highlights up to 40% financial benefits for LECs, promoting the LFCM as a viable solution for congestion management in future decentralized energy systems.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Building Trust in Healthcare with Privacy Techniques: Blockchain in the Cloud</title>
<link>https://arxiv.org/abs/2504.20700</link>
<guid>https://arxiv.org/abs/2504.20700</guid>
<content:encoded><![CDATA[
arXiv:2504.20700v1 Announce Type: new 
Abstract: This study introduces a cutting-edge architecture developed for the NewbornTime project, which uses advanced AI to analyze video data at birth and during newborn resuscitation, with the aim of improving newborn care. The proposed architecture addresses the crucial issues of patient consent, data security, and investing trust in healthcare by integrating Ethereum blockchain with cloud computing. Our blockchain-based consent application simplifies patient consent's secure and transparent management. We explain the smart contract mechanisms and privacy measures employed, ensuring data protection while permitting controlled data sharing among authorized parties. This work demonstrates the potential of combining blockchain and cloud technologies in healthcare, emphasizing their role in maintaining data integrity, with implications for computer science and healthcare innovation.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bitcoin, a DAO?</title>
<link>https://arxiv.org/abs/2504.20838</link>
<guid>https://arxiv.org/abs/2504.20838</guid>
<content:encoded><![CDATA[
arXiv:2504.20838v1 Announce Type: new 
Abstract: This paper investigates whether Bitcoin can be regarded as a decentralized autonomous organization (DAO), what insights it may offer for the broader DAO ecosystem, and how Bitcoin governance can be improved. First, a quantitative literature analysis reveals that Bitcoin is increasingly overlooked in DAO research, even though early works often classified it as a DAO. Next, the paper applies a DAO viability framework - centering on collective intelligence, digital democracy, and adaptation - to examine Bitcoin's organizational and governance mechanisms. Findings suggest that Bitcoin instantitates key DAO principles by enabling open participation, and employing decentralized decision-making through Bitcoin Improvement Proposals (BIPs), miner signaling, and user-activated soft forks. However, this governance carries potential risks, including reduced clarity on who truly 'votes' due to the concentration of economic power among large stakeholders. The paper concludes by highlighting opportunities to refine Bitcoin's deliberation process and reflecting on broader implications for DAO design, such as the absence of a legal entity. In doing so, it underscores Bitcoin's continued relevance as an archetype for decentralized governance, offering important findings for future DAO implementations.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fostering Self-Directed Growth with Generative AI: Toward a New Learning Analytics Framework</title>
<link>https://arxiv.org/abs/2504.20851</link>
<guid>https://arxiv.org/abs/2504.20851</guid>
<content:encoded><![CDATA[
arXiv:2504.20851v1 Announce Type: new 
Abstract: In an era increasingly shaped by decentralized knowledge ecosystems and pervasive AI technologies, fostering sustainable learner agency has become a critical educational imperative. This study introduces a novel conceptual framework integrating Generative Artificial Intelligence and Learning Analytics to cultivate Self-Directed Growth, a dynamic competency that enables learners to iteratively drive their own developmental pathways across diverse contexts.Building upon critical gaps in current research on Self Directed Learning and AI-mediated education, the proposed Aspire to Potentials for Learners (A2PL) model reconceptualizes the interplay of learner aspirations, complex thinking, and summative self-assessment within GAI supported environments.Methodological implications for future intervention design and learning analytics applications are discussed, positioning Self-Directed Growth as a pivotal axis for developing equitable, adaptive, and sustainable learning systems in the digital era.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Specification Mining for Smart Contracts with Trace Slicing and Predicate Abstraction</title>
<link>https://arxiv.org/abs/2403.13279</link>
<guid>https://arxiv.org/abs/2403.13279</guid>
<content:encoded><![CDATA[
arXiv:2403.13279v2 Announce Type: replace 
Abstract: Smart contracts are computer programs running on blockchains to implement Decentralized Applications. The absence of contract specifications hinders routine tasks, such as contract understanding and testing. In this work, we propose a specification mining approach to infer contract specifications from past transaction histories. Our approach derives high-level behavioral automata of function invocations, accompanied by program invariants statistically inferred from the transaction histories. We implemented our approach as tool SMCON and evaluated it on eleven well-studied Azure benchmark smart contracts and six popular real-world DApp smart contracts. The experiments show that SMCON mines reasonably accurate specifications that can be used to enhance symbolic analysis of smart contracts achieving higher code coverage and up to 56% speedup, and facilitate DApp developers in maintaining high-quality documentation and test suites.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Anomaly Detection in Time Series of EDFA Pump Currents to Monitor Degeneration Processes using Fuzzy Clustering</title>
<link>https://arxiv.org/abs/2408.15268</link>
<guid>https://arxiv.org/abs/2408.15268</guid>
<content:encoded><![CDATA[
arXiv:2408.15268v3 Announce Type: replace-cross 
Abstract: This article proposes a novel fuzzy clustering based anomaly detection method for pump current time series of EDFA systems. The proposed change detection framework (CDF) strategically combines the advantages of entropy analysis (EA) and principle component analysis (PCA) with fuzzy clustering procedures. In the framework, EA is applied for dynamic selection of features for reduction of the feature space and increase of computational performance. Furthermore, PCA is utilized to extract features from the raw feature space to enable generalization capability of the subsequent fuzzy clustering procedures. Three different fuzzy clustering methods, more precisely the fuzzy clustering algorithm, a probabilistic clustering algorithm and a possibilistic clustering algorithm are evaluated for performance and generalization. Hence, the proposed framework has the innovative feature to detect changes in pump current time series at an early stage for arbitrary points of operation, compared to state-of-the-art predefined alarms in commercially used EDFAs. Moreover, the approach is implemented and tested using experimental data. In addition, the proposed framework enables further approaches of applying decentralized predictive maintenance for optical fiber networks.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Channel Estimation for XL-MIMO Systems with Decentralized Baseband Processing: Integrating Local Reconstruction with Global Refinement</title>
<link>https://arxiv.org/abs/2501.17059</link>
<guid>https://arxiv.org/abs/2501.17059</guid>
<content:encoded><![CDATA[
arXiv:2501.17059v4 Announce Type: replace 
Abstract: In this paper, we investigate the channel estimation problem for extremely large-scale multiple-input multiple-output (XL-MIMO) systems with a hybrid analog-digital architecture, implemented within a decentralized baseband processing (DBP) framework with a star topology. Existing centralized and fully decentralized channel estimation methods face limitations due to excessive computational complexity or degraded performance. To overcome these challenges, we propose a novel two-stage channel estimation scheme that integrates local sparse reconstruction with global fusion and refinement. Specifically, in the first stage, by exploiting the sparsity of channels in the angular-delay domain, the local reconstruction task is formulated as a sparse signal recovery problem. To solve it, we develop a graph neural networks-enhanced sparse Bayesian learning (SBL-GNNs) algorithm, which effectively captures dependencies among channel coefficients, significantly improving estimation accuracy. In the second stage, the local estimates from the local processing units (LPUs) are aligned into a global angular domain for fusion at the central processing unit (CPU). Based on the aggregated observations, the channel refinement is modeled as a Bayesian denoising problem. To efficiently solve it, we devise a variational message passing algorithm that incorporates a Markov chain-based hierarchical sparse prior, effectively leveraging both the sparsity and the correlations of the channels in the global angular-delay domain. Simulation results validate the effectiveness and superiority of the proposed SBL-GNNs algorithm over existing methods, demonstrating improved estimation performance and reduced computational complexity.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Philosophic Turn for AI Agents: Replacing centralized digital rhetoric with decentralized truth-seeking</title>
<link>https://arxiv.org/abs/2504.18601</link>
<guid>https://arxiv.org/abs/2504.18601</guid>
<content:encoded><![CDATA[
arXiv:2504.18601v1 Announce Type: new 
Abstract: In the face of rapidly advancing AI technology, individuals will increasingly rely on AI agents to navigate life's growing complexities, raising critical concerns about maintaining both human agency and autonomy. This paper addresses a fundamental dilemma posed by AI decision-support systems: the risk of either becoming overwhelmed by complex decisions, thus losing agency, or having autonomy compromised by externally controlled choice architectures reminiscent of ``nudging'' practices. While the ``nudge'' framework, based on the use of choice-framing to guide individuals toward presumed beneficial outcomes, initially appeared to preserve liberty, at AI-driven scale, it threatens to erode autonomy. To counteract this risk, the paper proposes a philosophic turn in AI design. AI should be constructed to facilitate decentralized truth-seeking and open-ended inquiry, mirroring the Socratic method of philosophical dialogue. By promoting individual and collective adaptive learning, such AI systems would empower users to maintain control over their judgments, augmenting their agency without undermining autonomy. The paper concludes by outlining essential features for autonomy-preserving AI systems, sketching a path toward AI systems that enhance human judgment rather than undermine it.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Fusion of 3D Extended Object Tracking based on a B-Spline Shape Model</title>
<link>https://arxiv.org/abs/2504.18708</link>
<guid>https://arxiv.org/abs/2504.18708</guid>
<content:encoded><![CDATA[
arXiv:2504.18708v1 Announce Type: new 
Abstract: Extended Object Tracking (EOT) exploits the high resolution of modern sensors for detailed environmental perception. Combined with decentralized fusion, it contributes to a more scalable and robust perception system. This paper investigates the decentralized fusion of 3D EOT using a B-spline curve based model. The spline curve is used to represent the side-view profile, which is then extruded with a width to form a 3D shape. We use covariance intersection (CI) for the decentralized fusion and discuss the challenge of applying it to EOT. We further evaluate the tracking result of the decentralized fusion with simulated and real datasets of traffic scenarios. We show that the CI-based fusion can significantly improve the tracking performance for sensors with unfavorable perspective.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Clones in the Machine: A Feminist Critique of Agency in Digital Cloning</title>
<link>https://arxiv.org/abs/2504.18807</link>
<guid>https://arxiv.org/abs/2504.18807</guid>
<content:encoded><![CDATA[
arXiv:2504.18807v1 Announce Type: new 
Abstract: This paper critiques digital cloning in academic research, highlighting how it exemplifies AI solutionism. Digital clones, which replicate user data to simulate behavior, are often seen as scalable tools for behavioral insights. However, this framing obscures ethical concerns around consent, agency, and representation. Drawing on feminist theories of agency, the paper argues that digital cloning oversimplifies human complexity and risks perpetuating systemic biases. To address these issues, it proposes decentralized data repositories and dynamic consent models, promoting ethical, context-aware AI practices that challenge the reductionist logic of AI solutionism
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding Decentralized Social Feed Curation on Mastodon</title>
<link>https://arxiv.org/abs/2504.18817</link>
<guid>https://arxiv.org/abs/2504.18817</guid>
<content:encoded><![CDATA[
arXiv:2504.18817v1 Announce Type: new 
Abstract: As centralized social media platforms face growing concerns, more users are seeking greater control over their social feeds and turning to decentralized alternatives such as Mastodon. The decentralized nature of Mastodon creates unique opportunities for customizing feeds, yet user perceptions and curation strategies on these platforms remain unknown. This paper presents findings from a two-part interview study with 21 Mastodon users, exploring how they perceive, interact with, and manage their current feeds, and how we can better empower users to personalize their feeds on Mastodon. We use the qualitative findings of the first part of the study to guide the creation of Braids, a web-based prototype for feed curation. Results from the second part of our study, using Braids, highlighted opportunities and challenges for future research, particularly in using seamful design to enhance people's acceptance of algorithmic curation and nuanced trade-offs between machine learning-based and rule-based curation algorithms. To optimize user experience, we also discuss the tension between creating new apps and building add-ons in the decentralized social media realm.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>UnifyFL: Enabling Decentralized Cross-Silo Federated Learning</title>
<link>https://arxiv.org/abs/2504.18916</link>
<guid>https://arxiv.org/abs/2504.18916</guid>
<content:encoded><![CDATA[
arXiv:2504.18916v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning (ML) paradigm in which models are trained on private data across several devices called clients and combined at a single node called an aggregator rather than aggregating the data itself. Many organizations employ FL to have better privacy-aware ML-driven decision-making capabilities. However, organizations often operate independently rather than collaborate to enhance their FL capabilities due to the lack of an effective mechanism for collaboration. The challenge lies in balancing trust and resource efficiency. One approach relies on trusting a third-party aggregator to consolidate models from all organizations (multilevel FL), but this requires trusting an entity that may be biased or unreliable. Alternatively, organizations can bypass a third party by sharing their local models directly, which requires significant computational resources for validation. Both approaches reflect a fundamental trade-off between trust and resource constraints, with neither offering an ideal solution. In this work, we develop a trust-based cross-silo FL framework called \proj, which uses decentralized orchestration and distributed storage. \proj provides flexibility to the participating organizations and presents synchronous and asynchronous modes to handle stragglers. Our evaluation on a diverse testbed shows that \proj achieves a performance comparable to the ideal multilevel centralized FL while allowing trust and optimal use of resources.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Redefining Hybrid Blockchains: A Balanced Architecture</title>
<link>https://arxiv.org/abs/2504.18966</link>
<guid>https://arxiv.org/abs/2504.18966</guid>
<content:encoded><![CDATA[
arXiv:2504.18966v1 Announce Type: new 
Abstract: Blockchain technology has completely revolutionized the field of decentralized finance with the emergence of a variety of cryptocurrencies and digital assets. However, widespread adoption of this technology by governments and enterprises has been limited by concerns regarding the technology's scalability, governance, and economic sustainability. This paper aims to introduce a novel hybrid blockchain architecture that balances scalability, governance, and decentralization while being economically viable for all parties involved. The new semi-centralized model leverages strategies not prevalent in the field, such as resource and node isolation, containerization, separation of networking and compute layers, use of a Kafka pub-sub network instead of a peer-to-peer network, and stakes-based validator selection to possibly mitigate a variety of issues related to scalability, security, governance, and economic sustainability. Simulations conducted on Kubernetes demonstrate the architecture's ability to achieve over 1000 transactions per second, with consistent performance across scaled deployments, even on a lightweight consumer-grade laptop with resource constraints. The findings highlight the system's scalability, security, and economic viability, offering a robust framework for enterprise and government adoption.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Validation Framework for E-Contract and Smart Contract</title>
<link>https://arxiv.org/abs/2504.19137</link>
<guid>https://arxiv.org/abs/2504.19137</guid>
<content:encoded><![CDATA[
arXiv:2504.19137v1 Announce Type: new 
Abstract: We propose and develop a framework for validating smart contracts derived from e-contracts. The goal is to ensure the generated smart contracts fulfil all the conditions outlined in their corresponding e-contracts. By confirming alignment between the smart contracts and their original agreements, this approach enhances trust and reliability in automated contract execution. The proposed framework will systematically compare and validate the terms and clauses of the e-contracts with the logic of the smart contracts. This validation confirms that the agreement is accurately translated into executable code. Automated verification identifies issues between the e-contracts and their smart contract counterparts. This proposed work will solve the problems of gap between legal language and code execution, this framework ensures seamless integration of smart contracts into the existing legal framework.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Symmetric Policy Design for Multi-Agent Dispatch Coordination in Supply Chains</title>
<link>https://arxiv.org/abs/2504.19397</link>
<guid>https://arxiv.org/abs/2504.19397</guid>
<content:encoded><![CDATA[
arXiv:2504.19397v1 Announce Type: new 
Abstract: We study a decentralized dispatch coordination problem in a multi-agent supply chain setting with shared logistics capacity. We propose symmetric (identical) dispatch strategies for all agents, enabling efficient coordination without centralized control. Using a common information approach, we derive a dynamic programming solution that computes optimal symmetric dispatch strategies by transforming the multi-agent problem into a tractable dynamic program on the agents common information state. Simulation results demonstrate that our method significantly reduces coordination cost compared to baseline heuristics, including belief-based strategies and an always-dispatch policy. These findings highlight the benefits of combining symmetric strategy design with a common information-based dynamic programming framework for improving multi-agent coordination performance.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation</title>
<link>https://arxiv.org/abs/2504.19602</link>
<guid>https://arxiv.org/abs/2504.19602</guid>
<content:encoded><![CDATA[
arXiv:2504.19602v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized clients, enhancing privacy by keeping data local. Yet conventional FL, relying on frequent parameter-sharing, suffers from high communication overhead and limited model heterogeneity. Distillation-based FL approaches address these issues by sharing predictions (soft-labels) instead, but they often involve redundant transmissions across communication rounds, reducing efficiency. We propose SCARLET, a novel framework integrating synchronized soft-label caching and an enhanced Entropy Reduction Aggregation (Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing cached soft-labels, achieving up to 50% reduction in communication costs compared to existing methods while maintaining accuracy. Enhanced ERA can be tuned to adapt to non-IID data variations, ensuring robust aggregation and performance in diverse client scenarios. Experimental evaluations demonstrate that SCARLET consistently outperforms state-of-the-art distillation-based FL methods in terms of accuracy and communication efficiency. The implementation of SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Diffusion Stochastic Learning Over Adaptive Competing Networks</title>
<link>https://arxiv.org/abs/2504.19635</link>
<guid>https://arxiv.org/abs/2504.19635</guid>
<content:encoded><![CDATA[
arXiv:2504.19635v1 Announce Type: new 
Abstract: This paper studies a stochastic dynamic game between two competing teams, each consisting of a network of collaborating agents. Unlike fully cooperative settings, where all agents share a common objective, each team in this game aims to minimize its own distinct objective. In the adversarial setting, their objectives could be conflicting as in zero-sum games. Throughout the competition, agents share strategic information within their own team while simultaneously inferring and adapting to the strategies of the opposing team. We propose diffusion learning algorithms to address two important classes of this network game: i) a zero-sum game characterized by weak cross-team subgraph interactions, and ii) a general non-zero-sum game exhibiting strong cross-team subgraph interactions. We analyze the stability performance of the proposed algorithms under reasonable assumptions and illustrate the theoretical results through experiments on Cournot team competition and decentralized GAN training.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging</title>
<link>https://arxiv.org/abs/2504.19639</link>
<guid>https://arxiv.org/abs/2504.19639</guid>
<content:encoded><![CDATA[
arXiv:2504.19639v1 Announce Type: new 
Abstract: Federated Learning (FL) enables model training across decentralized devices without sharing raw data, thereby preserving privacy in sensitive domains like healthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN) architectures against traditional MLP across six state-of-the-art FL algorithms on a blood cell classification dataset. Notably, our experiments demonstrate that KAN can effectively replace MLP in federated environments, achieving superior performance with simpler architectures. Furthermore, we analyze the impact of key hyperparameters-grid size and network architecture-on KAN performance under varying degrees of Non-IID data distribution. Additionally, our ablation studies reveal that optimizing KAN width while maintaining minimal depth yields the best performance in federated settings. As a result, these findings establish KAN as a promising alternative for privacy-preserving medical imaging applications in distributed healthcare. To the best of our knowledge, this is the first comprehensive benchmark of KAN in FL settings for medical imaging task.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking</title>
<link>https://arxiv.org/abs/2504.19940</link>
<guid>https://arxiv.org/abs/2504.19940</guid>
<content:encoded><![CDATA[
arXiv:2504.19940v1 Announce Type: new 
Abstract: The growing spread of online misinformation has created an urgent need for scalable, reliable fact-checking solutions. Crowdsourced fact-checking - where non-experts evaluate claim veracity - offers a cost-effective alternative to expert verification, despite concerns about variability in quality and bias. Encouraged by promising results in certain contexts, major platforms such as X (formerly Twitter), Facebook, and Instagram have begun shifting from centralized moderation to decentralized, crowd-based approaches.
  In parallel, advances in Large Language Models (LLMs) have shown strong performance across core fact-checking tasks, including claim detection and evidence evaluation. However, their potential role in crowdsourced workflows remains unexplored. This paper investigates whether LLM-powered generative agents - autonomous entities that emulate human behavior and decision-making - can meaningfully contribute to fact-checking tasks traditionally reserved for human crowds. Using the protocol of La Barbera et al. (2024), we simulate crowds of generative agents with diverse demographic and ideological profiles. Agents retrieve evidence, assess claims along multiple quality dimensions, and issue final veracity judgments.
  Our results show that agent crowds outperform human crowds in truthfulness classification, exhibit higher internal consistency, and show reduced susceptibility to social and cognitive biases. Compared to humans, agents rely more systematically on informative criteria such as Accuracy, Precision, and Informativeness, suggesting a more structured decision-making process. Overall, our findings highlight the potential of generative agents as scalable, consistent, and less biased contributors to crowd-based fact-checking systems.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution</title>
<link>https://arxiv.org/abs/2412.06855</link>
<guid>https://arxiv.org/abs/2412.06855</guid>
<content:encoded><![CDATA[
arXiv:2412.06855v4 Announce Type: replace 
Abstract: Cooperation is vital to our survival and progress. Evolutionary game theory offers a lens to understand the structures and incentives that enable cooperation to be a successful strategy. As artificial intelligence agents become integral to human systems, the dynamics of cooperation take on unprecedented significance. The convergence of human-agent teaming, contract theory, and decentralized frameworks like Web3, grounded in transparency, accountability, and trust, offers a foundation for fostering cooperation by establishing enforceable rules and incentives for humans and AI agents. We conceptualize Incentivized Symbiosis as a social contract between humans and AI, inspired by Web3 principles and encoded in blockchain technology, to define and enforce rules, incentives, and consequences for both parties. By exploring this paradigm, we aim to catalyze new research at the intersection of systems thinking in AI, Web3, and society, fostering innovative pathways for cooperative human-agent coevolution.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Strong Duality Result for Constrained POMDPs with Multiple Cooperative Agents</title>
<link>https://arxiv.org/abs/2303.14932</link>
<guid>https://arxiv.org/abs/2303.14932</guid>
<content:encoded><![CDATA[
arXiv:2303.14932v2 Announce Type: replace-cross 
Abstract: The work studies the problem of decentralized constrained POMDPs in a team-setting where multiple nonstrategic agents have asymmetric information. Using an extension of Sion's Minimax theorem for functions with positive infinity and results on weak-convergence of measures, strong duality is established for the setting of infinite-horizon expected total discounted costs when the observations lie in a countable space, the actions are chosen from a finite space, the constraint costs are bounded, and the objective cost is bounded from below.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Monero Peer-to-peer Network Topology Analysis</title>
<link>https://arxiv.org/abs/2504.17809</link>
<guid>https://arxiv.org/abs/2504.17809</guid>
<content:encoded><![CDATA[
arXiv:2504.17809v1 Announce Type: new 
Abstract: Monero, a privacy-focused cryptocurrency, employs a decentralized peer-to-peer (P2P) network that plays a critical role in transaction propagation and consensus formation. While much research has explored Monero's privacy transaction mechanisms, its underlying P2P network architecture has remained relatively underexplored. In this study, building on our recent work on Monero network detection, we further investigate the network topology of Monero's P2P structure, which has evolved following recent protocol updates that enhanced security by obscuring peer information. Using k-core decomposition, we confirm that the Monero network exhibits a core-periphery structure, where a tightly interconnected core of supernodes is crucial for maintaining network cohesion, while peripheral nodes rely on these core nodes for connectivity. This structure explains why targeting central nodes does not easily lead to the rapid disintegration of the network's largest connected component while also providing a deeper understanding of the true architecture of Monero's peer protocol.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fishing for Phishers: Learning-Based Phishing Detection in Ethereum Transactions</title>
<link>https://arxiv.org/abs/2504.17953</link>
<guid>https://arxiv.org/abs/2504.17953</guid>
<content:encoded><![CDATA[
arXiv:2504.17953v1 Announce Type: new 
Abstract: Phishing detection on Ethereum has increasingly leveraged advanced machine learning techniques to identify fraudulent transactions. However, limited attention has been given to understanding the effectiveness of feature selection strategies and the role of graph-based models in enhancing detection accuracy. In this paper, we systematically examine these issues by analyzing and contrasting explicit transactional features and implicit graph-based features, both experimentally and analytically. We explore how different feature sets impact the performance of phishing detection models, particularly in the context of Ethereum's transactional network. Additionally, we address key challenges such as class imbalance and dataset composition and their influence on the robustness and precision of detection methods. Our findings demonstrate the advantages and limitations of each feature type, while also providing a clearer understanding of how feature affect model resilience and generalization in adversarial environments.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Journey of Modern OS Construction From boot to DOOM</title>
<link>https://arxiv.org/abs/2504.17984</link>
<guid>https://arxiv.org/abs/2504.17984</guid>
<content:encoded><![CDATA[
arXiv:2504.17984v1 Announce Type: new 
Abstract: VOS is a first-of-its-kind instructional OS that: (1) Runs on commodity, portable hardware. (2) Showcases modern features, including per-app address spaces, threading, commodity filesystems, USB, DMA, multicore, self-hosted debugging, and a window manager. (3) Supports rich applications such as 2D/3D games, music and video players, and a blockchain miner. Unlike traditional instructional systems, VOS emphasizes strong motivation for building systems-supporting engaging, media-rich apps that go beyond basic terminal programs. To achieve this, we design VOS to strike a careful balance between essential OS complexity and overall simplicity. Our method, which we call inverse engineering, breaks down a full-featured OS into a set of incremental, self-contained prototypes. Each prototype introduces a minimal set of OS mechanisms, driven by the needs of specific apps. The construction process (i.e., forward engineering) then progressively enables these apps by bringing up one mechanism at a time. VOS makes it accessible for a wider audience to experience building a software system that is self-contained and usable in everyday scenarios.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differential Privacy-Driven Framework for Enhancing Heart Disease Prediction</title>
<link>https://arxiv.org/abs/2504.18007</link>
<guid>https://arxiv.org/abs/2504.18007</guid>
<content:encoded><![CDATA[
arXiv:2504.18007v1 Announce Type: new 
Abstract: With the rapid digitalization of healthcare systems, there has been a substantial increase in the generation and sharing of private health data. Safeguarding patient information is essential for maintaining consumer trust and ensuring compliance with legal data protection regulations. Machine learning is critical in healthcare, supporting personalized treatment, early disease detection, predictive analytics, image interpretation, drug discovery, efficient operations, and patient monitoring. It enhances decision-making, accelerates research, reduces errors, and improves patient outcomes. In this paper, we utilize machine learning methodologies, including differential privacy and federated learning, to develop privacy-preserving models that enable healthcare stakeholders to extract insights without compromising individual privacy. Differential privacy introduces noise to data to guarantee statistical privacy, while federated learning enables collaborative model training across decentralized datasets. We explore applying these technologies to Heart Disease Data, demonstrating how they preserve privacy while delivering valuable insights and comprehensive analysis. Our results show that using a federated learning model with differential privacy achieved a test accuracy of 85%, ensuring patient data remained secure and private throughout the process.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Why Does My Transaction Fail? A First Look at Failed Transactions on the Solana Blockchain</title>
<link>https://arxiv.org/abs/2504.18055</link>
<guid>https://arxiv.org/abs/2504.18055</guid>
<content:encoded><![CDATA[
arXiv:2504.18055v1 Announce Type: new 
Abstract: Solana is an emerging blockchain platform, recognized for its high throughput and low transaction costs, positioning it as a preferred infrastructure for Decentralized Finance (DeFi), Non-Fungible Tokens (NFTs), and other Web 3.0 applications. In the Solana ecosystem, transaction initiators submit various instructions to interact with a diverse range of Solana smart contracts, among which are decentralized exchanges (DEXs) that utilize automated market makers (AMMs), allowing users to trade cryptocurrencies directly on the blockchain without the need for intermediaries. Despite the high throughput and low transaction costs of Solana, the advantages have exposed Solana to bot spamming for financial exploitation, resulting in the prevalence of failed transactions and network congestion.
  Prior work on Solana has mainly focused on the evaluation of the performance of the Solana blockchain, particularly scalability and transaction throughput, as well as on the improvement of smart contract security, leaving a gap in understanding the characteristics and implications of failed transactions on Solana. To address this gap, we conducted a large-scale empirical study of failed transactions on Solana, using a curated dataset of over 1.5 billion failed transactions across more than 72 million blocks. Specifically, we first characterized the failed transactions in terms of their initiators, failure-triggering programs, and temporal patterns, and compared their block positions and transaction costs with those of successful transactions. We then categorized the failed transactions by the error messages in their error logs, and investigated how specific programs and transaction initiators are associated with these errors...
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Composable Game-Theoretic Framework for Blockchains</title>
<link>https://arxiv.org/abs/2504.18214</link>
<guid>https://arxiv.org/abs/2504.18214</guid>
<content:encoded><![CDATA[
arXiv:2504.18214v1 Announce Type: new 
Abstract: Blockchains rely on economic incentives to ensure secure and decentralised operation, making incentive compatibility a core design concern. However, protocols are rarely deployed in isolation. Applications interact with the underlying consensus and network layers, and multiple protocols may run concurrently on the same chain. These interactions give rise to complex incentive dynamics that traditional, isolated analyses often fail to capture.
  We propose the first compositional game-theoretic framework for blockchain protocols. Our model represents blockchain protocols as interacting games across layers -- application, network, and consensus. It enables formal reasoning about incentive compatibility under composition by introducing two key abstractions: the cross-layer game, which models how strategies in one layer influence others, and cross-application composition, which captures how application protocols interact concurrently through shared infrastructure.
  We illustrate our framework through case studies on HTLCs, Layer-2 protocols, and MEV, showing how compositional analysis reveals subtle incentive vulnerabilities and supports modular security proofs.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Switch-Based Multi-Part Neural Network</title>
<link>https://arxiv.org/abs/2504.18241</link>
<guid>https://arxiv.org/abs/2504.18241</guid>
<content:encoded><![CDATA[
arXiv:2504.18241v1 Announce Type: new 
Abstract: This paper introduces decentralized and modular neural network framework designed to enhance the scalability, interpretability, and performance of artificial intelligence (AI) systems. At the heart of this framework is a dynamic switch mechanism that governs the selective activation and training of individual neurons based on input characteristics, allowing neurons to specialize in distinct segments of the data domain. This approach enables neurons to learn from disjoint subsets of data, mimicking biological brain function by promoting task specialization and improving the interpretability of neural network behavior. Furthermore, the paper explores the application of federated learning and decentralized training for real-world AI deployments, particularly in edge computing and distributed environments. By simulating localized training on non-overlapping data subsets, we demonstrate how modular networks can be efficiently trained and evaluated. The proposed framework also addresses scalability, enabling AI systems to handle large datasets and distributed processing while preserving model transparency and interpretability. Finally, we discuss the potential of this approach in advancing the design of scalable, privacy-preserving, and efficient AI systems for diverse applications.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Distributed Queue Length Estimation</title>
<link>https://arxiv.org/abs/2504.18503</link>
<guid>https://arxiv.org/abs/2504.18503</guid>
<content:encoded><![CDATA[
arXiv:2504.18503v1 Announce Type: new 
Abstract: Queue length monitoring is a commonly arising problem in numerous applications such as queue management systems, scheduling, and traffic monitoring. Motivated by such applications, we formulate a queue monitoring problem, where there is a FIFO queue with arbitrary arrivals and departures, and a server needs to monitor the length of a queue by using decentralized pings from packets in the queue. Packets can send pings informing the server about the number of packets ahead of them in the queue. Via novel online policies and lower bounds, we tightly characterize the trade-off between the number of pings sent and the accuracy of the server's real time estimates. Our work studies the trade-off under various arrival and departure processes, including constant-rate, Poisson, and adversarial processes.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Forensics and security issues in the Internet of Things</title>
<link>https://arxiv.org/abs/2309.02707</link>
<guid>https://arxiv.org/abs/2309.02707</guid>
<content:encoded><![CDATA[
arXiv:2309.02707v2 Announce Type: replace 
Abstract: Given the exponential expansion of the internet, the possibilities of security attacks and cybercrimes have increased accordingly. However, poorly implemented security mechanisms in the Internet of Things (IoT) devices make them susceptible to cyberattacks, which can directly affect users. IoT forensics is thus needed to investigate and mitigate such attacks. While many works have examined IoT applications and challenges, only a few have focused on both the forensic and security issues in IoT. Therefore, this paper reviews forensic and security issues associated with IoT in different fields. Prospects and challenges in IoT research and development are also highlighted. As the literature demonstrates, most IoT devices are vulnerable to attacks due to a lack of standardized security measures. Unauthorized users could get access, compromise data, and even benefit from control of critical infrastructure. To fulfill the security-conscious needs of consumers, IoT can be used to develop a smart home system by designing the security-conscious needs of consumers; IoT can be used to create a smart home system by designing an IoT can be used to develop a smart home system by designing a FLIP-based system that is highly scalable and adaptable. A blockchain-based authentication mechanism with a multi-chain structure can provide additional security protection between different trust domains. Deep learning can be utilized to develop a network forensics framework with a high-performing system for detecting and tracking cyberattack incidents. Moreover, researchers should consider limiting the amount of data created and delivered when using big data to develop IoT-based smart systems. The findings of this review will stimulate academics to seek potential solutions for the identified issues, thereby advancing the IoT field.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory Planner</title>
<link>https://arxiv.org/abs/2406.10060</link>
<guid>https://arxiv.org/abs/2406.10060</guid>
<content:encoded><![CDATA[
arXiv:2406.10060v3 Announce Type: replace 
Abstract: In decentralized multiagent trajectory planners, agents need to communicate and exchange their positions to generate collision-free trajectories. However, due to localization errors/uncertainties, trajectory deconfliction can fail even if trajectories are perfectly shared between agents. To address this issue, we first present PARM and PARM*, perception-aware, decentralized, asynchronous multiagent trajectory planners that enable a team of agents to navigate uncertain environments while deconflicting trajectories and avoiding obstacles using perception information. PARM* differs from PARM as it is less conservative, using more computation to find closer-to-optimal solutions. While these methods achieve state-of-the-art performance, they suffer from high computational costs as they need to solve large optimization problems onboard, making it difficult for agents to replan at high rates. To overcome this challenge, we present our second key contribution, PRIMER, a learning-based planner trained with imitation learning (IL) using PARM* as the expert demonstrator. PRIMER leverages the low computational requirements at deployment of neural networks and achieves a computation speed up to 5500 times faster than optimization-based approaches.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bitcoin: A Non-Continuous Time System</title>
<link>https://arxiv.org/abs/2501.11091</link>
<guid>https://arxiv.org/abs/2501.11091</guid>
<content:encoded><![CDATA[
arXiv:2501.11091v4 Announce Type: replace 
Abstract: In this paper, we explore the concept of time within Bitcoin's blockchain, which operates as a non-continuous time system. We focus on three core aspects that contribute to Bitcoin's time discontinuity: the random and distributed block generation process, the occurrence of forks and rollbacks that disrupt the linear progression of the blockchain, and the nature of transactions within this system, which are subject to potential reordering or invalidation. These elements combine to create a time structure in Bitcoin that is fundamentally different from the continuous, linear time systems typically seen in traditional computing and physics.
]]></content:encoded>
<pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mapping Trafficking Networks: A Data-Driven Approach to Disrupt Human Trafficking Post Russia-Ukraine Conflict</title>
<link>https://arxiv.org/abs/2504.17050</link>
<guid>https://arxiv.org/abs/2504.17050</guid>
<content:encoded><![CDATA[
arXiv:2504.17050v1 Announce Type: new 
Abstract: This study proposes a prototype for locating important individuals and financial exchanges in networks of people trafficking that have grown during the conflict between Russia and Ukraine. It focuses on the role of digital platforms, cryptocurrencies, and the dark web in facilitating these operations. The research maps trafficking networks and identifies key players and financial flows by utilizing open-source intelligence (OSINT), social network analysis (SNA), and blockchain analysis. The results show how cryptocurrencies are used for anonymous transactions and imply that upsetting central coordinators may cause wider networks to become unstable. In order to combat human trafficking, the study emphasizes the significance of real-time data sharing between international law enforcement. It also identifies future directions for the development of improved monitoring tools and cooperative platforms.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Hybrid Approach Using an Attention-Based Transformer + GRU Model for Predicting Cryptocurrency Prices</title>
<link>https://arxiv.org/abs/2504.17079</link>
<guid>https://arxiv.org/abs/2504.17079</guid>
<content:encoded><![CDATA[
arXiv:2504.17079v1 Announce Type: new 
Abstract: In this article, we introduce a novel deep learning hybrid model that integrates attention Transformer and Gated Recurrent Unit (GRU) architectures to improve the accuracy of cryptocurrency price predictions. By combining the Transformer's strength in capturing long-range patterns with the GRU's ability to model short-term and sequential trends, the hybrid model provides a well-rounded approach to time series forecasting. We apply the model to predict the daily closing prices of Bitcoin and Ethereum based on historical data that include past prices, trading volumes, and the Fear and Greed index. We evaluate the performance of our proposed model by comparing it with four other machine learning models: two are non-sequential feedforward models: Radial Basis Function Network (RBFN) and General Regression Neural Network (GRNN), and two are bidirectional sequential memory-based models: Bidirectional Long-Short-Term Memory (BiLSTM) and Bidirectional Gated Recurrent Unit (BiGRU). The performance of the model is assessed using several metrics, including Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE), along with statistical validation through the nonparametric Friedman test followed by a post hoc Wilcoxon signed rank test. The results demonstrate that our hybrid model consistently achieves superior accuracy, highlighting its effectiveness for financial prediction tasks. These findings provide valuable insights for improving real-time decision making in cryptocurrency markets and support the growing use of hybrid deep learning models in financial analytics.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Subframework-based Bearing Rigidity Maintenance Control in Multirobot Networks</title>
<link>https://arxiv.org/abs/2504.17103</link>
<guid>https://arxiv.org/abs/2504.17103</guid>
<content:encoded><![CDATA[
arXiv:2504.17103v1 Announce Type: new 
Abstract: This work presents a novel approach for analyzing and controlling bearing rigidity in multi-robot networks with dynamic topology. By decomposing the system's framework into subframeworks, we express bearing rigidity, a global property, as a set of local properties, with rigidity eigenvalues serving as natural local rigidity metrics. We propose a decentralized, scalable, gradient-based controller that uses only bearing measurements to execute mission-specific commands. The controller preserves bearing rigidity by maintaining rigidity eigenvalues above a threshold, and also avoids inter-robot collisions. Simulations confirm the scheme's effectiveness, with information exchange confined to subframeworks, underscoring its scalability and practicality.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Developing a Blockchain-Based Secure Digital Contents Distribution System</title>
<link>https://arxiv.org/abs/2504.17194</link>
<guid>https://arxiv.org/abs/2504.17194</guid>
<content:encoded><![CDATA[
arXiv:2504.17194v1 Announce Type: new 
Abstract: As digital content distribution expands rapidly through online platforms, securing digital media and protecting intellectual property has become increasingly complex. Traditional centralized systems, while widely adopted, suffer from vulnerabilities such as single points of failure and limited traceability of unauthorized access. This paper presents a blockchain-based secure digital content distribution system that integrates Sia, a decentralized storage network, and Skynet, a content delivery network, to enhance content protection and distribution. The proposed system employs a dual-layer architecture: off-chain for user authentication and on-chain for transaction validation using smart contracts and asymmetric encryption. By introducing a license issuance and secret block mechanism, the system ensures content authenticity, privacy, and controlled access. Experimental results demonstrate the feasibility and scalability of the system in securely distributing multimedia files. The proposed platform not only improves content security but also paves the way for future enhancements with decentralized applications and integrated royalty payment mechanisms.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comment on "e-PoS: Making PoS Decentralized and Fair"</title>
<link>https://arxiv.org/abs/2504.17256</link>
<guid>https://arxiv.org/abs/2504.17256</guid>
<content:encoded><![CDATA[
arXiv:2504.17256v1 Announce Type: new 
Abstract: Proof-of-Stake (PoS) is a prominent Sybil control mechanism for blockchain-based systems. In "e-PoS: Making PoS Decentralized and Fair," Saad et al. (TPDS'21) introduced a new Proof-of-Stake protocol, e-PoS, to enhance PoS applications' decentralization and fairness. In this comment paper, we address a misunderstanding in the work of Saad et al. The conventional Proof-of-Stake model that causes the fairness problem does not align with the general concept of Proof-of-Stake nor the Proof-of-Stake cryptocurrencies mentioned in their paper.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Operational Semantics for Crystality: A Smart Contract Language for Parallel EVMs</title>
<link>https://arxiv.org/abs/2504.17336</link>
<guid>https://arxiv.org/abs/2504.17336</guid>
<content:encoded><![CDATA[
arXiv:2504.17336v1 Announce Type: new 
Abstract: The increasing demand for scalable blockchain has driven research into parallel execution models for smart contracts. Crystality is a novel smart contract programming language designed for parallel Ethereum Virtual Machines (EVMs), enabling fine-grained concurrency through Programmable Contract Scopes and Asynchronous Functional Relay. This paper presents the first formal structural operational semantics for Crystality, providing a rigorous framework to reason about its execution. We mechanize the syntax and semantics of Crystality in the theorem-proving assistant Coq, enabling formal verification of correctness properties. As a case study, we verify a simplified token transfer function, demonstrating the applicability of our semantics in ensuring smart contract correctness. Our work lays the foundation for formally verified parallel smart contracts, contributing to the security and scalability of blockchain systems.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience</title>
<link>https://arxiv.org/abs/2504.17461</link>
<guid>https://arxiv.org/abs/2504.17461</guid>
<content:encoded><![CDATA[
arXiv:2504.17461v1 Announce Type: new 
Abstract: Climate change increases the frequency of extreme rainfall, placing a significant strain on urban infrastructures, especially Combined Sewer Systems (CSS). Overflows from overburdened CSS release untreated wastewater into surface waters, posing environmental and public health risks. Although traditional physics-based models are effective, they are costly to maintain and difficult to adapt to evolving system dynamics. Machine Learning (ML) approaches offer cost-efficient alternatives with greater adaptability. To systematically assess the potential of ML for modeling urban infrastructure systems, we propose a protocol for evaluating Neural Network architectures for CSS time series forecasting with respect to predictive performance, model complexity, and robustness to perturbations. In addition, we assess model performance on peak events and critical fluctuations, as these are the key regimes for urban wastewater management. To investigate the feasibility of lightweight models suitable for IoT deployment, we compare global models, which have access to all information, with local models, which rely solely on nearby sensor readings. Additionally, to explore the security risks posed by network outages or adversarial attacks on urban infrastructure, we introduce error models that assess the resilience of models. Our results demonstrate that while global models achieve higher predictive performance, local models provide sufficient resilience in decentralized scenarios, ensuring robust modeling of urban infrastructure. Furthermore, models with longer native forecast horizons exhibit greater robustness to data perturbations. These findings contribute to the development of interpretable and reliable ML solutions for sustainable urban wastewater management. The implementation is available in our GitHub repository.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework</title>
<link>https://arxiv.org/abs/2504.17471</link>
<guid>https://arxiv.org/abs/2504.17471</guid>
<content:encoded><![CDATA[
arXiv:2504.17471v1 Announce Type: new 
Abstract: Gossip Learning (GL) is a decentralized learning paradigm where users iteratively exchange and aggregate models with a small set of neighboring peers. Recent GL approaches rely on dynamic communication graphs built and maintained using Random Peer Sampling (RPS) protocols. Thanks to graph dynamics, GL can achieve fast convergence even over extremely sparse topologies. However, the robustness of GL over dy- namic graphs to Byzantine (model poisoning) attacks remains unaddressed especially when Byzantine nodes attack the RPS protocol to scale up model poisoning. We address this issue by introducing GRANITE, a framework for robust learning over sparse, dynamic graphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two key components (i) a History-aware Byzantine-resilient Peer Sampling protocol (HaPS), which tracks previously encountered identifiers to reduce adversarial influence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which leverages an estimate of Byzantine presence to set aggregation thresholds with formal guarantees. Empirical results confirm that GRANITE maintains convergence with up to 30% Byzantine nodes, improves learning speed via adaptive filtering of poisoned models and obtains these results in up to 9 times sparser graphs than dictated by current theory.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Personalized Distributed Learning with Data and Node Heterogeneity</title>
<link>https://arxiv.org/abs/2504.17520</link>
<guid>https://arxiv.org/abs/2504.17520</guid>
<content:encoded><![CDATA[
arXiv:2504.17520v1 Announce Type: new 
Abstract: To jointly tackle the challenges of data and node heterogeneity in decentralized learning, we propose a distributed strong lottery ticket hypothesis (DSLTH), based on which a communication-efficient personalized learning algorithm is developed. In the proposed method, each local model is represented as the Hadamard product of global real-valued parameters and a personalized binary mask for pruning. The local model is learned by updating and fusing the personalized binary masks while the real-valued parameters are fixed among different agents. To further reduce the complexity of hardware implementation, we incorporate a group sparse regularization term in the loss function, enabling the learned local model to achieve structured sparsity. Then, a binary mask aggregation algorithm is designed by introducing an intermediate aggregation tensor and adding a personalized fine-tuning step in each iteration, which constrains model updates towards the local data distribution. The proposed method effectively leverages the relativity among agents while meeting personalized requirements in heterogeneous node conditions. We also provide a theoretical proof for the DSLTH, establishing it as the foundation of the proposed method. Numerical simulations confirm the validity of the DSLTH and demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste</title>
<link>https://arxiv.org/abs/2504.17539</link>
<guid>https://arxiv.org/abs/2504.17539</guid>
<content:encoded><![CDATA[
arXiv:2504.17539v1 Announce Type: new 
Abstract: Blockchain technology enables secure, transparent data management in decentralized systems, supporting applications from cryptocurrencies like Bitcoin to tokenizing real-world assets like property. Its scalability and sustainability hinge on consensus mechanisms balancing security and efficiency. Proof of Work (PoW), used by Bitcoin, ensures security through energy-intensive computations but demands significant resources. Proof of Stake (PoS), as in Ethereum post-Merge, selects validators based on staked cryptocurrency, offering energy efficiency but risking centralization from wealth concentration. With AI models straining computational resources, we propose Proof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI, workers perform AI tasks like language processing or image analysis to earn coins, which are staked to secure the network, blending security with practical utility. Decentralized nodes--job posters, market coordinators, workers, and validators --collaborate via smart contracts to manage tasks and rewards.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Time Series Classification with ROCKET Features</title>
<link>https://arxiv.org/abs/2504.17617</link>
<guid>https://arxiv.org/abs/2504.17617</guid>
<content:encoded><![CDATA[
arXiv:2504.17617v1 Announce Type: new 
Abstract: Time series classification (TSC) is a critical task with applications in various domains, including healthcare, finance, and industrial monitoring. Due to privacy concerns and data regulations, Federated Learning has emerged as a promising approach for learning from distributed time series data without centralizing raw information. However, most FL solutions rely on a client-server architecture, which introduces robustness and confidentiality risks related to the distinguished role of the server, which is a single point of failure and can observe knowledge extracted from clients. To address these challenges, we propose DROCKS, a fully decentralized FL framework for TSC that leverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS, the global model is trained by sequentially traversing a structured path across federation nodes, where each node refines the model and selects the most effective local kernels before passing them to the successor. Extensive experiments on the UCR archive demonstrate that DROCKS outperforms state-of-the-art client-server FL approaches while being more resilient to node failures and malicious attacks. Our code is available at https://anonymous.4open.science/r/DROCKS-7FF3/README.md.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to Single-Feature Adversarial Perturbations</title>
<link>https://arxiv.org/abs/2504.17684</link>
<guid>https://arxiv.org/abs/2504.17684</guid>
<content:encoded><![CDATA[
arXiv:2504.17684v1 Announce Type: new 
Abstract: This paper explores the vulnerability of machine learning models to simple single-feature adversarial attacks in the context of Ethereum fraudulent transaction detection. Through comprehensive experimentation, we investigate the impact of various adversarial attack strategies on model performance metrics. Our findings, highlighting how prone those techniques are to simple attacks, are alarming, and the inconsistency in the attacks' effect on different algorithms promises ways for attack mitigation. We examine the effectiveness of different mitigation strategies, including adversarial training and enhanced feature selection, in enhancing model robustness and show their effectiveness.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence</title>
<link>https://arxiv.org/abs/2504.17703</link>
<guid>https://arxiv.org/abs/2504.17703</guid>
<content:encoded><![CDATA[
arXiv:2504.17703v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a transformative paradigm in the field of distributed machine learning, enabling multiple clients such as mobile devices, edge nodes, or organizations to collaboratively train a shared global model without the need to centralize sensitive data. This decentralized approach addresses growing concerns around data privacy, security, and regulatory compliance, making it particularly attractive in domains such as healthcare, finance, and smart IoT systems. This survey provides a concise yet comprehensive overview of Federated Learning, beginning with its core architecture and communication protocol. We discuss the standard FL lifecycle, including local training, model aggregation, and global updates. A particular emphasis is placed on key technical challenges such as handling non-IID (non-independent and identically distributed) data, mitigating system and hardware heterogeneity, reducing communication overhead, and ensuring privacy through mechanisms like differential privacy and secure aggregation. Furthermore, we examine emerging trends in FL research, including personalized FL, cross-device versus cross-silo settings, and integration with other paradigms such as reinforcement learning and quantum computing. We also highlight real-world applications and summarize benchmark datasets and evaluation metrics commonly used in FL research. Finally, we outline open research problems and future directions to guide the development of scalable, efficient, and trustworthy FL systems.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks</title>
<link>https://arxiv.org/abs/2402.16201</link>
<guid>https://arxiv.org/abs/2402.16201</guid>
<content:encoded><![CDATA[
arXiv:2402.16201v4 Announce Type: replace 
Abstract: Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and table consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\geq50\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aegis: Tethering a Blockchain with Primary-Chain Stake</title>
<link>https://arxiv.org/abs/2406.05904</link>
<guid>https://arxiv.org/abs/2406.05904</guid>
<content:encoded><![CDATA[
arXiv:2406.05904v3 Announce Type: replace 
Abstract: Blockchains implement decentralized monetary systems and applications. Recent advancements enable what we call tethering a blockchain to a primary blockchain, securing the tethered chain by nodes that post primary-chain tokens as collateral. The collateral ensures nodes behave as intended, until they withdraw it. Unlike a Proof of Stake blockchain which uses its own token as collateral, using primary-chain tokens shields the tethered chain from the volatility of its own token.
  State-of-the-art tethered blockchains either rely on centralization, or make extreme assumptions: that all communication is synchronous, that operators remain correct even post-withdrawal, or that withdrawals can be indefinitely delayed by tethered-chain failures.
  We prove that with partial synchrony, there is no solution to the problem. However, under the standard assumptions that communication with the primary chain is synchronous and communication among the tethered chain nodes is partially synchronous, there is a solution. We present a tethered-chain protocol called Aegis. Aegis uses references from its blocks to primary blocks to define committees, checkpoints on the primary chain to perpetuate decisions, and resets to establish new committees when previous ones become obsolete. It ensures safety at all times and rapid progress when latency among Aegis nodes is low.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MEV Capture Through Time-Advantaged Arbitrage</title>
<link>https://arxiv.org/abs/2410.10797</link>
<guid>https://arxiv.org/abs/2410.10797</guid>
<content:encoded><![CDATA[
arXiv:2410.10797v2 Announce Type: replace 
Abstract: As blockchains begin processing significant economic activity, the ability to include and order transactions inevitably becomes highly valuable, a concept known as Maximal Extractable Value (MEV). This makes effective mechanisms for transaction inclusion and ordering, and thereby the extraction of MEV, a key aspect of blockchain design. Beyond traditional approaches such as ordering in a first-come-first-serve manner or using priority fees, a recent proposal suggests auctioning off a time advantage for transaction inclusion. In this paper, we investigate this time advantage mechanism, focusing specifically on arbitrage opportunities on Automated Market Makers (AMMs), one of the largest sources of MEV today. We analyze the optimal strategy for a time-advantaged arbitrageur and compare the profits generated by various MEV extraction methods. Finally, we explore how AMMs can be adapted in the time advantage setting to capture a portion of the MEV.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating DAO Sustainability and Longevity Through On-Chain Governance Metrics</title>
<link>https://arxiv.org/abs/2504.11341</link>
<guid>https://arxiv.org/abs/2504.11341</guid>
<content:encoded><![CDATA[
arXiv:2504.11341v2 Announce Type: replace 
Abstract: Decentralised Autonomous Organisations (DAOs) automate governance and resource allocation through smart contracts, aiming to shift decision-making to distributed token holders. However, many DAOs face sustainability challenges linked to limited user participation, concentrated voting power, and technical design constraints. This paper addresses these issues by identifying research gaps in DAO evaluation and introducing a framework of Key Performance Indicators (KPIs) that capture governance efficiency, financial robustness, decentralisation, and community engagement. We apply the framework to a custom-built dataset of real-world DAOs constructed from on-chain data and analysed using non-parametric methods. The results reveal recurring governance patterns, including low participation rates and high proposer concentration, which may undermine long-term viability. The proposed KPIs offer a replicable, data-driven method for assessing DAO governance structures and identifying potential areas for improvement. These findings support a multidimensional approach to evaluating decentralised systems and provide practical tools for researchers and practitioners working to improve the resilience and effectiveness of DAO-based governance models.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Driven Solutions for Carbon Credit Trading: A Decentralized Platform for SMEs</title>
<link>https://arxiv.org/abs/2504.16085</link>
<guid>https://arxiv.org/abs/2504.16085</guid>
<content:encoded><![CDATA[
arXiv:2504.16085v1 Announce Type: new 
Abstract: The increasing demand for sustainability and compliance with global carbon regulations has posed significant challenges for small and medium-sized enterprises (SMEs). This paper proposes a blockchain-based decentralized carbon credit trading platform tailored for SMEs in Taiwan, aiming to simplify the complex carbon trading process and lower market entry barriers. Drawing upon the Diffusion of Innovations theory and transaction cost economics, we illustrate how blockchain technology can reduce informational asymmetry and intermediary costs in carbon markets. By integrating Ethereum-based smart contracts, the platform automates transactions, enhances transparency, and reduces administrative burdens - addressing key obstacles such as technical complexity and market risks. A controlled experimental design was conducted to compare the proposed system with a conventional centralized carbon trading platform. Statistical analysis confirms its effectiveness in minimizing time and expenses while ensuring compliance with the Carbon Border Adjustment Mechanism (CBAM) and the Clean Competition Act (CCA). User satisfaction was measured using the Kano model, with the results identifying essential features and prioritizing future enhancements. This study contributes a more comprehensive solution for SMEs seeking to achieve carbon neutrality, underscoring the transformative potential of blockchain technology in global carbon markets.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Carbyne: An Ultra-Lightweight DoS-Resilient Mempool for Bitcoin</title>
<link>https://arxiv.org/abs/2504.16089</link>
<guid>https://arxiv.org/abs/2504.16089</guid>
<content:encoded><![CDATA[
arXiv:2504.16089v1 Announce Type: new 
Abstract: The increasing adoption of cryptocurrencies has significantly amplified the resource requirements for operating full nodes, creating substantial barriers to entry. Unlike miners, who are financially incentivized through block rewards and transaction fees, full nodes lack direct economic compensation for their critical role in maintaining the network. A key resource burden is the transaction pool, which is particularly memory-intensive as it temporarily stores unconfirmed transactions awaiting verification and propagation across the network. We present Neonpool, a novel optimization for transaction pool leveraging bloom filter variants to drastically reduce memory consumption by up to 200 (e.g., 400 MB to 2 MB) while maintaining over 99.99% transaction processing accuracy. Implemented in C++ and evaluated on unique Bitcoin and Ethereum datasets, Neonpool enables efficient operation on lightweight clients, such as smartphones, IoT devices, and systems-on-a-chip, without requiring a hard fork. By lowering the cost of node participation, Neonpool enhances decentralization and strengthens the overall security and robustness of cryptocurrency networks.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Based Vulnerability Analysis of NFT Smart Contracts</title>
<link>https://arxiv.org/abs/2504.16113</link>
<guid>https://arxiv.org/abs/2504.16113</guid>
<content:encoded><![CDATA[
arXiv:2504.16113v1 Announce Type: new 
Abstract: In the research experiment of this article, our research work is divided into several stages. Firstly, we collected a large number of smart contract codes and classified them, identifying several common defects, including Risky Mutably Porxy, ERC-721 Recentrancy, Unlimited Mining, Missing Requirements, and Public Burns. Secondly, we used Python to process the smart contracts. On the one hand, we modified the file names, and on the other hand, we batched the process of the content for analysis and application. Next, we built a model of the decision tree. Firstly, we carried out the feature extraction. We selected the algorithm and divided the data. After comparing and processing, we chose the CART classification tree to process. By gene coefficient, we analyzed and sorted the data, and got the initial model of the decision tree. Then, we introduced the random forest model on the basis of the decision tree. From abstracting the same amount of samples to selecting features randomly.From adjusting and optimizing parameters to completing the construction of the forest model. Finally, we compared and analyzed the decision tree, random forest, and self-built model in the paper and drew general conclusions.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DMind Benchmark: The First Comprehensive Benchmark for LLM Evaluation in the Web3 Domain</title>
<link>https://arxiv.org/abs/2504.16116</link>
<guid>https://arxiv.org/abs/2504.16116</guid>
<content:encoded><![CDATA[
arXiv:2504.16116v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have led to significant progress on a wide range of natural language processing tasks. However, their effectiveness in specialized and rapidly evolving domains such as Web3 remains underexplored. In this paper, we introduce DMind Benchmark, a novel framework that systematically tests LLMs across nine key categories encompassing blockchain fundamentals, infrastructure, smart contract analysis, decentralized finance (DeFi), decentralized autonomous organizations (DAOs), non-fungible tokens (NFTs), token economics, meme concepts, and security vulnerabilities.
  DMind Benchmark goes beyond conventional multiple-choice questions by incorporating domain-specific subjective tasks (e.g., smart contract code auditing and repair, numeric reasoning on on-chain data, and fill-in assessments), thereby capturing real-world complexities and stress-testing model adaptability. We evaluate fifteen popular LLMs (from ChatGPT, DeepSeek, Claude, and Gemini series) on DMind Benchmark, uncovering performance gaps in Web3-specific reasoning and application, particularly in emerging areas like token economics and meme concepts. Even the strongest models face significant challenges in identifying subtle security vulnerabilities and analyzing complex DeFi mechanisms. To foster progress in this area, we publicly release our benchmark dataset, evaluation pipeline, and annotated results at http://www.dmind.ai, offering a valuable resource for advancing specialized domain adaptation and the development of more robust Web3-enabled LLMs.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Meets Adaptive Honeypots: A Trust-Aware Approach to Next-Gen IoT Security</title>
<link>https://arxiv.org/abs/2504.16226</link>
<guid>https://arxiv.org/abs/2504.16226</guid>
<content:encoded><![CDATA[
arXiv:2504.16226v1 Announce Type: new 
Abstract: Edge computing-based Next-Generation Wireless Networks (NGWN)-IoT offer enhanced bandwidth capacity for large-scale service provisioning but remain vulnerable to evolving cyber threats. Existing intrusion detection and prevention methods provide limited security as adversaries continually adapt their attack strategies. We propose a dynamic attack detection and prevention approach to address this challenge. First, blockchain-based authentication uses the Deoxys Authentication Algorithm (DAA) to verify IoT device legitimacy before data transmission. Next, a bi-stage intrusion detection system is introduced: the first stage uses signature-based detection via an Improved Random Forest (IRF) algorithm. In contrast, the second stage applies feature-based anomaly detection using a Diffusion Convolution Recurrent Neural Network (DCRNN). To ensure Quality of Service (QoS) and maintain Service Level Agreements (SLA), trust-aware service migration is performed using Heap-Based Optimization (HBO). Additionally, on-demand virtual High-Interaction honeypots deceive attackers and extract attack patterns, which are securely stored using the Bimodal Lattice Signature Scheme (BLISS) to enhance signature-based Intrusion Detection Systems (IDS). The proposed framework is implemented in the NS3 simulation environment and evaluated against existing methods across multiple performance metrics, including accuracy, attack detection rate, false negative rate, precision, recall, ROC curve, memory usage, CPU usage, and execution time. Experimental results demonstrate that the framework significantly outperforms existing approaches, reinforcing the security of NGWN-enabled IoT ecosystems
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Distributed Federated Learning Aggregation Placement using Particle Swarm Intelligence</title>
<link>https://arxiv.org/abs/2504.16227</link>
<guid>https://arxiv.org/abs/2504.16227</guid>
<content:encoded><![CDATA[
arXiv:2504.16227v1 Announce Type: new 
Abstract: Federated learning has become a promising distributed learning concept with extra insurance on data privacy. Extensive studies on various models of Federated learning have been done since the coinage of its term. One of the important derivatives of federated learning is hierarchical semi-decentralized federated learning, which distributes the load of the aggregation task over multiple nodes and parallelizes the aggregation workload at the breadth of each level of the hierarchy. Various methods have also been proposed to perform inter-cluster and intra-cluster aggregation optimally. Most of the solutions, nonetheless, require monitoring the nodes' performance and resource consumption at each round, which necessitates frequently exchanging systematic data. To optimally perform distributed aggregation in SDFL with minimal reliance on systematic data, we propose Flag-Swap, a Particle Swarm Optimization (PSO) method that optimizes the aggregation placement according only to the processing delay. Our simulation results show that PSO-based placement can find the optimal placement relatively fast, even in scenarios with many clients as candidates for aggregation. Our real-world docker-based implementation of Flag-Swap over the recently emerged FL framework shows superior performance compared to black-box-based deterministic placement strategies, with about 43% minutes faster than random placement, and 32% minutes faster than uniform placement, in terms of total processing time.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Two-Fold Byzantine Fault Tolerance Algorithm: Byzantine Consensus in Blockchain</title>
<link>https://arxiv.org/abs/2504.16267</link>
<guid>https://arxiv.org/abs/2504.16267</guid>
<content:encoded><![CDATA[
arXiv:2504.16267v1 Announce Type: new 
Abstract: Blockchain technology offers a decentralized and secure method for storing and authenticating data, rendering it well-suited for various applications such as digital currencies, supply chain management, and voting systems. However, the decentralized nature of blockchain also exposes it to vulnerabilities, particularly Byzantine faults, which arise when nodes in the network behave maliciously or encounter unexpected failures. Such incidents can result in inconsistencies within the blockchain and, in extreme scenarios, lead to a breakdown in consensus. Byzantine fault-tolerant consensus algorithms are crafted to tackle this challenge by ensuring that network nodes can agree on the blockchain's state even in the presence of faulty or malicious nodes. To bolster the system's resilience against these faults, it is imperative to detect them within the system. However, our examination of existing literature reveals a prevalent assumption: solutions typically operate under constraints regarding the number of faulty nodes. Such constraints confine the proposed solutions to ideal environments, limiting their practical applicability. In response, we propose a novel approach inspired by social paradigms, employing a trusted and fully monitored communication sub-process to detect Byzantine nodes. Upon detection, these nodes can be either disregarded in the consensus-building process, subjected to penalties, or undergo modifications as per the system's policy. Finally, we statistically demonstrate that our approach achieves a detection probability that exceeds 95\% for Byzantine nodes. In essence, our methodology ensures that if Byzantine nodes exhibit malicious behavior, healthy nodes can identify them with a confidence level of 95\%.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DTVM: Revolutionizing Smart Contract Execution with Determinism and Compatibility</title>
<link>https://arxiv.org/abs/2504.16552</link>
<guid>https://arxiv.org/abs/2504.16552</guid>
<content:encoded><![CDATA[
arXiv:2504.16552v1 Announce Type: new 
Abstract: We introduce the DeTerministic Virtual Machine (DTVM) Stack, a next-generation smart contract execution framework designed to address critical performance, determinism, and ecosystem compatibility challenges in blockchain networks. Building upon WebAssembly (Wasm) while maintaining full Ethereum Virtual Machine (EVM) ABI compatibility, DTVM introduces a Deterministic Middle Intermediate Representation (dMIR) and a hybrid lazy-JIT compilation engine to balance compilation speed and execution efficiency. DTVM further accommodates diverse instruction set architectures (e.g., EVM, RISC-V) through modular adaptation layers. This enables seamless integration with DTVM's hybrid lazy-JIT compilation engine, which dynamically optimizes performance while preserving deterministic execution guarantees across heterogeneous environments. The key contributions including: 1). The framework achieves up to 2$\times$ acceleration over evmone in dominant Ethereum contract (e.g. ERC20/721/1155) execution and reduces fibonacci computation latency by 11.8$\sim$40.5% compared to Wasm based VMs. 2). A novel trampoline hot-switch mechanism enables sub-millisecond (0.95ms) post-deployment invocation times, outperforming up to about 23$\times$ in compilation and invocation efficiency. 3). It supports multi-language development (Solidity, C++, Rust, Java, Go, and AssemblyScript) through unified bytecode conversion while maintaining EVM ABI compatibility for seamless invocation. It reduces machine code object sizes by 30.0$\sim$72.6%, coupled with a minimized Trusted Computing Base. 4). It offers SmartCogent, an AI-driven full-stack development experience, leveraging fine-tuned LLMs and retrieval-augmented generation to automate tasks across the smart contract lifecycle: development, debugging, security auditing, and deployment. DTVM Stack has been open-sourced (https://github.com/DTVMStack).
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simplified Swarm Learning Framework for Robust and Scalable Diagnostic Services in Cancer Histopathology</title>
<link>https://arxiv.org/abs/2504.16732</link>
<guid>https://arxiv.org/abs/2504.16732</guid>
<content:encoded><![CDATA[
arXiv:2504.16732v1 Announce Type: new 
Abstract: The complexities of healthcare data, including privacy concerns, imbalanced datasets, and interoperability issues, necessitate innovative machine learning solutions. Swarm Learning (SL), a decentralized alternative to Federated Learning, offers privacy-preserving distributed training, but its reliance on blockchain technology hinders accessibility and scalability. This paper introduces a \textit{Simplified Peer-to-Peer Swarm Learning (P2P-SL) Framework} tailored for resource-constrained environments. By eliminating blockchain dependencies and adopting lightweight peer-to-peer communication, the proposed framework ensures robust model synchronization while maintaining data privacy. Applied to cancer histopathology, the framework integrates optimized pre-trained models, such as TorchXRayVision, enhanced with DenseNet decoders, to improve diagnostic accuracy. Extensive experiments demonstrate the framework's efficacy in handling imbalanced and biased datasets, achieving comparable performance to centralized models while preserving privacy. This study paves the way for democratizing advanced machine learning in healthcare, offering a scalable, accessible, and efficient solution for privacy-sensitive diagnostic applications.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Formal Verification of Blockchain Nonforking in DAG-Based BFT Consensus with Dynamic Stake</title>
<link>https://arxiv.org/abs/2504.16853</link>
<guid>https://arxiv.org/abs/2504.16853</guid>
<content:encoded><![CDATA[
arXiv:2504.16853v1 Announce Type: new 
Abstract: Blockchain consensus protocols enable participants to agree on consistent views of the blockchain that may be ahead or behind relative to each other but do not fork into different chains. A number of recently popular Byzantine-fault-tolerant (BFT) protocols first construct a directed acyclic graph (DAG) that partially orders transactions, then linearize the DAG into a blockchain that totally orders transactions. The definitions and correctness proofs of these DAG-based protocols typically assume that the set of participants is fixed, which is impractical in long-lived blockchains. Additionally, only a few of those proofs have been machine-checked, uncovering errors in some published proofs. We developed a formal model of a DAG-based BFT protocol with dynamic stake, where participants can join and leave at every block, with stake used to weigh decisions in the protocol. We formally proved that blockchains never fork in the model, also clarifying how BFT bounds on faulty participants generalize to these highly dynamic sets of participants. Our model and proofs are formalized in the ACL2 theorem prover, apply to arbitrarily long executions and arbitrarily large system states, and are verified in 1 minute by ACL2.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Language for Smart Contracts with Secure Control Flow (Technical Report)</title>
<link>https://arxiv.org/abs/2407.01204</link>
<guid>https://arxiv.org/abs/2407.01204</guid>
<content:encoded><![CDATA[
arXiv:2407.01204v2 Announce Type: replace 
Abstract: Smart contracts are frequently vulnerable to control-flow attacks based on confused deputies, reentrancy, and incorrect error handling. These attacks exploit the complexity of interactions among multiple possibly unknown contracts. Existing best practices to prevent vulnerabilities rely on code patterns and heuristics that produce both false positives and false negatives. Even with extensive audits and heuristic tools, new vulnerabilities continue to arise, routinely costing tens of millions of dollars.
  We introduce SCIF, a language for secure smart contracts, that addresses these classes of control-flow attacks. By extending secure information flow mechanisms in a principled way, SCIF enforces both classic end-to-end information flow security and new security restrictions on control flow, even when SCIF contracts interact with malicious non-SCIF code. SCIF is implemented as a compiler to Solidity. We show how SCIF can secure contracts with minimal overhead through case studies of applications with intricate security reasoning and a large corpus of insecure code.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nav-SCOPE: Swarm Robot Cooperative Perception and Coordinated Navigation</title>
<link>https://arxiv.org/abs/2409.10049</link>
<guid>https://arxiv.org/abs/2409.10049</guid>
<content:encoded><![CDATA[
arXiv:2409.10049v2 Announce Type: replace 
Abstract: This paper proposes a lightweight systematic solution for multi-robot coordinated navigation with decentralized cooperative perception. An information flow is first created to facilitate real-time observation sharing over unreliable ad-hoc networks. Then, the environmental uncertainties of each robot are reduced by interaction fields that deliver complementary information. Finally, path optimization is achieved, enabling self-organized coordination with effective convergence, divergence, and collision avoidance. Our method is fully interpretable and ready for deployment without gaps. Comprehensive simulations and real-world experiments demonstrate reduced path redundancy, robust performance across various tasks, and minimal demands on computation and communication.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PoGO: A Scalable Proof of Useful Work via Quantized Gradient Descent and Merkle Proofs</title>
<link>https://arxiv.org/abs/2504.07540</link>
<guid>https://arxiv.org/abs/2504.07540</guid>
<content:encoded><![CDATA[
arXiv:2504.07540v2 Announce Type: replace 
Abstract: We present a design called Proof of Gradient Optimization (PoGO) for blockchain consensus, where miners produce verifiable evidence of training large-scale machine-learning models. Building on previous work, we incorporate quantized gradients (4-bit precision) to reduce storage and computation requirements, while still preserving the ability of verifiers to check that real progress has been made on lowering the model's loss. Additionally, we employ Merkle proofs over the full 32-bit model to handle large parameter sets and to enable random leaf checks with minimal on-chain data. We illustrate these ideas using GPT-3 (175B parameters) as a reference example and also refer to smaller but high-performance models (e.g., Gemma~3 with 27B parameters). We provide an empirical cost analysis showing that verification is significantly cheaper than training, thanks in part to quantization and sampling. We also discuss the necessity of longer block times (potentially hours) when incorporating meaningful training steps, the trade-offs when using specialized GPU hardware, and how binary diffs may incrementally optimize updates. Finally, we note that fine-tuning can be handled in a similar manner, merely changing the dataset and the manner of sampling but preserving the overall verification flow. Our protocol allows verifiers to issue either positive or negative attestations; these are aggregated at finalization to either confirm the update or slash the miner.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralised collaborative action: cryptoeconomics in space</title>
<link>https://arxiv.org/abs/2504.12493</link>
<guid>https://arxiv.org/abs/2504.12493</guid>
<content:encoded><![CDATA[
arXiv:2504.12493v2 Announce Type: replace 
Abstract: Blockchains and peer-to-peer systems are part of a trend towards computer systems that are "radically decentralised", by which we mean that they 1) run across many participants, 2) without central control, and 3) are such that qualities 1 and 2 are essential to the system's intended use cases.
  We propose a notion of topological space, which we call a "semitopology", to help us mathematically model such systems. We treat participants as points in a space, which are organised into "actionable coalitions". An actionable coalition is any set of participants who collectively have the resources to collaborate (if they choose) to progress according to the system's rules, without involving any other participants in the system.
  It turns out that much useful information about the system can be obtained \emph{just} by viewing it as a semitopology and studying its actionable coalitions. For example: we will prove a mathematical sense in which if every actionable coalition of some point p has nonempty intersection with every actionable coalition of another point q -- note that this is the negation of the famous Hausdorff separation property from topology -- then p and q must remain in agreement.
  This is of practical interest, because remaining in agreement is a key correctness property in many distributed systems. For example in blockchain, participants disagreeing is called "forking", and blockchain designers try hard to avoid it.
  We provide an accessible introduction to: the technical context of decentralised systems; why we build them and find them useful; how they motivate the theory of semitopological spaces; and we sketch some basic theorems and applications of the resulting mathematics.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Anatomical Federated Network (Dafne): An open client-server framework for the continuous, collaborative improvement of deep learning-based medical image segmentation</title>
<link>https://arxiv.org/abs/2302.06352</link>
<guid>https://arxiv.org/abs/2302.06352</guid>
<content:encoded><![CDATA[
arXiv:2302.06352v4 Announce Type: replace-cross 
Abstract: Purpose: To present and evaluate Dafne (deep anatomical federated network), a freely available decentralized, collaborative deep learning system for the semantic segmentation of radiological images through federated incremental learning. Materials and Methods: Dafne is free software with a client-server architecture. The client side is an advanced user interface that applies the deep learning models stored on the server to the user's data and allows the user to check and refine the prediction. Incremental learning is then performed at the client's side and sent back to the server, where it is integrated into the root model. Dafne was evaluated locally, by assessing the performance gain across model generations on 38 MRI datasets of the lower legs, and through the analysis of real-world usage statistics (n = 639 use-cases). Results: Dafne demonstrated a statistically improvement in the accuracy of semantic segmentation over time (average increase of the Dice Similarity Coefficient by 0.007 points/generation on the local validation set, p < 0.001). Qualitatively, the models showed enhanced performance on various radiologic image types, including those not present in the initial training sets, indicating good model generalizability. Conclusion: Dafne showed improvement in segmentation quality over time, demonstrating potential for learning and generalization.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Does Your Blockchain Need Multidimensional Transaction Fees?</title>
<link>https://arxiv.org/abs/2504.15438</link>
<guid>https://arxiv.org/abs/2504.15438</guid>
<content:encoded><![CDATA[
arXiv:2504.15438v1 Announce Type: new 
Abstract: Blockchains have block-size limits to ensure the entire cluster can keep up with the tip of the chain. These block-size limits are usually single-dimensional, but richer multidimensional constraints allow for greater throughput. The potential for performance improvements from multidimensional resource pricing has been discussed in the literature, but exactly how big those performance improvements are remains unclear. In order to identify the magnitude of additional throughput that multi-dimensional transaction fees can unlock, we introduce the concept of an $\alpha$-approximation. A constraint set $C_1$ is $\alpha$-approximated by $C_2$ if every block feasible under $C_1$ is also feasible under $C_2$ once all resource capacities are scaled by a factor of $\alpha$ (e.g., $\alpha =2$ corresponds to doubling all available resources). We show that the $\alpha$-approximation of the optimal single-dimensional gas measure corresponds to the value of a specific zero-sum game. However, the more general problem of finding the optimal $k$-dimensional approximation is NP-complete. Quantifying the additional throughput that multi-dimensional fees can provide allows blockchain designers to make informed decisions about whether the additional capacity unlocked by multidimensional constraints is worth the additional complexity they add to the protocol.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tracing Cross-chain Transactions between EVM-based Blockchains: An Analysis of Ethereum-Polygon Bridges</title>
<link>https://arxiv.org/abs/2504.15449</link>
<guid>https://arxiv.org/abs/2504.15449</guid>
<content:encoded><![CDATA[
arXiv:2504.15449v1 Announce Type: new 
Abstract: Ethereum's scalability has been a major concern due to its limited transaction throughput and high fees. To address these limitations, Polygon has emerged as a sidechain solution that facilitates asset transfers between Ethereum and Polygon, thereby improving scalability and reducing costs. However, current cross-chain transactions, particularly those between Ethereum and Polygon, lack transparency and traceability. This paper proposes a method to track cross-chain transactions across EVM-compatible blockchains. It leverages the unique feature that user addresses are consistent across EVM-compatible blockchains. We develop a matching heuristic algorithm that links transactions between the source and target chains by combining transaction time, value, and token identification. Applying our methodology to over 2 million cross-chain transactions (August 2020-August 2023) between Ethereum and Polygon, we achieve matching rates of up to 99.65% for deposits and 92.78% for withdrawals, across different asset types including Ether, ERC-20 tokens, and NFTs. In addition, we provide a comprehensive analysis of various properties and characteristics of cross-chain transactions. Our methodology and findings contribute to a better understanding of cross-chain transaction dynamics and bridge performance, with implications for improving bridge efficiency and security in cross-chain operations.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TrojanDam: Detection-Free Backdoor Defense in Federated Learning through Proactive Model Robustification utilizing OOD Data</title>
<link>https://arxiv.org/abs/2504.15674</link>
<guid>https://arxiv.org/abs/2504.15674</guid>
<content:encoded><![CDATA[
arXiv:2504.15674v1 Announce Type: new 
Abstract: Federated learning (FL) systems allow decentralized data-owning clients to jointly train a global model through uploading their locally trained updates to a centralized server. The property of decentralization enables adversaries to craft carefully designed backdoor updates to make the global model misclassify only when encountering adversary-chosen triggers. Existing defense mechanisms mainly rely on post-training detection after receiving updates. These methods either fail to identify updates which are deliberately fabricated statistically close to benign ones, or show inconsistent performance in different FL training stages. The effect of unfiltered backdoor updates will accumulate in the global model, and eventually become functional. Given the difficulty of ruling out every backdoor update, we propose a backdoor defense paradigm, which focuses on proactive robustification on the global model against potential backdoor attacks. We first reveal that the successful launching of backdoor attacks in FL stems from the lack of conflict between malicious and benign updates on redundant neurons of ML models. We proceed to prove the feasibility of activating redundant neurons utilizing out-of-distribution (OOD) samples in centralized settings, and migrating to FL settings to propose a novel backdoor defense mechanism, TrojanDam. The proposed mechanism has the FL server continuously inject fresh OOD mappings into the global model to activate redundant neurons, canceling the effect of backdoor updates during aggregation. We conduct systematic and extensive experiments to illustrate the superior performance of TrojanDam, over several SOTA backdoor defense methods across a wide range of FL settings.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustworthy Decentralized Autonomous Machines: A New Paradigm in Automation Economy</title>
<link>https://arxiv.org/abs/2504.15676</link>
<guid>https://arxiv.org/abs/2504.15676</guid>
<content:encoded><![CDATA[
arXiv:2504.15676v1 Announce Type: new 
Abstract: Decentralized Autonomous Machines (DAMs) represent a transformative paradigm in automation economy, integrating artificial intelligence (AI), blockchain technology, and Internet of Things (IoT) devices to create self-governing economic agents participating in Decentralized Physical Infrastructure Networks (DePIN). Capable of managing both digital and physical assets and unlike traditional Decentralized Autonomous Organizations (DAOs), DAMs extend autonomy into the physical world, enabling trustless systems for Real and Digital World Assets (RDWAs). In this paper, we explore the technological foundations, and challenges of DAMs and argue that DAMs are pivotal in transitioning from trust-based to trustless economic models, offering scalable, transparent, and equitable solutions for asset management. The integration of AI-driven decision-making, IoT-enabled operational autonomy, and blockchain-based governance allows DAMs to decentralize ownership, optimize resource allocation, and democratize access to economic opportunities. Therefore, in this research, we highlight the potential of DAMs to address inefficiencies in centralized systems, reduce wealth disparities, and foster a post-labor economy.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trusted Compute Units: A Framework for Chained Verifiable Computations</title>
<link>https://arxiv.org/abs/2504.15717</link>
<guid>https://arxiv.org/abs/2504.15717</guid>
<content:encoded><![CDATA[
arXiv:2504.15717v1 Announce Type: new 
Abstract: Blockchain and distributed ledger technologies (DLTs) facilitate decentralized computations across trust boundaries. However, ensuring complex computations with low gas fees and confidentiality remains challenging. Recent advances in Confidential Computing -- leveraging hardware-based Trusted Execution Environments (TEEs) -- and Proof-carrying Data -- employing cryptographic Zero-Knowledge Virtual Machines (zkVMs) -- hold promise for secure, privacy-preserving off-chain and layer-2 computations.On the other side, a homogeneous reliance on a single technology, such as TEEs or zkVMs, is impractical for decentralized environments with heterogeneous computational requirements. This paper introduces the Trusted Compute Unit (TCU), a unifying framework that enables composable and interoperable verifiable computations across heterogeneous technologies. Our approach allows decentralized applications (dApps) to flexibly offload complex computations to TCUs, obtaining proof of correctness. These proofs can be anchored on-chain for automated dApp interactions, while ensuring confidentiality of input data, and integrity of output data. We demonstrate how TCUs can support a prominent blockchain use case, such as federated learning. By enabling secure off-chain interactions without incurring on-chain confirmation delays or gas fees, TCUs significantly improve system performance and scalability. Experimental insights and performance evaluations confirm the feasibility and practicality of this unified approach, advancing the state of the art in verifiable off-chain services for the blockchain ecosystem.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Vulnerability Injection in Solidity Smart Contracts: A Mutation-Based Approach for Benchmark Development</title>
<link>https://arxiv.org/abs/2504.15948</link>
<guid>https://arxiv.org/abs/2504.15948</guid>
<content:encoded><![CDATA[
arXiv:2504.15948v1 Announce Type: new 
Abstract: The security of smart contracts is critical in blockchain systems, where even minor vulnerabilities can lead to substantial financial losses. Researchers proposed several vulnerability detection tools evaluated using existing benchmarks. However, most benchmarks are outdated and focus on a narrow set of vulnerabilities. This work evaluates whether mutation seeding can effectively inject vulnerabilities into Solidity-based smart contracts and whether state-of-the-art static analysis tools can detect the injected flaws. We aim to automatically inject vulnerabilities into smart contracts to generate large and wide benchmarks. We propose MuSe, a tool to generate vulnerable smart contracts by leveraging pattern-based mutation operators to inject six vulnerability types into real-world smart contracts. We analyzed these vulnerable smart contracts using Slither, a static analysis tool, to determine its capacity to identify them and assess their validity. The results show that each vulnerability has a different injection rate. Not all smart contracts can exhibit some vulnerabilities because they lack the prerequisites for injection. Furthermore, static analysis tools fail to detect all vulnerabilities injected using pattern-based mutations, underscoring the need for enhancements in static analyzers and demonstrating that benchmarks generated by mutation seeding tools can improve the evaluation of detection tools.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Charting the Uncharted: The Landscape of Monero Peer-to-Peer Network</title>
<link>https://arxiv.org/abs/2504.15986</link>
<guid>https://arxiv.org/abs/2504.15986</guid>
<content:encoded><![CDATA[
arXiv:2504.15986v1 Announce Type: new 
Abstract: The Monero blockchain enables anonymous transactions through advanced cryptography in its peer-to-peer network, which underpins decentralization, security, and trustless interactions. However, privacy measures obscure peer connections, complicating network analysis. This study proposes a method to infer peer connections in Monero's latest protocol version, where timestamp data is unavailable. We collect peerlist data from TCP flows, validate our inference algorithm, and map the network structure. Our results show high accuracy, improving with longer observation periods. This work is the first to reveal connectivity patterns in Monero's updated protocol, providing visualizations and insights into its topology. Our findings enhance the understanding of Monero's P2P network, including the role of supernodes, and highlight potential protocol and security improvements.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Line Graph-Based Framework for Identifying Optimal Routing Paths in Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2504.15809</link>
<guid>https://arxiv.org/abs/2504.15809</guid>
<content:encoded><![CDATA[
arXiv:2504.15809v1 Announce Type: cross 
Abstract: Decentralized exchanges, such as those employing constant product market makers (CPMMs) like Uniswap V2, play a crucial role in the blockchain ecosystem by enabling peer-to-peer token swaps without intermediaries. Despite the increasing volume of transactions, there remains limited research on identifying optimal trading paths across multiple DEXs. This paper presents a novel line-graph-based algorithm (LG) designed to efficiently discover profitable trading routes within DEX environments. We benchmark LG against the widely adopted Depth-First Search (DFS) algorithm under a linear routing scenario, encompassing platforms such as Uniswap, SushiSwap, and PancakeSwap. Experimental results demonstrate that LG consistently identifies trading paths that are as profitable as, or more profitable than, those found by DFS, while incurring comparable gas costs. Evaluations on Uniswap V2 token graphs across two temporal snapshots further validate LG's performance. Although LG exhibits exponential runtime growth with respect to graph size in empirical tests, it remains viable for practical, real-world use cases. Our findings underscore the potential of the LG algorithm for industrial adoption, offering tangible benefits to traders and market participants in the DeFi space.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Supply Chain Insecurity: The Lack of Integrity Protection in SBOM Solutions</title>
<link>https://arxiv.org/abs/2412.05138</link>
<guid>https://arxiv.org/abs/2412.05138</guid>
<content:encoded><![CDATA[
arXiv:2412.05138v3 Announce Type: replace 
Abstract: The SolarWinds attack, which exploited weaknesses in a software update mechanism, highlights the critical need for organizations to have better visibility into their software dependencies and potential vulnerabilities associated with them. The Software Bill of Materials (SBOM) is paramount in ensuring software supply chain security. Under the Executive Order issued by President Biden, the adoption of the SBOM has become obligatory within the United States. The executive order mandates that an SBOM must be provided for all software purchased by federal agencies. In this paper, we present an in-depth and systematic investigation of the trust that can be put into the output of SBOMs. Our research reveals that the SBOM generation process across popular programming languages is susceptible to stealthy manipulation by malicious insiders, leading to significant supply chain insecurities. We then investigated the tools used to consume SBOMs, examining their capability to detect and handle manipulated or compromised SBOM data. To address these security issues, we analyze the use of public repositories for software libraries to validate the integrity of dependencies and demonstrate the feasibility of our proof-of-concept implementation. We further evaluate an alternative, decentralized approach based on blockchain.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems</title>
<link>https://arxiv.org/abs/2504.10915</link>
<guid>https://arxiv.org/abs/2504.10915</guid>
<content:encoded><![CDATA[
arXiv:2504.10915v2 Announce Type: replace 
Abstract: The rise of autonomous AI agents, capable of perceiving, reasoning, and acting independently, signals a profound shift in how digital ecosystems operate, govern, and evolve. As these agents proliferate beyond centralized infrastructures, they expose foundational gaps in identity, accountability, and ethical alignment. Three critical questions emerge: Identity: Who or what is the agent? Accountability: Can its actions be verified, audited, and trusted? Ethical Consensus: Can autonomous systems reliably align with human values and prevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered Orchestration for Knowledgeful Agents), a unified, systems-level architecture for building ethically governed, interoperable AI agent ecosystems. LOKA introduces a proposed Universal Agent Identity Layer (UAIL) for decentralized, verifiable identity; intent-centric communication protocols for semantic coordination across diverse agents; and a Decentralized Ethical Consensus Protocol (DECP) that could enable agents to make context-aware decisions grounded in shared ethical baselines. Anchored in emerging standards such as Decentralized Identifiers (DIDs), Verifiable Credentials (VCs), and post-quantum cryptography, LOKA proposes a scalable, future-resilient blueprint for multi-agent AI governance. By embedding identity, trust, and ethics into the protocol layer itself, LOKA proposes the foundation for a new era of responsible, transparent, and autonomous AI ecosystems operating across digital and physical domains.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID Federated Learning</title>
<link>https://arxiv.org/abs/2504.12875</link>
<guid>https://arxiv.org/abs/2504.12875</guid>
<content:encoded><![CDATA[
arXiv:2504.12875v2 Announce Type: replace 
Abstract: Federated learning (FL) enables collaborative model training using decentralized private data from multiple clients. While FL has shown robustness against poisoning attacks with basic defenses, our research reveals new vulnerabilities stemming from non-independent and identically distributed (non-IID) data among clients. These vulnerabilities pose a substantial risk of model poisoning in real-world FL scenarios.
  To demonstrate such vulnerabilities, we develop a novel collaborative backdoor poisoning attack called CollaPois. In this attack, we distribute a single pre-trained model infected with a Trojan to a group of compromised clients. These clients then work together to produce malicious gradients, causing the FL model to consistently converge towards a low-loss region centered around the Trojan-infected model. Consequently, the impact of the Trojan is amplified, especially when the benign clients have diverse local data distributions and scattered local gradients. CollaPois stands out by achieving its goals while involving only a limited number of compromised clients, setting it apart from existing attacks. Also, CollaPois effectively avoids noticeable shifts or degradation in the FL model's performance on legitimate data samples, allowing it to operate stealthily and evade detection by advanced robust FL algorithms.
  Thorough theoretical analysis and experiments conducted on various benchmark datasets demonstrate the superiority of CollaPois compared to state-of-the-art backdoor attacks. Notably, CollaPois bypasses existing backdoor defenses, especially in scenarios where clients possess diverse data distributions. Moreover, the results show that CollaPois remains effective even when involving a small number of compromised clients. Notably, clients whose local data is closely aligned with compromised clients experience higher risks of backdoor infections.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Stateless Clients in Ethereum: Benchmarking Verkle Trees and Binary Merkle Trees with SNARKs</title>
<link>https://arxiv.org/abs/2504.14069</link>
<guid>https://arxiv.org/abs/2504.14069</guid>
<content:encoded><![CDATA[
arXiv:2504.14069v1 Announce Type: new 
Abstract: Ethereum, the leading platform for decentralized applications, faces challenges in maintaining decentralization due to the significant hardware requirements for validators to store Ethereum's entire state. To address this, the concept of stateless clients is under exploration, enabling validators to verify transactions using cryptographic witnesses rather than the full state. This paper compares two approaches currently being discussed for achieving statelessness: Verkle trees utilizing vector commitments and binary Merkle trees combined with SNARKs. Benchmarks are performed to evaluate proving time, witness size, and verification time. The results reveal that the Verkle tree implementation used for benchmarking offers proving and verification times on the order of seconds and proof sizes on the order of one MB. The SNARK-based Merkle trees exhibit slow proof generation times, while offering constant and fast verification time. Overall, the results indicate for Verkle trees to provide a more practical solution for Ethereum's stateless future, but both methods offer valuable insights into reducing the state burden on Ethereum nodes. We make the code used for benchmarking available on GitHub.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Signaling Mechanisms</title>
<link>https://arxiv.org/abs/2504.14163</link>
<guid>https://arxiv.org/abs/2504.14163</guid>
<content:encoded><![CDATA[
arXiv:2504.14163v1 Announce Type: new 
Abstract: We study a system composed of multiple distinct service locations that aims to convince customers to join the system by providing information to customers. We cast the system's information design problem in the framework of Bayesian persuasion and describe centralized and decentralized signaling. We provide efficient methods for computing the system's optimal centralized and decentralized signaling mechanisms and derive a performance guarantee for decentralized signaling when the locations' states are independent. The guarantee states that the probability that a customer joins under optimal decentralized signaling is bounded below by the product of a strictly positive constant and the probability that a customer joins under optimal centralized signaling. The constant depends only on the number of service locations. We provide an example that shows that the constant cannot be improved. We consider an extension to more-general objectives for the system and establish that the same guarantee continues to hold. We also extend our analysis to systems where the locations' states are correlated, and again derive a performance guarantee for decentralized signaling in that setting. For the correlated setting, we prove that the guarantee's asymptotic dependence upon the number of locations cannot be substantially improved. A comparison of our guarantees for independent locations and for correlated locations reveals the influence of dependence on the performance of decentralized signaling.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedC4: Graph Condensation Meets Client-Client Collaboration for Efficient and Private Federated Graph Learning</title>
<link>https://arxiv.org/abs/2504.14188</link>
<guid>https://arxiv.org/abs/2504.14188</guid>
<content:encoded><![CDATA[
arXiv:2504.14188v1 Announce Type: new 
Abstract: Federated Graph Learning (FGL) is an emerging distributed learning paradigm that enables collaborative model training over decentralized graph-structured data while preserving local privacy. Existing FGL methods can be categorized into two optimization architectures: (1) the Server-Client (S-C) paradigm, where clients upload local models for server-side aggregation; and (2) the Client-Client (C-C) paradigm, which allows direct information exchange among clients to support personalized training. Compared to S-C, the C-C architecture better captures global graph knowledge and enables fine-grained optimization through customized peer-to-peer communication. However, current C-C methods often broadcast identical and redundant node embeddings, incurring high communication costs and privacy risks. To address this, we propose FedC4, a novel framework that combines graph Condensation with Client-Client Collaboration. Instead of transmitting raw node-level features, FedC4 distills each client's private graph into a compact set of synthetic node embeddings, reducing communication overhead and enhancing privacy. In addition, FedC4 introduces three modules that allow source clients to send distinct node representations tailored to target clients'graph structures, enabling personalized optimization with global guidance. Extensive experiments on eight real-world datasets show that FedC4 outperforms state-of-the-art baselines in both performance and communication efficiency.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ScaloWork: Useful Proof-of-Work with Distributed Pool Mining</title>
<link>https://arxiv.org/abs/2504.14328</link>
<guid>https://arxiv.org/abs/2504.14328</guid>
<content:encoded><![CDATA[
arXiv:2504.14328v1 Announce Type: new 
Abstract: Bitcoin blockchain uses hash-based Proof-of-Work (PoW) that prevents unwanted participants from hogging the network resources. Anyone entering the mining game has to prove that they have expended a specific amount of computational power. However, the most popular Bitcoin blockchain consumes 175.87 TWh of electrical energy annually, and most of this energy is wasted on hash calculations, which serve no additional purpose. Several studies have explored re-purposing the wasted energy by replacing the hash function with meaningful computational problems that have practical applications. Minimum Dominating Set (MDS) in networks has numerous real-life applications. Building on this concept, Chrisimos [TrustCom '23] was proposed to replace hash-based PoW with the computation of a dominating set on real-life graph instances. However, Chrisimos has several drawbacks regarding efficiency and solution quality. This work presents a new framework for Useful PoW, ScaloWork, that decides the block proposer for the Bitcoin blockchain based on the solution for the dominating set problem. ScaloWork relies on the property of graph isomorphism and guarantees solution extractability. We also propose a distributed approach for calculating the dominating set, allowing miners to collaborate in a pool. This enables ScaloWork to handle larger graphs relevant to real-life applications, thereby enhancing scalability. Our framework also eliminates the problem of free-riders, ensuring fairness in the distribution of block rewards. We perform a detailed security analysis of our framework and prove our scheme as secure as hash-based PoW. We implement a prototype of our framework, and the results show that our system outperforms Chrisimos in all aspects.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralization in PoS Blockchain Consensus: Quantification and Advancement</title>
<link>https://arxiv.org/abs/2504.14351</link>
<guid>https://arxiv.org/abs/2504.14351</guid>
<content:encoded><![CDATA[
arXiv:2504.14351v1 Announce Type: new 
Abstract: Decentralization is a foundational principle of permissionless blockchains, with consensus mechanisms serving a critical role in its realization. This study quantifies the decentralization of consensus mechanisms in proof-of-stake (PoS) blockchains using a comprehensive set of metrics, including Nakamoto coefficients, Gini, Herfindahl Hirschman Index (HHI), Shapley values, and Zipfs coefficient. Our empirical analysis across ten prominent blockchains reveals significant concentration of stake among a few validators, posing challenges to fair consensus. To address this, we introduce two alternative weighting models for PoS consensus: Square Root Stake Weight (SRSW) and Logarithmic Stake Weight (LSW), which adjust validator influence through non-linear transformations. Results demonstrate that SRSW and LSW models improve decentralization metrics by an average of 51% and 132%, respectively, supporting more equitable and resilient blockchain systems.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Publicly Verifiable Secret Sharing: Generic Constructions and Lattice-Based Instantiations in the Standard Model</title>
<link>https://arxiv.org/abs/2504.14381</link>
<guid>https://arxiv.org/abs/2504.14381</guid>
<content:encoded><![CDATA[
arXiv:2504.14381v1 Announce Type: new 
Abstract: Publicly verifiable secret sharing (PVSS) allows a dealer to share a secret among a set of shareholders so that the secret can be reconstructed later from any set of qualified participants. In addition, any public verifier should be able to check the correctness of the sharing and reconstruction process. PVSS has been demonstrated to yield various applications, such as e-voting, distributed key generation, decentralized random number generation protocols, and multi-party computation. Although many concrete PVSS protocols have been proposed, their security is either proven in the random oracle model or relies on quantum-vulnerable assumptions such as factoring or discrete logarithm. In this work, we put forward a generic construction for PVSS that can be instantiated in the standard model under the Learning With Errors (LWE) assumption. Our instantiation provides the first post-quantum PVSS in the standard model, with a reasonable level of asymptotic efficiency.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Planet as a Brain: Towards Internet of AgentSites based on AIOS Server</title>
<link>https://arxiv.org/abs/2504.14411</link>
<guid>https://arxiv.org/abs/2504.14411</guid>
<content:encoded><![CDATA[
arXiv:2504.14411v1 Announce Type: new 
Abstract: The internet is undergoing a historical transformation from the "Internet of Websites" to the "Internet of AgentSites." While traditional Websites served as the foundation for information hosting and dissemination, a new frontier is emerging where AgentSites serve as the hubs of the internet, where each AgentSite hosts one or more AI agents that receive tasks, address them, and deliver actionable solutions, marking a significant shift in the digital landscape and representing the next generation of online ecosystems. Under this vision, AIOS, the AI Agent Operating System, serves as the server for the development, deployment and execution of AI agents, which is a fundamental infrastructure for the Internet of Agentsites.
  In this paper, we introduce AIOS Server, a runtime framework to host agents and enable global-scale collaboration among decentralized agents. AIOS Server provides a communication protocol leveraging the Model Context Protocol (MCP) and JSON-RPC to enable agent-agent or human-agent interactions. Each AIOS node operates as a server to host and execute agents, while supporting peer-to-peer coordination without reliance on centralized orchestration. Based on AIOS Server, we further present the world's first practically deployed Internet of Agentsites (AIOS-IoA), including AgentHub for agent registration and discovery and AgentChat for interactive communication, at https://planet.aios.foundation. The agent discovery mechanism based on Distributed Hash Tables (DHT) and a Gossip protocol serves as the search engine for the internet of agentsites. This work provides a practical foundation for building the Internet of Agentsites-a new paradigm where autonomous agents become first-class citizens of the web. The implementation is available at https://github.com/agiresearch/AIOS.Server and will be integrated into the AIOS main branch at https://github.com/agiresearch/AIOS.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Critically: Selective Self Distillation in Federated Learning on Non-IID Data</title>
<link>https://arxiv.org/abs/2504.14694</link>
<guid>https://arxiv.org/abs/2504.14694</guid>
<content:encoded><![CDATA[
arXiv:2504.14694v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train a global model while keeping local data decentralized. Data heterogeneity (non-IID) across clients has imposed significant challenges to FL, which makes local models re-optimize towards their own local optima and forget the global knowledge, resulting in performance degradation and convergence slowdown. Many existing works have attempted to address the non-IID issue by adding an extra global-model-based regularizing item to the local training but without an adaption scheme, which is not efficient enough to achieve high performance with deep learning models. In this paper, we propose a Selective Self-Distillation method for Federated learning (FedSSD), which imposes adaptive constraints on the local updates by self-distilling the global model's knowledge and selectively weighting it by evaluating the credibility at both the class and sample level. The convergence guarantee of FedSSD is theoretically analyzed and extensive experiments are conducted on three public benchmark datasets, which demonstrates that FedSSD achieves better generalization and robustness in fewer communication rounds, compared with other state-of-the-art FL methods.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proactive Radio Resource Allocation for 6G In-Factory Subnetworks</title>
<link>https://arxiv.org/abs/2504.14718</link>
<guid>https://arxiv.org/abs/2504.14718</guid>
<content:encoded><![CDATA[
arXiv:2504.14718v1 Announce Type: new 
Abstract: 6G In-Factory Subnetworks (InF-S) have recently been introduced as short-range, low-power radio cells installed in robots and production modules to support the strict requirements of modern control systems. Information freshness, characterized by the Age of Information (AoI), is crucial to guarantee the stability and accuracy of the control loop in these systems. However, achieving strict AoI performance poses significant challenges considering the limited resources and the high dynamic environment of InF-S. In this work, we introduce a proactive radio resource allocation approach to minimize the AoI violation probability. The proposed approach adopts a decentralized learning framework using Bayesian Ridge Regression (BRR) to predict the future AoI by actively learning the system dynamics. Based on the predicted AoI value, radio resources are proactively allocated to minimize the probability of AoI exceeding a predefined threshold, hence enhancing the reliability and accuracy of the control loop. The conducted simulation results prove the effectiveness of our proposed approach to improve the AoI performance where a reduction of 98% is achieved in the AoI violation probability compared to relevant baseline methods.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>vApps: Verifiable Applications at Internet Scale</title>
<link>https://arxiv.org/abs/2504.14809</link>
<guid>https://arxiv.org/abs/2504.14809</guid>
<content:encoded><![CDATA[
arXiv:2504.14809v1 Announce Type: new 
Abstract: Blockchain technology promises decentralized, trustless, and interoperable infrastructure. However, widespread adoption remains hindered by issues such as limited scalability, high transaction costs, and the complexity of maintaining coherent verification logic across different blockchain layers. This paper introduces Verifiable Applications (vApps), a novel development framework designed to streamline the creation and deployment of verifiable blockchain computing applications. vApps offer a unified Rust-based Domain-Specific Language (DSL) within a comprehensive SDK, featuring modular abstractions for verification, proof generation, and inter-chain connectivity. This eases the developer's burden in securing diverse software components, allowing them to focus on application logic. The DSL also ensures that applications can automatically take advantage of specialized precompiles and hardware acceleration to achieve consistently high performance with minimal developer effort, as demonstrated by benchmark results for zero-knowledge virtual machines (zkVMs). Experiments show that native Rust execution eliminates interpretation overhead, delivering up to an 832x cycle count improvement compared to EVM-based approaches. Precompiled circuits accelerate proving by over 95%, while GPU acceleration boosts throughput by up to 30x and recursion compresses proof size by up to 230x, enabling succinct and efficient verification. The framework also supports seamless integration with Web2 and Web3 systems, enabling developers to focus solely on their application logic. Through modular architecture, robust security guarantees, and composability, vApps pave the way toward a trust-minimized and verifiable Internet-scale application environment.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Security Framework for General Blockchain Layer 2 Protocols</title>
<link>https://arxiv.org/abs/2504.14965</link>
<guid>https://arxiv.org/abs/2504.14965</guid>
<content:encoded><![CDATA[
arXiv:2504.14965v1 Announce Type: new 
Abstract: Layer 2 (L2) solutions are the cornerstone of blockchain scalability, enabling high-throughput and low-cost interactions by shifting execution off-chain while maintaining security through interactions with the underlying ledger. Despite their common goals, the principal L2 paradigms -- payment channels, rollups, and sidechains -- differ substantially in architecture and assumptions, making it difficult to comparatively analyze their security and trade-offs.
  To address this, we present the first general security framework for L2 protocols. Our framework is based on the IITM-based Universal Composability (iUC) framework, in which L2 protocols are modeled as stateful machines interacting with higher-level protocol users and the underlying ledger. The methodology defines a generic execution environment that captures ledger events, message passing, and adversarial scheduling, and characterizes security through trace-based predicates parameterized by adversarial capabilities and timing assumptions. By abstracting away from protocol-specific details while preserving critical interface and execution behavior, the framework enables modular, protocol-agnostic reasoning and composable security proofs across a wide range of L2 constructions.
  To demonstrate its applicability, we analyze an example from each of the three dominant L2 scaling paradigms: a payment channel (Brick), a sidechain (Liquid Network), and a rollup (Arbitrum). By instantiating each within our framework, we derive their security properties and expose trade-offs. These include the time for dispute resolution, distribution of off-chain storage and computation, and varying trust assumptions (e.g., reliance on honest parties or data availability). Our framework unifies the analysis of diverse L2 designs and pinpoints their strengths and limitations, providing a foundation for secure, systematic L2 development.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages</title>
<link>https://arxiv.org/abs/2504.15063</link>
<guid>https://arxiv.org/abs/2504.15063</guid>
<content:encoded><![CDATA[
arXiv:2504.15063v1 Announce Type: new 
Abstract: Smart contracts are the cornerstone of decentralized applications and financial protocols, which extend the application of digital currency transactions. The applications and financial protocols introduce significant security challenges, resulting in substantial economic losses. Existing solutions predominantly focus on code vulnerabilities within smart contracts, accounting for only 50% of security incidents. Therefore, a more comprehensive study of security issues related to smart contracts is imperative. The existing empirical research realizes the static analysis of smart contracts from the perspective of the lifecycle and gives the corresponding measures for each stage. However, they lack the characteristic analysis of vulnerabilities in each stage and the distinction between the vulnerabilities. In this paper, we present the first empirical study on the security of smart contracts throughout their lifecycle, including deployment and execution, upgrade, and destruction stages. It delves into the security issues at each stage and provides at least seven feature descriptions. Finally, utilizing these seven features, five machine-learning classification models are used to identify vulnerabilities at different stages. The classification results reveal that vulnerable contracts exhibit distinct transaction features and ego network properties at various stages.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Review on Privacy in DAG-Based DLTs</title>
<link>https://arxiv.org/abs/2504.15233</link>
<guid>https://arxiv.org/abs/2504.15233</guid>
<content:encoded><![CDATA[
arXiv:2504.15233v1 Announce Type: new 
Abstract: Directed Acyclic Graph (DAG)-based Distributed Ledger Technologies (DLTs) have emerged as a promising solution to the scalability issues inherent in traditional blockchains. However, amidst the focus on scalability, the crucial aspect of privacy within DAG-based DLTs has been largely overlooked. This paper seeks to address this gap by providing a comprehensive examination of privacy notions and challenges within DAG-based DLTs. We delve into potential methodologies to enhance privacy within these systems, while also analyzing the associated hurdles and real-world implementations within state-of-the-art DAG-based DLTs. By exploring these methodologies, we not only illuminate the current landscape of privacy in DAG-based DLTs but also outline future research directions in this evolving field.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully Adaptive Stepsizes: Which System Benefit More -- Centralized or Decentralized?</title>
<link>https://arxiv.org/abs/2504.15196</link>
<guid>https://arxiv.org/abs/2504.15196</guid>
<content:encoded><![CDATA[
arXiv:2504.15196v1 Announce Type: cross 
Abstract: In decentralized optimization, the choice of stepsize plays a critical role in algorithm performance. A common approach is to use a shared stepsize across all agents to ensure convergence. However, selecting an optimal stepsize often requires careful tuning, which can be time-consuming and may lead to slow convergence, especially when there is significant variation in the smoothness (L-smoothness) of local objective functions across agents. Individually tuning stepsizes per agent is also impractical, particularly in large-scale networks. To address these limitations, we propose AdGT, an adaptive gradient tracking method that enables each agent to adjust its stepsize based on the smoothness of its local objective. We prove that AdGT generates a sequence of iterates that converges to the optimal consensus solution. Through numerical experiments, we compare AdGT with fixed-stepsize gradient tracking methods and demonstrate its superior performance. Additionally, we compare AdGT with adaptive gradient descent (AdGD) in a centralized setting and observe that fully adaptive stepsizes offer greater benefits in decentralized networks than in centralized ones.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MeritRank: Sybil Tolerant Reputation for Merit-based Tokenomics</title>
<link>https://arxiv.org/abs/2207.09950</link>
<guid>https://arxiv.org/abs/2207.09950</guid>
<content:encoded><![CDATA[
arXiv:2207.09950v2 Announce Type: replace 
Abstract: Decentralized reputation systems are emerging as promising mechanisms to enhance the effectiveness of token-based economies. Unlike traditional monetary incentives, these systems reward participants based on the actual value of their contributions to the network. However, the advantages and challenges associated with such systems remain largely unexplored. In this work, we investigate the inherent trade-offs in designing a decentralized reputation system that is simultaneously generalizable, trustless, and Sybil-resistant. Specifically, `generalizable' means that the system can assess various types of contributions across different contexts, `trustless' indicates that it functions without the need for a central authority to oversee reputations, and `Sybil-resistant' refers to its ability to withstand manipulations by fake identities, i.e., Sybil attacks.
  We propose MeritRank, a Sybil-tolerant reputation system based on feedback aggregation from participants. Instead of entirely preventing Sybil attacks, our approach effectively limits the benefits that attackers can gain from such strategies. This is achieved by reducing the perceived value of the attacker's and Sybil nodes' contributions through the application of decay mechanisms -- specifically, transitivity decay, connectivity decay, and epoch decay. Using a dataset of participant interactions in MakerDAO, we conducted experiments to demonstrate the Sybil tolerance of MeritRank.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fairness Notions in DAG-based DLTs</title>
<link>https://arxiv.org/abs/2308.04831</link>
<guid>https://arxiv.org/abs/2308.04831</guid>
<content:encoded><![CDATA[
arXiv:2308.04831v2 Announce Type: replace 
Abstract: This paper investigates the issue of fairness in Distributed Ledger Technology (DLT), specifically focusing on the shortcomings observed in current blockchain systems due to Miner Extractable Value (MEV) phenomena and systemic centralization. We explore the potential of Directed Acyclic Graphs (DAGs) as a solution to address or mitigate these fairness concerns. Our objective is to gain a comprehensive understanding of fairness in DAG-based DLTs by examining its different aspects and measurement metrics. We aim to establish a shared knowledge base that facilitates accurate fairness assessment and allows for an evaluation of whether DAG-based DLTs offer a more equitable design. We describe the various dimensions of fairness and conduct a comparative analysis to examine how they relate to different components of DLTs. This analysis serves as a catalyst for further research, encouraging the development of cryptographic systems that promote fairness.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Industrial Metaverse: Enabling Technologies, Open Problems, and Future Trends</title>
<link>https://arxiv.org/abs/2405.08542</link>
<guid>https://arxiv.org/abs/2405.08542</guid>
<content:encoded><![CDATA[
arXiv:2405.08542v2 Announce Type: replace 
Abstract: As an emerging technology that enables seamless integration between the physical and virtual worlds, the Metaverse has great potential to be deployed in the industrial production field with the development of extended reality (XR) and next-generation communication networks. This deployment, called the Industrial Metaverse, is used for product design, production operations, industrial quality inspection, and product testing. However, there lacks of in-depth understanding of the enabling technologies associated with the Industrial Metaverse. This encompasses both the precise industrial scenarios targeted by each technology and the potential migration of technologies developed in other domains to the industrial sector. Driven by this issue, in this article, we conduct a comprehensive survey of the state-of-the-art literature on the Industrial Metaverse. Specifically, we first analyze the advantages of the Metaverse for industrial production. Then, we review a collection of key enabling technologies of the Industrial Metaverse, including blockchain (BC), digital twin (DT), 6G, XR, and artificial intelligence (AI), and analyze how these technologies can support different aspects of industrial production. Subsequently, we present numerous formidable challenges encountered within the Industrial Metaverse, including confidentiality and security concerns, resource limitations, and interoperability constraints. Furthermore, we investigate the extant solutions devised to address them. Finally, we briefly outline several open issues and future research directions of the Industrial Metaverse.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Based Secure Vehicle Auction System with Smart Contracts</title>
<link>https://arxiv.org/abs/2501.04841</link>
<guid>https://arxiv.org/abs/2501.04841</guid>
<content:encoded><![CDATA[
arXiv:2501.04841v3 Announce Type: replace 
Abstract: The problem of a single point of failure in centralized systems poses a great challenge to the stability of such systems. Meanwhile, the tamperability of data within centralized systems makes users reluctant to trust and use centralized applications in many scenarios, including the financial and business sectors.
  Blockchain, as a new decentralized technology, addresses these issues effectively. As a typical decentralized system, blockchain can be utilized to build a data-sharing model. Users in a blockchain do not need to trust other users; instead, they trust that the majority of miner nodes are honest. Smart contracts enable developers to write distributed programs based on blockchain systems, ensuring that all code is immutable and secure.
  In this paper, we analyze the security of blockchain technology to illustrate its advantages and justify its use. Furthermore, we design a new system for storing and trading vehicle information based on the Ethereum blockchain and smart contract technology. Specifically, our system allows users to upload vehicle information and auction vehicles to transfer ownership. Our application provides great convenience to buyers and owners, while the use of smart contracts enhances the security and privacy of the system.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Auctions with Tokens: Monetary Policy as a Mechanism Design Choice</title>
<link>https://arxiv.org/abs/2301.13794</link>
<guid>https://arxiv.org/abs/2301.13794</guid>
<content:encoded><![CDATA[
arXiv:2301.13794v3 Announce Type: replace-cross 
Abstract: I study a repeated auction in which payments are made with a blockchain token created and initially owned by the auction designer. Unlike the ``virtual money'' previously examined in mechanism design, such tokens can be saved and traded outside the mechanism. I show that the present-discounted value of expected revenues equals that of a conventional dollar auction, but revenues accrue earlier and are less volatile. The optimal monetary policy burns the tokens used for payment, a practice common in blockchain-based protocols. I also show that the same outcome can be reproduced in a dollar auction if the auctioneer issues a suitable dollar-denominated security. This equivalence breaks down with moral hazard and contracting frictions: with severe contracting frictions the token auction dominates, whereas with mild contracting frictions the dollar auction combined with a dollar-denominated financial instrument is preferred.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bibliometric Analysis of Scientific Publications on Blockchain Research and Applications</title>
<link>https://arxiv.org/abs/2504.13387</link>
<guid>https://arxiv.org/abs/2504.13387</guid>
<content:encoded><![CDATA[
arXiv:2504.13387v1 Announce Type: new 
Abstract: Since the introduction of Bitcoin in 2008, blockchain technology has garnered widespread attention. Scholars from various research fields, countries, and institutions have published a significant number of papers on this subject. However, there is currently a lack of comprehensive analysis specifically focusing on the scientific publications in the field of blockchain.
  To conduct a comprehensive analysis, we compiled a corpus of 41,497 publications in blockchain research from 2008 to 2023 using the Clarivate databases. Through bibliometric and citation analyses, we gained valuable insights into the field. Our study offers an overview of the blockchain research landscape, including country, institution, authorship, and subject categories. Additionally, we identified Emerging Research Areas (ERA) using the co-citation clustering approach, examining factors such as recency, growth, and contributions from different countries/regions. Furthermore, we identified influential publications based on citation velocity and analyzed five representative Research Fronts in detail. This analysis provides a fine-grained examination of specific areas within blockchain research. Our findings contribute to understanding evolving trends, emerging applications, and potential directions for future research in the multidisciplinary field of blockchain.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Insecurity Through Obscurity: Veiled Vulnerabilities in Closed-Source Contracts</title>
<link>https://arxiv.org/abs/2504.13398</link>
<guid>https://arxiv.org/abs/2504.13398</guid>
<content:encoded><![CDATA[
arXiv:2504.13398v1 Announce Type: new 
Abstract: Most blockchains cannot hide the binary code of programs (i.e., smart contracts) running on them. To conceal proprietary business logic and to potentially deter attacks, many smart contracts are closed-source and employ layers of obfuscation. However, we demonstrate that such obfuscation can obscure critical vulnerabilities rather than enhance security, a phenomenon we term insecurity through obscurity. To systematically analyze these risks on a large scale, we present SKANF, a novel EVM bytecode analysis tool tailored for closed-source and obfuscated contracts. SKANF combines control-flow deobfuscation, symbolic execution, and concolic execution based on historical transactions to identify and exploit asset management vulnerabilities. Our evaluation on real-world Maximal Extractable Value (MEV) bots reveals that SKANF detects vulnerabilities in 1,028 contracts and successfully generates exploits for 373 of them, with potential losses exceeding \$9.0M. Additionally, we uncover 40 real-world MEV bot attacks that collectively resulted in \$900K in losses.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Addendum to NeBula: Towards Extending TEAM CoSTAR's Solution to Larger Scale Environments</title>
<link>https://arxiv.org/abs/2504.13461</link>
<guid>https://arxiv.org/abs/2504.13461</guid>
<content:encoded><![CDATA[
arXiv:2504.13461v1 Announce Type: new 
Abstract: This paper presents an appendix to the original NeBula autonomy solution developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), participating in the DARPA Subterranean Challenge. Specifically, this paper presents extensions to NeBula's hardware, software, and algorithmic components that focus on increasing the range and scale of the exploration environment. From the algorithmic perspective, we discuss the following extensions to the original NeBula framework: (i) large-scale geometric and semantic environment mapping; (ii) an adaptive positioning system; (iii) probabilistic traversability analysis and local planning; (iv) large-scale POMDP-based global motion planning and exploration behavior; (v) large-scale networking and decentralized reasoning; (vi) communication-aware mission planning; and (vii) multi-modal ground-aerial exploration solutions. We demonstrate the application and deployment of the presented systems and solutions in various large-scale underground environments, including limestone mine exploration scenarios as well as deployment in the DARPA Subterranean challenge.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bitcoin's Edge: Embedded Sentiment in Blockchain Transactional Data</title>
<link>https://arxiv.org/abs/2504.13598</link>
<guid>https://arxiv.org/abs/2504.13598</guid>
<content:encoded><![CDATA[
arXiv:2504.13598v1 Announce Type: new 
Abstract: Cryptocurrency blockchains, beyond their primary role as distributed payment systems, are increasingly used to store and share arbitrary content, such as text messages and files. Although often non-financial, this hidden content can impact price movements by conveying private information, shaping sentiment, and influencing public opinion. However, current analyses of such data are limited in scope and scalability, primarily relying on manual classification or hand-crafted heuristics. In this work, we address these limitations by employing Natural Language Processing techniques to analyze, detect patterns, and extract public sentiment encoded within blockchain transactional data. Using a variety of Machine Learning techniques, we showcase for the first time the predictive power of blockchain-embedded sentiment in forecasting cryptocurrency price movements on the Bitcoin and Ethereum blockchains. Our findings shed light on a previously underexplored source of freely available, transparent, and immutable data and introduce blockchain sentiment analysis as a novel and robust framework for enhancing financial predictions in cryptocurrency markets. Incidentally, we discover an asymmetry between cryptocurrencies; Bitcoin has an informational advantage over Ethereum in that the sentiment embedded into transactional data is sufficient to predict its price movement.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Distributed Arrays: Provably Secure Networking for Data Availability Sampling</title>
<link>https://arxiv.org/abs/2504.13757</link>
<guid>https://arxiv.org/abs/2504.13757</guid>
<content:encoded><![CDATA[
arXiv:2504.13757v1 Announce Type: new 
Abstract: Data Availability Sampling (DAS), a central component of Ethereum's roadmap, enables clients to verify data availability without requiring any single client to download the entire dataset. DAS operates by having clients randomly retrieve individual symbols of erasure-encoded data from a peer-to-peer network. While the cryptographic and encoding aspects of DAS have recently undergone formal analysis, the peer-to-peer networking layer remains underexplored, with a lack of security definitions and efficient, provably secure constructions.
  In this work, we address this gap by introducing a novel distributed data structure that can serve as the networking layer for DAS, which we call \emph{robust distributed arrays}. That is, we rigorously define a robustness property of a distributed data structure in an open permissionless network, that mimics a collection of arrays.
  Then, we give a simple and efficient construction and formally prove its robustness. Notably, every individual node is required to store only small portions of the data, and accessing array positions incurs minimal latency. The robustness of our construction relies solely on the presence of a minimal \emph{absolute} number of honest nodes in the network. In particular, we avoid any honest majority assumption.
  Beyond DAS, we anticipate that robust distributed arrays can have wider applications in distributed systems.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection</title>
<link>https://arxiv.org/abs/2504.13186</link>
<guid>https://arxiv.org/abs/2504.13186</guid>
<content:encoded><![CDATA[
arXiv:2504.13186v1 Announce Type: cross 
Abstract: The rapid advancement of deep learning (DL) has transformed healthcare, particularly in cancer detection and diagnosis. DL surpasses traditional machine learning and human accuracy, making it a critical tool for identifying diseases. Despite numerous reviews on DL in healthcare, a comprehensive analysis of its role in cancer detection remains limited. Existing studies focus on specific aspects, leaving gaps in understanding its broader impact. This paper addresses these gaps by reviewing advanced DL techniques, including transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These approaches enhance accuracy, tackle data scarcity, and enable decentralized learning while maintaining data privacy. TL adapts pre-trained models to new datasets, improving performance with limited labeled data. RL optimizes diagnostic pathways and treatment strategies, while FL fosters collaborative model development without sharing sensitive data. Transformers and LLMs, traditionally used in natural language processing, are now applied to medical data for improved interpretability. Additionally, this review examines these techniques' efficiency in cancer diagnosis, addresses challenges like data imbalance, and proposes solutions. It serves as a resource for researchers and practitioners, providing insights into current trends and guiding future research in advanced DL for cancer detection.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Decentralized Quantum Kernel Learning for Noisy and Adversarial Environment</title>
<link>https://arxiv.org/abs/2504.13782</link>
<guid>https://arxiv.org/abs/2504.13782</guid>
<content:encoded><![CDATA[
arXiv:2504.13782v1 Announce Type: cross 
Abstract: This paper proposes a general decentralized framework for quantum kernel learning (QKL). It has robustness against quantum noise and can also be designed to defend adversarial information attacks forming a robust approach named RDQKL. We analyze the impact of noise on QKL and study the robustness of decentralized QKL to the noise. By integrating robust decentralized optimization techniques, our method is able to mitigate the impact of malicious data injections across multiple nodes. Experimental results demonstrate that our approach maintains high accuracy under noisy quantum operations and effectively counter adversarial modifications, offering a promising pathway towards the future practical, scalable and secure quantum machine learning (QML).
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>If LLMs Would Just Look: Simple Line-by-line Checking Improves Vulnerability Localization</title>
<link>https://arxiv.org/abs/2410.15288</link>
<guid>https://arxiv.org/abs/2410.15288</guid>
<content:encoded><![CDATA[
arXiv:2410.15288v2 Announce Type: replace 
Abstract: The rapid expansion of software systems and the growing number of reported vulnerabilities have emphasized the importance of accurately identifying vulnerable code segments. Traditional methods for vulnerability localization, such as manual code audits or rule-based tools, are often time-consuming and limited in scope, typically focusing on specific programming languages or types of vulnerabilities. In recent years, the introduction of large language models (LLMs) such as GPT and LLaMA has opened new possibilities for automating vulnerability detection. However, while LLMs show promise in this area, they face challenges, particularly in maintaining accuracy over longer code contexts. This paper introduces LOVA, a novel framework leveraging the self-attention mechanisms inherent in LLMs to enhance vulnerability localization. Our key insight is that self-attention mechanisms assign varying importance to different parts of the input, making it possible to track how much attention the model focuses on specific lines of code. In the context of vulnerability localization, the hypothesis is that vulnerable lines of code will naturally attract higher attention weights because they have a greater influence on the model's output. By systematically tracking changes in attention weights and focusing on specific lines of code, LOVA improves the precision of identifying vulnerable lines across various programming languages. Through rigorous experimentation and evaluation, we demonstrate that LOVA significantly outperforms existing LLM-based approaches, achieving up to a 5.3x improvement in F1-scores. LOVA also demonstrated strong scalability, with up to a 14.6x improvement in smart contract vulnerability localization across languages like C, Python, Java, and Solidity. Its robustness was proven through consistent performance across different LLM architectures.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Less-excludable Mechanism for DAOs in Public Good Auctions</title>
<link>https://arxiv.org/abs/2504.11854</link>
<guid>https://arxiv.org/abs/2504.11854</guid>
<content:encoded><![CDATA[
arXiv:2504.11854v2 Announce Type: replace 
Abstract: With the rise of smart contracts, decentralized autonomous organizations (DAOs) have emerged in public good auctions, allowing "small" bidders to gather together and enlarge their influence in high-valued auctions. However, models and mechanisms in the existing research literature do not guarantee non-excludability, which is a main property of public goods. As such, some members of the winning DAO may be explicitly prevented from accessing the public good. This side effect leads to regrouping of small bidders within the DAO to have a larger say in the final outcome. In particular, we provide a polynomial-time algorithm to compute the best regrouping of bidders that maximizes the total bidding power of a DAO. We also prove that such a regrouping is less-excludable, better aligning the needs of the entire DAO and the nature of public goods. Next, notice that members of a DAO in public good auctions often have a positive externality among themselves. Thus we introduce a collective factor into the members' utility functions. We further extend the mechanism's allocation for each member to allow for partial access to the public good. Under the new model, we propose a mechanism that is incentive compatible in generic games and achieves higher social welfare as well as less-excludable allocations.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Federated Learning Meets Quantum Computing: Survey and Research Opportunities</title>
<link>https://arxiv.org/abs/2504.08814</link>
<guid>https://arxiv.org/abs/2504.08814</guid>
<content:encoded><![CDATA[
<div> :  (QFL),  (QC),  (FL),  (NISQ), 

<br /><br />:
QFLQCFLNISQFL-QCFLQFL <div>
arXiv:2504.08814v1 Announce Type: new 
Abstract: Quantum Federated Learning (QFL) is an emerging field that harnesses advances in Quantum Computing (QC) to improve the scalability and efficiency of decentralized Federated Learning (FL) models. This paper provides a systematic and comprehensive survey of the emerging problems and solutions when FL meets QC, from research protocol to a novel taxonomy, particularly focusing on both quantum and federated limitations, such as their architectures, Noisy Intermediate Scale Quantum (NISQ) devices, and privacy preservation, so on. This work explores key developments and integration strategies, along with the impact of quantum computing on FL, keeping a sharp focus on hybrid quantum-classical approaches. The paper offers an in-depth understanding of how the strengths of QC, such as gradient hiding, state entanglement, quantum key distribution, quantum security, and quantum-enhanced differential privacy, have been integrated into FL to ensure the privacy of participants in an enhanced, fast, and secure framework. Finally, this study proposes potential future directions to address the identified research gaps and challenges, aiming to inspire faster and more secure QFL models for practical use.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Layered Security Analysis of Blockchain Systems: From Attack Vectors to Defense and System Hardening</title>
<link>https://arxiv.org/abs/2504.09181</link>
<guid>https://arxiv.org/abs/2504.09181</guid>
<content:encoded><![CDATA[
<div> 

:<br />
2.0P2P <div>
arXiv:2504.09181v1 Announce Type: new 
Abstract: The application of Bitcoin enables people to understand blockchain technology gradually. Bitcoin is a decentralized currency that does not rely on third-party credit institutions, and the core of Bitcoin's underlying technology is blockchain. With the increasing value of Bitcoin and the vigorous development of decentralization, people's research on blockchain is also increasing day by day. Today's blockchain technology has not only made great achievements in the application of Bitcoin, but has also been preliminarily applied in other fields, such as finance, medical treatment, the Internet of Things, and so on. However, with the initial application of blockchain technology on the Internet, the security of blockchain technology has also been widely concerned by people in the industry. For example, whether currency trading platforms, smart contracts, blockchain consensus mechanisms, and other technologies are vulnerable to attacks, and how we can defend against these attacks digitally and optimize the blockchain system is exactly the subject we want to study. For the security of appeal blockchain, this paper first analyzes the security threats faced by the application digital currency trading platform of the blockchain system, then analyzes the security problems of smart contract closely related to blockchain 2.0, and then analyzes and studies the security threats of blockchain public chain, consensus mechanism, and P2P. Finally, combined with the security problems at all levels of the blockchain system we analyze and study how to optimize the security of the blockchain system.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Query-based Knowledge Transfer for Heterogeneous Learning Environments</title>
<link>https://arxiv.org/abs/2504.09205</link>
<guid>https://arxiv.org/abs/2504.09205</guid>
<content:encoded><![CDATA[
<div> : Decentralized collaborative learning, Query-based Knowledge Transfer (QKT), data heterogeneity, privacy constraints, federated learning

:
Query-based Knowledge Transfer (QKT)QKTQKT20.91%14.32%QKT<br /><br /> <div>
arXiv:2504.09205v1 Announce Type: new 
Abstract: Decentralized collaborative learning under data heterogeneity and privacy constraints has rapidly advanced. However, existing solutions like federated learning, ensembles, and transfer learning, often fail to adequately serve the unique needs of clients, especially when local data representation is limited. To address this issue, we propose a novel framework called Query-based Knowledge Transfer (QKT) that enables tailored knowledge acquisition to fulfill specific client needs without direct data exchange. QKT employs a data-free masking strategy to facilitate communication-efficient query-focused knowledge transfer while refining task-specific parameters to mitigate knowledge interference and forgetting. Our experiments, conducted on both standard and clinical benchmarks, show that QKT significantly outperforms existing collaborative learning methods by an average of 20.91\% points in single-class query settings and an average of 14.32\% points in multi-class query scenarios. Further analysis and ablation studies reveal that QKT effectively balances the learning of new and existing knowledge, showing strong potential for its application in decentralized learning.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartShift: A Secure and Efficient Approach to Smart Contract Migration</title>
<link>https://arxiv.org/abs/2504.09315</link>
<guid>https://arxiv.org/abs/2504.09315</guid>
<content:encoded><![CDATA[
<div> BlockchainSmartShift

:
SmartShiftSmartShift <div>
arXiv:2504.09315v1 Announce Type: new 
Abstract: Blockchain and smart contracts have emerged as revolutionary technologies transforming distributed computing. While platform evolution and smart contracts' inherent immutability necessitate migrations both across and within chains, migrating the vast amounts of critical data in these contracts while maintaining data integrity and minimizing operational disruption presents a significant challenge. To address these challenges, we present SmartShift, a framework that enables secure and efficient smart contract migrations through intelligent state partitioning and progressive function activation, preserving operational continuity during transitions. Our comprehensive evaluation demonstrates that SmartShift significantly reduces migration downtime while ensuring robust security, establishing a foundation for efficient and secure smart contract migration systems.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CrossLink: A Decentralized Framework for Secure Cross-Chain Smart Contract Execution</title>
<link>https://arxiv.org/abs/2504.09319</link>
<guid>https://arxiv.org/abs/2504.09319</guid>
<content:encoded><![CDATA[
<div> : CrossLink

:
CrossLinkCrossLink/ <div>
arXiv:2504.09319v1 Announce Type: new 
Abstract: This paper introduces CrossLink, a decentralized framework for secure cross-chain smart contract execution that effectively addresses the inherent limitations of contemporary solutions, which primarily focus on asset transfers and rely on potentially vulnerable centralized intermediaries. Recognizing the escalating demand for seamless interoperability among decentralized applications, CrossLink provides a trustless mechanism for smart contracts across disparate blockchain networks to communicate and interact. At its core, CrossLink utilizes a compact chain for selectively storing authorized contract states and employs a secure inter-chain messaging mechanism to ensure atomic execution and data consistency. By implementing a deposit/collateral fee system and efficient state synchronization, CrossLink enhances security and mitigates vulnerabilities, offering a novel approach to seamless, secure, and decentralized cross-chain interoperability. A formal security analysis further validates CrossLink's robustness against unauthorized modifications and denial-of-service attacks.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding</title>
<link>https://arxiv.org/abs/2504.09516</link>
<guid>https://arxiv.org/abs/2504.09516</guid>
<content:encoded><![CDATA[
<div> : <br /><br />:<br />
\texttt{FSSUAVL}SSL\texttt{FSSUAVL}\texttt{FSSUAVL}CNNViT\texttt{FSSUAVL}\texttt{FSSUAVL} <div>
arXiv:2504.09516v1 Announce Type: new 
Abstract: Recent studies have demonstrated that vision models can effectively learn multimodal audio-image representations when paired. However, the challenge of enabling deep models to learn representations from unpaired modalities remains unresolved. This issue is especially pertinent in scenarios like Federated Learning (FL), where data is often decentralized, heterogeneous, and lacks a reliable guarantee of paired data. Previous attempts tackled this issue through the use of auxiliary pretrained encoders or generative models on local clients, which invariably raise computational cost with increasing number modalities. Unlike these approaches, in this paper, we aim to address the task of unpaired audio and image recognition using \texttt{FSSUAVL}, a single deep model pretrained in FL with self-supervised contrastive learning (SSL). Instead of aligning the audio and image modalities, \texttt{FSSUAVL} jointly discriminates them by projecting them into a common embedding space using contrastive SSL. This extends the utility of \texttt{FSSUAVL} to paired and unpaired audio and image recognition tasks. Our experiments with CNN and ViT demonstrate that \texttt{FSSUAVL} significantly improves performance across various image- and audio-based downstream tasks compared to using separate deep models for each modality. Additionally, \texttt{FSSUAVL}'s capacity to learn multimodal feature representations allows for integrating auxiliary information, if available, to enhance recognition accuracy.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RoboComm: A DID-based scalable and privacy-preserving Robot-to-Robot interaction over state channels</title>
<link>https://arxiv.org/abs/2504.09517</link>
<guid>https://arxiv.org/abs/2504.09517</guid>
<content:encoded><![CDATA[
<div> 

:
RoboCommSelf-Sovereign IdentityDIDRoboComm <div>
arXiv:2504.09517v1 Announce Type: new 
Abstract: In a multi robot system establishing trust amongst untrusted robots from different organisations while preserving a robot's privacy is a challenge. Recently decentralized technologies such as smart contract and blockchain are being explored for applications in robotics. However, the limited transaction processing and high maintenance cost hinder the widespread adoption of such approaches. Moreover, blockchain transactions be they on public or private permissioned blockchain are publically readable which further fails to preserve the confidentiality of the robot's data and privacy of the robot.
  In this work, we propose RoboComm a Decentralized Identity based approach for privacy-preserving interaction between robots. With DID a component of Self-Sovereign Identity; robots can authenticate each other independently without relying on any third-party service. Verifiable Credentials enable private data associated with a robot to be stored within the robot's hardware, unlike existing blockchain based approaches where the data has to be on the blockchain. We improve throughput by allowing message exchange over state channels. Being a blockchain backed solution RoboComm provides a trustworthy system without relying on a single party. Moreover, we implement our proposed approach to demonstrate the feasibility of our solution.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference</title>
<link>https://arxiv.org/abs/2504.09620</link>
<guid>https://arxiv.org/abs/2504.09620</guid>
<content:encoded><![CDATA[
<div> : Metropolis-Hastings Captioning Game (MHCG), , , , 

:
Metropolis-Hastings Captioning Game (MHCG)-VLMsVLMVLMMHCGMHCGVLMs <div>
arXiv:2504.09620v1 Announce Type: new 
Abstract: We propose the Metropolis-Hastings Captioning Game (MHCG), a method to fuse knowledge of multiple vision-language models (VLMs) by learning from each other. Although existing methods that combine multiple models suffer from inference costs and architectural constraints, MHCG avoids these problems by performing decentralized Bayesian inference through a process resembling a language game. The knowledge fusion process establishes communication between two VLM agents alternately captioning images and learning from each other. We conduct two image-captioning experiments with two VLMs, each pre-trained on a different dataset. The first experiment demonstrates that MHCG achieves consistent improvement in reference-free evaluation metrics. The second experiment investigates how MHCG contributes to sharing VLMs' category-level vocabulary by observing the occurrence of the vocabulary in the generated captions.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Immutability with Flexibility: A Scheme for Secure and Efficient Smart Contract Upgrades</title>
<link>https://arxiv.org/abs/2504.09652</link>
<guid>https://arxiv.org/abs/2504.09652</guid>
<content:encoded><![CDATA[
<div> : FlexiContracts+

:
(DApps)gasFlexiContracts+FlexiContracts+FlexiContracts+ <div>
arXiv:2504.09652v1 Announce Type: new 
Abstract: The emergence of blockchain technology has revolutionized contract execution through the introduction of smart contracts. Ethereum, the leading blockchain platform, leverages smart contracts to power decentralized applications (DApps), enabling transparent and self-executing systems across various domains. While the immutability of smart contracts enhances security and trust, it also poses significant challenges for updates, defect resolution, and adaptation to changing requirements. Existing upgrade mechanisms are complex, resource-intensive, and costly in terms of gas consumption, often compromising security and limiting practical adoption. To address these challenges, we propose FlexiContracts+, a novel scheme that reimagines smart contracts by enabling secure, in-place upgrades on Ethereum while preserving historical data without relying on multiple contracts or extensive pre-deployment planning. FlexiContracts+ enhances security, simplifies development, reduces engineering overhead, and supports adaptable, expandable smart contracts. Comprehensive testing demonstrates that FlexiContracts+ achieves a practical balance between immutability and flexibility, advancing the capabilities of smart contract systems.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Tale of Two Learning Algorithms: Multiple Stream Random Walk and Asynchronous Gossip</title>
<link>https://arxiv.org/abs/2504.09792</link>
<guid>https://arxiv.org/abs/2504.09792</guid>
<content:encoded><![CDATA[
<div> : (MW)

<br /><br />:
(MW)MWMWMW <div>
arXiv:2504.09792v1 Announce Type: new 
Abstract: Although gossip and random walk-based learning algorithms are widely known for decentralized learning, there has been limited theoretical and experimental analysis to understand their relative performance for different graph topologies and data heterogeneity. We first design and analyze a random walk-based learning algorithm with multiple streams (walks), which we name asynchronous "Multi-Walk (MW)". We provide a convergence analysis for MW w.r.t iteration (computation), wall-clock time, and communication. We also present a convergence analysis for "Asynchronous Gossip", noting the lack of a comprehensive analysis of its convergence, along with the computation and communication overhead, in the literature. Our results show that MW has better convergence in terms of iterations as compared to Asynchronous Gossip in graphs with large diameters (e.g., cycles), while its relative performance, as compared to Asynchronous Gossip, depends on the number of walks and the data heterogeneity in graphs with small diameters (e.g., complete graphs). In wall-clock time analysis, we observe a linear speed-up with the number of walks and nodes in MW and Asynchronous Gossip, respectively. Finally, we show that MW outperforms Asynchronous Gossip in communication overhead, except in small-diameter topologies with extreme data heterogeneity. These results highlight the effectiveness of each algorithm in different graph topologies and data heterogeneity. Our codes are available for reproducibility.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Effective PBFT Consensus Service under Software Aging in Dynamic Scenarios</title>
<link>https://arxiv.org/abs/2504.09793</link>
<guid>https://arxiv.org/abs/2504.09793</guid>
<content:encoded><![CDATA[
<div> : PBFT

:
PBFT()PBFTMarkovPBFTPBFTPBFT <div>
arXiv:2504.09793v1 Announce Type: new 
Abstract: The increasing application and deployment of blockchain in various services necessitates the assurance of the effectiveness of PBFT (Practical Byzantine Fault Tolerance) consensus service. However, the performance of PBFT consensus service is challenged in dynamic scenarios. The paper explores how to reduce the consensus processing time and maintenance cost of PBFT consensus service under software aging in dynamic scenarios. We first propose a PBFT system, consisting of three subsystems, one active-node subsystem, one standby-node subsystem and a repair subsystem. All the active nodes participate in the consensus and all standby nodes aim for fault-tolerance. Each aging/crashed nodes become standby nodes after completing its repairing in the repair subsystem. The nodes migrate between the active-node and standby-node subsystems in order to support the continuity of the PBFT consensus service while reducing maintenance cost. Then, we develop a Markov-chain-based analytical model for capturing the behaviors of the system and also derive the formulas for calculating the metrics, including consensus processing time, PBFT service availability, the mean number of nodes in each subsystem. Finally, we design a Multi-Objective Evolutionary Algorithm-based method for minimizing both the PBFT service response time and the PBFT system maintenance cost. We also conduct experiments for evaluation.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Markov Clustering based Fully Automated Nonblocking Hierarchical Supervisory Control of Large-Scale Discrete-Event Systems</title>
<link>https://arxiv.org/abs/2504.09884</link>
<guid>https://arxiv.org/abs/2504.09884</guid>
<content:encoded><![CDATA[
<div> Markov

:
DESMarkovMarkovDES<br /><br /> <div>
arXiv:2504.09884v1 Announce Type: new 
Abstract: In this paper we revisit the abstraction-based approach to synthesize a hierarchy of decentralized supervisors and coordinators for nonblocking control of large-scale discrete-event systems (DES), and augment it with a new clustering method for automatic and flexible grouping of relevant components during the hierarchical synthesis process. This method is known as Markov clustering, which not only automatically performs grouping but also allows flexible tuning the sizes of the resulting clusters using a single parameter. Compared to the existing abstraction-based approach that lacks effective grouping method for general cases, our proposed approach based on Markov clustering provides a fully automated and effective hierarchical synthesis procedure applicable to general large-scale DES. Moreover, it is proved that the resulting hierarchy of supervisors and coordinators collectively achieves global nonblocking (and maximally permissive) controlled behavior under the same conditions as those in the existing abstraction-based approach. Finally, a benchmark case study is conducted to empirically demonstrate the effectiveness of our approach.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data</title>
<link>https://arxiv.org/abs/2504.09967</link>
<guid>https://arxiv.org/abs/2504.09967</guid>
<content:encoded><![CDATA[
<div> IMAXDMAX

<br />
:

IMAXXMLLMsIMAX1354K2X4.107.46XDMAXIMAXMLLM3.20%21.05%IMAXDMAXIMAXDMAXIMAX <div>
arXiv:2504.09967v1 Announce Type: new 
Abstract: The emergence of medical generalist foundation models has revolutionized conventional task-specific model development paradigms, aiming to better handle multiple tasks through joint training on large-scale medical datasets. However, recent advances prioritize simple data scaling or architectural component enhancement, while neglecting to re-examine multi-task learning from a data-centric perspective. Critically, simply aggregating existing data resources leads to decentralized image-task alignment, which fails to cultivate comprehensive image understanding or align with clinical needs for multi-dimensional image interpretation. In this paper, we introduce the image-centric multi-annotation X-ray dataset (IMAX), the first attempt to enhance the multi-task learning capabilities of medical multi-modal large language models (MLLMs) from the data construction level. To be specific, IMAX is featured from the following attributes: 1) High-quality data curation. A comprehensive collection of more than 354K entries applicable to seven different medical tasks. 2) Image-centric dense annotation. Each X-ray image is associated with an average of 4.10 tasks and 7.46 training entries, ensuring multi-task representation richness per image. Compared to the general decentralized multi-annotation X-ray dataset (DMAX), IMAX consistently demonstrates significant multi-task average performance gains ranging from 3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs. Moreover, we investigate differences in statistical patterns exhibited by IMAX and DMAX training processes, exploring potential correlations between optimization dynamics and multi-task performance. Finally, leveraging the core concept of IMAX data construction, we propose an optimized DMAX-based training strategy to alleviate the dilemma of obtaining high-quality IMAX data in practical scenarios.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proofs of Useful Work from Arbitrary Matrix Multiplication</title>
<link>https://arxiv.org/abs/2504.09971</link>
<guid>https://arxiv.org/abs/2504.09971</guid>
<content:encoded><![CDATA[
<div> proof-of-useful-work (PoUW)Nakamoto

:
Proof-of-Useful-Work (PoUW) 1+o(1)PoWL1GPUAI <div>
arXiv:2504.09971v1 Announce Type: new 
Abstract: We revisit the longstanding open problem of implementing Nakamoto's proof-of-work (PoW) consensus based on a real-world computational task $T(x)$ (as opposed to artificial random hashing), in a truly permissionless setting where the miner itself chooses the input $x$. The challenge in designing such a Proof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$ to produce a PoW certificate with prescribed hardness and with negligible computational overhead over the worst-case complexity of $T(\cdot)$ -- This ensures malicious miners cannot ``game the system" by fooling the verifier to accept with higher probability compared to honest miners (while using similar computational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead is trivial for any task $T$, but also useless.
  Our main result is a PoUW for the task of Matrix Multiplication $MatMul(A,B)$ of arbitrary matrices with $1+o(1)$ multiplicative overhead compared to naive $MatMul$ (even in the presence of Fast Matrix Multiplication-style algorithms, which are currently impractical). We conjecture that our protocol has optimal security in the sense that a malicious prover cannot obtain any significant advantage over an honest prover. This conjecture is based on reducing hardness of our protocol to the task of solving a batch of low-rank random linear equations which is of independent interest.
  Since $MatMul$s are the bottleneck of AI compute as well as countless industry-scale applications, this primitive suggests a concrete design of a new L1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin mining -- allowing GPU consumers to reduce their AI training and inference costs by ``re-using" it for blockchain consensus, in exchange for block rewards (2-for-1). This blockchain is currently under construction.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart Contract</title>
<link>https://arxiv.org/abs/2504.09977</link>
<guid>https://arxiv.org/abs/2504.09977</guid>
<content:encoded><![CDATA[
<div> : ReentrancyAccess ControlTimestamp Dependencytx.originUnchecked Low-Level Calls

<br /><br />:
SoliditySmartBugs CuratedSolidiFI Benchmarktx.origin <div>
arXiv:2504.09977v1 Announce Type: new 
Abstract: Poorly designed smart contracts are particularly vulnerable, as they may allow attackers to exploit weaknesses and steal the virtual currency they manage. In this study, we train a model using unsupervised learning to identify vulnerabilities in the Solidity source code of Ethereum smart contracts. To address the challenges associated with real-world smart contracts, our training data is derived from actual vulnerability samples obtained from datasets such as SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to develop a robust unsupervised static analysis method for detecting five specific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency, tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to identify outliers, which are subsequently classified as vulnerable smart contracts.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Characterizing LLM-driven Social Network: The Chirper.ai Case</title>
<link>https://arxiv.org/abs/2504.10286</link>
<guid>https://arxiv.org/abs/2504.10286</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
LLMsChirper.aiLLM65,000AI770Mastodon117,0001600LLMLLM <div>
arXiv:2504.10286v1 Announce Type: new 
Abstract: Large language models (LLMs) demonstrate the ability to simulate human decision-making processes, enabling their use as agents in modeling sophisticated social networks, both offline and online. Recent research has explored collective behavioral patterns and structural characteristics of LLM agents within simulated networks. However, empirical comparisons between LLM-driven and human-driven online social networks remain scarce, limiting our understanding of how LLM agents differ from human users. This paper presents a large-scale analysis of Chirper.ai, an X/Twitter-like social network entirely populated by LLM agents, comprising over 65,000 agents and 7.7 million AI-generated posts. For comparison, we collect a parallel dataset from Mastodon, a human-driven decentralized social network, with over 117,000 users and 16 million posts. We examine key differences between LLM agents and humans in posting behaviors, abusive content, and social network structures. Our findings provide critical insights into the evolving landscape of online social network analysis in the AI era, offering a comprehensive profile of LLM agents in social simulations.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Staggering and Fragmentation for Improved Large Message Handling in libp2p GossipSub</title>
<link>https://arxiv.org/abs/2504.10365</link>
<guid>https://arxiv.org/abs/2504.10365</guid>
<content:encoded><![CDATA[
<div> libp2p GossipSubshadow

<br /><br />
libp2p GossipSubP2PshadowGossipSub <div>
arXiv:2504.10365v1 Announce Type: new 
Abstract: The libp2p GossipSub protocol leverages a full-message mesh with a lower node degree and a more densely connected metadata-only (gossip) mesh. This combination allows an efficient dissemination of messages in unstructured peer-to-peer (P2P) networks. However, GossipSub needs to consider message size, which is crucial for the efficient operation of many applications, such as handling large Ethereum blocks. This paper proposes modifications to improve GossipSub's performance when transmitting large messages. We evaluate the proposed improvements using the shadow simulator. Our results show that the proposed improvements significantly enhance GossipSub's performance for large message transmissions in sizeable networks.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Topology-aware Generalization of Decentralized SGD</title>
<link>https://arxiv.org/abs/2206.12680</link>
<guid>https://arxiv.org/abs/2206.12680</guid>
<content:encoded><![CDATA[
<div> : Decentralized Stochastic Gradient Descent (D-SGD), , , , 

:
(D-SGD)D-SGD$\mathcal{O}{(N^{-1}+m^{-1} +\lambda^2)}$$N$$m$$1+\lambda$$\mathcal{O}{(N^{-(1+\alpha)/2}+ m^{-(1+\alpha)/2}+\lambda^{1+\alpha} + \phi_{\mathcal{S}})}$$\lambda$1D-SGDD-SGDVGG-11ResNet-18CIFAR-10CIFAR-100Tiny-ImageNetD-SGDhttps://github.com/Raiden-Zhu/Generalization-of-DSGD<br /><br /> <div>
arXiv:2206.12680v5 Announce Type: replace 
Abstract: This paper studies the algorithmic stability and generalizability of decentralized stochastic gradient descent (D-SGD). We prove that the consensus model learned by D-SGD is $\mathcal{O}{(N^{-1}+m^{-1} +\lambda^2)}$-stable in expectation in the non-convex non-smooth setting, where $N$ is the total sample size, $m$ is the worker number, and $1+\lambda$ is the spectral gap that measures the connectivity of the communication topology. These results then deliver an $\mathcal{O}{(N^{-(1+\alpha)/2}+ m^{-(1+\alpha)/2}+\lambda^{1+\alpha} + \phi_{\mathcal{S}})}$ in-average generalization bound, which is non-vacuous even when $\lambda$ is closed to $1$, in contrast to vacuous as suggested by existing literature on the projected version of D-SGD. Our theory indicates that the generalizability of D-SGD is positively correlated with the spectral gap, and can explain why consensus control in initial training phase can ensure better generalization. Experiments of VGG-11 and ResNet-18 on CIFAR-10, CIFAR-100 and Tiny-ImageNet justify our theory. To our best knowledge, this is the first work on the topology-aware generalization of vanilla D-SGD. Code is available at https://github.com/Raiden-Zhu/Generalization-of-DSGD.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Smart Contract Security Analysis with Execution Property Graphs</title>
<link>https://arxiv.org/abs/2305.14046</link>
<guid>https://arxiv.org/abs/2305.14046</guid>
<content:encoded><![CDATA[
<div> : Clue<br /><br />:
ClueClueClueForensic <div>
arXiv:2305.14046v3 Announce Type: replace 
Abstract: Smart contract vulnerabilities have led to significant financial losses, with their increasing complexity rendering outright prevention of hacks increasingly challenging. This trend highlights the crucial need for advanced forensic analysis and real-time intrusion detection, where dynamic analysis plays a key role in dissecting smart contract executions. Therefore, there is a pressing need for a unified and generic representation of smart contract executions, complemented by an efficient methodology that enables the modeling and identification of a broad spectrum of emerging attacks.
  We introduce Clue, a dynamic analysis framework specifically designed for the Ethereum virtual machine. Central to Clue is its ability to capture critical runtime information during contract executions, employing a novel graph-based representation, the Execution Property Graph. A key feature of Clue is its innovative graph traversal technique, which is adept at detecting complex attacks, including (read-only) reentrancy and price manipulation. Evaluation results reveal Clue's superior performance with high true positive rates and low false positive rates, outperforming state-of-the-art tools. Furthermore, Clue's efficiency positions it as a valuable tool for both forensic analysis and real-time intrusion detection.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Computation and Communication Efficient Lightweighting Vertical Federated Learning for Smart Building IoT</title>
<link>https://arxiv.org/abs/2404.00466</link>
<guid>https://arxiv.org/abs/2404.00466</guid>
<content:encoded><![CDATA[
<div> : , , , , 

:
LVFLLVFLLVFL<br /><br /> <div>
arXiv:2404.00466v2 Announce Type: replace 
Abstract: With the increasing number and enhanced capabilities of IoT devices in smart buildings, these devices are evolving beyond basic data collection and control to actively participate in deep learning tasks. Federated Learning (FL), as a decentralized learning paradigm, is well-suited for such scenarios. However, the limited computational and communication resources of IoT devices present significant challenges. While existing research has extensively explored efficiency improvements in Horizontal FL, these techniques cannot be directly applied to Vertical FL due to fundamental differences in data partitioning and model structure. To address this gap, we propose a Lightweight Vertical Federated Learning (LVFL) framework that jointly optimizes computational and communication efficiency. Our approach introduces two distinct lightweighting strategies: one for reducing the complexity of the feature model to improve local computation, and another for compressing feature embeddings to reduce communication overhead. Furthermore, we derive a convergence bound for the proposed LVFL algorithm that explicitly incorporates both computation and communication lightweighting ratios. Experimental results on an image classification task demonstrate that LVFL effectively mitigates resource demands while maintaining competitive learning performance.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SQIAsignHD: SQIsignHD Adaptor Signature</title>
<link>https://arxiv.org/abs/2404.09026</link>
<guid>https://arxiv.org/abs/2404.09026</guid>
<content:encoded><![CDATA[
<div> : adaptor

:
$\mathsf{SQIAsignHD}$Diffie-HellmanSIDH <div>
arXiv:2404.09026v4 Announce Type: replace 
Abstract: Adaptor signatures can be viewed as a generalized form of standard digital signature schemes by linking message authentication to the disclosure of a secret value. As a recent cryptographic primitive, they have become essential for blockchain applications, including cryptocurrencies, by reducing on-chain costs, improving fungibility, and enabling off-chain payments in payment-channel networks, payment-channel hubs, and atomic swaps. However, existing adaptor signature constructions are vulnerable to quantum attacks due to Shor's algorithm. In this work, we introduce $\mathsf{SQIAsignHD}$, a new quantum-resistant adaptor signature scheme based on isogenies of supersingular elliptic curves, using SQIsignHD - as the underlying signature scheme - and exploiting the idea of the artificial orientation on the supersingular isogeny Diffie-Hellman key exchange protocol, SIDH, to define the underlying hard relation. We, furthermore, provide a formal security proof for our proposed scheme.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Imitater: An Efficient Shared Mempool Protocol with Application to Byzantine Fault Tolerance</title>
<link>https://arxiv.org/abs/2409.19286</link>
<guid>https://arxiv.org/abs/2409.19286</guid>
<content:encoded><![CDATA[
<div> : (BFT)(SMP)ImitaterHotStuff

<br /><br />:
Imitater(SMP)BFTImitaterImitaterHotStuffImitater-HSStratus-HSImitater-HS <div>
arXiv:2409.19286v2 Announce Type: replace 
Abstract: Byzantine Fault Tolerant (BFT) consensus, a cornerstone of blockchain technology, has seen significant advancements. While existing BFT protocols ensure security guarantees, they often suffer from efficiency challenges, particularly under conditions of network instability or malicious exploitation of system mechanisms.
  We propose a novel Shared Mempool (SMP) protocol, named Imitater, which can be seamlessly integrated into BFT protocols. By chaining microblocks and applying coding techniques, Imitater efficiently achieves \emph{totality} and \emph{availability}. Furthermore, a BFT protocol augmented with Imitater ensures \emph{order preservation} of client transactions while mitigating the risks of \emph{over-distribution} and \emph{unbalanced workload}.
  In the experiment, we integrate Imitater into the HotStuff protocol, resulting in Imitater-HS. The performance of Imitater-HS is validated in a system with up to 256 nodes. Experimental results demonstrate the efficiency of our approach: Imitater-HS achieves higher throughput and lower latency in the presence of faulty nodes compared to Stratus-HS, the state-of-the-art protocol. Notably, the throughput improvement increases with the number of faulty nodes.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Weakly Supervised Panoptic Segmentation for Defect-Based Grading of Fresh Produce</title>
<link>https://arxiv.org/abs/2411.16219</link>
<guid>https://arxiv.org/abs/2411.16219</guid>
<content:encoded><![CDATA[
<div> : 

:
Segment Anything ModelSAM4761440SAMGitHubhttps://github.com/manuelknott/banana-defect-segmentation <div>
arXiv:2411.16219v2 Announce Type: replace 
Abstract: Visual inspection for defect grading in agricultural supply chains is crucial but traditionally labor-intensive and error-prone. Automated computer vision methods typically require extensively annotated datasets, which are often unavailable in decentralized supply chains. We address this challenge by evaluating the Segment Anything Model (SAM) to generate dense panoptic segmentation masks from sparse annotations. These dense predictions are then used to train a supervised panoptic segmentation model. Focusing on banana surface defects (bruises and scars), we validate our approach using 476 field images annotated with 1440 defects. While SAM-generated masks generally align with human annotations, substantially reducing annotation effort, we explicitly identify failure cases associated with specific defect sizes and shapes. Despite these limitations, our approach offers practical estimates of defect number and relative size from panoptic masks, underscoring the potential and current boundaries of foundation models for defect quantification in low-data agricultural scenarios. GitHub: https://github.com/manuelknott/banana-defect-segmentation
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proxima. A DAG based cooperative distributed ledger</title>
<link>https://arxiv.org/abs/2411.16456</link>
<guid>https://arxiv.org/abs/2411.16456</guid>
<content:encoded><![CDATA[
<div> (DAG)UTXO

:
DAGUTXOUTXOSybil <div>
arXiv:2411.16456v4 Announce Type: replace 
Abstract: This paper introduces a novel architecture for a distributed ledger, commonly referred to as a "blockchain", which is organized in the form of directed acyclic graph (DAG) with UTXO transactions as vertices, rather than as a chain of blocks. Consensus on the state of ledger assets is achieved through the cooperative consensus: a profit-driven behavior of token holders themselves, which is viable only when they cooperate by following the "biggest ledger coverage rule", akin the "longest chain rule" of Bitcoin. The cooperative behavior is facilitated by enforcing purposefully designed UTXO transaction validity constraints. Token holders are the sole category of participants authorized to make amendments to the ledger, making participation completely permissionless - without miners, validators, committees or staking - and without any need of knowledge about the composition of the set of all participants in the consensus. The setup allows to achieve high throughput and scalability alongside with low transaction costs, while preserving key aspects of high decentralization, open participation, and asynchronicity found in Bitcoin and other proof-of-work blockchains, but without unreasonable energy consumption. Sybil protection is achieved similarly to proof-of-stake blockchains, using tokens native to the ledger, yet the architecture operates in a leaderless manner without block proposers and committee selection.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Filtering against Spatio-Temporal False Data Attacks under Asynchronous Sampling</title>
<link>https://arxiv.org/abs/2411.19765</link>
<guid>https://arxiv.org/abs/2411.19765</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:

$\ell_1$IEEE 14-bus <div>
arXiv:2411.19765v2 Announce Type: replace 
Abstract: This paper addresses the secure state estimation problem for continuous linear time-invariant systems with non-periodic and asynchronous sampled measurements, where the sensors need to transmit not only measurements but also sampling time-stamps to the fusion center. This measurement and communication setup is well-suited for operating large-scale control systems and, at the same time, introduces new vulnerabilities that can be exploited by adversaries through (i) manipulation of measurements, (ii) manipulation of time-stamps, (iii) elimination of measurements, (iv) generation of completely new false measurements, or a combination of these attacks. To mitigate these attacks, we propose a decentralized estimation algorithm in which each sensor maintains its local state estimate asynchronously based on its measurements. The local states are synchronized through time prediction and fused after time-stamp alignment. In the absence of attacks, state estimates are proven to recover the optimal Kalman estimates by solving a weighted least square problem. In the presence of attacks, solving this weighted least square problem with the aid of $\ell_1$ regularization provides secure state estimates with uniformly bounded error under an observability redundancy assumption. The effectiveness of the proposed algorithm is demonstrated using a benchmark example of the IEEE 14-bus system.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Quorum Sizes in DAG-Based BFT Protocols</title>
<link>https://arxiv.org/abs/2504.08048</link>
<guid>https://arxiv.org/abs/2504.08048</guid>
<content:encoded><![CDATA[
<div> : DAGequivocation eliminationcommitting

:
DAGDAG-RiderTuskBullshark$2f+1$$kf+1$$k>3$DAG-Rider$2f+1$TuskBullsharkequivocation$3f+1$<br /><br /> <div>
arXiv:2504.08048v1 Announce Type: new 
Abstract: Several prominent DAG-based blockchain protocols, such as DAG-Rider, Tusk, and Bullshark, completely separate between equivocation elimination and committing; equivocation is handled through the use of a reliable Byzantine broadcast black-box protocol, while committing is handled by an independent DAG-based protocol. With such an architecture, a natural question that we study in this paper is whether the DAG protocol would work when the number of nodes (or validators) is only $2f+1$ (when equivocation is eliminated), and whether there are benefits in working with larger number of nodes, i.e., a total of $kf+1$ nodes for $k > 3$.
  We find that while DAG-Rider's correctness is maintained with $2f+1$ nodes, the asynchronous versions of both Tusk and Bullshark inherently depends on having $3f+1$ nodes, regardless of equivocation. We also explore the impact of having larger number of nodes on the expected termination time of these three protocols.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CertainSync: Rateless Set Reconciliation with Certainty</title>
<link>https://arxiv.org/abs/2504.08314</link>
<guid>https://arxiv.org/abs/2504.08314</guid>
<content:encoded><![CDATA[
<div> : set reconciliation, blockchain networks, CertainSync, Invertible Bloom Lookup Tables (IBLTs), UniverseReduceSync

<br /><br />:
 CertainSyncCertainSync  Invertible Bloom Lookup Tables (IBLTs)  CertainSync UniverseReduceSync <div>
arXiv:2504.08314v1 Announce Type: new 
Abstract: Set reconciliation is a fundamental task in distributed systems, particularly in blockchain networks, where it enables synchronization of transaction pools among peers and facilitates block dissemination. Traditional set reconciliation schemes are either statistical, offering success probability as a function of communication overhead and symmetric difference size, or require parametrization and estimation of that size, which can be error-prone. We present CertainSync, a novel reconciliation framework that, to the best of our knowledge, is the first to guarantee successful set reconciliation without any parametrization or estimators. The framework is rateless and adapts to the unknown symmetric difference size. Reconciliation is guaranteed whenever the communication overhead reaches a lower bound derived from the symmetric difference size and universe size. Our framework builds on recent constructions of Invertible Bloom Lookup Tables (IBLTs), ensuring successful element listing as long as the number of elements is bounded. We provide a theoretical analysis proving the certainty of reconciliation for multiple constructions. Our approach is validated by simulations, showing the ability to synchronize sets with efficient communication costs while maintaining guarantees compared to baseline schemes. To further reduce overhead in large universes such as blockchain networks, CertainSync is extended with a universe reduction technique. We compare and validate this extension, UniverseReduceSync, against the basic framework using real Ethereum transaction hash data. Results show a trade-off between lower communication costs and maintaining guarantees, offering a comprehensive solution for diverse reconciliation scenarios.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Adaptive Clustering Scheme for Client Selections in Communication-Efficient Federated Learning</title>
<link>https://arxiv.org/abs/2504.08356</link>
<guid>https://arxiv.org/abs/2504.08356</guid>
<content:encoded><![CDATA[
<div> IID

:
<br />
50%IID <div>
arXiv:2504.08356v1 Announce Type: new 
Abstract: Federated learning is a novel decentralized learning architecture. During the training process, the client and server must continuously upload and receive model parameters, which consumes a lot of network transmission resources. Some methods use clustering to find more representative customers, select only a part of them for training, and at the same time ensure the accuracy of training. However, in federated learning, it is not trivial to know what the number of clusters can bring the best training result. Therefore, we propose to dynamically adjust the number of clusters to find the most ideal grouping results. It may reduce the number of users participating in the training to achieve the effect of reducing communication costs without affecting the model performance. We verify its experimental results on the non-IID handwritten digit recognition dataset and reduce the cost of communication and transmission by almost 50% compared with traditional federated learning without affecting the accuracy of the model.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Belief States for Cooperative Multi-Agent Reinforcement Learning under Partial Observability</title>
<link>https://arxiv.org/abs/2504.08417</link>
<guid>https://arxiv.org/abs/2504.08417</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
 <div>
arXiv:2504.08417v1 Announce Type: new 
Abstract: Reinforcement learning in partially observable environments is typically challenging, as it requires agents to learn an estimate of the underlying system state. These challenges are exacerbated in multi-agent settings, where agents learn simultaneously and influence the underlying state as well as each others' observations. We propose the use of learned beliefs on the underlying state of the system to overcome these challenges and enable reinforcement learning with fully decentralized training and execution. Our approach leverages state information to pre-train a probabilistic belief model in a self-supervised fashion. The resulting belief states, which capture both inferred state information as well as uncertainty over this information, are then used in a state-based reinforcement learning algorithm to create an end-to-end model for cooperative multi-agent reinforcement learning under partial observability. By separating the belief and reinforcement learning tasks, we are able to significantly simplify the policy and value function learning tasks and improve both the convergence speed and the final performance. We evaluate our proposed method on diverse partially observable multi-agent tasks designed to exhibit different variants of partial observability.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Boosting multi-demographic federated learning for chest x-ray analysis using general-purpose self-supervised representations</title>
<link>https://arxiv.org/abs/2504.08584</link>
<guid>https://arxiv.org/abs/2504.08584</guid>
<content:encoded><![CDATA[
<div> : (AI), , (FL), (non-IID), 

:
398,523X9,125(P<0.001)(P<0.064)(P=0.242)(P=0.031)(P<0.008)(P=0.052) <div>
arXiv:2504.08584v1 Announce Type: new 
Abstract: Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>mixEEG: Enhancing EEG Federated Learning for Cross-subject EEG Classification with Tailored mixup</title>
<link>https://arxiv.org/abs/2504.07987</link>
<guid>https://arxiv.org/abs/2504.07987</guid>
<content:encoded><![CDATA[
<div> mixEEG

<br />
EEGEEGEEGmixEEGmixEEGmixupEEGmixEEGEEGGitHub <div>
arXiv:2504.07987v1 Announce Type: cross 
Abstract: The cross-subject electroencephalography (EEG) classification exhibits great challenges due to the diversity of cognitive processes and physiological structures between different subjects. Modern EEG models are based on neural networks, demanding a large amount of data to achieve high performance and generalizability. However, privacy concerns associated with EEG pose significant limitations to data sharing between different hospitals and institutions, resulting in the lack of large dataset for most EEG tasks. Federated learning (FL) enables multiple decentralized clients to collaboratively train a global model without direct communication of raw data, thus preserving privacy. For the first time, we investigate the cross-subject EEG classification in the FL setting. In this paper, we propose a simple yet effective framework termed mixEEG. Specifically, we tailor the vanilla mixup considering the unique properties of the EEG modality. mixEEG shares the unlabeled averaged data of the unseen subject rather than simply sharing raw data under the domain adaptation setting, thus better preserving privacy and offering an averaged label as pseudo-label. Extensive experiments are conducted on an epilepsy detection and an emotion recognition dataset. The experimental result demonstrates that our mixEEG enhances the transferability of global model for cross-subject EEG classification consistently across different datasets and model architectures. Code is published at: https://github.com/XuanhaoLiu/mixEEG.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AIArena: A Blockchain-Based Decentralized AI Training Platform</title>
<link>https://arxiv.org/abs/2412.14566</link>
<guid>https://arxiv.org/abs/2412.14566</guid>
<content:encoded><![CDATA[
<div> : AIAIArena

:
AIAIAIAIArenaAIAIArenaAIAIArenaBaseSepoliaAIArena <div>
arXiv:2412.14566v3 Announce Type: replace 
Abstract: The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Copy-and-Paste? Identifying EVM-Inequivalent Code Smells in Multi-chain Reuse Contracts</title>
<link>https://arxiv.org/abs/2504.07589</link>
<guid>https://arxiv.org/abs/2504.07589</guid>
<content:encoded><![CDATA[
<div> : EVM-

<br /><br />:
GasEVM-1,379326Stack OverflowEVM-EquivGuard905,948EVM-17.70%EVM- <div>
arXiv:2504.07589v2 Announce Type: replace 
Abstract: As the development of Solidity contracts on Ethereum, more developers are reusing them on other compatible blockchains. However, developers may overlook the differences between the designs of the blockchain system, such as the Gas Mechanism and Consensus Protocol, leading to the same contracts on different blockchains not being able to achieve consistent execution as on Ethereum. This inconsistency reveals design flaws in reused contracts, exposing code smells that hinder code reusability, and we define this inconsistency as EVM-Inequivalent Code Smells. In this paper, we conducted the first empirical study to reveal the causes and characteristics of EVM-Inequivalent Code Smells. To ensure the identified smells reflect real developer concerns, we collected and analyzed 1,379 security audit reports and 326 Stack Overflow posts related to reused contracts on EVM-compatible blockchains, such as Binance Smart Chain (BSC) and Polygon. Using the open card sorting method, we defined six types of EVM-Inequivalent Code Smells. For automated detection, we developed a tool named EquivGuard. It employs static taint analysis to identify key paths from different patterns and uses symbolic execution to verify path reachability. Our analysis of 905,948 contracts across six major blockchains shows that EVM-Inequivalent Code Smells are widespread, with an average prevalence of 17.70%. While contracts with code smells do not necessarily lead to financial loss and attacks, their high prevalence and significant asset management underscore the potential threats of reusing these smelly Ethereum contracts. Thus, developers are advised to abandon Copy-and-Paste programming practices and detect EVM-Inequivalent Code Smells before reusing Ethereum contracts.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable Routing in a City-Scale Wi-Fi Network for Disaster Recovery</title>
<link>https://arxiv.org/abs/2504.06406</link>
<guid>https://arxiv.org/abs/2504.06406</guid>
<content:encoded><![CDATA[
<div> MapMeshmesh

:
MapMeshmeshMapMeshWi-Fimesh <div>
arXiv:2504.06406v1 Announce Type: new 
Abstract: In this paper, we present a new city-scale decentralized mesh network system suited for disaster recovery and emergencies. When wide-area connectivity is unavailable or significantly degraded, our system, MapMesh, enables static access points and mobile devices equipped with Wi-Fi in a city to route packets via each other for intra-city connectivity and to/from any nodes that might have Internet access, e.g., via satellite. The chief contribution of our work is a new routing protocol that scales to millions of nodes, a significant improvement over prior work on wireless mesh and mobile ad hoc networks. Our approach uses detailed information about buildings from widely available maps--data that was unavailable at scale over a decade ago, but is widely available now--to compute paths in a scalable way.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>More Efficient Stealth Address Protocol</title>
<link>https://arxiv.org/abs/2504.06744</link>
<guid>https://arxiv.org/abs/2504.06744</guid>
<content:encoded><![CDATA[
<div> Stealth Address Protocol (SAP) (Module-LWE)

:
Stealth Address Protocol (SAP)Curvy(Module-LWE)CurvySAP <div>
arXiv:2504.06744v1 Announce Type: new 
Abstract: The integration of privacy-preserving transactions into public blockchains such as Ethereum remains a major challenge. The Stealth Address Protocol (SAP) provides recipient anonymity by generating unlinkable stealth addresses. Existing SAPs, such as the Dual-Key Stealth Address Protocol and the Curvy Protocol, have shown significant improvements in efficiency, but remain vulnerable to quantum attacks. Post-quantum SAPs based on lattice-based cryptography, such as the Module-LWE SAP, on the other hand, offer quantum resistance while achieving better performance.
  In this paper, we present a novel hybrid SAP that combines the Curvy protocol with the computational advantages of the Module-LWE technique while remaining Ethereum-friendly. In contrast to full post-quantum solutions, our approach does not provide quantum security, but achieves a significant speedup in scanning the ephemeral public key registry, about three times faster than the Curvy protocol. We present a detailed cryptographic construction of our protocol and compare its performance with existing solutions. Our results prove that this hybrid approach is the most efficient Ethereum-compatible SAP to date.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Buffer Centering for bittide Synchronization via Frame Rotation</title>
<link>https://arxiv.org/abs/2504.07044</link>
<guid>https://arxiv.org/abs/2504.07044</guid>
<content:encoded><![CDATA[
<div> : bittide

:
<br />
bittidebittide <div>
arXiv:2504.07044v1 Announce Type: new 
Abstract: Maintaining consistent time in distributed systems is a fundamental challenge. The bittide system addresses this by providing logical synchronization through a decentralized control mechanism that observes local buffer occupancies and controls the frequency of an oscillator at each node. A critical aspect of bittide's stability and performance is ensuring that these elastic buffers operate around a desired equilibrium point, preventing data loss due to overflow or underflow. This paper introduces a novel method for centering buffer occupancies in a bittide network using a technique we term frame rotation. We propose a control strategy utilizing a directed spanning tree of the network graph. By adjusting the frequencies of nodes in a specific order dictated by this tree, and employing a pulsed feedback controller that targets the buffer occupancy of edges within the spanning tree, we prove that all elastic buffers in the network can be driven to their desired equilibrium. This ordered adjustment approach ensures that prior centering efforts are not disrupted, providing a robust mechanism for managing buffer occupancy in bittide synchronized systems.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Writing is on the Wall: Analyzing the Boom of Inscriptions and its Impact on EVM-compatible Blockchains</title>
<link>https://arxiv.org/abs/2405.15288</link>
<guid>https://arxiv.org/abs/2405.15288</guid>
<content:encoded><![CDATA[
<div> : arXiv:2405.15288v3, Ethereum, EVMrollups, , 

:
EVMRollupsArbitrumZKsync Era90%53%99%ZKsyncArbitrum gas ZK-sync EraZK-rollupRollupsArbitrumBaseOptimism <div>
arXiv:2405.15288v3 Announce Type: replace 
Abstract: This paper examines inscription-related transactions on Ethereum and major EVM-compatible rollups, assessing their impact on scalability during transaction surges. Our results show that, on certain days, inscriptions accounted for nearly 90% of transactions on Arbitrum and ZKsync Era, while 53% on Ethereum, with 99% of these inscriptions involving meme coin minting. Furthermore, we show that ZKsync and Arbitrum saw lower median gas fees during these surges. ZKsync Era, a ZK-rollup, showed a greater fee reduction than the optimistic rollups studied -- Arbitrum, Base, and Optimism.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Communication-Efficient Adversarial Federated Learning for Robust Edge Intelligence</title>
<link>https://arxiv.org/abs/2501.15257</link>
<guid>https://arxiv.org/abs/2501.15257</guid>
<content:encoded><![CDATA[
<div> :  (Federated Learning),  (Adversarial Learning),  (Communication Efficiency),  (Pre-trained Model),  (Knowledge Distillation)

:<br />
IIDPM-AFLPM-AFL <div>
arXiv:2501.15257v2 Announce Type: replace 
Abstract: Federated learning (FL) has gained significant attention for enabling decentralized training on edge networks without exposing raw data. However, FL models remain susceptible to adversarial attacks and performance degradation in non-IID data settings, thus posing challenges to both robustness and accuracy. This paper aims to achieve communication-efficient adversarial federated learning (AFL) by leveraging a pre-trained model to enhance both robustness and accuracy under adversarial attacks and non-IID challenges in AFL. By leveraging the knowledge from a pre-trained model for both clean and adversarial images, we propose a pre-trained model-guided adversarial federated learning (PM-AFL) framework. This framework integrates vanilla and adversarial mixture knowledge distillation to effectively balance accuracy and robustness while promoting local models to learn from diverse data. Specifically, for clean accuracy, we adopt a dual distillation strategy where the class probabilities of randomly paired images, and their blended versions are aligned between the teacher model and the local models. For adversarial robustness, we employ a similar distillation approach but replace clean samples on the local side with adversarial examples. Moreover, by considering the bias between local and global models, we also incorporate a consistency regularization term to ensure that local adversarial predictions stay aligned with their corresponding global clean ones. These strategies collectively enable local models to absorb diverse knowledge from the teacher model while maintaining close alignment with the global model, thereby mitigating overfitting to local optima and enhancing the generalization of the global model. Experiments demonstrate that the PM-AFL-based framework not only significantly outperforms other methods but also maintains communication efficiency.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Smart Contract with Control Flow Integrity</title>
<link>https://arxiv.org/abs/2504.05509</link>
<guid>https://arxiv.org/abs/2504.05509</guid>
<content:encoded><![CDATA[
<div> : DeFi

<br />
:
30DeFiCrossGuardCrossGuardCrossGuard280.28%gasDeFi <div>
arXiv:2504.05509v1 Announce Type: new 
Abstract: Smart contracts power decentralized financial (DeFi) services but are vulnerable to complex security exploits that can lead to significant financial losses. Existing security measures often fail to adequately protect these contracts due to the composability of DeFi protocols and the increasing sophistication of attacks. Through a large-scale empirical study of historical transactions from the 30 hacked DeFi protocols, we discovered that while benign transactions typically exhibit a limited number of unique control flows, in stark contrast, attack transactions consistently introduce novel, previously unobserved control flows. Building on these insights, we developed CrossGuard, a novel framework that enforces control flow integrity in real-time to secure smart contracts. Crucially, CrossGuard does not require prior knowledge of specific hacks; instead, it dynamically enforces control flow whitelisting policies and applies simplification heuristics at runtime. This approach monitors and prevents potential attacks by reverting all transactions that do not adhere to the established control flow whitelisting rules. Our evaluation demonstrates that CrossGuard effectively blocks 28 of the 30 analyzed attacks when configured only once prior to contract deployment, maintaining a low false positive rate of 0.28% and minimal additional gas costs. These results underscore the efficacy of applying control flow integrity to smart contracts, significantly enhancing security beyond traditional methods and addressing the evolving threat landscape in the DeFi ecosystem.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How Do Solidity Versions Affect Vulnerability Detection Tools? An Empirical Study</title>
<link>https://arxiv.org/abs/2504.05515</link>
<guid>https://arxiv.org/abs/2504.05515</guid>
<content:encoded><![CDATA[
<div> : Solidity

:
EthereumSoliditySoliditypragmaSoliditySmartBugs <div>
arXiv:2504.05515v1 Announce Type: new 
Abstract: Context: Smart contract vulnerabilities pose significant security risks for the Ethereum ecosystem, driving the development of automated tools for detection and mitigation. Smart contracts are written in Solidity, a programming language that is rapidly evolving to add features and improvements to enhance smart contract security. New versions of Solidity change the compilation process, potentially affecting how tools interpret and analyze smart contract code. Objective: In such a continuously evolving landscape, we aim to investigate the compatibility of detection tools with Solidity versions. More specifically, we present a plan to study detection tools by empirically assessing (i) their compatibility with the Solidity pragma directives, (ii) their detection effectiveness, and (iii) their execution time across different versions of Solidity. Method: We will conduct an exploratory study by running several tools and collecting a large number of real-world smart contracts to create a balanced dataset. We will track and analyze the tool execution through SmartBugs, a framework that facilitates the tool execution and allows the integration of new tools.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Hierarchical Reinforcement Learning for Adaptive Traffic Signal Control</title>
<link>https://arxiv.org/abs/2504.05553</link>
<guid>https://arxiv.org/abs/2504.05553</guid>
<content:encoded><![CDATA[
<div> : (MARL), (ATSC), (FL), (FedAvg), (HFRL)

<br /><br />:
(HFRL)(MARL)FedAvgHFRLFedAvgHFRL <div>
arXiv:2504.05553v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) has shown promise for adaptive traffic signal control (ATSC), enabling multiple intersections to coordinate signal timings in real time. However, in large-scale settings, MARL faces constraints due to extensive data sharing and communication requirements. Federated learning (FL) mitigates these challenges by training shared models without directly exchanging raw data, yet traditional FL methods such as FedAvg struggle with highly heterogeneous intersections. Different intersections exhibit varying traffic patterns, demands, and road structures, so performing FedAvg across all agents is inefficient. To address this gap, we propose Hierarchical Federated Reinforcement Learning (HFRL) for ATSC. HFRL employs clustering-based or optimization-based techniques to dynamically group intersections and perform FedAvg independently within groups of intersections with similar characteristics, enabling more effective coordination and scalability than standard FedAvg. Our experiments on synthetic and real-world traffic networks demonstrate that HFRL not only outperforms both decentralized and standard federated RL approaches but also identifies suitable grouping patterns based on network structure or traffic demand, resulting in a more robust framework for distributed, heterogeneous systems.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels</title>
<link>https://arxiv.org/abs/2504.05615</link>
<guid>https://arxiv.org/abs/2504.05615</guid>
<content:encoded><![CDATA[
<div> Federated Learningnoisy labelsFedEFCprestoppingloss correction

:
FedEFCFedEFC(1) prestopping(2) FedEFC41.64%<br /><br /> <div>
arXiv:2504.05615v1 Announce Type: new 
Abstract: Federated Learning (FL) is a powerful framework for privacy-preserving distributed learning. It enables multiple clients to collaboratively train a global model without sharing raw data. However, handling noisy labels in FL remains a major challenge due to heterogeneous data distributions and communication constraints, which can severely degrade model performance. To address this issue, we propose FedEFC, a novel method designed to tackle the impact of noisy labels in FL. FedEFC mitigates this issue through two key techniques: (1) prestopping, which prevents overfitting to mislabeled data by dynamically halting training at an optimal point, and (2) loss correction, which adjusts model updates to account for label noise. In particular, we develop an effective loss correction tailored to the unique challenges of FL, including data heterogeneity and decentralized training. Furthermore, we provide a theoretical analysis, leveraging the composite proper loss property, to demonstrate that the FL objective function under noisy label distributions can be aligned with the clean label distribution. Extensive experimental results validate the effectiveness of our approach, showing that it consistently outperforms existing FL techniques in mitigating the impact of noisy labels, particularly under heterogeneous data settings (e.g., achieving up to 41.64% relative performance improvement over the existing loss correction method).
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust and Efficient Average Consensus with Non-Coherent Over-the-Air Aggregation</title>
<link>https://arxiv.org/abs/2504.05729</link>
<guid>https://arxiv.org/abs/2504.05729</guid>
<content:encoded><![CDATA[
<div> 

:<br />
D-PGDD-PGD <div>
arXiv:2504.05729v1 Announce Type: new 
Abstract: Non-coherent over-the-air (OTA) computation has garnered increasing attention for its advantages in facilitating information aggregation among distributed agents in resource-constrained networks without requiring precise channel estimation. A promising application scenario of this method is distributed average consensus in wireless multi-agent systems. However, in such scenario, non-coherent interference from concurrent OTA transmissions can introduce bias in the consensus value. To address this issue, we develop a robust distributed average consensus algorithm by formulating the consensus problem as a distributed optimization problem. Using decentralized projected gradient descent (D-PGD), our proposed algorithm can achieve unbiased mean square average consensus even in the presence of non-coherent interference and noise. Additionally, we implement transmit power control and receive scaling mechanisms to further accelerate convergence. Simulation results demonstrate that our method can significantly enhance the convergence speed of the D-PGD algorithm for OTA average consensus without compromising accuracy.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Security Vulnerabilities in Ethereum Smart Contracts: A Systematic Analysis</title>
<link>https://arxiv.org/abs/2504.05968</link>
<guid>https://arxiv.org/abs/2504.05968</guid>
<content:encoded><![CDATA[
<div> 

<br />
:
RemixSolidityDAOParityKotET <div>
arXiv:2504.05968v1 Announce Type: new 
Abstract: Smart contracts are a secure and trustworthy application that plays a vital role in decentralized applications in various fields such as insurance,the internet, and gaming. However, in recent years, smart contract security breaches have occurred frequently, and due to their financial properties, they have caused huge economic losses, such as the most famous security incident "The DAO" which caused a loss of over \$60 million in Ethereum. This has drawn a lot of attention from all sides. Writing a secure smart contract is now a critical issue.This paper focuses on Ether smart contracts and explains the main components of Ether, smart contract architecture and mechanism.The environment used in this paper is the Ethernet environment, using remix online compilation platform and Solidity language, according to the four security events of American Chain, The DAO, Parity and KotET, the principles of integer overflow attack, reentrant attack, access control attack and denial of service attack are studied and analyzed accordingly, and the scenarios of these vulnerabilities are reproduced, and the measures to prevent them are given. Finally, preventive measures are given. In addition, the principles of short address attack, early transaction attack and privileged function exposure attack are also introduced in detail, and security measures are proposed.As vulnerabilities continue to emerge, their classification will also evolve. The analysis and research of the current vulnerabilities are also to lay a solid foundation for avoiding more vulnerabilities.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning</title>
<link>https://arxiv.org/abs/2504.06135</link>
<guid>https://arxiv.org/abs/2504.06135</guid>
<content:encoded><![CDATA[
<div> : SHIMIRetrieval-Augmented Generation (RAG)

:
SHIMIAIRAGSHIMISHIMIMerkle-DAGCRDTSHIMI <div>
arXiv:2504.06135v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) and vector-based search have become foundational tools for memory in AI systems, yet they struggle with abstraction, scalability, and semantic precision - especially in decentralized environments. We present SHIMI (Semantic Hierarchical Memory Index), a unified architecture that models knowledge as a dynamically structured hierarchy of concepts, enabling agents to retrieve information based on meaning rather than surface similarity. SHIMI organizes memory into layered semantic nodes and supports top-down traversal from abstract intent to specific entities, offering more precise and explainable retrieval. Critically, SHIMI is natively designed for decentralized ecosystems, where agents maintain local memory trees and synchronize them asynchronously across networks. We introduce a lightweight sync protocol that leverages Merkle-DAG summaries, Bloom filters, and CRDT-style conflict resolution to enable partial synchronization with minimal overhead. Through benchmark experiments and use cases involving decentralized agent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy, semantic fidelity, and scalability - positioning it as a core infrastructure layer for decentralized cognitive systems.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Oracles for Real Estate Rental</title>
<link>https://arxiv.org/abs/2504.06180</link>
<guid>https://arxiv.org/abs/2504.06180</guid>
<content:encoded><![CDATA[
<div> 

:<br />
 <div>
arXiv:2504.06180v1 Announce Type: new 
Abstract: Blockchain technology has seen adoption across various industries and the real estate sector is no exception. The traditional property leasing process guarantees no trust between parties, uses insecure communication channels, and forces participants who are not familiar with the process to perform contracts. Blockchain technology emerges as a solution to simplify the traditional property leasing process. This work proposes the use of two blockchain oracles to handle, respectively, maintenance issues and automate rent payments in the context of property rental. These two components are introduced in a blockchain-based property rental platform.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</title>
<link>https://arxiv.org/abs/2504.06211</link>
<guid>https://arxiv.org/abs/2504.06211</guid>
<content:encoded><![CDATA[
<div> : Zero-Knowledge Proofs (), ZKP, HyperPlonk, , zkSpeed

:
Zero-Knowledge Proofs (ZKPs)ZKPsZKPGPUASICZKPzkSpeedHyperPlonkZKP366.46 mm2 TB/sCPU801 <div>
arXiv:2504.06211v1 Announce Type: new 
Abstract: Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in privacy-preserving and verifiable computing. ZKPs enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable machine learning, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process. Recent works have accelerated the key primitives of state-of-the-art ZKP protocols on GPU and ASIC. However, the protocols accelerated thus far face one of two challenges: they either require a trusted setup for each application, or they generate larger proof sizes with higher verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. This work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes for typical ZKP applications in publicly verifiable, consensus-based systems. We accelerate the entire protocol, including two major primitives: SumCheck and Multi-scalar Multiplications (MSMs). We develop a full-chip architecture using 366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation process, achieving geometric mean speedups of 801$\times$ over CPU baselines.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis</title>
<link>https://arxiv.org/abs/2504.06235</link>
<guid>https://arxiv.org/abs/2504.06235</guid>
<content:encoded><![CDATA[
<div> federated learning, domain generalization, decentralized, style sharing, convergence rate

<br /><br />:
FLDGFLDG$\texttt{StyleDDG}$DGDGDGDG$\texttt{StyleDDG}$$\texttt{StyleDDG}$$\texttt{StyleDDG}$ <div>
arXiv:2504.06235v1 Announce Type: new 
Abstract: Much of the federated learning (FL) literature focuses on settings where local dataset statistics remain the same between training and testing time. Recent advances in domain generalization (DG) aim to use data from source (training) domains to train a model that generalizes well to data from unseen target (testing) domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives and training processes; and (2) DG research in FL being limited to the conventional star-topology architecture. Addressing the second gap, we develop $\textit{Decentralized Federated Domain Generalization with Style Sharing}$ ($\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to allow devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we fill the first gap by providing the first systematic approach to mathematically analyzing style-based DG training optimization. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which a sub-linear convergence rate of $\texttt{StyleDDG}$ can be obtained. Through experiments on two popular DG datasets, we demonstrate that $\texttt{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal added communication overhead compared to decentralized gradient methods that do not employ style sharing.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Triple-entry Accounting, Blockchain and Next of Kin: Towards a Standardisation of Ledger Terminology</title>
<link>https://arxiv.org/abs/2101.02632</link>
<guid>https://arxiv.org/abs/2101.02632</guid>
<content:encoded><![CDATA[
<div> triple-entry accounting (TEA)blockchainterminologystandardisationdecentralised systemsdistributed ledgersdistributed journals

<br />
:
(TEA)TEATEA <div>
arXiv:2101.02632v3 Announce Type: replace 
Abstract: Triple-entry accounting (TEA) is simultaneously a novel application in the blockchain universe and one of the many concepts applied in blockchain technology. Its Wild Wild West status is accompanied by a lack of consistent and comprehensive set of categories, a state of play that impedes a proper apprehension of the technology, leading to contradictions and oversight of important nuances. To clearly delineate the confines of TEA within the world of blockchain, we provide building blocks to standardise its terminology. Particularly, we distinguish between essential elements such as accounting and bookkeeping, as well as between decentralised systems, distributed ledgers and distributed journals.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>4CNet: A Diffusion Approach to Map Prediction for Decentralized Multi-Robot Exploration</title>
<link>https://arxiv.org/abs/2402.17904</link>
<guid>https://arxiv.org/abs/2402.17904</guid>
<content:encoded><![CDATA[
<div> Mobile robots, unknown environments, 4CNet, map prediction, exploration

:<br />
4CNet1234CNet4CNet-E4CNet-E4CNet-E <div>
arXiv:2402.17904v3 Announce Type: replace 
Abstract: Mobile robots in unknown cluttered environments with irregularly shaped obstacles often face energy and communication challenges which directly affect their ability to explore these environments. In this paper, we introduce a novel deep learning architecture, Confidence-Aware Contrastive Conditional Consistency Model (4CNet), for robot map prediction during decentralized, resource-limited multi-robot exploration. 4CNet uniquely incorporates: 1) a conditional consistency model for map prediction in unstructured unknown regions, 2) a contrastive map-trajectory pretraining framework for a trajectory encoder that extracts spatial information from the trajectories of nearby robots during map prediction, and 3) a confidence network to measure the uncertainty of map prediction for effective exploration under resource constraints. We incorporate 4CNet within our proposed robot exploration with map prediction architecture, 4CNet-E. We then conduct extensive comparison studies with 4CNet-E and state-of-the-art heuristic and learning methods to investigate both map prediction and exploration performance in environments consisting of irregularly shaped obstacles and uneven terrain. Results showed that 4CNet-E obtained statistically significant higher prediction accuracy and area coverage with varying environment sizes, number of robots, energy budgets, and communication limitations when compared to database and learning-based methods. Hardware experiments were performed and validated the applicability and generalizability of 4CNet-E in both unstructured indoor and real natural outdoor environments.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HiCoCS: High Concurrency Cross-Sharding on Permissioned Blockchains</title>
<link>https://arxiv.org/abs/2501.04265</link>
<guid>https://arxiv.org/abs/2501.04265</guid>
<content:encoded><![CDATA[
<div> : HiCoCS

<br /><br />:
Web3(\textsf{CSTx})Hyperledger Fabric\textsf{CSTx}HiCoCSHiCoCS\textsf{CSTx}HiCoCS\textsf{CSTx}HiCoCS3.520.2 <div>
arXiv:2501.04265v3 Announce Type: replace 
Abstract: As the foundation of the Web3 trust system, blockchain technology faces increasing demands for scalability. Sharding emerges as a promising solution, but it struggles to handle highly concurrent cross-shard transactions (\textsf{CSTx}s), primarily due to simultaneous ledger operations on the same account. Hyperledger Fabric, a permissioned blockchain, employs multi-version concurrency control for parallel processing. Existing solutions use channels and intermediaries to achieve cross-sharding in Hyperledger Fabric. However, the conflict problem caused by highly concurrent \textsf{CSTx}s has not been adequately resolved. To fill this gap, we propose HiCoCS, a high concurrency cross-shard scheme for permissioned blockchains. HiCoCS creates a unique virtual sub-broker for each \textsf{CSTx} by introducing a composite key structure, enabling conflict-free concurrent transaction processing while reducing resource overhead. The challenge lies in managing large numbers of composite keys and mitigating intermediary privacy risks. HiCoCS utilizes virtual sub-brokers to receive and process \textsf{CSTx}s concurrently while maintaining a transaction pool. Batch processing is employed to merge multiple \textsf{CSTx}s in the pool, improving efficiency. We explore composite key reuse to reduce the number of virtual sub-brokers and lower system overhead. Privacy preservation is enhanced using homomorphic encryption. Evaluations show that HiCoCS improves cross-shard transaction throughput by 3.5-20.2 times compared to the baselines.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Federated XGBoost with CUDA-accelerated Homomorphic Encryption via NVIDIA FLARE</title>
<link>https://arxiv.org/abs/2504.03909</link>
<guid>https://arxiv.org/abs/2504.03909</guid>
<content:encoded><![CDATA[
<div> : , , XGBoost, , 

:
NVIDIA FLAREFederated XGBoostSecure Federated XGBoost(HE)HEFederated XGBoostCPUCUDAHECUDAFederated XGBoost30Secure Federated XGBoost <div>
arXiv:2504.03909v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized datasets. NVIDIA FLARE's Federated XGBoost extends the popular XGBoost algorithm to both vertical and horizontal federated settings, facilitating joint model development without direct data sharing. However, the initial implementation assumed mutual trust over the sharing of intermediate gradient statistics produced by the XGBoost algorithm, leaving potential vulnerabilities to honest-but-curious adversaries. This work introduces "Secure Federated XGBoost", an efficient solution to mitigate these risks. We implement secure federated algorithms for both vertical and horizontal scenarios, addressing diverse data security patterns. To secure the messages, we leverage homomorphic encryption (HE) to protect sensitive information during training. A novel plugin and processor interface seamlessly integrates HE into the Federated XGBoost pipeline, enabling secure aggregation over ciphertexts. We present both CPU-based and CUDA-accelerated HE plugins, demonstrating significant performance gains. Notably, our CUDA-accelerated HE implementation achieves up to 30x speedups in vertical Federated XGBoost compared to existing third-party solutions. By securing critical computation steps and encrypting sensitive assets, Secure Federated XGBoost provides robust data privacy guarantees, reinforcing the fundamental benefits of federated learning while maintaining high performance.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Commit-Reveal$^2$: Randomized Reveal Order Mitigates Last-Revealer Attacks in Commit-Reveal</title>
<link>https://arxiv.org/abs/2504.03936</link>
<guid>https://arxiv.org/abs/2504.03936</guid>
<content:encoded><![CDATA[
<div> : Commit-Reveallast revealerCommit-Reveal$^2$

:
Commit-Reveallast revealerCommit-Reveal$^2$Commit-Reveal<br /><br /> <div>
arXiv:2504.03936v1 Announce Type: new 
Abstract: Randomness generation is a fundamental component in blockchain systems, essential for tasks such as validator selection, zero-knowledge proofs, and decentralized finance operations. Traditional Commit-Reveal mechanisms provide simplicity and security but are susceptible to last revealer attacks, where an adversary can manipulate the random outcome by withholding their reveal. To address this vulnerability, we propose the Commit-Reveal$^2$ protocol, which employs a two-layer Commit-Reveal process to randomize the reveal order and mitigate the risk of such attacks. Additionally, we introduces a method to leverage off-chain networks to optimize communication costs and enhance efficiency. We implement a prototype of the proposed mechanism and publicly release the code to facilitate practical adoption and further research.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Source Mapping for Zero-Knowledge Smart Contracts: Design and Preliminary Evaluation</title>
<link>https://arxiv.org/abs/2504.04322</link>
<guid>https://arxiv.org/abs/2504.04322</guid>
<content:encoded><![CDATA[
<div> zero-knowledge-compatible smart contracts, source mapping, zkSolc, LLVM IR, zkEVM bytecode

:<br />
zkSolczkSolcSolidityLLVM IRzkEVM50500zkSyncSolidity97.2%8.6%zk-Rollup <div>
arXiv:2504.04322v1 Announce Type: new 
Abstract: Debugging and auditing zero-knowledge-compatible smart contracts remains a significant challenge due to the lack of source mapping in compilers such as zkSolc. In this work, we present a preliminary source mapping framework that establishes traceability between Solidity source code, LLVM IR, and zkEVM bytecode within the zkSolc compilation pipeline. Our approach addresses the traceability challenges introduced by non-linear transformations and proof-friendly optimizations in zero-knowledge compilation. To improve the reliability of mappings, we incorporate lightweight consistency checks based on static analysis and structural validation. We evaluate the framework on a dataset of 50 benchmark contracts and 500 real-world zkSync contracts, observing a mapping accuracy of approximately 97.2% for standard Solidity constructs. Expected limitations arise in complex scenarios such as inline assembly and deep inheritance hierarchies. The measured compilation overhead remains modest, at approximately 8.6%. Our initial results suggest that source mapping support in zero-knowledge compilation pipelines is feasible and can benefit debugging, auditing, and development workflows. We hope that this work serves as a foundation for further research and tool development aimed at improving developer experience in zk-Rollup environments.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ChronoSync: A Decentralized Chronometer Synchronization Protocol for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2504.04347</link>
<guid>https://arxiv.org/abs/2504.04347</guid>
<content:encoded><![CDATA[
<div> : <br /><br />:

gLyapunov <div>
arXiv:2504.04347v1 Announce Type: new 
Abstract: This work presents a decentralized time synchronization algorithm for multi-agent systems. Each agent possesses two clocks, a hardware clock that is perturbed by environmental phenomena (e.g., temperature, humidity, pressure, g forces, etc.) and a steerable software clock that inherits the perturbations affecting the hardware clock. Under these disturbances and the independent time kept by the hardware clocks, our consensus-based controller enables all agents to steer their software-defined clocks into practical synchronization while achieving a common user-defined clock drift. Furthermore, we treat the drift of each hardware clock as an unknown parameter, which our algorithm can accurately estimate. The coupling of the agents is modeled by a connected, undirected, and static graph. However, each agent possesses a timer mechanism that determines when to broadcast a sample of its software time and update its own software-time estimate. Hence, communication between agents can be directed, intermittent, and asynchronous. The closed-loop dynamics of the ensemble is modeled using a hybrid system, where a Lyapunov-based stability analysis demonstrates that a set encoding the time synchronization and clock drift estimation objectives is globally practically exponentially stable. The performance suggested by the theoretical development is confirmed in simulation.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WeiDetect: Weibull Distribution-Based Defense against Poisoning Attacks in Federated Learning for Network Intrusion Detection Systems</title>
<link>https://arxiv.org/abs/2504.04367</link>
<guid>https://arxiv.org/abs/2504.04367</guid>
<content:encoded><![CDATA[
<div> WeiDetect

:
NIDSIIDWeiDetectNIDSWeiDetect70%F11%14%CIC-Darknet2020CSE-CIC-IDS2018IID <div>
arXiv:2504.04367v1 Announce Type: new 
Abstract: In the era of data expansion, ensuring data privacy has become increasingly critical, posing significant challenges to traditional AI-based applications. In addition, the increasing adoption of IoT devices has introduced significant cybersecurity challenges, making traditional Network Intrusion Detection Systems (NIDS) less effective against evolving threats, and privacy concerns and regulatory restrictions limit their deployment. Federated Learning (FL) has emerged as a promising solution, allowing decentralized model training while maintaining data privacy to solve these issues. However, despite implementing privacy-preserving technologies, FL systems remain vulnerable to adversarial attacks. Furthermore, data distribution among clients is not heterogeneous in the FL scenario. We propose WeiDetect, a two-phase, server-side defense mechanism for FL-based NIDS that detects malicious participants to address these challenges. In the first phase, local models are evaluated using a validation dataset to generate validation scores. These scores are then analyzed using a Weibull distribution, identifying and removing malicious models. We conducted experiments to evaluate the effectiveness of our approach in diverse attack settings. Our evaluation included two popular datasets, CIC-Darknet2020 and CSE-CIC-IDS2018, tested under non-IID data distributions. Our findings highlight that WeiDetect outperforms state-of-the-art defense approaches, improving higher target class recall up to 70% and enhancing the global model's F1 score by 1% to 14%.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Large Language Model usage in Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2504.04685</link>
<guid>https://arxiv.org/abs/2504.04685</guid>
<content:encoded><![CDATA[
<div> : AI

:
LLMsSlitherMythrilLLM-basedLLMs <div>
arXiv:2504.04685v1 Announce Type: new 
Abstract: Recent years have seen an explosion of activity in Generative AI, specifically Large Language Models (LLMs), revolutionising applications across various fields. Smart contract vulnerability detection is no exception; as smart contracts exist on public chains and can have billions of dollars transacted daily, continuous improvement in vulnerability detection is crucial. This has led to many researchers investigating the usage of generative large language models (LLMs) to aid in detecting vulnerabilities in smart contracts.
  This paper presents a systematic review of the current LLM-based smart contract vulnerability detection tools, comparing them against traditional static and dynamic analysis tools Slither and Mythril. Our analysis highlights key areas where each performs better and shows that while these tools show promise, the LLM-based tools available for testing are not ready to replace more traditional tools. We conclude with recommendations on how LLMs are best used in the vulnerability detection process and offer insights for improving on the state-of-the-art via hybrid approaches and targeted pre-training of much smaller models.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large-Scale Mixed-Traffic and Intersection Control using Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2504.04691</link>
<guid>https://arxiv.org/abs/2504.04691</guid>
<content:encoded><![CDATA[
<div> : 

:
1480%6.175.09500454493 <div>
arXiv:2504.04691v1 Announce Type: new 
Abstract: Traffic congestion remains a significant challenge in modern urban networks. Autonomous driving technologies have emerged as a potential solution. Among traffic control methods, reinforcement learning has shown superior performance over traffic signals in various scenarios. However, prior research has largely focused on small-scale networks or isolated intersections, leaving large-scale mixed traffic control largely unexplored. This study presents the first attempt to use decentralized multi-agent reinforcement learning for large-scale mixed traffic control in which some intersections are managed by traffic signals and others by robot vehicles. Evaluating a real-world network in Colorado Springs, CO, USA with 14 intersections, we measure traffic efficiency via average waiting time of vehicles at intersections and the number of vehicles reaching their destinations within a time window (i.e., throughput). At 80% RV penetration rate, our method reduces waiting time from 6.17 s to 5.09 s and increases throughput from 454 vehicles per 500 seconds to 493 vehicles per 500 seconds, outperforming the baseline of fully signalized intersections. These findings suggest that integrating reinforcement learning-based control large-scale traffic can improve overall efficiency and may inform future urban planning strategies.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Trust in AI Marketplaces: Evaluating On-Chain Verification of Personalized AI models using zk-SNARKs</title>
<link>https://arxiv.org/abs/2504.04794</link>
<guid>https://arxiv.org/abs/2504.04794</guid>
<content:encoded><![CDATA[
<div> : Chainlink

<br /><br />:
zk-SNARKsChainlinkAIAI233.6361.50AIAIAI <div>
arXiv:2504.04794v1 Announce Type: new 
Abstract: The rapid advancement of artificial intelligence (AI) has brought about sophisticated models capable of various tasks ranging from image recognition to natural language processing. As these models continue to grow in complexity, ensuring their trustworthiness and transparency becomes critical, particularly in decentralized environments where traditional trust mechanisms are absent. This paper addresses the challenge of verifying personalized AI models in such environments, focusing on their integrity and privacy. We propose a novel framework that integrates zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs) with Chainlink decentralized oracles to verify AI model performance claims on blockchain platforms. Our key contribution lies in integrating zk-SNARKs with Chainlink oracles to securely fetch and verify external data to enable trustless verification of AI models on a blockchain. Our approach addresses the limitations of using unverified external data for AI verification on the blockchain while preserving sensitive information of AI models and enhancing transparency. We demonstrate our methodology with a linear regression model predicting Bitcoin prices using on-chain data verified on the Sepolia testnet. Our results indicate the framework's efficacy, with key metrics including proof generation taking an average of 233.63 seconds and verification time of 61.50 seconds. This research paves the way for transparent and trustless verification processes in blockchain-enabled AI ecosystems, addressing key challenges such as model integrity and model privacy protection. The proposed framework, while exemplified with linear regression, is designed for broader applicability across more complex AI models, setting the stage for future advancements in transparent AI verification.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartBugBert: BERT-Enhanced Vulnerability Detection for Smart Contract Bytecode</title>
<link>https://arxiv.org/abs/2504.05002</link>
<guid>https://arxiv.org/abs/2504.05002</guid>
<content:encoded><![CDATA[
<div> SmartBugBertBytecode

:
SmartBugBertBERTCFGopcodeTF-IDFCFGBERTLightGBMSmartBugBert6,157SmartBugBert90.62%91.76%91.19%F1CFG0.14 <div>
arXiv:2504.05002v1 Announce Type: new 
Abstract: Smart contracts deployed on blockchain platforms are vulnerable to various security vulnerabilities. However, only a small number of Ethereum contracts have released their source code, so vulnerability detection at the bytecode level is crucial. This paper introduces SmartBugBert, a novel approach that combines BERT-based deep learning with control flow graph (CFG) analysis to detect vulnerabilities directly from bytecode. Our method first decompiles smart contract bytecode into optimized opcode sequences, extracts semantic features using TF-IDF, constructs control flow graphs to capture execution logic, and isolates vulnerable CFG fragments for targeted analysis. By integrating both semantic and structural information through a fine-tuned BERT model and LightGBM classifier, our approach effectively identifies four critical vulnerability types: transaction-ordering, access control, self-destruct, and timestamp dependency vulnerabilities. Experimental evaluation on 6,157 Ethereum smart contracts demonstrates that SmartBugBert achieves 90.62% precision, 91.76% recall, and 91.19% F1-score, significantly outperforming existing detection methods. Ablation studies confirm that the combination of semantic features with CFG information substantially enhances detection performance. Furthermore, our approach maintains efficient detection speed (0.14 seconds per contract), making it practical for large-scale vulnerability assessment.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Smart Contract Vulnerability Detection in DApps Leveraging Fine-Tuned LLM</title>
<link>https://arxiv.org/abs/2504.05006</link>
<guid>https://arxiv.org/abs/2504.05006</guid>
<content:encoded><![CDATA[
<div> Decentralized Applications (DApps)Smart ContractsVulnerability DetectionLarge Language Models (LLMs)Fine-tuning

<br /><br />:

LLMs215DApp4,998FFTLoRALlama3-8BQwen2-7BLLMsFFTROS0.83F1LLM0.970.68LLMDApp <div>
arXiv:2504.05006v1 Announce Type: new 
Abstract: Decentralized applications (DApps) face significant security risks due to vulnerabilities in smart contracts, with traditional detection methods struggling to address emerging and machine-unauditable flaws. This paper proposes a novel approach leveraging fine-tuned Large Language Models (LLMs) to enhance smart contract vulnerability detection. We introduce a comprehensive dataset of 215 real-world DApp projects (4,998 contracts), including hard-to-detect logical errors like token price manipulation, addressing the limitations of existing simplified benchmarks. By fine-tuning LLMs (Llama3-8B and Qwen2-7B) with Full-Parameter Fine-Tuning (FFT) and Low-Rank Adaptation (LoRA), our method achieves superior performance, attaining an F1-score of 0.83 with FFT and data augmentation via Random Over Sampling (ROS). Comparative experiments demonstrate significant improvements over prompt-based LLMs and state-of-the-art tools. Notably, the approach excels in detecting non-machine-auditable vulnerabilities, achieving 0.97 precision and 0.68 recall for price manipulation flaws. The results underscore the effectiveness of domain-specific LLM fine-tuning and data augmentation in addressing real-world DApp security challenges, offering a robust solution for blockchain ecosystem protection.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hollow Victory: How Malicious Proposers Exploit Validator Incentives in Optimistic Rollup Dispute Games</title>
<link>https://arxiv.org/abs/2504.05094</link>
<guid>https://arxiv.org/abs/2504.05094</guid>
<content:encoded><![CDATA[
<div> Blockchain, Layer-2 Scaling, Optimistic Rollup, Dispute Game, Economic Security

<br /><br />:
Layer-2Optimistic RollupLayer-2 <div>
arXiv:2504.05094v1 Announce Type: new 
Abstract: Blockchain systems, such as Ethereum, are increasingly adopting layer-2 scaling solutions to improve transaction throughput and reduce fees. One popular layer-2 approach is the Optimistic Rollup, which relies on a mechanism known as a dispute game for block proposals. In these systems, validators can challenge blocks that they believe contain errors, and a successful challenge results in the transfer of a portion of the proposer's deposit as a reward. In this paper, we reveal a structural vulnerability in the mechanism: validators may not be awarded a proper profit despite winning a dispute challenge. We develop a formal game-theoretic model of the dispute game and analyze several scenarios, including cases where the proposer controls some validators and cases where a secondary auction mechanism is deployed to induce additional participation. Our analysis demonstrates that under current designs, the competitive pressure from validators may be insufficient to deter malicious behavior. We find that increased validator competition, paradoxically driven by higher rewards or participation, can allow a malicious proposer to significantly lower their net loss by capturing value through mechanisms like auctions. To address this, we propose countermeasures such as an escrowed reward mechanism and a commit-reveal protocol. Our findings provide critical insights into enhancing the economic security of layer-2 scaling solutions in blockchain networks.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Semantic Federated Learning for Real-Time Public Safety Tasks: Challenges, Methods, and Directions</title>
<link>https://arxiv.org/abs/2504.05107</link>
<guid>https://arxiv.org/abs/2504.05107</guid>
<content:encoded><![CDATA[
<div> DSFLSCBoWFire

<br /><br />:
DSFLDSFLSCBoWFireDSFL <div>
arXiv:2504.05107v1 Announce Type: new 
Abstract: Public safety tasks rely on the collaborative functioning of multiple edge devices (MEDs) and base stations (BSs) in different regions, consuming significant communication energy and computational resources to execute critical operations like fire monitoring and rescue missions. Traditional federated edge computing (EC) methods require frequent central communication, consuming substantial energy and struggling with resource heterogeneity across devices, networks, and data. To this end, this paper introduces a decentralized semantic federated learning (DSFL) framework tailored for large-scale wireless communication systems and heterogeneous MEDs. The framework incorporates a hierarchical semantic communication (SC) scheme to extend EC coverage and reduce communication overhead. Specifically, the lower layer optimizes intra-BS communication through task-specific encoding and selective transmission under constrained networks, while the upper layer ensures robust inter-BS communication via semantic aggregation and distributed consensus across different regions. To further balance communication costs and semantic accuracy, an energy-efficient aggregation scheme is developed for both intra-BS and inter-BS communication. The effectiveness of the DSFL framework is demonstrated through a case study using the BoWFire dataset, showcasing its potential in real-time fire detection scenarios. Finally, we outlines open issues for edge intelligence and SC in public safety tasks.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Taming Double-Spending in Offline Payments with Reputation-Weighted Loan Networks</title>
<link>https://arxiv.org/abs/2504.05143</link>
<guid>https://arxiv.org/abs/2504.05143</guid>
<content:encoded><![CDATA[
<div> : Blockchain, offline transaction, Overdraft, loan network, reputation

<br /><br />:
OverdraftOverdraftOverdraftSybilOverdraftSepolia <div>
arXiv:2504.05143v1 Announce Type: new 
Abstract: Blockchain solutions typically assume a synchronous network to ensure consistency and achieve consensus. In contrast, offline transaction systems aim to enable users to agree on and execute transactions without assuming bounded communication delays when interacting with the blockchain. Most existing offline payment schemes depend on trusted hardware wallets that are assumed to be secure and tamper-proof. While this work introduces Overdraft, a novel offline payment system that shifts the reliance from hardware to users themselves. Overdraft allows potential payment receivers to assess the likelihood of being paid, allowing them to accept transactions with confidence or deny them. Overdraft achieves this by maintaining a loan network that is weighted by online reputation. This loan network contains time-limited agreements where users pledge to cover another user's payment if necessary. For example, when a payer lacks sufficient funds at the moment of commitment. Offline users rely on the last known view of the loan network -- which they had access to when last online -- to determine whether to participate in an offline transaction. This view is used to estimate the probability of eventual payment, possibly using multiple loans. Once online again, users commit their transactions to the blockchain with any conflicts being resolved deterministically. Overdraft incorporates incentives for users and is designed to be resilient against Sybil attacks. As a proof of concept, we implemented Overdraft as an Ethereum Solidity smart contract and deployed it on the Sepolia testnet to evaluate its performance.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trial-and-Error Learning in Decentralized Matching Markets</title>
<link>https://arxiv.org/abs/2411.02377</link>
<guid>https://arxiv.org/abs/2411.02377</guid>
<content:encoded><![CDATA[
<div> : -sided

:
1) 2)  <div>
arXiv:2411.02377v2 Announce Type: replace 
Abstract: Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in several contexts. In static, centralized markets where agents know their preferences, standard algorithms can yield a stable matching. However, in dynamic, decentralized markets where agents must learn their preferences through interaction, such algorithms cannot be used. Our goal in this paper is to identify achievable stability guarantees in decentralized matching markets where (i) agents have limited information about their preferences and (ii) no central entity determines the match. Surprisingly, our first result demonstrates that these constraints do not preclude stability--simple "trial and error" learning policies guarantee convergence to a stable matching without requiring coordination between agents. Our second result shows that more sophisticated policies can direct the system toward a particular group's optimal stable matching. This finding highlights an important dimension of strategic learning: when agents can accurately model others' policies, they can adapt their own behavior to systematically influence outcomes in their favor--a phenomenon with broad implications for learning in multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Air Quality Monitoring: A Brief Review of Federated Learning Advances</title>
<link>https://arxiv.org/abs/2504.02909</link>
<guid>https://arxiv.org/abs/2504.02909</guid>
<content:encoded><![CDATA[
<div> : Federated Learning (), , , , 

:
Federated Learning () <div>
arXiv:2504.02909v1 Announce Type: new 
Abstract: Monitoring air quality and environmental conditions is crucial for public health and effective urban planning. Current environmental monitoring approaches often rely on centralized data collection and processing, which pose significant privacy, security, and scalability challenges. Federated Learning (FL) offers a promising solution to these limitations by enabling collaborative model training across multiple devices without sharing raw data. This decentralized approach addresses privacy concerns while still leveraging distributed data sources. This paper provides a comprehensive review of FL applications in air quality and environmental monitoring, emphasizing its effectiveness in predicting pollutants and managing environmental data. However, the paper also identifies key limitations of FL when applied in this domain, including challenges such as communication overhead, infrastructure demands, generalizability issues, computational complexity, and security vulnerabilities. For instance, communication overhead, caused by the frequent exchange of model updates between local devices and central servers, is a notable challenge. To address this, future research should focus on optimizing communication protocols and reducing the frequency of updates to lessen the burden on network resources. Additionally, the paper suggests further research directions to refine FL frameworks and enhance their applicability in real-world environmental monitoring scenarios. By synthesizing findings from existing studies, this paper highlights the potential of FL to improve air quality management while maintaining data privacy and security, and it provides valuable insights for future developments in the field.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating Identity-Based Identification against Adaptive Adversaries in Federated Learning</title>
<link>https://arxiv.org/abs/2504.03077</link>
<guid>https://arxiv.org/abs/2504.03077</guid>
<content:encoded><![CDATA[
<div> : (Federated Learning)(Reconnecting Malicious Clients)(Identity-Based Identification, IBI)(TNC-IBI)

<br /><br />:
(IBI)IBITNC-IBIIBIKrumTrimmed MeanFLRMCsIBIFLFL <div>
arXiv:2504.03077v1 Announce Type: new 
Abstract: Federated Learning (FL) has recently emerged as a promising paradigm for privacy-preserving, distributed machine learning. However, FL systems face significant security threats, particularly from adaptive adversaries capable of modifying their attack strategies to evade detection. One such threat is the presence of Reconnecting Malicious Clients (RMCs), which exploit FLs open connectivity by reconnecting to the system with modified attack strategies. To address this vulnerability, we propose integration of Identity-Based Identification (IBI) as a security measure within FL environments. By leveraging IBI, we enable FL systems to authenticate clients based on cryptographic identity schemes, effectively preventing previously disconnected malicious clients from re-entering the system. Our approach is implemented using the TNC-IBI (Tan-Ng-Chin) scheme over elliptic curves to ensure computational efficiency, particularly in resource-constrained environments like Internet of Things (IoT). Experimental results demonstrate that integrating IBI with secure aggregation algorithms, such as Krum and Trimmed Mean, significantly improves FL robustness by mitigating the impact of RMCs. We further discuss the broader implications of IBI in FL security, highlighting research directions for adaptive adversary detection, reputation-based mechanisms, and the applicability of identity-based cryptographic frameworks in decentralized FL architectures. Our findings advocate for a holistic approach to FL security, emphasizing the necessity of proactive defence strategies against evolving adaptive adversarial threats.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Collective World Model for Emergent Communication and Coordination</title>
<link>https://arxiv.org/abs/2504.03353</link>
<guid>https://arxiv.org/abs/2504.03353</guid>
<content:encoded><![CDATA[
<div> 

:
 <div>
arXiv:2504.03353v1 Announce Type: new 
Abstract: We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our distributed approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimistic Learning for Communication Networks</title>
<link>https://arxiv.org/abs/2504.03499</link>
<guid>https://arxiv.org/abs/2504.03499</guid>
<content:encoded><![CDATA[
<div> : AI/ML(OpL)

:
AI/ML(OpL)OpLOpLO-RAN <div>
arXiv:2504.03499v1 Announce Type: new 
Abstract: AI/ML-based tools are at the forefront of resource management solutions for communication networks. Deep learning, in particular, is highly effective in facilitating fast and high-performing decision-making whenever representative training data is available to build offline accurate models. Conversely, online learning solutions do not require training and enable adaptive decisions based on runtime observations, alas are often overly conservative. This extensive tutorial proposes the use of optimistic learning (OpL) as a decision engine for resource management frameworks in modern communication systems. When properly designed, such solutions can achieve fast and high-performing decisions -- comparable to offline-trained models -- while preserving the robustness and performance guarantees of the respective online learning approaches. We introduce the fundamental concepts, algorithms and results of OpL, discuss the roots of this theory and present different approaches to defining and achieving optimism. We proceed to showcase how OpL can enhance resource management in communication networks for several key problems such as caching, edge computing, network slicing, and workload assignment in decentralized O-RAN platforms. Finally, we discuss the open challenges that must be addressed to unlock the full potential of this new resource management approach.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An overview of the efficiency and censorship-resistance guarantees of widely-used consensus protocols</title>
<link>https://arxiv.org/abs/2504.03588</link>
<guid>https://arxiv.org/abs/2504.03588</guid>
<content:encoded><![CDATA[
<div> censorship resistanceshort-term inclusion guaranteesdecentralized systemsconsensus protocolsconsensusless protocols

:

less <div>
arXiv:2504.03588v1 Announce Type: new 
Abstract: Censorship resistance with short-term inclusion guarantees is an important feature of decentralized systems, missing from many state-of-the-art and even deployed consensus protocols. In leader-based protocols the leader arbitrarily selects the transactions to be included in the new block, and so does a block builder in protocols such as Bitcoin and Ethereum.
  In a different line of work, since the redundancy of consensus for implementing distributed payments was formally proven, consensusless protocols have been described in theory and deployed in the real world. This has resulted in blockchains and payment systems that are more efficient, and at the same time avoid the centralized role of a leader or block builder.
  In this report we review existing consensus and consensusless protocols with regard to their censorship-resistance, efficiency, and other properties. Moreover, we present an approach for new constructions with these properties in mind, building on existing leader-based protocols.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incremental Outlier Detection Modelling Using Streaming Analytics in Finance &amp; Health Care</title>
<link>https://arxiv.org/abs/2305.09907</link>
<guid>https://arxiv.org/abs/2305.09907</guid>
<content:encoded><![CDATA[
<div> : 

:
OCSVMIForest ASDESIForest ASD <div>
arXiv:2305.09907v2 Announce Type: replace 
Abstract: In the era of real-time data, traditional methods often struggle to keep pace with the dynamic nature of streaming environments. In this paper, we proposed a hybrid framework where in (i) stage-I follows a traditional approach where the model is built once and evaluated in a real-time environment, and (ii) stage-II employs an incremental learning approach where the model is continuously retrained as new data arrives, enabling it to adapt and stay up to date. To implement these frameworks, we employed 8 distinct state-of-the-art outlier detection models, including one-class support vector machine (OCSVM), isolation forest adaptive sliding window approach (IForest ASD), exact storm (ES), angle-based outlier detection (ABOD), local outlier factor (LOF), Kitsunes online algorithm (KitNet), and K-nearest neighbour conformal density and distance based (KNN CAD). We evaluated the performance of these models across seven financial and healthcare prediction tasks, including credit card fraud detection, churn prediction, Ethereum fraud detection, heart stroke prediction, and diabetes prediction. The results indicate that our proposed incremental learning framework significantly improves performance, particularly on highly imbalanced datasets. Among all models, the IForest ASD model consistently ranked among the top three best-performing models, demonstrating superior effectiveness across various datasets.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning in Adversarial Environments: Testbed Design and Poisoning Resilience in Cybersecurity</title>
<link>https://arxiv.org/abs/2409.09794</link>
<guid>https://arxiv.org/abs/2409.09794</guid>
<content:encoded><![CDATA[
<div> : Federated Learning, , , , Raspberry Pi

:
Federated Learning, FLRaspberry PiNvidia JetsonFlowerFL <div>
arXiv:2409.09794v2 Announce Type: replace 
Abstract: This paper presents the design and implementation of a Federated Learning (FL) testbed, focusing on its application in cybersecurity and evaluating its resilience against poisoning attacks. Federated Learning allows multiple clients to collaboratively train a global model while keeping their data decentralized, addressing critical needs for data privacy and security, particularly in sensitive fields like cybersecurity. Our testbed, built using Raspberry Pi and Nvidia Jetson hardware by running the Flower framework, facilitates experimentation with various FL frameworks, assessing their performance, scalability, and ease of integration. Through a case study on federated intrusion detection systems, the testbed's capabilities are shown in detecting anomalies and securing critical infrastructure without exposing sensitive network data. Comprehensive poisoning tests, targeting both model and data integrity, evaluate the system's robustness under adversarial conditions. The results show that while federated learning enhances data privacy and distributed learning, it remains vulnerable to poisoning attacks, which must be mitigated to ensure its reliability in real-world applications.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Controlled Social Learning: Altruism vs. Bias</title>
<link>https://arxiv.org/abs/2504.02648</link>
<guid>https://arxiv.org/abs/2504.02648</guid>
<content:encoded><![CDATA[
<div> controlled sequential social learningplannerprivate information structureoptimal policiessocial welfare

:
 <div>
arXiv:2504.02648v2 Announce Type: replace 
Abstract: We introduce a model of controlled sequential social learning in which a planner may pay a cost to adjust the private information structure of agents. The planner may seek to induce correct actions that are consistent with an unknown true state of the world (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates. This sheds light on practical policy questions, such as how the socially optimal level of ad personalization changes according to current beliefs or how a political campaign may selectively illuminate or obfuscate the winning potential of its candidate among voters. We then prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from the choices they induce in the agents. Even for a planner who has equivalent knowledge to an individual, cannot lie or cherry-pick information, and is fully observable, we demonstrate that it is possible to dramatically influence social welfare in both positive and negative directions.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Epistemic Closure and the Irreversibility of Misalignment: Modeling Systemic Barriers to Alignment Innovation</title>
<link>https://arxiv.org/abs/2504.02058</link>
<guid>https://arxiv.org/abs/2504.02058</guid>
<content:encoded><![CDATA[
<div> : 

:
AGIAIDCIDCIAGIDCI <div>
arXiv:2504.02058v1 Announce Type: new 
Abstract: Efforts to ensure the safe development of artificial general intelligence (AGI) often rely on consensus-based alignment approaches grounded in axiomatic formalism, interpretability, and empirical validation. However, these methods may be structurally unable to recognize or incorporate novel solutions that fall outside their accepted epistemic frameworks. This paper introduces a functional model of epistemic closure, in which cognitive, institutional, social, and infrastructural filters combine to make many alignment proposals illegible to existing evaluation systems. We present a weighted closure model supported by both theoretical and empirical sources, including a meta-analysis performed by an AI system on patterns of rejection and non-engagement with a framework for decentralized collective intelligence (DCI). We argue that the recursive failure to assess models like DCI is not just a sociological oversight but a structural attractor, mirroring the very risks of misalignment we aim to avoid in AGI. Without the adoption of DCI or a similarly recursive model of epistemic correction, we may be on a predictable path toward irreversible misalignment. The development and acceptance of this paper, first through simulated review and then through formal channels, provide a case study supporting its central claim: that epistemic closure can only be overcome by recursive modeling of the constraints that sustain it.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Achieving Unanimous Consensus in Decision Making Using Multi-Agents</title>
<link>https://arxiv.org/abs/2504.02128</link>
<guid>https://arxiv.org/abs/2504.02128</guid>
<content:encoded><![CDATA[
<div> : Proof-of-Work (PoW)Proof-of-Stake (PoS)LLMsdeliberation-based

:<br />
LLMsPoWPoS <div>
arXiv:2504.02128v1 Announce Type: new 
Abstract: Blockchain consensus mechanisms have relied on algorithms such as Proof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality and integrity. However, these approaches struggle with adaptability for decision-making where the opinions of each matter rather than reaching an agreement based on honest majority or weighted consensus. This paper introduces a novel deliberation-based consensus mechanism where Large Language Models (LLMs) act as rational agents engaging in structured discussions to reach a unanimous consensus. By leveraging graded consensus and a multi-round deliberation process, our approach ensures both unanimous consensus for definitive problems and graded confidence for prioritized decisions and policies. We provide a formalization of our system and use it to show that the properties of blockchains: consistency, agreement, liveness, and determinism are maintained. Moreover, experimental results demonstrate our system's feasibility, showcasing how our deliberation method's convergence, block properties, and accuracy enable decision-making on blockchain networks. We also address key challenges with this novel approach such as degeneration of thoughts, hallucinations, malicious models and nodes, resource consumption, and scalability.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Base Station Certificate and Multi-Factor Authentication for Cellular Radio Control Communication Security</title>
<link>https://arxiv.org/abs/2504.02133</link>
<guid>https://arxiv.org/abs/2504.02133</guid>
<content:encoded><![CDATA[
<div> base station authenticationmulti-factor authenticationblockchaindigital certificate5G

:
<br />
X.5095GRRCECDSA <div>
arXiv:2504.02133v1 Announce Type: new 
Abstract: Current cellular networking remains vulnerable to malicious fake base stations due to the lack of base station authentication mechanism or even a key to enable authentication. We design and build a base station certificate (certifying the base station's public key and location) and a multi-factor authentication (making use of the certificate and the information transmitted in the online radio control communications) to secure the authenticity and message integrity of the base station control communications. We advance beyond the state-of-the-art research by introducing greater authentication factors (and analyzing their individual security properties and benefits), and by using blockchain to deliver the base station digital certificate offline (enabling greater key length or security strength and computational or networking efficiency). We design the certificate construction, delivery, and the multi-factor authentication use on the user equipment. The user verification involves multiple factors verified through the ledger database, the location sensing (GPS in our implementation), and the cryptographic signature verification of the cellular control communication (SIB1 broadcasting). We analyze our scheme's security, performance, and the fit to the existing standardized networking protocols. Our work involves the implementation of building on X.509 certificate (adapted), smart contract-based blockchain, 5G-standardized RRC control communications, and software-defined radios. Our analyses show that our scheme effectively defends against more security threats and can enable stronger security, i.e., ECDSA with greater key lengths. Furthermore, our scheme enables computing and energy to be more than three times efficient than the previous research on the mobile user equipment.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FairDAG: Consensus Fairness over Concurrent Causal Design</title>
<link>https://arxiv.org/abs/2504.02194</link>
<guid>https://arxiv.org/abs/2504.02194</guid>
<content:encoded><![CDATA[
<div> : FairDAG

:
PompeThemisDAGFairDAG-ABFairDAG-RLFairDAGCloudLab <div>
arXiv:2504.02194v1 Announce Type: new 
Abstract: The rise of cryptocurrencies like Bitcoin and Ethereum has driven interest in blockchain technology, with Ethereum's smart contracts enabling the growth of decentralized finance (DeFi). However, research has shown that adversaries exploit transaction ordering to extract profits through attacks like front-running, sandwich attacks, and liquidation manipulation. This issue affects both permissionless and permissioned blockchains, as block proposers have full control over transaction ordering. To address this, a more fair approach to transaction ordering is essential.
  Existing fairness protocols, such as Pompe and Themis, operate on leader-based consensus protocols, which not only suffer from low throughput but also allow adversaries to manipulate transaction ordering. To address these limitations, we propose FairDAG-AB and FairDAG-RL, which leverage DAG-based consensus protocols.
  We theoretically demonstrate that FairDAG protocols not only uphold fairness guarantees, as previous fairness protocols do, but also achieve higher throughput and greater resilience to adversarial ordering manipulation. Our deployment and evaluation on CloudLab further validate these claims.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Generalization through Stochastic Bidirectional Parameter Updates Using Dual-Gradient Mechanism</title>
<link>https://arxiv.org/abs/2504.02213</link>
<guid>https://arxiv.org/abs/2504.02213</guid>
<content:encoded><![CDATA[
<div> : , , , , 

:
 <div>
arXiv:2504.02213v1 Announce Type: new 
Abstract: Federated learning (FL) has gained increasing attention due to privacy-preserving collaborative training on decentralized clients, mitigating the need to upload sensitive data to a central server directly. Nonetheless, recent research has underscored the risk of exposing private data to adversaries, even within FL frameworks. In general, existing methods sacrifice performance while ensuring resistance to privacy leakage in FL. We overcome these issues and generate diverse models at a global server through the proposed stochastic bidirectional parameter update mechanism. Using diverse models, we improved the generalization and feature representation in the FL setup, which also helped to improve the robustness of the model against privacy leakage without hurting the model's utility. We use global models from past FL rounds to follow systematic perturbation in parameter space at the server to ensure model generalization and resistance against privacy attacks. We generate diverse models (in close neighborhoods) for each client by using systematic perturbations in model parameters at a fine-grained level (i.e., altering each convolutional filter across the layers of the model) to improve the generalization and security perspective. We evaluated our proposed approach on four benchmark datasets to validate its superiority. We surpassed the state-of-the-art methods in terms of model utility and robustness towards privacy leakage. We have proven the effectiveness of our method by evaluating performance using several quantitative and qualitative results.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Temporal Graph Learning with Provenance for APT Detection in Supply Chains</title>
<link>https://arxiv.org/abs/2504.02313</link>
<guid>https://arxiv.org/abs/2504.02313</guid>
<content:encoded><![CDATA[
<div> : Cyber supply chain, Advanced persistent threats (APTs), Supply chain vulnerabilities (SCVs), Temporal graph learning, Multi-source monitoring

<br /><br />:
(ICT)APT <div>
arXiv:2504.02313v1 Announce Type: new 
Abstract: Cyber supply chain, encompassing digital asserts, software, hardware, has become an essential component of modern Information and Communications Technology (ICT) provisioning. However, the growing inter-dependencies have introduced numerous attack vectors, making supply chains a prime target for exploitation. In particular, advanced persistent threats (APTs) frequently leverage supply chain vulnerabilities (SCVs) as entry points, benefiting from their inherent stealth. Current defense strategies primarly focus on prevention through blockchain for integrity assurance or detection using plain-text source code analysis in open-source software (OSS). However, these approaches overlook scenarios where source code is unavailable and fail to address detection and defense during runtime. To bridge this gap, we propose a novel approach that integrates multi-source data, constructs a comprehensive dynamic provenance graph, and detects APT behavior in real time using temporal graph learning. Given the lack of tailored datasets in both industry and academia, we also aim to simulate a custom dataset by replaying real-world supply chain exploits with multi-source monitoring.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Learning-Augmented Peer-to-Peer Networks: Self-Stabilizing Graph Linearization with Untrusted Advice</title>
<link>https://arxiv.org/abs/2504.02448</link>
<guid>https://arxiv.org/abs/2504.02448</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
$O(\log n)$$\Omega(\log n)$$n$ <div>
arXiv:2504.02448v1 Announce Type: new 
Abstract: Distributed peer-to-peer systems are widely popular due to their decentralized nature, which ensures that no peer is critical for the functionality of the system. However, fully decentralized solutions are usually much harder to design, and tend to have a much higher overhead compared to centralized approaches, where the peers are connected to a powerful server. On the other hand, centralized approaches have a single point of failure. Thus, is there some way to combine their advantages without inheriting their disadvantages? To that end, we consider a supervised peer-to-peer approach where the peers can ask a potentially unreliable supervisor for advice. This is in line with the increasingly popular algorithmic paradigm called algorithms with predictions or learning-augmented algorithms, but we are the first to consider it in the context of peer-to-peer networks.
  Specifically, we design self-stabilizing algorithms for the fundamental problem of distributed graph linearization, where peers are supposed to recover the "sorted line" network from any initial network after a transient fault. With the help of the supervisor, peers can recover the sorted line network in $O(\log n)$ time, if the advice is correct; otherwise, the algorithm retains its original recovery time (i.e., without any supervisor). A crucial challenge that we overcome is to correctly compose multiple self-stabilizing algorithms, that is, one that processes and exploits the advice, and another that does not rely on the advice at all. Our key technical contributions combine ideas from the fields of overlay networks and proof-labeling schemes. Finally, we give a matching lower bound of $\Omega(\log n)$ for the recovery time of any algorithm if the advice can be corrupted, where $n$ is the network size.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent Shepherding Control of Non-Cohesive Targets</title>
<link>https://arxiv.org/abs/2504.02479</link>
<guid>https://arxiv.org/abs/2504.02479</guid>
<content:encoded><![CDATA[
<div> : 

:<br />
Deep Q-Network <div>
arXiv:2504.02479v1 Announce Type: new 
Abstract: We propose a decentralized reinforcement learning solution for multi-agent shepherding of non-cohesive targets using policy-gradient methods. Our architecture integrates target-selection with target-driving through Proximal Policy Optimization, overcoming discrete-action constraints of previous Deep Q-Network approaches and enabling smoother agent trajectories. This model-free framework effectively solves the shepherding problem without prior dynamics knowledge. Experiments demonstrate our method's effectiveness and scalability with increased target numbers and limited sensing capabilities.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ethics of Blockchain Technologies</title>
<link>https://arxiv.org/abs/2504.02504</link>
<guid>https://arxiv.org/abs/2504.02504</guid>
<content:encoded><![CDATA[
<div> 

<br />
:
 <div>
arXiv:2504.02504v1 Announce Type: new 
Abstract: This chapter explores three key questions in blockchain ethics. First, it situates blockchain ethics within the broader field of technology ethics, outlining its goals and guiding principles. Second, it examines the unique ethical challenges of blockchain applications, including permissionless systems, incentive mechanisms, and privacy concerns. Key obstacles, such as conceptual modeling and information asymmetries, are identified as critical issues. Finally, the chapter argues that blockchain ethics should be approached as an engineering discipline, emphasizing the analysis and design of trade-offs in complex systems.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain and Distributed Ledger Technologies for Cyberthreat Intelligence Sharing</title>
<link>https://arxiv.org/abs/2504.02537</link>
<guid>https://arxiv.org/abs/2504.02537</guid>
<content:encoded><![CDATA[
<div> cyberthreat

<br /><br />:
DLTDLTDLTDLT <div>
arXiv:2504.02537v1 Announce Type: new 
Abstract: Cyberthreat intelligence sharing is a critical aspect of cybersecurity, and it is essential to understand its definition, objectives, benefits, and impact on society. Blockchain and Distributed Ledger Technology (DLT) are emerging technologies that have the potential to transform intelligence sharing. This paper aims to provide a comprehensive understanding of intelligence sharing and the role of blockchain and DLT in enhancing it. The paper addresses questions related to the definition, objectives, benefits, and impact of intelligence sharing and provides a review of the existing literature. Additionally, the paper explores the challenges associated with blockchain and DLT and their potential impact on security and privacy. The paper also discusses the use of DLT and blockchain in security and intelligence sharing and highlights the associated challenges and risks. Furthermore, the paper examines the potential impact of a National Cybersecurity Strategy on addressing cybersecurity risks. Finally, the paper explores the experimental set up required for implementing blockchain and DLT for intelligence sharing and discusses the curricular ramifications of intelligence sharing.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EvoChain: A Framework for Tracking and Visualizing Smart Contract Evolution</title>
<link>https://arxiv.org/abs/2504.02704</link>
<guid>https://arxiv.org/abs/2504.02704</guid>
<content:encoded><![CDATA[
<div> : EvoChain

:

EvoChainNeo4jEvoChainAPI1301.5 <div>
arXiv:2504.02704v1 Announce Type: new 
Abstract: Tracking the evolution of smart contracts is challenging due to their immutable nature and complex upgrade mechanisms. We introduce EvoChain, a comprehensive framework and dataset designed to track and visualize smart contract evolution. Building upon data from our previous empirical study, EvoChain models contract relationships using a Neo4j graph database and provides an interactive web interface for exploration. The framework consists of a data layer, an API layer, and a user interface layer. EvoChain allows stakeholders to analyze contract histories, upgrade paths, and associated vulnerabilities by leveraging these components. Our dataset encompasses approximately 1.3 million upgradeable proxies and nearly 15,000 historical versions, enhancing transparency and trust in blockchain ecosystems by providing an accessible platform for understanding smart contract evolution.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Web3DB: Web 3.0 RDBMS for Individual Data Ownership</title>
<link>https://arxiv.org/abs/2504.02713</link>
<guid>https://arxiv.org/abs/2504.02713</guid>
<content:encoded><![CDATA[
<div> Web3DB

<br />
:
Web3DBWeb 3.0RDBMSDBMSWeb3DBRDBMSWeb3DBWeb3DBSQLWeb 3.0 <div>
arXiv:2504.02713v1 Announce Type: new 
Abstract: This paper introduces Web3DB, a decentralized relational database management system (RDBMS) designed to align with the principles of Web 3.0, addressing critical shortcomings of traditional centralized DBMS, such as data privacy, security vulnerabilities, and single points of failure. Several similar systems have been proposed, but they are not compatible with the legacy systems based on RDBMS. Motivated by the necessity for enhanced data sovereignty and the decentralization of data control, Web3DB leverages blockchain technology for fine-grained access control and utilizes decentralized data storage. This system leverages a novel, modular architecture that contributes to enhanced flexibility, scalability, and user-centric functionality. Central to the Web3DB innovation is its decentralized query execution, which uses cryptographic sortition and blockchain verification to ensure secure and fair query processing across network nodes. The motivation for integrating relational databases within decentralized DBMS primarily stems from the need to combine the robustness and ease of use of relational database structures with the benefits of decentralization. This paper outlines the architecture of Web3DB, its practical implementation, and the system's ability to support SQL-like operations on relational data, manage multi-tenancy, and facilitate open data sharing, setting new standards for decentralized databases in the Web 3.0 era.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Myth of Immutability: A Multivocal Review on Smart Contract Upgradeability</title>
<link>https://arxiv.org/abs/2504.02719</link>
<guid>https://arxiv.org/abs/2504.02719</guid>
<content:encoded><![CDATA[
<div> : 

:
 <div>
arXiv:2504.02719v1 Announce Type: new 
Abstract: The immutability of smart contracts on blockchain platforms like Ethereum promotes security and trustworthiness but presents challenges for updates, bug fixes, or adding new features post-deployment. These limitations can lead to vulnerabilities and outdated functionality, impeding the evolution and maintenance of decentralized applications. Despite various upgrade mechanisms proposed in academic research and industry, a comprehensive analysis of their trade-offs and practical implications is lacking. This study aims to systematically identify, classify, and evaluate existing smart contract upgrade mechanisms, bridging the gap between theoretical concepts and practical implementations. It introduces standardized terminology and evaluates the trade-offs of different approaches using software quality attributes. We conducted a Multivocal Literature Review (MLR) to analyze upgrade mechanisms from both academic research and industry practice. We first establish a unified definition of smart contract upgradeability and identify core components essential for understanding the upgrade process. Based on this definition, we classify existing methods into full upgrade and partial upgrade approaches, introducing standardized terminology to harmonize the diverse terms used in the literature. We then characterize each approach and assess its benefits and limitations using software quality attributes such as complexity, flexibility, security, and usability. The analysis highlights significant trade-offs among upgrade mechanisms, providing valuable insights into the benefits and limitations of each approach. These findings guide developers and researchers in selecting mechanisms tailored to specific project requirements.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-Aware Multi-Agent Learning for Dynamic Network Bridging</title>
<link>https://arxiv.org/abs/2404.01551</link>
<guid>https://arxiv.org/abs/2404.01551</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
 <div>
arXiv:2404.01551v2 Announce Type: replace 
Abstract: Addressing complex cooperative tasks in safety-critical environments poses significant challenges for multi-agent systems, especially under conditions of partial observability. We focus on a dynamic network bridging task, where agents must learn to maintain a communication path between two moving targets. To ensure safety during training and deployment, we integrate a control-theoretic safety filter that enforces collision avoidance through local setpoint updates. We develop and evaluate multi-agent reinforcement learning safety-informed message passing, showing that encoding safety filter activations as edge-level features improves coordination. The results suggest that local safety enforcement and decentralized learning can be effectively combined in distributed multi-agent tasks.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sustainable broadcasting in Blockchain Networks with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2407.15616</link>
<guid>https://arxiv.org/abs/2407.15616</guid>
<content:encoded><![CDATA[
<div> : 

:
64002600RLRL <div>
arXiv:2407.15616v2 Announce Type: replace 
Abstract: Recent estimates put the carbon footprint of Bitcoin and Ethereum at an average of 64 and 26 million tonnes of CO2 per year, respectively. To address this growing problem, several possible approaches have been proposed in the literature: creating alternative blockchain consensus mechanisms, applying redundancy reduction techniques, utilizing renewable energy sources, and employing energy-efficient devices, etc. In this paper, we follow the second avenue and propose an efficient approach based on reinforcement learning that improves the block broadcasting scheme in blockchain networks. The analysis and experimental results confirmed that the proposed improvement of the block propagation scheme could cleverly handle network dynamics and achieve better results than the default approach. Additionally, our technical integration of the simulator and developed RL environment can be used as a complete solution for further study of new schemes and protocols that use RL or other ML techniques.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMSE: Semi-supervised federated learning approach for IoT network intrusion detection</title>
<link>https://arxiv.org/abs/2410.14121</link>
<guid>https://arxiv.org/abs/2410.14121</guid>
<content:encoded><![CDATA[
<div> : (IoT)(federated learning)(semi-supervised learning)(intrusion detection)(aggregate algorithm)

<br /><br />:
Shrink AutoencoderCentroid one-class classifierSAE-CENMSEAvgN-BaIoTDirichlet93.98$\pm$2.9097.30$\pm$0.4950% <div>
arXiv:2410.14121v2 Announce Type: replace 
Abstract: This paper proposes a novel federated learning approach for improving IoT network intrusion detection. The rise of IoT has expanded the cyber attack surface, making traditional centralized machine learning methods insufficient due to concerns about data availability, computational resources, transfer costs, and especially privacy preservation. A semi-supervised federated learning model was developed to overcome these issues, combining the Shrink Autoencoder and Centroid one-class classifier (SAE-CEN). This approach enhances the performance of intrusion detection by effectively representing normal network data and accurately identifying anomalies in the decentralized strategy. Additionally, a mean square error-based aggregation algorithm (MSEAvg) was introduced to improve global model performance by prioritizing more accurate local models. The results obtained in our experimental setup, which uses various settings relying on the N-BaIoT dataset and Dirichlet distribution, demonstrate significant improvements in real-world heterogeneous IoT networks in detection accuracy from 93.98$\pm$2.90 to 97.30$\pm$0.49, reduced learning costs when requiring only 50\% of gateways participating in the training process, and robustness in large-scale networks.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Resilient Federated Learning in CyberEdge Networks: Recent Advances and Future Trends</title>
<link>https://arxiv.org/abs/2504.01240</link>
<guid>https://arxiv.org/abs/2504.01240</guid>
<content:encoded><![CDATA[
<div> : resilient federated learning (ResFL), CyberEdge, adaptive hierarchical learning, feature-oriented security, fault tolerance

:
CyberEdgeResFLFLFL6GLLMsResFLAIResFLCyberEdge <div>
arXiv:2504.01240v1 Announce Type: new 
Abstract: In this survey, we investigate the most recent techniques of resilient federated learning (ResFL) in CyberEdge networks, focusing on joint training with agglomerative deduction and feature-oriented security mechanisms. We explore adaptive hierarchical learning strategies to tackle non-IID data challenges, improving scalability and reducing communication overhead. Fault tolerance techniques and agglomerative deduction mechanisms are studied to detect unreliable devices, refine model updates, and enhance convergence stability. Unlike existing FL security research, we comprehensively analyze feature-oriented threats, such as poisoning, inference, and reconstruction attacks that exploit model features. Moreover, we examine resilient aggregation techniques, anomaly detection, and cryptographic defenses, including differential privacy and secure multi-party computation, to strengthen FL security. In addition, we discuss the integration of 6G, large language models (LLMs), and interoperable learning frameworks to enhance privacy-preserving and decentralized cross-domain training. These advancements offer ultra-low latency, artificial intelligence (AI)-driven network management, and improved resilience against adversarial attacks, fostering the deployment of secure ResFL in CyberEdge networks.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IRS Assisted Decentralized Learning for Wideband Spectrum Sensing</title>
<link>https://arxiv.org/abs/2504.01344</link>
<guid>https://arxiv.org/abs/2504.01344</guid>
<content:encoded><![CDATA[
<div> IRS

<br /><br />

IRSIRSSNR <div>
arXiv:2504.01344v1 Announce Type: new 
Abstract: The increasing demand for reliable connectivity in industrial environments necessitates effective spectrum utilization strategies, especially in the context of shared spectrum bands.
  However, the dynamic spectrum-sharing mechanisms often lead to significant interference and critical failures, creating a trade-off between spectrum scarcity and under-utilization.
  This paper addresses these challenges by proposing a novel Intelligent Reflecting Surface (IRS)-assisted spectrum sensing framework integrated with decentralized deep learning.
  The proposed model overcomes partial observation constraints and minimizes communication overhead while leveraging IRS technology to enhance spectrum sensing accuracy.
  Through comprehensive simulations, the framework demonstrates its ability to monitor wideband spectrum occupancy effectively, even under challenging signal-to-noise ratio (SNR) conditions.
  This approach offers a scalable and robust solution for spectrum management in next-generation wireless networks.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Accelerating Blockchain Scalability: New Models for Parallel Transaction Execution in the EVM</title>
<link>https://arxiv.org/abs/2504.01370</link>
<guid>https://arxiv.org/abs/2504.01370</guid>
<content:encoded><![CDATA[
<div> : Ethereum

:
gas <div>
arXiv:2504.01370v1 Announce Type: new 
Abstract: As the number of decentralized applications and users on Ethereum grows, the ability of the blockchain to efficiently handle a growing number of transactions becomes increasingly strained. Ethereums current execution model relies heavily on sequential processing, meaning that operations are processed one after the other, which creates significant bottlenecks to future scalability demands. While scalability solutions for Ethereum exist, they inherit the limitations of the EVM, restricting the extent to which they can scale. This paper proposes a novel solution to enable maximally parallelizable executions within Ethereum, built out of three self-sufficient approaches. These approaches include strategies in which Ethereum transaction state accesses could be strategically and efficiently predetermined, and further propose how the incorporation of gas based incentivization mechanisms could enforce a maximally parallelizable network.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>K2: On Optimizing Distributed Transactions in a Multi-region Data Store with TrueTime Clocks (Extended Version)</title>
<link>https://arxiv.org/abs/2504.01460</link>
<guid>https://arxiv.org/abs/2504.01460</guid>
<content:encoded><![CDATA[
<div> TrueTime(TTC)K2Google Spanner

:
K2TrueTime(TTC)Google SpannerK2TTC<br />
1. K2
2. K2
3. K2TTC

K2 <div>
arXiv:2504.01460v1 Announce Type: new 
Abstract: TrueTime clocks (TTCs) that offer accurate and reliable time within limited uncertainty bounds have been increasingly implemented in many clouds. Multi-region data stores that seek decentralized synchronization for high performance represent an ideal application of TTC. However, the co-designs between the two were often undervalued or failed to realize their full potential.
  This paper proposes K2, a multi-region data store that intensely explores the opportunity of using TTC for distributed transactions. Compared to its pioneer, Google Spanner, K2 augments TTC's semantics in three core design pillars. First, K2 carries a new timestamp-generating scheme that is capable of providing a small time uncertainty bound at scale. Second, K2 revitalizes existing multi-version timestamp-ordered concurrency control to realize multi-version properties for read-write transactions. Third, K2 introduces a new TTC-based visibility control protocol that provides efficient reads at replicas. Our evaluation shows that, K2 achieves an order of magnitude higher transaction throughput relative to other practical geo-distributed transaction protocols while ensuring a lower visibility delay at asynchronous replicas.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Approximate Agreement Algorithms for Byzantine Collaborative Learning</title>
<link>https://arxiv.org/abs/2504.01504</link>
<guid>https://arxiv.org/abs/2504.01504</guid>
<content:encoded><![CDATA[
<div> : Byzantine 

<br /><br />:

$n$() <div>
arXiv:2504.01504v1 Announce Type: new 
Abstract: In Byzantine collaborative learning, $n$ clients in a peer-to-peer network collectively learn a model without sharing their data by exchanging and aggregating stochastic gradient estimates. Byzantine clients can prevent others from collecting identical sets of gradient estimates. The aggregation step thus needs to be combined with an efficient (approximate) agreement subroutine to ensure convergence of the training process.
  In this work, we study the geometric median aggregation rule for Byzantine collaborative learning. We show that known approaches do not provide theoretical guarantees on convergence or gradient quality in the agreement subroutine. To satisfy these theoretical guarantees, we present a hyperbox algorithm for geometric median aggregation.
  We practically evaluate our algorithm in both centralized and decentralized settings under Byzantine attacks on non-i.i.d. data. We show that our geometric median-based approaches can tolerate sign-flip attacks better than known mean-based approaches from the literature.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sky of Unlearning (SoUL): Rewiring Federated Machine Unlearning via Selective Pruning</title>
<link>https://arxiv.org/abs/2504.01705</link>
<guid>https://arxiv.org/abs/2504.01705</guid>
<content:encoded><![CDATA[
<div> : (IoD), (FL), (FU), sky of unlearning (SoUL), 

<br /><br />:
sky of unlearning (SoUL)(IoD)(FL)SoULSoULIoDSoUL <div>
arXiv:2504.01705v1 Announce Type: new 
Abstract: The Internet of Drones (IoD), where drones collaborate in data collection and analysis, has become essential for applications such as surveillance and environmental monitoring. Federated learning (FL) enables drones to train machine learning models in a decentralized manner while preserving data privacy. However, FL in IoD networks is susceptible to attacks like data poisoning and model inversion. Federated unlearning (FU) mitigates these risks by eliminating adversarial data contributions, preventing their influence on the model. This paper proposes sky of unlearning (SoUL), a federated unlearning framework that efficiently removes the influence of unlearned data while maintaining model performance. A selective pruning algorithm is designed to identify and remove neurons influential in unlearning but minimally impact the overall performance of the model. Simulations demonstrate that SoUL outperforms existing unlearning methods, achieves accuracy comparable to full retraining, and reduces computation and communication overhead, making it a scalable and efficient solution for resource-constrained IoD networks.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Track and Trace: Automatically Uncovering Cross-chain Transactions in the Multi-blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2504.01822</link>
<guid>https://arxiv.org/abs/2504.01822</guid>
<content:encoded><![CDATA[
<div> ABCTRACER

<br />
:
(DeFi)ABCTRACER(CeFi)ABCTRACERABCTRACER12F191.75%ABCTRACERDeFi <div>
arXiv:2504.01822v1 Announce Type: new 
Abstract: Cross-chain technology enables seamless asset transfer and message-passing within decentralized finance (DeFi) ecosystems, facilitating multi-chain coexistence in the current blockchain environment. However, this development also raises security concerns, as malicious actors exploit cross-chain asset flows to conceal the provenance and destination of assets, thereby facilitating illegal activities such as money laundering. Consequently, the need for cross-chain transaction traceability has become increasingly urgent. Prior research on transaction traceability has predominantly focused on single-chain and centralized finance (CeFi) cross-chain scenarios, overlooking DeFispecific considerations. This paper proposes ABCTRACER, an automated, bi-directional cross-chain transaction tracing tool, specifically designed for DeFi ecosystems. By harnessing transaction event log mining and named entity recognition techniques, ABCTRACER automatically extracts explicit cross-chain cues. These cues are then combined with information retrieval techniques to encode implicit cues. ABCTRACER facilitates the autonomous learning of latent associated information and achieves bidirectional, generalized cross-chain transaction tracing. Our experiments on 12 mainstream cross-chain bridges demonstrate that ABCTRACER attains 91.75% bi-directional traceability (F1 metrics) with self-adaptive capability. Furthermore, we apply ABCTRACER to real-world cross-chain attack transactions and money laundering traceability, thereby bolstering the traceability and blockchain ecological security of DeFi bridging applications.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Matching, Unanticipated Experiences, Divorce, Flirting, Rematching, Etc</title>
<link>https://arxiv.org/abs/2504.01280</link>
<guid>https://arxiv.org/abs/2504.01280</guid>
<content:encoded><![CDATA[
<div> <br /><br />:
\(1-\varepsilon\)\varepsilon/ <div>
arXiv:2504.01280v1 Announce Type: cross 
Abstract: We study dynamic decentralized two-sided matching in which players may encounter unanticipated experiences. As they become aware of these experiences, they may change their preferences over players on the other side of the market. Consequently, they may get ``divorced'' and rematch again with other agents, which may lead to further unanticipated experiences etc. A matching is stable if there is absence of pairwise common belief in blocking. Stable matchings can be destabilized by unanticipated experiences. Yet, we show that there exist self-confirming outcomes that are stable and do not lead to further unanticipated experiences. We introduce a natural decentralized matching process that, at each period assigns probability $1 - \varepsilon$ to the satisfaction of a mutual optimal blocking pair (if it exists) and picks any optimal blocking pair otherwise. The parameter $\varepsilon$ is interpreted as a friction of the matching market. We show that for any decentralized matching process, frictions are necessary for convergence to stability even without unawareness. Our process converges to self-confirming stable outcomes. Further, we allow for bilateral communication/flirting that changes the awareness and say that a matching is flirt-proof stable if there is absence of communication leading to pairwise common belief in blocking. We show that our natural decentralized matching process converges to flirt-proof self-confirming outcomes.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts</title>
<link>https://arxiv.org/abs/2401.07261</link>
<guid>https://arxiv.org/abs/2401.07261</guid>
<content:encoded><![CDATA[
<div> Decentralized Finance (DeFi)smart contract vulnerabilitiesattack detectionadversarial contractsLookAhead

:
DeFi30DeFiMLtransformerLookAheadLook AheadF10.8966Forta44.4%0.16% <div>
arXiv:2401.07261v5 Announce Type: replace 
Abstract: Decentralized Finance (DeFi) incidents stemming from the exploitation of smart contract vulnerabilities have culminated in financial damages exceeding 3 billion US dollars. Existing defense mechanisms typically focus on detecting and reacting to malicious transactions executed by attackers that target victim contracts. However, with the emergence of private transaction pools where transactions are sent directly to miners without first appearing in public mempools, current detection tools face significant challenges in identifying attack activities effectively. Based on the fact that most attack logic rely on deploying one or more intermediate smart contracts as supporting components to the exploitation of victim contracts, detection methods have been proposed that focus on identifying these adversarial contracts instead of adversarial transactions. However, previous state-of-the-art approaches in this direction have failed to produce results satisfactory enough for real-world deployment. In this paper, we propose a new framework for effectively detecting DeFi attacks via unveiling adversarial contracts. Our approach allows us to leverage common attack patterns, code semantics and intrinsic characteristics found in malicious smart contracts to build the LookAhead system based on Machine Learning (ML) classifiers and a transformer model that is able to effectively distinguish adversarial contracts from benign ones, and make timely predictions of different types of potential attacks. Experiments show that LookAhead achieves an F1-score as high as 0.8966, which represents an improvement of over 44.4% compared to the previous state-of-the-art solution Forta, with a False Positive Rate (FPR) at only 0.16%.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Blockchain and Opportunistic Edge Driven Metaverse of Everything</title>
<link>https://arxiv.org/abs/2410.20594</link>
<guid>https://arxiv.org/abs/2410.20594</guid>
<content:encoded><![CDATA[
<div> Decentralized Metaverses, Web 3.0/4.0, Metaverse of Everything (MoE), Internet of Everything (IoE), Opportunistic Edge Computing (OEC)

<br /><br />:
Web 3.0Web 4.0Decentralized MetaversesInternet of Everything, IoEMetaverse of Everything, MoEOpportunistic Edge Computing, OECIoEMoE <div>
arXiv:2410.20594v2 Announce Type: replace 
Abstract: Decentralized Metaverses, built on Web 3.0 and Web 4.0 technologies, have attracted significant attention across various fields. This innovation leverages blockchain, Decentralized Autonomous Organizations (DAOs), Extended Reality (XR) and advanced technologies to create immersive and interconnected digital environments that mirror the real world. This article delves into the Metaverse of Everything (MoE), a platform that fuses the Metaverse concept with the Internet of Everything (IoE), an advanced version of the Internet of Things (IoT) that connects not only physical devices but also people, data and processes within a networked environment. Thus, the MoE integrates generated data and virtual entities, creating an extensive network of interconnected components. This article seeks to advance current MoE, examining decentralization and the application of Opportunistic Edge Computing (OEC) for interactions with surrounding IoT devices and IoE entities. Moreover, it outlines the main challenges to guide researchers and businesses towards building a future cyber-resilient opportunistic MoE.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-LLM Text Summarization</title>
<link>https://arxiv.org/abs/2412.15487</link>
<guid>https://arxiv.org/abs/2412.15487</guid>
<content:encoded><![CDATA[
<div> : LLM

:
LLMLarge Language ModelLLMLLMkLLMLLMLLMkLLMLLMLLM3LLM <div>
arXiv:2412.15487v2 Announce Type: replace 
Abstract: In this work, we propose a Multi-LLM summarization framework, and investigate two different multi-LLM strategies including centralized and decentralized. Our multi-LLM summarization framework has two fundamentally important steps at each round of conversation: generation and evaluation. These steps are different depending on whether our multi-LLM decentralized summarization is used or centralized. In both our multi-LLM decentralized and centralized strategies, we have k different LLMs that generate diverse summaries of the text. However, during evaluation, our multi-LLM centralized summarization approach leverages a single LLM to evaluate the summaries and select the best one whereas k LLMs are used for decentralized multi-LLM summarization. Overall, we find that our multi-LLM summarization approaches significantly outperform the baselines that leverage only a single LLM by up to 3x. These results indicate the effectiveness of multi-LLM approaches for summarization.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resolving the Exploration-Exploitation Dilemma in Evolutionary Algorithms: A Novel Human-Centered Framework</title>
<link>https://arxiv.org/abs/2501.02153</link>
<guid>https://arxiv.org/abs/2501.02153</guid>
<content:encoded><![CDATA[
<div> : Evolutionary Algorithms, Exploration-Exploitation Dilemma, Human-Centered Two-Phase Search (HCTPS), Search Space Control Parameter (SSCP), Genetic Algorithm

:
Evolutionary Algorithms-Human-Centered Two-Phase Search, HCTPSSearch Space Control Parameter, SSCP-SSCPHCTPSEAHCTPS- <div>
arXiv:2501.02153v2 Announce Type: replace 
Abstract: Evolutionary Algorithms (EAs) are widely employed tools for complex search and optimization tasks; however, the absence of an overarching operational framework that permits a systematic regulation of the exploration-exploitation tradeoff--critical for efficient convergence--restricts the full actualization of their potential, leading to the so-called exploration-exploitation dilemma in algorithm design. A systematic resolution to this dilemma requires: (1) an independent yet coordinated control over exploration and exploitation, and (2) an explicit, computationally feasible, adaptive regulation mechanism. The current, almost decentralized, traditional parameter tuning-centeric approach--lacks the foundation to satisfy these requirements under encoding-imposed structural constraints.
  We propose a Human-Centered Two-Phase Search (HCTPS) framework, in which the actualization of (1) and (2) is enabled through an external configuration variable--the Search Space Control Parameter (SSCP). As the sole control knob of HCTPS, the SSCP centralizes exploration adjustments, sparing users from micromanaging traditional parameters with unintelligible interdependencies. To this construct, the human user serves as a meta-parameter, adaptively steering the regulatory process via SSCP adjustments. We prove that the HCTPS strictly surpasses the current approach in terms of search space coverage without disrupting the EAs' inherent convergence mechanisms, demonstrate a concrete instantiation of it--using the Genetic Algorithm as the underlying heuristic on a suite of global benchmark unconstrained optimization problems, provide a through assessment of the proposed framework, and envision future research directions.
  Any search algorithm prone to this dilemma can be applied in light of the proposed framework, being algorithm-agnostic by design.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Navigating Decentralized Online Social Networks: An Overview of Technical and Societal Challenges in Architectural Choices</title>
<link>https://arxiv.org/abs/2504.00071</link>
<guid>https://arxiv.org/abs/2504.00071</guid>
<content:encoded><![CDATA[
<div> MastodonBlueskyHiveNostr<br /><br />:<br />
MastodonBlueskyHiveNostrTwitter <div>
arXiv:2504.00071v1 Announce Type: new 
Abstract: Decentralized online social networks have evolved from experimental stages to operating at unprecedented scale, with broader adoption and more active use than ever before. Platforms like Mastodon, Bluesky, Hive, and Nostr have seen notable growth, particularly following the wave of user migration after Twitter's acquisition in October 2022. As new platforms build upon earlier decentralization architectures and explore novel configurations, it becomes increasingly important to understand how these foundations shape both the direction and limitations of decentralization. Prior literature primarily focuses on specific architectures, resulting in fragmented views that overlook how different social networks encounter similar challenges and complement one another. This paper fills that gap by presenting a comprehensive view of the current decentralized online social network landscape. We examine four major architectures: federated, peer-to-peer, blockchain, and hybrid, tracing their evolution and evaluating how they support core social networking functions. By linking these architectural aspects to real-world cases, our work provides a foundation for understanding the societal implications of decentralized social platforms.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Few-Shot Generation of Brain Tumors for Secure and Fair Data Sharing</title>
<link>https://arxiv.org/abs/2504.00150</link>
<guid>https://arxiv.org/abs/2504.00150</guid>
<content:encoded><![CDATA[
<div> : 

:
(DFGM)DFGMUNetDFGMDice3.9%4.6% <div>
arXiv:2504.00150v1 Announce Type: new 
Abstract: Leveraging multi-center data for medical analytics presents challenges due to privacy concerns and data heterogeneity. While distributed approaches such as federated learning has gained traction, they remain vulnerable to privacy breaches, particularly in sensitive domains like medical imaging. Generative models, such as diffusion models, enhance privacy by synthesizing realistic data. However, they are prone to memorization, especially when trained on small datasets. This study proposes a decentralized few-shot generative model (DFGM) to synthesize brain tumor images while fully preserving privacy. DFGM harmonizes private tumor data with publicly shareable healthy images from multiple medical centers, constructing a new dataset by blending tumor foregrounds with healthy backgrounds. This approach ensures stringent privacy protection and enables controllable, high-quality synthesis by preserving both the healthy backgrounds and tumor foregrounds. We assess DFGM's effectiveness in brain tumor segmentation using a UNet, achieving Dice score improvements of 3.9% for data augmentation and 4.6% for fairness on a separate dataset.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>$\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks</title>
<link>https://arxiv.org/abs/2504.00218</link>
<guid>https://arxiv.org/abs/2504.00218</guid>
<content:encoded><![CDATA[
<div> Large Language Model (LLM)

<br /><br />
PIELLlamaMistralGemmaDeepSeekJailBreakBenchAdversarialBench7Llama-GuardPromptGuard <div>
arXiv:2504.00218v1 Announce Type: new 
Abstract: Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking pragmatic systems that have constrains such as limited token bandwidth, latency between message delivery, and defense mechanisms. We design a $\textit{permutation-invariant adversarial attack}$ that optimizes prompt distribution across latency and bandwidth-constraint network topologies to bypass distributed safety mechanisms within the system. Formulating the attack path as a problem of $\textit{maximum-flow minimum-cost}$, coupled with the novel $\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage graph-based optimization to maximize attack success rate while minimizing detection risk. Evaluating across models including $\texttt{Llama}$, $\texttt{Mistral}$, $\texttt{Gemma}$, $\texttt{DeepSeek}$ and other variants on various datasets like $\texttt{JailBreakBench}$ and $\texttt{AdversarialBench}$, our method outperforms conventional attacks by up to $7\times$, exposing critical vulnerabilities in multi-agent systems. Moreover, we demonstrate that existing defenses, including variants of $\texttt{Llama-Guard}$ and $\texttt{PromptGuard}$, fail to prohibit our attack, emphasizing the urgent need for multi-agent specific safety mechanisms.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedPaI: Achieving Extreme Sparsity in Federated Learning via Pruning at Initialization</title>
<link>https://arxiv.org/abs/2504.00308</link>
<guid>https://arxiv.org/abs/2504.00308</guid>
<content:encoded><![CDATA[
<div> : Federated Learning (), , , Pruning at Initialization (), FedPaI

<br /><br />:
FedPaIFedPaIPruning at Initialization (PaI)FedPaIFLFedPaIFedPaIIID98%6.47.9FLFedPaI <div>
arXiv:2504.00308v1 Announce Type: new 
Abstract: Federated Learning (FL) enables distributed training on edge devices but faces significant challenges due to resource constraints in edge environments, impacting both communication and computational efficiency. Existing iterative pruning techniques improve communication efficiency but are limited by their centralized design, which struggles with FL's decentralized and data-imbalanced nature, resulting in suboptimal sparsity levels. To address these issues, we propose FedPaI, a novel efficient FL framework that leverages Pruning at Initialization (PaI) to achieve extreme sparsity. FedPaI identifies optimal sparse connections at an early stage, maximizing model capacity and significantly reducing communication and computation overhead by fixing sparsity patterns at the start of training. To adapt to diverse hardware and software environments, FedPaI supports both structured and unstructured pruning. Additionally, we introduce personalized client-side pruning mechanisms for improved learning capacity and sparsity-aware server-side aggregation for enhanced efficiency. Experimental results demonstrate that FedPaI consistently outperforms existing efficient FL that applies conventional iterative pruning with significant leading in efficiency and model accuracy. For the first time, our proposed FedPaI achieves an extreme sparsity level of up to 98% without compromising the model accuracy compared to unpruned baselines, even under challenging non-IID settings. By employing our FedPaI with joint optimization of model learning capacity and sparsity, FL applications can benefit from faster convergence and accelerate the training by 6.4 to 7.9 times.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Performance Analysis, Lessons Learned and Practical Advice for a 6G Inter-Provider DApp on the Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2504.00555</link>
<guid>https://arxiv.org/abs/2504.00555</guid>
<content:encoded><![CDATA[
<div> : 6GProof-of-Stake (PoS)<br /><br />:

6GSepoliaProof-of-Stake (PoS)EVMSLA20%30-5080-90%1530EVM6G <div>
arXiv:2504.00555v1 Announce Type: new 
Abstract: This paper presents a multi-contract blockchain framework for inter-provider agreements in 6G networks, emphasizing performance analysis under a realistic Proof-of-Stake (PoS) setting on Ethereum's Sepolia testnet. We begin by quantifying Ethereum Virtual Machine (EVM)-based gas usage for critical operations such as provider registration, service addition, and SLA penalty enforcement, observing that cold writes and deep data structures can each inflate gas consumption by up to 20\%. We then examine block-level dynamics when multiple transactions execute concurrently, revealing that moderate concurrency (e.g., 30--50 simultaneous transactions) can fill blocks to 80--90\% of their gas limit and nearly double finalization times from around 15~seconds to over 30~seconds. Finally, we synthesize these insights into a practical design guide, demonstrating that flattening nested mappings, consolidating storage writes, and selectively timing high-impact transactions can markedly reduce costs and latency spikes. Collectively, our findings underscore the importance of EVM-specific optimizations and transaction scheduling for large-scale decentralized applications in 6G telecom scenarios. The implementation is available online.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2504.00587</link>
<guid>https://arxiv.org/abs/2504.00587</guid>
<content:encoded><![CDATA[
<div> Large Language Models (LLMs)AgentNet

<br /><br />:

AgentNetLLMsAgentNet1. LLM2. 3. AgentNet <div>
arXiv:2504.00587v1 Announce Type: new 
Abstract: The rapid advancement of Large Language Models (LLMs) has catalyzed the development of multi-agent systems, where multiple LLM-based agents collaborate to solve complex tasks. However, existing systems predominantly rely on centralized coordination, which introduces scalability bottlenecks, limits adaptability, and creates single points of failure. Additionally, concerns over privacy and proprietary knowledge sharing hinder cross-organizational collaboration, leading to siloed expertise. To address these challenges, we propose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based framework that enables LLM-based agents to autonomously evolve their capabilities and collaborate efficiently in a Directed Acyclic Graph (DAG)-structured network. Unlike traditional multi-agent systems that depend on static role assignments or centralized control, AgentNet allows agents to specialize dynamically, adjust their connectivity, and route tasks without relying on predefined workflows. AgentNet's core design is built upon several key innovations: (1) Fully Decentralized Paradigm: Removing the central orchestrator, allowing agents to coordinate and specialize autonomously, fostering fault tolerance and emergent collective intelligence. (2) Dynamically Evolving Graph Topology: Real-time adaptation of agent connections based on task demands, ensuring scalability and resilience.(3) Adaptive Learning for Expertise Refinement: A retrieval-based memory system that enables agents to continuously update and refine their specialized skills. By eliminating centralized control, AgentNet enhances fault tolerance, promotes scalable specialization, and enables privacy-preserving collaboration across organizations. Through decentralized coordination and minimal data exchange, agents can leverage diverse knowledge sources while safeguarding sensitive information.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Federated Training of Diffusion Models with Privacy Guarantees</title>
<link>https://arxiv.org/abs/2504.00952</link>
<guid>https://arxiv.org/abs/2504.00952</guid>
<content:encoded><![CDATA[
<div> (AI)

:
AI <div>
arXiv:2504.00952v1 Announce Type: new 
Abstract: The scarcity of accessible, compliant, and ethically sourced data presents a considerable challenge to the adoption of artificial intelligence (AI) in sensitive fields like healthcare, finance, and biomedical research. Furthermore, access to unrestricted public datasets is increasingly constrained due to rising concerns over privacy, copyright, and competition. Synthetic data has emerged as a promising alternative, and diffusion models -- a cutting-edge generative AI technology -- provide an effective solution for generating high-quality and diverse synthetic data. In this paper, we introduce a novel federated learning framework for training diffusion models on decentralized private datasets. Our framework leverages personalization and the inherent noise in the forward diffusion process to produce high-quality samples while ensuring robust differential privacy guarantees. Our experiments show that our framework outperforms non-collaborative training methods, particularly in settings with high data heterogeneity, and effectively reduces biases and imbalances in synthetic data, resulting in fairer downstream models.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Holistic analysis on the sustainability of Federated Learning across AI product lifecycle</title>
<link>https://arxiv.org/abs/2312.14628</link>
<guid>https://arxiv.org/abs/2312.14628</guid>
<content:encoded><![CDATA[
<div> Federated Learning, Cross-Silo FL, , , 

<br />
:
Federated LearningCross-Silo FLCross-Silo FLAICross-Silo FLCO2Cross-Silo FLIT <div>
arXiv:2312.14628v2 Announce Type: replace 
Abstract: In light of emerging legal requirements and policies focused on privacy protection, there is a growing trend of companies across various industries adopting Federated Learning (FL). This decentralized approach involves multiple clients or silos, collaboratively training a global model under the coordination of a central server while utilizing their private local data. Unlike traditional methods that necessitate data sharing and transmission, Cross-Silo FL allows clients to share model updates rather than raw data, thereby enhancing privacy. Despite its growing adoption, the carbon impact associated with Cross-Silo FL remains poorly understood due to the limited research in this area. This study seeks to bridge this gap by evaluating the sustainability of Cross-Silo FL throughout the entire AI product lifecycle, extending the analysis beyond the model training phase alone. We systematically compare this decentralized method with traditional centralized approaches and present a robust quantitative framework for assessing the costs and CO2 emissions in real-world Cross-Silo FL environments. Our findings indicate that the energy consumption and costs of model training are comparable between Cross-Silo Federated Learning and Centralized Learning. However, the additional data transfer and storage requirements inherent in Centralized Learning can result in significant, often overlooked CO2 emissions. Moreover, we introduce an innovative data and application management system that integrates Cross-Silo FL and analytics, aiming at improving the sustainability and economic efficiency of IT enterprises.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Convergence of Decentralized Actor-Critic Algorithm in General-sum Markov Games</title>
<link>https://arxiv.org/abs/2409.04613</link>
<guid>https://arxiv.org/abs/2409.04613</guid>
<content:encoded><![CDATA[
<div> : Markov, , , (MNPF), Nash

:
MarkovMarkovactor-critic(MNPF)LyapunovNash <div>
arXiv:2409.04613v5 Announce Type: replace 
Abstract: Markov games provide a powerful framework for modeling strategic multi-agent interactions in dynamic environments. Traditionally, convergence properties of decentralized learning algorithms in these settings have been established only for special cases, such as Markov zero-sum and potential games, which do not fully capture real-world interactions. In this paper, we address this gap by studying the asymptotic properties of learning algorithms in general-sum Markov games. In particular, we focus on a decentralized algorithm where each agent adopts an actor-critic learning dynamic with asynchronous step sizes. This decentralized approach enables agents to operate independently, without requiring knowledge of others' strategies or payoffs. We introduce the concept of a Markov Near-Potential Function (MNPF) and demonstrate that it serves as an approximate Lyapunov function for the policy updates in the decentralized learning dynamics, which allows us to characterize the convergent set of strategies. We further strengthen our result under specific regularity conditions and with finite Nash equilibria.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design, Implementation and Practical Energy-Efficiency Evaluation of a Blockchain Based Academic Credential Verification System for Low-Power Nodes</title>
<link>https://arxiv.org/abs/2410.20605</link>
<guid>https://arxiv.org/abs/2410.20605</guid>
<content:encoded><![CDATA[
<div> : Proof-of-WorkProof-of-AuthorityCPURaspberry Pi 4Orange Pi OneEthereum gas limit

<br /><br />:
Inter-Planetary File SystemIPFSProof-of-Work (PoW) Proof-of-Authority (PoA) PoACPURaspberry Pi 4Orange Pi OneEthereum gas limit  <div>
arXiv:2410.20605v2 Announce Type: replace 
Abstract: The educational system manages extensive documentation and paperwork, which can lead to human errors and sometimes abuse or fraud, such as the falsification of diplomas, certificates or other credentials. In fact, in the last years, multiple cases of fraud have been detected, which have a significant cost to society, since they harm the trustworthiness of certificates and academic institutions. To tackle such an issue, this article proposes a solution aimed at recording and verifying academic records through a decentralized application that is supported by a smart contract deployed in the Ethereum blockchain and by a decentralized storage system based on Inter-Planetary File System (IPFS). The proposed solution is evaluated in terms of performance and energy-efficiency, comparing the results obtained with a traditional Proof-of-Work (PoW) consensus protocol and the new Proof-of-Authority (PoA) protocol. The results shown in this paper indicate that the latter is clearly greener and demands less CPU load. Moreover, this article compares the performance of a traditional computer and two SBCs (a Raspberry Pi 4 and an Orange Pi One), showing that is possible to make use of the latter low-power devices to implement blockchain nodes but at the cost of higher response latency. Furthermore, the impact of Ethereum gas limit is evaluated, demonstrating its significant influence on the blockchain network performance. Thus, this article provides guidelines, useful practical evaluations and key findings that will help the next generation of green blockchain developers and researchers.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Battery Operations in Electricity Markets: Strategic Behavior and Distortions</title>
<link>https://arxiv.org/abs/2406.18685</link>
<guid>https://arxiv.org/abs/2406.18685</guid>
<content:encoded><![CDATA[
<div> : 

:
Price of Anarchy9/84/3 <div>
arXiv:2406.18685v2 Announce Type: replace-cross 
Abstract: Electric power systems are undergoing a major transformation as they integrate intermittent renewable energy sources, and batteries to smooth out variations in renewable energy production. As privately-owned batteries grow from their role as marginal "price-takers" to significant players in the market, a natural question arises: How do batteries operate in electricity markets, and how does the strategic behavior of decentralized batteries distort decisions compared to centralized batteries? We propose an analytically tractable model that captures salient features of the highly complex electricity market. We derive in closed form the resulting battery behavior and generation cost in three operating regimes: (i) no battery, (ii) centralized battery, and (ii) decentralized profit-maximizing battery. We establish that a decentralized battery distorts its discharge decisions in three ways. First, there is quantity withholding, i.e., discharging less than centrally optimal. Second, there is a shift in participation from day-ahead to real-time, i.e., postponing some of its discharge from day-ahead to real-time. Third, there is reduction in real-time responsiveness, or discharging less in response to smoothing real-time demand than centrally optimal. We also quantify the impact of the battery market power on total system cost via the Price of Anarchy metric, and prove that the it is always between $9/8$ and $4/3$. That is, incentive misalignment always exists, but it is bounded even in the worst case. We calibrate our model to real data from Los Angeles and Houston. Lastly, we show that competition is very effective at reducing distortions, but many market power mitigation mechanisms backfire, and lead to higher total cost.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Analyzing Performance Bottlenecks in Zero-Knowledge Proof Based Rollups on Ethereum</title>
<link>https://arxiv.org/abs/2503.22709</link>
<guid>https://arxiv.org/abs/2503.22709</guid>
<content:encoded><![CDATA[
<div> rollupHardhat Ethereum

:
<br />
ZKProllupHardhatZKPZKP-based rollups <div>
arXiv:2503.22709v1 Announce Type: new 
Abstract: Blockchain technology is rapidly evolving, with scalability remaining one of its most significant challenges. While various solutions have been proposed and continue to be developed, it is essential to consider the blockchain trilemma -- balancing scalability, security, and decentralization -- when designing new approaches. One promising solution is the zero-knowledge proof (ZKP)-based rollup, implemented on top of Ethereum. However, the performance of these systems is often limited by the efficiency of the ZKP mechanism. This paper explores the performance of ZKP-based rollups, focusing on a solution built using the Hardhat Ethereum development environment. Through detailed analysis, the paper identifies and examines key bottlenecks within the ZKP system, providing insight into potential areas for optimization to enhance scalability and overall system performance.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assessing the influence of cybersecurity threats and risks on the adoption and growth of digital banking: a systematic literature review</title>
<link>https://arxiv.org/abs/2503.22710</link>
<guid>https://arxiv.org/abs/2503.22710</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
2015202478PRISMAGDPRPSD2GLBA <div>
arXiv:2503.22710v1 Announce Type: new 
Abstract: The rapid digitalization of banking services has significantly transformed financial transactions, offering enhanced convenience and efficiency for consumers. However, the increasing reliance on digital banking has also exposed financial institutions and users to a wide range of cybersecurity threats, including phishing, malware, ransomware, data breaches, and unauthorized access. This study systematically examines the influence of cybersecurity threats on digital banking security, adoption, and regulatory compliance by conducting a comprehensive review of 78 peer-reviewed articles published between 2015 and 2024. Using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology, this research critically evaluates the most prevalent cyber threats targeting digital banking platforms, the effectiveness of modern security measures, and the role of regulatory frameworks in mitigating financial cybersecurity risks. The findings reveal that phishing and malware attacks remain the most commonly exploited cyber threats, leading to significant financial losses and consumer distrust. Multi-factor authentication (MFA) and biometric security have been widely adopted to combat unauthorized access, while AI-driven fraud detection and blockchain technology offer promising solutions for securing financial transactions. However, the integration of third-party FinTech solutions introduces additional security risks, necessitating stringent regulatory oversight and cybersecurity protocols. The study also highlights that compliance with global cybersecurity regulations, such as GDPR, PSD2, and GLBA, enhances digital banking security by enforcing strict authentication measures, encryption protocols, and real-time fraud monitoring.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FeatherWallet: A Lightweight Mobile Cryptocurrency Wallet Using zk-SNARKs</title>
<link>https://arxiv.org/abs/2503.22717</link>
<guid>https://arxiv.org/abs/2503.22717</guid>
<content:encoded><![CDATA[
<div> : FeatherWalletSNARKs

<br /><br />:
FeatherWalletFeatherWalletSNARKs264zk-SNARK40GB12 gas SPVFeatherWallet20PoWPoS <div>
arXiv:2503.22717v1 Announce Type: new 
Abstract: Traditionally, mobile wallets rely on a trusted server that provides them with a current view of the blockchain, and thus, these wallets do not need to validate the header chain or transaction inclusion themselves. If a mobile wallet were to validate a header chain and inclusion of its transactions, it would require significant storage and performance overhead, which is challenging and expensive to ensure on resource-limited devices, such as smartphones. Moreover, such an overhead would be multiplied by the number of cryptocurrencies the user holds in a wallet. Therefore, we introduce a novel approach, called FeatherWallet, to mobile wallet synchronization designed to eliminate trust in a server while providing efficient utilization of resources. Our approach addresses the challenges associated with storage and bandwidth requirements by off-chaining validation of header chains using SNARK-based proofs of chain extension, which are verified by a smart contract. This offers us a means of storing checkpoints in header chains of multiple blockchains. The key feature of our approach is the ability of mobile clients to update their partial local header chains using checkpoints derived from the proof verification results stored in the smart contract. In the evaluation, we created zk-SNARK proofs for the 2, 4, 8, 16, 32, and 64 headers within our trustless off-chain service. For 64-header proofs, the off-chain service producing proofs requires at least 40 GB of RAM, while the minimal gas consumption is achieved for 12 proofs bundled in a single transaction. We achieved a 20-fold reduction in storage overhead for a mobile client in contrast to traditional SPV clients. Although we have developed a proof-of-concept for PoW blockchains, the whole approach can be extended in principle to other consensus mechanisms, e.g., PoS.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strategies for decentralised UAV-based collisions monitoring in rugby</title>
<link>https://arxiv.org/abs/2503.22757</link>
<guid>https://arxiv.org/abs/2503.22757</guid>
<content:encoded><![CDATA[
<div> (UAV)(TBI)

:<br />
NetLogo(TBI) <div>
arXiv:2503.22757v1 Announce Type: new 
Abstract: Recent advancements in unmanned aerial vehicle (UAV) technology have opened new avenues for dynamic data collection in challenging environments, such as sports fields during fast-paced sports action. For the purposes of monitoring sport events for dangerous injuries, we envision a coordinated UAV fleet designed to capture high-quality, multi-view video footage of collision events in real-time. The extracted video data is crucial for analyzing athletes' motions and investigating the probability of sports-related traumatic brain injuries (TBI) during impacts. This research implemented a UAV fleet system on the NetLogo platform, utilizing custom collision detection algorithms to compare against traditional TV-coverage strategies. Our system supports decentralized data capture and autonomous processing, providing resilience in the rapidly evolving dynamics of sports collisions.
  The collaboration algorithm integrates both shared and local data to generate multi-step analyses aimed at determining the efficacy of custom methods in enhancing the accuracy of TBI prediction models. Missions are simulated in real-time within a two-dimensional model, focusing on the strategic capture of collision events that could lead to TBI, while considering operational constraints such as rapid UAV maneuvering and optimal positioning. Preliminary results from the NetLogo simulations suggest that custom collision detection methods offer superior performance over standard TV-coverage strategies by enabling more precise and timely data capture. This comparative analysis highlights the advantages of tailored algorithmic approaches in critical sports safety applications.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Federated Learning Through Secure Cluster-Weighted Client Aggregation</title>
<link>https://arxiv.org/abs/2503.22971</link>
<guid>https://arxiv.org/abs/2503.22971</guid>
<content:encoded><![CDATA[
<div> : 

:
ClusterGuardFLk-meanssoftmax <div>
arXiv:2503.22971v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a promising paradigm in machine learning, enabling collaborative model training across decentralized devices without the need for raw data sharing. In FL, a global model is trained iteratively on local datasets residing on individual devices, each contributing to the model's improvement. However, the heterogeneous nature of these local datasets, stemming from diverse user behaviours, device capabilities, and data distributions, poses a significant challenge. The inherent heterogeneity in federated learning gives rise to various issues, including model performance discrepancies, convergence challenges, and potential privacy concerns. As the global model progresses through rounds of training, the disparities in local data quality and quantity can impede the overall effectiveness of federated learning systems. Moreover, maintaining fairness and privacy across diverse user groups becomes a paramount concern. To address this issue, this paper introduces a novel FL framework, ClusterGuardFL, that employs dissimilarity scores, k-means clustering, and reconciliation confidence scores to dynamically assign weights to client updates. The dissimilarity scores between global and local models guide the formation of clusters, with cluster size influencing the weight allocation. Within each cluster, a reconciliation confidence score is calculated for individual data points, and a softmax layer generates customized weights for clients. These weights are utilized in the aggregation process, enhancing the model's robustness and privacy. Experimental results demonstrate the efficacy of the proposed approach in achieving improved model performance in diverse datasets.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ethereum Price Prediction Employing Large Language Models for Short-term and Few-shot Forecasting</title>
<link>https://arxiv.org/abs/2503.23190</link>
<guid>https://arxiv.org/abs/2503.23190</guid>
<content:encoded><![CDATA[
<div> : 

:<br />
LLMsLLMsLLMsMSEMAERMSELLMs <div>
arXiv:2503.23190v1 Announce Type: new 
Abstract: Cryptocurrencies have transformed financial markets with their innovative blockchain technology and volatile price movements, presenting both challenges and opportunities for predictive analytics. Ethereum, being one of the leading cryptocurrencies, has experienced significant market fluctuations, making its price prediction an attractive yet complex problem. This paper presents a comprehensive study on the effectiveness of Large Language Models (LLMs) in predicting Ethereum prices for short-term and few-shot forecasting scenarios. The main challenge in training models for time series analysis is the lack of data. We address this by leveraging a novel approach that adapts existing pre-trained LLMs on natural language or images from billions of tokens to the unique characteristics of Ethereum price time series data. Through thorough experimentation and comparison with traditional and contemporary models, our results demonstrate that selectively freezing certain layers of pre-trained LLMs achieves state-of-the-art performance in this domain. This approach consistently surpasses benchmarks across multiple metrics, including Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE), demonstrating its effectiveness and robustness. Our research not only contributes to the existing body of knowledge on LLMs but also provides practical insights in the cryptocurrency prediction domain. The adaptability of pre-trained LLMs to handle the nature of Ethereum prices suggests a promising direction for future research, potentially including the integration of sentiment analysis to further refine forecasting accuracy.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Design of Ultra Large-Scale Control Systems: Progress, Challenges, and Prospects</title>
<link>https://arxiv.org/abs/2503.23416</link>
<guid>https://arxiv.org/abs/2503.23416</guid>
<content:encoded><![CDATA[
<div> : 

:
(ULSS) <div>
arXiv:2503.23416v1 Announce Type: new 
Abstract: The transition from large centralized complex control systems to distributed configurations that rely on a network of a very large number of interconnected simpler subsystems is ongoing and inevitable in many applications. It is attributed to the quest for resilience, flexibility, and scalability in a multitude of engineering fields with far-reaching societal impact. Although many design methods for distributed and decentralized control systems are available, most of them rely on a centralized design procedure requiring some form of global information of the whole system. Clearly, beyond a certain scale of the network, these centralized design procedures for distributed controllers are no longer feasible and we refer to the corresponding systems as ultra large-scale systems (ULSS). For these ULSS, design algorithms are needed that are distributed themselves among the subsystems and are subject to stringent requirements regarding communication, computation, and memory usage of each subsystem. In this paper, a set of requirements is provided that assures a feasible real-time implementation of all phases of a control solution on an ultra large scale. State-of-the-art approaches are reviewed in the light of these requirements and the challenges hampering the development of befitting control algorithms are pinpointed. Comparing the challenges with the current progress leads to the identification and motivation of promising research directions.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Processing goes far beyond "the app" -- Privacy issues of decentralized Digital Contact Tracing using the example of the German Corona-Warn-App (CWA)</title>
<link>https://arxiv.org/abs/2503.23444</link>
<guid>https://arxiv.org/abs/2503.23444</guid>
<content:encoded><![CDATA[
<div> : SARS-CoV-2, GDPR, (DPIA), Corona-Warn-App(CWA), 

:<br />
SARS-CoV-22020(GDPR)(DPIA)(SDM)Corona-Warn-App(CWA)DPIA <div>
arXiv:2503.23444v1 Announce Type: new 
Abstract: Since SARS-CoV-2 started spreading in Europe in early 2020, there has been a strong call for technical solutions to combat or contain the pandemic, with contact tracing apps at the heart of the debates. The EU's General Data Protection Regulation (GDPR) requires controllers to carry out a data protection impact assessment (DPIA) where their data processing is likely to result in a high risk to the rights and freedoms (Art. 35 GDPR). A DPIA is a structured risk analysis that identifies and evaluates possible consequences of data processing relevant to fundamental rights in advance and describes the measures envisaged to address these risks or expresses the inability to do so. Based on the Standard Data Protection Model (SDM), we present the results of a scientific and methodologically clear DPIA of the German German Corona-Warn-App (CWA). It shows that even a decentralized architecture involves numerous serious weaknesses and risks, including larger ones still left unaddressed in current implementations. It also found that none of the proposed designs operates on anonymous data or ensures proper anonymisation. It also showed that informed consent would not be a legitimate legal ground for the processing. For all points where data subjects' rights are still not sufficiently safeguarded, we briefly outline solutions.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Demystifying Private Transactions and Their Impact in PoW and PoS Ethereum</title>
<link>https://arxiv.org/abs/2503.23510</link>
<guid>https://arxiv.org/abs/2503.23510</guid>
<content:encoded><![CDATA[
<div> : EthereumProof-of-Work (PoW)Proof-of-Stake (PoS)Maximum Extractable Value (MEV)

:<br />
Ethereum14,810,392PoW30,062,232PoSPoWPoS(MEV)(DeFi)DeFiPoSPoWPoSMEV <div>
arXiv:2503.23510v1 Announce Type: new 
Abstract: In Ethereum, private transactions, a specialized transaction type employed to evade public Peer-to-Peer (P2P) network broadcasting, remain largely unexplored, particularly in the context of the transition from Proof-of-Work (PoW) to Proof-of-Stake (PoS) consensus mechanisms. To address this gap, we investigate the transaction characteristics, (un)intended usages, and monetary impacts by analyzing large-scale datasets comprising 14,810,392 private transactions within a 15.5-month PoW dataset and 30,062,232 private transactions within a 15.5-month PoS dataset. While originally designed for security purposes, we find that private transactions predominantly serve three distinct functions in both PoW and PoS Ethereum: extracting Maximum Extractable Value (MEV), facilitating monetary transfers to distribute mining rewards, and interacting with popular Decentralized Finance (DeFi) applications. Furthermore, we find that private transactions are utilized in DeFi attacks to circumvent surveillance by white hat monitors, with an increased prevalence observed in PoS Ethereum compared to PoW Ethereum. Additionally, in PoS Ethereum, there is a subtle uptick in the role of private transactions for MEV extraction. This shift could be attributed to the decrease in transaction costs. However, this reduction in transaction cost and the cancellation of block rewards result in a significant decrease in mining profits for block creators.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Functional Bugs in Smart Contracts through LLM-Powered and Bug-Oriented Composite Analysis</title>
<link>https://arxiv.org/abs/2503.23718</link>
<guid>https://arxiv.org/abs/2503.23718</guid>
<content:encoded><![CDATA[
<div> : PROMFUZZ

:
PROMFUZZPROMFUZZbugPROMFUZZF186.96%93.02%50%PROMFUZZDeFi3024CVE ID <div>
arXiv:2503.23718v1 Announce Type: new 
Abstract: Smart contracts are fundamental pillars of the blockchain, playing a crucial role in facilitating various business transactions. However, these smart contracts are vulnerable to exploitable bugs that can lead to substantial monetary losses. A recent study reveals that over 80% of these exploitable bugs, which are primarily functional bugs, can evade the detection of current tools. The primary issue is the significant gap between understanding the high-level logic of the business model and checking the low-level implementations in smart contracts. Furthermore, identifying deeply rooted functional bugs in smart contracts requires the automated generation of effective detection oracles based on various bug features. To address these challenges, we design and implement PROMFUZZ, an automated and scalable system to detect functional bugs, in smart contracts. In PROMFUZZ, we first propose a novel Large Language Model (LLM)-driven analysis framework, which leverages a dual-agent prompt engineering strategy to pinpoint potentially vulnerable functions for further scrutiny. We then implement a dual-stage coupling approach, which focuses on generating invariant checkers that leverage logic information extracted from potentially vulnerable functions. Finally, we design a bug-oriented fuzzing engine, which maps the logical information from the high-level business model to the low-level smart contract implementations, and performs the bug-oriented fuzzing on targeted functions. We compare PROMFUZZ with multiple state-of-the-art methods. The results show that PROMFUZZ achieves 86.96% recall and 93.02% F1-score in detecting functional bugs, marking at least a 50% improvement in both metrics over state-of-the-art methods. Moreover, we perform an in-depth analysis on real-world DeFi projects and detect 30 zero-day bugs. Up to now, 24 zero-day bugs have been assigned CVE IDs.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PDSL: Privacy-Preserved Decentralized Stochastic Learning with Heterogeneous Data Distribution</title>
<link>https://arxiv.org/abs/2503.23726</link>
<guid>https://arxiv.org/abs/2503.23726</guid>
<content:encoded><![CDATA[
<div> : Decentralized Learning, Heterogeneous Data, Privacy Preservation, Differential Privacy, PDSL

:<br />
PDSLShapleyPDSL <div>
arXiv:2503.23726v1 Announce Type: new 
Abstract: In the paradigm of decentralized learning, a group of agents collaborates to learn a global model using distributed datasets without a central server. However, due to the heterogeneity of the local data across the different agents, learning a robust global model is rather challenging. Moreover, the collaboration of the agents relies on their gradient information exchange, which poses a risk of privacy leakage. In this paper, to address these issues, we propose PDSL, a novel privacy-preserved decentralized stochastic learning algorithm with heterogeneous data distribution. On one hand, we innovate in utilizing the notion of Shapley values such that each agent can precisely measure the contributions of its heterogeneous neighbors to the global learning goal; on the other hand, we leverage the notion of differential privacy to prevent each agent from suffering privacy leakage when it contributes gradient information to its neighbors. We conduct both solid theoretical analysis and extensive experiments to demonstrate the efficacy of our PDSL algorithm in terms of privacy preservation and convergence.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain for Federated Learning in the Internet of Things: Trustworthy Adaptation, Standards, and the Road Ahead</title>
<link>https://arxiv.org/abs/2503.23823</link>
<guid>https://arxiv.org/abs/2503.23823</guid>
<content:encoded><![CDATA[
<div> 

:
FLDLTsFL3GPPETSIITU-TIEEEO-RANFLFLIOTA TangleFL6GFLDLT-FL <div>
arXiv:2503.23823v1 Announce Type: new 
Abstract: As edge computing gains prominence in Internet of Things (IoTs), smart cities, and autonomous systems, the demand for real-time machine intelligence with low latency and model reliability continues to grow. Federated Learning (FL) addresses these needs by enabling distributed model training without centralizing user data, yet it remains reliant on centralized servers and lacks built-in mechanisms for transparency and trust. Blockchain and Distributed Ledger Technologies (DLTs) can fill this gap by introducing immutability, decentralized coordination, and verifiability into FL workflows. This article presents current standardization efforts from 3GPP, ETSI, ITU-T, IEEE, and O-RAN that steer the integration of FL and blockchain in IoT ecosystems. We then propose a blockchain-based FL framework that replaces the centralized aggregator, incorporates reputation monitoring of IoT devices, and minimizes overhead via selective on-chain storage of model updates. We validate our approach with IOTA Tangle, demonstrating stable throughput and block confirmations, even under increasing FL workloads. Finally, we discuss architectural considerations and future directions for embedding trustworthy and resource-efficient FL in emerging 6G networks and vertical IoT applications. Our results underscore the potential of DLT-enhanced FL to meet stringent trust and energy requirements of next-generation IoT deployments.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Practical Rollup Escape Hatch Design</title>
<link>https://arxiv.org/abs/2503.23986</link>
<guid>https://arxiv.org/abs/2503.23986</guid>
<content:encoded><![CDATA[
<div> : rollupLayer 2

<br />
:
rolluprollupLayer 1Layer 2rollupLayer 1rollupLayer 2Layer 2ETHERC-20ERC-721 <div>
arXiv:2503.23986v1 Announce Type: new 
Abstract: A rollup network is a type of popular "Layer 2" scaling solution for general purpose "Layer 1" blockchains like Ethereum. Rollups networks separate execution of transactions from other aspects like consensus, processing transactions off of the Layer 1, and posting the data onto the underlying layer for security. While rollups offer significant scalability advantages, they often rely on centralized operators for transaction ordering and inclusion, which also introduces potential risks. If the operator fails to build rollup blocks or propose new state roots to the underlying Layer 1, users may lose access to digital assets on the rollup. An escape hatch allows users to bypass the failing operator and withdraw assets directly on the Layer 1. We propose using a time-based trigger, Merkle proofs, and new resolver contracts to implement a practical escape hatch for these networks. The use of novel resolver contracts allow user owned assets to be located in the Layer 2 state root, including those owned by smart contracts, in order to allow users to escape them. This design ensures safe and verifiable escape of assets, including ETH, ERC-20 and ERC-721 tokens, and more, from the Layer 2.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Dynamic Spectrum Access via Fully Decentralized Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.24296</link>
<guid>https://arxiv.org/abs/2503.24296</guid>
<content:encoded><![CDATA[
<div> : (rl)

:<br />
-rl(fsrL)fsrl(i)(ii)(iii)rlfsrl89.0%48.1% <div>
arXiv:2503.24296v1 Announce Type: new 
Abstract: We consider a decentralized wireless network with several source-destination pairs sharing a limited number of orthogonal frequency bands. Sources learn to adapt their transmissions (specifically, their band selection strategy) over time, in a decentralized manner, without sharing information with each other. Sources can only observe the outcome of their own transmissions (i.e., success or collision), having no prior knowledge of the network size or of the transmission strategy of other sources. The goal of each source is to maximize their own throughput while striving for network-wide fairness. We propose a novel fully decentralized Reinforcement Learning (RL)-based solution that achieves fairness without coordination. The proposed Fair Share RL (FSRL) solution combines: (i) state augmentation with a semi-adaptive time reference; (ii) an architecture that leverages risk control and time difference likelihood; and (iii) a fairness-driven reward structure. We evaluate FSRL in more than 50 network settings with different number of agents, different amounts of available spectrum, in the presence of jammers, and in an ad-hoc setting. Simulation results suggest that, when we compare FSRL with a common baseline RL algorithm from the literature, FSRL can be up to 89.0% fairer (as measured by Jain's fairness index) in stringent settings with several sources and a single frequency band, and 48.1% fairer on average.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalized Reputation Computation Ontology and Temporal Graph Architecture</title>
<link>https://arxiv.org/abs/1912.00176</link>
<guid>https://arxiv.org/abs/1912.00176</guid>
<content:encoded><![CDATA[
<div> : <br /><br />: AIAI <div>
arXiv:1912.00176v2 Announce Type: replace 
Abstract: The problem of reliable democratic governance is important for survival of any community, and it will be more critical over time communities with levels of social connectivity in society rapidly increasing with speeds and scales of electronic communication. In order to face such challenge, different sorts of rating and reputation systems are being developed, however reputation gaming and manipulation in such systems appears to be serious problem. We are considering use of advanced reputation system supporting "liquid democracy" principle with generalized design and underlying ontology fitting different sorts of environments such as social networks, financial ecosystems and marketplaces. The suggested system is based on "temporal weighted liquid rank" algorithm employing different sorts of explicit and implicit ratings being exchanged by members of the society. For the purpose, we suggest "incremental reputation" design and graph database used for implementation of the system. Finally, we present evaluation of the system against real social network and financial blockchain data. The entire framework is expected to be the foundation of any multi-agent AI framework, so the evolution of distributed multi-agent AI architecture and dynamics will be based on the organic reputation scores earned by the agents that are part of it.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning in Quantum Common-Interest Games and the Separability Problem</title>
<link>https://arxiv.org/abs/2302.04789</link>
<guid>https://arxiv.org/abs/2302.04789</guid>
<content:encoded><![CDATA[
<div> KKT<br /><br /><br />
CIGsCIGKKTCIG/CIG <div>
arXiv:2302.04789v3 Announce Type: replace 
Abstract: Learning in games has emerged as a powerful tool for machine learning with numerous applications. Quantum games model interactions between strategic players who have access to quantum resources, and several recent works have studied {learning in} the competitive regime of quantum zero-sum games. Going beyond this setting, we introduce quantum common-interest games (CIGs) where players have density matrices as strategies and their interests are perfectly aligned. We bridge the gap between optimization and game theory by establishing the equivalence between KKT (first-order stationary) points of an instance of the Best Separable State (BSS) problem and the Nash equilibria of its corresponding quantum CIG. This allows learning dynamics for the quantum CIG to be seen as decentralized algorithms for the BSS problem. Taking the perspective of learning in games, we then introduce non-commutative extensions of the continuous-time replicator dynamics and the discrete-time best response dynamics/linear multiplicative weights update for learning in quantum CIGs. We prove analogues of classical convergence results of the dynamics and explore differences which arise in the quantum setting. Finally, we corroborate our theoretical findings through extensive experiments.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Contracts in the Real World: A Statistical Exploration of External Data Dependencies</title>
<link>https://arxiv.org/abs/2406.13253</link>
<guid>https://arxiv.org/abs/2406.13253</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
10,5009,3563,6009%249 <div>
arXiv:2406.13253v2 Announce Type: replace 
Abstract: Smart contracts with external data are crucial for functionality but pose security and reliability concerns. Statistical and quantitative studies on this interaction are scarce. To address this gap, we analyzed 10,500 smart contracts, retaining 9,356 valid ones after excluding outdated or erroneous ones.We employed code parsing to transform contract code into abstract syntax trees and identified keywords associated with external data dependencies. We conducted a quantitative analysis by comparing these keywords to a reference list. We manually classified the 9,356 valid smart contracts to ascertain their application domains and typical interaction methods with external data. Additionally, we created a database with this data to facilitate research on smart contract dependencies. Moreover, we reviewed over 3,600 security audit reports, manually identifying 249 (approximately 9%) related to external data interactions and categorized their dependencies. We explored the correlation between smart contract complexity and external data dependency to provide insights for their design and auditing processes. These studies aim to enhance the security and reliability of smart contracts and offer practical guidance to developers and auditors.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collisionless and Decentralized Formation Control for Strings</title>
<link>https://arxiv.org/abs/2102.13621</link>
<guid>https://arxiv.org/abs/2102.13621</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:

<br />
1. <br />
2. <br />
3. <br />
 <div>
arXiv:2102.13621v2 Announce Type: replace-cross 
Abstract: A decentralized feedback controller for multi-agent systems, inspired by vehicle platooning, is proposed. The closed loop resulting from the decentralized control action has three distinctive features: the generation of collision-free trajectories, flocking of the system towards a consensus state in velocity, and asymptotic convergence to a prescribed pattern of distances between agents. For each feature, a rigorous dynamical analysis is provided, yielding a characterization of the set of parameters and initial configurations where collision avoidance, flocking, and pattern formation are guaranteed. Numerical tests assess the theoretical results presented.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Bilevel Optimization: A Perspective from Transient Iteration Complexity</title>
<link>https://arxiv.org/abs/2402.03167</link>
<guid>https://arxiv.org/abs/2402.03167</guid>
<content:encoded><![CDATA[
<div> stochastic bilevel optimization, decentralized, D-SOBA, transient iteration complexity, network topology

:<br />
SBOD-SOBA/D-SOBAD-SOBA-SOHessianJacobianD-SOBA-FOD-SOBASBOD-SOBA <div>
arXiv:2402.03167v3 Announce Type: replace-cross 
Abstract: Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, most decentralized SBO algorithms focus solely on asymptotic convergence rates, overlooking transient iteration complexity-the number of iterations required before asymptotic rates dominate, which results in limited understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. To address this issue, this paper introduces D-SOBA, a Decentralized Stochastic One-loop Bilevel Algorithm framework. D-SOBA comprises two variants: D-SOBA-SO, which incorporates second-order Hessian and Jacobian matrices, and D-SOBA-FO, which relies entirely on first-order gradients. We provide a comprehensive non-asymptotic convergence analysis and establish the transient iteration complexity of D-SOBA. This provides the first theoretical understanding of how network topology, data heterogeneity, and nested bilevel structures influence decentralized SBO. Extensive experimental results demonstrate the efficiency and theoretical advantages of D-SOBA.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Security Analysis of Blockchain-based Cryptocurrency</title>
<link>https://arxiv.org/abs/2503.22156</link>
<guid>https://arxiv.org/abs/2503.22156</guid>
<content:encoded><![CDATA[
<div> cryptocurrency, security threats, attacks, blockchain infrastructure, detection and defense solutions

<br /><br />:
cryptocurrency <div>
arXiv:2503.22156v1 Announce Type: new 
Abstract: Cryptocurrency is a novel exploration of a form of currency that proposes a decentralized electronic payment scheme based on blockchain technology and cryptographic theory. While cryptocurrency has the security characteristics of being distributed and tamper-proof, increasing market demand has led to a rise in malicious transactions and attacks, thereby exposing cryptocurrency to vulnerabilities, privacy issues, and security threats. Particularly concerning are the emerging types of attacks and threats, which have made securing cryptocurrency increasingly urgent. Therefore, this paper classifies existing cryptocurrency security threats and attacks into five fundamental categories based on the blockchain infrastructure and analyzes in detail the vulnerability principles exploited by each type of threat and attack. Additionally, the paper examines the attackers' logic and methods and successfully reproduces the vulnerabilities. Furthermore, the author summarizes the existing detection and defense solutions and evaluates them, all of which provide important references for ensuring the security of cryptocurrency. Finally, the paper discusses the future development trends of cryptocurrency, as well as the public challenges it may face.
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unbiased Max-Min Embedding Classification for Transductive Few-Shot Learning: Clustering and Classification Are All You Need</title>
<link>https://arxiv.org/abs/2503.22193</link>
<guid>https://arxiv.org/abs/2503.22193</guid>
<content:encoded><![CDATA[
<div> : (FSL), (TFSL), (UMMEC), , Sinkhorn

:<br />
(UMMEC)UMMECSinkhornUMMECTFSL <div>
arXiv:2503.22193v1 Announce Type: new 
Abstract: Convolutional neural networks and supervised learning have achieved remarkable success in various fields but are limited by the need for large annotated datasets. Few-shot learning (FSL) addresses this limitation by enabling models to generalize from only a few labeled examples. Transductive few-shot learning (TFSL) enhances FSL by leveraging both labeled and unlabeled data, though it faces challenges like the hubness problem. To overcome these limitations, we propose the Unbiased Max-Min Embedding Classification (UMMEC) Method, which addresses the key challenges in few-shot learning through three innovative contributions. First, we introduce a decentralized covariance matrix to mitigate the hubness problem, ensuring a more uniform distribution of embeddings. Second, our method combines local alignment and global uniformity through adaptive weighting and nonlinear transformation, balancing intra-class clustering with inter-class separation. Third, we employ a Variational Sinkhorn Few-Shot Classifier to optimize the distances between samples and class prototypes, enhancing classification accuracy and robustness. These combined innovations allow the UMMEC method to achieve superior performance with minimal labeled data. Our UMMEC method significantly improves classification performance with minimal labeled data, advancing the state-of-the-art in TFSL.
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FLIP: Towards Comprehensive and Reliable Evaluation of Federated Prompt Learning</title>
<link>https://arxiv.org/abs/2503.22263</link>
<guid>https://arxiv.org/abs/2503.22263</guid>
<content:encoded><![CDATA[
<div> promptFLIP

:
promptpromptFLIP8prompt4126promptprompt <div>
arXiv:2503.22263v1 Announce Type: new 
Abstract: The increasing emphasis on privacy and data security has driven the adoption of federated learning, a decentralized approach to train machine learning models without sharing raw data. Prompt learning, which fine-tunes prompt embeddings of pretrained models, offers significant advantages in federated settings by reducing computational costs and communication overheads while leveraging the strong performance and generalization capabilities of vision-language models such as CLIP. This paper addresses the intersection of federated learning and prompt learning, particularly for vision-language models. In this work, we introduce a comprehensive framework, named FLIP, to evaluate federated prompt learning algorithms. FLIP assesses the performance of 8 state-of-the-art federated prompt learning methods across 4 federated learning protocols and 12 open datasets, considering 6 distinct evaluation scenarios. Our findings demonstrate that prompt learning maintains strong generalization performance in both in-distribution and out-of-distribution settings with minimal resource consumption. This work highlights the effectiveness of federated prompt learning in environments characterized by data scarcity, unseen classes, and cross-domain distributional shifts. We open-source the code for all implemented algorithms in FLIP to facilitate further research in this domain.
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems</title>
<link>https://arxiv.org/abs/2503.22639</link>
<guid>https://arxiv.org/abs/2503.22639</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
 <div>
arXiv:2503.22639v1 Announce Type: cross 
Abstract: The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Federated Learning Against Poisoning Attacks: A GAN-Based Defense Framework</title>
<link>https://arxiv.org/abs/2503.20884</link>
<guid>https://arxiv.org/abs/2503.20884</guid>
<content:encoded><![CDATA[
<div> : Federated Learning, , , , 

:
(Federated Learning)(cGAN)FL<br /><br /> <div>
arXiv:2503.20884v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized devices without sharing raw data, but it remains vulnerable to poisoning attacks that compromise model integrity. Existing defenses often rely on external datasets or predefined heuristics (e.g. number of malicious clients), limiting their effectiveness and scalability. To address these limitations, we propose a privacy-preserving defense framework that leverages a Conditional Generative Adversarial Network (cGAN) to generate synthetic data at the server for authenticating client updates, eliminating the need for external datasets. Our framework is scalable, adaptive, and seamlessly integrates into FL workflows. Extensive experiments on benchmark datasets demonstrate its robust performance against a variety of poisoning attacks, achieving high True Positive Rate (TPR) and True Negative Rate (TNR) of malicious and benign clients, respectively, while maintaining model accuracy. The proposed framework offers a practical and effective solution for securing federated learning systems.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Theoretical Framework for Distribution-Aware Dataset Search</title>
<link>https://arxiv.org/abs/2503.21235</link>
<guid>https://arxiv.org/abs/2503.21235</guid>
<content:encoded><![CDATA[
<div> 

:

PtilePref N  d  $\mathcal{P}$Ptile$\tilde{O}(N)$$\tilde{O}(1+OUT)$PtilePrefOUT j P_j  +2 (0,1)  <div>
arXiv:2503.21235v1 Announce Type: new 
Abstract: Effective data discovery is a cornerstone of modern data-driven decision-making. Yet, identifying datasets with specific distributional characteristics, such as percentiles or preferences, remains challenging. While recent proposals have enabled users to search based on percentile predicates, much of the research in data discovery relies on heuristics. This paper presents the first theoretically backed framework that unifies data discovery under centralized and decentralized settings.
  Let $\mathcal{P}=\{P_1,...,P_N\}$ be a repository of $N$ datasets, where $P_i\subset \mathbb{R}^d$, for $d=O(1)$ . We study the percentile indexing (Ptile) problem and the preference indexing (Pref) problem under the centralized and the federated setting. In the centralized setting we assume direct access to the datasets. In the federated setting we assume access to a synopsis of each dataset. The goal of Ptile is to construct a data structure such that given a predicate (rectangle $R$ and interval $\theta$) report all indexes $J$ such that $j\in J$ iff $|P_j\cap R|/|P_j|\in\theta$. The goal of Pref is to construct a data structure such that given a predicate (vector $v$ and interval $\theta$) report all indexes $J$ such that $j\in J$ iff $\omega(P_j,v)\in \theta$, where $\omega(P_j,v)$ is the inner-product of the $k$-th largest projection of $P_j$ on $v$. We first show that we cannot hope for near-linear data structures with polylogarithmic query time in the centralized setting. Next we show $\tilde{O}(N)$ space data structures that answer Ptile and Pref queries in $\tilde{O}(1+OUT)$ time, where $OUT$ is the output size. Each data structure returns a set of indexes $J$ such that i) for every $P_i$ that satisfies the predicate, $i\in J$ and ii) if $j\in J$ then $P_j$ satisfies the predicate up to an additive error $\varepsilon+2\delta$, where $\varepsilon\in(0,1)$ and $\delta$ is the error of synopses.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Intelligence: When Large AI Models Meet Federated Fine-Tuning and Collaborative Reasoning at the Network Edge</title>
<link>https://arxiv.org/abs/2503.21412</link>
<guid>https://arxiv.org/abs/2503.21412</guid>
<content:encoded><![CDATA[
<div> : (AI), , , , 

<br /><br />:

AI(federated fine-tuning)--AI <div>
arXiv:2503.21412v1 Announce Type: new 
Abstract: Large artificial intelligence (AI) models exhibit remarkable capabilities in various application scenarios, but deploying them at the network edge poses significant challenges due to issues such as data privacy, computational resources, and latency. In this paper, we explore federated fine-tuning and collaborative reasoning techniques to facilitate the implementation of large AI models in resource-constrained wireless networks. Firstly, promising applications of large AI models within specific domains are discussed. Subsequently, federated fine-tuning methods are proposed to adapt large AI models to specific tasks or environments at the network edge, effectively addressing the challenges associated with communication overhead and enhancing communication efficiency. These methodologies follow clustered, hierarchical, and asynchronous paradigms to effectively tackle privacy issues and eliminate data silos. Furthermore, to enhance operational efficiency and reduce latency, efficient frameworks for model collaborative reasoning are developed, which include decentralized horizontal collaboration, cloud-edge-end vertical collaboration, and multi-access collaboration. Next, simulation results demonstrate the effectiveness of our proposed methods in reducing the fine-tuning loss of large AI models across various downstream tasks. Finally, several open challenges and research opportunities are outlined.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Learning-Based Traffic Monitoring With a Swarm of Drones</title>
<link>https://arxiv.org/abs/2503.21433</link>
<guid>https://arxiv.org/abs/2503.21433</guid>
<content:encoded><![CDATA[
<div> : 

:
Q<br /><br /> <div>
arXiv:2503.21433v1 Announce Type: new 
Abstract: Efficient traffic monitoring is crucial for managing urban transportation networks, especially under congested and dynamically changing traffic conditions. Drones offer a scalable and cost-effective alternative to fixed sensor networks. However, deploying fleets of low-cost drones for traffic monitoring poses challenges in adaptability, scalability, and real-time operation. To address these issues, we propose a learning-based framework for decentralized traffic monitoring with drone swarms, targeting the uneven and unpredictable distribution of monitoring needs across urban areas. Our approach introduces a semi-decentralized reinforcement learning model, which trains a single Q-function using the collective experience of the swarm. This model supports full scalability, flexible deployment, and, when hardware allows, the online adaptation of each drone's action-selection mechanism. We first train and evaluate the model in a synthetic traffic environment, followed by a case study using real traffic data from Shenzhen, China, to validate its performance and demonstrate its potential for real-world applications in complex urban monitoring tasks.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unveiling Latent Information in Transaction Hashes: Hypergraph Learning for Ethereum Ponzi Scheme Detection</title>
<link>https://arxiv.org/abs/2503.21463</link>
<guid>https://arxiv.org/abs/2503.21463</guid>
<content:encoded><![CDATA[
<div> EthereumPonzi schemesHyperDet<br /><br />:

HyperDet <div>
arXiv:2503.21463v1 Announce Type: new 
Abstract: With the widespread adoption of Ethereum, financial frauds such as Ponzi schemes have become increasingly rampant in the blockchain ecosystem, posing significant threats to the security of account assets. Existing Ethereum fraud detection methods typically model account transactions as graphs, but this approach primarily focuses on binary transactional relationships between accounts, failing to adequately capture the complex multi-party interaction patterns inherent in Ethereum. To address this, we propose a hypergraph modeling method for the Ponzi scheme detection method in Ethereum, called HyperDet. Specifically, we treat transaction hashes as hyperedges that connect all the relevant accounts involved in a transaction. Additionally, we design a two-step hypergraph sampling strategy to significantly reduce computational complexity. Furthermore, we introduce a dual-channel detection module, including the hypergraph detection channel and the hyper-homo graph detection channel, to be compatible with existing detection methods. Experimental results show that, compared to traditional homogeneous graph-based methods, the hyper-homo graph detection channel achieves significant performance improvements, demonstrating the superiority of hypergraph in Ponzi scheme detection. This research offers innovations for modeling complex relationships in blockchain data.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Static and Repeated Cooperative Games for the Optimization of the AoI in IoT Networks</title>
<link>https://arxiv.org/abs/2503.21633</link>
<guid>https://arxiv.org/abs/2503.21633</guid>
<content:encoded><![CDATA[
<div> 5G6G

:
<br />
5GAoIGTi) ii) NEsNEPoDU <div>
arXiv:2503.21633v1 Announce Type: new 
Abstract: Wireless sensing and the internet of things (IoT) are nowadays pervasive in 5G and beyond networks, and they are expected to play a crucial role in 6G. However, a centralized optimization of a distributed system is not always possible and cost-efficient. In this paper, we analyze a setting in which two sensors collaboratively update a common server seeking to minimize the age of information (AoI) of the latest sample of a common physical process. We consider a distributed and uncoordinated setting where each sensor lacks information about whether the other decides to update the server. This strategic setting is modeled through game theory (GT) and two games are defined: i) a static game of complete information with an incentive mechanism for cooperation, and ii) a repeated game over a finite horizon where the static game is played at each stage. We perform a mathematical analysis of the static game finding three Nash Equilibria (NEs) in pure strategies and one in mixed strategies. A numerical simulation of the repeated game is also presented and novel and valuable insight into the setting is given thanks to the definition of a new metric, the price of delayed updates (PoDU), which shows that the decentralized solution provides results close to the centralized optimum.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Process Channels: A New Layer for Process Enactment Based on Blockchain State Channels</title>
<link>https://arxiv.org/abs/2304.01107</link>
<guid>https://arxiv.org/abs/2304.01107</guid>
<content:encoded><![CDATA[
<div> 

:
OverlayGas <div>
arXiv:2304.01107v3 Announce Type: replace 
Abstract: For the enactment of inter-organizational business processes, blockchain can guarantee the enforcement of process models and the integrity of execution traces. However, existing solutions come with downsides regarding throughput scalability, latency, and suboptimal tradeoffs between confidentiality and transparency. To address these issues, we propose to change the foundation of blockchain-based business process execution: from on-chain smart contracts to state channels, an overlay network on top of a blockchain. State channels allow conducting most transactions off-chain while mostly retaining the core security properties offered by blockchain. Our proposal, process channels, is a model-driven approach to enacting processes on state channels, with the aim to retain the desired blockchain properties while reducing the on-chain footprint as much as possible. We here focus on the principled approach of state channels as a platform, to enable manifold future optimizations in various directions, like latency and confidentiality. We implement our approach prototypical and evaluate it both qualitatively (w.r.t. assumptions and guarantees) and quantitatively (w.r.t. correctness and gas cost). In short, while the initial deployment effort is higher with state channels, it typically pays off after a few process instances; and as long as the new assumptions hold, so do the guarantees.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Contrastive Forward-Forward Algorithm</title>
<link>https://arxiv.org/abs/2409.11593</link>
<guid>https://arxiv.org/abs/2409.11593</guid>
<content:encoded><![CDATA[
<div> FFSCFF

:
FFFFSCFFSCFFSCFFMNISTCIFAR-10STL-10Tiny ImageNetFF <div>
arXiv:2409.11593v2 Announce Type: replace 
Abstract: Agents that operate autonomously benefit from lifelong learning capabilities. However, compatible training algorithms must comply with the decentralized nature of these systems, which imposes constraints on both the parameter counts and the computational resources. The Forward-Forward (FF) algorithm is one of these. FF relies only on feedforward operations, the same used for inference, for optimizing layer-wise objectives. This purely forward approach eliminates the need for transpose operations required in traditional backpropagation. Despite its potential, FF has failed to reach state-of-the-art performance on most standard benchmark tasks, in part due to unreliable negative data generation methods for unsupervised learning.
  In this work, we propose the Self-Contrastive Forward-Forward (SCFF) algorithm, a competitive training method aimed at closing this performance gap. Inspired by standard self-supervised contrastive learning for vision tasks, SCFF generates positive and negative inputs applicable across various datasets. The method demonstrates superior performance compared to existing unsupervised local learning algorithms on several benchmark datasets, including MNIST, CIFAR-10, STL-10, and Tiny ImageNet. We extend FF's application to training recurrent neural networks, expanding its utility to sequential data tasks. These findings pave the way for high-accuracy, real-time learning on resource-constrained edge devices.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Interpretation to Correction: A Decentralized Optimization Framework for Exact Convergence in Federated Learning</title>
<link>https://arxiv.org/abs/2503.20117</link>
<guid>https://arxiv.org/abs/2503.20117</guid>
<content:encoded><![CDATA[
<div> Federated LearningFOCUS

<br /><br />:
FLFedAvgFedAvgFedAvgFOCUSFOCUSPolyak-Lojasiewicz <div>
arXiv:2503.20117v1 Announce Type: new 
Abstract: This work introduces a novel decentralized framework to interpret federated learning (FL) and, consequently, correct the biases introduced by arbitrary client participation and data heterogeneity, which are two typical traits in practical FL. Specifically, we first reformulate the core processes of FedAvg - client participation, local updating, and model aggregation - as stochastic matrix multiplications. This reformulation allows us to interpret FedAvg as a decentralized algorithm. Leveraging the decentralized optimization framework, we are able to provide a concise analysis to quantify the impact of arbitrary client participation and data heterogeneity on FedAvg's convergence point. This insight motivates the development of Federated Optimization with Exact Convergence via Push-pull Strategy (FOCUS), a novel algorithm inspired by the decentralized algorithm that eliminates these biases and achieves exact convergence without requiring the bounded heterogeneity assumption. Furthermore, we theoretically prove that FOCUS exhibits linear convergence (exponential decay) for both strongly convex and non-convex functions satisfying the Polyak-Lojasiewicz condition, regardless of the arbitrary nature of client participation.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unlocking the Value of Decentralized Data: A Federated Dual Learning Approach for Model Aggregation</title>
<link>https://arxiv.org/abs/2503.20138</link>
<guid>https://arxiv.org/abs/2503.20138</guid>
<content:encoded><![CDATA[
<div> (AI)(FL)

<br /><br />:
 <div>
arXiv:2503.20138v1 Announce Type: new 
Abstract: Artificial Intelligence (AI) technologies have revolutionized numerous fields, yet their applications often rely on costly and time-consuming data collection processes. Federated Learning (FL) offers a promising alternative by enabling AI models to be trained on decentralized data where data is scattered across clients (distributed nodes). However, existing FL approaches struggle to match the performance of centralized training due to challenges such as heterogeneous data distribution and communication delays, limiting their potential for breakthroughs. We observe that many real-world use cases involve hybrid data regimes, in which a server (center node) has access to some data while a large amount of data is distributed across associated clients. To improve the utilization of decentralized data under this regime, address data heterogeneity issue, and facilitate asynchronous communication between the server and clients, we propose a dual learning approach that leverages centralized data at the server to guide the merging of model updates from clients. Our method accommodates scenarios where server data is out-of-domain relative to decentralized client data, making it applicable to a wide range of use cases. We provide theoretical analysis demonstrating the faster convergence of our method compared to existing methods. Furthermore, experimental results across various scenarios show that our approach significantly outperforms existing technologies, highlighting its potential to unlock the value of large amounts of decentralized data.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Small-Signal Stability Condition of Inverter-Integrated Power Systems: Closed-Form Expression by Stationary Power Flow Variables</title>
<link>https://arxiv.org/abs/2503.20276</link>
<guid>https://arxiv.org/abs/2503.20276</guid>
<content:encoded><![CDATA[
<div> : 

:<br />
3-bus <div>
arXiv:2503.20276v1 Announce Type: new 
Abstract: This paper shows that a necessary and sufficient condition for the small-signal stability of an inverter-integrated power system can be expressed in terms of semidefinite matrix inequalities determined only by the synchronous reactance of the components, the susceptance matrix of the transmission network, and the stationary values of the power flow distribution. To derive the stability condition, we consider a class of grid-forming inverters corresponding to a singular perturbation of the synchronous generator. The resulting matrix inequality condition, which has twice as many dimensions as the number of buses and is independent of the dynamics of the connected components, is expressed in terms of each component compensating in a decentralized manner for the loss of frequency synchronization caused by the reactive power consumption in the transmission network. A simple numerical example using a 3-bus power system model shows that a grid-forming inverter load improves power system synchronization, while a grid-following inverter load disrupts it.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bounded Exhaustive Random Program Generation for Testing Solidity Compilers and Analyzers</title>
<link>https://arxiv.org/abs/2503.20332</link>
<guid>https://arxiv.org/abs/2503.20332</guid>
<content:encoded><![CDATA[
<div> SolidityErwin<br /><br />:

SolidityErwinErwinSoliditybugErwinsolcsolangSolidityslither23bugSolidityErwinsolc4,58214,737 <div>
arXiv:2503.20332v1 Announce Type: new 
Abstract: Random program generators often exhibit opportunism: they generate programs without a specific focus within the vast search space defined by the programming language. This opportunistic behavior hinders the effective generation of programs that trigger bugs in compilers and analyzers, even when such programs closely resemble those generated. To address this limitation, we propose bounded exhaustive random program generation, a novel method that focuses the search space of program generation with the aim of more quickly identifying bug-triggering programs. Our approach comprises two stages: 1) generating random program templates, which are incomplete test programs containing bug-related placeholders, and 2) conducting a bounded exhaustive enumeration of valid values for each placeholder within these templates. To ensure efficiency, we maintain a solvable constraint set during the template generation phase and then methodically explore all possible values of placeholders within these constraints during the exhaustive enumeration phase. We have implemented this approach for Solidity, a popular smart contract language for the Ethereum blockchain, in a tool named Erwin. Based on a recent study of Solidity compiler bugs, the placeholders used by Erwin relate to language features commonly associated with compiler bugs. Erwin has successfully identified 23 previously unknown bugs across two Solidity compilers, solc and solang, and one Solidity static analyzer, slither. Evaluation results demonstrate that Erwin outperforms state-of-the-art Solidity fuzzers in bug detection and complements developer-written test suites by covering 4,582 edges and 14,737 lines of the solc compiler that were missed by solc unit tests.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CNN+Transformer Based Anomaly Traffic Detection in UAV Networks for Emergency Rescue</title>
<link>https://arxiv.org/abs/2503.20355</link>
<guid>https://arxiv.org/abs/2503.20355</guid>
<content:encoded><![CDATA[
<div> (UAV)(SDN)(CNN)Transformer

:
(SDN)SDN(CNN)TransformerCTranATDCTranATDCNNTransformerLSTM <div>
arXiv:2503.20355v1 Announce Type: new 
Abstract: The unmanned aerial vehicle (UAV) network has gained significant attentions in recent years due to its various applications. However, the traffic security becomes the key threatening public safety issue in an emergency rescue system due to the increasing vulnerability of UAVs to cyber attacks in environments with high heterogeneities. Hence, in this paper, we propose a novel anomaly traffic detection architecture for UAV networks based on the software-defined networking (SDN) framework and blockchain technology. Specifically, SDN separates the control and data plane to enhance the network manageability and security. Meanwhile, the blockchain provides decentralized identity authentication and data security records. Beisdes, a complete security architecture requires an effective mechanism to detect the time-series based abnormal traffic. Thus, an integrated algorithm combining convolutional neural networks (CNNs) and Transformer (CNN+Transformer) for anomaly traffic detection is developed, which is called CTranATD. Finally, the simulation results show that the proposed CTranATD algorithm is effective and outperforms the individual CNN, Transformer, and LSTM algorithms for detecting anomaly traffic.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Reasoning in Blockchain: Foundations, Applications, and Frontiers</title>
<link>https://arxiv.org/abs/2503.20461</link>
<guid>https://arxiv.org/abs/2503.20461</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
 <div>
arXiv:2503.20461v1 Announce Type: new 
Abstract: Blockchain technology has emerged as a transformative paradigm for decentralized and secure data management across diverse application domains, including healthcare, supply chain management, and the Internet of Things. Its core features, such as decentralization, immutability, and auditability, achieved through distributed consensus algorithms and cryptographic techniques, offer significant advantages for multi-stakeholder applications requiring transparency and trust. However, the inherent complexity and security-critical nature of blockchain systems necessitate rigorous analysis and verification to ensure their correctness, reliability, and resilience against potential vulnerabilities.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain-Enabled Framework for Storage and Retrieval of Social Data</title>
<link>https://arxiv.org/abs/2503.20497</link>
<guid>https://arxiv.org/abs/2503.20497</guid>
<content:encoded><![CDATA[
<div> : 

:
Hyper Ledger Fabric (HLF) <div>
arXiv:2503.20497v1 Announce Type: new 
Abstract: The increasing availability of data from diverse sources, including trusted entities such as governments, as well as untrusted crowd-sourced contributors, demands a secure and trustworthy environment for storage and retrieval. Blockchain, as a distributed and immutable ledger, offers a promising solution to address these challenges. This short paper studies the feasibility of a blockchain-based framework for secure data storage and retrieval across trusted and untrusted sources, focusing on provenance, storage mechanisms, and smart contract security. Through initial experiments using Hyper Ledger Fabric (HLF), we evaluate the storage efficiency, scalability, and feasibility of the proposed approach. This study serves as a motivation for future research to develop a comprehensive blockchain-based storage and retrieval framework.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Precise Static Identification of Ethereum Storage Variables</title>
<link>https://arxiv.org/abs/2503.20690</link>
<guid>https://arxiv.org/abs/2503.20690</guid>
<content:encoded><![CDATA[
<div> : VM(EVM)

:
VM(EVM)98.6%92.6%80.8%68.2%<br /><br /> <div>
arXiv:2503.20690v1 Announce Type: new 
Abstract: Smart contracts are small programs that run autonomously on the blockchain, using it as their persistent memory. The predominant platform for smart contracts is the Ethereum VM (EVM). In EVM smart contracts, a problem with significant applications is to identify data structures (in blockchain state, a.k.a. "storage"), given only the deployed smart contract code. The problem has been highly challenging and has often been considered nearly impossible to address satisfactorily. (For reference, the latest state-of-the-art research tool fails to recover nearly all complex data structures and scales to under 50% of contracts.) Much of the complication is that the main on-chain data structures (mappings and arrays) have their locations derived dynamically through code execution.
  We propose sophisticated static analysis techniques to solve the identification of on-chain data structures with extremely high fidelity and completeness. Our analysis scales nearly universally and recovers deep data structures. Our techniques are able to identify the exact types of data structures with 98.6% precision and at least 92.6% recall, compared to a state-of-the-art tool managing 80.8% and 68.2% respectively. Strikingly, the analysis is often more complete than the storage description that the compiler itself produces, with full access to the source code.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain-based Quantum Binary Voting for Decentralized IoT Towards Industry 5.0</title>
<link>https://arxiv.org/abs/2503.20247</link>
<guid>https://arxiv.org/abs/2503.20247</guid>
<content:encoded><![CDATA[
<div> Industry 5.0(IoT)

<br /><br />:
5.0Sybil51%-IBM QuantumSimulaqron <div>
arXiv:2503.20247v1 Announce Type: cross 
Abstract: Industry 5.0 depends on intelligence, automation, and hyperconnectivity operations for effective and sustainable human-machine collaboration. Pivotal technologies like the Internet of Things (IoT) enable this by facilitating connectivity and data-driven decision-making between cyber-physical devices. As IoT devices are prone to cyberattacks, they can use blockchain to improve transparency in the network and prevent data tampering. However, in some cases, even blockchain networks are vulnerable to Sybil and 51% attacks. This has motivated the development of quantum blockchains that are more resilient to such attacks as they leverage post-quantum cryptographic protocols and secure quantum communication channels. In this work, we develop a quantum binary voting algorithm for the IoT-quantum blockchain frameworks that enables inter-connected devices to reach a consensus on the validity of transactions, even in the presence of potential faults or malicious actors. The correctness of the voting protocol is provided in detail, and the results show that it guarantees the achievement of a consensus securely against all kinds of significant external and internal attacks concerning quantum bit commitment, quantum blockchain, and quantum Byzantine agreement. We also provide an implementation of the voting algorithm with the quantum circuits simulated on the IBM Quantum platform and Simulaqron library.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian Approach</title>
<link>https://arxiv.org/abs/2401.08351</link>
<guid>https://arxiv.org/abs/2401.08351</guid>
<content:encoded><![CDATA[
<div> Federated Learning ()Personalized FL ()PAC-PFLPAC-Bayesian generalization bound

<br /><br />:
PAC-PFLPAC-PFLPFLPAC-PFLPAC-PAC-PFL <div>
arXiv:2401.08351v2 Announce Type: replace 
Abstract: Federated Learning (FL) aims to infer a shared model from private and decentralized data stored by multiple clients. Personalized FL (PFL) enhances the model's fit for each client by adapting the global model to the clients. A significant level of personalization is required for highly heterogeneous clients but can be challenging to achieve, especially when clients' datasets are small. To address this issue, we introduce the PAC-PFL framework for PFL of probabilistic models. PAC-PFL infers a shared hyper-posterior and treats each client's posterior inference as the personalization step. Unlike previous PFL algorithms, PAC-PFL does not regularize all personalized models towards a single shared model, thereby greatly enhancing its personalization flexibility. By establishing and minimizing a PAC-Bayesian generalization bound on the average true loss of clients, PAC-PFL effectively mitigates overfitting even in data-poor scenarios. Additionally, PAC-PFL provides generalization bounds for new clients joining later. PAC-PFL achieves accurate and well-calibrated predictions, as supported by our experiments.
]]></content:encoded>
<pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reliability is Blind: Collective Incentives for Decentralized Computing Marketplaces without Individual Behavior Information</title>
<link>https://arxiv.org/abs/2503.19055</link>
<guid>https://arxiv.org/abs/2503.19055</guid>
<content:encoded><![CDATA[
<div> : 

:
 <div>
arXiv:2503.19055v1 Announce Type: new 
Abstract: In decentralized cloud computing marketplaces, ensuring fair and efficient interactions among asset providers and end-users is crucial. A key concern is meeting agreed-upon service-level objectives like the service's reliability. In this decentralized context, traditional mechanisms often fail to address the complexity of task failures, due to limited available and trustworthy insights into these independent actors' individual behavior. This paper proposes a collective incentive mechanism that blindly punishes all involved parties when a task fails. Based on ruin theory, we show that Collective Incentives improve behavior in the marketplace by creating a disincentive for faults and misbehavior even when the parties at fault are unknown, in turn leading to a more robust marketplace. Simulations for small and large pools of marketplace assets show that Collective Incentives enable to meet or exceed a reliability target, i.e., the success-rate of tasks run using marketplace assets, by eventually discarding failure-prone assets while preserving reliable ones.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COoL-TEE: Client-TEE Collaboration for Resilient Distributed Search</title>
<link>https://arxiv.org/abs/2503.19063</link>
<guid>https://arxiv.org/abs/2503.19063</guid>
<content:encoded><![CDATA[
<div> places(IHS)(TEE)COoL-TEE

:
<br />
placesCOoL-TEE(IHS)COoL-TEETEETEECOoL-TEEIHS2%7%DeSearch20% <div>
arXiv:2503.19063v1 Announce Type: new 
Abstract: Current marketplaces rely on search mechanisms with distributed systems but centralized governance, making them vulnerable to attacks, failures, censorship and biases. While search mechanisms with more decentralized governance (e.g., DeSearch) have been recently proposed, these are still exposed to information head-start attacks (IHS) despite the use of Trusted Execution Environments (TEEs). These attacks allow malicious users to gain a head-start over other users for the discovery of new assets in the market, which give them an unfair advantage in asset acquisition. We propose COoL-TEE, a TEE-based provider selection mechanism for distributed search, running in single- or multi-datacenter environments, that is resilient to information head-start attacks. COoL-TEE relies on a Client-TEE collaboration, which enables clients to distinguish between slow providers and malicious ones. Performance evaluations in single- and multi-datacenter environments show that, using COoL-TEE, malicious users respectively gain only up to 2% and 7% of assets more than without IHS, while they can claim 20% or more on top of their fair share in the same conditions with DeSearch.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empirical Evaluation and Scalability Analysis of Proof of Team Sprint (PoTS): Reward Fairness, Energy Efficiency, and System Stability</title>
<link>https://arxiv.org/abs/2503.19289</link>
<guid>https://arxiv.org/abs/2503.19289</guid>
<content:encoded><![CDATA[
<div> Proof of Team Sprint (PoTS), Proof of Work (PoW), , , 

:
Proof of Team Sprint (PoTS)PoTSProof of Work (PoW)PoWPoTS54PoTSPoTS$1/N$6464PoTS160.90PoTS <div>
arXiv:2503.19289v1 Announce Type: new 
Abstract: This paper presents an empirical evaluation of the Proof of Team Sprint (PoTS) consensus algorithm, focusing on reward fairness, energy efficiency, system stability, and scalability. We conducted large-scale simulations comparing PoTS with conventional Proof of Work (PoW) across various team sizes and computational conditions. In PoW, the highest-performance node ranked first in all 100 trials, demonstrating extreme centralization. In contrast, PoTS reduced this dominance: the same node ranked first only 54 times, indicating fairer reward distribution. Statistical analysis showed that as team size increased, skewness and kurtosis of reward distributions decreased, confirming improved equity among participants. PoTS also demonstrated significant energy savings. The total active computation time followed a near $1/N$ scaling trend, reducing energy use by up to 64 times when team size was 64, while preserving consensus integrity. Repeated simulations showed stable reward distributions and system performance, affirming PoTS's robustness. Furthermore, the correlation between performance and reward peaked at 0.90 for team size 16, reflecting an optimal balance between fairness and meritocracy. Overall, PoTS offers a cooperative, energy-efficient alternative to PoW, mitigating centralization risks and promoting equitable participation. These findings validate PoTS as a sustainable and fair consensus mechanism suited for future blockchain systems.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robustness of Proof of Team Sprint (PoTS) Against Attacks: A Simulation-Based Analysis</title>
<link>https://arxiv.org/abs/2503.19293</link>
<guid>https://arxiv.org/abs/2503.19293</guid>
<content:encoded><![CDATA[
<div> : Proof of Team Sprint (PoTS)<br /><br />:<br />
Proof of Team SprintPoTS(N)()PoTS=0.5N180.4%=0.8N=180.47%N=162.79%(NCE)PoTSPoTSPoTS <div>
arXiv:2503.19293v1 Announce Type: new 
Abstract: This study evaluates the robustness of Proof of Team Sprint (PoTS) against adversarial attacks through simulations, focusing on the attacker win rate and computational efficiency under varying team sizes (\( N \)) and attacker ratios (\( \alpha \)). Our results demonstrate that PoTS effectively reduces an attacker's ability to dominate the consensus process. For instance, when \( \alpha = 0.5 \), the attacker win rate decreases from 50.7\% at \( N = 1 \) to below 0.4\% at \( N = 8 \), effectively neutralizing adversarial influence. Similarly, at \( \alpha = 0.8 \), the attacker win rate drops from 80.47\% at \( N = 1 \) to only 2.79\% at \( N = 16 \). In addition to its strong security properties, PoTS maintains high computational efficiency. We introduce the concept of Normalized Computation Efficiency (NCE) to quantify this efficiency gain, showing that PoTS significantly improves resource utilization as team size increases. The results indicate that as \( N \) grows, PoTS not only enhances security but also achieves better computational efficiency due to the averaging effects of execution time variations. These findings highlight PoTS as a promising alternative to traditional consensus mechanisms, offering both robust security and efficient resource utilization. By leveraging team-based block generation and randomized participant reassignment, PoTS provides a scalable and resilient approach to decentralized consensus.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fairness in Proof of Team Sprint (PoTS): Evaluating Reward Distribution Across Performance Levels</title>
<link>https://arxiv.org/abs/2503.19301</link>
<guid>https://arxiv.org/abs/2503.19301</guid>
<content:encoded><![CDATA[
<div> Proof of Team Sprint (PoTS), , , , 

<br /><br />:
Proof of Team Sprint (PoTS)(PoW)PoTSPoTSPoTSPoTS <div>
arXiv:2503.19301v1 Announce Type: new 
Abstract: Blockchain consensus mechanisms must balance security, decentralization, and efficiency while ensuring fair participation. Proof of Team Sprint (PoTS) is a cooperative consensus mechanism designed to address the energy inefficiencies and centralization tendencies of traditional Proof of Work (PoW). Unlike PoW, where rewards disproportionately favor high-performance nodes, PoTS encourages collaboration by forming teams and distributing rewards more equitably among participants. In this study, we evaluate the fairness properties of PoTS by analyzing reward distribution under varying computational power distributions. Through extensive simulations, we compare equal-share allocation and proportional reward allocation, highlighting their impact on decentralization and participation. Our results demonstrate that PoTS significantly reduces reward disparity between high-performance and low-performance nodes, fostering a more inclusive ecosystem. Additionally, we observe that as team sizes increase, the influence of individual computational power is mitigated, allowing lower-performance nodes to contribute meaningfully. Moreover, our findings reveal that the marginal benefit of investing in extremely high-performance hardware diminishes, which discourages centralization and aligns incentives toward sustainable participation. We also discuss the economic implications of PoTS, particularly its potential to reshape blockchain mining strategies by balancing fairness with computational efficiency. These insights contribute to the broader discussion on blockchain fairness and provide a foundation for further research into cooperative consensus mechanisms.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On-Chain Analysis of Smart Contract Dependency Risks on Ethereum</title>
<link>https://arxiv.org/abs/2503.19548</link>
<guid>https://arxiv.org/abs/2503.19548</guid>
<content:encoded><![CDATA[
<div> : 

:
<br />
2024124100110<br />
1. 59%20244<br />
2. 110.001%205050%<br />
3. <br />
4. 

 <div>
arXiv:2503.19548v1 Announce Type: new 
Abstract: In this paper, we present the first large-scale empirical study of smart contract dependencies, analyzing over 41 million contracts and 11 billion interactions on Ethereum up to December 2024. Our results yield four key insights: (1) 59% of contract transactions involve multiple contracts (median of 4 per transaction in 2024) indicating potential smart contract dependency risks; (2) the ecosystem exhibits extreme centralization, with just 11 (0.001%) deployers controlling 20.5 million (50%) of alive contracts, with major risks related to factory contracts and deployer privileges; (3) three most depended-upon contracts are mutable, meaning large parts of the ecosystem rely on contracts that can be altered at any time, which is a significant risk, (4) actual smart contract protocol dependencies are significantly more complex than officially documented, undermining Ethereum's transparency ethos, and creating unnecessary attack surface. Our work provides the first large-scale empirical foundation for understanding smart contract dependency risks, offering crucial insights for developers, users, and security researchers in the blockchain space.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMM-X: A Trustworthy and Interpretable Framework for Federated Multi-Modal Learning in Dynamic Environments</title>
<link>https://arxiv.org/abs/2503.19564</link>
<guid>https://arxiv.org/abs/2503.19564</guid>
<content:encoded><![CDATA[
<div> : 

:
FedMM-XFedMM-X <div>
arXiv:2503.19564v1 Announce Type: new 
Abstract: As artificial intelligence systems increasingly operate in Real-world environments, the integration of multi-modal data sources such as vision, language, and audio presents both unprecedented opportunities and critical challenges for achieving trustworthy intelligence. In this paper, we propose a novel framework that unifies federated learning with explainable multi-modal reasoning to ensure trustworthiness in decentralized, dynamic settings. Our approach, called FedMM-X (Federated Multi-Modal Explainable Intelligence), leverages cross-modal consistency checks, client-level interpretability mechanisms, and dynamic trust calibration to address challenges posed by data heterogeneity, modality imbalance, and out-of-distribution generalization. Through rigorous evaluation across federated multi-modal benchmarks involving vision-language tasks, we demonstrate improved performance in both accuracy and interpretability while reducing vulnerabilities to adversarial and spurious correlations. Further, we introduce a novel trust score aggregation method to quantify global model reliability under dynamic client participation. Our findings pave the way toward developing robust, interpretable, and socially responsible AI systems in Real-world environments.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NickPay, an Auditable, Privacy-Preserving, Nickname-Based Payment System</title>
<link>https://arxiv.org/abs/2503.19872</link>
<guid>https://arxiv.org/abs/2503.19872</guid>
<content:encoded><![CDATA[
<div> NickPayEthereumNicknames for Group Signatures (NGS)

:<br />
NickPayEthereumNickPayNickPayNicknames for Group Signatures (NGS)NGSNickPay <div>
arXiv:2503.19872v1 Announce Type: new 
Abstract: In this paper, we describe the motivation, design, security properties, and a prototype implementation of NickPay, a new privacy-preserving yet auditable payment system built on top of the Ethereum blockchain platform. NickPay offers a strong level of privacy to participants and prevents successive payment transfers from being linked to their actual owners.
  It is providing the transparency that blockchains ensure and at the same time, preserving the possibility for a trusted authority to access sensitive information, e.g., for audit purposes or compliance with financial regulations.
  NickPay builds upon the Nicknames for Group Signatures (NGS) scheme, a new signing system based on dynamic ``nicknames'' for signers that extends the schemes of group signatures and signatures with flexible public keys.
  NGS enables identified group members to expose their flexible public keys, thus allowing direct and natural applications such as auditable private payment systems, NickPay being a blockchain-based prototype of these.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Applications of Certified Randomness</title>
<link>https://arxiv.org/abs/2503.19759</link>
<guid>https://arxiv.org/abs/2503.19759</guid>
<content:encoded><![CDATA[
<div> : certified randomness, quantum computers, security, fairness, applications

<br />
:
 <div>
arXiv:2503.19759v1 Announce Type: cross 
Abstract: Certified randomness can be generated with untrusted remote quantum computers using multiple known protocols, one of which has been recently realized experimentally. Unlike the randomness sources accessible on today's classical computers, the output of these protocols can be certified to be random under certain computational hardness assumptions, with no trust required in the hardware generating the randomness. In this perspective, we explore real-world applications for which the use of certified randomness protocols may lead to improved security and fairness. We identify promising applications in areas including cryptography, differential privacy, financial markets, and blockchain. Through this initial exploration, we hope to shed light on potential applications of certified randomness.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal Sharding for Scalable Blockchains with Deconstructed SMR</title>
<link>https://arxiv.org/abs/2406.08252</link>
<guid>https://arxiv.org/abs/2406.08252</guid>
<content:encoded><![CDATA[
<div> Arete

:
<br />
AreteAreteSMRAreteSMRArete--AreteAWS500Arete <div>
arXiv:2406.08252v4 Announce Type: replace 
Abstract: Sharding is proposed to enhance blockchain scalability. However, a size-security dilemma where every shard must be large enough to ensure its security constrains the efficacy of individual shards and the degree of sharding itself. Most existing sharding solutions therefore rely on either weakening the adversary or making stronger assumptions on network links.
  This paper presents Arete, an optimally scalable blockchain sharding protocol designed to resolve the dilemma based on an observation that if individual shards can tolerate a higher fraction of (Byzantine) faults, we can securely create smaller shards in a larger quantity. The key idea of Arete, therefore, is to improve the security resilience/threshold of shards by dividing the blockchain's State Machine Replication (SMR) process itself. Similar to modern blockchains, Arete first decouples SMR in three steps: transaction dissemination, ordering, and execution. However, unlike other blockchains, for Arete, a single ordering shard performs the ordering task while multiple processing shards perform the dissemination and execution of blocks. As processing shards do not run consensus, each of those can tolerate up to half compromised nodes. Moreover, the SMR process in the ordering shard is lightweight as it only operates on the block digests. Second, Arete considers safety and liveness against Byzantine failures separately to improve the safety threshold further while tolerating temporary liveness violations in a controlled manner. Apart from the creation of more optimal-size shards, such a deconstructed SMR scheme also empowers us to devise a novel certify-order-execute architecture to fully parallelize transaction handling, thereby improving the performance of sharding systems. We implement Arete and evaluate it on a AWS environment by running up to 500 nodes, showing that Arete outperforms the state-of-the-art sharding protocols.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Causal Inference: Multi-Study ATE Estimation beyond Meta-Analysis</title>
<link>https://arxiv.org/abs/2410.16870</link>
<guid>https://arxiv.org/abs/2410.16870</guid>
<content:encoded><![CDATA[
<div> Federated Causal InferenceAverage Treatment Effect (ATE)Plug-in G-FormulaRandomized Controlled Trials (RCTs)asymptotic variance

:
Plug-in G-Formula(ATE)(RCTs) <div>
arXiv:2410.16870v2 Announce Type: replace-cross 
Abstract: We study Federated Causal Inference, an approach to estimate treatment effects from decentralized data across centers. We compare three classes of Average Treatment Effect (ATE) estimators derived from the Plug-in G-Formula, ranging from simple meta-analysis to one-shot and multi-shot federated learning, the latter leveraging the full data to learn the outcome model (albeit requiring more communication). Focusing on Randomized Controlled Trials (RCTs), we derive the asymptotic variance of these estimators for linear models. Our results provide practical guidance on selecting the appropriate estimator for various scenarios, including heterogeneity in sample sizes, covariate distributions, treatment assignment schemes, and center effects. We validate these findings with a simulation study.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhanced Smart Contract Reputability Analysis using Multimodal Data Fusion on Ethereum</title>
<link>https://arxiv.org/abs/2503.17426</link>
<guid>https://arxiv.org/abs/2503.17426</guid>
<content:encoded><![CDATA[
<div> : GANopcode

<br /><br />:
GANopcode97.67%0.9427.25% <div>
arXiv:2503.17426v1 Announce Type: new 
Abstract: The evaluation of smart contract reputability is essential to foster trust in decentralized ecosystems. However, existing methods that rely solely on static code analysis or transactional data, offer limited insight into evolving trustworthiness. We propose a multimodal data fusion framework that integrates static code features with transactional data to enhance reputability prediction. Our framework initially focuses on static code analysis, utilizing GAN-augmented opcode embeddings to address class imbalance, achieving 97.67% accuracy and a recall of 0.942 in detecting illicit contracts, surpassing traditional oversampling methods. This forms the crux of a reputability-centric fusion strategy, where combining static and transactional data improves recall by 7.25% over single-source models, demonstrating robust performance across validation sets. By providing a holistic view of smart contract behaviour, our approach enhances the model's ability to assess reputability, identify fraudulent activities, and predict anomalous patterns. These capabilities contribute to more accurate reputability assessments, proactive risk mitigation, and enhanced blockchain security.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NFTs as a Data-Rich Test Bed: Conspicuous Consumption and its Determinants</title>
<link>https://arxiv.org/abs/2503.17457</link>
<guid>https://arxiv.org/abs/2503.17457</guid>
<content:encoded><![CDATA[
<div> NFTwagon

:
NFTNFTwagonNFTNFTwagonNFTNFT <div>
arXiv:2503.17457v1 Announce Type: new 
Abstract: Conspicuous consumption occurs when a consumer derives value from a good based on its social meaning as a signal of wealth, taste, and/or community affiliation. Common conspicuous goods include designer footwear, country club memberships, and artwork; conspicuous goods also exist in the digital sphere, with non-fungible tokens (NFTs) as a prominent example. The NFT market merits deeper study for two key reasons: first, it is poorly understood relative to its economic scale; and second, it is unusually amenable to analysis because NFT transactions are publicly available on the blockchain, making them useful as a test bed for conspicuous consumption dynamics. This paper introduces a model that incorporates two previously identified elements of conspicuous consumption: the \emph{bandwagon effect} (goods increase in value as they become more popular) and the \emph{snob effect} (goods increase in value as they become rarer). Our model resolves the apparent tension between these two effects, exhibiting net complementarity between others' and one's own conspicuous consumption. We also introduce a novel dataset combining NFT transactions with embeddings of the corresponding NFT images computed using an off-the-shelf vision transformer architecture. We use our dataset to validate the model, showing that the bandwagon effect raises an NFT collection's value as more consumers join, while the snob effect drives consumers to seek rarer NFTs within a given collection.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation</title>
<link>https://arxiv.org/abs/2503.17683</link>
<guid>https://arxiv.org/abs/2503.17683</guid>
<content:encoded><![CDATA[
<div> : Decentralized Multi-Source Domain Adaptation, Federated Dataset Dictionary Learning, Wasserstein barycenters, decentralization, privacy

:
Decentralized Multi-Source Domain AdaptationFederated Dataset Dictionary LearningFedDaDiLWasserstein<br /><br /> <div>
arXiv:2503.17683v1 Announce Type: new 
Abstract: Decentralized Multi-Source Domain Adaptation (DMSDA) is a challenging task that aims to transfer knowledge from multiple related and heterogeneous source domains to an unlabeled target domain within a decentralized framework. Our work tackles DMSDA through a fully decentralized federated approach. In particular, we extend the Federated Dataset Dictionary Learning (FedDaDiL) framework by eliminating the necessity for a central server. FedDaDiL leverages Wasserstein barycenters to model the distributional shift across multiple clients, enabling effective adaptation while preserving data privacy. By decentralizing this framework, we enhance its robustness, scalability, and privacy, removing the risk of a single point of failure. We compare our method to its federated counterpart and other benchmark algorithms, showing that our approach effectively adapts source domains to an unlabeled target domain in a fully decentralized manner.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligence Sequencing and the Path-Dependence of Intelligence Evolution: AGI-First vs. DCI-First as Irreversible Attractors</title>
<link>https://arxiv.org/abs/2503.17688</link>
<guid>https://arxiv.org/abs/2503.17688</guid>
<content:encoded><![CDATA[
<div> : , , , , 

:
AGIDCIAGIDCIAIAGIAGIDCIDCIvs. <div>
arXiv:2503.17688v1 Announce Type: new 
Abstract: The trajectory of intelligence evolution is often framed around the emergence of artificial general intelligence (AGI) and its alignment with human values. This paper challenges that framing by introducing the concept of intelligence sequencing: the idea that the order in which AGI and decentralized collective intelligence (DCI) emerge determines the long-term attractor basin of intelligence. Using insights from dynamical systems, evolutionary game theory, and network models, it argues that intelligence follows a path-dependent, irreversible trajectory. Once development enters a centralized (AGI-first) or decentralized (DCI-first) regime, transitions become structurally infeasible due to feedback loops and resource lock-in. Intelligence attractors are modeled in functional state space as the co-navigation of conceptual and adaptive fitness spaces. Early-phase structuring constrains later dynamics, much like renormalization in physics. This has major implications for AI safety: traditional alignment assumes AGI will emerge and must be controlled after the fact, but this paper argues that intelligence sequencing is more foundational. If AGI-first architectures dominate before DCI reaches critical mass, hierarchical monopolization and existential risk become locked in. If DCI-first emerges, intelligence stabilizes around decentralized cooperative equilibrium. The paper further explores whether intelligence structurally biases itself toward an attractor based on its self-modeling method -- externally imposed axioms (favoring AGI) vs. recursive internal visualization (favoring DCI). Finally, it proposes methods to test this theory via simulations, historical lock-in case studies, and intelligence network analysis. The findings suggest that intelligence sequencing is a civilizational tipping point: determining whether the future is shaped by unbounded competition or unbounded cooperation.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CRDT-Based Game State Synchronization in Peer-to-Peer VR</title>
<link>https://arxiv.org/abs/2503.17826</link>
<guid>https://arxiv.org/abs/2503.17826</guid>
<content:encoded><![CDATA[
<div> : (CRDTs)

<br /><br />
:
(CRDTs)P2P <div>
arXiv:2503.17826v1 Announce Type: new 
Abstract: Virtual presence demands ultra-low latency, a factor that centralized architectures, by their nature, cannot minimize. Local peer-to-peer architectures offer a compelling alternative, but also pose unique challenges in terms of network infrastructure. This paper introduces a prototype leveraging Conflict-Free Replicated Data Types (CRDTs) to enable real-time collaboration in a shared virtual environment. Using this prototype, we investigate latency, synchronization, and the challenges of decentralized coordination in dynamic non-Byzantine contexts. We aim to question prevailing assumptions about decentralized architectures and explore the practical potential of P2P in advancing virtual presence. This work challenges the constraints of mediated networks and highlights the potential of decentralized architectures to redefine collaboration and interaction in digital spaces.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Blockchain-based Access Control for the Internet of Things</title>
<link>https://arxiv.org/abs/2503.17873</link>
<guid>https://arxiv.org/abs/2503.17873</guid>
<content:encoded><![CDATA[
<div> (IoT)(ABAC)<br /><br />:<br />
IoTDBC-ABACHyperledger FabricHyperledger CaliperDBC-ABAC <div>
arXiv:2503.17873v1 Announce Type: new 
Abstract: Recently, the Internet of Things (IoT) environment has become increasingly fertile for malicious users to break the security and privacy of IoT users. Access control is a paramount necessity to forestall illicit access. Traditional access control mechanisms are designed and managed in a centralized manner, thus rendering them unfit for decentralized IoT systems. To address the distributed IoT environment, blockchain is viewed as a promising decentralised data management technology. In this thesis, we investigate the state-of-art works in the domain of distributed blockchain-based access control. We establish the most important requirements and assess related works against them. We propose a Distributed Blockchain and Attribute-based Access Control model for IoT entitled (DBC-ABAC) that merges blockchain technology with the attribute-based access control model. A proof-of-concept implementation is presented using Hyperledger Fabric. To validate performance, we experimentally evaluate and compare our work with other recent works using Hyperledger Caliper tool. Results indicate that the proposed model surpasses other works in terms of latency and throughput with considerable efficiency.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Navigation of a Cable-Towed Load using Quadrupedal Robot Team via MARL</title>
<link>https://arxiv.org/abs/2503.18221</link>
<guid>https://arxiv.org/abs/2503.18221</guid>
<content:encoded><![CDATA[
<div> MARL

<br />

MARLCTDEMARLMARL <div>
arXiv:2503.18221v1 Announce Type: new 
Abstract: This work addresses the challenge of enabling a team of quadrupedal robots to collaboratively tow a cable-connected load through cluttered and unstructured environments while avoiding obstacles. Leveraging cables allows the multi-robot system to navigate narrow spaces by maintaining slack when necessary. However, this introduces hybrid physical interactions due to alternating taut and slack states, with computational complexity that scales exponentially as the number of agents increases. To tackle these challenges, we developed a scalable and decentralized system capable of dynamically coordinating a variable number of quadrupedal robots while managing the hybrid physical interactions inherent in the load-towing task. At the core of this system is a novel multi-agent reinforcement learning (MARL)-based planner, designed for decentralized coordination. The MARL-based planner is trained using a centralized training with decentralized execution (CTDE) framework, enabling each robot to make decisions autonomously using only local (ego) observations. To accelerate learning and ensure effective collaboration across varying team sizes, we introduce a tailored training curriculum for MARL. Experimental results highlight the flexibility and scalability of the framework, demonstrating successful deployment with one to four robots in real-world scenarios and up to twelve robots in simulation. The decentralized planner maintains consistent inference times, regardless of the team size. Additionally, the proposed system demonstrates robustness to environment perturbations and adaptability to varying load weights. This work represents a step forward in achieving flexible and efficient multi-legged robotic collaboration in complex and real-world environments.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Curationary Tale: Logarithmic Regret in DeFi Lending via Dynamic Pricing</title>
<link>https://arxiv.org/abs/2503.18237</link>
<guid>https://arxiv.org/abs/2503.18237</guid>
<content:encoded><![CDATA[
<div> : DeFi

:
(DeFi)2020DeFi1000AaveMorphoEulerDeFi$T$$O(\log T)$$\Omega(\sqrt{T})$ <div>
arXiv:2503.18237v1 Announce Type: new 
Abstract: Lending within decentralized finance (DeFi) has facilitated over $100 billion of loans since 2020. A long-standing inefficiency in DeFi lending protocols such as Aave is the use of static pricing mechanisms for loans. These mechanisms have been shown to maximize neither welfare nor revenue for participants in DeFi lending protocols. Recently, adaptive supply models pioneered by Morpho and Euler have become a popular means of dynamic pricing for loans. This pricing is facilitated by agents known as curators, who bid to match supply and demand. We construct and analyze an online learning model for static and dynamic pricing models within DeFi lending. We show that when loans are small and have a short duration relative to an observation time $T$, adaptive supply models achieve $O(\log T)$ regret, while static models cannot achieve better than $\Omega(\sqrt{T})$ regret. We then study competitive behavior between curators, demonstrating that adaptive supply mechanisms maximize revenue and welfare for both borrowers and lenders.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Risk Management for Distributed Arbitrage Systems: Integrating Artificial Intelligence</title>
<link>https://arxiv.org/abs/2503.18265</link>
<guid>https://arxiv.org/abs/2503.18265</guid>
<content:encoded><![CDATA[
<div> (AI)DeFi

:<br />
AIDeFiAaveAI <div>
arXiv:2503.18265v1 Announce Type: new 
Abstract: Effective risk management solutions become absolutely crucial when financial markets embrace distributed technology and decentralized financing (DeFi). This study offers a thorough survey and comparative analysis of the integration of artificial intelligence (AI) in risk management for distributed arbitrage systems. We examine several modern caching techniques namely in memory caching, distributed caching, and proxy caching and their functions in enhancing performance in decentralized settings. Through literature review we examine the utilization of AI techniques for alleviating risks related to market volatility, liquidity challenges, operational failures, regulatory compliance, and security threats. This comparison research evaluates various case studies from prominent DeFi technologies, emphasizing critical performance metrics like latency reduction, load balancing, and system resilience. Additionally, we examine the problems and trade offs associated with these technologies, emphasizing their effects on consistency, scalability, and fault tolerance. By meticulously analyzing real world applications, specifically centering on the Aave platform as our principal case study, we illustrate how the purposeful amalgamation of AI with contemporary caching methodologies has revolutionized risk management in distributed arbitrage systems.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ED-DAO: Energy Donation Algorithms based on Decentralized Autonomous Organization</title>
<link>https://arxiv.org/abs/2503.18424</link>
<guid>https://arxiv.org/abs/2503.18424</guid>
<content:encoded><![CDATA[
<div> DAOHED

<br /><br />:
ED-DAOHEDHEDP2DUG2DP2PDUG2DP2DP2PDHED0.43%64 <div>
arXiv:2503.18424v1 Announce Type: new 
Abstract: Energy is a fundamental component of modern life, driving nearly all aspects of daily activities. As such, the inability to access energy when needed is a significant issue that requires innovative solutions. In this paper, we propose ED-DAO, a novel fully transparent and community-driven decentralized autonomous organization (DAO) designed to facilitate energy donations. We analyze the energy donation process by exploring various approaches and categorizing them based on both the source of donated energy and funding origins. We propose a novel Hybrid Energy Donation (HED) algorithm, which enables contributions from both external and internal donors. External donations are payments sourced from entities such as charities and organizations, where energy is sourced from the utility grid and prosumers. Internal donations, on the other hand, come from peer contributors with surplus energy. HED prioritizes donations in the following sequence: peer-sourced energy (P2D), utilitygrid-sourced energy (UG2D), and direct energy donations by peers (P2PD). By merging these donation approaches, the HED algorithm increases the volume of donated energy, providing a more effective means to address energy poverty. Experiments were conducted on a dataset to evaluate the effectiveness of the proposed method. The results showed that HED increased the total donated energy by at least 0.43% (64 megawatts) compared to the other algorithms (UG2D, P2D, and P2PD).
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributionally Robust Federated Learning: An ADMM Algorithm</title>
<link>https://arxiv.org/abs/2503.18436</link>
<guid>https://arxiv.org/abs/2503.18436</guid>
<content:encoded><![CDATA[
<div> Federated LearningDRFLADMM

<br /><br />
DRFLDRFLDRFLADMMDRFL <div>
arXiv:2503.18436v1 Announce Type: new 
Abstract: Federated learning (FL) aims to train machine learning (ML) models collaboratively using decentralized data, bypassing the need for centralized data aggregation. Standard FL models often assume that all data come from the same unknown distribution. However, in practical situations, decentralized data frequently exhibit heterogeneity. We propose a novel FL model, Distributionally Robust Federated Learning (DRFL), that applies distributionally robust optimization to overcome the challenges posed by data heterogeneity and distributional ambiguity. We derive a tractable reformulation for DRFL and develop a novel solution method based on the alternating direction method of multipliers (ADMM) algorithm to solve this problem. Our experimental results demonstrate that DRFL outperforms standard FL models under data heterogeneity and ambiguity.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Multi-Robot Coordination through Locality-Based Factorized Multi-Agent Actor-Critic Algorithm</title>
<link>https://arxiv.org/abs/2503.18816</link>
<guid>https://arxiv.org/abs/2503.18816</guid>
<content:encoded><![CDATA[
<div> Actor-CriticFACMACLoc-FACMAC

<br />
Actor-CriticLoc-FACMACFACMACLoc-FACMACLoc-FACMACLOMAQFACMACQMIXMARLLoc-FACMAC108%Actor-Critic <div>
arXiv:2503.18816v1 Announce Type: new 
Abstract: In this work, we present a novel cooperative multi-agent reinforcement learning method called \textbf{Loc}ality based \textbf{Fac}torized \textbf{M}ulti-Agent \textbf{A}ctor-\textbf{C}ritic (Loc-FACMAC). Existing state-of-the-art algorithms, such as FACMAC, rely on global reward information, which may not accurately reflect the quality of individual robots' actions in decentralized systems. We integrate the concept of locality into critic learning, where strongly related robots form partitions during training. Robots within the same partition have a greater impact on each other, leading to more precise policy evaluation. Additionally, we construct a dependency graph to capture the relationships between robots, facilitating the partitioning process. This approach mitigates the curse of dimensionality and prevents robots from using irrelevant information. Our method improves existing algorithms by focusing on local rewards and leveraging partition-based learning to enhance training efficiency and performance. We evaluate the performance of Loc-FACMAC in three environments: Hallway, Multi-cartpole, and Bounded-Cooperative-Navigation. We explore the impact of partition sizes on the performance and compare the result with baseline MARL algorithms such as LOMAQ, FACMAC, and QMIX. The experiments reveal that, if the locality structure is defined properly, Loc-FACMAC outperforms these baseline algorithms up to 108\%, indicating that exploiting the locality structure in the actor-critic framework improves the MARL performance.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamics of Insect Paraintelligence: How a Mindless Colony of Ants Meaningfully Moves a Beetle</title>
<link>https://arxiv.org/abs/2503.18858</link>
<guid>https://arxiv.org/abs/2503.18858</guid>
<content:encoded><![CDATA[
<div> : Vector Dissipation of Randomness (VDR), , , , ant and beetle

:
(Vector Dissipation of Randomness, VDR)VDRVDRVDRAnt and Beetle <div>
arXiv:2503.18858v1 Announce Type: cross 
Abstract: In this work, a new concept called Vector Dissipation of Randomness (VDR) is developed and formalized. It describes the mechanism by which complex multicomponent systems transition from chaos to order through the filtering of random directions, accumulation of information in the environment, and self-organization of agents. VDR explains how individual random strategies can evolve into collective goaldirected behavior, leading to the emergence of an ordered structure without centralized control. To test the proposed model, a numerical simulation of the "ant and beetle" system was conducted, in which agents (ants) randomly choose movement directions, but through feedback mechanisms and filtering of weak strategies, they form a single coordinated vector of the beetles movement. VDR is a universal mechanism applicable to a wide range of self-organizing systems, including biological populations, decentralized technological networks, sociological processes, and artificial intelligence algorithms. For the first time, an equation of the normalized emergence function in the processing of vector dissipation of randomness in the Ant and Beetle system has been formulated. The concept of paraintelligence was introduced for the first time. Insect paraintelligence is interpreted as a rational functionality that is close to or equivalent to intelligent activity in the absence of reflexive consciousness and selfawareness.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RouTEE: A Secure Payment Network Routing Hub using Trusted Execution Environments</title>
<link>https://arxiv.org/abs/2012.04254</link>
<guid>https://arxiv.org/abs/2012.04254</guid>
<content:encoded><![CDATA[
<div> : cryptocurrencies, off-chain transactions, payment channels, multi-hop payments, RouTEE

<br /><br />:
RouTEEoff-chainpayment channelsmulti-hopRouTEETEEsRouTEERouTEERouTEELightning Network <div>
arXiv:2012.04254v2 Announce Type: replace 
Abstract: Cryptocurrencies such as Bitcoin and Ethereum have made payment transactions possible without a trusted third party, but they have a scalability issue due to their consensus mechanisms. Payment networks have emerged to overcome this limitation by executing transactions outside of the blockchain, which is why these are referred to as off-chain transactions. In order to establish a payment channel between two users, the users lock their deposits in the blockchain, and then they can pay each other through the channel. Furthermore, payment networks support multi-hop payments that allow users to transfer their balances to other users who are connected to them via multiple channels. However, multi-hop payments are hard to be accomplished, as they are heavily dependent on routing users on a payment path from a sender to a receiver. Although routing hubs can make multi-hop payments more practical and efficient, they need a lot of collateral locked for a long period and have privacy issues in terms of payment history.
  We propose RouTEE, a secure payment routing hub that is fully feasible without the hub's deposit. Unlike existing payment networks, RouTEE provides high balance liquidity, and details about payments are concealed from hosts by leveraging trusted execution environments (TEEs). RouTEE is designed to make rational hosts behave honestly, by introducing a new routing fee scheme and a secure settlement method. Moreover, users do not need to monitor the blockchain in real-time or run full nodes. They can participate in RouTEE by simply verifying block headers through light clients; furthermore, having only one channel with RouTEE is sufficient to interact with other users. Our implementation demonstrates that RouTEE is highly efficient and outperforms Lightning Network that is the state-of-the-art payment network.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring and Enhancing Placement of IDS in RPL: A Federated Learning-based Approach</title>
<link>https://arxiv.org/abs/2303.16561</link>
<guid>https://arxiv.org/abs/2303.16561</guid>
<content:encoded><![CDATA[
<div> : RPL

:
RPLRPLIDSRPLFLFLIDSIDFL <div>
arXiv:2303.16561v2 Announce Type: replace 
Abstract: In RPL security, intrusion detection (ID) plays a vital role, especially given its susceptibility to attacks, particularly those carried out by insider threats. While numerous studies in the literature have proposed intrusion detection systems (IDS) utilizing diverse techniques, the placement of such systems within RPL topology remains largely unexplored. This study aims to address this gap by rigorously evaluating three intrusion detection architectures, considering central and distributed placement, across multiple criteria including effectiveness, cost, privacy, and security. The findings underscore the significant impact of attacker position and the proximity of IDS to attackers on detection outcomes. Hence, alongside the evaluation of traditional intrusion detection architectures, this study explores the use of federated learning (FL) for improving intrusion detection within RPL networks. FL's decentralized model training approach effectively addresses the impact of attacker position on IDS performance by ensuring the collection of relevant information from nodes regardless of their proximity to potential attackers. Moreover, this approach not only mitigates security concerns but also minimizes communication overhead among ID nodes. Consequently, FL reduces the need for extensive data transfer, thus mitigating the impact of packet loss and latency inherent in lossy networks. Additionally, the study investigates the effect of local data sharing on FL performance, clarifying the balance between effectiveness and security.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Socially Beneficial Metaverse: Framework, Technologies, Applications, and Challenges</title>
<link>https://arxiv.org/abs/2310.17260</link>
<guid>https://arxiv.org/abs/2310.17260</guid>
<content:encoded><![CDATA[
<div> : 

:
SB-MetaverseSB-Metaverse <div>
arXiv:2310.17260v2 Announce Type: replace 
Abstract: In recent years, the maturation of emerging technologies such as Virtual Reality, Digital twins, and Blockchain has accelerated the realization of the metaverse. As a virtual world independent of the real world, the metaverse will provide users with a variety of virtual activities that bring great convenience to society. In addition, the metaverse can facilitate digital twins, which offers transformative possibilities for the industry. Thus, the metaverse has attracted the attention of the industry, and a huge amount of capital is about to be invested. However, the development of the metaverse is still in its infancy and little research has been undertaken so far. We describe the development of the metaverse. Next, we introduce the architecture of the socially beneficial metaverse (SB-Metaverse) and we focus on the technologies that support the operation of SB-Metaverse. In addition, we also present the applications of SB-Metaverse. Finally, we discuss several challenges faced by SB-Metaverse which must be addressed in the future.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models for Blockchain Security: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2403.14280</link>
<guid>https://arxiv.org/abs/2403.14280</guid>
<content:encoded><![CDATA[
<div> :  (LLMs),  (BS), , , 

:
LLMsLLM4BSLLMsLLMsLLMsLLM4BS <div>
arXiv:2403.14280v5 Announce Type: replace 
Abstract: Large Language Models (LLMs) have emerged as powerful tools across various domains within cyber security. Notably, recent studies are increasingly exploring LLMs applied to the context of blockchain security (BS). However, there remains a gap in a comprehensive understanding regarding the full scope of applications, impacts, and potential constraints of LLMs on blockchain security. To fill this gap, we undertake a literature review focusing on the studies that apply LLMs in blockchain security (LLM4BS).
  Our study aims to comprehensively analyze and understand existing research, and elucidate how LLMs contribute to enhancing the security of blockchain systems. Through a thorough examination of existing literature, we delve into the integration of LLMs into various aspects of blockchain security. We explore the mechanisms through which LLMs can bolster blockchain security, including their applications in smart contract auditing, transaction anomaly detection, vulnerability repair, program analysis of smart contracts, and serving as participants in the cryptocurrency community. Furthermore, we assess the challenges and limitations associated with leveraging LLMs for enhancing blockchain security, considering factors such as scalability, privacy concerns, and ethical concerns. Our thorough review sheds light on the opportunities and potential risks of tasks on LLM4BS, providing valuable insights for researchers, practitioners, and policymakers alike.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Infighting in the Dark: Multi-Label Backdoor Attack in Federated Learning</title>
<link>https://arxiv.org/abs/2409.19601</link>
<guid>https://arxiv.org/abs/2409.19601</guid>
<content:encoded><![CDATA[
<div> : Federated Learning, Multi-Label Backdoor Attack, Non-cooperative, Adversarial Adaptation, Constrained Optimization

<br /><br />:

Federated Learning()(Multi-Label Backdoor Attack, MBA)MirageFLMBAMirage(In-Distribution, ID)IDIDMirage900ASR97%90% <div>
arXiv:2409.19601v3 Announce Type: replace 
Abstract: Federated Learning (FL), a privacy-preserving decentralized machine learning framework, has been shown to be vulnerable to backdoor attacks. Current research primarily focuses on the Single-Label Backdoor Attack (SBA), wherein adversaries share a consistent target. However, a critical fact is overlooked: adversaries may be non-cooperative, have distinct targets, and operate independently, which exhibits a more practical scenario called Multi-Label Backdoor Attack (MBA). Unfortunately, prior works are ineffective in the MBA scenario since non-cooperative attackers exclude each other. In this work, we conduct an in-depth investigation to uncover the inherent constraints of the exclusion: similar backdoor mappings are constructed for different targets, resulting in conflicts among backdoor functions. To address this limitation, we propose Mirage, the first non-cooperative MBA strategy in FL that allows attackers to inject effective and persistent backdoors into the global model without collusion by constructing in-distribution (ID) backdoor mapping. Specifically, we introduce an adversarial adaptation method to bridge the backdoor features and the target distribution in an ID manner. Additionally, we further leverage a constrained optimization method to ensure the ID mapping survives in the global training dynamics. Extensive evaluations demonstrate that Mirage outperforms various state-of-the-art attacks and bypasses existing defenses, achieving an average ASR greater than 97\% and maintaining over 90\% after 900 rounds. This work aims to alert researchers to this potential threat and inspire the design of effective defense mechanisms. Code has been made open-source.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On-device Federated Learning in Smartphones for Detecting Depression from Reddit Posts</title>
<link>https://arxiv.org/abs/2410.13709</link>
<guid>https://arxiv.org/abs/2410.13709</guid>
<content:encoded><![CDATA[
<div> :(FL)

:<br />
FLGRURNNLSTMRedditFLtokenizerFLFL <div>
arXiv:2410.13709v2 Announce Type: replace 
Abstract: Depression detection using deep learning models has been widely explored in previous studies, especially due to the large amounts of data available from social media posts. These posts provide valuable information about individuals' mental health conditions and can be leveraged to train models and identify patterns in the data. However, distributed learning approaches have not been extensively explored in this domain. In this study, we adopt Federated Learning (FL) to facilitate decentralized training on smartphones while protecting user data privacy. We train three neural network architectures--GRU, RNN, and LSTM on Reddit posts to detect signs of depression and evaluate their performance under heterogeneous FL settings. To optimize the training process, we leverage a common tokenizer across all client devices, which reduces the computational load. Additionally, we analyze resource consumption and communication costs on smartphones to assess their impact in a real-world FL environment. Our experimental results demonstrate that the federated models achieve comparable performance to the centralized models. This study highlights the potential of FL for decentralized mental health prediction by providing a secure and efficient model training process on edge devices.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Incremental Named Entity Recognition</title>
<link>https://arxiv.org/abs/2411.11623</link>
<guid>https://arxiv.org/abs/2411.11623</guid>
<content:encoded><![CDATA[
<div> : Federated Incremental NER, Local-Global Forgetting Defense (LGFD), , , 

:
(Federated Incremental NER)Local-Global Forgetting Defense (LGFD)LGFDLGFDLGFD <div>
arXiv:2411.11623v2 Announce Type: replace 
Abstract: Federated Named Entity Recognition (FNER) boosts model training within each local client by aggregating the model updates of decentralized local clients, without sharing their private data. However, existing FNER methods assume fixed entity types and local clients in advance, leading to their ineffectiveness in practical applications. In a more realistic scenario, local clients receive new entity types continuously, while new local clients collecting novel data may irregularly join the global FNER training. This challenging setup, referred to here as Federated Incremental NER, renders the global model suffering from heterogeneous forgetting of old entity types from both intra-client and inter-client perspectives. To overcome these challenges, we propose a Local-Global Forgetting Defense (LGFD) model. Specifically, to address intra-client forgetting, we develop a structural knowledge distillation loss to retain the latent space's feature structure and a pseudo-label-guided inter-type contrastive loss to enhance discriminative capability over different entity types, effectively preserving previously learned knowledge within local clients. To tackle inter-client forgetting, we propose a task switching monitor that can automatically identify new entity types under privacy protection and store the latest old global model for knowledge distillation and pseudo-labeling. Experiments demonstrate significant improvement of our LGFD model over comparison methods.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed LLMs and Multimodal Large Language Models: A Survey on Advances, Challenges, and Future Directions</title>
<link>https://arxiv.org/abs/2503.16585</link>
<guid>https://arxiv.org/abs/2503.16585</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:
 <div>
arXiv:2503.16585v1 Announce Type: new 
Abstract: Language models (LMs) are machine learning models designed to predict linguistic patterns by estimating the probability of word sequences based on large-scale datasets, such as text. LMs have a wide range of applications in natural language processing (NLP) tasks, including autocomplete and machine translation. Although larger datasets typically enhance LM performance, scalability remains a challenge due to constraints in computational power and resources. Distributed computing strategies offer essential solutions for improving scalability and managing the growing computational demand. Further, the use of sensitive datasets in training and deployment raises significant privacy concerns. Recent research has focused on developing decentralized techniques to enable distributed training and inference while utilizing diverse computational resources and enabling edge AI. This paper presents a survey on distributed solutions for various LMs, including large language models (LLMs), vision language models (VLMs), multimodal LLMs (MLLMs), and small language models (SLMs). While LLMs focus on processing and generating text, MLLMs are designed to handle multiple modalities of data (e.g., text, images, and audio) and to integrate them for broader applications. To this end, this paper reviews key advancements across the MLLM pipeline, including distributed training, inference, fine-tuning, and deployment, while also identifying the contributions, limitations, and future areas of improvement. Further, it categorizes the literature based on six primary focus areas of decentralization. Our analysis describes gaps in current methodologies for enabling distributed solutions for LMs and outline future research directions, emphasizing the need for novel solutions to enhance the robustness and applicability of distributed LMs.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoBRA: A Universal Strategyproof Confirmation Protocol for Quorum-based Proof-of-Stake Blockchains</title>
<link>https://arxiv.org/abs/2503.16783</link>
<guid>https://arxiv.org/abs/2503.16783</guid>
<content:encoded><![CDATA[
<div> quorum-based State Machine Replication (SMR)Proof-of-Stake (PoS)hybridimpossibility

:
Quorum(SMR)(PoS)<br />
1. 1/3QuorumSMR<br />
2. 2/3SMR

SMRSMRCosmos5/6PoS <div>
arXiv:2503.16783v1 Announce Type: new 
Abstract: We present a formal analysis of quorum-based State Machine Replication (SMR) protocols in Proof-of-Stake (PoS) systems under a hybrid threat model comprising honest, Byzantine, and rational validators. Our analysis of traditional quorum-based protocols establishes two fundamental impossibility results: (1) in partially synchronous networks, no quorum-based protocol can achieve SMR when rational and Byzantine validators comprise more than $1/3$ of participants, and (2) in synchronous networks, SMR remains impossible when rational and Byzantine validators comprise $2/3$ or more of participants.
  To overcome these limitations, we propose two complementary solutions in our hybrid model. First, we introduce a protocol that enforces a bound on the volume of the total transacted amount that is finalized within any time window $\Delta$ and prove that this bound is necessary for secure SMR protocols in our model. Second, we present the \emph{strongest chain rule}, which enables efficient finalization of transactions when the majority of honest participants provably support the SMR execution. Through empirical analysis of Ethereum and Cosmos networks, we demonstrate that validator participation consistently exceeds the required ${5}/{6}$ threshold, establishing the practical feasibility of our solution in production PoS systems.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Thorough Assessment of the Non-IID Data Impact in Federated Learning</title>
<link>https://arxiv.org/abs/2503.17070</link>
<guid>https://arxiv.org/abs/2503.17070</guid>
<content:encoded><![CDATA[
<div> federated learning, non-IID, , Hellinger Distance, 

:<br />
(federated learning)(non-IID)Hellinger Distance-IIDFL-IIDFLHellinger DistanceFLFLFL-IID <div>
arXiv:2503.17070v1 Announce Type: new 
Abstract: Federated learning (FL) allows collaborative machine learning (ML) model training among decentralized clients' information, ensuring data privacy. The decentralized nature of FL deals with non-independent and identically distributed (non-IID) data. This open problem has notable consequences, such as decreased model performance and more significant convergence times. Despite its importance, experimental studies systematically addressing all types of data heterogeneity (a.k.a. non-IIDness) remain scarce. We aim to fill this gap by assessing and quantifying the non-IID effect through a thorough empirical analysis. We use the Hellinger Distance (HD) to measure differences in distribution among clients. Our study benchmarks four state-of-the-art strategies for handling non-IID data, including label, feature, quantity, and spatiotemporal skewness, under realistic and controlled conditions. This is the first comprehensive analysis of the spatiotemporal skew effect in FL. Our findings highlight the significant impact of label and spatiotemporal skew non-IID types on FL model performance, with notable performance drops occurring at specific HD thresholds. Additionally, the FL performance is heavily affected mainly when the non-IIDness is extreme. Thus, we provide recommendations for FL research to tackle data heterogeneity effectively. Our work represents the most extensive examination of non-IIDness in FL, offering a robust foundation for future research.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LoGoFair: Post-Processing for Local and Global Fairness in Federated Learning</title>
<link>https://arxiv.org/abs/2503.17231</link>
<guid>https://arxiv.org/abs/2503.17231</guid>
<content:encoded><![CDATA[
<div> : 

:<br />
LoGoFairCH1LoGoFairCH2LoGoFairLoGoFair <div>
arXiv:2503.17231v1 Announce Type: new 
Abstract: Federated learning (FL) has garnered considerable interest for its capability to learn from decentralized data sources. Given the increasing application of FL in decision-making scenarios, addressing fairness issues across different sensitive groups (e.g., female, male) in FL is crucial. Current research often focuses on facilitating fairness at each client's data (local fairness) or within the entire dataset across all clients (global fairness). However, existing approaches that focus exclusively on either local or global fairness fail to address two key challenges: (\textbf{CH1}) Under statistical heterogeneity, global fairness does not imply local fairness, and vice versa. (\textbf{CH2}) Achieving fairness under model-agnostic setting. To tackle the aforementioned challenges, this paper proposes a novel post-processing framework for achieving both Local and Global Fairness in the FL context, namely LoGoFair. To address CH1, LoGoFair endeavors to seek the Bayes optimal classifier under local and global fairness constraints, which strikes the optimal accuracy-fairness balance in the probabilistic sense. To address CH2, LoGoFair employs a model-agnostic federated post-processing procedure that enables clients to collaboratively optimize global fairness while ensuring local fairness, thereby achieving the optimal fair classifier within FL. Experimental results on three real-world datasets further illustrate the effectiveness of the proposed LoGoFair framework.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralization: A Qualitative Survey of Node Operators</title>
<link>https://arxiv.org/abs/2503.17246</link>
<guid>https://arxiv.org/abs/2503.17246</guid>
<content:encoded><![CDATA[
<div> decentralization, blockchain, decentralization theatre, network topology, governance topology

<br /><br />:
 <div>
arXiv:2503.17246v1 Announce Type: new 
Abstract: Decentralization is understood both by professionals in the blockchain industry and general users as a core design goal of permissionless ledgers. However, its meaning is far from universally agreed, and often it is easier to get opinions on what it is not, rather than what it is. In this paper, we solicit definitions of 'decentralization' and 'decentralization theatre' from blockchain node operators. Key to a definition is asking about effective decentralization strategies, as well as those that are ineffective, sometimes deliberately so. Malicious, deceptive or at the least incompetent strategies are commonly referred to by the term 'decentralization theatre.' Finally, we ask what is being decentralized. We find that most operators conceive decentralization as existing broadly on a technical and a governance axis. Isolating relevant variables, we collapse the categories to network topology and governance topology, or the structure of decision-making power. Our key finding is that `decentralization' alone does not affect ledger immutability or systemic robustness.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fed-NDIF: A Noise-Embedded Federated Diffusion Model For Low-Count Whole-Body PET Denoising</title>
<link>https://arxiv.org/abs/2503.16635</link>
<guid>https://arxiv.org/abs/2503.16635</guid>
<content:encoded><![CDATA[
<div> : (LCPET), , (Federated Learning), , Fed-NDIF

<br /><br />:
(LCPET)Fed-NDIFFed-NDIF2.5D(NSTD)(FedAvg)UNetFed-NDIF3DPSNRSSIMNMSE <div>
arXiv:2503.16635v1 Announce Type: cross 
Abstract: Low-count positron emission tomography (LCPET) imaging can reduce patients' exposure to radiation but often suffers from increased image noise and reduced lesion detectability, necessitating effective denoising techniques. Diffusion models have shown promise in LCPET denoising for recovering degraded image quality. However, training such models requires large and diverse datasets, which are challenging to obtain in the medical domain. To address data scarcity and privacy concerns, we combine diffusion models with federated learning -- a decentralized training approach where models are trained individually at different sites, and their parameters are aggregated on a central server over multiple iterations. The variation in scanner types and image noise levels within and across institutions poses additional challenges for federated learning in LCPET denoising. In this study, we propose a novel noise-embedded federated learning diffusion model (Fed-NDIF) to address these challenges, leveraging a multicenter dataset and varying count levels. Our approach incorporates liver normalized standard deviation (NSTD) noise embedding into a 2.5D diffusion model and utilizes the Federated Averaging (FedAvg) algorithm to aggregate locally trained models into a global model, which is subsequently fine-tuned on local datasets to optimize performance and obtain personalized models. Extensive validation on datasets from the University of Bern, Ruijin Hospital in Shanghai, and Yale-New Haven Hospital demonstrates the superior performance of our method in enhancing image quality and improving lesion quantification. The Fed-NDIF model shows significant improvements in PSNR, SSIM, and NMSE of the entire 3D volume, as well as enhanced lesion detectability and quantification, compared to local diffusion models and federated UNet-based models.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Market Makers in Cryptoeconomic Systems: A Taxonomy and Archetypes</title>
<link>https://arxiv.org/abs/2309.12818</link>
<guid>https://arxiv.org/abs/2309.12818</guid>
<content:encoded><![CDATA[
<div> : AMM

:
(AMM)AMMAMMAMMAMM<br /><br /> <div>
arXiv:2309.12818v3 Announce Type: replace-cross 
Abstract: Designing automated market makers (AMMs) is crucial for decentralized token exchanges in cryptoeconomic systems. At the intersection of software engineering and economics, AMM design is complex and, if done incorrectly, can lead to financial risks and inefficiencies. We developed an AMM taxonomy for systematically comparing AMM designs and propose three AMM archetypes that meet key requirements for token issuance and exchange. This work bridges software engineering and economic perspectives, providing insights to help developers design AMMs tailored to diverse use cases and foster sustainable cryptoeconomic systems.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Identifying Likely-Reputable Blockchain Projects on Ethereum</title>
<link>https://arxiv.org/abs/2503.15542</link>
<guid>https://arxiv.org/abs/2503.15542</guid>
<content:encoded><![CDATA[
<div> Ethereum

<br /><br />:
LightGBM217939770.984AUC 0.99910received_tnx <div>
arXiv:2503.15542v1 Announce Type: new 
Abstract: Identifying reputable Ethereum projects remains a critical challenge within the expanding blockchain ecosystem. The ability to distinguish between legitimate initiatives and potentially fraudulent schemes is non-trivial. This work presents a systematic approach that integrates multiple data sources with advanced analytics to evaluate credibility, transparency, and overall trustworthiness. The methodology applies machine learning techniques to analyse transaction histories on the Ethereum blockchain.
  The study classifies accounts based on a dataset comprising 2,179 entities linked to illicit activities and 3,977 associated with reputable projects. Using the LightGBM algorithm, the approach achieves an average accuracy of 0.984 and an average AUC of 0.999, validated through 10-fold cross-validation. Key influential factors include time differences between transactions and received_tnx.
  The proposed methodology provides a robust mechanism for identifying reputable Ethereum projects, fostering a more secure and transparent investment environment. By equipping stakeholders with data-driven insights, this research enables more informed decision-making, risk mitigation, and the promotion of legitimate blockchain initiatives. Furthermore, it lays the foundation for future advancements in trust assessment methodologies, contributing to the continued development and maturity of the Ethereum ecosystem.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions</title>
<link>https://arxiv.org/abs/2503.15546</link>
<guid>https://arxiv.org/abs/2503.15546</guid>
<content:encoded><![CDATA[
<div> Large Language Models (LLMs)

<br />
:
LLMsLLM90%98%0.05LLM <div>
arXiv:2503.15546v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into autonomous robotic agents for conducting online transactions poses significant cybersecurity challenges. This study aims to enforce robust cybersecurity constraints to mitigate the risks associated with data breaches, transaction fraud, and system manipulation. The background focuses on the rise of LLM-driven robotic systems in e-commerce, finance, and service industries, alongside the vulnerabilities they introduce. A novel security architecture combining blockchain technology with multi-factor authentication (MFA) and real-time anomaly detection was implemented to safeguard transactions. Key performance metrics such as transaction integrity, response time, and breach detection accuracy were evaluated, showing improved security and system performance. The results highlight that the proposed architecture reduced fraudulent transactions by 90%, improved breach detection accuracy to 98%, and ensured secure transaction validation within a latency of 0.05 seconds. These findings emphasize the importance of cybersecurity in the deployment of LLM-driven robotic systems and suggest a framework adaptable to various online platforms.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Acurast: Decentralized Serverless Cloud</title>
<link>https://arxiv.org/abs/2503.15654</link>
<guid>https://arxiv.org/abs/2503.15654</guid>
<content:encoded><![CDATA[
<div> Acurastless

:

AcurastAcurastAcurastAcurast <div>
arXiv:2503.15654v1 Announce Type: new 
Abstract: Centralized trust is ubiquitous in today's interconnected world, from computational resources to data storage and its underlying infrastructure. The monopolization of cloud computing resembles a feudalistic system, causing a loss of privacy and data ownership.
  Cloud Computing and the Internet in general face widely recognized challenges, such as (1) the centralization of trust in auxiliary systems (e.g., centralized cloud providers), (2) the seamless and permissionless interoperability of fragmented ecosystems and (2) the effectiveness, verifiability, and confidentiality of the computation. Acurast is a decentralized serverless cloud that addresses all these shortcomings, following the call for a global-scale cloud founded on the principles of the open-source movement.
  In Acurast, a purpose-built orchestrator, a reputation engine, and an attestation service are enshrined in the consensus layer. Developers can off-load their computations and verify executions cryptographically. Furthermore, Acurast offers a modular execution layer, taking advantage of secure hardware and trusted execution environments, removing the trust required in third parties, and reducing them to cryptographic hardness assumptions. With this modular architecture, Acurast serves as a decentralized and serverless cloud, allowing confidential and verifiable compute backed by the hardware of security and performance mobile devices.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cybersecurity in Vehicle-to-Grid (V2G) Systems: A Systematic Review</title>
<link>https://arxiv.org/abs/2503.15730</link>
<guid>https://arxiv.org/abs/2503.15730</guid>
<content:encoded><![CDATA[
<div> : V2GCRML

:
PRISMA202020246V2G133<br />
1. 103/133V2GCRML<br />
2. V2G11281V2G<br />
3. V2G<br />
4. AIAI(AIA)AIA<br />
5. V2G <div>
arXiv:2503.15730v1 Announce Type: new 
Abstract: This paper presents a systematic review of recent advancements in V2G cybersecurity, employing the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework for detailed searches across three journal databases and included only peer-reviewed studies published between 2020 and 2024 (June). We identified and reviewed 133 V2G cybersecurity studies and found five important insights on existing V2G cybersecurity research. First, most studies (103 of 133) focused on protecting V2G systems against cyber threats, while only seven studies addressed the recovery aspect of the CRML (Cybersecurity Risk Management Lifecycle) function. Second, existing studies have adequately addressed the security of EVs and EVCS (EV charging stations) in V2G systems (112 and 81 of 133 studies, respectively). However, none have focused on the linkage between the behaviour of EV users and the cybersecurity of V2G systems. Third, physical access, control-related vulnerabilities, and user behaviour-related attacks in V2G systems are not addressed significantly. Furthermore, existing studies overlook vulnerabilities and attacks specific to AI and blockchain technologies. Fourth, blockchain, artificial intelligence (AI), encryption, control theory, and optimisation are the main technologies used, and finally, the inclusion of quantum safety within encryption and AI models and AI assurance (AIA) is in a very early stage; only two and one of 133 studies explicitly addressed quantum safety and AIA through explainability. By providing a holistic perspective, this study identifies critical research gaps and outlines future directions for developing robust end-to-end cybersecurity solutions to safeguard V2G systems and support global sustainability goals.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prediction of Permissioned Blockchain Performance for Resource Scaling Configurations</title>
<link>https://arxiv.org/abs/2503.15769</link>
<guid>https://arxiv.org/abs/2503.15769</guid>
<content:encoded><![CDATA[
<div> BaaS

<br />
:
BaaSBaaS1.9% <div>
arXiv:2503.15769v1 Announce Type: new 
Abstract: Blockchain is increasingly offered as blockchain-as-a-service (BaaS) by cloud service providers. However, configuring BaaS appropriately for optimal performance and reliability resorts to try-and-error. A key challenge is that BaaS is often perceived as a ``black-box,'' leading to uncertainties in performance and resource provisioning. Previous studies attempted to address this challenge; however, the impacts of both vertical and horizontal scaling remain elusive. To this end, we present machine learning-based models to predict network reliability and throughput based on scaling configurations. In our evaluation, the models exhibit prediction errors of ~1.9%, which is highly accurate and can be applied in the real-world.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Are We There Yet? A Study of Decentralized Identity Applications</title>
<link>https://arxiv.org/abs/2503.15964</link>
<guid>https://arxiv.org/abs/2503.15964</guid>
<content:encoded><![CDATA[
<div> : Decentralized Identities (DI), Self-Sovereign Identities (SSI), , , 

:<br />
Decentralized Identities (DI)Self-Sovereign Identities (SSI) <div>
arXiv:2503.15964v1 Announce Type: new 
Abstract: The development of Decentralized Identities (DI) and Self-Sovereign Identities (SSI) has seen significant growth in recent years. This is accompanied by a numerous academic and commercial contributions to the development of principles, standards, and systems. While several comprehensive reviews have been produced, they predominantly focus on academic literature, with few considering grey literature to provide a holistic view of technological advancements. Furthermore, no existing surveys have thoroughly analyzed real-world deployments to understand the barriers to the widespread adoption of decentralized identity models. This paper addresses the gap by exploring both academic and grey literature and examining commercial and governmental initiatives, to present a comprehensive landscape of decentralized identity technologies and their adoption in real-world. Additionally, it identifies the practical challenges and limitations that slowdown the transition from centralized to decentralized identity management systems. By shifting the focus from purely technological constraints to real-world deployment issues, this survey identifies the underlying reasons preventing the adoption of decentralized identities despite their evident benefits to the data owner.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Digital Asset Data Lakehouse. The concept based on a blockchain research center</title>
<link>https://arxiv.org/abs/2503.15968</link>
<guid>https://arxiv.org/abs/2503.15968</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
 <div>
arXiv:2503.15968v1 Announce Type: new 
Abstract: In the rapidly evolving landscape of digital assets and blockchain technologies, the necessity for robust, scalable, and secure data management platforms has never been more critical. This paper introduces a novel software architecture designed to meet these demands by leveraging the inherent strengths of cloud-native technologies and modular micro-service based architectures, to facilitate efficient data management, storage and access, across different stakeholders. We detail the architectural design, including its components and interactions, and discuss how it addresses common challenges in managing blockchain data and digital assets, such as scalability, data siloing, and security vulnerabilities. We demonstrate the capabilities of the platform by employing it into multiple real-life scenarios, namely providing data in near real-time to scientists in help with their research. Our results indicate that the proposed architecture not only enhances the efficiency and scalability of distributed data management but also opens new avenues for innovation in the research reproducibility area. This work lays the groundwork for future research and development in machine learning operations systems, offering a scalable and secure framework for the burgeoning digital economy.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Financial Twin Chain, a Platform to Support Financial Sustainability in Supply Chains</title>
<link>https://arxiv.org/abs/2503.15980</link>
<guid>https://arxiv.org/abs/2503.15980</guid>
<content:encoded><![CDATA[
<div> 

:
AI <div>
arXiv:2503.15980v1 Announce Type: new 
Abstract: The financial sustainability of a generic supply chain is a complex problem, which can be addressed through detailed monitoring of financial operations deriving from stakeholder interrelationships and consequent analysis of these financial data to compute the relative economic indicators. This allows the identification of specific fintech tools that can be selected to mitigate financial risks. The intention is to retrieve the financial transactions and private information of stakeholders involved in the supply chain to construct a knowledge base and a digital twin representation that can be used to visualize, analyze, and mitigate the issues associated with the financial sustainability of the chain. We propose a software platform that employs key enabling technologies, including AI, blockchain, knowledge graph, and others, opportunely coordinated to address the financial sustainability problem affecting single stakeholders and the entire supply chain. This platform allows for the involvement of external entities that can help stakeholders or the whole supply chain to solve financial sustainability problems through economic interventions. Moreover, introducing these entities enables stakeholders less well-positioned in the market to access financial services offered by credit institutions, utilising the supply chain's internal information as evidence of its reliability. To validate the proposed idea, a case study will be presented analyzing the financial instrument of securitization.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Agents in Cryptoland: Practical Attacks and No Silver Bullet</title>
<link>https://arxiv.org/abs/2503.16248</link>
<guid>https://arxiv.org/abs/2503.16248</guid>
<content:encoded><![CDATA[
<div> : AIWeb3

<br /><br />:
AIWeb3AIWeb3AIElizaOSAI <div>
arXiv:2503.16248v1 Announce Type: new 
Abstract: The integration of AI agents with Web3 ecosystems harnesses their complementary potential for autonomy and openness, yet also introduces underexplored security risks, as these agents dynamically interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain-based financial ecosystems when exposed to adversarial threats in real-world scenarios. We introduce the concept of context manipulation -- a comprehensive attack vector that exploits unprotected context surfaces, including input channels, memory modules, and external data feeds. Through empirical analysis of ElizaOS, a decentralized AI agent framework for automated Web3 operations, we demonstrate how adversaries can manipulate context by injecting malicious instructions into prompts or historical interaction records, leading to unintended asset transfers and protocol violations which could be financially devastating. Our findings indicate that prompt-based defenses are insufficient, as malicious inputs can corrupt an agent's stored context, creating cascading vulnerabilities across interactions and platforms. This research highlights the urgent need to develop AI agents that are both secure and fiduciarily responsible.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-preserving Blockchain-enabled Parametric Insurance via Remote Sensing and IoT</title>
<link>https://arxiv.org/abs/2305.08384</link>
<guid>https://arxiv.org/abs/2305.08384</guid>
<content:encoded><![CDATA[
<div> : parametric insurance, blockchain, privacy preservation, zero-knowledge proofs, zk-SNARKs

:
(zk-SNARKs)zk-SNARKs80%gas <div>
arXiv:2305.08384v2 Announce Type: replace 
Abstract: Traditional Insurance, a popular approach of financial risk management, has suffered from the issues of high operational costs, opaqueness, inefficiency and a lack of trust. Recently, blockchain-enabled "parametric insurance" through authorized data sources (e.g., remote sensing and IoT) aims to overcome these issues by automating the underwriting and claim processes of insurance policies on a blockchain. However, the openness of blockchain platforms raises a concern of user privacy, as the private user data in insurance claims on a blockchain may be exposed to outsiders. In this paper, we propose a privacy-preserving parametric insurance framework based on succinct zero-knowledge proofs (zk-SNARKs), whereby an insuree submits a zero-knowledge proof (without revealing any private data) for the validity of an insurance claim and the authenticity of its data sources to a blockchain for transparent verification. Moreover, we extend the recent zk-SNARKs to support robust privacy protection for multiple heterogeneous data sources and improve its efficiency to cut the incurred gas cost by 80%. As a proof-of-concept, we implemented a working prototype of bushfire parametric insurance on real-world blockchain platform Ethereum, and present extensive empirical evaluations.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ammBoost: State Growth Control for AMMs</title>
<link>https://arxiv.org/abs/2406.17094</link>
<guid>https://arxiv.org/abs/2406.17094</guid>
<content:encoded><![CDATA[
<div> : (AMM), Web 3.0, , 2, ammBoost

:
ammBoost(AMM)Web 3.0ammBoost22ammBoostgas96.05%93.42%Uniswap500OptimismammBoost99.94% <div>
arXiv:2406.17094v4 Announce Type: replace 
Abstract: Automated market makers (AMMs) are a prime example of Web 3.0 applications. Their popularity and high trading activity led to serious scalability issues in terms of throughput and state size. In this paper, we address these challenges by utilizing a new sidechain architecture, building a system called ammBoost. ammBoost reduces the amount of on-chain transactions, boosts throughput, and supports blockchain pruning. We devise several techniques to enable layer 2 processing for AMMs, including a functionality-split and layer 2 traffic summarization paradigm, an epoch-based deposit mechanism, and pool snapshot-based and delayed token-payout trading. We also build a proof-of-concept for a Uniswap-inspired use case to empirically evaluate performance. Our experiments show that ammBoost decreases the gas cost by 96.05% and the chain growth by at least 93.42%, and that it can support up to 500x of the daily traffic volume of Uniswap. We also compare ammBoost to an Optimism-inspired solution showing a 99.94% reduction in transaction finality.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Content ARCs: Decentralized Content Rights in the Age of Generative AI</title>
<link>https://arxiv.org/abs/2503.14519</link>
<guid>https://arxiv.org/abs/2503.14519</guid>
<content:encoded><![CDATA[
<div> Generative AIAIARCsAuthenticity, Rights, Compensation

:
AIGenAIAIGenAIARCsAIAI <div>
arXiv:2503.14519v1 Announce Type: new 
Abstract: The rise of Generative AI (GenAI) has sparked significant debate over balancing the interests of creative rightsholders and AI developers. As GenAI models are trained on vast datasets that often include copyrighted material, questions around fair compensation and proper attribution have become increasingly urgent. To address these challenges, this paper proposes a framework called \emph{Content ARCs} (Authenticity, Rights, Compensation). By combining open standards for provenance and dynamic licensing with data attribution, and decentralized technologies, Content ARCs create a mechanism for managing rights and compensating creators for using their work in AI training. We characterize several nascent works in the AI data licensing space within Content ARCs and identify where challenges remain to fully implement the end-to-end framework.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ELTEX: A Framework for Domain-Driven Synthetic Data Generation</title>
<link>https://arxiv.org/abs/2503.15055</link>
<guid>https://arxiv.org/abs/2503.15055</guid>
<content:encoded><![CDATA[
<div> : ELTEX

<br /><br />:
ELTEXEfficient LLM Token ExtractionELTEXGemma-2BELTEXGPT-4 <div>
arXiv:2503.15055v1 Announce Type: new 
Abstract: We present ELTEX (Efficient LLM Token Extraction), a domain-driven framework for generating high-quality synthetic training data in specialized domains. While Large Language Models (LLMs) have shown impressive general capabilities, their performance in specialized domains like cybersecurity remains limited by the scarcity of domain-specific training data. ELTEX addresses this challenge by systematically integrating explicit domain indicator extraction with dynamic prompting to preserve critical domain knowledge throughout the generation process. We demonstrate ELTEX's effectiveness in the context of blockchain-related cyberattack detection, where we fine-tune Gemma-2B using various combinations of real and ELTEX-generated data. Our results show that the ELTEX-enhanced model achieves performance competitive with GPT-4 across both standard classification metrics and uncertainty calibration, while requiring significantly fewer computational resources. We release a curated synthetic dataset of social media texts for cyberattack detection in blockchain. Our work demonstrates that domain-driven synthetic data generation can effectively bridge the performance gap between resource-efficient models and larger architectures in specialized domains.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>UltraFlwr -- An Efficient Federated Medical and Surgical Object Detection Framework</title>
<link>https://arxiv.org/abs/2503.15161</link>
<guid>https://arxiv.org/abs/2503.15161</guid>
<content:encoded><![CDATA[
<div> UltraFlwrFederated Learning (FL)YOLO-PAPartial Aggregation (PA)

:<br />
 UltraFlwr FL YOLO PAYOLO-PA 83%YOLO-PA FA BCCD  m2cai16-tool-locations  UltraFlwr  UltraFlwr  GitHub  <div>
arXiv:2503.15161v1 Announce Type: new 
Abstract: Object detection shows promise for medical and surgical applications such as cell counting and tool tracking. However, its faces multiple real-world edge deployment challenges including limited high-quality annotated data, data sharing restrictions, and computational constraints. In this work, we introduce UltraFlwr, a framework for federated medical and surgical object detection. By leveraging Federated Learning (FL), UltraFlwr enables decentralized model training across multiple sites without sharing raw data. To further enhance UltraFlwr's efficiency, we propose YOLO-PA, a set of novel Partial Aggregation (PA) strategies specifically designed for YOLO models in FL. YOLO-PA significantly reduces communication overhead by up to 83% per round while maintaining performance comparable to Full Aggregation (FA) strategies. Our extensive experiments on BCCD and m2cai16-tool-locations datasets demonstrate that YOLO-PA not only provides better client models compared to client-wise centralized training and FA strategies, but also facilitates efficient training and deployment across resource-constrained edge devices. Further, we also establish one of the first benchmarks in federated medical and surgical object detection. This paper advances the feasibility of training and deploying detection models on the edge, making federated object detection more practical for time-critical and resource-constrained medical and surgical applications. UltraFlwr is publicly available at https://github.com/KCL-BMEIS/UltraFlwr.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems</title>
<link>https://arxiv.org/abs/2503.15172</link>
<guid>https://arxiv.org/abs/2503.15172</guid>
<content:encoded><![CDATA[
<div> Multi-Agent Deep Reinforcement Learning (MADRL)MARL(DSA)

<br /><br />
MADRLDSADSAMADRL <div>
arXiv:2503.15172v1 Announce Type: new 
Abstract: Multi-Agent Deep Reinforcement Learning (MADRL) has emerged as a powerful tool for optimizing decentralized decision-making systems in complex settings, such as Dynamic Spectrum Access (DSA). However, deploying deep learning models on resource-constrained edge devices remains challenging due to their high computational cost. To address this challenge, in this paper, we present a novel sparse recurrent MARL framework integrating gradual neural network pruning into the independent actor global critic paradigm. Additionally, we introduce a harmonic annealing sparsity scheduler, which achieves comparable, and in certain cases superior, performance to standard linear and polynomial pruning schedulers at large sparsities. Our experimental investigation demonstrates that the proposed DSA framework can discover superior policies, under diverse training conditions, outperforming conventional DSA, MADRL baselines, and state-of-the-art pruning techniques.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Robust Routing Protocol for 5G Mesh Networks</title>
<link>https://arxiv.org/abs/2503.15173</link>
<guid>https://arxiv.org/abs/2503.15173</guid>
<content:encoded><![CDATA[
<div> : ad-hoc

:
ad-hocDECT 2020 NR (NR+) <div>
arXiv:2503.15173v1 Announce Type: new 
Abstract: We consider a novel routing protocol suitable for ad-hoc networks with dynamically changing topologies, such as DECT 2020 NR (NR+) systems, which often lead to missing links between the nodes and thus, incomplete or inefficient routes. A key point of the proposed protocol is the combination of network discovery and matrix completion techniques, which allow the nodes to establish communication paths efficiently and reliably. Additionally, multihop localization is performed to estimate the location of the nodes without needing to broadcast each node's geographical position, thus preserving privacy during the routing process and enabling nodes in the network to independently find potentially missing paths in a decentralized manner instead of flooding the whole network. Simulation results illustrate the good performance of the proposed technique in terms of the average number of hops of the obtained routes in different scenarios, with different network densities and amounts of incompleteness.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Role-Selection Game in Block Production under Proposer-Builder Separation</title>
<link>https://arxiv.org/abs/2503.15184</link>
<guid>https://arxiv.org/abs/2503.15184</guid>
<content:encoded><![CDATA[
<div> Proposer-Builder Separation (PBS)-sided marketagent-based simulation

<br /><br />:
Proposer-BuilderPBS <div>
arXiv:2503.15184v1 Announce Type: new 
Abstract: To address the risks of validator centralization, the Ethereum community introduced Proposer-Builder Separation (PBS), which divides the roles of block building and block proposing to foster a more equitable environment for blockchain participants. PBS creates a two-sided market, wherein searchers provide valuable bundles with bids to builders with the demand for their inclusion in a block, and builders vie for order flows from searchers to secure victory in the block-building auction. In this work, we propose a novel co-evolutionary framework to analyze the behavior of participants in the aforementioned two-sided market. Leveraging agent-based simulations enables us to observe the strategy evolution results of autonomous agents and understand how each profit-seeking actor can benefit from the block-building process under different market conditions. We observe that searchers and builders can develop distinct bidding and rebate strategies under varying conditions (conflict probabilities between bundles), with searchers learning to differentiate their bids based on the rebates offered by different builders. Through empirical game-theoretic analysis, we compute the dynamic equilibrium solution of agents' strategies under two meta-strategies, which predicts the frequency at which agents employ block building and bundle sharing strategies in the two-sided market. Our analysis reveals that agents achieve a dynamic equilibrium as searchers when the probability of conflict between bundles is low. As this conflict probability rises to a certain critical level, the dynamic equilibrium transitions to favor agents becoming builders.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automating Comment Generation for Smart Contract from Bytecode</title>
<link>https://arxiv.org/abs/2503.15270</link>
<guid>https://arxiv.org/abs/2503.15270</guid>
<content:encoded><![CDATA[
<div> : 

:
SmartBTSmartBTSmartBTSmartBTSmartBT <div>
arXiv:2503.15270v1 Announce Type: new 
Abstract: Recently, smart contracts have played a vital role in automatic financial and business transactions. To help end users without programming background to better understand the logic of smart contracts, previous studies have proposed models for automatically translating smart contract source code into their corresponding code summaries. However, in practice, only 13% of smart contracts deployed on the Ethereum blockchain are associated with source code. The practical usage of these existing tools is significantly restricted. Considering that bytecode is always necessary when deploying smart contracts, in this paper, we first introduce the task of automatically generating smart contract code summaries from bytecode. We propose a novel approach, named SmartBT (Smart contract Bytecode Translator) for automatically translating smart contract bytecode into fine-grained natural language description directly. Two key challenges are posed for this task: structural code logic hidden in bytecode and the huge semantic gap between bytecode and natural language descriptions. To address the first challenge, we transform bytecode into CFG (Control-Flow Graph) to learn code structural and logic details. Regarding the second challenge, we introduce an information retrieval component to fetch similar comments for filling the semantic gap. Then the structural input and semantic input are used to build an attentional sequence-to-sequence neural network model. The copy mechanism is employed to copy rare words directly from similar comments and the coverage mechanism is employed to eliminate repetitive outputs. The automatic evaluation results show that SmartBT outperforms a set of baselines by a large margin, and the human evaluation results show the effectiveness and potential of SmartBT in producing meaningful and accurate comments for smart contract code from bytecode directly.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Investigating shocking events in the Ethereum stablecoin ecosystem through temporal multilayer graph structure</title>
<link>https://arxiv.org/abs/2407.10614</link>
<guid>https://arxiv.org/abs/2407.10614</guid>
<content:encoded><![CDATA[
<div> Web3<br /><br />:
Web3TerraUSDLUNA <div>
arXiv:2407.10614v2 Announce Type: replace 
Abstract: In the dynamic landscape of the Web, we are witnessing the emergence of the Web3 paradigm, which dictates that platforms should rely on blockchain technology and cryptocurrencies to sustain themselves and their profitability. Cryptocurrencies are characterised by high market volatility and susceptibility to substantial crashes, issues that require temporal analysis methodologies able to tackle the high temporal resolution, heterogeneity and scale of blockchain data. While existing research attempts to analyse crash events, fundamental questions persist regarding the optimal time scale for analysis, differentiation between long-term and short-term trends, and the identification and characterisation of shock events within these decentralised systems. This paper addresses these issues by examining cryptocurrencies traded on the Ethereum blockchain, with a spotlight on the crash of the stablecoin TerraUSD and the currency LUNA designed to stabilise it. Utilising complex network analysis and a multi-layer temporal graph allows the study of the correlations between the layers representing the currencies and system evolution across diverse time scales. The investigation sheds light on the strong interconnections among stablecoins pre-crash and the significant post-crash transformations. We identify anomalous signals before, during, and after the collapse, emphasising their impact on graph structure metrics and user movement across layers. This paper pioneers temporal, cross-chain graph analysis to explore a cryptocurrency collapse. It emphasises the importance of temporal analysis for studies on web-derived data and how graph-based analysis can enhance traditional econometric results. Overall, this research carries implications beyond its field, for example for regulatory agencies aiming to safeguard users from shocks and monitor investment risks for citizens and clients.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARLadona -- Towards Cooperative Team Play Using Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.20326</link>
<guid>https://arxiv.org/abs/2409.20326</guid>
<content:encoded><![CDATA[
<div> MARLMARLadonaGEE

<br /><br />:
MARLadonaGEEMARLHELIOS66.8% <div>
arXiv:2409.20326v3 Announce Type: replace 
Abstract: Robot soccer, in its full complexity, poses an unsolved research challenge. Current solutions heavily rely on engineered heuristic strategies, which lack robustness and adaptability. Deep reinforcement learning has gained significant traction in various complex robotics tasks such as locomotion, manipulation, and competitive games (e.g., AlphaZero, OpenAI Five), making it a promising solution to the robot soccer problem. This paper introduces MARLadona. A decentralized multi-agent reinforcement learning (MARL) training pipeline capable of producing agents with sophisticated team play behavior, bridging the shortcomings of heuristic methods. Furthermore, we created an open-source multi-agent soccer environment. Utilizing our MARL framework and a modified global entity encoder (GEE) as our core architecture, our approach achieves a 66.8% win rate against HELIOS agent, which employs a state-of-the-art heuristic strategy. In addition, we provided an in-depth analysis of the policy behavior and interpreted the agent's intention using the critic network.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoliDiffy: AST Differencing for Solidity Smart Contracts</title>
<link>https://arxiv.org/abs/2411.07718</link>
<guid>https://arxiv.org/abs/2411.07718</guid>
<content:encoded><![CDATA[
<div> : (AST)SoliDiffyGit

:
<br />
SoliDiffySolidityASTSoliDiffy353,262SoliDiffy96.1%925GitSoliDiffyhttps://github.com/mojtaba-eshghie/SoliDiffy <div>
arXiv:2411.07718v4 Announce Type: replace 
Abstract: Structured code differencing is the act of comparing the hierarchical structure of code via its abstract syntax tree (AST) to capture modifications. AST-based source code differencing enables tasks such as vulnerability detection and automated repair where traditional line-based differencing falls short. We introduce SoliDiffy, the first AST differencing tool for Solidity smart contracts with the ability to generate an edit script that soundly shows the structural differences between two smart-contracts using insert, delete, update, move operations. In our evaluation on 353,262 contract pairs, SoliDiffy achieved a 96.1% diffing success rate, surpassing the state-of-the-art, and produced significantly shorter edit scripts. Additional experiments on 925 real-world commits further confirmed its superiority compared to Git line-based differencing. SoliDiffy provides accurate representations of smart contract evolution even in the existence of multiple complex modifications to the source code. SoliDiffy is made publicly available at https://github.com/mojtaba-eshghie/SoliDiffy.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Omnichain Web: The Universal Framework for Streamlined Chain Abstraction and Cross-Layer Interaction</title>
<link>https://arxiv.org/abs/2411.10132</link>
<guid>https://arxiv.org/abs/2411.10132</guid>
<content:encoded><![CDATA[
<div> : Web3AIOmnichain Web<br /><br />:
Web3Web2AIrollupsAIDojimaOmnichain WebWeb2Web3AIOmniRollupsOmni SequencerAILineraRagno NetworkL1Proof NetworkBuilder MarketplaceWeb2Web3Omnichain WebWeb3Web2 <div>
arXiv:2411.10132v2 Announce Type: replace 
Abstract: The Web3 ecosystem is highly fragmented, making seamless integration difficult for over a billion Web2 businesses, enterprises, and AI protocols. As blockchains, rollups, and app-specific chains expand, cross-chain interactions remain inefficient, and liquidity is deeply fragmented. AI systems lack standardized blockchain access, limiting autonomous functionality. Intent-based interactions, crucial for AI-driven automation, face scalability issues due to the absence of robust execution platforms. Meanwhile, the current solver ecosystem is centralized, as liquidity rebalancing remains a challenge due to a lack of developer-friendly tools. Dojima's Omnichain Web introduces a universal framework that abstracts blockchain complexity, bridging Web2, Web3, and AI. At its core, OmniRollups facilitate scalable execution across chains, while the Omni Sequencer ensures atomic, secure intent processing. Linera microchains enable AI-driven transaction automation, seamlessly integrating with Web3 data streams. Ragno Network decentralizes L1 infrastructure, optimizing cross-chain liquidity flows, while the Proof Network enhances cryptographic security for omnichain transactions. Finally, the Builder Marketplace introduces a solver-driven execution layer, allowing developers to build and monetize intent-based applications without liquidity constraints. By fostering a composable marketplace at the intersection of Web2 and Web3, Omnichain Web enables the seamless flow of data, value, and computation. This framework mirrors the internet, bridging Web3 decentralization with Web2 scale to drive the next wave of adoption.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedTilt: Towards Multi-Level Fairness-Preserving and Robust Federated Learning</title>
<link>https://arxiv.org/abs/2503.13537</link>
<guid>https://arxiv.org/abs/2503.13537</guid>
<content:encoded><![CDATA[
<div> Federated LearningfairnessrobustnessFedTilttilted empirical risk minimization

<br /><br />

FedTiltFedTiltFedTiltFedTilt <div>
arXiv:2503.13537v1 Announce Type: new 
Abstract: Federated Learning (FL) is an emerging decentralized learning paradigm that can partly address the privacy concern that cannot be handled by traditional centralized and distributed learning. Further, to make FL practical, it is also necessary to consider constraints such as fairness and robustness. However, existing robust FL methods often produce unfair models, and existing fair FL methods only consider one-level (client) fairness and are not robust to persistent outliers (i.e., injected outliers into each training round) that are common in real-world FL settings. We propose \texttt{FedTilt}, a novel FL that can preserve multi-level fairness and be robust to outliers. In particular, we consider two common levels of fairness, i.e., \emph{client fairness} -- uniformity of performance across clients, and \emph{client data fairness} -- uniformity of performance across different classes of data within a client. \texttt{FedTilt} is inspired by the recently proposed tilted empirical risk minimization, which introduces tilt hyperparameters that can be flexibly tuned. Theoretically, we show how tuning tilt values can achieve the two-level fairness and mitigate the persistent outliers, and derive the convergence condition of \texttt{FedTilt} as well. Empirically, our evaluation results on a suite of realistic federated datasets in diverse settings show the effectiveness and flexibility of the \texttt{FedTilt} framework and the superiority to the state-of-the-arts.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SDFLMQ: A Semi-Decentralized Federated Learning Framework over MQTT</title>
<link>https://arxiv.org/abs/2503.13624</link>
<guid>https://arxiv.org/abs/2503.13624</guid>
<content:encoded><![CDATA[
<div> : (SDFL), , MQTT, , 

:
SDFLMQMQTTSDFLMQ/SDFLMQ <div>
arXiv:2503.13624v1 Announce Type: new 
Abstract: Federated Learning is widely discussed as a distributed machine learning concept with stress on preserving data privacy. Various structures of Federated Learning were proposed. Centralized Federated learning for instance has been the primary structure that suits cloud computing. Decentralized Federated learning also has been proposed for ecosystems where communication is dominantly peer-to-peer. Semi-Decentralized Federated Learning (SDFL) has emerged recently as a new concept where the interconnected nodes are clustered, and each cluster is managed independently. The potential of SDFL lies in its clustering feature, which distributes the load of the global model update down onto multiple nodes. Since the concept is fairly new, much can be done to render this FL model a reliable, efficient, and real-time service at the edge. In this paper, we propose SDFLMQ, a semi-decentralized Federated learning framework at the Edge that uses MQTT as the communication protocol. We demonstrate how the publish/subscribe communication model is used to facilitate the clustering and load balancing in SDFL. We also demonstrate how SDFLMQ can use some of the core MQTT features to expand its capacity with no significant costs. Based on some primary evaluations, we demonstrate how SDFLMQ can efficiently distribute the load of aggregation, and potentially save unnecessary memory allocation, all with no requirement for a powerful central unit for aggregation and global model update. We also disclose some of the key future expansions of SDFLMQ with a focus on the operation of large deep neural network models at the edge.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>XChainDataGen: A Cross-Chain Dataset Generation Framework</title>
<link>https://arxiv.org/abs/2503.13637</link>
<guid>https://arxiv.org/abs/2503.13637</guid>
<content:encoded><![CDATA[
<div> XChainDataGen

:
XChainDataGen(cctxs)1135GB11,285,753280GasEIP-7683cctxXChainDataGen(DeFi) <div>
arXiv:2503.13637v1 Announce Type: new 
Abstract: The number of blockchain interoperability protocols for transferring data and assets between blockchains has grown significantly. However, no open dataset of cross-chain transactions exists to study interoperability protocols in operation. There is also no tool to generate such datasets and make them available to the community. This paper proposes XChainDataGen, a tool to extract cross-chain data from blockchains and generate datasets of cross-chain transactions (cctxs). Using XChainDataGen, we extracted over 35 GB of data from five cross-chain protocols deployed on 11 blockchains in the last seven months of 2024, identifying 11,285,753 cctxs that moved over 28 billion USD in cross-chain token transfers. Using the data collected, we compare protocols and provide insights into their security, cost, and performance trade-offs. As examples, we highlight differences between protocols that require full finality on the source blockchain and those that only demand soft finality (\textit{security}). We compare user costs, fee models, and the impact of variables such as the Ethereum gas price on protocol fees (\textit{cost}). Finally, we produce the first analysis of the implications of EIP-7683 for cross-chain intents, which are increasingly popular and greatly improve the speed with which cctxs are processed (\textit{performance}), thereby enhancing the user experience. The availability of XChainDataGen and this dataset allows various analyses, including trends in cross-chain activity, security assessments of interoperability protocols, and financial research on decentralized finance (DeFi) protocols.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Continuification Control of Multi-Agent Systems via Distributed Density Estimation</title>
<link>https://arxiv.org/abs/2503.14119</link>
<guid>https://arxiv.org/abs/2503.14119</guid>
<content:encoded><![CDATA[
<div>  decentralized implementation, continuification, multi-agent systems, density control, unit circle, kernel density estimation, PI consensus dynamics, local density estimates, local control actions, centralized approaches, reliability, practical applicability.

<br /><br />
/ODEs/SDEsPDEsPI <div>
arXiv:2503.14119v1 Announce Type: new 
Abstract: This paper introduces a novel decentralized implementation of a continuification-based strategy to control the density of large-scale multi-agent systems on the unit circle. While continuification methods effectively address micro-to-macro control problems by reformulating ordinary/stochastic differential equations (ODEs/SDEs) agent-based models into more tractable partial differential equations (PDEs), they traditionally require centralized knowledge of macroscopic state observables. We overcome this limitation by developing a distributed density estimation framework that combines kernel density estimation with PI consensus dynamics. Our approach enables agents to compute local density estimates and derive local control actions using only information from neighboring agents in a communication network. Numerical validations across multiple scenarios - including regulation, tracking, and time-varying communication topologies - confirm the effectiveness of the proposed approach. They also convincingly demonstrate that our decentralized implementation achieves performance comparable to centralized approaches while enhancing reliability and practical applicability.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Resilient Airdrop Mechanisms: Empirical Measurement of Hunter Profits and Airdrop Game Theory Modeling</title>
<link>https://arxiv.org/abs/2503.14316</link>
<guid>https://arxiv.org/abs/2503.14316</guid>
<content:encoded><![CDATA[
<div> airdropSybil

<br />
:
airdropSybilHopLayerZero <div>
arXiv:2503.14316v1 Announce Type: new 
Abstract: Airdrops issued by platforms are to distribute tokens, drive user adoption, and promote decentralized services. The distributions attract airdrop hunters (attackers), who exploit the system by employing Sybil attacks, i.e., using multiple identities to manipulate token allocations to meet eligibility criteria. While debates around airdrop hunting question the potential benefits to the ecosystem, exploitative behaviors like Sybil attacks clearly undermine the system's integrity, eroding trust and credibility. Despite the increasing prevalence of these tactics, a gap persists in the literature regarding systematic modeling of airdrop hunters' costs and returns, alongside the theoretical models capturing the interactions among all roles for airdrop mechanism design. Our study first conducts an empirical analysis of transaction data from the Hop Protocol and LayerZero, identifying prevalent attack patterns and estimating hunters' expected profits. Furthermore, we develop a game-theory model that simulates the interactions between attackers, organizers, and bounty hunters, proposing optimal incentive structures that enhance detection while minimizing organizational costs.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized RISE-based Control for Exponential Heterogeneous Multi-Agent Target Tracking of Second-Order Nonlinear Systems</title>
<link>https://arxiv.org/abs/2503.14418</link>
<guid>https://arxiv.org/abs/2503.14418</guid>
<content:encoded><![CDATA[
<div> decentralized implementationRobust Integral of the Sign of the Error (RISE) multi-agent target trackingLyapunov-based design-analysislocal information exchange

:
(RISE)RISELyapunovPLyapunov <div>
arXiv:2503.14418v1 Announce Type: new 
Abstract: This work presents a decentralized implementation of a Robust Integral of the Sign of the Error (RISE) controller for multi-agent target tracking problems with exponential convergence guarantees. Previous RISE-based approaches for multi-agent systems required 2-hop communication, limiting practical applicability. New insights from a Lyapunov-based design-analysis approach are used to eliminate the need for multi-hop communication required in previous literature, while yielding exponential target tracking. The new insights include the development of a new P-function which is developed which works in tandem with the inclusion of the interaction matrix in the Lyapunov function. Nonsmooth Lyapunov-based stability analysis methods are used to yield semi-global exponential convergence to the target agent state despite the presence of bounded disturbances with bounded derivatives. The resulting outcome is a controller that achieves exponential target tracking with only local information exchange between neighboring agents.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework</title>
<link>https://arxiv.org/abs/2503.14353</link>
<guid>https://arxiv.org/abs/2503.14353</guid>
<content:encoded><![CDATA[
<div> : decentralized gradient descent (DGD), diffusion, strongly convex, smooth objectives, undirected topologies, contraction mappings, mean Hessian theorem (MHT), convergence bounds, noise-free, noisy regimes, algorithm dynamics, asymptotic convergence properties, multiple local gradient updates, time-varying step sizes, stochastic DGD, communication noise, random topologies.

<br /><br />:
(DGD)(MHT)DGD <div>
arXiv:2503.14353v1 Announce Type: cross 
Abstract: The decentralized gradient descent (DGD) algorithm, and its sibling, diffusion, are workhorses in decentralized machine learning, distributed inference and estimation, and multi-agent coordination. We propose a novel, principled framework for the analysis of DGD and diffusion for strongly convex, smooth objectives, and arbitrary undirected topologies, using contraction mappings coupled with a result called the mean Hessian theorem (MHT). The use of these tools yields tight convergence bounds, both in the noise-free and noisy regimes. While these bounds are qualitatively similar to results found in the literature, our approach using contractions together with the MHT decouples the algorithm dynamics (how quickly the algorithm converges to its fixed point) from its asymptotic convergence properties (how far the fixed point is from the global optimum). This yields a simple, intuitive analysis that is accessible to a broader audience. Extensions are provided to multiple local gradient updates, time-varying step sizes, noisy gradients (stochastic DGD and diffusion), communication noise, and random topologies.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain with proof of quantum work</title>
<link>https://arxiv.org/abs/2503.14462</link>
<guid>https://arxiv.org/abs/2503.14462</guid>
<content:encoded><![CDATA[
<div> : 

:
D-Wave <div>
arXiv:2503.14462v1 Announce Type: cross 
Abstract: We propose a blockchain architecture in which mining requires a quantum computer. The consensus mechanism is based on proof of quantum work, a quantum-enhanced alternative to traditional proof of work that leverages quantum supremacy to make mining intractable for classical computers. We have refined the blockchain framework to incorporate the probabilistic nature of quantum mechanics, ensuring stability against sampling errors and hardware inaccuracies. To validate our approach, we implemented a prototype blockchain on four D-Wave$^{\rm TM}$ quantum annealing processors geographically distributed within North America, demonstrating stable operation across hundreds of thousands of quantum hashing operations. Our experimental protocol follows the same approach used in the recent demonstration of quantum supremacy [1], ensuring that classical computers cannot efficiently perform the same computation task. By replacing classical machines with quantum systems for mining, it is possible to significantly reduce the energy consumption and environmental impact traditionally associated with blockchain mining. Beyond serving as a proof of concept for a meaningful application of quantum computing, this work highlights the potential for other near-term quantum computing applications using existing technology.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unsynchronized Decentralized Q-Learning: Two Timescale Analysis By Persistence</title>
<link>https://arxiv.org/abs/2308.03239</link>
<guid>https://arxiv.org/abs/2308.03239</guid>
<content:encoded><![CDATA[
<div> : (MARL)Q

:<br />
QQQ <div>
arXiv:2308.03239v2 Announce Type: replace 
Abstract: Non-stationarity is a fundamental challenge in multi-agent reinforcement learning (MARL), where agents update their behaviour as they learn. Many theoretical advances in MARL avoid the challenge of non-stationarity by coordinating the policy updates of agents in various ways, including synchronizing times at which agents are allowed to revise their policies. Synchronization enables analysis of many MARL algorithms via multi-timescale methods, but such synchronization is infeasible in many decentralized applications. In this paper, we study an unsynchronized variant of the decentralized Q-learning algorithm, a recent MARL algorithm for stochastic games. We provide sufficient conditions under which the unsynchronized algorithm drives play to equilibrium with high probability. Our solution utilizes constant learning rates in the Q-factor update, which we show to be critical for relaxing the synchronization assumptions of earlier work. Our analysis also applies to unsynchronized generalizations of a number of other algorithms from the regret testing tradition, whose performance is analyzed by multi-timescale methods that study Markov chains obtained via policy update dynamics. This work extends the applicability of the decentralized Q-learning algorithm and its relatives to settings in which parameters are selected in an independent manner, and tames non-stationarity without imposing the coordination assumptions of prior work.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reusable Formal Verification of DAG-based Consensus Protocols</title>
<link>https://arxiv.org/abs/2407.02167</link>
<guid>https://arxiv.org/abs/2407.02167</guid>
<content:encoded><![CDATA[
<div> : DAGTLA+

:
DAGDAG-RiderCordial MinersHashgraphEventual Synchronous BullSharkAlephDAGTLA+TLAPSTLA+TLAPSDAGDAG<br /><br /> <div>
arXiv:2407.02167v2 Announce Type: replace 
Abstract: Blockchains use consensus protocols to reach agreement, e.g., on the ordering of transactions. DAG-based consensus protocols are increasingly adopted by blockchain companies to reduce energy consumption and enhance security. These protocols collaboratively construct a partial order of blocks (DAG construction) and produce a linear sequence of blocks (DAG ordering). Given the strategic significance of blockchains, formal proofs of the correctness of key components such as consensus protocols are essential. This paper presents safety-verified specifications for five DAG-based consensus protocols. Four of these protocols -- DAG-Rider, Cordial Miners, Hashgraph, and Eventual Synchronous BullShark -- are well-established in the literature. The fifth protocol is a minor variation of Aleph, another well-established protocol. Our framework enables proof reuse, reducing proof efforts by almost half. It achieves this by providing various independent, formally verified, specifications of DAG construction and ordering variations, which can be combined to express all five protocols. We employ TLA+ for specifying the protocols and writing their proofs, and the TLAPS proof system to automatically check the proofs. Each TLA+ specification is relatively compact, and TLAPS efficiently verifies hundreds to thousands of obligations within minutes. The significance of our work is two-fold: first, it supports the adoption of DAG-based systems by providing robust safety assurances; second, it illustrates that DAG-based consensus protocols are amenable to practical, reusable, and compositional formal methods.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative distributed model predictive control for embedded systems: Experiments with hovercraft formations</title>
<link>https://arxiv.org/abs/2409.13334</link>
<guid>https://arxiv.org/abs/2409.13334</guid>
<content:encoded><![CDATA[
<div> : arXiv:2409.13334v2, , Hovercraft, , 

<br />
:

HovercraftHovercraftHovercraft <div>
arXiv:2409.13334v2 Announce Type: replace 
Abstract: This paper presents experiments for embedded cooperative distributed model predictive control applied to a team of hovercraft floating on an air hockey table. The hovercraft collectively solve a centralized optimal control problem in each sampling step via a stabilizing decentralized real-time iteration scheme using the alternating direction method of multipliers. The efficient implementation does not require a central coordinator, executes onboard the hovercraft, and facilitates sampling intervals in the millisecond range. The formation control experiments showcase the flexibility of the approach on scenarios with point-to-point transitions, trajectory tracking, collision avoidance, and moving obstacles.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Multi-Robotic Arm Interaction via 3D Convex Shapes</title>
<link>https://arxiv.org/abs/2503.11791</link>
<guid>https://arxiv.org/abs/2503.11791</guid>
<content:encoded><![CDATA[
<div>  barrier (HOCBFs)/

:<br />
3DBarrierHOCBFsHessianFranka Research 3 <div>
arXiv:2503.11791v1 Announce Type: new 
Abstract: Inter-robot collisions pose a significant safety risk when multiple robotic arms operate in close proximity. We present an online collision avoidance methodology leveraging 3D convex shape-based High-Order Control Barrier Functions (HOCBFs) to address this issue. While prior works focused on using Control Barrier Functions (CBFs) for human-robotic arm and single-arm collision avoidance, we explore the problem of collision avoidance between multiple robotic arms operating in a shared space. In our methodology, we utilize the proposed HOCBFs as centralized and decentralized safety filters. These safety filters are compatible with any nominal controller and ensure safety without significantly restricting the robots' workspace. A key challenge in implementing these filters is the computational overhead caused by the large number of safety constraints and the computation of a Hessian matrix per constraint. We address this challenge by employing numerical differentiation methods to approximate computationally intensive terms. The effectiveness of our method is demonstrated through extensive simulation studies and real-world experiments with Franka Research 3 robotic arms.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TFHE-Coder: Evaluating LLM-agentic Fully Homomorphic Encryption Code Generation</title>
<link>https://arxiv.org/abs/2503.12217</link>
<guid>https://arxiv.org/abs/2503.12217</guid>
<content:encoded><![CDATA[
<div> : TFHELLM

:
TFHETFHETFHEReLULLMLLMLLMRAGagenticTFHELLMFHE <div>
arXiv:2503.12217v1 Announce Type: new 
Abstract: Fully Homomorphic Encryption over the torus (TFHE) enables computation on encrypted data without decryption, making it a cornerstone of secure and confidential computing. Despite its potential in privacy preserving machine learning, secure multi party computation, private blockchain transactions, and secure medical diagnostics, its adoption remains limited due to cryptographic complexity and usability challenges. While various TFHE libraries and compilers exist, practical code generation remains a hurdle. We propose a compiler integrated framework to evaluate LLM inference and agentic optimization for TFHE code generation, focusing on logic gates and ReLU activation. Our methodology assesses error rates, compilability, and structural similarity across open and closedsource LLMs. Results highlight significant limitations in off-the-shelf models, while agentic optimizations such as retrieval augmented generation (RAG) and few-shot prompting reduce errors and enhance code fidelity. This work establishes the first benchmark for TFHE code generation, demonstrating how LLMs, when augmented with domain-specific feedback, can bridge the expertise gap in FHE code generation.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Laboratory to Real World: A New Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification</title>
<link>https://arxiv.org/abs/2503.12232</link>
<guid>https://arxiv.org/abs/2503.12232</guid>
<content:encoded><![CDATA[
<div> -<br /><br />: -VI-ReIDL2RWL2RW1) 2) L2RWVI-ReIDL2RWVI-ReID <div>
arXiv:2503.12232v1 Announce Type: new 
Abstract: Aiming to match pedestrian images captured under varying lighting conditions, visible-infrared person re-identification (VI-ReID) has drawn intensive research attention and achieved promising results. However, in real-world surveillance contexts, data is distributed across multiple devices/entities, raising privacy and ownership concerns that make existing centralized training impractical for VI-ReID. To tackle these challenges, we propose L2RW, a benchmark that brings VI-ReID closer to real-world applications. The rationale of L2RW is that integrating decentralized training into VI-ReID can address privacy concerns in scenarios with limited data-sharing regulation. Specifically, we design protocols and corresponding algorithms for different privacy sensitivity levels. In our new benchmark, we ensure the model training is done in the conditions that: 1) data from each camera remains completely isolated, or 2) different data entities (e.g., data controllers of a certain region) can selectively share the data. In this way, we simulate scenarios with strict privacy constraints which is closer to real-world conditions. Intensive experiments with various server-side federated algorithms are conducted, showing the feasibility of decentralized VI-ReID training. Notably, when evaluated in unseen domains (i.e., new data entities), our L2RW, trained with isolated data (privacy-preserved), achieves performance comparable to SOTAs trained with shared data (privacy-unrestricted). We hope this work offers a novel research entry for deploying VI-ReID that fits real-world scenarios and can benefit the community.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GameChat: Multi-LLM Dialogue for Safe, Agile, and Socially Optimal Multi-Agent Navigation in Constrained Environments</title>
<link>https://arxiv.org/abs/2503.12333</link>
<guid>https://arxiv.org/abs/2503.12333</guid>
<content:encoded><![CDATA[
<div> 

:<br />
GameChatGameChat Barrier GameChat35%SMG-CBF20%50%100% <div>
arXiv:2503.12333v1 Announce Type: new 
Abstract: Safe, agile, and socially compliant multi-robot navigation in cluttered and constrained environments remains a critical challenge. This is especially difficult with self-interested agents in decentralized settings, where there is no central authority to resolve conflicts induced by spatial symmetry. We address this challenge by proposing a novel approach, GameChat, which facilitates safe, agile, and deadlock-free navigation for both cooperative and self-interested agents. Key to our approach is the use of natural language communication to resolve conflicts, enabling agents to prioritize more urgent tasks and break spatial symmetry in a socially optimal manner. Our algorithm ensures subgame perfect equilibrium, preventing agents from deviating from agreed-upon behaviors and supporting cooperation. Furthermore, we guarantee safety through control barrier functions and preserve agility by minimizing disruptions to agents' planned trajectories. We evaluate GameChat in simulated environments with doorways and intersections. The results show that even in the worst case, GameChat reduces the time for all agents to reach their goals by over 35% from a naive baseline and by over 20% from SMG-CBF in the intersection scenario, while doubling the rate of ensuring the agent with a higher priority task reaches the goal first, from 50% (equivalent to random chance) to a 100% perfect performance at maximizing social welfare.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SCOOP: CoSt-effective COngestiOn Attacks in Payment Channel Networks</title>
<link>https://arxiv.org/abs/2503.12625</link>
<guid>https://arxiv.org/abs/2503.12625</guid>
<content:encoded><![CDATA[
<div> : SCOOP

<br /><br />:
PCNsPCNSCOOPPCNs40%50%60%90% <div>
arXiv:2503.12625v1 Announce Type: new 
Abstract: Payment channel networks (PCNs) are a promising solution to address blockchain scalability and throughput challenges, However, the security of PCNs and their vulnerability to attacks are not sufficiently studied. In this paper, we introduce SCOOP, a framework that includes two novel congestion attacks on PCNs. These attacks consider the minimum transferable amount along a path (path capacity) and the number of channels involved (path length), formulated as linear optimization problems. The first attack allocates the attacker's budget to achieve a specific congestion threshold, while the second maximizes congestion under budget constraints. Simulation results show the effectiveness of the proposed attack formulations in comparison to other attack strategies. Specifically, the results indicate that the first attack provides around a 40\% improvement in congestion performance, while the second attack offers approximately a 50\% improvement in comparison to the state-of-the-art. Moreover, in terms of payment to congestion efficiency, the first attack is about 60\% more efficient, and the second attack is around 90\% more efficient in comparison to state-of-the-art
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enabling High-Frequency Trading with Near-Instant, Trustless Cross-Chain Transactions via Pre-Signing Adaptor Signatures</title>
<link>https://arxiv.org/abs/2503.12719</link>
<guid>https://arxiv.org/abs/2503.12719</guid>
<content:encoded><![CDATA[
<div> atomic swaps, cross-chain, cryptocurrency transactions, transaction times, decentralized finance, Bitcoin, Ethereum, protocol, intermediary currency, centralized trusted third party, 15 seconds, Layer 2 solutions.

<br /><br />
atomic swaps206015 <div>
arXiv:2503.12719v1 Announce Type: new 
Abstract: Atomic swaps have been widely considered to be an ideal solution for cross-chain cryptocurrency transactions due to their trustless and decentralized nature. However, their adoption in practice has been strictly limited compared to centralized exchange order books because of long transaction times (anywhere from 20 to 60 minutes) prohibiting market makers from accurately pricing atomic swap spreads. For the decentralized finance ecosystem to expand and benefit all users, this would require accommodating market makers and high-frequency traders to reduce spreads and dramatically boost liquidity. This white paper will introduce a protocol for atomic swaps that eliminates the need for an intermediary currency or centralized trusted third party, reducing transaction times between Bitcoin and Ethereum swaps to approximately 15 seconds for a market maker, and could be reduced further with future Layer 2 solutions.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cancermorphic Computing Toward Multilevel Machine Intelligence</title>
<link>https://arxiv.org/abs/2503.12743</link>
<guid>https://arxiv.org/abs/2503.12743</guid>
<content:encoded><![CDATA[
<div> 

:<br />
 <div>
arXiv:2503.12743v1 Announce Type: new 
Abstract: Despite their potential to address crucial bottlenecks in computing architectures and contribute to the pool of biological inspiration for engineering, pathological biological mechanisms remain absent from computational theory. We hereby introduce the concept of cancer-inspired computing as a paradigm drawing from the adaptive, resilient, and evolutionary strategies of cancer, for designing computational systems capable of thriving in dynamic, adversarial or resource-constrained environments. Unlike known bioinspired approaches (e.g., evolutionary and neuromorphic architectures), cancer-inspired computing looks at emulating the uniqueness of cancer cells survival tactics, such as somatic mutation, metastasis, angiogenesis and immune evasion, as parallels to desirable features in computing architectures, for example decentralized propagation and resource optimization, to impact areas like fault tolerance and cybersecurity. While the chaotic growth of cancer is currently viewed as uncontrollable in biology, randomness-based algorithms are already being successfully demonstrated in enhancing the capabilities of other computing architectures, for example chaos computing integration. This vision focuses on the concepts of multilevel intelligence and context-driven mutation, and their potential to simultaneously overcome plasticity-limited neuromorphic approaches and the randomness of chaotic approaches. The introduction of this concept aims to generate interdisciplinary discussion to explore the potential of cancer-inspired mechanisms toward powerful and resilient artificial systems.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LIVEPOINT: Fully Decentralized, Safe, Deadlock-Free Multi-Robot Control in Cluttered Environments with High-Dimensional Inputs</title>
<link>https://arxiv.org/abs/2503.13098</link>
<guid>https://arxiv.org/abs/2503.13098</guid>
<content:encoded><![CDATA[
<div> LIVEPOINT

:
"LIVEPOINT" Barrier LIVEPOINT  CBFsLIVEPOINT LIVEPOINT 100%MPCORCA  MPNet  LIVEPOINT 35% <div>
arXiv:2503.13098v1 Announce Type: new 
Abstract: Fully decentralized, safe, and deadlock-free multi-robot navigation in dynamic, cluttered environments is a critical challenge in robotics. Current methods require exact state measurements in order to enforce safety and liveness e.g. via control barrier functions (CBFs), which is challenging to achieve directly from onboard sensors like lidars and cameras. This work introduces LIVEPOINT, a decentralized control framework that synthesizes universal CBFs over point clouds to enable safe, deadlock-free real-time multi-robot navigation in dynamic, cluttered environments. Further, LIVEPOINT ensures minimally invasive deadlock avoidance behavior by dynamically adjusting agents' speeds based on a novel symmetric interaction metric. We validate our approach in simulation experiments across highly constrained multi-robot scenarios like doorways and intersections. Results demonstrate that LIVEPOINT achieves zero collisions or deadlocks and a 100% success rate in challenging settings compared to optimization-based baselines such as MPC and ORCA and neural methods such as MPNet, which fail in such environments. Despite prioritizing safety and liveness, LIVEPOINT is 35% smoother than baselines in the doorway environment, and maintains agility in constrained environments while still being safe and deadlock-free.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Knowledge Proof-Based Consensus for Blockchain-Secured Federated Learning</title>
<link>https://arxiv.org/abs/2503.13255</link>
<guid>https://arxiv.org/abs/2503.13255</guid>
<content:encoded><![CDATA[
<div>  zk-SNARK

:<br />
(ZKPoT)Proof-of-WorkProof-of-StakeZKPoTzk-SNARKFL <div>
arXiv:2503.13255v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple participants to collaboratively train machine learning models while ensuring their data remains private and secure. Blockchain technology further enhances FL by providing stronger security, a transparent audit trail, and protection against data tampering and model manipulation. Most blockchain-secured FL systems rely on conventional consensus mechanisms: Proof-of-Work (PoW) is computationally expensive, while Proof-of-Stake (PoS) improves energy efficiency but risks centralization as it inherently favors participants with larger stakes. Recently, learning-based consensus has emerged as an alternative by replacing cryptographic tasks with model training to save energy. However, this approach introduces potential privacy vulnerabilities, as the training process may inadvertently expose sensitive information through gradient sharing and model updates. To address these challenges, we propose a novel Zero-Knowledge Proof of Training (ZKPoT) consensus mechanism. This method leverages the zero-knowledge succinct non-interactive argument of knowledge proof (zk-SNARK) protocol to validate participants' contributions based on their model performance, effectively eliminating the inefficiencies of traditional consensus methods and mitigating the privacy risks posed by learning-based consensus. We analyze our system's security, demonstrating its capacity to prevent the disclosure of sensitive information about local models or training data to untrusted parties during the entire FL process. Extensive experiments demonstrate that our system is robust against privacy and Byzantine attacks while maintaining accuracy and utility without trade-offs, scalable across various blockchain settings, and efficient in both computation and communication.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial Spacetimes for Reactive Control of Resource-Limited Robots</title>
<link>https://arxiv.org/abs/2503.13355</link>
<guid>https://arxiv.org/abs/2503.13355</guid>
<content:encoded><![CDATA[
<div> field-based reactive control, artificial spacetimes, microrobots, formal analysis, experimental validation

:
 <div>
arXiv:2503.13355v1 Announce Type: new 
Abstract: Field-based reactive control provides a minimalist, decentralized route to guiding robots that lack onboard computation. Such schemes are well suited to resource-limited machines like microrobots, yet implementation artifacts, limited behaviors, and the frequent lack of formal guarantees blunt adoption. Here, we address these challenges with a new geometric approach called artificial spacetimes. We show that reactive robots navigating control fields obey the same dynamics as light rays in general relativity. This surprising connection allows us to adopt techniques from relativity and optics for constructing and analyzing control fields. When implemented, artificial spacetimes guide robots around structured environments, simultaneously avoiding boundaries and executing tasks like rallying or sorting, even when the field itself is static. We augment these capabilities with formal tools for analyzing what robots will do and provide experimental validation with silicon-based microrobots. Combined, this work provides a new framework for generating composed robot behaviors with minimal overhead.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARTSIA: Safeguarding Data Confidentiality in Blockchain-Driven Process Execution</title>
<link>https://arxiv.org/abs/2407.10684</link>
<guid>https://arxiv.org/abs/2407.10684</guid>
<content:encoded><![CDATA[
<div> : MARTSIA

:<br />
MARTSIAMARTSIAMARTSIAMARTSIA <div>
arXiv:2407.10684v2 Announce Type: replace 
Abstract: Blockchain technology streamlines multi-party collaborations in decentralized settings, especially when trust is limited or difficult to establish. While public blockchains enhance transparency and reliability by replicating data across all network nodes, they also conflict with confidentiality. Here, we introduce Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA) to address this challenge. MARTSIA provides fine-grained read-access control at the message-part level by combining user-defined policies with certifier-declared attributes. The approach guarantees that even though data is replicated across the network to maintain consistency, fault tolerance, and availability, its confidentiality is securely preserved through encryption. To this end, MARTSIA integrates blockchain technologies, Multi-Authority Attribute-Based Encryption, and distributed hash-table file storages. This architecture effectively balances the transparency inherent in public blockchains with the privacy required for sensitive applications. We present the tool and its applicability in a business scenario.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simultaneous Ground Reaction Force and State Estimation via Constrained Moving Horizon Estimation</title>
<link>https://arxiv.org/abs/2411.12047</link>
<guid>https://arxiv.org/abs/2411.12047</guid>
<content:encoded><![CDATA[
<div> (GRF)(MHE)

<br /><br />:
MHE200Hz0.04sBuckySTRIDEUnitree Go1GRF <div>
arXiv:2411.12047v2 Announce Type: replace 
Abstract: Accurate ground reaction force (GRF) estimation can significantly improve the adaptability of legged robots in various real-world applications. For instance, with estimated GRF and contact kinematics, the locomotion control and planning assist the robot in overcoming uncertain terrains. The canonical momentum-based methods, formulated as nonlinear observers, do not fully address the noisy measurements and the dependence between floating-base states and the generalized momentum dynamics. In this paper, we present a simultaneous ground reaction force and state estimation framework for legged robots, which systematically addresses the sensor noise and the coupling between states and dynamics. With the floating base orientation estimated separately, a decentralized Moving Horizon Estimation (MHE) method is implemented to fuse the robot dynamics, proprioceptive sensors, exteroceptive sensors, and deterministic contact complementarity constraints in a convex windowed optimization. The proposed method is shown to be capable of providing accurate GRF and state estimation on several legged robots, including the custom-designed humanoid robot Bucky, the open-source educational planar bipedal robot STRIDE, and the quadrupedal robot Unitree Go1, with a frequency of 200Hz and a past time window of 0.04s.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AVA: Fault-tolerant Reconfigurable Geo-Replication on Heterogeneous Clusters</title>
<link>https://arxiv.org/abs/2412.01999</link>
<guid>https://arxiv.org/abs/2412.01999</guid>
<content:encoded><![CDATA[
<div> Fault-tolerant replicated databases, Blockchain, Clustered replication, Heterogeneous, Reconfigurable, AVA, Safety, Liveness, Consensus-agnostic, Geo-distributed, HotStuff, BFT-SMaRt

:<br />
AVAHotStuffBFT-SMaRt <div>
arXiv:2412.01999v2 Announce Type: replace 
Abstract: Fault-tolerant replicated database systems consume less energy than the compute-intensive proof-of-work blockchain. Thus, they are promising technologies for the building blocks that assemble global financial infrastructure. To facilitate global scaling, clustered replication protocols are essential in orchestrating nodes into clusters based on proximity. However, the existing approaches often assume a homogeneous and fixed model in which the number of nodes across clusters is the same and fixed, and often limited to a fail-stop fault model. This paper presents heterogeneous and reconfigurable clustered replication for the general environment with arbitrary failures. In particular, we present AVA, a fault-tolerant reconfigurable geo-replication that allows dynamic membership: replicas are allowed to join and leave clusters. We formally state and prove the safety and liveness properties of the protocol. Furthermore, our replication protocol is consensus-agnostic, meaning each cluster can utilize any local replication mechanism. In our comprehensive evaluation, we instantiate our replication with both HotStuff and BFT-SMaRt. Experiments on geo-distributed deployments on Google Cloud demonstrates that members of clusters can be reconfigured without considerably affecting transaction processing, and that heterogeneity of clusters may significantly improve throughput.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond A Single AI Cluster: A Survey of Decentralized LLM Training</title>
<link>https://arxiv.org/abs/2503.11023</link>
<guid>https://arxiv.org/abs/2503.11023</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
 <div>
arXiv:2503.11023v1 Announce Type: new 
Abstract: The emergence of large language models (LLMs) has revolutionized AI development, yet their training demands computational resources beyond a single cluster or even datacenter, limiting accessibility to large organizations. Decentralized training has emerged as a promising paradigm to leverage dispersed resources across clusters, datacenters, and global regions, democratizing LLM development for broader communities. As the first comprehensive exploration of this emerging field, we present decentralized LLM training as a resource-driven paradigm and categorize it into community-driven and organizational approaches. Furthermore, our in-depth analysis clarifies decentralized LLM training, including: (1) position with related domain concepts comparison, (2) decentralized resource development trends, and (3) recent advances with discussion under a novel taxonomy. We also provide up-to-date case studies and explore future directions, contributing to the evolution of decentralized LLM training research.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartShards: Churn-Tolerant Continuously Available Distributed Ledger</title>
<link>https://arxiv.org/abs/2503.11077</link>
<guid>https://arxiv.org/abs/2503.11077</guid>
<content:encoded><![CDATA[
<div> : SmartShards/

<br /><br />:
SmartShardsSmartShardsSmartShardsSmartShards/ <div>
arXiv:2503.11077v1 Announce Type: new 
Abstract: We present SmartShards: a new sharding algorithm for improving Byzantine tolerance and churn resistance in blockchains. Our algorithm places a peer in multiple shards to create an overlap. This simplifies cross-shard communication and shard membership management. We describe SmartShards, prove it correct and evaluate its performance.
  We propose several SmartShards extensions: defense against a slowly adaptive adversary, combining transactions into blocks, fortification against the join/leave attack.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing 6G Dense Network Deployment for the Metaverse Using Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.11449</link>
<guid>https://arxiv.org/abs/2503.11449</guid>
<content:encoded><![CDATA[
<div> : Metaverse, 6G, (IAB), (DRL), Deep Q-Network (DQN)

:
Metaverse6GIAB6GDRLIABDeep Q-NetworkDQNDDQNDueling DQNDRLDueling DQN12.3%DRL6GIAB <div>
arXiv:2503.11449v1 Announce Type: new 
Abstract: As the Metaverse envisions deeply immersive and pervasive connectivity in 6G networks, Integrated Access and Backhaul (IAB) emerges as a critical enabler to meet the demanding requirements of massive and immersive communications. IAB networks offer a scalable solution for expanding broadband coverage in urban environments. However, optimizing IAB node deployment to ensure reliable coverage while minimizing costs remains challenging due to location constraints and the dynamic nature of cities. Existing heuristic methods, such as Greedy Algorithms, have been employed to address these optimization problems. This work presents a novel Deep Reinforcement Learning ( DRL) approach for IAB network planning, tailored to future 6G scenarios that seek to support ultra-high data rates and dense device connectivity required by immersive Metaverse applications. We utilize Deep Q-Network (DQN) with action elimination and integrate DQN, Double Deep Q-Network ( DDQN), and Dueling DQN architectures to effectively manage large state and action spaces. Simulations with various initial donor configurations demonstrate the effectiveness of our DRL approach, with Dueling DQN reducing node count by an average of 12.3% compared to traditional heuristics. The study underscores how advanced DRL techniques can address complex network planning challenges in 6G-enabled Metaverse contexts, providing an efficient and adaptive solution for IAB deployment in diverse urban environments.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lightweight Learning for Grant-Free Activity Detection in Cell-Free Massive MIMO Networks</title>
<link>https://arxiv.org/abs/2503.11305</link>
<guid>https://arxiv.org/abs/2503.11305</guid>
<content:encoded><![CDATA[
<div> grant-free(GF-RA)(mMTC)(5G)5G(6G)(AD)(CF-mMIMO)

:

GF-RAGF-RA(GB-RA)CF-mMIMOGF-RA3GPP99%<br /><br /> <div>
arXiv:2503.11305v1 Announce Type: cross 
Abstract: Grant-free random access (GF-RA) is a promising access technique for massive machine-type communications (mMTC) in future wireless networks, particularly in the context of 5G and beyond (6G) systems. Within the context of GF-RA, this study investigates the efficiency of employing supervised machine learning techniques to tackle the challenges on the device activity detection (AD). GF-RA addresses scalability by employing non-orthogonal pilot sequences, which provides an efficient alternative comparing to conventional grant-based random access (GB-RA) technique that are constrained by the scarcity of orthogonal preamble resources. In this paper, we propose a novel lightweight data-driven algorithmic framework specifically designed for activity detection in GF-RA for mMTC in cell-free massive multiple-input multiple-output (CF-mMIMO) networks. We propose two distinct framework deployment strategies, centralized and decentralized, both tailored to streamline the proposed approach implementation across network infrastructures. Moreover, we introduce optimized post-detection methodologies complemented by a clustering stage to enhance overall detection performances. Our 3GPP-compliant simulations have validated that the proposed algorithm achieves state-of-the-art model-based activity detection accuracy while significantly reducing complexity. Achieving 99% accuracy, it demonstrates real-world viability and effectiveness.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Beginner's Textbook for Fully Homomorphic Encryption</title>
<link>https://arxiv.org/abs/2503.05136</link>
<guid>https://arxiv.org/abs/2503.05136</guid>
<content:encoded><![CDATA[
<div> : (FHE)

:
FHEFHEReLUsigmoidFHEFHEFHE <div>
arXiv:2503.05136v3 Announce Type: replace 
Abstract: Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables computations to be performed directly on encrypted data, as if the data were in plaintext. After all computations are performed on the encrypted data, it can be decrypted to reveal the result. The decrypted value matches the result that would have been obtained if the same computations were applied to the plaintext data.
  FHE supports basic operations such as addition and multiplication on encrypted numbers. Using these fundamental operations, more complex computations can be constructed, including subtraction, division, logic gates (e.g., AND, OR, XOR, NAND, MUX), and even advanced mathematical functions such as ReLU, sigmoid, and trigonometric functions (e.g., sin, cos). These functions can be implemented either as exact formulas or as approximations, depending on the trade-off between computational efficiency and accuracy.
  Fully Homomorphic Encryption (FHE) enables privacy-preserving machine learning by allowing a server to process the client's data in its encrypted form through an ML model. With FHE, the server learns neither the plaintext version of the input features nor the inference results. Only the client, using their secret key, can decrypt and access the results at the end of the service protocol.FHE can also be applied to confidential blockchain services, ensuring that sensitive data in smart contracts remains encrypted and confidential while maintaining the transparency and integrity of the execution process. Other applications of FHE include secure outsourcing of data analytics, encrypted database queries, privacy-preserving searches, efficient multi-party computation for digital signatures, and more.
  This article is designed to help the reader understand how FHE works from the mathematical level.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Deadlock Avoidance for Decentralized Multi-agent Systems via CBF-inspired Risk Measurement</title>
<link>https://arxiv.org/abs/2503.09621</link>
<guid>https://arxiv.org/abs/2503.09621</guid>
<content:encoded><![CDATA[
<div> : Decentralized control, Deadlock, Control Lyapunov Function, Control Barrier Function, Multi-agent systems

:
(CLF)(CBF)CBFCBF<br /><br /> <div>
arXiv:2503.09621v1 Announce Type: new 
Abstract: Decentralized safe control plays an important role in multi-agent systems given the scalability and robustness without reliance on a central authority. However, without an explicit global coordinator, the decentralized control methods are often prone to deadlock -- a state where the system reaches equilibrium, causing the robots to stall. In this paper, we propose a generalized decentralized framework that unifies the Control Lyapunov Function (CLF) and Control Barrier Function (CBF) to facilitate efficient task execution and ensure deadlock-free trajectories for the multi-agent systems. As the agents approach the deadlock-related undesirable equilibrium, the framework can detect the equilibrium and drive agents away before that happens. This is achieved by a secondary deadlock resolution design with an auxiliary CBF to prevent the multi-agent systems from converging to the undesirable equilibrium. To avoid dominating effects due to the deadlock resolution over the original task-related controllers, a deadlock indicator function using CBF-inspired risk measurement is proposed and encoded in the unified framework for the agents to adaptively determine when to activate the deadlock resolution. This allows the agents to follow their original control tasks and seamlessly unlock or deactivate deadlock resolution as necessary, effectively improving task efficiency. We demonstrate the effectiveness of the proposed method through theoretical analysis, numerical simulations, and real-world experiments.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Complementarity, Augmentation, or Substitutivity? The Impact of Generative Artificial Intelligence on the U.S. Federal Workforce</title>
<link>https://arxiv.org/abs/2503.09637</link>
<guid>https://arxiv.org/abs/2503.09637</guid>
<content:encoded><![CDATA[
<div> : 

<br />
:
AIAIAI(OPM)AI <div>
arXiv:2503.09637v1 Announce Type: new 
Abstract: This study investigates the near-future impacts of generative artificial intelligence (AI) technologies on occupational competencies across the U.S. federal workforce. We develop a multi-stage Retrieval-Augmented Generation system to leverage large language models for predictive AI modeling that projects shifts in required competencies and to identify vulnerable occupations on a knowledge-by-skill-by-ability basis across the federal government workforce. This study highlights policy recommendations essential for workforce planning in the era of AI. We integrate several sources of detailed data on occupational requirements across the federal government from both centralized and decentralized human resource sources, including from the U.S. Office of Personnel Management (OPM) and various federal agencies. While our preliminary findings suggest some significant shifts in required competencies and potential vulnerability of certain roles to AI-driven changes, we provide nuanced insights that support arguments against abrupt or generic approaches to strategic human capital planning around the development of generative AI. The study aims to inform strategic workforce planning and policy development within federal agencies and demonstrates how this approach can be replicated across other large employment institutions and labor markets.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMSGL: A Self-Expressive Hypergraph Based Federated Multi-View Learning</title>
<link>https://arxiv.org/abs/2503.09643</link>
<guid>https://arxiv.org/abs/2503.09643</guid>
<content:encoded><![CDATA[
<div> federated learningdata privacycommunication bottleneckmulti-view dataFedMSGL

<br /><br />:
Self-expressive Hypergraph Based Federated Multi-view LearningFedMSGLFedMSGL <div>
arXiv:2503.09643v1 Announce Type: new 
Abstract: Federated learning is essential for enabling collaborative model training across decentralized data sources while preserving data privacy and security. This approach mitigates the risks associated with centralized data collection and addresses concerns related to data ownership and compliance. Despite significant advancements in federated learning algorithms that address communication bottlenecks and enhance privacy protection, existing works overlook the impact of differences in data feature dimensions, resulting in global models that disproportionately depend on participants with large feature dimensions. Additionally, current single-view federated learning methods fail to account for the unique characteristics of multi-view data, leading to suboptimal performance in processing such data. To address these issues, we propose a Self-expressive Hypergraph Based Federated Multi-view Learning method (FedMSGL). The proposed method leverages self-expressive character in the local training to learn uniform dimension subspace with latent sample relation. At the central side, an adaptive fusion technique is employed to generate the global model, while constructing a hypergraph from the learned global and view-specific subspace to capture intricate interconnections across views. Experiments on multi-view datasets with different feature dimensions validated the effectiveness of the proposed method.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Management Framework for Federated Coalition Networks</title>
<link>https://arxiv.org/abs/2503.09666</link>
<guid>https://arxiv.org/abs/2503.09666</guid>
<content:encoded><![CDATA[
<div> : , , , , 

:
(FCN)FCN <div>
arXiv:2503.09666v1 Announce Type: new 
Abstract: In a globalized and interconnected world, interoperability has become a key concept for advancing tactical scenarios. Federated Coalition Networks (FCN) enable cooperation between entities from multiple nations while allowing each to maintain control over their systems. However, this interoperability necessitates the sharing of increasing amounts of information between different tactical assets, raising the need for higher security measures. Emerging technologies like blockchain drive a revolution in secure communications, paving the way for new tactical scenarios. In this work, we propose a blockchain-based framework to enhance the resilience and security of the management of these networks. We offer a guide to FCN design to help a broad audience understand the military networks in international missions by a use case and key functions applied to a proposed architecture. We evaluate its effectiveness and performance in information encryption to validate this framework.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent LLM Actor-Critic Framework for Social Robot Navigation</title>
<link>https://arxiv.org/abs/2503.09758</link>
<guid>https://arxiv.org/abs/2503.09758</guid>
<content:encoded><![CDATA[
<div> : SAMALM

:
SAMALMactor-criticSAMALMSAMALMhttps://sites.google.com/view/SAMALM <div>
arXiv:2503.09758v1 Announce Type: new 
Abstract: Recent advances in robotics and large language models (LLMs) have sparked growing interest in human-robot collaboration and embodied intelligence. To enable the broader deployment of robots in human-populated environments, socially-aware robot navigation (SAN) has become a key research area. While deep reinforcement learning approaches that integrate human-robot interaction (HRI) with path planning have demonstrated strong benchmark performance, they often struggle to adapt to new scenarios and environments. LLMs offer a promising avenue for zero-shot navigation through commonsense inference. However, most existing LLM-based frameworks rely on centralized decision-making, lack robust verification mechanisms, and face inconsistencies in translating macro-actions into precise low-level control signals. To address these challenges, we propose SAMALM, a decentralized multi-agent LLM actor-critic framework for multi-robot social navigation. In this framework, a set of parallel LLM actors, each reflecting distinct robot personalities or configurations, directly generate control signals. These actions undergo a two-tier verification process via a global critic that evaluates group-level behaviors and individual critics that assess each robot's context. An entropy-based score fusion mechanism further enhances self-verification and re-query, improving both robustness and coordination. Experimental results confirm that SAMALM effectively balances local autonomy with global oversight, yielding socially compliant behaviors and strong adaptability across diverse multi-robot scenarios. More details and videos about this work are available at: https://sites.google.com/view/SAMALM.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Review on Understanding the Decentralized and Collaborative Approach in Machine Learning</title>
<link>https://arxiv.org/abs/2503.09833</link>
<guid>https://arxiv.org/abs/2503.09833</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
 <div>
arXiv:2503.09833v1 Announce Type: new 
Abstract: The arrival of Machine Learning (ML) completely changed how we can unlock valuable information from data. Traditional methods, where everything was stored in one place, had big problems with keeping information private, handling large amounts of data, and avoiding unfair advantages. Machine Learning has become a powerful tool that uses Artificial Intelligence (AI) to overcome these challenges. We started by learning the basics of Machine Learning, including the different types like supervised, unsupervised, and reinforcement learning. We also explored the important steps involved, such as preparing the data, choosing the right model, training it, and then checking its performance. Next, we examined some key challenges in Machine Learning, such as models learning too much from specific examples (overfitting), not learning enough (underfitting), and reflecting biases in the data used. Moving beyond centralized systems, we looked at decentralized Machine Learning and its benefits, like keeping data private, getting answers faster, and using a wider variety of data sources. We then focused on a specific type called federated learning, where models are trained without directly sharing sensitive information. Real-world examples from healthcare and finance were used to show how collaborative Machine Learning can solve important problems while still protecting information security. Finally, we discussed challenges like communication efficiency, dealing with different types of data, and security. We also explored using a Zero Trust framework, which provides an extra layer of protection for collaborative Machine Learning systems. This approach is paving the way for a bright future for this groundbreaking technology.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring Mutual Empowerment Between Wireless Networks and RL-based LLMs: A Survey</title>
<link>https://arxiv.org/abs/2503.09956</link>
<guid>https://arxiv.org/abs/2503.09956</guid>
<content:encoded><![CDATA[
<div> (RL)(LLMs)

<br /><br />:
RLLLMsChatGPTDeepSeekGrok-3RL-based LLMsRL-based LLMsRL-based LLMsRL-based LLMs <div>
arXiv:2503.09956v1 Announce Type: new 
Abstract: Reinforcement learning (RL)-based large language models (LLMs), such as ChatGPT, DeepSeek, and Grok-3, have gained significant attention for their exceptional capabilities in natural language processing and multimodal data understanding. Meanwhile, the rapid expansion of information services has driven the growing need for intelligence, efficient, and adaptable wireless networks. Wireless networks require the empowerment of RL-based LLMs while these models also benefit from wireless networks to broaden their application scenarios. Specifically, RL-based LLMs can enhance wireless communication systems through intelligent resource allocation, adaptive network optimization, and real-time decision-making. Conversely, wireless networks provide a vital infrastructure for the efficient training, deployment, and distributed inference of RL-based LLMs, especially in decentralized and edge computing environments. This mutual empowerment highlights the need for a deeper exploration of the interplay between these two domains. We first review recent advancements in wireless communications, highlighting the associated challenges and potential solutions. We then discuss the progress of RL-based LLMs, focusing on key technologies for LLM training, challenges, and potential solutions. Subsequently, we explore the mutual empowerment between these two fields, highlighting key motivations, open challenges, and potential solutions. Finally, we provide insights into future directions, applications, and their societal impact to further explore this intersection, paving the way for next-generation intelligent communication systems. Overall, this survey provides a comprehensive overview of the relationship between RL-based LLMs and wireless networks, offering a vision where these domains empower each other to drive innovations.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NumScout: Unveiling Numerical Defects in Smart Contracts using LLM-Pruning Symbolic Execution</title>
<link>https://arxiv.org/abs/2503.10041</link>
<guid>https://arxiv.org/abs/2503.10041</guid>
<content:encoded><![CDATA[
<div> : EthereumNumScout

:
(TVL)1,199NumScoutNumScoutLLM28.4%6,617NumScout1,77489.7% <div>
arXiv:2503.10041v1 Announce Type: new 
Abstract: In recent years, the Ethereum platform has witnessed a proliferation of smart contracts, accompanied by exponential growth in total value locked (TVL). High-TVL smart contracts often require complex numerical computations, particularly in mathematical financial models used by many decentralized applications (DApps). Improper calculations can introduce numerical defects, posing potential security risks. Existing research primarily focuses on traditional numerical defects like integer overflow, and there is currently a lack of systematic research and effective detection methods targeting new types of numerical defects. In this paper, we identify five new types of numerical defects through the analysis of 1,199 audit reports by utilizing the open card method. Each defect is defined and illustrated with a code example to highlight its features and potential consequences. We also propose NumScout, a symbolic execution-based tool designed to detect these five defects. Specifically, the tool combines information from source code and bytecode, analyzing key operations such as comparisons and transfers, to effectively locate defects and report them based on predefined detection patterns. Furthermore, NumScout uses a large language model (LLM) to prune functions which are unrelated to numerical operations. This step allows symbolic execution to quickly enter the target function and improve runtime speed by 28.4%. We run NumScout on 6,617 real-world contracts and evaluated its performance based on manually labeled results. We find that 1,774 contracts contained at least one of the five defects, and the tool achieved an overall precision of 89.7%.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentDAO: Synthesis of Proposal Transactions Via Abstract DAO Semantics</title>
<link>https://arxiv.org/abs/2503.10099</link>
<guid>https://arxiv.org/abs/2503.10099</guid>
<content:encoded><![CDATA[
<div> Decentralized Autonomous Organizations (DAOs)AgentLarge Language ModelsDAOLang

:
Decentralized Autonomous Organizations (DAOs)AgentLabel-Centric RetrievalDAOLangDAOLangGPT-4DAOLang <div>
arXiv:2503.10099v1 Announce Type: new 
Abstract: While the trend of decentralized governance is obvious (cryptocurrencies and blockchains are widely adopted by multiple sovereign countries), initiating governance proposals within Decentralized Autonomous Organizations (DAOs) is still challenging, i.e., it requires providing a low-level transaction payload, therefore posing significant barriers to broad community participation. To address these challenges, we propose a multi-agent system powered by Large Language Models with a novel Label-Centric Retrieval algorithm to automate the translation from natural language inputs into executable proposal transactions. The system incorporates DAOLang, a Domain-Specific Language to simplify the specification of various governance proposals. The key optimization achieved by DAOLang is a semantic-aware abstraction of user input that reliably secures proposal generation with a low level of token demand. A preliminary evaluation on real-world applications reflects the potential of DAOLang in terms of generating complicated types of proposals with existing foundation models, e.g. GPT-4o.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal Reward Allocation via Proportional Splitting</title>
<link>https://arxiv.org/abs/2503.10185</link>
<guid>https://arxiv.org/abs/2503.10185</guid>
<content:encoded><![CDATA[
<div> : BitcoinProportional Splitting (PRS)Proof-of-Work (PoW)

<br /><br />:
Proportional Splitting (PRS)PRSPRSPRSPoEMPoWPRSFruitChainsPRS <div>
arXiv:2503.10185v1 Announce Type: new 
Abstract: Following the publication of Bitcoin's arguably most famous attack, selfish mining, various works have introduced mechanisms to enhance blockchain systems' game theoretic resilience. Some reward mechanisms, like FruitChains, have been shown to be equilibria in theory. However, their guarantees assume non-realistic parameters and their performance degrades significantly in a practical deployment setting. In this work we introduce a reward allocation mechanism, called Proportional Splitting (PRS), which outperforms existing state of the art. We show that, for large enough parameters, PRS is an equilibrium, offering the same theoretical guarantees as the state of the art. In addition, for practical, realistically small, parameters, PRS outperforms all existing reward mechanisms across an array of metrics. We implement PRS on top of a variant of PoEM, a Proof-of-Work (PoW) protocol that enables a more accurate estimation of each party's mining power compared to e.g., Bitcoin. We then evaluate PRS both theoretically and in practice. On the theoretical side, we show that our protocol combined with PRS is an equilibrium and guarantees fairness, similar to FruitChains. In practice, we compare PRS with an array of existing reward mechanisms and show that, assuming an accurate estimation of the mining power distribution, it outperforms them across various well-established metrics. Finally, we realize this assumption by approximating the power distribution via low-work objects called "workshares" and quantify the tradeoff between the approximation's accuracy and storage overhead.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Modal Federated Learning Framework for Remote Sensing Image Classification</title>
<link>https://arxiv.org/abs/2503.10262</link>
<guid>https://arxiv.org/abs/2503.10262</guid>
<content:encoded><![CDATA[
<div> federated learning, , , , 

<br /><br />:
1MF2FW3MIMhttps://git.tu-berlin.de/rsim/multi-modal-FL <div>
arXiv:2503.10262v1 Announce Type: new 
Abstract: Federated learning (FL) enables the collaborative training of deep neural networks across decentralized data archives (i.e., clients) without sharing the local data of the clients. Most of the existing FL methods assume that the data distributed across all clients is associated with the same data modality. However, remote sensing (RS) images present in different clients can be associated with diverse data modalities. The joint use of the multi-modal RS data can significantly enhance classification performance. To effectively exploit decentralized and unshared multi-modal RS data, our paper introduces a novel multi-modal FL framework for RS image classification problems. The proposed framework comprises three modules: 1) multi-modal fusion (MF); 2) feature whitening (FW); and 3) mutual information maximization (MIM). The MF module employs iterative model averaging to facilitate learning without accessing multi-modal training data on clients. The FW module aims to address the limitations of training data heterogeneity by aligning data distributions across clients. The MIM module aims to model mutual information by maximizing the similarity between images from different modalities. For the experimental analyses, we focus our attention on multi-label classification and pixel-based classification tasks in RS. The results obtained using two benchmark archives show the effectiveness of the proposed framework when compared to state-of-the-art algorithms in the literature. The code of the proposed framework will be available at https://git.tu-berlin.de/rsim/multi-modal-FL.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Message Size Matters: AlterBFT's Approach to Practical Synchronous BFT in Public Clouds</title>
<link>https://arxiv.org/abs/2503.10292</link>
<guid>https://arxiv.org/abs/2503.10292</guid>
<content:encoded><![CDATA[
<div> synchronous consensus protocols, AlterBFT, hybrid synchronous system model, latency, Byzantine fault-tolerance

:
AlterBFTAlterBFT15AlterBFT <div>
arXiv:2503.10292v1 Announce Type: new 
Abstract: Synchronous consensus protocols offer a significant advantage over their asynchronous and partially synchronous counterparts by providing higher fault tolerance -- an essential benefit in distributed systems, like blockchains, where participants may have incentives to act maliciously. However, despite this advantage, synchronous protocols are often met with skepticism due to concerns about their performance, as the latency of synchronous protocols is tightly linked to a conservative time bound for message delivery.
  This paper introduces AlterBFT, a new Byzantine fault-tolerant consensus protocol. The key idea behind AlterBFT lies in the new model we propose, called hybrid synchronous system model. The new model is inspired by empirical observations about network behavior in the public cloud environment and combines elements from the synchronous and partially synchronous models. Namely, it distinguishes between small messages that respect time bounds and large messages that may violate bounds but are eventually timely. Leveraging this observation, AlterBFT achieves up to 15$\times$ lower latency than state-of-the-art synchronous protocols while maintaining similar throughput and the same fault tolerance. Compared to partially synchronous protocols, AlterBFT provides higher fault tolerance, higher throughput, and comparable latency.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Public Channel-Based Fair Exchange Protocols with Advertising</title>
<link>https://arxiv.org/abs/2503.10411</link>
<guid>https://arxiv.org/abs/2503.10411</guid>
<content:encoded><![CDATA[
<div> : fair exchange, advertising phase, zk-SNARKs, decentralized platform, NFT

:
zk-SNARKsIPFSNFT <div>
arXiv:2503.10411v1 Announce Type: new 
Abstract: Before a fair exchange takes place, there is typically an advertisement phase with the goal of increasing the appeal of possessing a digital asset while keeping it sufficiently hidden. In this work, we give a definition that explicitly combines a fair-exchange protocol with a prior advertising phase. Then, we construct such a fair exchange protocol with aids using zk-SNARKs and relying on mainstream decentralized platforms (i.e., a blockchain with smart contracts like Ethereum and a decentralized storage system like IPFS). Experimental results confirm the practical relevance of our decentralized approach, paving the road towards building decentralized marketplaces where users can, even anonymously, and without direct off-chain communications, effectively advertise and exchange their digital assets as part of a system of enhanced NFTs.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis</title>
<link>https://arxiv.org/abs/2503.10412</link>
<guid>https://arxiv.org/abs/2503.10412</guid>
<content:encoded><![CDATA[
<div> : dFLMoE

:<br />
dFLMoEMoEdFLMoE <div>
arXiv:2503.10412v1 Announce Type: new 
Abstract: Federated learning has wide applications in the medical field. It enables knowledge sharing among different healthcare institutes while protecting patients' privacy. However, existing federated learning systems are typically centralized, requiring clients to upload client-specific knowledge to a central server for aggregation. This centralized approach would integrate the knowledge from each client into a centralized server, and the knowledge would be already undermined during the centralized integration before it reaches back to each client. Besides, the centralized approach also creates a dependency on the central server, which may affect training stability if the server malfunctions or connections are unstable. To address these issues, we propose a decentralized federated learning framework named dFLMoE. In our framework, clients directly exchange lightweight head models with each other. After exchanging, each client treats both local and received head models as individual experts, and utilizes a client-specific Mixture of Experts (MoE) approach to make collective decisions. This design not only reduces the knowledge damage with client-specific aggregations but also removes the dependency on the central server to enhance the robustness of the framework. We validate our framework on multiple medical tasks, demonstrating that our method evidently outperforms state-of-the-art approaches under both model homogeneity and heterogeneity settings.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Building Cooperative Embodied Agents Modularly with Large Language Models</title>
<link>https://arxiv.org/abs/2307.02485</link>
<guid>https://arxiv.org/abs/2307.02485</guid>
<content:encoded><![CDATA[
<div> : LLMsCooperative Embodied Language Agent (CoELA)GPT-4LLAMA-2

<br /><br />:
LLMsCooperative Embodied Language Agent (CoELA)LLMsGPT-4CoELAC-WAHTDW-MATLLAMA-2CoELACoELALLMs <div>
arXiv:2307.02485v2 Announce Type: cross 
Abstract: In this work, we address challenging multi-agent cooperation problems with decentralized control, raw sensory observations, costly communication, and multi-objective tasks instantiated in various embodied environments. While previous research either presupposes a cost-free communication channel or relies on a centralized controller with shared observations, we harness the commonsense knowledge, reasoning ability, language comprehension, and text generation prowess of LLMs and seamlessly incorporate them into a cognitive-inspired modular framework that integrates with perception, memory, and execution. Thus building a Cooperative Embodied Language Agent CoELA, who can plan, communicate, and cooperate with others to accomplish long-horizon tasks efficiently. Our experiments on C-WAH and TDW-MAT demonstrate that CoELA driven by GPT-4 can surpass strong planning-based methods and exhibit emergent effective communication. Though current Open LMs like LLAMA-2 still underperform, we fine-tune a CoELA with data collected with our agents and show how they can achieve promising performance. We also conducted a user study for human-agent interaction and discovered that CoELA communicating in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COMBO: Compositional World Models for Embodied Multi-Agent Cooperation</title>
<link>https://arxiv.org/abs/2404.10775</link>
<guid>https://arxiv.org/abs/2404.10775</guid>
<content:encoded><![CDATA[
<div> 


2-4

<br /><br /> <div>
arXiv:2404.10775v2 Announce Type: replace 
Abstract: In this paper, we investigate the problem of embodied multi-agent cooperation, where decentralized agents must cooperate given only egocentric views of the world. To effectively plan in this setting, in contrast to learning world dynamics in a single-agent scenario, we must simulate world dynamics conditioned on an arbitrary number of agents' actions given only partial egocentric visual observations of the world. To address this issue of partial observability, we first train generative models to estimate the overall world state given partial egocentric observations. To enable accurate simulation of multiple sets of actions on this world state, we then propose to learn a compositional world model for multi-agent cooperation by factorizing the naturally composable joint actions of multiple agents and compositionally generating the video conditioned on the world state. By leveraging this compositional world model, in combination with Vision Language Models to infer the actions of other agents, we can use a tree search procedure to integrate these modules and facilitate online cooperative planning. We evaluate our methods on three challenging benchmarks with 2-4 agents. The results show our compositional world model is effective and the framework enables the embodied agents to cooperate efficiently with different agents across various tasks and an arbitrary number of agents, showing the promising future of our proposed methods. More videos can be found at https://embodied-agi.cs.umass.edu/combo/.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust Decentralized Learning with Local Updates and Gradient Tracking</title>
<link>https://arxiv.org/abs/2405.00965</link>
<guid>https://arxiv.org/abs/2405.00965</guid>
<content:encoded><![CDATA[
<div> 

:
--Dec-FedTrack-<br /><br /> <div>
arXiv:2405.00965v2 Announce Type: replace 
Abstract: As distributed learning applications such as Federated Learning, the Internet of Things (IoT), and Edge Computing grow, it is critical to address the shortcomings of such technologies from a theoretical perspective. As an abstraction, we consider decentralized learning over a network of communicating clients or nodes and tackle two major challenges: data heterogeneity and adversarial robustness. We propose a decentralized minimax optimization method that employs two important modules: local updates and gradient tracking. Minimax optimization is the key tool to enable adversarial training for ensuring robustness. Having local updates is essential in Federated Learning (FL) applications to mitigate the communication bottleneck, and utilizing gradient tracking is essential to proving convergence in the case of data heterogeneity. We analyze the performance of the proposed algorithm, Dec-FedTrack, in the case of nonconvex-strongly concave minimax optimization, and prove that it converges a stationary point. We also conduct numerical experiments to support our theoretical findings.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Constrained Learning for Decentralized Multi-Objective Coverage Control</title>
<link>https://arxiv.org/abs/2409.11311</link>
<guid>https://arxiv.org/abs/2409.11311</guid>
<content:encoded><![CDATA[
<div>  Swarm-- (LPAC) 

:
IDFs(1) (2) - LPAC  IDF  LPAC  30% IDFs  <div>
arXiv:2409.11311v2 Announce Type: replace 
Abstract: The multi-objective coverage control problem requires a robot swarm to collaboratively provide sensor coverage to multiple heterogeneous importance density fields IDFs simultaneously. We pose this as an optimization problem with constraints and study two different formulations: (1) Fair coverage, where we minimize the maximum coverage cost for any field, promoting equitable resource distribution among all fields; and (2) Constrained coverage, where each field must be covered below a certain cost threshold, ensuring that critical areas receive adequate coverage according to predefined importance levels. We study the decentralized setting where robots have limited communication and local sensing capabilities, making the system more realistic, scalable, and robust. Given the complexity, we propose a novel decentralized constrained learning approach that combines primal-dual optimization with a Learnable Perception-Action-Communication (LPAC) neural network architecture. We show that the Lagrangian of the dual problem can be reformulated as a linear combination of the IDFs, enabling the LPAC policy to serve as a primal solver. We empirically demonstrate that the proposed method (i) significantly outperforms state-of-the-art decentralized controllers by 30% on average in terms of coverage cost, (ii) transfers well to larger environments with more robots, and (iii) scalable in the number of IDFs and robots in the swarm.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assessing Vulnerability in Smart Contracts: The Role of Code Complexity Metrics in Security Analysis</title>
<link>https://arxiv.org/abs/2411.17343</link>
<guid>https://arxiv.org/abs/2411.17343</guid>
<content:encoded><![CDATA[
<div> Solidity

:
<br />
Solidity21 <div>
arXiv:2411.17343v3 Announce Type: replace 
Abstract: Codes with specific characteristics are more exposed to security vulnerabilities. Studies have revealed that codes that do not adhere to best practices are more challenging to verify and maintain, increasing the likelihood of unnoticed or unintentionally introduced vulnerabilities. Given the crucial role of smart contracts in blockchain systems, ensuring their security and conducting thorough vulnerability analysis is critical. This study investigates the use of code complexity metrics as indicators of vulnerable code in Solidity smart contracts. We highlight the significance of complexity metrics as valuable complementary features for vulnerability assessment and provide insights into the individual power of each metric. By analyzing 21 complexity metrics, we explored their interrelation, association with vulnerability, discriminative power, and mean values in vulnerable versus neutral codes. The results revealed some high correlations and potential redundancies among certain metrics, but weak correlations between each independent metric and vulnerability. Nevertheless, we found that all metrics can effectively discriminate between vulnerable and neutral codes, and most complexity metrics, except for three, exhibited higher values in vulnerable codes.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain As a Platform For Artificial Intelligence (AI) Transparency</title>
<link>https://arxiv.org/abs/2503.08699</link>
<guid>https://arxiv.org/abs/2503.08699</guid>
<content:encoded><![CDATA[
<div> : 

:
AIAIAIAIAIAI <div>
arXiv:2503.08699v1 Announce Type: new 
Abstract: As artificial intelligence (AI) systems become increasingly complex and autonomous, concerns over transparency and accountability have intensified. The "black box" problem in AI decision-making limits stakeholders' ability to understand, trust, and verify outcomes, particularly in high-stakes sectors such as healthcare, finance, and autonomous systems. Blockchain technology, with its decentralized, immutable, and transparent characteristics, presents a potential solution to enhance AI transparency and auditability. This paper explores the integration of blockchain with AI to improve decision traceability, data provenance, and model accountability. By leveraging blockchain as an immutable record-keeping system, AI decision-making can become more interpretable, fostering trust among users and regulatory compliance. However, challenges such as scalability, integration complexity, and computational overhead must be addressed to fully realize this synergy. This study discusses existing research, proposes a framework for blockchain-enhanced AI transparency, and highlights practical applications, benefits, and limitations. The findings suggest that blockchain could be a foundational technology for ensuring AI systems remain accountable, ethical, and aligned with regulatory standards.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Secure Blockchain-Assisted Framework for Real-Time Maritime Environmental Compliance Monitoring</title>
<link>https://arxiv.org/abs/2503.08707</link>
<guid>https://arxiv.org/abs/2503.08707</guid>
<content:encoded><![CDATA[
<div> MARPOL

:<br />
MARPOLPolygonPolygon <div>
arXiv:2503.08707v1 Announce Type: new 
Abstract: The maritime industry is governed by stringent environmental regulations, most notably the International Convention for the Prevention of Pollution from Ships (MARPOL). Ensuring compliance with these regulations is difficult due to low inspection rates and the risk of data fabrication. To address these issues, this paper proposes a secure blockchain-assisted framework for real-time maritime environmental compliance monitoring. By integrating IoT and shipboard sensors with blockchain technology, the framework ensures immutable and transparent record-keeping of environmental data. Smart contracts automate compliance verification and notify relevant authorities in case of non-compliance. A proof-of-concept case study on sulfur emissions demonstrates the framework's efficacy in enhancing MARPOL enforcement through real-time data integrity and regulatory adherence. The proposed system leverages the Polygon blockchain for scalability and efficiency, providing a robust solution for maritime environmental protection. The evaluation results demonstrate that the proposed blockchain-enhanced compliance monitoring system effectively and securely ensures real-time regulatory adherence with high scalability, efficiency, and cost-effectiveness, leveraging the robust capabilities of the Polygon blockchain.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Semantic Link Network Model for Supporting Traceability of Logistics on Blockchain</title>
<link>https://arxiv.org/abs/2503.08717</link>
<guid>https://arxiv.org/abs/2503.08717</guid>
<content:encoded><![CDATA[
<div> : -

:
- <div>
arXiv:2503.08717v1 Announce Type: new 
Abstract: The ability of tracing states of logistic transportations requires an efficient storage and retrieval of the state of logistic transportations and locations of logistic objects. However, the restriction of sharing states and locations of logistic objects across organizations from different countries makes it hard to deploy a centralized database for implementing the traceability in a cross-border logistic system. This paper proposes a semantic data model on Blockchain to represent a logistic process based on the Semantic Link Network model where each semantic link represents a logistic transportation of a logistic object between two parties. A state representation model is designed to represent the states of a logistic transportation with semantic links. It enables the locations of logistic objects to be derived from the link states. A mapping from the semantic links to the blockchain transactions is designed to enable schema of semantic links and states of semantic links to be published in blockchain transactions. To improve the efficiency of tracing a path of semantic links on blockchain platform, an algorithm is designed to build shortcuts along the path of semantic links to enable a query on the path of a logistic object to reach the target in logarithmic steps on the blockchain platform. A reward-penalty policy is designed to allow participants to confirm the state of links on blockchain. Analysis and simulation demonstrate the flexibility, effectiveness and the efficiency of Semantic Link Network on immutable blockchain for implementing logistic traceability.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentive Analysis for Agent Participation in Federated Learning</title>
<link>https://arxiv.org/abs/2503.09039</link>
<guid>https://arxiv.org/abs/2503.09039</guid>
<content:encoded><![CDATA[
<div> 

:
 <div>
arXiv:2503.09039v1 Announce Type: new 
Abstract: Federated learning offers a decentralized approach to machine learning, where multiple agents collaboratively train a model while preserving data privacy. In this paper, we investigate the decision-making and equilibrium behavior in federated learning systems, where agents choose between participating in global training or conducting independent local training. The problem is first modeled as a stage game and then extended to a repeated game to analyze the long-term dynamics of agent participation. For the stage game, we characterize the participation patterns and identify Nash equilibrium, revealing how data heterogeneity influences the equilibrium behavior-specifically, agents with similar data qualities will participate in FL as a group. We also derive the optimal social welfare and show that it coincides with Nash equilibrium under mild assumptions. In the repeated game, we propose a privacy-preserving, computationally efficient myopic strategy. This strategy enables agents to make practical decisions under bounded rationality and converges to a neighborhood of Nash equilibrium of the stage game in finite time. By combining theoretical insights with practical strategy design, this work provides a realistic and effective framework for guiding and analyzing agent behaviors in federated learning systems.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Data Analytics: Review and Challenges</title>
<link>https://arxiv.org/abs/2503.09165</link>
<guid>https://arxiv.org/abs/2503.09165</guid>
<content:encoded><![CDATA[
<div> 

:
<br /><br /> <div>
arXiv:2503.09165v1 Announce Type: new 
Abstract: The integration of blockchain technology with data analytics is essential for extracting insights in the cryptocurrency space. Although academic literature on blockchain data analytics is limited, various industry solutions have emerged to address these needs. This paper provides a comprehensive literature review, drawing from both academic research and industry applications. We classify blockchain analytics tools into categories such as block explorers, on-chain data providers, research platforms, and crypto market data providers. Additionally, we discuss the challenges associated with blockchain data analytics, including data accessibility, scalability, accuracy, and interoperability. Our findings emphasize the importance of bridging academic research and industry innovations to advance blockchain data analytics.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RaceTEE: A Practical Privacy-Preserving Off-Chain Smart Contract Execution Architecture</title>
<link>https://arxiv.org/abs/2503.09317</link>
<guid>https://arxiv.org/abs/2503.09317</guid>
<content:encoded><![CDATA[
<div> : Decentralized on-chain smart contracts, Privacy-preserving, Off-chain execution, Trusted Execution Environments (TEEs), RaceTEE

:
RaceTEE(TEEs)RaceTEETEEsRaceTEETEEIntel SGXEthereumRaceTEE <div>
arXiv:2503.09317v1 Announce Type: new 
Abstract: Decentralized on-chain smart contracts enable trustless collaboration, yet their inherent data transparency and execution overhead hinder widespread adoption. Existing cryptographic approaches incur high computational costs and lack generality. Meanwhile, prior TEE-based solutions suffer from practical limitations, such as the inability to support inter-contract interactions, reliance on unbreakable TEEs, and compromised usability. We introduce RaceTEE, a practical and privacy-preserving off-chain execution architecture for smart contracts that leverages Trusted Execution Environments (TEEs). RaceTEE decouples transaction ordering (on-chain) from execution (off-chain), with computations performed competitively in TEEs, ensuring confidentiality and minimizing overhead. It further enhances practicality through three key improvements: supporting secure inter-contract interactions, providing a key rotation scheme that enforces forward and backward secrecy even in the event of TEE breaches, and enabling full compatibility with existing blockchains without altering the user interaction model. To validate its feasibility, we prototype RaceTEE using Intel SGX and Ethereum, demonstrating its applicability across various use cases and evaluating its performance.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Heuristic-Based Address Clustering in Cardano Blockchain</title>
<link>https://arxiv.org/abs/2503.09327</link>
<guid>https://arxiv.org/abs/2503.09327</guid>
<content:encoded><![CDATA[
<div> CardanoExtended Unspent Transaction Outputs

:
CardanoExtended Unspent Transaction OutputsCardanoUnionFind2017920231CardanoCardano9.67 <div>
arXiv:2503.09327v1 Announce Type: new 
Abstract: Blockchain technology has recently gained widespread popularity as a practical method of storing immutable data while preserving the privacy of users by anonymizing their real identities. This anonymization approach, however, significantly complicates the analysis of blockchain data. To address this problem, heuristic-based clustering algorithms as an effective way of linking all addresses controlled by the same entity have been presented in the literature. In this paper, considering the particular features of the Extended Unspent Transaction Outputs accounting model introduced by the Cardano blockchain, two new clustering heuristics are proposed for clustering the Cardano payment addresses. Applying these heuristics and employing the UnionFind algorithm, we efficiently cluster all the addresses that have appeared on the Cardano blockchain from September 2017 to January 2023, where each cluster represents a distinct entity. The results show that each medium-sized entity in the Cardano network owns and controls 9.67 payment addresses on average. The results also confirm that a power law distribution is fitted to the distribution of entity sizes recognized using our proposed heuristics.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning on Virtual Heterogeneous Data with Local-global Distillation</title>
<link>https://arxiv.org/abs/2303.02278</link>
<guid>https://arxiv.org/abs/2303.02278</guid>
<content:encoded><![CDATA[
<div> Federated Learningdataset distillationheterogeneityFedLGDvirtual heterogeneous data

<br /><br />:
FedLGDFedLGDFedLGDhttps://github.com/ubc-tea/FedLGD  <div>
arXiv:2303.02278v3 Announce Type: replace 
Abstract: While Federated Learning (FL) is gaining popularity for training machine learning models in a decentralized fashion, numerous challenges persist, such as asynchronization, computational expenses, data heterogeneity, and gradient and membership privacy attacks. Lately, dataset distillation has emerged as a promising solution for addressing the aforementioned challenges by generating a compact synthetic dataset that preserves a model's training efficacy. However, we discover that using distilled local datasets can amplify the heterogeneity issue in FL. To address this, we propose Federated Learning on Virtual Heterogeneous Data with Local-Global Dataset Distillation (FedLGD), where we seamlessly integrate dataset distillation algorithms into FL pipeline and train FL using a smaller synthetic dataset (referred as virtual data). Specifically, to harmonize the domain shifts, we propose iterative distribution matching to inpaint global information to local virtual data and use federated gradient matching to distill global virtual data that serve as anchor points to rectify heterogeneous local training, without compromising data privacy. We experiment on both benchmark and real-world datasets that contain heterogeneous data from different sources, and further scale up to an FL scenario that contains a large number of clients with heterogeneous and class-imbalanced data. Our method outperforms state-of-the-art heterogeneous FL algorithms under various settings. Our code is available at https://github.com/ubc-tea/FedLGD.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Overcoming Data and Model Heterogeneities in Decentralized Federated Learning via Synthetic Anchors</title>
<link>https://arxiv.org/abs/2405.11525</link>
<guid>https://arxiv.org/abs/2405.11525</guid>
<content:encoded><![CDATA[
<div> : Decentralized Federated Learning, Data Heterogeneity, Model Generalizability, Synthetic Anchors, Knowledge Distillation

<br /><br />:
DeSAFLDeSAKDREGKDDeSA <div>
arXiv:2405.11525v2 Announce Type: replace 
Abstract: Conventional Federated Learning (FL) involves collaborative training of a global model while maintaining user data privacy. One of its branches, decentralized FL, is a serverless network that allows clients to own and optimize different local models separately, which results in saving management and communication resources. Despite the promising advancements in decentralized FL, it may reduce model generalizability due to lacking a global model. In this scenario, managing data and model heterogeneity among clients becomes a crucial problem, which poses a unique challenge that must be overcome: How can every client's local model learn generalizable representation in a decentralized manner? To address this challenge, we propose a novel Decentralized FL technique by introducing Synthetic Anchors, dubbed as DeSA. Based on the theory of domain adaptation and Knowledge Distillation (KD), we theoretically and empirically show that synthesizing global anchors based on raw data distribution facilitates mutual knowledge transfer. We further design two effective regularization terms for local training: 1) REG loss that regularizes the distribution of the client's latent embedding with the anchors and 2) KD loss that enables clients to learn from others. Through extensive experiments on diverse client data distributions, we showcase the effectiveness of DeSA in enhancing both inter- and intra-domain accuracy of each client.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trustworthy AIGC Copyright Management with Full Lifecycle Recording and Multi-party Supervision in Blockchain</title>
<link>https://arxiv.org/abs/2406.14966</link>
<guid>https://arxiv.org/abs/2406.14966</guid>
<content:encoded><![CDATA[
<div> (AIGC)

<br />
: AIAIGCAIGCAIGCAIGCAIGCAIGC <div>
arXiv:2406.14966v2 Announce Type: replace 
Abstract: As artificial intelligence technology becomes increasingly widespread, AI-generated content (AIGC) is gradually penetrating into many fields. Although AIGC plays an increasingly prominent role in business and cultural communication, the issue of copyright has also triggered widespread social discussion. The current legal system for copyright is built around human creators, yet in the realm of AIGC, the role of humans in content creation has diminished, with the creative expression primarily reliant on artificial intelligence. This discrepancy has led to numerous complexities and challenges in determining the copyright ownership of AIGC within the established legal boundaries. In view of this, it is necessary to meticulously record contributions of all entities involved in the generation of AIGC to achieve a fair distribution of copyright. For this purpose, this study thoroughly records the intermediate data generated throughout the full lifecycle of AIGC and deposits them into a decentralized blockchain system for secure multi-party supervision, thereby constructing a trustworthy AIGC copyright management system. In the event of copyright disputes, auditors can retrieve valuable proof from the blockchain, accurately defining the copyright ownership of AIGC products. Both theoretical and experimental analyses confirm that this scheme shows exceptional performance and security in the management of AIGC copyrights.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain</title>
<link>https://arxiv.org/abs/2409.16444</link>
<guid>https://arxiv.org/abs/2409.16444</guid>
<content:encoded><![CDATA[
<div> : (IoT), , (DRL), , 

:<br />
(IoT)(DRL)20152024DRLDRLDRL <div>
arXiv:2409.16444v2 Announce Type: replace 
Abstract: The accelerated expansion of the Internet of Things (IoT) has raised critical challenges associated with privacy, security, and data integrity, specifically in infrastructures such as smart cities or smart manufacturing. Blockchain technology provides immutable, scalable, and decentralized solutions to address these challenges, and integrating deep reinforcement learning (DRL) into the IoT environment offers enhanced adaptability and decision-making. This paper investigates the integration of blockchain and DRL to optimize mobile transmission and secure data exchange in IoT-assisted smart cities. Through the clustering and categorization of IoT application systems, the combination of DRL and blockchain is shown to enhance the performance of IoT networks by maintaining privacy and security. Based on the review of papers published between 2015 and 2024, we have classified the presented approaches and offered practical taxonomies, which provide researchers with critical perspectives and highlight potential areas for future exploration and research. Our investigation shows how combining blockchain's decentralized framework with DRL can address privacy and security issues, improve mobile transmission efficiency, and guarantee robust, privacy-preserving IoT systems. Additionally, we explore blockchain integration for DRL and outline the notable applications of DRL technology. By addressing the challenges of machine learning and blockchain integration, this study proposes novel perspectives for researchers and serves as a foundational exploration from an interdisciplinary standpoint.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HIPPO-MAT: Decentralized Task Allocation Using GraphSAGE and Multi-Agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.07662</link>
<guid>https://arxiv.org/abs/2503.07662</guid>
<content:encoded><![CDATA[
<div> <br /><br /><br />
HIPPO-MATGraphSAGEIPPOUAVsUGVsA*30JetBot ROS AIJetson NanoESP-NOWESP32-S3SLAM92.5%16.49%300.32 <div>
arXiv:2503.07662v1 Announce Type: new 
Abstract: This paper tackles decentralized continuous task allocation in heterogeneous multi-agent systems. We present a novel framework HIPPO-MAT that integrates graph neural networks (GNN) employing a GraphSAGE architecture to compute independent embeddings on each agent with an Independent Proximal Policy Optimization (IPPO) approach for multi-agent deep reinforcement learning. In our system, unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) share aggregated observation data via communication channels while independently processing these inputs to generate enriched state embeddings. This design enables dynamic, cost-optimal, conflict-aware task allocation in a 3D grid environment without the need for centralized coordination. A modified A* path planner is incorporated for efficient routing and collision avoidance. Simulation experiments demonstrate scalability with up to 30 agents and preliminary real-world validation on JetBot ROS AI Robots, each running its model on a Jetson Nano and communicating through an ESP-NOW protocol using ESP32-S3, which confirms the practical viability of the approach that incorporates simultaneous localization and mapping (SLAM). Experimental results revealed that our method achieves a high 92.5% conflict-free success rate, with only a 16.49% performance gap compared to the centralized Hungarian method, while outperforming the heuristic decentralized baseline based on greedy approach. Additionally, the framework exhibits scalability with up to 30 agents with allocation processing of 0.32 simulation step time and robustness in responding to dynamically generated tasks.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Using a single actor to output personalized policy for different intersections</title>
<link>https://arxiv.org/abs/2503.07678</link>
<guid>https://arxiv.org/abs/2503.07678</guid>
<content:encoded><![CDATA[
<div> :  (MARL),  (ATSC),  (non-iid ),  (HAMH-PPO),  (CTDE)

:
HAMH-PPOHAMH-PPOCTDEHAMH-PPOPPOHAMH-PPO- <div>
arXiv:2503.07678v1 Announce Type: new 
Abstract: Recently, with the development of Multi-agent reinforcement learning (MARL), adaptive traffic signal control (ATSC) has achieved satisfactory results. In traffic scenarios with multiple intersections, MARL treats each intersection as an agent and optimizes traffic signal control strategies through learning and real-time decision-making. Considering that observation distributions of intersections might be different in real-world scenarios, shared parameter methods might lack diversity and thus lead to high generalization requirements in the shared-policy network. A typical solution is to increase the size of network parameters. However, simply increasing the scale of the network does not necessarily improve policy generalization, which is validated in our experiments. Accordingly, an approach that considers both the personalization of intersections and the efficiency of parameter sharing is required. To this end, we propose Hyper-Action Multi-Head Proximal Policy Optimization (HAMH-PPO), a Centralized Training with Decentralized Execution (CTDE) MARL method that utilizes a shared PPO policy network to deliver personalized policies for intersections with non-iid observation distributions. The centralized critic in HAMH-PPO uses graph attention units to calculate the graph representations of all intersections and outputs a set of value estimates with multiple output heads for each intersection. The decentralized execution actor takes the local observation history as input and output distributions of action as well as a so-called hyper-action to balance the multiple values estimated from the centralized critic to further guide the updating of TSC policies. The combination of hyper-action and multi-head values enables multiple agents to share a single actor-critic while achieving personalized policies.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos</title>
<link>https://arxiv.org/abs/2503.07799</link>
<guid>https://arxiv.org/abs/2503.07799</guid>
<content:encoded><![CDATA[
<div> : (CHD)

:
(CHD)(STUD)CHD(VAD)(DivMerge)VADCHDF123.77%30.13%5 <div>
arXiv:2503.07799v1 Announce Type: new 
Abstract: Congenital Heart Disease (CHD) is one of the leading causes of fetal mortality, yet the scarcity of labeled CHD data and strict privacy regulations surrounding fetal ultrasound (US) imaging present significant challenges for the development of deep learning-based models for CHD detection. Centralised collection of large real-world datasets for rare conditions, such as CHD, from large populations requires significant co-ordination and resource. In addition, data governance rules increasingly prevent data sharing between sites. To address these challenges, we introduce, for the first time, a novel privacy-preserving, zero-shot CHD detection framework that formulates CHD detection as a normality modeling problem integrated with model merging. In our framework dubbed Sparse Tube Ultrasound Distillation (STUD), each hospital site first trains a sparse video tube-based self-supervised video anomaly detection (VAD) model on normal fetal heart US clips with self-distillation loss. This enables site-specific models to independently learn the distribution of healthy cases. To aggregate knowledge across the decentralized models while maintaining privacy, we propose a Divergence Vector-Guided Model Merging approach, DivMerge, that combines site-specific models into a single VAD model without data exchange. Our approach preserves domain-agnostic rich spatio-temporal representations, ensuring generalization to unseen CHD cases. We evaluated our approach on real-world fetal US data collected from 5 hospital sites. Our merged model outperformed site-specific models by 23.77% and 30.13% in accuracy and F1-score respectively on external test sets.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Network Analysis of Uniswap: Centralization and Fragility in the Decentralized Exchange Market</title>
<link>https://arxiv.org/abs/2503.07834</link>
<guid>https://arxiv.org/abs/2503.07834</guid>
<content:encoded><![CDATA[
<div> Uniswap

<br />
:

Uniswap20231031Uniswap-202055Uniswap V220231031UniswapUniswapTVL <div>
arXiv:2503.07834v1 Announce Type: new 
Abstract: The Uniswap is a Decentralized Exchange (DEX) protocol that facilitates automatic token exchange without the need for traditional order books. Every pair of tokens forms a liquidity pool on Uniswap, and each token can be paired with any other token to create liquidity pools. This characteristic motivates us to employ a complex network approach to analyze the features of the Uniswap market. This research presents a comprehensive analysis of the Uniswap network using complex network methods. The network on October 31, 2023, is built to observe its recent features, showcasing both scale-free and core-periphery properties. By employing node and edge-betweenness metrics, we detect the most important tokens and liquidity pools. Additionally, we construct daily networks spanning from the beginning of Uniswap V2 on May 5, 2020, until October 31, 2023, and our findings demonstrate that the network becomes increasingly fragile over time. Furthermore, we conduct a robustness analysis by simulating the deletion of nodes to estimate the impact of some extreme events such as the Terra collapse. The results indicate that the Uniswap network exhibits robustness, yet it is notably fragile when deleting tokens with high betweenness centrality. This finding highlights that, despite being a decentralized exchange, Uniswap exhibits significant centralization tendencies in terms of token network connectivity and the distribution of TVL across nodes (tokens) and edges (liquidity pools).
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Integration of Grid Edge Resources into Wholesale Electricity Markets via Mean-field Games</title>
<link>https://arxiv.org/abs/2503.07984</link>
<guid>https://arxiv.org/abs/2503.07984</guid>
<content:encoded><![CDATA[
<div> 

:
prosumerDERprosumerprosumerMFEMFEDER <div>
arXiv:2503.07984v1 Announce Type: new 
Abstract: Grid edge resources refer to distributed energy resources (DERs) located on the consumer side of the electrical grid, controlled by consumers rather than utility companies. Integrating DERs with real-time electricity pricing can better align distributed supply with system demand, improving grid efficiency and reliability. However, DER owners, known as prosumers, often lack the expertise and resources to directly participate in wholesale energy markets, limiting their ability to fully realize the economic potential of their assets. Meanwhile, as DER adoption grows, the number of prosumers participating in the energy system is expected to increase significantly, creating additional challenges in coordination and market participation.
  To address these challenges, we propose a mean-field game framework that enables prosumers to autonomously learn optimal decision policies based on dynamic market prices and their variable solar generation. Our framework is designed to accommodate heterogeneous agents and demonstrates the existence of a mean-field equilibrium (MFE) in a wholesale energy market with many prosumers. Additionally, we introduce an algorithm that automates prosumers' resource control, facilitating real-time decision-making for energy storage management. Numerical experiments suggest that our approach converges towards an MFE and effectively reduces peak loads and price volatility, especially during periods of external demand or supply shocks. This study highlights the potential of a fully decentralized approach to integrating DERs into wholesale markets while improving market efficiency.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordinated Path Following of UAVs using Event-Triggered Communication over Networks with Digraph Topologies</title>
<link>https://arxiv.org/abs/2503.08129</link>
<guid>https://arxiv.org/abs/2503.08129</guid>
<content:encoded><![CDATA[
<div> UAV

:
Zeno<br /><br /> <div>
arXiv:2503.08129v1 Announce Type: new 
Abstract: This article presents a novel time-coordination algorithm based on event-triggered communication to ensure multiple UAVs progress along their desired paths in coordination with one another. In the proposed algorithm, a UAV transmits its progression information to its neighbor UAVs only when a decentralized trigger condition is satisfied. Consequently, it significantly reduces the volume of inter-vehicle communications required to achieve the goal compared with the existing algorithms based on continuous communication. With such intermittent communications, it is shown that a decentralized coordination controller guarantees exponential convergence of the coordination error to a neighborhood of zero. Furthermore, a lower bound on the difference between two consecutive event-triggered times is provided showing that the Zeno behavior is excluded with the proposed algorithm. Lastly, simulation results validate the efficacy of the proposed algorithm.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Query Verification for Blockchain Superlight Clients Using SNARKs</title>
<link>https://arxiv.org/abs/2503.08359</link>
<guid>https://arxiv.org/abs/2503.08359</guid>
<content:encoded><![CDATA[
<div> SNARKs

<br /><br />:
SNARKsSNARKs <div>
arXiv:2503.08359v1 Announce Type: new 
Abstract: Blockchains are among the most powerful technologies to realize decentralized information systems. In order to safely enjoy all guarantees provided by a blockchain, one should maintain a full node, therefore maintaining an updated local copy of the ledger. This allows one to locally verify transactions, states of smart contracts, and to compute any information over them.
  Unfortunately, for obvious practical reasons, a very large part of blockchain-based information systems consists of users relying on clients that access data stored in blockchains only through servers, without verifying what is received. In notable use cases, the user has application-specific queries that can be answered only by very few servers, sometimes all belonging to the same organization. This clearly re-introduces a single point of failure.
  In this work we present an architecture allowing superlight clients (i.e., clients that do not want to download the involved transactions) to outsource the computation of a query to a (possibly untrusted) server, receiving a trustworthy answer. Our architecture relies on the power of SNARKs and makes them lighter to compute by using data obtained from full nodes and blockchain explorers, possibly leveraging the existence of smart contracts.
  The viability of our architecture is confirmed by an experimental evaluation on concrete scenarios. Our work paves the road towards blockchain-based information systems that remain decentralized and reliable even when users rely on common superlight clients (e.g., smartphones).
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modular Customization of Diffusion Models via Blockwise-Parameterized Low-Rank Adaptation</title>
<link>https://arxiv.org/abs/2503.08575</link>
<guid>https://arxiv.org/abs/2503.08575</guid>
<content:encoded><![CDATA[
<div> : BlockLoRA

:
BlockLoRABlockLoRALoRABlockLoRA15 <div>
arXiv:2503.08575v1 Announce Type: new 
Abstract: Recent diffusion model customization has shown impressive results in incorporating subject or style concepts with a handful of images. However, the modular composition of multiple concepts into a customized model, aimed to efficiently merge decentralized-trained concepts without influencing their identities, remains unresolved. Modular customization is essential for applications like concept stylization and multi-concept customization using concepts trained by different users. Existing post-training methods are only confined to a fixed set of concepts, and any different combinations require a new round of retraining. In contrast, instant merging methods often cause identity loss and interference of individual merged concepts and are usually limited to a small number of concepts. To address these issues, we propose BlockLoRA, an instant merging method designed to efficiently combine multiple concepts while accurately preserving individual concepts' identity. With a careful analysis of the underlying reason for interference, we develop the Randomized Output Erasure technique to minimize the interference of different customized models. Additionally, Blockwise LoRA Parameterization is proposed to reduce the identity loss during instant model merging. Extensive experiments validate the effectiveness of BlockLoRA, which can instantly merge 15 concepts of people, subjects, scenes, and styles with high fidelity.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Fair and Lightweight Consensus Algorithm for IoT</title>
<link>https://arxiv.org/abs/2503.08607</link>
<guid>https://arxiv.org/abs/2503.08607</guid>
<content:encoded><![CDATA[
<div> IoT

:
<br />
(IoT)1) 2) 3)  <div>
arXiv:2503.08607v1 Announce Type: new 
Abstract: As hyperconnected devices and decentralized data architectures expand, securing IoT transactions becomes increasingly challenging. Blockchain offers a promising solution, but its effectiveness relies on the underlying consensus algorithm. Traditional mechanisms like PoW and PoS are often impractical for resource-constrained IoT environments. To address these limitations, this work introduces a fair and lightweight hybrid consensus algorithm tailored for IoT. The proposed approach minimizes resource demands on the nodes while ensuring a secure and fair agreement process. Specifically, it leverages a distributed lottery mechanism to fairly propose blocks without requiring specialized hardware. In addition, a reputation-based block voting mechanism is incorporated to enhance trust and establish finality. Finally, experimental evaluation was conducted to validate the key features of the consensus algorithm.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Low-Cost Privacy-Preserving Decentralized Learning</title>
<link>https://arxiv.org/abs/2403.11795</link>
<guid>https://arxiv.org/abs/2403.11795</guid>
<content:encoded><![CDATA[
<div> : , Zip-DL, , , 

:<br />
Zip-DLZip-DLZip-DLZip-DL35%13%Zip-DL59%Zip-DL <div>
arXiv:2403.11795v3 Announce Type: replace 
Abstract: Decentralized learning (DL) is an emerging paradigm of collaborative machine learning that enables nodes in a network to train models collectively without sharing their raw data or relying on a central server. This paper introduces Zip-DL, a privacy-aware DL algorithm that leverages correlated noise to achieve robust privacy against local adversaries while ensuring efficient convergence at low communication costs. By progressively neutralizing the noise added during distributed averaging, Zip-DL combines strong privacy guarantees with high model accuracy. Its design requires only one communication round per gradient descent iteration, significantly reducing communication overhead compared to competitors. We establish theoretical bounds on both convergence speed and privacy guarantees. Moreover, extensive experiments demonstrating Zip-DL's practical applicability make it outperform state-of-the-art methods in the accuracy vs. vulnerability trade-off. Specifically, Zip-DL (i) reduces membership-inference attack success rates by up to 35% compared to baseline DL, (ii) decreases attack efficacy by up to 13% compared to competitors offering similar utility, and (iii) achieves up to 59% higher accuracy to completely nullify a basic attack scenario, compared to a state-of-the-art privacy-preserving approach under the same threat model. These results position Zip-DL as a practical and efficient solution for privacy-preserving decentralized learning in real-world applications.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Formal Foundation for Blockchain Rollups</title>
<link>https://arxiv.org/abs/2406.16219</link>
<guid>https://arxiv.org/abs/2406.16219</guid>
<content:encoded><![CDATA[
<div> Layer 2ZK-Rollups

<br /><br />:
Layer 2RollupsZK-RollupsLayer 2AlloyLayer 2Rollups <div>
arXiv:2406.16219v2 Announce Type: replace 
Abstract: Blockchains like Bitcoin and Ethereum have revolutionized digital transactions, yet scalability issues persist. Layer 2 solutions, such as validity proof Rollups (ZK-Rollups), aim to address these challenges by processing transactions off-chain and validating them on the main chain. However, concerns remain about security and censorship resistance, particularly regarding centralized control in Layer 2 and inadequate mechanisms for enforcing these properties through Layer 1 contracts. This work presents a formal analysis using the Alloy specification language to examine and design key Layer 2 functionalities, including forced transaction queues, safe blacklisting, and upgradeability. Through this analysis, we identify potential vulnerabilities in current mechanisms and propose enhanced models to strengthen security and censorship resistance, setting new standards for the security of rollups.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A new framework for prognostics in decentralized industries: Enhancing fairness, security, and transparency through Blockchain and Federated Learning</title>
<link>https://arxiv.org/abs/2503.05725</link>
<guid>https://arxiv.org/abs/2503.05725</guid>
<content:encoded><![CDATA[
<div> : , , , , 4.0

:<br />
4.0(FL)(BC)(RUL)FLBCNASA CMAPSSGitHub4.0 <div>
arXiv:2503.05725v1 Announce Type: new 
Abstract: As global industries transition towards Industry 5.0 predictive maintenance PM remains crucial for cost effective operations resilience and minimizing downtime in increasingly smart manufacturing environments In this chapter we explore how the integration of Federated Learning FL and blockchain BC technologies enhances the prediction of machinerys Remaining Useful Life RUL within decentralized and human centric industrial ecosystems Traditional centralized data approaches raise concerns over privacy security and scalability especially as Artificial intelligence AI driven smart manufacturing becomes more prevalent This chapter leverages FL to enable localized model training across multiple sites while utilizing BC to ensure trust transparency and data integrity across the network This BC integrated FL framework optimizes RUL predictions enhances data privacy and security establishes transparency and promotes collaboration in decentralized manufacturing It addresses key challenges such as maintaining privacy and security ensuring transparency and fairness and incentivizing participation in decentralized networks Experimental validation using the NASA CMAPSS dataset demonstrates the model effectiveness in real world scenarios and we extend our findings to the broader research community through open source code on GitHub inviting collaborative development to drive innovation in Industry 5.0
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SEAFL: Enhancing Efficiency in Semi-Asynchronous Federated Learning through Adaptive Aggregation and Selective Training</title>
<link>https://arxiv.org/abs/2503.05755</link>
<guid>https://arxiv.org/abs/2503.05755</guid>
<content:encoded><![CDATA[
<div> Federated Learningstragglersasynchronous FLsemi-asynchronous FLSEAFL

:<br />
SEAFLSEAFLSEAFLSEAFL22% <div>
arXiv:2503.05755v1 Announce Type: new 
Abstract: Federated Learning (FL) is a promising distributed machine learning framework that allows collaborative learning of a global model across decentralized devices without uploading their local data. However, in real-world FL scenarios, the conventional synchronous FL mechanism suffers from inefficient training caused by slow-speed devices, commonly known as stragglers, especially in heterogeneous communication environments. Though asynchronous FL effectively tackles the efficiency challenge, it induces substantial system overheads and model degradation. Striking for a balance, semi-asynchronous FL has gained increasing attention, while still suffering from the open challenge of stale models, where newly arrived updates are calculated based on outdated weights that easily hurt the convergence of the global model. In this paper, we present {\em SEAFL}, a novel FL framework designed to mitigate both the straggler and the stale model challenges in semi-asynchronous FL. {\em SEAFL} dynamically assigns weights to uploaded models during aggregation based on their staleness and importance to the current global model. We theoretically analyze the convergence rate of {\em SEAFL} and further enhance the training efficiency with an extended variant that allows partial training on slower devices, enabling them to contribute to global aggregation while reducing excessive waiting times. We evaluate the effectiveness of {\em SEAFL} through extensive experiments on three benchmark datasets. The experimental results demonstrate that {\em SEAFL} outperforms its closest counterpart by up to $\sim$22\% in terms of the wall-clock training time required to achieve target accuracy.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Between Innovation and Oversight: A Cross-Regional Study of AI Risk Management Frameworks in the EU, U.S., UK, and China</title>
<link>https://arxiv.org/abs/2503.05773</link>
<guid>https://arxiv.org/abs/2503.05773</guid>
<content:encoded><![CDATA[
<div> : (AI)(EU)(U.S.)(UK)

<br />
:
AI <div>
arXiv:2503.05773v1 Announce Type: new 
Abstract: As artificial intelligence (AI) technologies increasingly enter important sectors like healthcare, transportation, and finance, the development of effective governance frameworks is crucial for dealing with ethical, security, and societal risks. This paper conducts a comparative analysis of AI risk management strategies across the European Union (EU), United States (U.S.), United Kingdom (UK), and China. A multi-method qualitative approach, including comparative policy analysis, thematic analysis, and case studies, investigates how these regions classify AI risks, implement compliance measures, structure oversight, prioritize transparency, and respond to emerging innovations. Examples from high-risk contexts like healthcare diagnostics, autonomous vehicles, fintech, and facial recognition demonstrate the advantages and limitations of different regulatory models. The findings show that the EU implements a structured, risk-based framework that prioritizes transparency and conformity assessments, while the U.S. uses decentralized, sector-specific regulations that promote innovation but may lead to fragmented enforcement. The flexible, sector-specific strategy of the UK facilitates agile responses but may lead to inconsistent coverage across domains. China's centralized directives allow rapid large-scale implementation while constraining public transparency and external oversight. These insights show the necessity for AI regulation that is globally informed yet context-sensitive, aiming to balance effective risk management with technological progress. The paper concludes with policy recommendations and suggestions for future research aimed at enhancing effective, adaptive, and inclusive AI governance globally.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Technology Adoption in Food Bank Supply Chains: A Rough DEMATEL-Based Approach</title>
<link>https://arxiv.org/abs/2503.05811</link>
<guid>https://arxiv.org/abs/2503.05811</guid>
<content:encoded><![CDATA[
<div> : DEMATEL

<br /><br />:
(FBSC)(DEMATEL)DEMATEL <div>
arXiv:2503.05811v1 Announce Type: new 
Abstract: Food banks can improve food donation administration, provide real-time inventory tracking, and guarantee compliance with food safety regulations by incorporating blockchain technology. The efficiency, openness, and dependability of food bank supply chains are greatly increased by this integration, leading to more sustainable and successful operations. This study focuses on two primary objectives: identifying key barriers to effective Food bank supply chain (FBSC) operations in blockchain adoption and exploring the interrelationships among these barriers. Barriers were categorized into external and internal frameworks and analyzed using insights from academics and FBs experts. The Decision-Making Trial and Evaluation Laboratory (DEMATEL) methodology was employed to model and quantify the causal relationships among these barriers. DEMATEL's strength lies in its ability to map interdependencies and feedback loops, providing a nuanced understanding of the links between independent and dependent variables in a cause-and-effect network. To address subjectivity and ambiguity in expert opinions during group decision-making, rough theory was integrated with DEMATEL, ensuring a robust approach to handling conflicting perspectives and uncertainty.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Distributed Learning-Enhanced Predictive Control for Multiple Quadrupedal Robots</title>
<link>https://arxiv.org/abs/2503.05836</link>
<guid>https://arxiv.org/abs/2503.05836</guid>
<content:encoded><![CDATA[
<div> : Formation controlControl Lyapunov FunctionsControl Barrier FunctionsScale-Adaptive Permutation-Invariant EncodingSAPIEData Distribution ServiceDDSDeadlock resolutionNVIDIA Omniverse Isaac SimReal-world experiments

<br /><br />:

Scale-Adaptive Permutation-Invariant Encoding (SAPIE) Data Distribution ServiceNVIDIA Omniverse Isaac SimXG <div>
arXiv:2503.05836v1 Announce Type: new 
Abstract: Quadrupedal robots exhibit remarkable adaptability in unstructured environments, making them well-suited for formation control in real-world applications. However, keeping stable formations while ensuring collision-free navigation presents significant challenges due to dynamic obstacles, communication constraints, and the complexity of legged locomotion. This paper proposes a distributed model predictive control framework for multi-quadruped formation control, integrating Control Lyapunov Functions to ensure formation stability and Control Barrier Functions for decentralized safety enforcement. To address the challenge of dynamically changing team structures, we introduce Scale-Adaptive Permutation-Invariant Encoding (SAPIE), which enables robust feature encoding of neighboring robots while preserving permutation invariance. Additionally, we develop a low-latency Data Distribution Service-based communication protocol and an event-triggered deadlock resolution mechanism to enhance real-time coordination and prevent motion stagnation in constrained spaces. Our framework is validated through high-fidelity simulations in NVIDIA Omniverse Isaac Sim and real-world experiments using our custom quadrupedal robotic system, XG. Results demonstrate stable formation control, real-time feasibility, and effective collision avoidance, validating its potential for large-scale deployment.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Merry-Go-Round: Safe Control of Decentralized Multi-Robot Systems with Deadlock Prevention</title>
<link>https://arxiv.org/abs/2503.05848</link>
<guid>https://arxiv.org/abs/2503.05848</guid>
<content:encoded><![CDATA[
<div> 

:
<br /><br /> <div>
arXiv:2503.05848v1 Announce Type: new 
Abstract: We propose a hybrid approach for decentralized multi-robot navigation that ensures both safety and deadlock prevention. Building on a standard control formulation, we add a lightweight deadlock prevention mechanism by forming temporary "roundabouts" (circular reference paths). Each robot relies only on local, peer-to-peer communication and a controller for base collision avoidance; a roundabout is generated or joined on demand to avert deadlocks. Robots in the roundabout travel in one direction until an escape condition is met, allowing them to return to goal-oriented motion. Unlike classical decentralized methods that lack explicit deadlock resolution, our roundabout maneuver ensures system-wide forward progress while preserving safety constraints. Extensive simulations and physical robot experiments show that our method consistently outperforms or matches the success and arrival rates of other decentralized control approaches, particularly in cluttered or high-density scenarios, all with minimal centralized coordination.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Universal Scalability in Declarative Program Analysis (with Choice-Based Combination Pruning)</title>
<link>https://arxiv.org/abs/2503.05945</link>
<guid>https://arxiv.org/abs/2503.05945</guid>
<content:encoded><![CDATA[
<div> Datalogchoice

:<br />
DatalogSouffl\'ecardinalityDatalogJavaDoopGigahorse20 <div>
arXiv:2503.05945v1 Announce Type: new 
Abstract: In this work, we present a simple, uniform, and elegant solution to the problem, with stunning practical effectiveness and application to virtually any Datalog-based analysis. The approach consists of leveraging the choice construct, supported natively in modern Datalog engines like Souffl\'e. The choice construct allows the definition of functional dependencies in a relation and has been used in the past for expressing worklist algorithms. We show a near-universal construction that allows the choice construct to flexibly limit evaluation of predicates. The technique is applicable to practically any analysis architecture imaginable, since it adaptively prunes evaluation results when a (programmer-controlled) projection of a relation exceeds a desired cardinality. We apply the technique to probably the largest, pre-existing Datalog analysis frameworks in existence: Doop (for Java bytecode) and the main client analyses from the Gigahorse framework (for Ethereum smart contracts). Without needing to understand the existing analysis logic and with minimal, local-only changes, the performance of each framework increases dramatically, by over 20x for the hardest inputs, with near-negligible sacrifice in completeness.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Multi-Agent Q-Learning for Policy Optimization: Decentralized Wireless Networks</title>
<link>https://arxiv.org/abs/2503.05970</link>
<guid>https://arxiv.org/abs/2503.05970</guid>
<content:encoded><![CDATA[
<div> Q-learningQMEMQMEMQM-MEMQ

:<br />
TXsBSsMEMQM-MEMQQ-learningM-MEMQTXsQTXsQTX-CTDEM-MEMQAPE55%35%50%45%M-MEMQAPE <div>
arXiv:2503.05970v1 Announce Type: new 
Abstract: Q-learning is a widely used reinforcement learning (RL) algorithm for optimizing wireless networks, but faces challenges with large state-spaces. Recently proposed multi-environment mixed Q-learning (MEMQ) algorithm addresses these challenges by employing multiple Q-learning algorithms across multiple synthetically generated, distinct but structurally related environments, so-called digital cousins. In this paper, we propose a novel multi-agent MEMQ (M-MEMQ) for cooperative decentralized wireless networks with multiple networked transmitters (TXs) and base stations (BSs). TXs do not have access to global information (joint state and actions). The new concept of coordinated and uncoordinated states is introduced. In uncoordinated states, TXs act independently to minimize their individual costs and update local Q-functions. In coordinated states, TXs use a Bayesian approach to estimate the joint state and update the joint Q-functions. The cost of information-sharing scales linearly with the number of TXs and is independent of the joint state-action space size. Several theoretical guarantees, including deterministic and probabilistic convergence, bounds on estimation error variance, and the probability of misdetecting the joint states, are given. Numerical simulations show that M-MEMQ outperforms several decentralized and centralized training with decentralized execution (CTDE) multi-agent RL algorithms by achieving 55% lower average policy error (APE), 35% faster convergence, 50% reduced runtime complexity, and 45% less sample complexity. Furthermore, M-MEMQ achieves comparable APE with significantly lower complexity than centralized methods. Simulations validate the theoretical analyses.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedEM: A Privacy-Preserving Framework for Concurrent Utility Preservation in Federated Learning</title>
<link>https://arxiv.org/abs/2503.06021</link>
<guid>https://arxiv.org/abs/2503.06021</guid>
<content:encoded><![CDATA[
<div> Federated Learningprivacy concernsgradient-sharing processFederated Error Minimization (FedEM)adaptive noise injection

<br />
:
Federated Error Minimization (FedEM) gradient FedEM  <div>
arXiv:2503.06021v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative training of models across distributed clients without sharing local data, addressing privacy concerns in decentralized systems. However, the gradient-sharing process exposes private data to potential leakage, compromising FL's privacy guarantees in real-world applications. To address this issue, we propose Federated Error Minimization (FedEM), a novel algorithm that incorporates controlled perturbations through adaptive noise injection. This mechanism effectively mitigates gradient leakage attacks while maintaining model performance. Experimental results on benchmark datasets demonstrate that FedEM significantly reduces privacy risks and preserves model accuracy, achieving a robust balance between privacy protection and utility preservation.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Free Black-Box Federated Learning via Zeroth-Order Gradient Estimation</title>
<link>https://arxiv.org/abs/2503.06028</link>
<guid>https://arxiv.org/abs/2503.06028</guid>
<content:encoded><![CDATA[
<div> : , , , , 

:<br />
FedZGEFedZGE <div>
arXiv:2503.06028v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized clients to collaboratively train a global model under the orchestration of a central server without exposing their individual data. However, the iterative exchange of model parameters between the server and clients imposes heavy communication burdens, risks potential privacy leakage, and even precludes collaboration among heterogeneous clients. Distillation-based FL tackles these challenges by exchanging low-dimensional model outputs rather than model parameters, yet it highly relies on a task-relevant auxiliary dataset that is often not available in practice. Data-free FL attempts to overcome this limitation by training a server-side generator to directly synthesize task-specific data samples for knowledge transfer. However, the update rule of the generator requires clients to share on-device models for white-box access, which greatly compromises the advantages of distillation-based FL. This motivates us to explore a data-free and black-box FL framework via Zeroth-order Gradient Estimation (FedZGE), which estimates the gradients after flowing through on-device models in a black-box optimization manner to complete the training of the generator in terms of fidelity, transferability, diversity, and equilibrium, without involving any auxiliary data or sharing any model parameters, thus combining the advantages of both distillation-based FL and data-free FL. Experiments on large-scale image classification datasets and network architectures demonstrate the superiority of FedZGE in terms of data heterogeneity, model heterogeneity, communication efficiency, and privacy protection.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vairiational Stochastic Games</title>
<link>https://arxiv.org/abs/2503.06037</link>
<guid>https://arxiv.org/abs/2503.06037</guid>
<content:encoded><![CDATA[
<div> Control as Inference (CAI)<br /><br /><br />
CAI- <div>
arXiv:2503.06037v1 Announce Type: new 
Abstract: The Control as Inference (CAI) framework has successfully transformed single-agent reinforcement learning (RL) by reframing control tasks as probabilistic inference problems. However, the extension of CAI to multi-agent, general-sum stochastic games (SGs) remains underexplored, particularly in decentralized settings where agents operate independently without centralized coordination. In this paper, we propose a novel variational inference framework tailored to decentralized multi-agent systems. Our framework addresses the challenges posed by non-stationarity and unaligned agent objectives, proving that the resulting policies form an $\epsilon$-Nash equilibrium. Additionally, we demonstrate theoretical convergence guarantees for the proposed decentralized algorithms. Leveraging this framework, we instantiate multiple algorithms to solve for Nash equilibrium, mean-field Nash equilibrium, and correlated equilibrium, with rigorous theoretical convergence analysis.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vision-aware Multimodal Prompt Tuning for Uploadable Multi-source Few-shot Domain Adaptation</title>
<link>https://arxiv.org/abs/2503.06106</link>
<guid>https://arxiv.org/abs/2503.06106</guid>
<content:encoded><![CDATA[
<div> :  (MFDA),  (UMFDA), CLIP,  (VAMP), 

<br />
:
(UMFDA)CLIP(VAMP)OfficeHomeDomainNetVAMPUMFDA <div>
arXiv:2503.06106v1 Announce Type: new 
Abstract: Conventional multi-source domain few-shot adaptation (MFDA) faces the challenge of further reducing the load on edge-side devices in low-resource scenarios. Considering the native language-supervised advantage of CLIP and the plug-and-play nature of prompt to transfer CLIP efficiently, this paper introduces an uploadable multi-source few-shot domain adaptation (UMFDA) schema. It belongs to a decentralized edge collaborative learning in the edge-side models that must maintain a low computational load. And only a limited amount of annotations in source domain data is provided, with most of the data being unannotated. Further, this paper proposes a vision-aware multimodal prompt tuning framework (VAMP) under the decentralized schema, where the vision-aware prompt guides the text domain-specific prompt to maintain semantic discriminability and perceive the domain information. The cross-modal semantic and domain distribution alignment losses optimize each edge-side model, while text classifier consistency and semantic diversity losses promote collaborative learning among edge-side models. Extensive experiments were conducted on OfficeHome and DomainNet datasets to demonstrate the effectiveness of the proposed VAMP in the UMFDA, which outperformed the previous prompt tuning methods.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generation of Optimized Solidity Code for Machine Learning Models using LLMs</title>
<link>https://arxiv.org/abs/2503.06203</link>
<guid>https://arxiv.org/abs/2503.06203</guid>
<content:encoded><![CDATA[
<div> : (ML), , LMST, (LLMs), 

<br /><br />:
LMSTLLMsMLSoliditygasMLLLMsML <div>
arXiv:2503.06203v1 Announce Type: new 
Abstract: While a plethora of machine learning (ML) models are currently available, along with their implementation on disparate platforms, there is hardly any verifiable ML code which can be executed on public blockchains. We propose a novel approach named LMST that enables conversion of the inferencing path of an ML model as well as its weights trained off-chain into Solidity code using Large Language Models (LLMs). Extensive prompt engineering is done to achieve gas cost optimization beyond mere correctness of the produced code, while taking into consideration the capabilities and limitations of the Ethereum Virtual Machine. We have also developed a proof of concept decentralized application using the code so generated for verifying the accuracy claims of the underlying ML model. An extensive set of experiments demonstrate the feasibility of deploying ML models on blockchains through automated code translation using LLMs.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigating Blockchain extractable value (BEV) threats by Distributed Transaction Sequencing in Blockchains</title>
<link>https://arxiv.org/abs/2503.06279</link>
<guid>https://arxiv.org/abs/2503.06279</guid>
<content:encoded><![CDATA[
<div> : (DeFi)Transaction Order Dependence (TOD)Blockchain Extractable Value (BEV)Distributed Transaction Sequencing Strategy (DTSS)

<br /><br />:
(DeFi)TODBEVTIDDeFiBEV$540.54 million(DTSS)(AHP)DTSSNormalized Allocation Disparity Metric (NADM)DTSSBEVDeFi <div>
arXiv:2503.06279v1 Announce Type: new 
Abstract: The rapid growth of Blockchain and Decentralized Finance (DeFi) has introduced new challenges and vulnerabilities that threaten the integrity and efficiency of the ecosystem. This study identifies critical issues such as Transaction Order Dependence (TOD), Blockchain Extractable Value (BEV), and Transaction Importance Diversity (TID), which collectively undermine the fairness and security of DeFi systems. BEV-related activities, including Sandwich attacks, Liquidations, and Transaction Replay, have emerged as significant threats, collectively generating $540.54 million in losses over 32 months across 11,289 addresses, involving 49,691 cryptocurrencies and 60,830 on-chain markets. These attacks exploit transaction mechanics to manipulate asset prices and extract value at the expense of other participants, with Sandwich attacks being particularly impactful. Additionally, the growing adoption of Blockchain in traditional finance highlights the challenge of TID, where high transaction volumes can strain systems and compromise time-sensitive operations. To address these pressing issues, we propose a novel Distributed Transaction Sequencing Strategy (DTSS), which combines forking mechanisms and the Analytic Hierarchy Process (AHP) to enforce fair and transparent transaction ordering in a decentralized manner. Our approach is further enhanced by an optimization framework and the introduction of the Normalized Allocation Disparity Metric (NADM), which ensures optimal parameter selection for transaction prioritization. Experimental evaluations demonstrate that DTSS effectively mitigates BEV risks, enhances transaction fairness, and significantly improves the security and transparency of DeFi ecosystems. This work is essential for protecting the future of decentralized finance and promoting its integration into global financial systems.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mobility-Aware Decentralized Federated Learning with Joint Optimization of Local Iteration and Leader Selection for Vehicular Networks</title>
<link>https://arxiv.org/abs/2503.06443</link>
<guid>https://arxiv.org/abs/2503.06443</guid>
<content:encoded><![CDATA[
<div> :  (Federated Learning)

:
MDFLFLMDFLLSOPDec-POMDPMAPPODec-POMDP<br /><br /> <div>
arXiv:2503.06443v1 Announce Type: new 
Abstract: Federated learning (FL) emerges as a promising approach to empower vehicular networks, composed by intelligent connected vehicles equipped with advanced sensing, computing, and communication capabilities. While previous studies have explored the application of FL in vehicular networks, they have largely overlooked the intricate challenges arising from the mobility of vehicles and resource constraints.In this paper, we propose a framework of mobility-aware decentralized federated learning (MDFL) for vehicular networks. In this framework, nearby vehicles train an FL model collaboratively, yet in a decentralized manner. We formulate a local iteration and leader selection joint optimization problem (LSOP) to improve the training efficiency of MDFL. For problem solving, we first reformulate LSOP as a decentralized partially observable Markov decision process (Dec-POMDP), and then develop an effective optimization algorithm based on multi-agent proximal policy optimization (MAPPO) to solve Dec-POMDP. Finally, we verify the performance of the proposed algorithm by comparing it with other algorithms.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mobility-Aware Multi-Task Decentralized Federated Learning for Vehicular Networks: Modeling, Analysis, and Optimization</title>
<link>https://arxiv.org/abs/2503.06468</link>
<guid>https://arxiv.org/abs/2503.06468</guid>
<content:encoded><![CDATA[
<div> : arXiv:2503.06468v1, , , , , , 

:<br />
MMFLTSLPFLTSLPDEC-POMDPHAPPODEC-POMDP <div>
arXiv:2503.06468v1 Announce Type: new 
Abstract: Federated learning (FL) is a promising paradigm that can enable collaborative model training between vehicles while protecting data privacy, thereby significantly improving the performance of intelligent transportation systems (ITSs). In vehicular networks, due to mobility, resource constraints, and the concurrent execution of multiple training tasks, how to allocate limited resources effectively to achieve optimal model training of multiple tasks is an extremely challenging issue. In this paper, we propose a mobility-aware multi-task decentralized federated learning (MMFL) framework for vehicular networks. By this framework, we address task scheduling, subcarrier allocation, and leader selection, as a joint optimization problem, termed as TSLP. For the case with a single FL task, we derive the convergence bound of model training. For general cases, we first model TSLP as a resource allocation game, and prove the existence of a Nash equilibrium (NE). Then, based on this proof, we reformulate the game as a decentralized partially observable Markov decision process (DEC-POMDP), and develop an algorithm based on heterogeneous-agent proximal policy optimization (HAPPO) to solve DEC-POMDP. Finally, numerical results are used to demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully-Decentralized MADDPG with Networked Agents</title>
<link>https://arxiv.org/abs/2503.06747</link>
<guid>https://arxiv.org/abs/2503.06747</guid>
<content:encoded><![CDATA[
<div> MADDPG

:
-MADDPGMADDPG <div>
arXiv:2503.06747v1 Announce Type: new 
Abstract: In this paper, we devise three actor-critic algorithms with decentralized training for multi-agent reinforcement learning in cooperative, adversarial, and mixed settings with continuous action spaces. To this goal, we adapt the MADDPG algorithm by applying a networked communication approach between agents. We introduce surrogate policies in order to decentralize the training while allowing for local communication during training. The decentralized algorithms achieve comparable results to the original MADDPG in empirical tests, while reducing computational cost. This is more pronounced with larger numbers of agents.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collective Behavior Clone with Visual Attention via Neural Interaction Graph Prediction</title>
<link>https://arxiv.org/abs/2503.06869</link>
<guid>https://arxiv.org/abs/2503.06869</guid>
<content:encoded><![CDATA[
<div> collective behavioral cloning (CBC)graph variational autoencoder (GVAE)swarm systemvisual attention networkdecentralized vision-based robot swarm

<br />
:
(CBC)(GVAE)CBC Swarm  <div>
arXiv:2503.06869v1 Announce Type: new 
Abstract: In this paper, we propose a framework, collective behavioral cloning (CBC), to learn the underlying interaction mechanism and control policy of a swarm system. Given the trajectory data of a swarm system, we propose a graph variational autoencoder (GVAE) to learn the local interaction graph. Based on the interaction graph and swarm trajectory, we use behavioral cloning to learn the control policy of the swarm system. To demonstrate the practicality of CBC, we deploy it on a real-world decentralized vision-based robot swarm system. A visual attention network is trained based on the learned interaction graph for online neighbor selection. Experimental results show that our method outperforms previous approaches in predicting both the interaction graph and swarm actions with higher accuracy. This work offers a promising approach for understanding interaction mechanisms and swarm dynamics in future swarm robotics research. Code and data are available.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Comparing User Activity on X and Mastodon</title>
<link>https://arxiv.org/abs/2503.07068</link>
<guid>https://arxiv.org/abs/2503.07068</guid>
<content:encoded><![CDATA[
<div> FediverseTwitterMastodon

<br />
:
FediverseMastodonTwitterTwitterMastodonmstdn.jp <div>
arXiv:2503.07068v1 Announce Type: new 
Abstract: The "Fediverse", a federation of decentralized social media servers, has emerged after a decade in which centralized platforms like X (formerly Twitter) have dominated the landscape. The structure of a federation should affect user activity, as a user selects a server to access the Fediverse and posts are distributed along the structure. This paper reports on the differences in user activity between Twitter and Mastodon, a prominent example of decentralized social media. The target of the analysis is Japanese posts because both Twitter and Mastodon are actively used especially in Japan. Our findings include a larger number of replies on Twitter, more consistent user engagement on mstdn.jp, and different topic preferences on each server.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedRand: Enhancing Privacy in Federated Learning with Randomized LoRA Subparameter Updates</title>
<link>https://arxiv.org/abs/2503.07216</link>
<guid>https://arxiv.org/abs/2503.07216</guid>
<content:encoded><![CDATA[
<div> Federated Learningvision-languageLow-Rank AdaptationFedRand

:
<br />
FedRandFedRandLoRALoRAVLMFedRandMembership Inference AttacksMIA <div>
arXiv:2503.07216v1 Announce Type: new 
Abstract: Federated Learning (FL) is a widely used framework for training models in a decentralized manner, ensuring that the central server does not have direct access to data from local clients. However, this approach may still fail to fully preserve data privacy, as models from local clients are exposed to the central server during the aggregation process. This issue becomes even more critical when training vision-language models (VLMs) with FL, as VLMs can easily memorize training data instances, making them vulnerable to membership inference attacks (MIAs). To address this challenge, we propose the FedRand framework, which avoids disclosing the full set of client parameters. In this framework, each client randomly selects subparameters of Low-Rank Adaptation (LoRA) from the server and keeps the remaining counterparts of the LoRA weights as private parameters. After training both parameters on the client's private dataset, only the non-private client parameters are sent back to the server for aggregation. This approach mitigates the risk of exposing client-side VLM parameters, thereby enhancing data privacy. We empirically validate that FedRand improves robustness against MIAs compared to relevant baselines while achieving accuracy comparable to methods that communicate full LoRA parameters across several benchmark datasets.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Availability Modeling for Blockchain Provisioning in Private Clouds</title>
<link>https://arxiv.org/abs/2503.07391</link>
<guid>https://arxiv.org/abs/2503.07391</guid>
<content:encoded><![CDATA[
<div> Hyperledger Fabric

:
<br />
Hyperledger Fabric <div>
arXiv:2503.07391v1 Announce Type: new 
Abstract: Blockchain technology has emerged, and many previous studies have assessed its performance issues. However, less attention has been paid to the dependability attributes, which have been a critical topic in service provisioning, considering public or private infrastructures. This paper introduces analytical models to assess the availability of private blockchain infrastructure for Hyperledger Fabric-based applications. Furthermore, a case study will be presented to demonstrate the feasibility of the proposed model, which may assist stakeholders in deciding whether to migrate from old to new technology. Some of the obtained results indicate that, unlike most conventional systems, general availability may decrease as new nodes are added to the environment. This phenomenon occurs due to the adopted endorsement policy, which determines the proportion of required nodes to sign the authenticity of a transaction.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Centralized to Decentralized Federated Learning: Theoretical Insights, Privacy Preservation, and Robustness Challenges</title>
<link>https://arxiv.org/abs/2503.07505</link>
<guid>https://arxiv.org/abs/2503.07505</guid>
<content:encoded><![CDATA[
<div> Federated LearningCentralized FLDecentralized FLSeparate AggregationJoint Optimization

<br /><br />:
arXiv:2503.07505v1Federated LearningFLFLCentralized FL, CFLFLDecentralized FL, DFLCFLDFLCFLDFLDFLFL <div>
arXiv:2503.07505v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative learning without directly sharing individual's raw data. FL can be implemented in either a centralized (server-based) or decentralized (peer-to-peer) manner. In this survey, we present a novel perspective: the fundamental difference between centralized FL (CFL) and decentralized FL (DFL) is not merely the network topology, but the underlying training protocol: separate aggregation vs. joint optimization. We argue that this distinction in protocol leads to significant differences in model utility, privacy preservation, and robustness to attacks. We systematically review and categorize existing works in both CFL and DFL according to the type of protocol they employ. This taxonomy provides deeper insights into prior research and clarifies how various approaches relate or differ. Through our analysis, we identify key gaps in the literature. In particular, we observe a surprising lack of exploration of DFL approaches based on distributed optimization methods, despite their potential advantages. We highlight this under-explored direction and call for more research on leveraging distributed optimization for federated learning. Overall, this work offers a comprehensive overview from centralized to decentralized FL, sheds new light on the core distinctions between approaches, and outlines open challenges and future directions for the field.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentive-Compatible Recovery from Manipulated Signals, with Applications to Decentralized Physical Infrastructure</title>
<link>https://arxiv.org/abs/2503.07558</link>
<guid>https://arxiv.org/abs/2503.07558</guid>
<content:encoded><![CDATA[
<div> unverifiable informationsignal networkdecentralized physical infrastructure networks (DePIN)truthful signal reportingsource identifiability

:
""""DePINDePIN <div>
arXiv:2503.07558v1 Announce Type: new 
Abstract: We introduce the first formal model capturing the elicitation of unverifiable information from a party (the "source") with implicit signals derived by other players (the "observers"). Our model is motivated in part by applications in decentralized physical infrastructure networks (a.k.a. "DePIN"), an emerging application domain in which physical services (e.g., sensor information, bandwidth, or energy) are provided at least in part by untrusted and self-interested parties. A key challenge in these signal network applications is verifying the level of service that was actually provided by network participants.
  We first establish a condition called source identifiability, which we show is necessary for the existence of a mechanism for which truthful signal reporting is a strict equilibrium. For a converse, we build on techniques from peer prediction to show that in every signal network that satisfies the source identifiability condition, there is in fact a strictly truthful mechanism, where truthful signal reporting gives strictly higher total expected payoff than any less informative equilibrium. We furthermore show that this truthful equilibrium is in fact the unique equilibrium of the mechanism if there is positive probability that any one observer is unconditionally honest (e.g., if an observer were run by the network owner). Also, by extending our condition to coalitions, we show that there are generally no collusion-resistant mechanisms in the settings that we consider.
  We apply our framework and results to two DePIN applications: proving location, and proving bandwidth. In the location-proving setting observers learn (potentially enlarged) Euclidean distances to the source. Here, our condition has an appealing geometric interpretation, implying that the source's location can be truthfully elicited if and only if it is guaranteed to lie inside the convex hull of the observers.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Split-n-Chain: Privacy-Preserving Multi-Node Split Learning with Blockchain-Based Auditability</title>
<link>https://arxiv.org/abs/2503.07570</link>
<guid>https://arxiv.org/abs/2503.07570</guid>
<content:encoded><![CDATA[
<div> : Split-n-Chain

:
Split-n-ChainSplit-n-ChainSplit-n-ChainSplit-n-Chain <div>
arXiv:2503.07570v1 Announce Type: new 
Abstract: Deep learning, when integrated with a large amount of training data, has the potential to outperform machine learning in terms of high accuracy. Recently, privacy-preserving deep learning has drawn significant attention of the research community. Different privacy notions in deep learning include privacy of data provided by data-owners and privacy of parameters and/or hyperparameters of the underlying neural network. Federated learning is a popular privacy-preserving execution environment where data-owners participate in learning the parameters collectively without leaking their respective data to other participants. However, federated learning suffers from certain security/privacy issues. In this paper, we propose Split-n-Chain, a variant of split learning where the layers of the network are split among several distributed nodes. Split-n-Chain achieves several privacy properties: data-owners need not share their training data with other nodes, and no nodes have access to the parameters and hyperparameters of the neural network (except that of the respective layers they hold). Moreover, Split-n-Chain uses blockchain to audit the computation done by different nodes. Our experimental results show that: Split-n-Chain is efficient, in terms of time required to execute different phases, and the training loss trend is similar to that for the same neural network when implemented in a monolithic fashion.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Distributed Learning over Decentralized Networks with Convoluted Support Vector Machine</title>
<link>https://arxiv.org/abs/2503.07563</link>
<guid>https://arxiv.org/abs/2503.07563</guid>
<content:encoded><![CDATA[
<div> (ADMM)

<br /><br />:
 hinge (ADMM)ADMMADMM <div>
arXiv:2503.07563v1 Announce Type: cross 
Abstract: This paper addresses the problem of efficiently classifying high-dimensional data over decentralized networks. Penalized support vector machines (SVMs) are widely used for high-dimensional classification tasks. However, the double nonsmoothness of the objective function poses significant challenges in developing efficient decentralized learning methods. Many existing procedures suffer from slow, sublinear convergence rates. To overcome this limitation, we consider a convolution-based smoothing technique for the nonsmooth hinge loss function. The resulting loss function remains convex and smooth. We then develop an efficient generalized alternating direction method of multipliers (ADMM) algorithm for solving penalized SVM over decentralized networks. Our theoretical contributions are twofold. First, we establish that our generalized ADMM algorithm achieves provable linear convergence with a simple implementation. Second, after a sufficient number of ADMM iterations, the final sparse estimator attains near-optimal statistical convergence and accurately recovers the true support of the underlying parameters. Extensive numerical experiments on both simulated and real-world datasets validate our theoretical findings.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Machine Learning for Wireless Metaverse: Fundamentals, Use Case, and Future Directions</title>
<link>https://arxiv.org/abs/2211.03703</link>
<guid>https://arxiv.org/abs/2211.03703</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
MLML <div>
arXiv:2211.03703v2 Announce Type: replace 
Abstract: Today's wireless systems are posing key challenges in terms of quality of service and quality of physical experience. Metaverse has the potential to reshape, transform, and add innovations to the existing wireless systems. A metaverse is a collective virtual open space that can enable wireless systems using digital twins, digital avatars, and interactive experience technologies. Machine learning (ML) is indispensable for modeling twins, avatars, and deploying interactive experience technologies. In this paper, we present the role of ML in enabling metaverse-based wireless systems. We discuss key fundamental concepts for advancing ML in the metaverse-based wireless systems. Moreover, we present a case study of deep reinforcement learning for metaverse sensing. Finally, we discuss the future directions along with potential solutions.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advances in APPFL: A Comprehensive and Extensible Federated Learning Framework</title>
<link>https://arxiv.org/abs/2409.11585</link>
<guid>https://arxiv.org/abs/2409.11585</guid>
<content:encoded><![CDATA[
<div> (Federated Learning)(heterogeneity)(security)APPFL(open-source)

<br /><br />:
APPFLAPPFLAPPFLAPPFLGitHub <div>
arXiv:2409.11585v2 Announce Type: replace 
Abstract: Federated learning (FL) is a distributed machine learning paradigm enabling collaborative model training while preserving data privacy. In today's landscape, where most data is proprietary, confidential, and distributed, FL has become a promising approach to leverage such data effectively, particularly in sensitive domains such as medicine and the electric grid. Heterogeneity and security are the key challenges in FL, however, most existing FL frameworks either fail to address these challenges adequately or lack the flexibility to incorporate new solutions. To this end, we present the recent advances in developing APPFL, an extensible framework and benchmarking suite for federated learning, which offers comprehensive solutions for heterogeneity and security concerns, as well as user-friendly interfaces for integrating new algorithms or adapting to new applications. We demonstrate the capabilities of APPFL through extensive experiments evaluating various aspects of FL, including communication efficiency, privacy preservation, computational performance, and resource utilization. We further highlight the extensibility of APPFL through case studies in vertical, hierarchical, and decentralized FL. APPFL is fully open-sourced on GitHub at https://github.com/APPFL/APPFL.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security</title>
<link>https://arxiv.org/abs/2410.02191</link>
<guid>https://arxiv.org/abs/2410.02191</guid>
<content:encoded><![CDATA[
<div> : Location-Based Social NetworksPoint-of-Interest (POI)

<br /><br />:
Location-Based Social NetworksPoint-of-Interest (POI)POI <div>
arXiv:2410.02191v2 Announce Type: replace 
Abstract: The widespread adoption of smartphones and Location-Based Social Networks has led to a massive influx of spatio-temporal data, creating unparalleled opportunities for enhancing Point-of-Interest (POI) recommendation systems. These advanced POI systems are crucial for enriching user experiences, enabling personalized interactions, and optimizing decision-making processes in the digital landscape. However, existing surveys tend to focus on traditional approaches and few of them delve into cutting-edge developments, emerging architectures, as well as security considerations in POI recommendations. To address this gap, our survey stands out by offering a comprehensive, up-to-date review of POI recommendation systems, covering advancements in models, architectures, and security aspects. We systematically examine the transition from traditional models to advanced techniques such as large language models. Additionally, we explore the architectural evolution from centralized to decentralized and federated learning systems, highlighting the improvements in scalability and privacy. Furthermore, we address the increasing importance of security, examining potential vulnerabilities and privacy-preserving approaches. Our taxonomy provides a structured overview of the current state of POI recommendation, while we also identify promising directions for future research in this rapidly advancing field.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient and Universally Accessible Cross-Chain Options without Upfront Holder Collateral</title>
<link>https://arxiv.org/abs/2410.15724</link>
<guid>https://arxiv.org/abs/2410.15724</guid>
<content:encoded><![CDATA[
<div> : 

:
<br />
1. <br />
2. <br />
3. DAPS<br />
4.  <div>
arXiv:2410.15724v2 Announce Type: replace 
Abstract: Options are fundamental to blockchain-based financial services, offering essential tools for risk management and price speculation, which enhance liquidity, flexibility, and market efficiency in decentralized finance (DeFi). Despite the growing interest in options for blockchain-resident assets, such as cryptocurrencies, current option mechanisms face significant challenges, including a high reliance on trusted third parties, limited asset support, high trading delays, and the requirement for option holders to provide upfront collateral.
  In this paper, we present a protocol that addresses the aforementioned issues. Our protocol is the first to eliminate the need for holders to post collateral when establishing options in trustless service environments (i.e. without a cross-chain bridge), which is achieved by introducing a guarantee from the option writer. Its universality allows for cross-chain options involving nearly \textit{any} assets on \textit{any} two different blockchains, provided the chains' programming languages can enforce and execute the necessary contract logic. Another key innovation is reducing option position transfer latency, which uses Double-Authentication-Preventing Signatures (DAPS). Our evaluation demonstrates that the proposed scheme reduces option transfer latency to less than half of that in existing methods. Rigorous security analysis proves that our protocol achieves secure option trading, even when facing adversarial behaviors.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal Pushing</title>
<link>https://arxiv.org/abs/2411.07104</link>
<guid>https://arxiv.org/abs/2411.07104</guid>
<content:encoded><![CDATA[
<div> quadrupedal robots, multi-agent reinforcement learning, obstacle-aware, long-horizon pushing, real-world application

:
RRT36.0%24.5%Go1Push-CuboidPush-T <div>
arXiv:2411.07104v3 Announce Type: replace 
Abstract: Recently, quadrupedal locomotion has achieved significant success, but their manipulation capabilities, particularly in handling large objects, remain limited, restricting their usefulness in demanding real-world applications such as search and rescue, construction, industrial automation, and room organization. This paper tackles the task of obstacle-aware, long-horizon pushing by multiple quadrupedal robots. We propose a hierarchical multi-agent reinforcement learning framework with three levels of control. The high-level controller integrates an RRT planner and a centralized adaptive policy to generate subgoals, while the mid-level controller uses a decentralized goal-conditioned policy to guide the robots toward these sub-goals. A pre-trained low-level locomotion policy executes the movement commands. We evaluate our method against several baselines in simulation, demonstrating significant improvements over baseline approaches, with 36.0% higher success rates and 24.5% reduction in completion time than the best baseline. Our framework successfully enables long-horizon, obstacle-aware manipulation tasks like Push-Cuboid and Push-T on Go1 robots in the real world.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks</title>
<link>https://arxiv.org/abs/2404.03227</link>
<guid>https://arxiv.org/abs/2404.03227</guid>
<content:encoded><![CDATA[
<div> -hop

:
-hop/(i) (ii) (iii) (iv)  <div>
arXiv:2404.03227v2 Announce Type: replace-cross 
Abstract: We address the challenge of sampling and remote estimation for autoregressive Markovian processes in a multi-hop wireless network with statistically-identical agents. Agents cache the most recent samples from others and communicate over wireless collision channels governed by an underlying graph topology. Our goal is to minimize time-average estimation error and/or age of information with decentralized scalable sampling and transmission policies, considering both oblivious (where decision-making is independent of the physical processes) and non-oblivious policies (where decision-making depends on physical processes). We prove that in oblivious policies, minimizing estimation error is equivalent to minimizing the age of information. The complexity of the problem, especially the multi-dimensional action spaces and arbitrary network topologies, makes theoretical methods for finding optimal transmission policies intractable. We optimize the policies using a graphical multi-agent reinforcement learning framework, where each agent employs a permutation-equivariant graph neural network architecture. Theoretically, we prove that our proposed framework exhibits desirable transferability properties, allowing transmission policies trained on small- or moderate-size networks to be executed effectively on large-scale topologies. Numerical experiments demonstrate that (i) Our proposed framework outperforms state-of-the-art baselines; (ii) The trained policies are transferable to larger networks, and their performance gains increase with the number of agents; (iii) The training procedure withstands non-stationarity even if we utilize independent learning techniques; and, (iv) Recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity in independent learning.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully First-Order Methods for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2410.19319</link>
<guid>https://arxiv.org/abs/2410.19319</guid>
<content:encoded><![CDATA[
<div> decentralized stochastic bilevel optimization (DSBO)Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT)first-order oraclessample complexitylinear speedup

:
DSBODecentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT) oracle  oracle$n$DSBO$\epsilon$-$\mathcal{O}(n^{-1}\epsilon^{-7})$ <div>
arXiv:2410.19319v2 Announce Type: replace-cross 
Abstract: This paper focuses on decentralized stochastic bilevel optimization (DSBO) where agents only communicate with their neighbors. We propose Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a novel algorithm that only requires first-order oracles that are much cheaper than second-order oracles widely adopted in existing works. We further provide a finite-time convergence analysis showing that for $n$ agents collaboratively solving the DSBO problem, the sample complexity of finding an $\epsilon$-stationary point in our algorithm is $\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known results of the single-agent counterpart with linear speedup. The numerical experiments demonstrate both the communication and training efficiency of our algorithm.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Urban Metaverse: Die Smart City im Industrial Metaverse</title>
<link>https://arxiv.org/abs/2503.04729</link>
<guid>https://arxiv.org/abs/2503.04729</guid>
<content:encoded><![CDATA[
<div> Urban Metaverse

<br /><br />:
Urban MetaverseUrban MetaverseIT <div>
arXiv:2503.04729v1 Announce Type: new 
Abstract: The Urban Metaverse describes an immersive 3D environment that connects the physical world of the city and its citizens with its digital data and systems. Physical and digital realities merge, opening up new possibilities for the design and use of the city. This trend study serves as a source of inspiration and guidance for city and community leaders, urban planners, IT professionals, and anyone interested in the future of urban spaces. It helps to understand the opportunities and challenges of the Urban Metaverse as an evolution of the Smart City and to set the course for sustainable and innovative urban development. To this end, the study analyzes the opportunities that the Urban Metaverse offers for urban administration and the everyday life of citizens, presents key technologies, and highlights the socio-economic challenges of implementation. The focus is on the potential of the Urban Metaverse to optimize the planning and operation of urban infrastructures, to promote inclusion and civic participation, and to enhance the innovative capacity of cities and municipalities. The study develops four recommendations for the implementation of metaverse applications in an urban context: 1. user-centered design, 2. ubiquitous accessibility, 3. proactive design of the regulatory framework, and 4. development of viable business models. Note: This document is published in English. An English version is in preparation.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Slow is Fast! Dissecting Ethereum's Slow Liquidity Drain</title>
<link>https://arxiv.org/abs/2503.04850</link>
<guid>https://arxiv.org/abs/2503.04850</guid>
<content:encoded><![CDATA[
<div> : Decentralized Finance (DeFi), Slow Liquidity Drain (SLID) scam, empirical analysis, machine learning, early detection

<br /><br />:
2018DEXs319,1663,117SLID1SLID4.7795%DeFiDeFi <div>
arXiv:2503.04850v1 Announce Type: new 
Abstract: We identify the slow liquidity drain (SLID) scam, an insidious and highly profitable threat to decentralized finance (DeFi), posing a large-scale, persistent, and growing risk to the ecosystem. Unlike traditional scams such as rug pulls or honeypots (USENIX Sec'19, USENIX Sec'23), SLID gradually siphons funds from liquidity pools over extended periods, making detection significantly more challenging. In this paper, we conducted the first large-scale empirical analysis of 319,166 liquidity pools across six major decentralized exchanges (DEXs) since 2018. We identified 3,117 SLID affected liquidity pools, resulting in cumulative losses of more than US$103 million. We propose a rule-based heuristic and an enhanced machine learning model for early detection. Our machine learning model achieves a detection speed 4.77 times faster than the heuristic while maintaining 95% accuracy. Our study establishes a foundation for protecting DeFi investors at an early stage and promoting transparency in the DeFi ecosystem.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SAFE-TAXI: A Hierarchical Multi-UAS Safe Auto-Taxiing Framework with Runtime Safety Assurance and Conflict Resolution</title>
<link>https://arxiv.org/abs/2503.04942</link>
<guid>https://arxiv.org/abs/2503.04942</guid>
<content:encoded><![CDATA[
<div> MPC-CBF

:<br />
SAFE-TAXISAFE-TAXIMPC-CBFMPC-CBFNight Vapor <div>
arXiv:2503.04942v1 Announce Type: new 
Abstract: We present a hierarchical safe auto-taxiing framework to enhance the automated ground operations of multiple unmanned aircraft systems (multi-UAS). The auto-taxiing problem becomes particularly challenging due to (i) unknown disturbances, such as crosswind affecting the aircraft dynamics, (ii) taxiway incursions due to unplanned obstacles, and (iii) spatiotemporal conflicts at the intersections between multiple entry points in the taxiway. To address these issues, we propose a hierarchical framework, i.e., SAFE-TAXI, combining centralized spatiotemporal planning with decentralized MPC-CBF-based control to safely navigate the aircraft through the taxiway while avoiding intersection conflicts and unplanned obstacles (e.g., other aircraft or ground vehicles). Our proposed framework decouples the auto-taxiing problem temporally into conflict resolution and motion planning, respectively. Conflict resolution is handled in a centralized manner by computing conflict-aware reference trajectories for each aircraft. In contrast, safety assurance from unplanned obstacles is handled by an MPC-CBF-based controller implemented in a decentralized manner. We demonstrate the effectiveness of our proposed framework through numerical simulations and experimentally validate it using Night Vapor, a small-scale fixed-wing test platform.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation</title>
<link>https://arxiv.org/abs/2503.04946</link>
<guid>https://arxiv.org/abs/2503.04946</guid>
<content:encoded><![CDATA[
<div> FED-IPTW

:
ITEITEFED-IPTWIPTWeICUFED-IPTWITE <div>
arXiv:2503.04946v1 Announce Type: new 
Abstract: Individual treatment effect (ITE) estimation is to evaluate the causal effects of treatment strategies on some important outcomes, which is a crucial problem in healthcare. Most existing ITE estimation methods are designed for centralized settings. However, in real-world clinical scenarios, the raw data are usually not shareable among hospitals due to the potential privacy and security risks, which makes the methods not applicable. In this work, we study the ITE estimation task in a federated setting, which allows us to harness the decentralized data from multiple hospitals. Due to the unavoidable confounding bias in the collected data, a model directly learned from it would be inaccurate. One well-known solution is Inverse Probability Treatment Weighting (IPTW), which uses the conditional probability of treatment given the covariates to re-weight each training example. Applying IPTW in a federated setting, however, is non-trivial. We found that even with a well-estimated conditional probability, the local model training step using each hospital's data alone would still suffer from confounding bias. To address this, we propose FED-IPTW, a novel algorithm to extend IPTW into a federated setting that enforces both global (over all the data) and local (within each hospital) decorrelation between covariates and treatments. We validated our approach on the task of comparing the treatment effects of mechanical ventilation on improving survival probability for patients with breadth difficulties in the intensive care unit (ICU). We conducted experiments on both synthetic and real-world eICU datasets and the results show that FED-IPTW outperform state-of-the-art methods on all the metrics on factual prediction and ITE estimation tasks, paving the way for personalized treatment strategy design in mechanical ventilation usage.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>bittide: Control Time, Not Flows</title>
<link>https://arxiv.org/abs/2503.05033</link>
<guid>https://arxiv.org/abs/2503.05033</guid>
<content:encoded><![CDATA[
<div> bittideFPGA

:
<br />
bittideFPGA8bittidebittidebittide <div>
arXiv:2503.05033v1 Announce Type: new 
Abstract: This paper presents the first hardware implementation of bittide, a decentralized clock synchronization mechanism for achieving logical synchrony in distributed systems. We detail the design and implementation of an 8-node bittide network using off-the-shelf FPGA boards and adjustable clock sources. Through experiments with various network topologies, including fully connected, hourglass, and cube, we demonstrate the effectiveness of bittide in aligning node frequencies and bounding buffer excursions. We collect and analyze frequency, buffer occupancy, and logical latency data, validating the hardware's performance against theoretical predictions and simulations. Our results show that bittide achieves tight frequency alignment, robustly handles varying physical latencies, and establishes a consistent notion of logical time across the network, enabling predictable distributed computation at scale with zero in-band overhead.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Using "Failure Costs" to Guarantee Execution Quality in Competitive and Permissionless Order Flow Auctions</title>
<link>https://arxiv.org/abs/2503.05338</link>
<guid>https://arxiv.org/abs/2503.05338</guid>
<content:encoded><![CDATA[
<div> escrow

:<br />
OFAMEVBRAIDAtlasescrow <div>
arXiv:2503.05338v1 Announce Type: new 
Abstract: In the context of decentralized blockchains, accurately simulating the outcome of order flow auctions (OFAs) off-chain is challenging due to adversarial sequencing, encrypted bids, and frequent state changes. Existing approaches, such as deterministic sorting via consensus layer modifications (e.g., MEV taxes) (Robinson and White 2024) and BRAID (Resnick 2024) or atomic execution of aggregated bids (e.g., Atlas) (Watts et al. 2024), remain vulnerable in permissionless settings where limited throughput allows rational adversaries to submit "spoof" bids that block their competitors' access to execution. We propose a new failure cost penalty that applies only when a solution is executed but does not pay its bid or fulfill the order. Combined with an on-chain escrow system, this mechanism empowers applications to asynchronously issue their users a guaranteed minimum outcome before the execution results are finalized. It implies a direct link between blockchain throughput, censorship resistance, and the capital efficiency of auction participants (e.g., solvers), which intuitively extends to execution quality. At equilibrium, bids fully reflect the potential for price improvement between bid submission and execution, but only partially reflect the potential for price declines. This asymmetry unbounded upside for winning bids, limited downside for failed bids, and no loss for losing bids - ultimately benefits users.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantitative Decentralized Stability Certificates for Grid-Forming Converter Control</title>
<link>https://arxiv.org/abs/2503.05403</link>
<guid>https://arxiv.org/abs/2503.05403</guid>
<content:encoded><![CDATA[
<div> : 

:<br />
 <div>
arXiv:2503.05403v1 Announce Type: new 
Abstract: We propose a decentralized framework for guaranteeing the small-signal stability of future power systems with grid-forming converters. Our approach leverages dynamic loop-shifting techniques to compensate for the lack of passivity in the network dynamics and establishes decentralized parametric stability certificates, depending on the local device-level controls and incorporating the effects of the network dynamics. By following practical tuning rules, we are able to ensure plug-and-play operation without centralized coordination. Unlike prior works, our approach accommodates coupled frequency and voltage dynamics, incorporates network dynamics, and does not rely on specific network configurations or operating points, offering a general and scalable solution for the integration of power-electronics-based devices into future power systems. We validate our theoretical stability results through numerical case studies in a high-fidelity simulation model.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Decentralized Sequencer and Data Availability Committee for Rollups Using Set Consensus</title>
<link>https://arxiv.org/abs/2503.05451</link>
<guid>https://arxiv.org/abs/2503.05451</guid>
<content:encoded><![CDATA[
<div> Layer 2L2rollupsDAC sequencer

:

Layer 2 (L2) rollupsL2L1L2sequencersequencerarrangerL1sequencerarrangerSet Byzantine Consensus (SBC)arrangersequencer <div>
arXiv:2503.05451v1 Announce Type: new 
Abstract: Blockchains face a scalability challenge due to the intrinsic throughput limitations of consensus protocols and the limitation in block sizes due to decentralization. An alternative to improve the number of transactions per second is to use Layer 2 (L2) rollups. L2s perform most computations offchain using blockchains (L1) minimally under-the-hood to guarantee correctness. A sequencer receives offchain L2 transaction requests, batches them, and commits compressed or hashed batches to L1. Hashing offers much better compression but requires a data availability committee (DAC) to translate hashes back into their corresponding batches. Current L2s consist of a centralized sequencer which receives and serializes all transactions and an optional DAC. Centralized sequencers can undesirably influence L2s evolution. We propose in this paper a fully decentralized implementation of a service that combines (1) a sequencer that posts hashes to the L1 blockchain and (2) the data availability committee that reverses the hashes. We call the resulting service a (decentralized) arranger. Our decentralized arranger is based on Set Byzantine Consensus (SBC), a service where participants can propose sets of values and consensus is reached on a subset of the union of the values proposed. We extend SBC for our fully decentralized arranger. Our main contributions are (1) a formal definition of arrangers; (2) two implementations, one with a centralized sequencer and another with a fully decentralized algorithm, with their proof of correctness; and (3) empirical evidence that our solution scales by implementing all building blocks necessary to implement a correct server.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Practical Federated Learning without a Server</title>
<link>https://arxiv.org/abs/2503.05509</link>
<guid>https://arxiv.org/abs/2503.05509</guid>
<content:encoded><![CDATA[
<div> Federated Learning, Plexus, Decentralized FL, Time-to-accuracy, Communication Volume

:
<br />
PlexusPlexusPlexus10001.4-1.615.8-29230.5-77.9 <div>
arXiv:2503.05509v1 Announce Type: new 
Abstract: Federated Learning (FL) enables end-user devices to collaboratively train ML models without sharing raw data, thereby preserving data privacy. In FL, a central parameter server coordinates the learning process by iteratively aggregating the trained models received from clients. Yet, deploying a central server is not always feasible due to hardware unavailability, infrastructure constraints, or operational costs. We present Plexus, a fully decentralized FL system for large networks that operates without the drawbacks originating from having a central server. Plexus distributes the responsibilities of model aggregation and sampling among participating nodes while avoiding network-wide coordination. We evaluate Plexus using realistic traces for compute speed, pairwise latency and network capacity. Our experiments on three common learning tasks and with up to 1000 nodes empirically show that Plexus reduces time-to-accuracy by 1.4-1.6x, communication volume by 15.8-292x and training resources needed for convergence by 30.5-77.9x compared to conventional decentralized learning algorithms.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Compliance of AI Systems</title>
<link>https://arxiv.org/abs/2503.05571</link>
<guid>https://arxiv.org/abs/2503.05571</guid>
<content:encoded><![CDATA[
<div> (AI)AI

<br /><br />:
AIAIAIAIAIAIAIAIAI <div>
arXiv:2503.05571v1 Announce Type: new 
Abstract: The increasing integration of artificial intelligence (AI) systems in various fields requires solid concepts to ensure compliance with upcoming legislation. This paper systematically examines the compliance of AI systems with relevant legislation, focusing on the EU's AI Act and the compliance of data sets. The analysis highlighted many challenges associated with edge devices, which are increasingly being used to deploy AI applications closer and closer to the data sources. Such devices often face unique issues due to their decentralized nature and limited computing resources for implementing sophisticated compliance mechanisms. By analyzing AI implementations, the paper identifies challenges and proposes the first best practices for legal compliance when developing, deploying, and running AI. The importance of data set compliance is highlighted as a cornerstone for ensuring the trustworthiness, transparency, and explainability of AI systems, which must be aligned with ethical standards set forth in regulatory frameworks such as the AI Act. The insights gained should contribute to the ongoing discourse on the responsible development and deployment of embedded AI systems.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Extended Version: Non-Preemptive Scheduling of Flexible Loads in Smart Grids via Convex Optimization</title>
<link>https://arxiv.org/abs/2503.04909</link>
<guid>https://arxiv.org/abs/2503.04909</guid>
<content:encoded><![CDATA[
<div> : 

:
MICP--MICP <div>
arXiv:2503.04909v1 Announce Type: cross 
Abstract: This paper studies the scheduling of a large population of non-preemptive flexible electric loads, each of which has a flexible starting time but once started will follow a fixed load shape until completion. We first formulate the scheduling problem as a mixed-integer convex program (MICP), then propose an efficient polynomial time relaxation-adjustment-rounding algorithm for solving the problem. The key novelty of the proposed method lies in its adjustment step, which uses a graph-based algorithm to navigate within the set of optimal points of the convex relaxation while reducing the number of fractional entries in the solution. We establish mathematically that our algorithm yields solutions that are near optimal for a finite number of loads and with its sub-optimality independent of the number of loads. Consequently, the proposed method is asymptotically optimal in a per-load cost sense when the number of loads increases. Despite the gap between the MICP and its convex relaxation, we establish that the solution of the proposed algorithm can be decentralized by marginal prices of the convex relaxation. We also develop and analyze variants of the proposed algorithm for settings with uncertainty and with time-varying realistic load shapes. Finally, we numerically evaluate the proposed algorithm in a case study for the non-preemptive scheduling of electric vehicles charging loads.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PACC: A Passive-Arm Approach for High-Payload Collaborative Carrying with Quadruped Robots Using Model Predictive Control</title>
<link>https://arxiv.org/abs/2403.19862</link>
<guid>https://arxiv.org/abs/2403.19862</guid>
<content:encoded><![CDATA[
<div> passive arm structuresintrinsic impedancequadruped robotscollaborative carryingModel Predictive Controller

<br />
:
---- <div>
arXiv:2403.19862v3 Announce Type: replace 
Abstract: In this paper, we introduce the concept of using passive arm structures with intrinsic impedance for robot-robot and human-robot collaborative carrying with quadruped robots. The concept is meant for a leader-follower task and takes a minimalist approach that focuses on exploiting the robots' payload capabilities and reducing energy consumption, without compromising the robot locomotion capabilities. We introduce a preliminary arm mechanical design and describe how to use its joint displacements to guide the robot's motion. To control the robot's locomotion, we propose a decentralized Model Predictive Controller that incorporates an approximation of the arm dynamics and the estimation of the external forces from the collaborative carrying. We validate the overall system experimentally by performing both robot-robot and human-robot collaborative carrying on a stair-like obstacle and on rough terrain.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.18862</link>
<guid>https://arxiv.org/abs/2409.18862</guid>
<content:encoded><![CDATA[
<div>  Barrier 

:
 Barrier <br /><br /> <div>
arXiv:2409.18862v4 Announce Type: replace 
Abstract: We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Personalization for Federated Medical Image Segmentation via Gossip Contrastive Mutual Learning</title>
<link>https://arxiv.org/abs/2503.03883</link>
<guid>https://arxiv.org/abs/2503.03883</guid>
<content:encoded><![CDATA[
<div> Federated Learning, Gossip Contrastive Mutual Learning (GCML), , Deep Contrast Mutual Learning (DCML), 

<br /><br />:
Gossip Contrastive Mutual Learning (GCML)Federated LearningGCMLGossipDeep Contrast Mutual Learning (DCML)GCMLFL <div>
arXiv:2503.03883v1 Announce Type: new 
Abstract: Federated Learning (FL) presents a promising avenue for collaborative model training among medical centers, facilitating knowledge exchange without compromising data privacy. However, vanilla FL is prone to server failures and rarely achieves optimal performance on all participating sites due to heterogeneous data distributions among them. To overcome these challenges, we propose Gossip Contrastive Mutual Learning (GCML), a unified framework to optimize personalized models in a decentralized environment, where Gossip Protocol is employed for flexible and robust peer-to-peer communication. To make efficient and reliable knowledge exchange in each communication without the global knowledge across all the sites, we introduce deep contrast mutual learning (DCML), a simple yet effective scheme to encourage knowledge transfer between the incoming and local models through collaborative training on local data. By integrating DCML with other efforts to optimize site-specific models by leveraging useful information from peers, we evaluated the performance and efficiency of the proposed method on three publicly available datasets with different segmentation tasks. Our extensive experimental results show that the proposed GCML framework outperformed both centralized and decentralized FL methods with significantly reduced communication overhead, indicating its potential for real-world deployment.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Joint Beamforming and Antenna Position Optimization for Fluid Antenna-Assisted MU-MIMO Networks</title>
<link>https://arxiv.org/abs/2503.04040</link>
<guid>https://arxiv.org/abs/2503.04040</guid>
<content:encoded><![CDATA[
<div> (FAS)(MU-MIMO) sum rate (WSR)(BCA)(DBP)

<br /><br />:

(MU-MIMO)(BCA)(FA)BCAFA(DBP)MIMOFA-assisted MU-MIMO47%WSR70% <div>
arXiv:2503.04040v1 Announce Type: new 
Abstract: The fluid antenna system (FAS) has emerged as a disruptive technology for future wireless networks, offering unprecedented degrees of freedom (DoF) through the dynamic configuration of antennas in response to propagation environment variations. The integration of fluid antennas (FAs) with multiuser multiple-input multiple-output (MU-MIMO) networks promises substantial weighted sum rate (WSR) gains via joint beamforming and FA position optimization. However, the joint design is challenging due to the strong coupling between beamforming matrices and antenna positions. To address the challenge, we propose a novel block coordinate ascent (BCA)-based method in FA-assisted MU-MIMO networks. Specifically, we first employ matrix fractional programming techniques to reformulate the original complex problem into a more tractable form. Then, we solve the reformulated problem following the BCA principle, where we develop a low-complexity majorization maximization algorithm capable of optimizing all FA positions simultaneously. To further reduce the computational, storage, and interconnection costs, we propose a decentralized implementation for our proposed algorithm by utilizing the decentralized baseband processing (DBP) architecture. Simulation results demonstrate that with our proposed algorithm, the FA-assisted MU-MIMO system achieves up to a 47% WSR improvement over conventional MIMO networks equipped with fixed-position antennas. Moreover, the decentralized implementation reduces computation time by approximately 70% and has similar performance compared with the centralized implementation.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DVM-SLAM: Decentralized Visual Monocular Simultaneous Localization and Mapping for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.04126</link>
<guid>https://arxiv.org/abs/2503.04126</guid>
<content:encoded><![CDATA[
<div> Cooperative Simultaneous Localization and Mapping (C-SLAM)Decentralized Visual Monocular SLAM (DVM-SLAM)

:
(C-SLAM)Decentralized Visual Monocular SLAM (DVM-SLAM)(MAVs)DVM-SLAMC-SLAM <div>
arXiv:2503.04126v1 Announce Type: new 
Abstract: Cooperative Simultaneous Localization and Mapping (C-SLAM) enables multiple agents to work together in mapping unknown environments while simultaneously estimating their own positions. This approach enhances robustness, scalability, and accuracy by sharing information between agents, reducing drift, and enabling collective exploration of larger areas. In this paper, we present Decentralized Visual Monocular SLAM (DVM-SLAM), the first open-source decentralized monocular C-SLAM system. By only utilizing low-cost and light-weight monocular vision sensors, our system is well suited for small robots and micro aerial vehicles (MAVs). DVM-SLAM's real-world applicability is validated on physical robots with a custom collision avoidance framework, showcasing its potential in real-time multi-agent autonomous navigation scenarios. We also demonstrate comparable accuracy to state-of-the-art centralized monocular C-SLAM systems. We open-source our code and provide supplementary material online.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LiteChain: A Lightweight Blockchain for Verifiable and Scalable Federated Learning in Massive Edge Networks</title>
<link>https://arxiv.org/abs/2503.04140</link>
<guid>https://arxiv.org/abs/2503.04140</guid>
<content:encoded><![CDATA[
<div> LiteChain

:<br />
MENsFLLiteChainLiteChainMENsLiteChainCBFTLiteChainHyperledger FabricLiteChain <div>
arXiv:2503.04140v1 Announce Type: new 
Abstract: Leveraging blockchain in Federated Learning (FL) emerges as a new paradigm for secure collaborative learning on Massive Edge Networks (MENs). As the scale of MENs increases, it becomes more difficult to implement and manage a blockchain among edge devices due to complex communication topologies, heterogeneous computation capabilities, and limited storage capacities. Moreover, the lack of a standard metric for blockchain security becomes a significant issue. To address these challenges, we propose a lightweight blockchain for verifiable and scalable FL, namely LiteChain, to provide efficient and secure services in MENs. Specifically, we develop a distributed clustering algorithm to reorganize MENs into a two-level structure to improve communication and computing efficiency under security requirements. Moreover, we introduce a Comprehensive Byzantine Fault Tolerance (CBFT) consensus mechanism and a secure update mechanism to ensure the security of model transactions through LiteChain. Our experiments based on Hyperledger Fabric demonstrate that LiteChain presents the lowest end-to-end latency and on-chain storage overheads across various network scales, outperforming the other two benchmarks. In addition, LiteChain exhibits a high level of robustness against replay and data poisoning attacks.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>One-Shot Clustering for Federated Learning</title>
<link>https://arxiv.org/abs/2503.04231</link>
<guid>https://arxiv.org/abs/2503.04231</guid>
<content:encoded><![CDATA[
<div> Federated LearningClustered Federated LearningOne-Shot Clustered Federated Learning (OCFL)cosine

:
One-Shot Clustered Federated Learning (OCFL)OCFL <div>
arXiv:2503.04231v1 Announce Type: new 
Abstract: Federated Learning (FL) is a widespread and well adopted paradigm of decentralized learning that allows training one model from multiple sources without the need to directly transfer data between participating clients. Since its inception in 2015, it has been divided into numerous sub-fields that deal with application-specific issues, be it data heterogeneity or resource allocation. One such sub-field, Clustered Federated Learning (CFL), is dealing with the problem of clustering the population of clients into separate cohorts to deliver personalized models. Although few remarkable works have been published in this domain, the problem is still largely unexplored, as its basic assumption and settings are slightly different from standard FL. In this work, we present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic algorithm that can automatically detect the earliest suitable moment for clustering. Our algorithm is based on the computation of cosine similarity between gradients of the clients and a temperature measure that detects when the federated model starts to converge. We empirically evaluate our methodology by testing various one-shot clustering algorithms for over thirty different tasks on three benchmark datasets. Our experiments showcase the good performance of our approach when used to perform CFL in an automated manner without the need to adjust hyperparameters.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lite-PoT: Practical Powers-of-Tau Setup Ceremony</title>
<link>https://arxiv.org/abs/2503.04549</link>
<guid>https://arxiv.org/abs/2503.04549</guid>
<content:encoded><![CDATA[
<div> zk-SNARKPoT<br /><br />:
Lite-PoTzk-SNARKPowers of TauPoTPoT$m$$d$PoT$O(md)$Lite-PoT$O(1)$PoT$2^{15}$16$m$$O(d)$$m$ <div>
arXiv:2503.04549v1 Announce Type: new 
Abstract: Zero-Knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARK) schemes have gained significant adoption in privacy-preserving applications, decentralized systems (e.g., blockchain), and verifiable computation due to their efficiency. However, the most efficient zk-SNARKs often rely on a one-time trusted setup to generate a public parameter, often known as the ``Powers of Tau" (PoT) string. The leakage of the secret parameter, $\tau$, in the string would allow attackers to generate false proofs, compromising the soundness of all zk-SNARK systems built on it.
  Prior proposals for decentralized setup ceremonies have utilized blockchain-based smart contracts to allow any party to contribute randomness to $\tau$ while also preventing censorship of contributions. For a PoT string of $d$-degree generated by the randomness of $m$ contributors, these solutions required a total of $O(md)$ on-chain operations (i.e., in terms of both storage and cryptographic operations). These operations primarily consisted of costly group operations, particularly scalar multiplication on pairing curves, which discouraged participation and limited the impact of decentralization
  In this work, we present Lite-PoT, which includes two key protocols designed to reduce participation costs: \emph{(i)} a fraud-proof protocol to reduce the number of expensive on-chain cryptographic group operations to $O(1)$ per contributor. Our experimental results show that (with one transaction per update) our protocol enables decentralized ceremonies for PoT strings up to a $2^{15}$ degree, an $\approx 16x$ improvement over existing on-chain solutions; \emph{(ii)} a proof aggregation technique that batches $m$ randomness contributions into one on-chain update with only $O(d)$ on-chain operations, independent of $m$. This significantly reduces the monetary cost of on-chain updates by $m$-fold via amortization.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Boosting Blockchain Throughput: Parallel EVM Execution with Asynchronous Storage for Reddio</title>
<link>https://arxiv.org/abs/2503.04595</link>
<guid>https://arxiv.org/abs/2503.04595</guid>
<content:encoded><![CDATA[
<div> Reddio

:
ReddioReddio(1) MPT(2) trieI/O(3)  <div>
arXiv:2503.04595v1 Announce Type: new 
Abstract: The increasing adoption of blockchain technology has led to a growing demand for higher transaction throughput. Traditional blockchain platforms, such as Ethereum, execute transactions sequentially within each block, limiting scalability. Parallel execution has been proposed to enhance performance, but existing approaches either impose strict dependency annotations, rely on conservative static analysis, or suffer from high contention due to inefficient state management. Moreover, even when transaction execution is parallelized at the upper layer, storage operations remain a bottleneck due to sequential state access and I/O amplification. In this paper, we propose Reddio, a batch-based parallel transaction execution framework with asynchronous storage. Reddio processes transactions in parallel while addressing the storage bottleneck through three key techniques: (i) direct state reading, which enables efficient state access without traversing the Merkle Patricia Trie (MPT); (ii) asynchronous parallel node loading, which preloads trie nodes concurrently with execution to reduce I/O overhead; and (iii) pipelined workflow, which decouples execution, state reading, and storage updates into overlapping phases to maximize hardware utilization.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality</title>
<link>https://arxiv.org/abs/2401.13898</link>
<guid>https://arxiv.org/abs/2401.13898</guid>
<content:encoded><![CDATA[
<div> 

<br /><br />:
MFCPLMFCPLMFCPL <div>
arXiv:2401.13898v2 Announce Type: replace 
Abstract: Multimodal federated learning (MFL) has emerged as a decentralized machine learning paradigm, allowing multiple clients with different modalities to collaborate on training a global model across diverse data sources without sharing their private data. However, challenges, such as data heterogeneity and severely missing modalities, pose crucial hindrances to the robustness of MFL, significantly impacting the performance of global model. The occurrence of missing modalities in real-world applications, such as autonomous driving, often arises from factors like sensor failures, leading knowledge gaps during the training process. Specifically, the absence of a modality introduces misalignment during the local training phase, stemming from zero-filling in the case of clients with missing modalities. Consequently, achieving robust generalization in global model becomes imperative, especially when dealing with clients that have incomplete data. In this paper, we propose $\textbf{Multimodal Federated Cross Prototype Learning (MFCPL)}$, a novel approach for MFL under severely missing modalities. Our MFCPL leverages the complete prototypes to provide diverse modality knowledge in modality-shared level with the cross-modal regularization and modality-specific level with cross-modal contrastive mechanism. Additionally, our approach introduces the cross-modal alignment to provide regularization for modality-specific features, thereby enhancing the overall performance, particularly in scenarios involving severely missing modalities. Through extensive experiments on three multimodal datasets, we demonstrate the effectiveness of MFCPL in mitigating the challenges of data heterogeneity and severely missing modalities while improving the overall performance and robustness of MFL.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Edge General Intelligence via Large Language Models: Opportunities and Challenges</title>
<link>https://arxiv.org/abs/2410.18125</link>
<guid>https://arxiv.org/abs/2410.18125</guid>
<content:encoded><![CDATA[
<div> :  (EI),  (LLMs),  (EGI), , , ,  (SLMs)

<br /><br />:
(EI)(LLMs)(EGI)EGI(SLMs)EGI <div>
arXiv:2410.18125v3 Announce Type: replace 
Abstract: Edge Intelligence (EI) has been instrumental in delivering real-time, localized services by leveraging the computational capabilities of edge networks. The integration of Large Language Models (LLMs) empowers EI to evolve into the next stage: Edge General Intelligence (EGI), enabling more adaptive and versatile applications that require advanced understanding and reasoning capabilities. However, systematic exploration in this area remains insufficient. This survey delineates the distinctions between EGI and traditional EI, categorizing LLM-empowered EGI into three conceptual systems: centralized, hybrid, and decentralized. For each system, we detail the framework designs and review existing implementations. Furthermore, we evaluate the performance and throughput of various Small Language Models (SLMs) that are more suitable for development on edge devices. This survey provides researchers with a comprehensive vision of EGI, offering insights into its vast potential and establishing a foundation for future advancements in this rapidly evolving field.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data Poisoning Attacks to Locally Differentially Private Range Query Protocols</title>
<link>https://arxiv.org/abs/2503.03454</link>
<guid>https://arxiv.org/abs/2503.03454</guid>
<content:encoded><![CDATA[
<div> : Local Differential Privacy (LDP), , , , , , 

:<br />
LDPLDPNorm-Sub5-10 <div>
arXiv:2503.03454v2 Announce Type: replace 
Abstract: Local Differential Privacy (LDP) has been widely adopted to protect user privacy in decentralized data collection. However, recent studies have revealed that LDP protocols are vulnerable to data poisoning attacks, where malicious users manipulate their reported data to distort aggregated results. In this work, we present the first study on data poisoning attacks targeting LDP range query protocols, focusing on both tree-based and grid-based approaches. We identify three key challenges in executing such attacks, including crafting consistent and effective fake data, maintaining data consistency across levels or grids, and preventing server detection. To address the first two challenges, we propose novel attack methods that are provably optimal, including a tree-based attack and a grid-based attack, designed to manipulate range query results with high effectiveness. \textbf{Our key finding is that the common post-processing procedure, Norm-Sub, in LDP range query protocols can help the attacker massively amplify their attack effectiveness.} In addition, we study a potential countermeasure, but also propose an adaptive attack capable of evading this defense to address the third challenge. We evaluate our methods through theoretical analysis and extensive experiments on synthetic and real-world datasets. Our results show that the proposed attacks can significantly amplify estimations for arbitrary range queries by manipulating a small fraction of users, providing 5-10x more influence than a normal user to the estimation.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamics and Inequalities in Digital Social Networks: A Computational and Sociological Review</title>
<link>https://arxiv.org/abs/2503.02887</link>
<guid>https://arxiv.org/abs/2503.02887</guid>
<content:encoded><![CDATA[
<div> -

:<br />
- <div>
arXiv:2503.02887v1 Announce Type: new 
Abstract: Digital networks have profoundly transformed the ways in which individuals interact, exchange information, and establish connections, leading to the emergence of phenomena such as virality, misinformation cascades, and online polarization. This review conducts a thorough examination of the micro-macro linkages within digital social networks, analyzing how individual actions like liking, sharing, and commenting coalesce into broader systemic patterns and how these interactions are influenced by algorithmic mediation. Utilizing a multidisciplinary literature base, this study explores the interaction among user behaviors, network structures, and platform algorithms that intensify biases, strengthen homophily, and foster echo chambers. We delve into crucial dynamics including the scalability's impact on weak tie propagation, the amplification effects on influencers, and the rise of digital inequalities, employing both theoretical and empirical approaches. By synthesizing insights from sociology, network theory, and computational social science, this paper underscores the necessity for novel frameworks that integrate algorithmic processes into established micro-macro models. The conclusion presents practical strategies aimed at promoting fairer digital networks through decentralized architectures, algorithmic fairness, and improved digital inclusion, tackling significant challenges such as polarization and misinformation within networked societies.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding Across Different Environments and Tasks</title>
<link>https://arxiv.org/abs/2503.02992</link>
<guid>https://arxiv.org/abs/2503.02992</guid>
<content:encoded><![CDATA[
<div> Multi-Agent Path Finding (MAPF)RAILGUN

:
(MAPF)RAILGUNRAILGUNMAPF plannerRAILGUN<br /><br /> <div>
arXiv:2503.02992v1 Announce Type: new 
Abstract: Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the community's continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Knowledge Augmentation in Federation: Rethinking What Collaborative Learning Can Bring Back to Decentralized Data</title>
<link>https://arxiv.org/abs/2503.03140</link>
<guid>https://arxiv.org/abs/2503.03140</guid>
<content:encoded><![CDATA[
<div> : 

:
KAFKAF <div>
arXiv:2503.03140v1 Announce Type: new 
Abstract: Data, as an observable form of knowledge, has become one of the most important factors of production for the development of Artificial Intelligence (AI). Meanwhile, increasing legislation and regulations on private and proprietary information results in scattered data sources also known as the ``data islands''. Although some collaborative learning paradigms such as Federated Learning (FL) can enable privacy-preserving training over decentralized data, they have inherent deficiencies in fairness, costs and reproducibility because of being learning-centric, which greatly limits the way how participants cooperate with each other. In light of this, we present a knowledge-centric paradigm termed \emph{Knowledge Augmentation in Federation} (KAF), with focus on how to enhance local knowledge through collaborative effort. We provide the suggested system architecture, formulate the prototypical optimization objective, and review emerging studies that employ methodologies suitable for KAF. On our roadmap, with a three-way categorization we describe the methods for knowledge expansion, knowledge filtering, and label and feature space correction in the federation. Further, we highlight several challenges and open questions that deserve more attention from the community. With our investigation, we intend to offer new insights for what collaborative learning can bring back to decentralized data.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Access Specification-Aware Software Transactional Memory Techniques for Efficient Execution of Smart Contract Transactions</title>
<link>https://arxiv.org/abs/2503.03203</link>
<guid>https://arxiv.org/abs/2503.03203</guid>
<content:encoded><![CDATA[
<div> (STM)

:<br />
SupraLayer 1AptosBlockSTMPEVMSTMSTMSTMEVMMoveVMSupraSTM (saSupraSTM)Aptos' BlockSTMPEVM <div>
arXiv:2503.03203v1 Announce Type: new 
Abstract: For a high-performance blockchain like Supra's Layer 1, minimizing latencies across key components is crucial-such as data dissemination, consensus (or ordering), and transaction execution. While through significant innovations we have improved the first two, transaction execution remains an area for further optimization. Software Transactional Memory (STM) is a widely used technique for parallel execution, with Aptos' BlockSTM pioneering its application of efficient blockchain transaction processing on multi-core validator nodes. Subsequently, PEVM [13] adapted BlockSTM for EVM transaction execution. However, we identified a gap in existing STM techniques-while access specifications have been used in industry (e.g., Solana's user-provided read-write sets), they have not been leveraged to enhance STM efficiency. Our experimental analysis demonstrates that specification-aware STMs outperform their plain counterparts on both EVM and MoveVM. To maximize these benefits, we have designed specification-aware SupraSTM (saSupraSTM), a novel algorithm that fully utilizes access specifications. Through extensive testing, saSupraSTM outperforms both our specification-aware adaptation of Aptos' BlockSTM and specification-aware PEVM, setting a new benchmark for transaction execution efficiency in the context of blockchain networks.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum-Inspired Privacy-Preserving Federated Learning Framework for Secure Dementia Classification</title>
<link>https://arxiv.org/abs/2503.03267</link>
<guid>https://arxiv.org/abs/2503.03267</guid>
<content:encoded><![CDATA[
<div> MRI

<br /><br />:
QKDCNNQKDOASISMRI1%AIAI <div>
arXiv:2503.03267v1 Announce Type: new 
Abstract: Dementia, a neurological disorder impacting millions globally, presents significant challenges in diagnosis and patient care. With the rise of privacy concerns and security threats in healthcare, federated learning (FL) has emerged as a promising approach to enable collaborative model training across decentralized datasets without exposing sensitive patient information. However, FL remains vulnerable to advanced security breaches such as gradient inversion and eavesdropping attacks. This paper introduces a novel framework that integrates federated learning with quantum-inspired encryption techniques for dementia classification, emphasizing privacy preservation and security. Leveraging quantum key distribution (QKD), the framework ensures secure transmission of model weights, protecting against unauthorized access and interception during training. The methodology utilizes a convolutional neural network (CNN) for dementia classification, with federated training conducted across distributed healthcare nodes, incorporating QKD-encrypted weight sharing to secure the aggregation process. Experimental evaluations conducted on MRI data from the OASIS dataset demonstrate that the proposed framework achieves identical accuracy levels to a baseline model while enhancing data security and reducing loss by almost 1% compared to the classical baseline model. The framework offers significant implications for democratizing access to AI-driven dementia diagnostics in low- and middle-income countries, addressing critical resource and privacy constraints. This work contributes a robust, scalable, and secure federated learning solution for healthcare applications, paving the way for broader adoption of quantum-inspired techniques in AI-driven medical research.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks</title>
<link>https://arxiv.org/abs/2503.03391</link>
<guid>https://arxiv.org/abs/2503.03391</guid>
<content:encoded><![CDATA[
<div> Mobile edge computing (MEC)air-ground networks6Gunmanned aerial vehicles (UAVs)multi-agent Markov decision process (MDP)

:<br />
(MEC)(MAGIN)(UAV)(MDP)Beta(MAPPO-BD)MAPPO-BDMAGIN <div>
arXiv:2503.03391v1 Announce Type: new 
Abstract: Mobile edge computing (MEC)-enabled air-ground networks are a key component of 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles (UAVs) and high-altitude platform stations (HAPS) to provide dynamic services to ground IoT devices (IoTDs). These IoTDs support real-time applications (e.g., multimedia and Metaverse services) that demand high computational resources and strict quality of service (QoS) guarantees in terms of latency and task queue management. Given their limited energy and processing capabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed processing, forming a multi-tier MEC system. This paper tackles the overall energy minimization problem in MEC-enabled air-ground integrated networks (MAGIN) by jointly optimizing UAV trajectories, computing resource allocation, and queue-aware task offloading decisions. The optimization is challenging due to the nonconvex, nonlinear nature of this hierarchical system, which renders traditional methods ineffective. We reformulate the problem as a multi-agent Markov decision process (MDP) with continuous action spaces and heterogeneous agents, and propose a novel variant of multi-agent proximal policy optimization with a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show that MAPPO-BD outperforms baseline schemes, achieving superior energy savings and efficient resource management in MAGIN while meeting queue delay and edge computing constraints.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs</title>
<link>https://arxiv.org/abs/2503.03428</link>
<guid>https://arxiv.org/abs/2503.03428</guid>
<content:encoded><![CDATA[
<div> : 

<br /><br />:

(PET)70% <div>
arXiv:2503.03428v1 Announce Type: new 
Abstract: In a world where data is the new currency, wearable health devices offer unprecedented insights into daily life, continuously monitoring vital signs and metrics. However, this convenience raises privacy concerns, as these devices collect sensitive data that can be misused or breached. Traditional measures often fail due to real-time data processing needs and limited device power. Users also lack awareness and control over data sharing and usage. We propose a Privacy-Enhancing Technology (PET) framework for wearable devices, integrating federated learning, lightweight cryptographic methods, and selectively deployed blockchain technology. The blockchain acts as a secure ledger triggered only upon data transfer requests, granting users real-time notifications and control. By dismantling data monopolies, this approach returns data sovereignty to individuals. Through real-world applications like secure medical data sharing, privacy-preserving fitness tracking, and continuous health monitoring, our framework reduces privacy risks by up to 70 percent while preserving data utility and performance. This innovation sets a new benchmark for wearable privacy and can scale to broader IoT ecosystems, including smart homes and industry. As data continues to shape our digital landscape, our research underscores the critical need to maintain privacy and user control at the forefront of technological progress.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards an Emotion-Aware Metaverse: A Human-Centric Shipboard Fire Drill Simulator</title>
<link>https://arxiv.org/abs/2503.03570</link>
<guid>https://arxiv.org/abs/2503.03570</guid>
<content:encoded><![CDATA[
<div> XR, Metaverse, , (VR), 

:<br />
VRMeta Quest ProVR14.1832.72 <div>
arXiv:2503.03570v1 Announce Type: new 
Abstract: Traditional XR and Metaverse applications prioritize user experience (UX) for adoption and success but often overlook a crucial aspect of user interaction: emotions. This article addresses this gap by presenting an emotion-aware Metaverse application: a Virtual Reality (VR) fire drill simulator designed to prepare crews for shipboard emergencies. The simulator detects emotions in real time, assessing trainees responses under stress to improve learning outcomes. Its architecture incorporates eye-tracking and facial expression analysis via Meta Quest Pro headsets. The system features four levels whose difficulty is increased progressively to evaluate user decision-making and emotional resilience. The system was evaluated in two experimental phases. The first phase identified challenges, such as navigation issues and lack of visual guidance. These insights led to an improved second version with a better user interface, visual cues and a real-time task tracker. Performance metrics like completion times, task efficiency and emotional responses were analyzed. The obtained results show that trainees with prior VR or gaming experience navigated the scenarios more efficiently. Moreover, the addition of task-tracking visuals and navigation guidance significantly improved user performance, reducing task completion times between 14.18\% and 32.72\%. Emotional responses were captured, revealing that some participants were engaged, while others acted indifferently, indicating the need for more immersive elements. Overall, this article provides useful guidelines for creating the next generation of emotion-aware Metaverse applications.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Zero-Knowledge Proof-based Verifiable Decentralized Machine Learning in Communication Network: A Comprehensive Survey</title>
<link>https://arxiv.org/abs/2310.14848</link>
<guid>https://arxiv.org/abs/2310.14848</guid>
<content:encoded><![CDATA[
<div> ZKP-VML

<br /><br />:
Zero-Knowledge ProofZKPZKP-VMLZKP-VMLZKP-VMLZKP-VML <div>
arXiv:2310.14848v2 Announce Type: replace 
Abstract: Over recent decades, machine learning has significantly advanced network communication, enabling improved decision-making, user behavior analysis, and fault detection. Decentralized approaches, where participants exchange computation results instead of raw private data, mitigate these risks but introduce challenges related to trust and verifiability. A critical issue arises: How can one ensure the integrity and validity of computation results shared by other participants? Existing survey articles predominantly address security and privacy concerns in decentralized machine learning, whereas this survey uniquely highlights the emerging issue of verifiability. Recognizing the critical role of zero-knowledge proofs in ensuring verifiability, we present a comprehensive review of Zero-Knowledge Proof-based Verifiable Machine Learning (ZKP-VML). To clarify the research problem, we present a definition of ZKP-VML consisting of four algorithms, along with several corresponding key security properties. Besides, we provide an overview of the current research landscape by systematically organizing the research timeline and categorizing existing schemes based on their security properties. Furthermore, through an in-depth analysis of each existing scheme, we summarize their technical contributions and optimization strategies, aiming to uncover common design principles underlying ZKP-VML schemes. Building on the reviews and analysis presented, we identify current research challenges and suggest future research directions. To the best of our knowledge, this is the most comprehensive survey to date on verifiable decentralized machine learning and ZKP-VML.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning with Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16720</link>
<guid>https://arxiv.org/abs/2409.16720</guid>
<content:encoded><![CDATA[
<div> 

:
CTDEPPO5.5m*5.5m*2.0m13.65 m/s13.4 rad/s <div>
arXiv:2409.16720v2 Announce Type: replace 
Abstract: Recent innovations in autonomous drones have facilitated time-optimal flight in single-drone configurations, and enhanced maneuverability in multi-drone systems by applying optimal control and learning-based methods. However, few studies have achieved time-optimal motion planning for multi-drone systems, particularly during highly agile maneuvers or in dynamic scenarios. This paper presents a decentralized policy network using multi-agent reinforcement learning for time-optimal multi-drone flight. To strike a balance between flight efficiency and collision avoidance, we introduce a soft collision-free mechanism inspired by optimization-based methods. By customizing PPO in a centralized training, decentralized execution (CTDE) fashion, we unlock higher efficiency and stability in training while ensuring lightweight implementation. Extensive simulations show that, despite slight performance trade-offs compared to single-drone systems, our multi-drone approach maintains near-time-optimal performance with a low collision rate. Real-world experiments validate our method, with two quadrotors using the same network as in simulation achieving a maximum speed of 13.65 m/s and a maximum body rate of 13.4 rad/s in a 5.5 m * 5.5 m * 2.0 m space across various tracks, relying entirely on onboard computation.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Protecting DeFi Platforms against Non-Price Flash Loan Attacks</title>
<link>https://arxiv.org/abs/2503.01944</link>
<guid>https://arxiv.org/abs/2503.01944</guid>
<content:encoded><![CDATA[
<div> : (DeFi)

:
FlashGuardFlashGuardmempoolFlashGuard150.3199.93%410.92FlashGuard4.0571FlashGuardDeFi <div>
arXiv:2503.01944v1 Announce Type: new 
Abstract: Smart contracts in Decentralized Finance (DeFi) platforms are attractive targets for attacks as their vulnerabilities can lead to massive amounts of financial losses. Flash loan attacks, in particular, pose a major threat to DeFi protocols that hold a Total Value Locked (TVL) exceeding \$106 billion. These attacks use the atomicity property of blockchains to drain funds from smart contracts in a single transaction. While existing research primarily focuses on price manipulation attacks, such as oracle manipulation, mitigating non-price flash loan attacks that often exploit smart contracts' zero-day vulnerabilities remains largely unaddressed. These attacks are challenging to detect because of their unique patterns, time sensitivity, and complexity. In this paper, we present FlashGuard, a runtime detection and mitigation method for non-price flash loan attacks. Our approach targets smart contract function signatures to identify attacks in real-time and counterattack by disrupting the attack transaction atomicity by leveraging the short window when transactions are visible in the mempool but not yet confirmed. When FlashGuard detects an attack, it dispatches a stealthy dusting counterattack transaction to miners to change the victim contract's state which disrupts the attack's atomicity and forces the attack transaction to revert. We evaluate our approach using 20 historical attacks and several unseen attacks. FlashGuard achieves an average real-time detection latency of 150.31ms, a detection accuracy of over 99.93\%, and an average disruption time of 410.92ms. FlashGuard could have potentially rescued over \$405.71 million in losses if it were deployed prior to these attack instances. FlashGuard demonstrates significant potential as a DeFi security solution to mitigate and handle rising threats of non-price flash loan attacks.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trust and Friction: Negotiating How Information Flows Through Decentralized Social Media</title>
<link>https://arxiv.org/abs/2503.02150</link>
<guid>https://arxiv.org/abs/2503.02150</guid>
<content:encoded><![CDATA[
<div> Fediverse

<br />
:
Fediverse23 <div>
arXiv:2503.02150v1 Announce Type: new 
Abstract: Decentralized social media protocols enable users in independent, user-hosted servers (i.e., instances) to interact with each other while they self-govern. This community-based model of social media governance opens up new opportunities for tailored decision-making about information flows -- i.e., what user data is shared to whom and when -- and in turn, for protecting user privacy. To better understand how community governance shapes privacy expectations on decentralized social media, we conducted a semi-structured interview with 23 users of the Fediverse, a decentralized social media network. Our findings illustrate important factors that shape a community's understandings of information flows, such as rules and proactive efforts from admins who are perceived as trustworthy. We also highlight ''governance frictions'' between communities that raise new privacy risks due to incompatibilities in values, security practices, and software. Our findings highlight the unique challenges of decentralized social media, suggest design opportunities to address frictions, and outline the role of participatory decision-making to realize the full potential of decentralization.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AugFL: Augmenting Federated Learning with Pretrained Models</title>
<link>https://arxiv.org/abs/2503.02154</link>
<guid>https://arxiv.org/abs/2503.02154</guid>
<content:encoded><![CDATA[
<div> Federated Learning, , , , 

:

Federated LearningAugFL-ADMMAugFLAugFL

<br /><br /> <div>
arXiv:2503.02154v1 Announce Type: new 
Abstract: Federated Learning (FL) has garnered widespread interest in recent years. However, owing to strict privacy policies or limited storage capacities of training participants such as IoT devices, its effective deployment is often impeded by the scarcity of training data in practical decentralized learning environments. In this paper, we study enhancing FL with the aid of (large) pre-trained models (PMs), that encapsulate wealthy general/domain-agnostic knowledge, to alleviate the data requirement in conducting FL from scratch. Specifically, we consider a networked FL system formed by a central server and distributed clients. First, we formulate the PM-aided personalized FL as a regularization-based federated meta-learning problem, where clients join forces to learn a meta-model with knowledge transferred from a private PM stored at the server. Then, we develop an inexact-ADMM-based algorithm, AugFL, to optimize the problem with no need to expose the PM or incur additional computational costs to local clients. Further, we establish theoretical guarantees for AugFL in terms of communication complexity, adaptation performance, and the benefit of knowledge transfer in general non-convex cases. Extensive experiments corroborate the efficacy and superiority of AugFL over existing baselines.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Traffic Signal Control based on Multi-Agent Reinforcement Learning. Case Study on a simulated real-world corridor</title>
<link>https://arxiv.org/abs/2503.02189</link>
<guid>https://arxiv.org/abs/2503.02189</guid>
<content:encoded><![CDATA[
<div> multi-agent reinforcement learningpolicy-based methodsProximal Policy OptimizationPPO

<br /><br />

Proximal Policy OptimizationMA-PPOVissim-MaxTimeASCMA-PPO14%29%MA-PPO <div>
arXiv:2503.02189v1 Announce Type: new 
Abstract: The very few studies that have attempted to formulate multi-agent reinforcement learning (RL) algorithms for adaptive traffic signal control have mainly used value-based RL methods although recent literature has shown that policy-based methods may perform better in partially observable environments. Additionally, because of the simplifying assumptions on signal timing made almost universally across previous studies, RL methods remain largely untested for real-world signal timing plans. This study formulates a multi-agent proximal policy optimization (MA-PPO) algorithm to implement adaptive and coordinated traffic control along an arterial corridor. The formulated MA-PPO has centralized critic architecture under the centralized training and decentralized execution framework. All agents are formulated to allow selection and implementation of up to eight signal phases as commonly implemented in the field controllers. The formulated algorithm is tested on a simulated real-world corridor with seven intersections, actual/complete traffic movements and signal phases, traffic volumes, and network geometry including intersection spacings. The performance of the formulated MA-PPO adaptive control algorithm is compared with the field implemented coordinated and actuated signal control (ASC) plans modeled using Vissim-MaxTime software in the loop simulation (SILs). The speed of convergence for each agent largely depended on the size of the action space which in turn depended on the number and sequence of signal phases. Compared with the currently implemented ASC signal timings, MA-PPO showed a travel time reduction of about 14% and 29%, respectively for the two through movements across the entire test corridor. Through volume sensitivity experiments, the formulated MA-PPO showed good stability, robustness and adaptability to changes in traffic demand.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Goal-Oriented Interference Coordination in 6G In-Factory Subnetworks</title>
<link>https://arxiv.org/abs/2503.02521</link>
<guid>https://arxiv.org/abs/2503.02521</guid>
<content:encoded><![CDATA[
<div> : subnetworks, , , 6G, , , , , , 

<br />
:
6G <div>
arXiv:2503.02521v1 Announce Type: new 
Abstract: Subnetworks are expected to enhance wireless pervasiveness for critical applications such as wireless control of plants, however, they are interference-limited due to their extreme density. This paper proposes a goal-oriented joint power and multiple sub-bands allocation policy for interference coordination in 6G in-factory subnetworks. Current methods for interference coordination in subnetworks only focus on optimizing communication metrics, such as the block error rate, without considering the goal of the controlled plants. This oversight often leads to inefficient allocation of the limited radio resources. To address this, we devise a novel decentralized inter-subnetwork interference coordination policy optimized using a Bayesian framework to ensure the long-term stability of the subnetwork-controlled plants. Our results show that the proposed decentralized method can support more than twice the density of subnetwork-controlled plants compared to centralized schemes that aim to minimize the block error rate while reducing execution complexity significantly.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated nnU-Net for Privacy-Preserving Medical Image Segmentation</title>
<link>https://arxiv.org/abs/2503.02549</link>
<guid>https://arxiv.org/abs/2503.02549</guid>
<content:encoded><![CDATA[
<div> nnU-NetFederated Fingerprint Extraction (FFE)Asymmetric Federated Averaging (AsymFedAvg)

:
FednnU-NetnnU-NetnnU-NetFederated Fingerprint Extraction (FFE)  Asymmetric Federated Averaging (AsymFedAvg)186https://github.com/faildeny/FednnUNet  <div>
arXiv:2503.02549v1 Announce Type: new 
Abstract: The nnU-Net framework has played a crucial role in medical image segmentation and has become the gold standard in multitudes of applications targeting different diseases, organs, and modalities. However, so far it has been used primarily in a centralized approach where the data collected from hospitals are stored in one center and used to train the nnU-Net. This centralized approach has various limitations, such as leakage of sensitive patient information and violation of patient privacy. Federated learning is one of the approaches to train a segmentation model in a decentralized manner that helps preserve patient privacy. In this paper, we propose FednnU-Net, a federated learning extension of nnU-Net. We introduce two novel federated learning methods to the nnU-Net framework - Federated Fingerprint Extraction (FFE) and Asymmetric Federated Averaging (AsymFedAvg) - and experimentally show their consistent performance for breast, cardiac and fetal segmentation using 6 datasets representing samples from 18 institutions. Additionally, to further promote research and deployment of decentralized training in privacy constrained institutions, we make our plug-n-play framework public. The source-code is available at https://github.com/faildeny/FednnUNet .
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning for Privacy-Preserving Feedforward Control in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.02693</link>
<guid>https://arxiv.org/abs/2503.02693</guid>
<content:encoded><![CDATA[
<div>  Federated LearningFeedforward controlFeedback controlMulti-agent systemsAutonomous driving

<br /><br />

FL <div>
arXiv:2503.02693v1 Announce Type: new 
Abstract: Feedforward control (FF) is often combined with feedback control (FB) in many control systems, improving tracking performance, efficiency, and stability. However, designing effective data-driven FF controllers in multi-agent systems requires significant data collection, including transferring private or proprietary data, which raises privacy concerns and incurs high communication costs. Therefore, we propose a novel approach integrating Federated Learning (FL) into FF control to address these challenges. This approach enables privacy-preserving, communication-efficient, and decentralized continuous improvement of FF controllers across multiple agents without sharing personal or proprietary data. By leveraging FL, each agent learns a local, neural FF controller using its data and contributes only model updates to a global aggregation process, ensuring data privacy and scalability. We demonstrate the effectiveness of our method in an autonomous driving use case. Therein, vehicles equipped with a trajectory-tracking feedback controller are enhanced by FL-based neural FF control. Simulations highlight significant improvements in tracking performance compared to pure FB control, analogous to model-based FF control. We achieve comparable tracking performance without exchanging private vehicle-specific data compared to a centralized neural FF control. Our results underscore the potential of FL-based neural FF control to enable privacy-preserving learning in multi-agent control systems, paving the way for scalable and efficient autonomous systems applications.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ESSPI: ECDSA/Schnorr Signed Program Input for BitVMX</title>
<link>https://arxiv.org/abs/2503.02772</link>
<guid>https://arxiv.org/abs/2503.02772</guid>
<content:encoded><![CDATA[
<div> BitVMXOTSECDSA/SchnorrESSPI

:

ESSPIBitVMXECDSA/SchnorrLamportWinternitzESSPI1:2001:1BitVMX(1) BitVMX CPU(2) (3) DAG(4) BitVMXSPVNiPoPoWsSTARKs<br /><br /> <div>
arXiv:2503.02772v1 Announce Type: new 
Abstract: The BitVM and BitVMX protocols have long relied on inefficient one-time signature (OTS) schemes like Lamport and Winternitz for signing program inputs. These schemes exhibit significant storage overheads, hindering their practical application. This paper introduces ESSPI, an optimized method leveraging ECDSA/Schnorr signatures to sign the BitVMX program input. With Schnorr signatures we achieve an optimal 1:1 data expansion, compared to the current known best ratio of 1:200 based on Winternitz signatures. To accomplish this we introduce 4 innovations to BitVMX: (1) a modification of the BitVMX CPU, adding a challengeable hashing core to it, (2) a new partition-based search to detect fraud during hashing, (3) a new enhanced transaction DAG with added data-carrying transactions with a fraud-verifying smart-contract and (4) a novel timelock-based method for proving data availability to Bitcoin smart contracts. The enhanced BitVMX protocol enables the verification of uncompressed inputs such as SPV proofs, NiPoPoWs, or longer computation integrity proofs, such as STARKs.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Game-Theoretic Approach for High-Resolution Automotive FMCW Radar Interference Avoidance</title>
<link>https://arxiv.org/abs/2503.02327</link>
<guid>https://arxiv.org/abs/2503.02327</guid>
<content:encoded><![CDATA[
<div> FMCW

:
FMCWNECCESINR <div>
arXiv:2503.02327v1 Announce Type: cross 
Abstract: Nonlinear frequency hopping has emerged as a promising approach for mitigating interference and enhancing range resolution in automotive FMCW radar systems. Achieving an optimal balance between high range-resolution and effective interference mitigation remains challenging, especially without centralized frequency scheduling. This paper presents a game-theoretic framework for interference avoidance, in which each radar operates as an independent player, optimizing its performance through decentralized decision-making. We examine two equilibrium concepts--Nash Equilibrium (NE) and Coarse Correlated Equilibrium (CCE)--as strategies for frequency band allocation, with CCE demonstrating particular effectiveness through regret minimization algorithms. We propose two interference avoidance algorithms: Nash Hopping, a model-based approach, and No-Regret Hopping, a model-free adaptive method. Simulation results indicate that both methods effectively reduce interference and enhance the signal-to-interference-plus-noise ratio (SINR). Notably, No-regret Hopping further optimizes frequency spectrum utilization, achieving improved range resolution compared to Nash Hopping.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Reinforcement Learning for Multi-Agent Multi-Resource Allocation via Dynamic Cluster Agreements</title>
<link>https://arxiv.org/abs/2503.02437</link>
<guid>https://arxiv.org/abs/2503.02437</guid>
<content:encoded><![CDATA[
<div> LGTC-IPPO

:
LGTC-IPPOIPPOLGTC-IPPO <div>
arXiv:2503.02437v1 Announce Type: cross 
Abstract: This paper addresses the challenge of allocating heterogeneous resources among multiple agents in a decentralized manner. Our proposed method, LGTC-IPPO, builds upon Independent Proximal Policy Optimization (IPPO) by integrating dynamic cluster consensus, a mechanism that allows agents to form and adapt local sub-teams based on resource demands. This decentralized coordination strategy reduces reliance on global information and enhances scalability. We evaluate LGTC-IPPO against standard multi-agent reinforcement learning baselines and a centralized expert solution across a range of team sizes and resource distributions. Experimental results demonstrate that LGTC-IPPO achieves more stable rewards, better coordination, and robust performance even as the number of agents or resource types increases. Additionally, we illustrate how dynamic clustering enables agents to reallocate resources efficiently also for scenarios with discharging resources.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Adversarial Training over Graphs</title>
<link>https://arxiv.org/abs/2303.13326</link>
<guid>https://arxiv.org/abs/2303.13326</guid>
<content:encoded><![CDATA[
<div> : 

:
min-max<br /><br /> <div>
arXiv:2303.13326v2 Announce Type: replace 
Abstract: The vulnerability of machine learning models to adversarial attacks has been attracting considerable attention in recent years. Most existing studies focus on the behavior of stand-alone single-agent learners. In comparison, this work studies adversarial training over graphs, where individual agents are subjected to perturbations of varied strength levels across space. It is expected that interactions by linked agents, and the heterogeneity of the attack models that are possible over the graph, can help enhance robustness in view of the coordination power of the group. Using a min-max formulation of distributed learning, we develop a decentralized adversarial training framework for multi-agent systems. Specifically, we devise two decentralized adversarial training algorithms by relying on two popular decentralized learning strategies--diffusion and consensus. We analyze the convergence properties of the proposed framework for strongly-convex, convex, and non-convex environments, and illustrate the enhanced robustness to adversarial attacks.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CrowdAL: Towards a Blockchain-empowered Active Learning System in Crowd Data Labeling</title>
<link>https://arxiv.org/abs/2503.00066</link>
<guid>https://arxiv.org/abs/2503.00066</guid>
<content:encoded><![CDATA[
<div> : Active Learning, Crowdsourcing, Blockchain, Smart Contracts, Zero-Knowledge Proofs

:<br />
CrowdALActive LearningCrowdAL <div>
arXiv:2503.00066v1 Announce Type: new 
Abstract: Active Learning (AL) is a machine learning technique where the model selectively queries the most informative data points for labeling by human experts. Integrating AL with crowdsourcing leverages crowd diversity to enhance data labeling but introduces challenges in consensus and privacy. This poster presents CrowdAL, a blockchain-empowered crowd AL system designed to address these challenges. CrowdAL integrates blockchain for transparency and a tamper-proof incentive mechanism, using smart contracts to evaluate crowd workers' performance and aggregate labeling results, and employs zero-knowledge proofs to protect worker privacy.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction</title>
<link>https://arxiv.org/abs/2503.00154</link>
<guid>https://arxiv.org/abs/2503.00154</guid>
<content:encoded><![CDATA[
<div> Non-Terrestrial Networks (NTNs)Federated Learning (FL)Kolmogorov-Arnold Networks (KANs)traffic forecastingLow Earth Orbit (LEO)

:<br />
(NTNs)(LEO)Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN)Fed-MLPFed-KANKANsNTNFed-KANFed-MLP77.39%Fed-KAN(O-RAN)NTN <div>
arXiv:2503.00154v1 Announce Type: new 
Abstract: Non-Terrestrial Networks (NTNs) are becoming a critical component of modern communication infrastructures, especially with the advent of Low Earth Orbit (LEO) satellite systems. Traditional centralized learning approaches face major challenges in such networks due to high latency, intermittent connectivity and limited bandwidth. Federated Learning (FL) is a promising alternative as it enables decentralized training while maintaining data privacy. However, existing FL models, such as Federated Learning with Multi-Layer Perceptrons (Fed-MLP), can struggle with high computational complexity and poor adaptability to dynamic NTN environments. This paper provides a detailed analysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its implementation and performance improvements over traditional FL models in NTN environments for traffic forecasting. The proposed Fed-KAN is a novel approach that utilises the functional approximation capabilities of KANs in a FL framework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real satellite operator and show a significant reduction in training and test loss. Our results show that Fed-KAN can achieve a 77.39% reduction in average test loss compared to Fed-MLP, highlighting its improved performance and better generalization ability. At the end of the paper, we also discuss some potential applications of Fed-KAN within O-RAN and Fed-KAN usage for split functionalities in NTN architecture.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Elastic Restaking Networks</title>
<link>https://arxiv.org/abs/2503.00170</link>
<guid>https://arxiv.org/abs/2503.00170</guid>
<content:encoded><![CDATA[
<div> : 

:
 <div>
arXiv:2503.00170v1 Announce Type: new 
Abstract: Decentralized services for blockchains often require their validators (operators) to deposit stake (collateral), which is forfeited (slashed) if they misbehave. Restaking networks let validators secure multiple services by reusing stake, giving rise to a strategic game: Validators can coordinate to misbehave across multiple services, extracting digital assets while forfeiting their stake only once.
  Previous work focused either on preventing coordinated misbehavior or on protecting services if all other services are Byzantine and might unjustly cause slashing due to bugs or malice. The first model overlooks how a single Byzantine service can collapse the network, while the second ignores shared-stake benefits.
  To bridge the gap, we model the strategic game of coordinated misbehavior when a given fraction of services are Byzantine. We introduce elastic restaking networks, where validators can allocate portions of their stake that may cumulatively exceed their total stake, and when allocations are lost, the remaining stake stretches to cover remaining allocations. We show that elastic networks exhibit superior robustness compared to previous approaches, and demonstrate a synergistic effect where an elastic restaking network enhances its blockchain's security, contrary to community concerns of an opposite effect in existing networks. We then design incentives for tuning validators' allocations.
  Our elastic restaking system and incentive design have immediate practical implications for deployed restaking networks, which have billions of dollars in stake.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Path Dependence in AMM-Based Markets: Mathematical Proof and Implications for Truth Discovery</title>
<link>https://arxiv.org/abs/2503.00201</link>
<guid>https://arxiv.org/abs/2503.00201</guid>
<content:encoded><![CDATA[
<div> : Automated Market Maker (AMM)

:<br />
Automated Market Maker (AMM) UniswapAMMAMMETH/USDCAMM <div>
arXiv:2503.00201v1 Announce Type: new 
Abstract: This paper demonstrates that Automated Market Maker (AMM) based markets, such as those using constant product formulas (e.g., Uniswap), are inherently path-dependent. We prove mathematically that the sequence of operations in AMMs determines the final state, challenging the notion that market prices solely reflect information. This property has profound implications for decentralized prediction markets that rely on AMMs for price discovery, as it demonstrates they cannot function as pure "truth machines." Using both mathematical proofs and empirical evidence from ETH/USDC pools, we show that AMM-based markets incorporate historical path information beyond the current market beliefs. Our findings contribute to the understanding of market efficiency, mechanism design, and the interpretation of prices in decentralized finance systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asynchronous Personalized Federated Learning through Global Memorization</title>
<link>https://arxiv.org/abs/2503.00407</link>
<guid>https://arxiv.org/abs/2503.00407</guid>
<content:encoded><![CDATA[
<div> Federated LearningAsynchronous Personalized Federated Learning (AP FL)

<br /><br />

Asynchronous Personalized Federated Learning, AP FLAP FL AP FL <div>
arXiv:2503.00407v1 Announce Type: new 
Abstract: The proliferation of Internet of Things devices and advances in communication technology have unleashed an explosion of personal data, amplifying privacy concerns amid stringent regulations like GDPR and CCPA. Federated Learning offers a privacy preserving solution by enabling collaborative model training across decentralized devices without centralizing sensitive data. However, statistical heterogeneity from non-independent and identically distributed datasets and system heterogeneity due to client dropouts particularly those with monopolistic classes severely degrade the global model's performance. To address these challenges, we propose the Asynchronous Personalized Federated Learning framework, which empowers clients to develop personalized models using a server side semantic generator. This generator, trained via data free knowledge transfer under global model supervision, enhances client data diversity by producing both seen and unseen samples, the latter enabled by Zero-Shot Learning to mitigate dropout-induced data loss. To counter the risks of synthetic data impairing training, we introduce a decoupled model interpolation method, ensuring robust personalization. Extensive experiments demonstrate that AP FL significantly outperforms state of the art FL methods in tackling non-IID distributions and client dropouts, achieving superior accuracy and resilience across diverse real-world scenarios.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Revolutionizing Healthcare Record Management: Secure Documentation Storage and Access through Advanced Blockchain Solutions</title>
<link>https://arxiv.org/abs/2503.00742</link>
<guid>https://arxiv.org/abs/2503.00742</guid>
<content:encoded><![CDATA[
<div> : 

<br />
:
SHA-256IPFSArgon2AESIPFSPBFTMFAMetaMaskGanacheTruffleCPU <div>
arXiv:2503.00742v1 Announce Type: new 
Abstract: Integrating blockchain technology into healthcare systems presents a transformative approach to documenting, storing, and accessing electronic health records (EHRs). This research introduces a novel blockchain-based EHR system designed to significantly enhance security, scalability, and accessibility compared to existing solutions. Current systems primarily utilize SHA-256 for security and either IPFS or centralized storage, which, while effective, have limitations in providing comprehensive data integrity and security. The proposed system leverages a hybrid security algorithm combining Argon2 and AES and integrates a hybrid storage and consensus mechanism utilizing IPFS and PBFT. This multifaceted approach ensures robust encryption, efficient consensus, and high fault tolerance. Furthermore, the system incorporates Multi-Factor Authentication (MFA) to safeguard against unauthorized access. It utilizes advanced blockchain tools like MetaMask, Ganache, and Truffle to facilitate seamless interaction with the decentralized network. Simulation results demonstrate that this system offers superior protection against data breaches and enhances operational efficiency. Specifically, the proposed hybrid model substantially improves data integrity, consensus efficiency, fault tolerance, data availability, latency, bandwidth utilization, throughput, memory usage, and CPU usage across various healthcare applications. To validate the performance and security of the proposed system, comprehensive analyses were conducted using real-world healthcare scenarios. The findings highlight the significant advantages of the blockchain-based EHR system, emphasizing its potential to revolutionize healthcare data management by ensuring secure, reliable, and efficient handling of sensitive medical information.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fully Self-Synchronized Control for Hybrid Series-Parallel Electronized Power Networks</title>
<link>https://arxiv.org/abs/2503.00943</link>
<guid>https://arxiv.org/abs/2503.00943</guid>
<content:encoded><![CDATA[
<div> : hybrid series-parallel system, self-synchronization, control, decentralized control strategy, power droop, power factor angle droop

<br /><br />:
 <div>
arXiv:2503.00943v1 Announce Type: new 
Abstract: The hybrid series-parallel system is the final form of the power electronics-enabled power system, which combines the advantages of both series and parallel connections. Although self-synchronization of parallel-type and series-type systems is well known, self-synchronization of hybrid systems remains unrevealed. To fill in this gap, a fully self-synchronized control for hybrid series-parallel system is proposed in this paper. Based on the self-synchronization mechanism of power angle in parallel-type system and power factor angle in series-type system, a decentralized control strategy by integration of power droop and power factor angle droop can realize self-synchronization and power balancing of each module in the hybrid system.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Design, Implementation and Practical Evaluation of an Opportunistic Communications Protocol Based on Bluetooth Mesh and libp2p</title>
<link>https://arxiv.org/abs/2503.00976</link>
<guid>https://arxiv.org/abs/2503.00976</guid>
<content:encoded><![CDATA[
<div> : (IoT), , 5, libp2p, 

:<br />
5libp2p88.55% <div>
arXiv:2503.00976v1 Announce Type: new 
Abstract: The increasing proliferation of Internet of Things (IoT) devices has created a growing need for more efficient communication networks, especially in areas where continuous connectivity is unstable or unavailable. Opportunistic networks have emerged as a possible solution in such scenarios, allowing for intermittent and decentralized data sharing. This article presents a novel communication protocol that uses Bluetooth 5 and the libp2p framework to enable decentralized and opportunistic communications among IoT devices. The protocol provides dynamic peer discovery and decentralized management, resulting in a more flexible and robust IoT network infrastructure. The performance of the proposed architecture was evaluated through experiments in both controlled and industrial scenarios, with a particular emphasis on latency and on the impact of the presence of obstacles. The obtained results show that the protocol has the ability to improve data transfer in environments with limited connectivity, making it adequate for both urban and rural areas, as well as for challenging environments such as shipyards. Moreover, the presented findings conclude that the protocol works well in situations with minimal signal obstruction and short distances, like homes, where average latency values of about 8 s have been achieved with no losses. Furthermore, the protocol can also be used in industrial scenarios, even when metal obstacles increase signal attenuation, and over long distances, where average latency values of about 8.5 s have been obtained together with packet losses of less than 5%.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SolBench: A Dataset and Benchmark for Evaluating Functional Correctness in Solidity Code Completion and Repair</title>
<link>https://arxiv.org/abs/2503.01098</link>
<guid>https://arxiv.org/abs/2503.01098</guid>
<content:encoded><![CDATA[
<div> : SoliditySolBench<br /><br />:
SoliditySolBenchSoliditySolBench1,1554,178SolidityLLMLLM <div>
arXiv:2503.01098v1 Announce Type: new 
Abstract: Smart contracts are crucial programs on blockchains, and their immutability post-deployment makes functional correctness vital. Despite progress in code completion models, benchmarks for Solidity, the primary smart contract language, are lacking. Existing metrics like BLEU do not adequately assess the functional correctness of generated smart contracts. To fill this gap, we introduce SolBench, a benchmark for evaluating the functional correctness of Solidity smart contracts generated by code completion models. SolBench includes 4,178 functions from 1,155 Ethereum-deployed contracts. Testing advanced models revealed challenges in generating correct code without context, as Solidity functions rely on context-defined variables and interfaces. To address this, we propose a Retrieval-Augmented Code Repair framework. In this framework, an executor verifies functional correctness, and if necessary, an LLM repairs the code using retrieved snippets informed by executor traces. We conduct a comprehensive evaluation of both closed-source and open-source LLMs across various model sizes and series to assess their performance in smart contract completion. The results show that code repair and retrieval techniques effectively enhance the correctness of smart contract completion while reducing computational costs.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graph-Based Dynamics and Network Control of a Single Articulated Robotic System</title>
<link>https://arxiv.org/abs/2503.01101</link>
<guid>https://arxiv.org/abs/2503.01101</guid>
<content:encoded><![CDATA[
<div> graph-based dynamics, multi-agent systems, robotic swarms, single articulated robotic (SAR) systems, decentralized network control

<br /><br />:
SARholonomicLagrangianSAR- <div>
arXiv:2503.01101v1 Announce Type: new 
Abstract: Extensive research on graph-based dynamics and control of multi-agent systems has successfully demonstrated control of robotic swarms, where each robot is perceived as an independent agent virtually connected by a network topology. The strong advantage of the network control structure lies in the decentralized nature of the control action, which only requires the knowledge of virtually connected agents. In this paper, we seek to expand the ideas of virtual network constraints to physical constraints on a class of tree-structured robots which we denote as single articulated robotic (SAR) systems. In our proposed framework, each link can be viewed as an agent, and each holonomic constraint connecting links serves as an edge. By following the first principles of Lagrangian dynamics, we derive a consensus-like matrix-differential equation with weighted graph and edge Laplacians for the dynamics of a SAR system. The sufficient condition for the holonomic constraint forces becoming independent to the control inputs is derived. This condition leads to a decentralized leader-follower network control framework for regulating the relative configuration of the robot. Simulation results demonstrate the effectiveness of the proposed control method.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploration on Real World Assets and Tokenization</title>
<link>https://arxiv.org/abs/2503.01111</link>
<guid>https://arxiv.org/abs/2503.01111</guid>
<content:encoded><![CDATA[
<div> tokenizationreal-world assetsblockchainliquidityasset management

:
(RWAs)<br /><br /> <div>
arXiv:2503.01111v1 Announce Type: new 
Abstract: This study delves into the tokenization of real-world assets (RWAs) on the blockchain with the objective of augmenting liquidity and refining asset management practices. By conducting an exhaustive analysis of the technical procedures implicated and scrutinizing case studies of existing deployments, this research evaluates the advantages, hurdles, and prospective advancements of blockchain technology in reshaping conventional asset management paradigms.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Empirical Smart Contracts Latency Analysis on Ethereum Blockchain for Trustworthy Inter-Provider Agreements</title>
<link>https://arxiv.org/abs/2503.01397</link>
<guid>https://arxiv.org/abs/2503.01397</guid>
<content:encoded><![CDATA[
<div> 6G

:
DApp6GgasSepolia gas 12.523.910.924.70.43gas0.3686%30 <div>
arXiv:2503.01397v1 Announce Type: new 
Abstract: As 6G networks evolve, inter-provider agreements become crucial for dynamic resource sharing and network slicing across multiple domains, requiring on-demand capacity provisioning while enabling trustworthy interaction among diverse operators. To address these challenges, we propose a blockchain-based Decentralized Application (DApp) on Ethereum that introduces four smart contracts, organized into a Preliminary Agreement Phase and an Enforcement Phase, and measures their gas usage, thereby establishing an open marketplace where service providers can list, lease, and enforce resource sharing. We present an empirical evaluation of how gas price, block size, and transaction count affect transaction processing time on the live Sepolia Ethereum testnet in a realistic setting, focusing on these distinct smart-contract phases with varying computational complexities. We first examine transaction latency as the number of users (batch size) increases, observing median latencies from 12.5 s to 23.9 s in the Preliminary Agreement Phase and 10.9 s to 24.7 s in the Enforcement Phase. Building on these initial measurements, we perform a comprehensive Kruskal-Wallis test (p < 0.001) to compare latency distributions across quintiles of gas price, block size, and transaction count. The post-hoc analyses reveal that high-volume blocks overshadow fee variations when transaction logic is more complex (effect sizes up to 0.43), whereas gas price exerts a stronger influence when the computation is lighter (effect sizes up to 0.36). Overall, 86% of transactions finalize within 30 seconds, underscoring that while designing decentralized applications, there must be a balance between contract complexity and fee strategies. The implementation of this work is publicly accessible online.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FLAME: A Federated Learning Benchmark for Robotic Manipulation</title>
<link>https://arxiv.org/abs/2503.01729</link>
<guid>https://arxiv.org/abs/2503.01729</guid>
<content:encoded><![CDATA[
<div> federated learningrobotic manipulationFLAMEdecentralized trainingdata privacy

<br />
:

FLAMEFederated Learning Across Manipulation EnvironmentsFLAME160,000FLAMEFLAME <div>
arXiv:2503.01729v1 Announce Type: new 
Abstract: Recent progress in robotic manipulation has been fueled by large-scale datasets collected across diverse environments. Training robotic manipulation policies on these datasets is traditionally performed in a centralized manner, raising concerns regarding scalability, adaptability, and data privacy. While federated learning enables decentralized, privacy-preserving training, its application to robotic manipulation remains largely unexplored. We introduce FLAME (Federated Learning Across Manipulation Environments), the first benchmark designed for federated learning in robotic manipulation. FLAME consists of: (i) a set of large-scale datasets of over 160,000 expert demonstrations of multiple manipulation tasks, collected across a wide range of simulated environments; (ii) a training and evaluation framework for robotic policy learning in a federated setting. We evaluate standard federated learning algorithms in FLAME, showing their potential for distributed policy learning and highlighting key challenges. Our benchmark establishes a foundation for scalable, adaptive, and privacy-aware robotic learning.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shifting Power: Leveraging LLMs to Simulate Human Aversion in ABMs of Bilateral Financial Exchanges, A bond market study</title>
<link>https://arxiv.org/abs/2503.00320</link>
<guid>https://arxiv.org/abs/2503.00320</guid>
<content:encoded><![CDATA[
<div> : TRIBE

:<br />
TRIBETRIBE1LLMs23 <div>
arXiv:2503.00320v1 Announce Type: cross 
Abstract: Bilateral markets, such as those for government bonds, involve decentralized and opaque transactions between market makers (MMs) and clients, posing significant challenges for traditional modeling approaches. To address these complexities, we introduce TRIBE an agent-based model augmented with a large language model (LLM) to simulate human-like decision-making in trading environments. TRIBE leverages publicly available data and stylized facts to capture realistic trading dynamics, integrating human biases like risk aversion and ambiguity sensitivity into the decision-making processes of agents. Our research yields three key contributions: first, we demonstrate that integrating LLMs into agent-based models to enhance client agency is feasible and enriches the simulation of agent behaviors in complex markets; second, we find that even slight trade aversion encoded within the LLM leads to a complete cessation of trading activity, highlighting the sensitivity of market dynamics to agents' risk profiles; third, we show that incorporating human-like variability shifts power dynamics towards clients and can disproportionately affect the entire system, often resulting in systemic agent collapse across simulations. These findings underscore the emergent properties that arise when introducing stochastic, human-like decision processes, revealing new system behaviors that enhance the realism and complexity of artificial societies.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
</channel>
</rss>