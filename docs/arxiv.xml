<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>

<item>
<title>Learning Efficient Flocking Control based on Gibbs Random Fields</title>
<link>https://arxiv.org/abs/2502.02984</link>
<guid>https://arxiv.org/abs/2502.02984</guid>
<content:encoded><![CDATA[
<div> 关键词：多agent强化学习(MARL)，Gibbs随机场(GRFs)，多机器人系统，协同控制，运动安全性

<br><br>总结:
本文提出了一种基于Gibbs随机场的多agent强化学习(MARL)框架，用于解决多机器人系统在拥挤环境中实现高效协同控制所面临的计算负担、性能优化和运动安全性挑战。该框架利用GRFs将多机器人系统表示为遵循联合概率分布的一组随机变量，从而为设计群集奖励提供了新视角。通过基于GRF的信用分配方法实现了去中心化的训练与执行机制，增强了MARL对于机器人数量的可扩展性。同时，引入了动作注意力模块，以隐式预测邻近机器人的运动意图，从而缓解了MARL中的非平稳性问题。实验与仿真结果表明，提出的框架能够在复杂环境中使多机器人系统学习到有效的分布式控制策略，成功率高达约99%。此外，还进行了消融研究以验证不同框架模块的有效性。 <div>
arXiv:2502.02984v1 Announce Type: new 
Abstract: Flocking control is essential for multi-robot systems in diverse applications, yet achieving efficient flocking in congested environments poses challenges regarding computation burdens, performance optimality, and motion safety. This paper addresses these challenges through a multi-agent reinforcement learning (MARL) framework built on Gibbs Random Fields (GRFs). With GRFs, a multi-robot system is represented by a set of random variables conforming to a joint probability distribution, thus offering a fresh perspective on flocking reward design. A decentralized training and execution mechanism, which enhances the scalability of MARL concerning robot quantity, is realized using a GRF-based credit assignment method. An action attention module is introduced to implicitly anticipate the motion intentions of neighboring robots, consequently mitigating potential non-stationarity issues in MARL. The proposed framework enables learning an efficient distributed control policy for multi-robot systems in challenging environments with success rate around $99\%$, as demonstrated through thorough comparisons with state-of-the-art solutions in simulations and experiments. Ablation studies are also performed to validate the efficiency of different framework modules.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-objective methods in Federated Learning: A survey and taxonomy</title>
<link>https://arxiv.org/abs/2502.03108</link>
<guid>https://arxiv.org/abs/2502.03108</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、多目标优化、集成方法、分类、研究方向

<br><br>总结:
本文主要关注了Federated Learning范式下，如何通过多目标优化解决分布式机器学习中数据分散带来的复杂现实问题。随着该策略的普及，需要平衡公平性、效用和资源消耗等冲突需求的问题日益突出。文章指出现有工作开始认识到将多目标方法与联邦学习相结合的重要性，并首次在此领域提供了清晰而系统的整合方式概述。作者提出了一个多目标方法与联邦学习结合使用的初步分类体系，对当前的研究现状进行了有针对性的调查，并为相关贡献给出了明确的分类标签。鉴于这一领域的不断发展，该分类体系旨在为未来研究提供坚实基础，既能概括现有工作，又能预示未来的拓展方向。最后，文章指出了开放挑战及未来可能的研究方向。 <div>
arXiv:2502.03108v1 Announce Type: new 
Abstract: The Federated Learning paradigm facilitates effective distributed machine learning in settings where training data is decentralized across multiple clients. As the popularity of the strategy grows, increasingly complex real-world problems emerge, many of which require balancing conflicting demands such as fairness, utility, and resource consumption. Recent works have begun to recognise the use of a multi-objective perspective in answer to this challenge. However, this novel approach of combining federated methods with multi-objective optimisation has never been discussed in the broader context of both fields. In this work, we offer a first clear and systematic overview of the different ways the two fields can be integrated. We propose a first taxonomy on the use of multi-objective methods in connection with Federated Learning, providing a targeted survey of the state-of-the-art and proposing unambiguous labels to categorise contributions. Given the developing nature of this field, our taxonomy is designed to provide a solid basis for further research, capturing existing works while anticipating future additions. Finally, we outline open challenges and possible directions for further research.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Double Distillation Network for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.03125</link>
<guid>https://arxiv.org/abs/2502.03125</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning, centralized training-decentralized execution (CTDE), partial observability, Double Distillation Network (DDN), exploration capabilities

<br><br>总结:

本文针对多智能体强化学习中由于执行阶段的部分可观测性导致的累积误差问题，提出了一种名为Double Distillation Network (DDN)的新方法。DDN包含两个蒸馏模块，旨在增强鲁棒协作并促进信息约束条件下的协同过程。外部蒸馏模块利用全局指导网络和局部策略网络通过蒸馏技术缩小训练与执行之间的差距；内部蒸馏模块则引入基于状态信息的内在奖励，以提升智能体的探索能力。大量实验表明，DDN在多个场景下显著提高了性能。 <div>
arXiv:2502.03125v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning typically employs a centralized training-decentralized execution (CTDE) framework to alleviate the non-stationarity in environment. However, the partial observability during execution may lead to cumulative gap errors gathered by agents, impairing the training of effective collaborative policies. To overcome this challenge, we introduce the Double Distillation Network (DDN), which incorporates two distillation modules aimed at enhancing robust coordination and facilitating the collaboration process under constrained information. The external distillation module uses a global guiding network and a local policy network, employing distillation to reconcile the gap between global training and local execution. In addition, the internal distillation module introduces intrinsic rewards, drawn from state information, to enhance the exploration capabilities of agents. Extensive experiments demonstrate that DDN significantly improves performance across multiple scenarios.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Thetacrypt: A Distributed Service for Threshold Cryptography</title>
<link>https://arxiv.org/abs/2502.03247</link>
<guid>https://arxiv.org/abs/2502.03247</guid>
<content:encoded><![CDATA[
<div> 关键词: threshold cryptography, Thetacrypt, distributed systems, blockchain, cryptographic schemes

总结:
Thetacrypt是一个灵活、通用的库，旨在将多种阈值加密方案整合到单一代码库中，支持易于构建基于阈值密码学的分布式系统，并且与实现语言无关。该库以统一的方式支持各种不同协议，目前包含了覆盖密码算法、签名和随机数生成在内的六种加密方案。此外，Thetacrypt还具有一個可适配的底层网络层接口，提供点对点通信和总量序广播通道，后者可以由分布式账本等技术实现。Thetacrypt作为一个受控测试平台，可用于在一致条件下评估多个阈值密码方案的性能，表明传统的微观基准测试方法忽视了协议的分布式特性及其对于系统性能的相关性。 <div>
arXiv:2502.03247v1 Announce Type: new 
Abstract: Threshold cryptography is a powerful and well-known technique with many applications to systems relying on distributed trust. It has recently emerged also as a solution to challenges in blockchain: frontrunning prevention, managing wallet keys, and generating randomness. This work presents Thetacrypt, a versatile library for integrating many threshold schemes into one codebase. It offers a way to easily build distributed systems using threshold cryptography and is agnostic to their implementation language. The architecture of Thetacrypt supports diverse protocols uniformly. The library currently includes six cryptographic schemes that span ciphers, signatures, and randomness generation. The library additionally contains a flexible adapter to an underlying networking layer that provides peer-to-peer communication and a total-order broadcast channel; the latter can be implemented by distributed ledgers, for instance. Thetacrypt serves as a controlled testbed for evaluating the performance of multiple threshold-cryptographic schemes under consistent conditions, showing how the traditional micro benchmarking approach neglects the distributed nature of the protocols and its relevance when considering system performance.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interaction-Aware Gaussian Weighting for Clustered Federated Learning</title>
<link>https://arxiv.org/abs/2502.03340</link>
<guid>https://arxiv.org/abs/2502.03340</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 数据异质性, 类别不平衡, 集群化FL, FedGWC<br><br>总结:<br>
本文提出了一种新型的联邦学习方法FedGWC，旨在解决数据异质性和类别不平衡导致的模型性能下降问题。FedGWC采用集群化的联邦学习策略，通过利用高斯奖励机制将客户端根据其数据分布进行聚类，从而实现更健壮和个性化的模型训练。同时，文中还引入了Wasserstein调整得分，这是一种用于评估FL中集群凝聚力与个体类别分布关系的新聚类指标。实验结果显示，FedGWC在聚类质量和分类准确性上均优于现有的联邦学习算法，验证了该方法的有效性。 <div>
arXiv:2502.03340v1 Announce Type: new 
Abstract: Federated Learning (FL) emerged as a decentralized paradigm to train models while preserving privacy. However, conventional FL struggles with data heterogeneity and class imbalance, which degrade model performance. Clustered FL balances personalization and decentralized training by grouping clients with analogous data distributions, enabling improved accuracy while adhering to privacy constraints. This approach effectively mitigates the adverse impact of heterogeneity in FL. In this work, we propose a novel clustered FL method, FedGWC (Federated Gaussian Weighting Clustering), which groups clients based on their data distribution, allowing training of a more robust and personalized model on the identified clusters. FedGWC identifies homogeneous clusters by transforming individual empirical losses to model client interactions with a Gaussian reward mechanism. Additionally, we introduce the Wasserstein Adjusted Score, a new clustering metric for FL to evaluate cluster cohesion with respect to the individual class distribution. Our experiments on benchmark datasets show that FedGWC outperforms existing FL algorithms in cluster quality and classification accuracy, validating the efficacy of our approach.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2502.03377</link>
<guid>https://arxiv.org/abs/2502.03377</guid>
<content:encoded><![CDATA[
<div> 关键词: NG-IoT, 电力消耗, 物联网设备, 飞行LoRa网关, 多智能体强化学习

总结:
随着下一代物联网(NG-IoT)网络的迅速发展，连接设备数量的增长导致电力消耗显著增加，对资源可用性和大规模物联网部署的可持续性提出了挑战。本文提出了一种利用搭载于无人机(UAV)上的飞行LoRa网关收集LoRa终端设备(EDs)数据并传输至中央服务器的方法，旨在通过联合优化无线LoRa网络的发射功率、扩频因子、带宽和ED关联来最大化全球系统能效(EE)。为解决这一难题，文章将问题建模为部分可观测马尔科夫决策过程(POMDP)，并采用集中训练与分散执行(Centralized Training and Decentralized Execution, CTDE)下的合作多智能体强化学习(MARL)方法。模拟结果显示，基于多智能体亲策略优化(MAPPO)算法的提出的方案能显著提高全球系统EE，并优于传统的MARL策略。<br><br> <div>
arXiv:2502.03377v1 Announce Type: new 
Abstract: With the rapid development of next-generation Internet of Things (NG-IoT) networks, the increasing number of connected devices has led to a surge in power consumption. This rise in energy demand poses significant challenges to resource availability and raises sustainability concerns for large-scale IoT deployments. Efficient energy utilization in communication networks, particularly for power-constrained IoT devices, has thus become a critical area of research. In this paper, we deployed flying LoRa gateways (GWs) mounted on unmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) and transmit it to a central server. Our primary objective is to maximize the global system energy efficiency (EE) of wireless LoRa networks by joint optimization of transmission power (TP), spreading factor (SF), bandwidth (W), and ED association. To solve this challenging problem, we model the problem as a partially observable Markov decision process (POMDP), where each flying LoRa GW acts as a learning agent using a cooperative Multi-Agent Reinforcement Learning (MARL) approach under centralized training and decentralized execution (CTDE). Simulation results demonstrate that our proposed method, based on the multi-agent proximal policy optimization (MAPPO) algorithm, significantly improves the global system EE and surpasses the conventional MARL schemes.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cryptocurrency Network Analysis</title>
<link>https://arxiv.org/abs/2502.03411</link>
<guid>https://arxiv.org/abs/2502.03411</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币网络分析、社交网络分析、交易数据、比特币、以太坊

<br><br>总结:
本文主要介绍了加密货币网络分析这一领域，该领域应用社交网络分析的方法和技术来研究源自加密货币（如比特币）的交易数据，以及基于智能合约系统（如以太坊）中用户交换的价值、数字物品和服务。与大多数在线社交网络主要交换文本内容不同，这些系统中的用户主要是进行价值转移。 <div>
arXiv:2502.03411v1 Announce Type: new 
Abstract: Cryptocurrency network analysis consists of applying the tools and methods of social network analysis to transactional data issued from cryptocurrencies. The main difference with most online social networks is that users do not exchange textual content but instead value -- in systems designed mainly as cryptocurrency, such as Bitcoin -- or digital items and services in more permissive systems based on smart contracts such as Ethereum.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid Blockchain-IPFS Solution for Secure and Scalable Data Collection and Storage for Smart Water Meters</title>
<link>https://arxiv.org/abs/2502.03427</link>
<guid>https://arxiv.org/abs/2502.03427</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网(IoT)，区块链，InterPlanetary File System (IPFS)，智能水表(SWM)，存储效率

总结:

该文研究了一种将区块链与InterPlanetary File System (IPFS)结合的混合方案，旨在优化物联网(IoT)应用如智能水表(SWM)数据的存储效率并确保安全性。通过将大量数据下链存储至IPFS以减轻区块链的压力，同时保持链上数据完整性。文章基于substrate构建了一个用于存储SWM数据的私有区块链，并进行了控制实验，评估了在不同数据量和节点数情况下，区块链单独使用和结合IPFS两种情况下的性能。实验结果显示，采用IPFS集成方案能显著减少区块链上的存储需求，从而减小块大小、提高交易吞吐量和改善块生成时间。这些发现强调了混合区块链-IPFS模型对于高容量IoT数据高效且安全管理的潜力。 <div>
arXiv:2502.03427v1 Announce Type: new 
Abstract: Scalable and secure data management is important in Internet of Things (IoT) applications such as smart water meters, where traditional blockchain storage can be restrictive due to high data volumes. This paper investigates a hybrid blockchain and InterPlanetary File System (IPFS) approach designed to optimise storage efficiency, enhance throughput, and reduce block time by offloading large data off-chain to IPFS while preserving on-chain integrity. A substrate-based private blockchain was developed to store smart water meter (SWM) data, and controlled experiments were conducted to evaluate blockchain performance with and without IPFS. Key metrics, including block size, block time, and transaction throughput, were analysed across varying data volumes and node counts. Results show that integrating IPFS significantly reduces on-chain storage demands, leading to smaller block sizes, increased throughput, and improved block times compared to blockchain-only storage. These findings highlight the potential of hybrid blockchain-IPFS models for efficiently and securely managing high-volume IoT data.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Analyzing Political Discourse on Discord during the 2024 U.S. Presidential Election</title>
<link>https://arxiv.org/abs/2502.03433</link>
<guid>https://arxiv.org/abs/2502.03433</guid>
<content:encoded><![CDATA[
<div> 关键词：社交媒体、Discord、政治运动、2024年美国大选、语义分析

总结:
该研究关注了在主流社交媒体平台之外的Discord上关于2024年美国总统选举的政治讨论。通过对超过3000万条来自政治服务器的消息进行分析，研究人员将这些服务器划分为共和党倾向、民主党倾向和中立三类。研究发现，在关键竞选事件期间，共和党服务器更侧重于经济政策讨论，而民主党服务器则更多涉及平等和进步议题。此外，在卡玛拉·哈里斯被提名为副总统候选人后，共和党倾向的服务器中的性别歧视等有毒语言有所增加。这项研究揭示了 Discord 在塑造和理解在线政治参与方面日益增长的作用，为分析这一新兴平台上的政治行为提供了初步见解。 <div>
arXiv:2502.03433v1 Announce Type: new 
Abstract: Social media networks have amplified the reach of social and political movements, but most research focuses on mainstream platforms such as X, Reddit, and Facebook, overlooking Discord. As a rapidly growing, community-driven platform with optional decentralized moderation, Discord offers unique opportunities to study political discourse. This study analyzes over 30 million messages from political servers on Discord discussing the 2024 U.S. elections. Servers were classified as Republican-aligned, Democratic-aligned, or unaligned based on their descriptions. We tracked changes in political conversation during key campaign events and identified distinct political valence and implicit biases in semantic association through embedding analysis. We observed that Republican servers emphasized economic policies, while Democratic servers focused on equality-related and progressive causes. Furthermore, we detected an increase in toxic language, such as sexism, in Republican-aligned servers after Kamala Harris's nomination. These findings provide a first look at political behavior on Discord, highlighting its growing role in shaping and understanding online political engagement.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Model-based Analysis of Mining Fairness in a Blockchain</title>
<link>https://arxiv.org/abs/2406.00595</link>
<guid>https://arxiv.org/abs/2406.00595</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、公平性、挖矿、交易处理能力、数学模型

总结:
本文针对区块链中的挖掘公平性问题进行研究，该问题是交易处理能力和挖矿公平性之间存在矛盾，可能导致去中心化的削弱。尽管该问题在采用如GHOST协议等方法后仍未能解决，但目前对挖掘公平性的定量分析研究尚不充分。为此，文章提出一种计算挖掘公平性的方法，首先通过建立假设每轮最多生成两个区块的简单数学模型来近似复杂的区块链网络，并在此基础上定量化地定义了局部挖矿公平性以及推导出一系列全球挖矿公平性的衡量指标。接着，通过区块链网络模拟验证了该计算方法相比现有方法能更准确地计算出网络中的挖掘公平性。最后，作者从挖矿公平性的角度对多种网络进行了深入分析。 <div>
arXiv:2406.00595v2 Announce Type: replace 
Abstract: Mining fairness in blockchain refers to equality between the computational resources invested in mining and the block rewards received. There exists a dilemma wherein increasing the transaction processing capacity of a blockchain compromises mining fairness, which consequently undermines its decentralization. This dilemma remains unresolved even with methods such as the greedy heaviest observed subtree (GHOST) protocol, indicating that mining fairness is an inherent bottleneck in the transaction processing capacity of the blockchain system. However, despite its significance, there have been insufficient research studies that have quantitatively analyzed mining fairness. In this paper, we propose a method for calculating mining fairness. First, we approximated a complex blockchain network using a simple mathematical model, assuming that no more than two blocks are generated per round. Within this model, we quantitatively determined local mining fairness and derived several measures of global mining fairness based on local mining fairness. Subsequently, we validated by blockchain network simulations that our calculation method computes mining fairness in networks much more accurately than existing methods. Finally, we analyzed various networks from the perspective of mining fairness.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>

<item>
<title>Expected Return Symmetries</title>
<link>https://arxiv.org/abs/2502.01711</link>
<guid>https://arxiv.org/abs/2502.01711</guid>
<content:encoded><![CDATA[
<div> 关键词：对称性、深度学习、多智能体、部分可观测马尔科夫决策过程、预期回报对称性

<br /><br />总结:
本文提出了一个新的研究方向，关注于在深度学习特别是多智能体环境中对称性的利用与发现。文章指出现有方法主要处理已知环境对称性以解决协调失败问题，但自动发现环境对称性，特别是在部分可观测马尔科夫决策过程中，仍是一个开放问题。为此，文中引入了一种更广泛的新对称性概念——预期回报对称性，它将环境对称性作为其子群。通过训练兼容预期回报对称性的智能体，作者展示了这些智能体能实现比仅使用环境对称性更好的零样本协调效果。此外，该方法对环境结构几乎没有预先假设，也不需要访问真实的对称信息。 <div>
arXiv:2502.01711v1 Announce Type: new 
Abstract: Symmetry is an important inductive bias that can improve model robustness and generalization across many deep learning domains. In multi-agent settings, a priori known symmetries have been shown to address a fundamental coordination failure mode known as mutually incompatible symmetry breaking; e.g. in a game where two independent agents can choose to move "left'' or "right'', and where a reward of +1 or -1 is received when the agents choose the same action or different actions, respectively. However, the efficient and automatic discovery of environment symmetries, in particular for decentralized partially observable Markov decision processes, remains an open problem. Furthermore, environmental symmetry breaking constitutes only one type of coordination failure, which motivates the search for a more accessible and broader symmetry class. In this paper, we introduce such a broader group of previously unexplored symmetries, which we call expected return symmetries, which contains environment symmetries as a subgroup. We show that agents trained to be compatible under the group of expected return symmetries achieve better zero-shot coordination results than those using environment symmetries. As an additional benefit, our method makes minimal a priori assumptions about the structure of their environment and does not require access to ground truth symmetries.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeViNE: A Decentralized Virtual Network Embedding Algorithm</title>
<link>https://arxiv.org/abs/2502.01807</link>
<guid>https://arxiv.org/abs/2502.01807</guid>
<content:encoded><![CDATA[
<div> 关键词：Virtual Network Embedding (VNE), 分布式算法, 可扩展性, 故障容错, DoS攻击

总结:
本文针对虚拟网络嵌入(VNE)技术提出了一种分布式算法实现方案。该方案旨在解决传统集中式算法存在的可扩展性和单一故障点问题以及对DoS攻击的防御能力不足。方法是选取L个物理节点作为领导者，并使用简单的BFS等算法在其局部网络中嵌入虚拟网络请求(VNR)。随后通过领导者选举机制确定成本最低、收入最高的节点，并将嵌入结果传播给其他领导者。利用这种分布式策略，提高了解决方案的可扩展性和鲁棒性。实验结果显示，相较于现有方法，该完全分布式的算法在接受率上提升了$12\%$，并将收益与成本比改善了大约$21\%$。 <div>
arXiv:2502.01807v1 Announce Type: new 
Abstract: Virtual Network Embedding (VNE) is a technique for mapping virtual networks onto a physical network infrastructure, enabling multiple virtual networks to coexist on a shared physical network. Previous works focused on implementing centralized VNE algorithms, which suffer from lack of scalability and robustness. This project aims to implement a decentralized virtual network embedding algorithm that addresses the challenges of network virtualization, such as scalability, single point of failure, and DoS attacks. The proposed approach involves selecting L leaders from the physical nodes and embedding a virtual network request (VNR) in the local network of each leader using a simple algorithm like BFS. The algorithm then uses a leader-election mechanism for determining the node with the lowest cost and highest revenue and propagates the embedding to other leaders. By utilizing decentralization, we improve the scalability and robustness of the solution. Additionally, we evaluate the effectiveness of our fully decentralized algorithm by comparing it with existing approaches. Our algorithm performs $12\%$ better in terms of acceptance rate and improves the revenue-to-cost ratio by roughly $21\%$ to compared approaches.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal Routing in the Presence of Hooks: Three Case Studies</title>
<link>https://arxiv.org/abs/2502.02059</link>
<guid>https://arxiv.org/abs/2502.02059</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv, CFMMs, hooks, 优化路由, 交易执行

总结:
本文研究了在网络中具有挂钩(hooks)的常数函数市场制造商(CFMMs)环境下，用户交易执行的优化问题。挂钩是Uniswap即将推出的新版本中引入的概念，允许流动性提供者为资金池添加额外信息并设置交易约束，使CFMM能够读取外部数据（如波动率信息）以及实现附加功能，例如链上限价订单。文章重点探讨了三种在挂钩存在下进行交易最优路由的方法：1) 通过限价订单路由；2) 最优清算和时间加权平均市场制造商(TWAMMs)；3) 非组合性挂钩，它能在承担填充风险的同时提供额外产出。利用凸优化和动态规划工具，文中提出了简单的方法来制定和解决这些问题，这些方法对实践者来说具有实用价值。 <div>
arXiv:2502.02059v1 Announce Type: new 
Abstract: We consider the problem of optimally executing a user trade over networks of constant function market makers (CFMMs) in the presence of hooks. Hooks, introduced in an upcoming version of Uniswap, are auxiliary smart contracts that allow for extra information to be added to liquidity pools. This allows liquidity providers to enable constraints on trades, allowing CFMMs to read external data, such as volatility information, and implement additional features, such as onchain limit orders. We consider three important case studies for how to optimally route trades in the presence of hooks: 1) routing through limit orders, 2) optimal liquidations and time-weighted average market makers (TWAMMs), and 3) noncomposable hooks, which provide additional output in exchange for fill risk. Leveraging tools from convex optimization and dynamic programming, we propose simple methods for formulating and solving these problems that can be useful for practitioners.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAGNNET: Multi-Agent Graph Neural Network-based Efficient Task Allocation for Autonomous Vehicles with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.02311</link>
<guid>https://arxiv.org/abs/2502.02311</guid>
<content:encoded><![CDATA[
<div> 关键词: 异构多智能体系统、通信约束、图神经网络、集中式训练分散式执行、深度强化学习<br /><br />总结:

本文针对异构多智能体系统中存在通信约束的分布式任务分配挑战，提出了一种新的融合图神经网络（GNN）与集中式训练分散式执行（CTDE）范式的框架，并结合定制化的Proximal Policy Optimization（PPO）算法进行多智能体深度强化学习（MARL）。该方法允许无人机(UAVs)和无人地面车辆(UGVs)在无需中央协调的情况下动态高效地分配任务。框架旨在最小化总旅行时间并同时避免任务分配冲突，采用基于预约的A*和R*路径规划器进行成本计算和路由规划。实验结果显示，所提方法实现了高达92.5%的无冲突成功率，与中心化的匈牙利方法相比，性能差距仅为7.49%，并且优于基于贪婪策略的启发式分散基线。此外，该框架表现出良好的可扩展性，支持多达20个智能体的任务分配处理时间仅需2.8秒，并具有应对动态生成任务的鲁棒性，显示出其在复杂多智能体场景中实际应用的巨大潜力。 <div>
arXiv:2502.02311v1 Announce Type: new 
Abstract: This paper addresses the challenge of decentralized task allocation within heterogeneous multi-agent systems operating under communication constraints. We introduce a novel framework that integrates graph neural networks (GNNs) with a centralized training and decentralized execution (CTDE) paradigm, further enhanced by a tailored Proximal Policy Optimization (PPO) algorithm for multi-agent deep reinforcement learning (MARL). Our approach enables unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to dynamically allocate tasks efficiently without necessitating central coordination in a 3D grid environment. The framework minimizes total travel time while simultaneously avoiding conflicts in task assignments. For the cost calculation and routing, we employ reservation-based A* and R* path planners. Experimental results revealed that our method achieves a high 92.5% conflict-free success rate, with only a 7.49% performance gap compared to the centralized Hungarian method, while outperforming the heuristic decentralized baseline based on greedy approach. Additionally, the framework exhibits scalability with up to 20 agents with allocation processing of 2.8 s and robustness in responding to dynamically generated tasks, underscoring its potential for real-world applications in complex multi-agent scenarios.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy by Design for Self-Sovereign Identity Systems: An in-depth Component Analysis completed by a Design Assistance Dashboard</title>
<link>https://arxiv.org/abs/2502.02520</link>
<guid>https://arxiv.org/abs/2502.02520</guid>
<content:encoded><![CDATA[
<div> 关键词: Self-Sovereign Identity (SSI)、隐私保护、设计选择、建筑层次、决策辅助仪表板

<br /><br />总结:
本文关注于Self-Sovereign Identity (SSI)系统在数字身份管理中的应用及其对个人隐私的影响。文章旨在帮助SSI解决方案设计师做出有利于隐私保护的设计选择。作者将SSI系统的构建模块划分为5个结构层，并针对每一层分析了选用不同构建块对隐私的影响。此外，文章提出了一种设计辅助仪表板，该仪表板可以全面展示SSI系统的整体情况，并清晰地显示架构选择与技术构建块之间的相互依赖关系，从而使得设计师能够做出满足隐私需求的明智决策。 <div>
arXiv:2502.02520v1 Announce Type: new 
Abstract: The use of Self-Sovereign Identity (SSI) systems for digital identity management is gaining traction and interest. Countries such as Bhutan have already implemented an SSI infrastructure to manage the identity of their citizens. The EU, thanks to the revised eIDAS regulation, is opening the door for SSI vendors to develop SSI systems for the planned EU digital identity wallet. These developments, which fall within the sovereign domain, raise questions about individual privacy.
  The purpose of this article is to help SSI solution designers make informed choices to ensure that the designed solution is privacy-friendly. The observation is that the range of possible solutions is very broad, from DID and DID resolution methods to verifiable credential types, publicly available information (e.g. in a blockchain), type of infrastructure, etc. As a result, the article proposes (1) to group the elementary building blocks of a SSI system into 5 structuring layers, (2) to analyze for each layer the privacy implications of using the chosen building block, and (3) to provide a design assistance dashboard that gives the complete picture of the SSI, and shows the interdependencies between architectural choices and technical building blocks, allowing designers to make informed choices and graphically achieve a SSI solution that meets their need for privacy.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Client Selection in Federated Learning</title>
<link>https://arxiv.org/abs/2502.00036</link>
<guid>https://arxiv.org/abs/2502.00036</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 差分隐私, 故障容忍, 客户选择框架, 性能提升

<br /><br />总结:
本文提出了一种新颖的客户端选择框架，该框架结合了差分隐私和故障容忍性，应用于联邦学习中以保护数据隐私的同时实现分布式机器学习。这个自适应客户端选择策略根据性能和系统约束动态调整参与训练的客户端数量，并通过添加噪声来保护隐私。实验在UNSW-NB15和ROAD数据集上的网络异常检测任务中表明，相较于基线方法，该方法能够提高准确性达7%，并减少训练时间约25%。同时，其增强的鲁棒性也带来了较小的性能牺牲。 <div>
arXiv:2502.00036v1 Announce Type: new 
Abstract: Federated Learning (FL) enables decentralized machine learning while preserving data privacy. This paper proposes a novel client selection framework that integrates differential privacy and fault tolerance. The adaptive client selection adjusts the number of clients based on performance and system constraints, with noise added to protect privacy. Evaluated on the UNSW-NB15 and ROAD datasets for network anomaly detection, the method improves accuracy by 7% and reduces training time by 25% compared to baselines. Fault tolerance enhances robustness with minimal performance trade-offs.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>JustAct+: Justified and Accountable Actions in Policy-Regulated, Multi-Domain Data Processing</title>
<link>https://arxiv.org/abs/2502.00138</link>
<guid>https://arxiv.org/abs/2502.00138</guid>
<content:encoded><![CDATA[
<div> 关键词：Inter-organisational数据交换、规范、GDPR、智能合约、JustAct框架

总结:
本文介绍了JustAct框架，该框架针对跨组织数据交换中由法律、协议和个体同意等多源规范所约束的问题。文章指出，现有的如智能合约、访问控制和使用控制等解决方案假设政策为公开或静态划分，这可能牺牲了问责制和灵活性。而JustAct框架则提倡去中心化的代理机构自主创建、传播并组装政策片段来证明其行为合理性，并确保即使在查看全部动态策略的不完全情况下，任何观察者也能复现权限许可过程。此外，通过外部同步的协议重新配置来集中控制，从而使得控制集中程度仅限于各代理机构期望的程度。文中详细描述了JustAct框架在一个特定的数据处理系统中的实现，并基于逻辑编程设计了一种适合的政策语言。通过对现有政策管理的跨领域医疗数据处理系统Brane的案例研究，展示了该框架的特点与优势。 <div>
arXiv:2502.00138v1 Announce Type: new 
Abstract: Inter-organisational data exchange is regulated by norms originating from sources ranging from (inter)national laws, to processing agreements, and individual consent. Verifying norm compliance is complex because laws (e.g., GDPR) distribute responsibility and require accountability. Moreover, in some application domains (e.g., healthcare), privacy requirements extend the norms (e.g., patient consent). In contrast, existing solutions such as smart contracts, access- and usage-control assume policies to be public, or otherwise, statically partition policy information at the cost of accountability and flexibility. Instead, our framework prescribes how decentralised agents justify their actions with policy fragments that the agents autonomously create, gossip, and assemble. Crucially, the permission of actions is always reproducible by any observer, even with a partial view of all the dynamic policies. Actors can be sure that future auditors will confirm their permissions. Systems centralise control by (re)configuring externally synchronised agreements, the bases of all justifications. As a result, control is centralised only to the extent desired by the agents.
  In this paper, we define the JustAct framework, detail its implementation in a particular data-processing system, and design a suitable policy language based on logic programming. A case study reproduces Brane - an existing policy-regulated, inter-domain, medical data processing system - and serves to demonstrate and assess the qualities of the framework.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study</title>
<link>https://arxiv.org/abs/2502.00182</link>
<guid>https://arxiv.org/abs/2502.00182</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 隐私保护, 联邦学习, 数据分布不均, 损失景观

总结:<br />
本文探讨了随着隐私保护意识和数据法规增强而兴起的联邦学习（FL）方法，该方法可在不共享原始数据的情况下训练分散的数据源上的机器学习模型。然而，非独立同分布（non-IID）的数据导致了FL性能下降的问题。通过对从梯度下降到FL以及从IID到non-IID数据设置的全面调查，研究发现客户端损失景观的不一致性是性能退化的主要原因。据此，现有的解决方法可以被归类为两大策略：(i) 调整参数更新路径；(ii) 修改客户端损失景观。这些发现为理解和应对FL中的非IID挑战提供了清晰视角，并可指导该领域的未来研究。 <div>
arXiv:2502.00182v1 Announce Type: new 
Abstract: As privacy concerns and data regulations grow, federated learning (FL) has emerged as a promising approach for training machine learning models across decentralized data sources without sharing raw data. However, a significant challenge in FL is that client data are often non-IID (non-independent and identically distributed), leading to reduced performance compared to centralized learning. While many methods have been proposed to address this issue, their underlying mechanisms are often viewed from different perspectives. Through a comprehensive investigation from gradient descent to FL, and from IID to non-IID data settings, we find that inconsistencies in client loss landscapes primarily cause performance degradation in non-IID scenarios. From this understanding, we observe that existing methods can be grouped into two main strategies: (i) adjusting parameter update paths and (ii) modifying client loss landscapes. These findings offer a clear perspective on addressing non-IID challenges in FL and help guide future research in the field.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2502.00201</link>
<guid>https://arxiv.org/abs/2502.00201</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度学习、金融欺诈检测、卷积神经网络、长期短期记忆、区块链集成

<br /><br />总结:
本文系统回顾了深度学习（DL）技术在金融欺诈检测领域的进展，这是一个金融领域的重要问题。通过对2019年至2024年间发表的57篇相关研究文献采用Kitchenham系统性文献回顾方法进行分析，研究表明卷积神经网络、长短期记忆网络和变压器等深度学习模型在信用卡交易、保险理赔及财务报表审计等领域具有较高的有效性。文章评估了精确率、召回率、F1分数和AUC-ROC等性能指标，并探讨了数据隐私框架的影响以及特征工程和数据预处理方面的进步。同时，文中指出了面临的挑战，如数据集不平衡、模型可解释性及伦理考量，并提出了自动化和隐私保护技术的应用机会，例如区块链集成和主成分分析。通过过去五年的发展趋势分析，该文识别出了DL应用在金融欺诈检测中的关键空白点及有前景的研究方向，为研究人员和实践者提供了可操作的见解。 <div>
arXiv:2502.00201v1 Announce Type: new 
Abstract: This paper systematically reviews advancements in deep learning (DL) techniques for financial fraud detection, a critical issue in the financial sector. Using the Kitchenham systematic literature review approach, 57 studies published between 2019 and 2024 were analyzed. The review highlights the effectiveness of various deep learning models such as Convolutional Neural Networks, Long Short-Term Memory, and transformers across domains such as credit card transactions, insurance claims, and financial statement audits. Performance metrics such as precision, recall, F1-score, and AUC-ROC were evaluated. Key themes explored include the impact of data privacy frameworks and advancements in feature engineering and data preprocessing. The study emphasizes challenges such as imbalanced datasets, model interpretability, and ethical considerations, alongside opportunities for automation and privacy-preserving techniques such as blockchain integration and Principal Component Analysis. By examining trends over the past five years, this review identifies critical gaps and promising directions for advancing DL applications in financial fraud detection, offering actionable insights for researchers and practitioners.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024)</title>
<link>https://arxiv.org/abs/2502.00627</link>
<guid>https://arxiv.org/abs/2502.00627</guid>
<content:encoded><![CDATA[
<div> 关键词: Discord, 数据集, 通信平台, 社区治理, 信息传播

总结:
本文介绍了针对Discord平台的一项重要研究成果——“ Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024)”数据集。该数据集包含了自2015年Discord成立以来至2024年底期间，来自3,167个公共服务器上的超过205亿条消息，涉及474万名用户，约占Discord公开服务器列表的10%。数据集提供了丰富的时空和主题框架，可用于分析分散式管理、社区治理、信息传播和社会动态等议题。数据收集遵循道德准则和隐私标准，采用匿名技术处理。数据以结构化的JSON文件形式组织，便于与计算社会科学方法论无缝对接。初步分析揭示了用户参与度、机器人利用以及语言多样性等方面的重要趋势，其中英语占主导地位，同时西班牙语、法语和葡萄牙语也有显著存在。此外，社交、艺术、音乐和梗图等领域成为社区的主要主题，凸显了Discord已从以游戏为中心的通讯工具扩展到多元化在线社区的现状。 <div>
arXiv:2502.00627v1 Announce Type: new 
Abstract: Discord has evolved from a gaming-focused communication tool into a versatile platform supporting diverse online communities. Despite its large user base and active public servers, academic research on Discord remains limited due to data accessibility challenges. This paper introduces Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024), the most extensive Discord public server's data to date. The dataset comprises over 2.05 billion messages from 4.74 million users across 3,167 public servers, representing approximately 10% of servers listed in Discord's Discovery feature. Spanning from Discord's launch in 2015 to the end of 2024, it offers a robust temporal and thematic framework for analyzing decentralized moderation, community governance, information dissemination, and social dynamics. Data was collected through Discord's public API, adhering to ethical guidelines and privacy standards via anonymization techniques. Organized into structured JSON files, the dataset facilitates seamless integration with computational social science methodologies. Preliminary analyses reveal significant trends in user engagement, bot utilization, and linguistic diversity, with English predominating alongside substantial representations of Spanish, French, and Portuguese. Additionally, prevalent community themes such as social, art, music, and memes highlight Discord's expansion beyond its gaming origins.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Encrypted Large Model Inference: The Equivariant Encryption Paradigm</title>
<link>https://arxiv.org/abs/2502.01013</link>
<guid>https://arxiv.org/abs/2502.01013</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模深度学习模型、隐私保护、等变加密（Equivariant Encryption, EE）、安全盲推断、性能 overhead

<br /><br />总结:
本文提出了一个新的隐私保护技术——等变加密（Equivariant Encryption, EE），针对大规模深度学习模型在分布式或去中心化环境中的部署所引发的数据隐私问题。相较于传统的安全多方计算、同态加密和差分隐私方法，EE能在几乎无性能开销的情况下实现对加密数据的安全“盲”推理。EE通过选择性地模糊神经网络层内的关键内部表示，同时保持线性和预设非线性操作的精确功能，确保原始输入、中间激活值以及输出均保留在保密状态。文章阐述了EE的理论基础，比较了其与传统隐私保护技术在性能和集成复杂度方面的表现，并展示了在包括卷积网络和大型语言模型等多种架构上的应用可行性。此外，文章还进行了全面的威胁分析和基准测试，证实EE能够在保持高精度和吞吐量的同时，有效地弥合了强数据机密性和现代大规模模型推理严格效率要求之间的鸿沟。 <div>
arXiv:2502.01013v1 Announce Type: new 
Abstract: Large scale deep learning model, such as modern language models and diffusion architectures, have revolutionized applications ranging from natural language processing to computer vision. However, their deployment in distributed or decentralized environments raises significant privacy concerns, as sensitive data may be exposed during inference. Traditional techniques like secure multi-party computation, homomorphic encryption, and differential privacy offer partial remedies but often incur substantial computational overhead, latency penalties, or limited compatibility with non-linear network operations. In this work, we introduce Equivariant Encryption (EE), a novel paradigm designed to enable secure, "blind" inference on encrypted data with near zero performance overhead. Unlike fully homomorphic approaches that encrypt the entire computational graph, EE selectively obfuscates critical internal representations within neural network layers while preserving the exact functionality of both linear and a prescribed set of non-linear operations. This targeted encryption ensures that raw inputs, intermediate activations, and outputs remain confidential, even when processed on untrusted infrastructure. We detail the theoretical foundations of EE, compare its performance and integration complexity against conventional privacy preserving techniques, and demonstrate its applicability across a range of architectures, from convolutional networks to large language models. Furthermore, our work provides a comprehensive threat analysis, outlining potential attack vectors and baseline strategies, and benchmarks EE against standard inference pipelines in decentralized settings. The results confirm that EE maintains high fidelity and throughput, effectively bridging the gap between robust data confidentiality and the stringent efficiency requirements of modern, large scale model inference.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tackling Feature and Sample Heterogeneity in Decentralized Multi-Task Learning: A Sheaf-Theoretic Approach</title>
<link>https://arxiv.org/abs/2502.01145</link>
<guid>https://arxiv.org/abs/2502.01145</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated multi-task learning (FMTL), decentralized setting, cellular sheaves, Sheaf-FMTL算法, communication savings

总结:<br />
本文提出了一种基于sheaf理论的新型联邦多任务学习（FMTL）方法，旨在解决在分布式环境中复杂任务关系建模和处理客户端特征及样本异质性的问题。通过使用细胞sheaf表示客户端间的关系，该框架能够灵活地模拟不同客户端模型间的交互。文章将基于sheaf的FMTL优化问题形式化为sheaf拉普拉斯正则化，并提出了求解该问题的Sheaf-FMTL算法。进一步地，证明Sheaf-FMTL算法具有与最先进的分布式FMTL算法相媲美的亚线性收敛率。实验表明，Sheaf-FMTL相较于分布式FMTL基线方法能实现显著的通信开销节省，发送更少的比特数。 <div>
arXiv:2502.01145v1 Announce Type: new 
Abstract: Federated multi-task learning (FMTL) aims to simultaneously learn multiple related tasks across clients without sharing sensitive raw data. However, in the decentralized setting, existing FMTL frameworks are limited in their ability to capture complex task relationships and handle feature and sample heterogeneity across clients. To address these challenges, we introduce a novel sheaf-theoretic-based approach for FMTL. By representing client relationships using cellular sheaves, our framework can flexibly model interactions between heterogeneous client models. We formulate the sheaf-based FMTL optimization problem using sheaf Laplacian regularization and propose the Sheaf-FMTL algorithm to solve it. We show that the proposed framework provides a unified view encompassing many existing federated learning (FL) and FMTL approaches. Furthermore, we prove that our proposed algorithm, Sheaf-FMTL, achieves a sublinear convergence rate in line with state-of-the-art decentralized FMTL algorithms. Extensive experiments demonstrate that Sheaf-FMTL exhibits communication savings by sending significantly fewer bits compared to decentralized FMTL baselines.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Neural Cellular Automata for Decentralized Sensing using a Soft Inductive Sensor Array for Distributed Manipulator Systems</title>
<link>https://arxiv.org/abs/2502.01242</link>
<guid>https://arxiv.org/abs/2502.01242</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Manipulator Systems (分布式操纵系统)、Decentralized Sensing (去中心化传感)、Neural Cellular Automata (神经细胞自动机)、Inductive Sensor Board (感应传感器板)、Fault-Tolerance (容错性)

<br />
总结:
本文介绍了针对分布式操纵系统的新型去中心化传感方法，该方法使用神经细胞自动机(NCA)。与当前通常依赖中央化的单摄像头计算机视觉系统的DMS不同，提出的感应传感器板设计用于分布式传感并评估其通过局部交互和计算估计全局对象属性（如几何中心）的能力。实验表明，基于NCA的传感网络能以0.24倍的传感器间距离准确估计物体位置，并在传感器故障和噪声情况下保持鲁棒性，同时能无缝扩展到不同的网络规模。这些发现强调了本地化、去中心化计算在实现DMS中可伸缩、容错和抗噪的对象属性估计方面的潜力。 <div>
arXiv:2502.01242v1 Announce Type: new 
Abstract: In Distributed Manipulator Systems (DMS), decentralization is a highly desirable property as it promotes robustness and facilitates scalability by distributing computational burden and eliminating singular points of failure. However, current DMS typically utilize a centralized approach to sensing, such as single-camera computer vision systems. This centralization poses a risk to system reliability and offers a significant limiting factor to system size. In this work, we introduce a decentralized approach for sensing and in a Distributed Manipulator Systems using Neural Cellular Automata (NCA). Demonstrating a decentralized sensing in a hardware implementation, we present a novel inductive sensor board designed for distributed sensing and evaluate its ability to estimate global object properties, such as the geometric center, through local interactions and computations. Experiments demonstrate that NCA-based sensing networks accurately estimate object position at 0.24 times the inter sensor distance. They maintain resilience under sensor faults and noise, and scale seamlessly across varying network sizes. These findings underscore the potential of local, decentralized computations to enable scalable, fault-tolerant, and noise-resilient object property estimation in DMS
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Discriminative Naive Bayes Classifier</title>
<link>https://arxiv.org/abs/2502.01532</link>
<guid>https://arxiv.org/abs/2502.01532</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Naive Bayes、分类、数据隐私、实验验证

<br />
总结:
本文提出了一种针对离散变量的新型联邦学习方法，用于朴素贝叶斯(Naive Bayes, NB)分类。该方法将一种判别式的NB变体进行联邦化处理，只共享无意义的参数而非条件概率表，从而增强了对可能攻击的防御能力。通过在12个数据集上进行大量实验，与非联邦设置和生成式NB基线进行了比较，实验结果证实了所提方法在实现高精度分类方面的有效性。这一研究为保护数据隐私的同时进行分布式机器学习模型训练提供了新的解决方案。 <div>
arXiv:2502.01532v1 Announce Type: new 
Abstract: Federated Learning has emerged as a promising approach to train machine learning models on decentralized data sources while preserving data privacy. This paper proposes a new federated approach for Naive Bayes (NB) classification, assuming discrete variables. Our approach federates a discriminative variant of NB, sharing meaningless parameters instead of conditional probability tables. Therefore, this process is more reliable against possible attacks. We conduct extensive experiments on 12 datasets to validate the efficacy of our approach, comparing federated and non-federated settings. Additionally, we benchmark our method against the generative variant of NB, which serves as a baseline for comparison. Our experimental results demonstrate the effectiveness of our method in achieving accurate classification.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedGES: A Federated Learning Approach for BN Structure Learning</title>
<link>https://arxiv.org/abs/2502.01538</link>
<guid>https://arxiv.org/abs/2502.01538</guid>
<content:encoded><![CDATA[
<div> 关键词：贝叶斯网络、联邦学习、贪婪等价搜索、结构融合、隐私保护

总结:
本文提出了一种名为FedGES的新颖联邦学习方法，用于在分布式环境中进行贝叶斯网络（BN）结构学习。FedGES针对传统BN结构学习中的数据集中问题，创新性地仅交换不断演进的网络结构而非参数或数据，从而有效解决了隐私和安全挑战。该方法实现了协作模型开发，通过结构性融合将各客户端在迭代过程中生成的有限模型结合在一起。此外，为了增强客户端的一致性，文中还提出了控制性的结构融合策略。实验结果表明，FedGES在高维度（大量变量）和稀疏数据场景中表现优异，为现实世界的BN结构学习提供了一个实用且能保护隐私的解决方案。<br /><br /> <div>
arXiv:2502.01538v1 Announce Type: new 
Abstract: Bayesian Network (BN) structure learning traditionally centralizes data, raising privacy concerns when data is distributed across multiple entities. This research introduces Federated GES (FedGES), a novel Federated Learning approach tailored for BN structure learning in decentralized settings using the Greedy Equivalence Search (GES) algorithm. FedGES uniquely addresses privacy and security challenges by exchanging only evolving network structures, not parameters or data. It realizes collaborative model development, using structural fusion to combine the limited models generated by each client in successive iterations. A controlled structural fusion is also proposed to enhance client consensus when adding any edge. Experimental results on various BNs from {\sf bnlearn}'s BN Repository validate the effectiveness of FedGES, particularly in high-dimensional (a large number of variables) and sparse data scenarios, offering a practical and privacy-preserving solution for real-world BN structure learning.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Inference for Distributed Geospatial Data Using Low-Rank Models</title>
<link>https://arxiv.org/abs/2502.00309</link>
<guid>https://arxiv.org/abs/2502.00309</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模空间数据、去中心化框架、参数推断、低秩模型、证据下界

<br /><br />总结:
本文提出了一种针对大规模空间数据的去中心化参数推断框架，旨在解决集中式框架中的单点故障和通信瓶颈问题。该框架特别适用于空间低秩模型，针对观测值间的空间相关性带来的挑战，文章创新地提出了利用证据下界的新型目标函数，使之适应于分布式优化方法。文中采用块下降法结合多共识与动态一致性平均策略进行有效参数优化，并证明了新目标函数在真实参数附近的凸性，确保了所提方法的收敛性。此外，文章还首次从理论上确立了在空间低秩模型背景下估计器的一致性和渐近正态性。通过大量的模拟实验和真实数据实验证明了该框架的稳健性和可扩展性。 <div>
arXiv:2502.00309v1 Announce Type: cross 
Abstract: Advancements in information technology have enabled the creation of massive spatial datasets, driving the need for scalable and efficient computational methodologies. While offering viable solutions, centralized frameworks are limited by vulnerabilities such as single-point failures and communication bottlenecks. This paper presents a decentralized framework tailored for parameter inference in spatial low-rank models to address these challenges. A key obstacle arises from the spatial dependence among observations, which prevents the log-likelihood from being expressed as a summation-a critical requirement for decentralized optimization approaches. To overcome this challenge, we propose a novel objective function leveraging the evidence lower bound, which facilitates the use of decentralized optimization techniques. Our approach employs a block descent method integrated with multi-consensus and dynamic consensus averaging for effective parameter optimization. We prove the convexity of the new objective function in the vicinity of the true parameters, ensuring the convergence of the proposed method. Additionally, we present the first theoretical results establishing the consistency and asymptotic normality of the estimator within the context of spatial low-rank models. Extensive simulations and real-world data experiments corroborate these theoretical findings, showcasing the robustness and scalability of the framework.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean-Field Games With Finitely Many Players: Independent Learning and Subjectivity</title>
<link>https://arxiv.org/abs/2209.05703</link>
<guid>https://arxiv.org/abs/2209.05703</guid>
<content:encoded><![CDATA[
<div> 关键词：独立学习者、均值场游戏、部分观察、马尔科夫决策过程、主观Q均衡

总结:
本文研究了从分散学习角度出发的部分观察均值场游戏，重点关注算法设计指导结构和独立学习者系统中涌现行为的理解。文章提出了一种新的有限玩家、局部动作可观测以及对全局状态进行一般性部分观测的均值场游戏模型。研究了包括全局可观测、局部及均值场可观测、局部及压缩均值场可观测以及仅局部可观测在内的多种观测通道。文章建立了单一代理人控制问题等价于完全观测马尔科夫决策过程（MDP）以及仅等价于部分观测马尔科夫决策过程（POMDP）的条件。基于与MDP的联系，证明在均值场可观测下，记忆无关的静态策略存在完美平衡。利用与POMDP的关联，证明了在上述任何观测通道下的独立学习代理人的学习迭代过程收敛。将极限值解释为主观价值函数，这些函数被用于定义部分观察n玩家均值场游戏的新解概念——主观Q均衡，并在均值场或全局可观测性条件下证明其存在性。此外，文章还提出了针对部分观察n玩家均值场游戏的分布式学习算法，并展示该算法可通过适应近期发展的满意路径理论引导游戏向主观Q均衡收敛。 <div>
arXiv:2209.05703v4 Announce Type: replace 
Abstract: Independent learners are agents that employ single-agent algorithms in multi-agent systems, intentionally ignoring the effect of other strategic agents. This paper studies mean-field games from a decentralized learning perspective, with two primary objectives: (i) to identify structure that can guide algorithm design, and (ii) to understand the emergent behaviour in systems of independent learners. We study a new model of partially observed mean-field games with finitely many players, local action observability, and a general observation channel for partial observations of the global state. Specific observation channels considered include (a) global observability, (b) local and mean-field observability, (c) local and compressed mean-field observability, and (d) only local observability. We establish conditions under which the control problem of a given agent is equivalent to a fully observed MDP, as well as conditions under which the control problem is equivalent only to a POMDP. Building on the connection to MDPs, we prove the existence of perfect equilibrium among memoryless stationary policies under mean-field observability. Leveraging the connection to POMDPs, we prove convergence of learning iterates obtained by independent learning agents under any of the aforementioned observation channels. We interpret the limiting values as subjective value functions, which an agent believes to be relevant to its control problem. These subjective value functions are then used to propose subjective Q-equilibrium, a new solution concept for partially observed n-player mean-field games, whose existence is proved under mean-field or global observability. We provide a decentralized learning algorithm for partially observed n-player mean-field games, and we show that it drives play to subjective Q-equilibrium by adapting the recently developed theory of satisficing paths to allow for subjectivity.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>It Takes Two: A Peer-Prediction Solution for Blockchain Verifier's Dilemma</title>
<link>https://arxiv.org/abs/2406.01794</link>
<guid>https://arxiv.org/abs/2406.01794</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链安全、共识机制、验证者困境、拜占庭容错、诚实激励<br /><br />总结:
本文针对区块链系统的安全性及其依赖的去中心化共识进行了研究，提出了一个解决“验证者困境”的新框架。该框架是一个基于拜占庭容错的一阶段贝叶斯真实性的多验证者激励机制，旨在无须访问真相的情况下，鼓励所有验证者进行诚实验证，即便在验证过程中存在噪声观测。此外，该机制还优化了对合谋和其他恶意行为的抗攻击性，并展示了其对于不准确先验和信念的鲁棒性。通过理论上保证的稳健激励属性，这项研究为增强区块链及其他分布式系统安全性和韧性的去中心化验证协议设计提供了一个框架。 <div>
arXiv:2406.01794v3 Announce Type: replace 
Abstract: The security of blockchain systems is fundamentally based on the decentralized consensus in which the majority of parties behave honestly, and the content verification process is essential to maintaining the robustness of blockchain systems. However, the phenomenon that a secure blockchain system with few or no cheaters could not provide sufficient incentive for (rational) verifiers to honestly perform the costly verification, referred to as the Verifier's Dilemma, could incentivize lazy reporting and undermine the fundamental security of blockchain systems. While existing works have attempted to insert deliberate errors to disincentivize lazy verification, the decentralized environment renders it impossible to judge the correctness of verification or detect malicious verifiers directly without additional layers of procedures, e.g., reputation systems or additional committee voting.
  In this paper, we initiate the research with the development of a Byzantine-robust peer prediction framework towards the design of one-phase Bayesian truthful mechanisms for the decentralized verification games among multiple verifiers, incentivizing all verifiers to perform honest verification without access to the ground truth even in the presence of noisy observations in the verification process. Furthermore, we optimize our mechanism to realize provable robustness against collusions and other malicious behavior from the verifiers, and also show its resilience to inaccurate priors and beliefs. With the theoretically guaranteed robust incentive properties of our mechanism, our study provides a framework of incentive design for decentralized verification protocols that enhances the security and robustness of the blockchain and potentially other decentralized systems.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Global Public Sentiment on Decentralized Finance: A Spatiotemporal Analysis of Geo-tagged Tweets from 150 Countries</title>
<link>https://arxiv.org/abs/2409.00843</link>
<guid>https://arxiv.org/abs/2409.00843</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、去中心化金融(DeFi)、全球情绪分布、情感分析、地理加权回归分析

<br /><br />总结:
本文研究了自2012年至2022年间源自7.4亿条推文中超过1.5亿条与DeFi相关的地理标记推文，通过BERT基多语种分类模型进行情感分析。研究将这些推文数据与经济和地缘政治数据相结合，构建了一个多模态数据集。使用情感分析、空间计量经济学、聚类和主题建模等方法，揭示了全球范围内DeFi参与度和情感表达的显著差异。研究发现，自2015年后，经济发展水平对DeFi参与度具有显著影响，尤其是人均GDP成为预测DeFi相关推文比例的关键因素。富裕国家在DeFi讨论中更为活跃，而低收入国家更多地从金融安全和暴富的角度谈论DeFi；相比之下，中等收入国家将其与社会和宗教议题关联，高收入国家则主要视其为投机工具或娱乐形式。这项研究推进了计算社会科学和金融领域的交叉学科研究，并通过在GitHub上提供数据集和代码以及在KNIME平台上提供非代码工作流程，支持开放科学，从而助力学者、政策制定者、监管机构和开发者在全球范围内探索DeFi采纳与情感动态，推动实现更广泛的金融包容性和负责任的DeFi参与。 <div>
arXiv:2409.00843v2 Announce Type: replace-cross 
Abstract: Blockchain technology and decentralized finance (DeFi) are reshaping global financial systems. Despite their impact, the spatial distribution of public sentiment and its economic and geopolitical determinants are often overlooked. This study analyzes over 150 million geo-tagged, DeFi-related tweets from 2012 to 2022, sourced from a larger dataset of 7.4 billion tweets. Using sentiment scores from a BERT-based multilingual classification model, we integrated these tweets with economic and geopolitical data to create a multimodal dataset. Employing techniques like sentiment analysis, spatial econometrics, clustering, and topic modeling, we uncovered significant global variations in DeFi engagement and sentiment. Our findings indicate that economic development significantly influences DeFi engagement, particularly after 2015. Geographically weighted regression analysis revealed GDP per capita as a key predictor of DeFi tweet proportions, with its impact growing following major increases in cryptocurrency values such as bitcoin. While wealthier nations are more actively engaged in DeFi discourse, the lowest-income countries often discuss DeFi in terms of financial security and sudden wealth. Conversely, middle-income countries relate DeFi to social and religious themes, whereas high-income countries view it mainly as a speculative instrument or entertainment. This research advances interdisciplinary studies in computational social science and finance and supports open science by making our dataset and code available on GitHub, and providing a non-code workflow on the KNIME platform. These contributions enable a broad range of scholars to explore DeFi adoption and sentiment, aiding policymakers, regulators, and developers in promoting financial inclusion and responsible DeFi engagement globally.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quest Love: Do Blockchain Points Build Loyalty or Just Feed the Bots?</title>
<link>https://arxiv.org/abs/2501.18810</link>
<guid>https://arxiv.org/abs/2501.18810</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链生态系统、用户任务、奖励机制、自动化脚本、数据分析

总结:<br />
本文研究了区块链生态系统中用户任务（quest）的设计与影响因素，分析了一项为期10个月、完成次数达8000万次的任务系统数据。研究发现，任务完成率受奖励量、奖励货币价值、难度和成本等因素的影响。此外，文中还讨论了 farming 和机器人脚本在其中的作用，以及区分真实用户与自动化脚本所面临的复杂性问题。 <div>
arXiv:2501.18810v1 Announce Type: new 
Abstract: Blockchain ecosystems -- such as those built around chains, layers, and services -- try to engage users for a variety of reasons: user education, growing and protecting their market share, climbing metric-measuring leaderboards with competing systems, demonstrating usage to investors, and identifying worthy recipients for newly created tokens (airdrops). A popular approach is offering user quests: small tasks that can be completed by a user, exposing them to a common task they might want to do in the future, and rewarding them for completion. In this paper, we capture blockchain data from one deployed quest system that offered 43 unique quests over 10 months with 80M completions. We use this data to offer insight about the factors that impact task completion: amount of reward, monetary value of reward, difficulty, and cost. We also discuss the role of farming and bots, and the factors that complicate distinguishing real users from automated scripts.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Bias-Correction Decentralized Stochastic Gradient Algorithm with Momentum Acceleration</title>
<link>https://arxiv.org/abs/2501.19082</link>
<guid>https://arxiv.org/abs/2501.19082</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式随机优化算法、数据异质性、动量加速、Exact-Diffusion with Momentum (EDM)、收敛性

<br /><br />总结:
本文提出了一种名为Exact-Diffusion with Momentum (EDM)的分布式随机梯度算法，该算法通过引入动量方法可以纠正数据异质性导致的偏差并加速算法收敛。理论分析表明，在非凸目标函数情况下，EDM算法能以与数据异质性无关的亚线性速度收敛到最优解的邻域；而在满足Polyak-{\L}ojasiewicz条件（比$\mu$-强凸性假设更弱）的情况下，则可实现线性收敛。最后，通过对一系列现有去中心化优化算法进行仿真对比评估，验证了所提算法在应对数据异质性和网络稀疏性问题上的有效性。 <div>
arXiv:2501.19082v1 Announce Type: new 
Abstract: Distributed stochastic optimization algorithms can handle large-scale data simultaneously and accelerate model training. However, the sparsity of distributed networks and the heterogeneity of data limit these advantages. This paper proposes a momentum-accelerated distributed stochastic gradient algorithm, referred to as Exact-Diffusion with Momentum (EDM), which can correct the bias caused by data heterogeneity and introduces the momentum method commonly used in deep learning to accelerate the convergence of the algorithm. We theoretically demonstrate that this algorithm converges to the neighborhood of the optimum sub-linearly irrelevant to data heterogeneity when applied to non-convex objective functions and linearly under the Polyak-{\L}ojasiewicz condition (a weaker assumption than $\mu$-strongly convexity). Finally, we evaluate the performance of the proposed algorithm by simulation, comparing it with a range of existing decentralized optimization algorithms to demonstrate its effectiveness in addressing data heterogeneity and network sparsity.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics</title>
<link>https://arxiv.org/abs/2501.19239</link>
<guid>https://arxiv.org/abs/2501.19239</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式多智能体、多臂赌博机、重尾分布、稀疏随机图、同步通信

总结:
本文研究了在完全重尾分布环境下，多个智能体通过稀疏随机图进行通信并观察到重尾（同质或异质）奖励分布的分布式多智能体多臂赌博机问题。研究目标是在所有智能体中找到具有最高全局奖励均值的最佳臂。文章首次探讨此类完全重尾场景，揭示了现实世界系统中多客户端间通信和推断的动态及挑战。在同质性设置下，算法利用重尾图的独特中心结构，通过中心估计器聚合奖励信息以降低UCB指数构建过程中的噪声；当有M个智能体且度分布幂律指数$\alpha > 1$时，算法实现了接近于$O(M^{1 -\frac{1}{\alpha}} \log{T})$的遗憾界。在异质性奖励情况下，智能体通过与邻居通信同步，并将交换得到的估计器聚合到UCB指数中；基于新建立的稀疏随机图上的信息延迟界限，证明了$O(M \log{T})$的遗憾界。这些结果优于现有仅针对静态连通图或密集图及轻尾动态的研究工作。 <div>
arXiv:2501.19239v1 Announce Type: new 
Abstract: We study decentralized multi-agent multi-armed bandits in fully heavy-tailed settings, where clients communicate over sparse random graphs with heavy-tailed degree distributions and observe heavy-tailed (homogeneous or heterogeneous) reward distributions with potentially infinite variance. The objective is to maximize system performance by pulling the globally optimal arm with the highest global reward mean across all clients. We are the first to address such fully heavy-tailed scenarios, which capture the dynamics and challenges in communication and inference among multiple clients in real-world systems. In homogeneous settings, our algorithmic framework exploits hub-like structures unique to heavy-tailed graphs, allowing clients to aggregate rewards and reduce noises via hub estimators when constructing UCB indices; under $M$ clients and degree distributions with power-law index $\alpha > 1$, our algorithm attains a regret bound (almost) of order $O(M^{1 -\frac{1}{\alpha}} \log{T})$. Under heterogeneous rewards, clients synchronize by communicating with neighbors, aggregating exchanged estimators in UCB indices; With our newly established information delay bounds on sparse random graphs, we prove a regret bound of $O(M \log{T})$. Our results improve upon existing work, which only address time-invariant connected graphs, or light-tailed dynamics in dense graphs and rewards.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>S-VOTE: Similarity-based Voting for Client Selection in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.19279</link>
<guid>https://arxiv.org/abs/2501.19279</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning (DFL)，S-VOTE，client selection，non-IID数据分布，通信成本，资源使用优化，模型性能，参与不平衡，局部训练，更快收敛，能源消耗减少。

<br /><br />总结:
本文提出了S-VOTE，一种针对非IID数据分布环境下的去中心化联邦学习（DFL）中的投票基客户端选择机制。S-VOTE旨在优化资源使用并提升模型性能，它采用自适应策略解决参与不平衡问题，允许未充分利用的客户端在不显著增加资源成本的情况下做出贡献。实验结果显示，与基线方法相比，S-VOTE能够降低最多21%的通信成本，加快4-6%的收敛速度，并在某些配置下改善本地性能高达9-17%，同时实现了14-24%的能源消耗降低。这些成果表明S-VOTE在应对异构环境中的DFL挑战方面具有潜力。 <div>
arXiv:2501.19279v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) enables collaborative, privacy-preserving model training without relying on a central server. This decentralized approach reduces bottlenecks and eliminates single points of failure, enhancing scalability and resilience. However, DFL also introduces challenges such as suboptimal models with non-IID data distributions, increased communication overhead, and resource usage. Thus, this work proposes S-VOTE, a voting-based client selection mechanism that optimizes resource usage and enhances model performance in federations with non-IID data conditions. S-VOTE considers an adaptive strategy for spontaneous local training that addresses participation imbalance, allowing underutilized clients to contribute without significantly increasing resource costs. Extensive experiments on benchmark datasets demonstrate the S-VOTE effectiveness. More in detail, it achieves lower communication costs by up to 21%, 4-6% faster convergence, and improves local performance by 9-17% compared to baseline methods in some configurations, all while achieving a 14-24% energy consumption reduction. These results highlight the potential of S-VOTE to address DFL challenges in heterogeneous environments.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Noninterference Analysis of Irreversible or Reversible Systems with Nondeterminism and Probabilities</title>
<link>https://arxiv.org/abs/2501.19290</link>
<guid>https://arxiv.org/abs/2501.19290</guid>
<content:encoded><![CDATA[
<div> 关键词: 非交互理论、概率性、不可逆系统、可逆系统、弱有向相似性、分支有向相似性、智能合约

总结:
本文探讨了非交互理论在多级安全系统中分析安全计算的应用。针对带有概率和非确定性的环境，文章分别对不可逆系统和可逆系统进行了研究。对于不可逆系统，该文扩展了Aldini等人在生成-反应型概率设定中的结果，采用概率弱有向相似性来重新阐述非交互属性；而对于可逆系统，则是在纯非确定性环境基础上，结合Esposito等人成果，引入概率分支有向相似性进行研究。文章还讨论了这些属性的分类、保持性和组合性方面，以及与非确定性情况的比较。通过一个概率性智能合约的例子，展示了扩展后的非交互理论的适用性。<br /><br /> <div>
arXiv:2501.19290v1 Announce Type: new 
Abstract: Noninterference theory supports the analysis of secure computations in multi-level security systems. Classical equivalence-based approaches to noninterference mainly rely on bisimilarity. In a nondeterministic setting, assessing noninterference through weak bisimilarity is adequate for irreversible systems, whereas for reversible ones branching bisimilarity has been recently proven to be more appropriate. In this paper we address the same two families of systems, with the difference that probabilities come into play in addition to nondeterminism. For irreversible systems we extend the results of Aldini, Bravetti, and Gorrieri developed in a generative-reactive probabilistic setting, while for reversible systems we extend the results of Esposito, Aldini, Bernardo, and Rossi developed in a purely nondeterministic setting. We recast noninterference properties by adopting probabilistic variants of weak and branching bisimilarities for irreversible and reversible systems respectively. Then we investigate a taxonomy of those properties as well as their preservation and compositionality aspects, along with a comparison with the nondeterministic taxonomy. The adequacy of the extended noninterference theory is illustrated via a probabilistic smart contract example.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SeDe: Balancing Blockchain Privacy and Regulatory Compliance by Selective De-Anonymization</title>
<link>https://arxiv.org/abs/2311.08167</link>
<guid>https://arxiv.org/abs/2311.08167</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、区块链、匿名性、合规框架、Selective De-Anonymization (SeDe)、阈值加密、零知识证明

<br />
总结：
本文提出了一个旨在平衡区块链隐私保护与监管合规性的框架——Selective De-Anonymization (SeDe)。该框架允许基于区块链的隐私保护应用通过递归遍历关联交易的子图来识别非法交易。SeDe实现这一目标的同时，避免将去匿名化决策或控制权交给单个实体，而是将其分散到多个实体之间并确保它们对各自行为负责。为了实现这一框架，文中采用了阈值加密方案和零知识证明技术。 <div>
arXiv:2311.08167v5 Announce Type: replace 
Abstract: Privacy is one of the essential pillars for the widespread adoption of blockchains, but public blockchains are transparent by nature. Modern analytics techniques can easily subdue the pseudonymity feature of a blockchain user. Some applications have been able to provide practical privacy protections using privacy-preserving cryptography techniques. However, malicious actors have abused them illicitly, discouraging honest actors from using privacy-preserving applications as "mixing" user interactions and funds with anonymous bad actors, causing compliance and regulatory concerns.
  In this paper, we propose a framework that balances privacy-preserving features by establishing a regulatory and compliant framework called Selective De-Anonymization (SeDe). The adoption of this framework allows privacy-preserving applications on blockchains to de-anonymize illicit transactions by recursive traversal of subgraphs of linked transactions. Our technique achieves this without leaving de-anonymization decisions or control in the hands of a single entity but distributing it among multiple entities while holding them accountable for their respective actions. To instantiate, our framework uses threshold encryption schemes and Zero-Knowledge Proofs (ZKPs).
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Blockchain technology within an Information Ecosystem</title>
<link>https://arxiv.org/abs/2402.13191</link>
<guid>https://arxiv.org/abs/2402.13191</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-based Information Ecosystems (BBIEs), 信任机制, 分布式数据管理, 商业逻辑分解, 葡萄酒供应链管理

<br /><br />总结:
本文提出了基于区块链的信息生态系统（BBIEs）的架构和技术细节，该系统利用区块链技术在各方之间提供信任机制并管理共享业务逻辑，打破了传统信息生态系统中由单一主导公司控制的局面。研究需求源于对协作商业环境的当前需求以及对从业者进行调查所收集的数据。通过实证案例——涉及多个企业和监管机构的葡萄酒供应链管理，验证了该架构方案的合理性。提出的解决方案将基于区块链的应用与现有信息系统整合为生态系统的模块，从而实现低成本、可扩展性和高级别的安全性。结论指出，尽管我们仍需深入探究和细化技术在支持创新型多组织商业模式中的可能性，但BBIEs在这方面具有显著的推动作用。 <div>
arXiv:2402.13191v2 Announce Type: replace 
Abstract: Context: Blockchain-based Information Ecosystems (BBIEs) are a type of information ecosystem in which blockchain technology is used to provide a trust mechanism among parties and to manage shared business logic, breaking the traditional scheme of Information Ecosystems dominated by a leading company and leveraging the decentralization of data management, information flow, and business logic. Objective: In this paper, we propose architecture and technical aspects concerning the creation of a BBIE, underlining the advantages supplied and the logic decomposition among the business and storage components. Method: The requirements are derived from the current needs of the collaborative business and the data collected by surveying practitioners. To get these needs we followed the Grounded Theory research approach. We validate our architectural schema against a case study dealing with the management of a wine supply chain, also involving different companies and supervision authorities. Results: The proposed solution integrates blockchain-based applications with the existing information system as a module of the ecosystem, leveraging on the low costs, scalability, and high-level security because of the restricted access to the network. Conclusion: We must go a long way in deepening and refining the possibilities offered by technology in supporting innovative multi-organizational business models. BBIEs can contribute substantially to paving the way in such a direction.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Case Study in Acceleration AI Ethics: The TELUS GenAI Conversational Agent</title>
<link>https://arxiv.org/abs/2501.18038</link>
<guid>https://arxiv.org/abs/2501.18038</guid>
<content:encoded><![CDATA[
<div> 关键词：加速伦理、人工智能、创新、安全、TELUS

总结:
<br />
本文探讨了加速伦理这一概念，它关注人工智能领域的创新与安全之间的紧张关系。文章明确了加速伦理理论框架，包括五个要素：创新能解决创新带来的问题、创新具有内在价值、未知驱动进步、治理去中心化以及道德内嵌。随后以加拿大电信公司TELUS开发的生成式人工智能语言工具为例，说明了加速伦理框架如何通过持续创新来最大限度地实现社会责任，而不是在创新和社会责任之间进行取舍。通过此案例，可以看出加速AI伦理是一种兼顾并最大化社会利益和创新发展的方法。 <div>
arXiv:2501.18038v1 Announce Type: new 
Abstract: Acceleration ethics addresses the tension between innovation and safety in artificial intelligence. The acceleration argument is that the most effective way to approach risks raised by innovation is with still more innovating. This paper begins by defining acceleration ethics theoretically. It is composed of five elements: innovation solves innovation problems, innovation is intrinsically valuable, the unknown is encouraging, governance is decentralized, ethics is embedded. Subsequently, the paper illustrates the acceleration framework with a use-case, a generative artificial intelligence language tool developed by the Canadian telecommunications company TELUS. While the purity of theoretical positions is blurred by real-world ambiguities, the TELUS experience indicates that acceleration AI ethics is a way of maximizing social responsibility through innovation, as opposed to sacrificing social responsibility for innovation, or sacrificing innovation for social responsibility.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Measuring Blockchain Decentralization</title>
<link>https://arxiv.org/abs/2501.18279</link>
<guid>https://arxiv.org/abs/2501.18279</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化、测量方法、共识层、参与度

总结:<br />
本文针对区块链系统中去中心化衡量方法缺乏广泛接受的标准这一问题，开展了一项系统化研究工作。文章提出了一种框架，根据所测量的目标资源、数据提取方法以及生成最终测量值所使用的函数对现有测量技术进行分类。通过对前期工作的实证分析，作者发现数据提取阶段的一些看似不重要的选择（如估计窗口大小或应用阈值）会对去中心化程度的计算产生重大影响。此外，探索性因素分析表明，在基于工作量证明(PoW)的区块链中，共识层上的参与度与去中心化并不相关，而在基于权益证明(PoS)的系统中，不同指标则归结为单一因素，这挑战了区块链社区长期以来关于参与度越高去中心化程度越高的假设。最后，结合实证分析和原理性推理，文章为研究人员提供了实用建议，以指导他们进行区块链去中心化的测量，并进一步依据这些建议系统化整理了现有文献。 <div>
arXiv:2501.18279v1 Announce Type: new 
Abstract: In the context of blockchain systems, the importance of decentralization is undermined by the lack of a widely accepted methodology to measure it. To address this gap, we set out a systematization effort targeting the decentralization measurement workflow. To facilitate our systematization, we put forth a framework that categorizes all measurement techniques used in previous work based on the resource they target, the methods they use to extract resource allocation, and the functions they apply to produce the final measurements. We complement this framework with an empirical analysis designed to evaluate whether the various pre-processing steps and metrics used in prior work capture the same underlying concept of decentralization. Our analysis brings about a number of novel insights and observations. First, the seemingly innocuous choices performed during data extraction, such as the size of estimation windows or the application of thresholds that affect the resource distribution, have important repercussions when calculating the level of decentralization. Second, exploratory factor analysis suggests that in Proof-of-Work (PoW) blockchains, participation on the consensus layer is not correlated with decentralization, but rather captures a distinct signal, unlike in Proof-of-Stake (PoS) systems, where the different metrics align under a single factor. These findings challenge the long-held assumption within the blockchain community that higher participation drives higher decentralization. Finally, we combine the results of our empirical analysis with first-principles reasoning to derive practical recommendations for researchers that set out to measure blockchain decentralization, and we further systematize the existing literature in line with these recommendations.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DCatalyst: A Unified Accelerated Framework for Decentralized Optimization</title>
<link>https://arxiv.org/abs/2501.18114</link>
<guid>https://arxiv.org/abs/2501.18114</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized optimization、network、agents、Nesterov acceleration、DCatalyst

总结:
我们研究了在网络无中心服务器情况下的分布式优化问题，该网络由图模型表示，目标是最小化$f+r$，其中$f$代表的是各局部代理损失的平均（强）凸函数，而$r$是一个凸的、扩展值函数。为此，我们提出了DCatalyst，一个将Nesterov加速集成到分布式优化算法中的统一黑盒框架。DCatalyst作为一个内在具有不精确性和动量加速特性的近似亲和方法（构成外层循环），能够无缝嵌入任何选定的分布式算法（作为内层循环）。我们证明了无论选择哪种分布式算法或问题实例，DCatalyst都能实现最优的通信和计算复杂度（至多对数因子）。尤其值得一提的是，它将加速能力扩展到了以前缺乏加速解法的问题类别，从而拓宽了分布式方法的有效性。从技术角度来说，我们的框架引入了“不精确估计序列”——这是对Nesterov估计算序的一个新颖扩展，特别针对分布式环境中复合损失的最小化，巧妙地处理了共识误差和代理人子问题的不精确解决方案，这是现有模型尚未解决的挑战。 <div>
arXiv:2501.18114v1 Announce Type: cross 
Abstract: We study decentralized optimization over a network of agents, modeled as graphs, with no central server. The goal is to minimize $f+r$, where $f$ represents a (strongly) convex function averaging the local agents' losses, and $r$ is a convex, extended-value function.
  We introduce DCatalyst, a unified black-box framework that integrates Nesterov acceleration into decentralized optimization algorithms. %, enhancing their performance. At its core, DCatalyst operates as an \textit{inexact}, \textit{momentum-accelerated} proximal method (forming the outer loop) that seamlessly incorporates any selected decentralized algorithm (as the inner loop). We demonstrate that DCatalyst achieves optimal communication and computational complexity (up to log-factors) across various decentralized algorithms and problem instances. Notably, it extends acceleration capabilities to problem classes previously lacking accelerated solution methods, thereby broadening the effectiveness of decentralized methods.
  On the technical side, our framework introduce the {\it inexact estimating sequences}--a novel extension of the well-known Nesterov's estimating sequences, tailored for the minimization of composite losses in decentralized settings. This method adeptly handles consensus errors and inexact solutions of agents' subproblems, challenges not addressed by existing models.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Experimental relativistic zero-knowledge proofs with unconditional security</title>
<link>https://arxiv.org/abs/2501.18176</link>
<guid>https://arxiv.org/abs/2501.18176</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、量子非局域性游戏、子集相对论位承诺、图三着色问题、无条件安全

<br /><br />总结：
本文提出并实验实现了基于子集相对论位承诺和量子非局域性游戏的一种无条件安全的零知识证明（ZKP）方案，用于解决图三着色问题。该协议实现了交互轮数与边数量之间的线性关系，从而将复杂度和存储需求降低了十三个数量级，显著提高了其实用可行性。这项工作展示了在不信任的互联网环境中，结合特殊相对论和量子理论在无信任加密中的强大潜力，为抵御量子攻击的应用铺平了道路。 <div>
arXiv:2501.18176v1 Announce Type: cross 
Abstract: Zero-knowledge proofs (ZKPs) are widely applied in digital economies, such as cryptocurrencies and smart contracts, for establishing trust and ensuring privacy between untrusted parties. However, almost all ZKPs rely on unproven computational assumptions or are vulnerable to quantum adversaries. We propose and experimentally implement an unconditionally secure ZKP for the graph three-coloring problem by combining subset relativistic bit commitments with quantum nonlocality game. Our protocol achieves a linear relationship between interactive rounds and the number of edges, reducing round complexity and storage requirements by thirteen orders of magnitude, thereby significantly enhancing practical feasibility. Our work illustrates the powerful potential of integrating special relativity with quantum theory in trustless cryptography, paving the way for robust applications against quantum attacks in distrustful internet environments.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization</title>
<link>https://arxiv.org/abs/2501.18183</link>
<guid>https://arxiv.org/abs/2501.18183</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized optimization、projection-free、upper-linearizable functions、DR-次模函数优化、up-concave optimization

总结:

我们提出了一种新的去中心化无投影优化框架，将无投影方法扩展到更广泛的上线性可分解函数类别。该框架结合了去中心化优化技术和上线性可分解函数框架的灵活性，从而对传统的DR-次模函数优化进行了有效推广。我们实现了对于任何$0\le \theta \le 1$，在去中心化上线性可分解函数优化中得到$O(T^{1-\theta/2})$的遗憾值，通信复杂度为$O(T^\theta)$以及线性优化Oracle调用次数为$O(T^{2\theta})$的结果。这使得首次能够处理具有一般凸约束的单调上凹优化问题和非单调上凹优化问题。此外，还将上述针对第一阶反馈的结果扩展到了零阶、半带宽和带宽反馈的情况。 <div>
arXiv:2501.18183v1 Announce Type: cross 
Abstract: We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\theta/2})$ with communication complexity of $O(T^{\theta})$ and number of linear optimization oracle calls of $O(T^{2\theta})$ for decentralized upper-linearizable function optimization, for any $0\le \theta \le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>REPS: Recycled Entropy Packet Spraying for Adaptive Load Balancing and Failure Mitigation</title>
<link>https://arxiv.org/abs/2407.21625</link>
<guid>https://arxiv.org/abs/2407.21625</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据中心、网络负载均衡、人工智能训练、REPS、超高速以太网

<br />
总结:

下一代数据中心需要高效的网络负载均衡来处理不断增长的人工智能训练和一般数据中心流量。现有的Ethernet解决方案（如等价多路径ECMP和无感知包喷洒OPS）在网络规模扩大及随之而来的网络故障增加时难以保持高网络利用率。为解决这些问题，本文提出了REPS，这是一种轻量级、分布式、逐包自适应的负载均衡算法，旨在优化网络利用效率并确保快速从链路故障中恢复。REPS通过缓存表现良好的路径来适应网络条件，当发生网络故障时，能在不到100微秒的时间内重新路由流量。REPS设计用于与下一代乱序传输技术（如超高速以太网）部署，并且每个连接仅引入不超过25字节的状态开销。我们对REPS进行了大规模模拟和基于FPGA的NIC的广泛评估。 <div>
arXiv:2407.21625v3 Announce Type: replace 
Abstract: Next-generation datacenters require highly efficient network load balancing to manage the growing scale of artificial intelligence (AI) training and general datacenter traffic. Existing solutions designed for Ethernet, such as Equal Cost Multi-Path (ECMP) and oblivious packet spraying (OPS), struggle to maintain high network utilizations as datacenter topologies (and network failures as a consequence) continue to grow. To address these limitations, we propose REPS, a lightweight decentralized per-packet adaptive load balancing algorithm designed to optimize network utilization while ensuring rapid recovery from link failures. REPS adapts to network conditions by caching good-performing paths. In case of a network failure, REPS re-routes traffic away from it in less than 100 microseconds. REPS is designed to be deployed with next-generation out-of-order transports, such as Ultra Ethernet, and introduces less than 25 bytes of per-connection state. We extensively evaluate REPS in large-scale simulations and FPGA-based NICs.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized MIMO Systems with Imperfect CSI using LMMSE Receivers</title>
<link>https://arxiv.org/abs/2408.12811</link>
<guid>https://arxiv.org/abs/2408.12811</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化基带处理, 分布式基带处理, 大规模多输入多输出, 信道状态信息, 线性最小均方误差接收器

总结:
本文探讨了大规模多输入多输出(MIMO)系统中，中心化基带处理(CBP)面临的数据交互和高维度计算问题，为此引入了分布式基带处理(DBP)。针对DBP在具有空间相关性和不完美信道状态信息(CSI)情况下的优化融合方案及其性能分析尚未有文献研究的问题，文章考虑了一种采用线性最小均方误差(LMMSE)接收器的分布式MIMO系统。首先，建立了具有较高计算和数据输入/输出(I/O)成本的最优线性融合方案；接着，提出了两种降低复杂度的次优融合策略，并利用随机矩阵理论(RMT)得到了三种方案的信号对干扰及噪声比(SINR)闭合形式表达式，揭示了次优方案成为最优条件。此外，文章确定了分布式LMMSE接收器的最佳正则化参数，明确了最佳天线分区策略，并证明随着集群数量增加，SINR将下降。数值仿真验证了理论结果的准确性。 <div>
arXiv:2408.12811v2 Announce Type: replace 
Abstract: Centralized baseband processing (CBP) is required to achieve the full potential of massive multiple-input multiple-output (MIMO) systems. However, due to the large number of antennas, CBP suffers from two major issues: 1) Tremendous data interconnection between radio frequency (RF) circuitry and processing fabrics; and 2) high-dimensional computation. To this end, decentralized baseband processing (DBP) has been proposed, where the antennas at the BS are partitioned into clusters connected to separate RF circuits and equipped with separate computing units. Unfortunately, due to the decentralized structure, the optimal fusion scheme and performance analysis for DBP with general spatial correlation between clusters and imperfect channel state information (CSI) are not available in the literature. In this paper, we consider a decentralized MIMO system where all clusters adopt linear minimum mean-square error (LMMSE) receivers with imperfect CSI. Specifically, we first establish the optimal linear fusion scheme which has high computational and data input/output (I/O) costs. To reduce the costs, we further propose two sub-optimal fusion schemes with reduced complexity. For all three schemes, we derive the closed-form expressions for the signal-to-interference-and-noise ratio (SINR) by leveraging random matrix theory (RMT) and demonstrate the conditions under which the sub optimal schemes are optimal. Furthermore, we determine the optimal regularization parameter for decentralized LMMSE receivers, identify the best antenna partitioning strategy, and prove that the SINR will decrease as the number of clusters increases. Numerical simulations validate the accuracy of the theoretical results.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pandora's Box: Cross-Chain Arbitrages in the Realm of Blockchain Interoperability</title>
<link>https://arxiv.org/abs/2501.17335</link>
<guid>https://arxiv.org/abs/2501.17335</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、Layer-1、Layer-2、跨链套利、Maximal Extractable Value (MEV)

<br /><br />总结:
本文首次系统性研究了两种非原子性的跨链套利策略：Sequence-Independent Arbitrage (SIA)和Sequence-Dependent Arbitrage (SDA)，这两种策略分别涉及不同区块链间的独立双向交易及依赖资产桥的套利。研究涵盖了过去一年（从2023年9月至2024年8月）九条区块链的数据，共发现260,808例跨链套利机会，其中32.37%涉及到桥接解决方案。这些套利活动产生了至少9,496,115.28美元的利润，总交易量达465,797,487.98美元。同时，文章分析了跨链套利对安全的影响，包括套利者集中化、失败交易导致的网络拥塞以及私有内存池采用率的增长问题。最后，文中探讨了sequencer激励机制并提出了一个风险优化的套利策略。 <div>
arXiv:2501.17335v1 Announce Type: new 
Abstract: Over recent years, the blockchain ecosystem has grown significantly with the emergence of new Layer-1 (L1) and Layer-2 (L2) networks. These blockchains typically host Decentralized Exchanges (DEXes) for trading assets such as native currencies and stablecoins. While this diversity enriches the ecosystem, it also fragments liquidity, posing challenges for DEXes offering the same assets across multiple blockchains. This fragmentation leads to price discrepancies, creating opportunities like arbitrages for profit-seeking traders, which fall under the broader category of exploitative economic practices known as Maximal Extractable Value (MEV). Although MEV extraction has been extensively studied within single domains (i.e., individual blockchains), cross-chain arbitrages, a form of cross-domain MEV, have received little attention due to their non-atomic nature, complicating both execution and detection.
  In this paper, we shed light on opaque cross-chain MEV activities by presenting the first systematic study of two non-atomic cross-chain arbitrage strategies: Sequence-Independent Arbitrage (SIA) and Sequence-Dependent Arbitrage (SDA). The former involves independent, opposite-direction trades across chains, while the latter relies on asset bridges. We analyze the effectiveness of these strategies across nine blockchains over a one-year period from September 2023 to August 2024, identifying 260,808 cross-chain arbitrages, 32.37% of which involve bridging solutions. These arbitrages generated a lower-bound profit of 9,496,115.28 USD from a total traded volume of 465,797,487.98 USD. Additionally, we examine the security implications of cross-chain arbitrages, uncovering centralization among arbitrageurs, network congestion caused by failed transactions, and growing private mempool adoption. Finally, we discuss sequencer incentives and propose a risk-optimized arbitrage strategy.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Do We Really Need to Design New Byzantine-robust Aggregation Rules?</title>
<link>https://arxiv.org/abs/2501.17381</link>
<guid>https://arxiv.org/abs/2501.17381</guid>
<content:encoded><![CDATA[
<div> 关键词: federated learning, poisoning attacks, aggregation rules, FoundationFL, Byzantine-robust

总结:<br />
本文关注了联邦学习（Federated Learning, FL）中的数据中毒攻击问题，提出了一种新的防御机制——FoundationFL。传统上，通过设计抵抗拜占庭故障的聚合规则来应对这类攻击，但本文指出，增强已有的、经过验证的聚合规则的鲁棒性即可实现FL的安全。FoundationFL方法由服务器生成合成更新，在接收到客户端的本地模型更新后，结合使用Trimmed-mean或Median等已有拜占庭容错聚合规则进行更新融合。理论上，文章证明了FoundationFL在拜占庭环境下的收敛性能。实验结果在多个真实世界的数据集上验证了FoundationFL方法的有效性和效率。 <div>
arXiv:2501.17381v1 Announce Type: new 
Abstract: Federated learning (FL) allows multiple clients to collaboratively train a global machine learning model through a server, without exchanging their private training data. However, the decentralized aspect of FL makes it susceptible to poisoning attacks, where malicious clients can manipulate the global model by sending altered local model updates. To counter these attacks, a variety of aggregation rules designed to be resilient to Byzantine failures have been introduced. Nonetheless, these methods can still be vulnerable to sophisticated attacks or depend on unrealistic assumptions about the server. In this paper, we demonstrate that there is no need to design new Byzantine-robust aggregation rules; instead, FL can be secured by enhancing the robustness of well-established aggregation rules. To this end, we present FoundationFL, a novel defense mechanism against poisoning attacks. FoundationFL involves the server generating synthetic updates after receiving local model updates from clients. It then applies existing Byzantine-robust foundational aggregation rules, such as Trimmed-mean or Median, to combine clients' model updates with the synthetic ones. We theoretically establish the convergence performance of FoundationFL under Byzantine settings. Comprehensive experiments across several real-world datasets validate the efficiency of our FoundationFL method.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Are you a DePIN? A Decision Tree to Classify Decentralized Physical Infrastructure Networks</title>
<link>https://arxiv.org/abs/2501.17416</link>
<guid>https://arxiv.org/abs/2501.17416</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized physical infrastructure networks (DePINs), Web3, Decision tree, Blockchain systems, Helium, Bitcoin

总结:<br />
本文探讨了去中心化物理基础设施网络（DePINs）这一新兴的Web3垂直领域，并分析了其与传统建设方法及其它Web2、Web3应用之间的界限。研究者提出了一种新的决策树模型，用于系统性地将系统分类为DePIN，该模型基于前期研究和诸如是否存在三方市场、供应方是否通过代币激励以及是否需要实体资产部署等标准进行区分。文章通过将决策树应用于Helium和比特币等区块链系统，展示了其在区分DePIN系统方面的实用价值。这项研究为进一步确立识别和归类DePIN系统的客观、系统化方法做出了重要贡献，并为构建全面、公正的DePIN系统数据库奠定了基础，进而可以指导未来该领域的研究和发展。 <div>
arXiv:2501.17416v1 Announce Type: new 
Abstract: Decentralized physical infrastructure networks (DePINs) are an emerging vertical within "Web3" replacing the traditional method that physical infrastructures are constructed. Yet, the boundaries between DePIN and traditional method of building crowd-sourced infrastructures such as citizen science initiatives or other Web3 verticals are not always so clear cut. In this work, we systematically analyze the differences between DePIN and other Web2 and Web3 verticals. For this, the study proposes a novel decision tree for classifying systems as DePIN. This tree is informed by prior studies and differentiates DePIN from related concepts using criteria such as the presence of a three-sided market, token-based incentives for supply, and the requirement for physical asset placement in those systems.
  The paper demonstrates the application of the decision tree to various blockchain systems, including Helium and Bitcoin, showcasing its practical utility in differentiating DePIN systems.
  This research offers significant contributions towards establishing a more objective and systematic approach to identifying and categorizing DePIN systems. It lays the groundwork for creating a comprehensive and unbiased database of DePIN systems, which will inform future research and development within this emerging sector.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Coalitional model predictive control of an irrigation canal</title>
<link>https://arxiv.org/abs/2501.17561</link>
<guid>https://arxiv.org/abs/2501.17561</guid>
<content:encoded><![CDATA[
<div> 关键词： hierarchical control scheme、large-scale systems、network topology、decentralized model predictive control (MPC)、Dez irrigation canal

<br /><br />总结:

本文提出了一种用于大规模系统的分层控制方案，该系统组件可以通过数据网络交换信息。该方案的主要目标是通过主动修改网络拓扑来寻找控制性能和通信成本之间的最佳折衷。监督层采取的行动改变了控制代理对完整系统的认知以及它们可以相互通信的代理集合。每个链接子系统的联盟（即合作社）基于底层管理的分布式模型预测控制(MPC)策略进行独立控制，并对输入施加硬约束，同时考虑软约束以避免状态可行性问题。研究者在针对水系统的精确模拟器SOBEK上采用Dez灌溉渠模型验证了所提控制方案的性能，并将其结果与使用集中式MPC控制器的结果进行了比较。 <div>
arXiv:2501.17561v1 Announce Type: new 
Abstract: We present a hierarchical control scheme for large-scale systems whose components can exchange information through a data network. The main goal of the supervisory layer is to find the best compromise between control performance and communicational costs by actively modifying the network topology. The actions taken at the supervisory layer alter the control agents' knowledge of the complete system, and the set of agents with which they can communicate. Each group of linked subsystems, or coalition, is independently controlled based on a decentralized model predictive control (MPC) scheme, managed at the bottom layer. Hard constraints on the inputs are imposed, while soft constraints on the states are considered to avoid feasibility issues. The performance of the proposed control scheme is validated on a model of the Dez irrigation canal, implemented on the accurate simulator for water systems SOBEK. Finally, the results are compared with those obtained using a centralized MPC controller.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning With Individualized Privacy Through Client Sampling</title>
<link>https://arxiv.org/abs/2501.17634</link>
<guid>https://arxiv.org/abs/2501.17634</guid>
<content:encoded><![CDATA[
<div> 关键词：Individualized Differential Privacy (IDP)，Federated Learning (FL)，客户端特定采样率，隐私预算，SCALE方法

总结:
本文提出了一个针对联邦学习(FL)中个体化差分隐私(IDP)的新方法，该方法根据用户不同的隐私偏好来调整客户端的采样率。通过将SAMPLE算法从集中式环境扩展到FL，并将其与修改后的IDP-FedAvg算法相结合，实现了对用户个性化隐私预算的处理。实验结果显示，相较于统一的DP基线，这种方法在减少隐私和效用之间的权衡方面表现出明显优势，且优于相关工作中分配不同噪声尺度的SCALE方法。然而，对于具有非独立同分布数据的复杂任务，由于分布式设置的约束，仍存在挑战。 <div>
arXiv:2501.17634v1 Announce Type: new 
Abstract: With growing concerns about user data collection, individualized privacy has emerged as a promising solution to balance protection and utility by accounting for diverse user privacy preferences. Instead of enforcing a uniform level of anonymization for all users, this approach allows individuals to choose privacy settings that align with their comfort levels. Building on this idea, we propose an adapted method for enabling Individualized Differential Privacy (IDP) in Federated Learning (FL) by handling clients according to their personal privacy preferences. By extending the SAMPLE algorithm from centralized settings to FL, we calculate client-specific sampling rates based on their heterogeneous privacy budgets and integrate them into a modified IDP-FedAvg algorithm. We test this method under realistic privacy distributions and multiple datasets. The experimental results demonstrate that our approach achieves clear improvements over uniform DP baselines, reducing the trade-off between privacy and utility. Compared to the alternative SCALE method in related work, which assigns differing noise scales to clients, our method performs notably better. However, challenges remain for complex tasks with non-i.i.d. data, primarily stemming from the constraints of the decentralized setting.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gateways for Institutional-Grade Commerce and Interoperability of Digital Assets</title>
<link>https://arxiv.org/abs/2501.17732</link>
<guid>https://arxiv.org/abs/2501.17732</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式账本、互操作性、标准化服务接口、网关、监管合规

总结:
本文探讨了传统金融基础设施与现代去中心化基础设施（如分布式账本）无缝连接的需求及所面临的风险和挑战。文章指出，实现这种互操作性的关键第一步是要认识到分布式账本往往用于社区成员间资源共享，并通过标准化服务接口（或应用程序编程接口(API)）来实现不同系统的跨系统互通。文中提出的“ ledger gateways”（或简称网关）是指实施这些标准化服务接口并接入分布式账本的计算机和软件系统。网关的主要职责是与其他实现相同标准化服务接口的对等网关进行通信，执行跨境数据和价值转移，并成为管理需遵守法律法规的许可环境的重要机制（例如欧盟GDPR、MiCA数字资产法规、FAFT第15建议以及ISO 27001标准）。 <div>
arXiv:2501.17732v1 Announce Type: new 
Abstract: It is time for the legacy financial infrastructure to seamlessly connect with modern, decentralized infrastructure. Although it is increasingly evident that decentralized infrastructure for finance (namely distributed ledgers) will coexist with and complement legacy infrastructure, it is also clear that such interoperability efforts carry new risks and concerns. In particular, managing the range of heterogeneous (and not well-established) infrastructure brings security, privacy, and regulatory issues. The first step to overcome some of these challenges is to recognize that in many deployment instances using distributed ledgers, the purpose of the ledger is to share resources among the community members. The second step after recognizing that borders exist is to understand that interoperability across systems can be best achieved through the use of standardized service interfaces (or application programming interfaces (API)). In this paper we use the term ledger gateways (or simply gateways) to denote the computer and software systems that implement the standardized service interfaces into a distributed ledger. The main purpose of a gateway is to communicate with other peer gateways that implement the same standardized service interface. Among others, peer gateways perform the transfer of data and value across borders (legal or national borders). Gateways also become a mechanism to manage a permissioned environment, where abiding by laws and regulations is crucial for business compliance (e.g., EU General Data Protection Regulations (GDPR), EU MiCa regulation on digital assets, FAFT Recommendation 15, ISO 27001.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BitMLx: Secure Cross-chain Smart Contracts For Bitcoin-style Cryptocurrencies</title>
<link>https://arxiv.org/abs/2501.17733</link>
<guid>https://arxiv.org/abs/2501.17733</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contract, cross-chain, BitMLx, compiler, cryptocurrencies

总结:<br />
本文提出了首个用于跨链智能合约的领域特定语言BitMLx，它允许与持有多种比特币类加密货币的多个用户进行交互。文章贡献了一个编译器，能够将BitMLx合同自动翻译成涉及的每种加密货币的单独合同以及一个同步执行这些合同的用户策略。作者证明了遵循规定策略与多个合同互动的诚实用户，其最终持有的资金至少与执行原始BitMLx合同时一样多。最后，文章实现了BitMLx编译器并通过多元链捐赠和跨不同加密货币的贷款等示例应用展示了其实用性。 <div>
arXiv:2501.17733v1 Announce Type: new 
Abstract: A smart contract is an interactive program that governs funds in the realm of a single cryptocurrency. Yet, the many existing cryptocurrencies have spurred the design of cross-chain applications that require interactions with multiple cryptocurrencies simultaneously. Currently, cross-chain applications are implemented as use-case-specific cryptographic protocols that serve as overlay to synchronize smart contract executions in the different cryptocurrencies. Hence, their design requires substantial expertise, as well as a security analysis in complex cryptographic frameworks.
  In this work, we present BitMLx, the first domain-specific language for cross-chain smart contracts, enabling interactions with several users that hold funds across multiple Bitcoin-like cryptocurrencies. We contribute a compiler to automatically translate a BitMLx contract into one contract per involved cryptocurrency and a user strategy that synchronizes the execution of these contracts. We prove that an honest user, who follows the prescribed strategy when interacting with the several contracts, ends up with at least as many funds as in the corresponding execution of the BitMLx contract. Last, but not least, we implement the BitMLx compiler and demonstrate its utility in the design of illustrative examples of cross-chain applications such as multi-chain donations or loans across different cryptocurrencies.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Atomic Transfer Graphs: Secure-by-design Protocols for Heterogeneous Blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2501.17786</link>
<guid>https://arxiv.org/abs/2501.17786</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、异构性、原子转移图(ATOM)、Conditional Timelock Contracts (CTLCs)、安全协议框架

<br /><br />总结:
本文针对区块链领域的异构性问题，提出了一个新的研究框架，用于设计适用于特定区块链和应用的安全协议。该框架基于原子转移图(ATOM)，它能够描述期望的转账结构，并捕捉众多区块链协议共享的安全性和功能目标。文章引入了Conditional Timelock Contracts (CTLCs)这一新型智能合约机制，可在多种具有受限脚本语言（如比特币）的加密货币中实现，并结合支付通道进行应用。通过ATGs，不仅可以实现新的应用场景，还能表达并确保现有支付通道网络和复杂多方跨币种交换等以太坊式加密货币应用的安全性和功能目标。此框架首次为这些用例提供了普适且可证明安全的协议，并在性能上与现有的特定场景协议相匹配或有所提升。 <div>
arXiv:2501.17786v1 Announce Type: new 
Abstract: The heterogeneity of the blockchain landscape has motivated the design of blockchain protocols tailored to specific blockchains and applications that, hence, require custom security proofs. We observe that many blockchain protocols share common security and functionality goals, which can be captured by an atomic transfer graph (ATG) describing the structure of desired transfers. Based on this observation, we contribute a framework for generating secure-by-design protocols that realize these goals. The resulting protocols build upon Conditional Timelock Contracts (CTLCs), a novel minimal smart contract functionality that can be implemented in a large variety of cryptocurrencies with a restricted scripting language (e.g., Bitcoin), and payment channels. We show how ATGs, in addition to enabling novel applications, capture the security and functionality goals of existing applications, including many examples from payment channel networks and complex multi-party cross-currency swaps among Ethereum-style cryptocurrencies. Our framework is the first to provide generic and provably secure protocols for all these use cases while matching or improving the performance of existing use-case-specific protocols.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DRACO: Decentralized Asynchronous Federated Learning over Row-Stochastic Wireless Networks</title>
<link>https://arxiv.org/abs/2406.13533</link>
<guid>https://arxiv.org/abs/2406.13533</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning, asynchronous SGD, row-stochastic gossip wireless networks, continuous communication, DRACO

总结:
为应对智能物联网和边缘AI等新兴应用场景对完全去中心化（无服务器）网络中神经网络训练的需求，本文提出了一种名为DRACO的新方法。该方法针对去中心化异步随机梯度下降（SGD）进行研究，并利用连续通信技术，在行随机 gossip 无线网络中实现该过程。DRACO允许去中心化网络中的边缘设备在连续的时间线上执行本地训练和模型交换，从而消除了对同步时间要求的依赖。此外，该算法还采用了一种解耦通信和计算日程的技术，赋予所有用户完全自主权以及对延迟节点的可控指导。通过全面的收敛性分析，文章突出了异步和自主参与在去中心化优化中的优势。数值实验验证了所提方法的有效性。 <div>
arXiv:2406.13533v2 Announce Type: replace 
Abstract: Recent developments and emerging use cases, such as smart Internet of Things (IoT) and Edge AI, have sparked considerable interest in the training of neural networks over fully decentralized (serverless) networks. One of the major challenges of decentralized learning is to ensure stable convergence without resorting to strong assumptions applied for each agent regarding data distributions or updating policies. To address these issues, we propose DRACO, a novel method for decentralized asynchronous Stochastic Gradient Descent (SGD) over row-stochastic gossip wireless networks by leveraging continuous communication. Our approach enables edge devices within decentralized networks to perform local training and model exchanging along a continuous timeline, thereby eliminating the necessity for synchronized timing. The algorithm also features a specific technique of decoupling communication and computation schedules, which empowers complete autonomy for all users and manageable instructions for stragglers. Through a comprehensive convergence analysis, we highlight the advantages of asynchronous and autonomous participation in decentralized optimization. Our numerical experiments corroborate the efficacy of the proposed technique.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-based Crowdsourced Deep Reinforcement Learning as a Service</title>
<link>https://arxiv.org/abs/2501.16369</link>
<guid>https://arxiv.org/abs/2501.16369</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习(DRL)、区块链、众包、DRL即服务(DRLaaS)、智能合约

总结:<br />
本文提出了一种基于区块链的众包深度强化学习即服务（DRLaaS）框架，旨在提高DRL解决方案的可用性。该框架提供两种类型的任务服务：DRL训练和模型共享。通过众包方式，用户可以利用工作者的专业知识和计算能力进行DRL解决方案的训练。同时，用户可以通过模型分享获取预训练模型以助于使用迁移学习方法训练新的DRL解决方案。整个DRLaaS框架建立在联盟链之上，确保可追溯和自主执行。文章设计了用于管理工作者和模型分配的智能合约，并利用星际文件系统（IPFS）保证数据分布的防篡改性。实验证明，该框架在多个DRL应用中表现出有效性。 <div>
arXiv:2501.16369v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) has emerged as a powerful paradigm for solving complex problems. However, its full potential remains inaccessible to a broader audience due to its complexity, which requires expertise in training and designing DRL solutions, high computational capabilities, and sometimes access to pre-trained models. This necessitates the need for hassle-free services that increase the availability of DRL solutions to a variety of users. To enhance the accessibility to DRL services, this paper proposes a novel blockchain-based crowdsourced DRL as a Service (DRLaaS) framework. The framework provides DRL-related services to users, covering two types of tasks: DRL training and model sharing. Through crowdsourcing, users could benefit from the expertise and computational capabilities of workers to train DRL solutions. Model sharing could help users gain access to pre-trained models, shared by workers in return for incentives, which can help train new DRL solutions using methods in knowledge transfer. The DRLaaS framework is built on top of a Consortium Blockchain to enable traceable and autonomous execution. Smart Contracts are designed to manage worker and model allocation, which are stored using the InterPlanetary File System (IPFS) to ensure tamper-proof data distribution. The framework is tested on several DRL applications, proving its efficacy.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Decentralized Online Learning for Supervised Regression and Classification Problems</title>
<link>https://arxiv.org/abs/2501.16519</link>
<guid>https://arxiv.org/abs/2501.16519</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning networks, optimization framework, performance-to-weight mapping, performance timeframe, performance-reward mapping

<br /><br />总结:
本文研究了去中心化学习网络中关键参数的优化框架，这些参数包括历史表现与参与者权重之间的映射斜率、性能评估的时间范围以及表现与公平奖励之间的映射斜率。通过模拟Allora网络设计并扩展至处理分类任务的一系列数值实验，对这些参数进行了优化和对比分析。研究表明，最优的表现-权重映射、性能时间范围和表现-奖励映射会随着网络构成和问题类型的不同而变化。这些发现为去中心化学习协议的优化提供了有价值见解，并讨论了如何将这些结果推广到基于推断综合的任何去中心化AI网络的优化中。 <div>
arXiv:2501.16519v1 Announce Type: new 
Abstract: Decentralized learning networks aim to synthesize a single network inference from a set of raw inferences provided by multiple participants. To determine the combined inference, these networks must adopt a mapping from historical participant performance to weights, and to appropriately incentivize contributions they must adopt a mapping from performance to fair rewards. Despite the increased prevalence of decentralized learning networks, there exists no systematic study that performs a calibration of the associated free parameters. Here we present an optimization framework for key parameters governing decentralized online learning in supervised regression and classification problems. These parameters include the slope of the mapping between historical performance and participant weight, the timeframe for performance evaluation, and the slope of the mapping between performance and rewards. These parameters are optimized using a suite of numerical experiments that mimic the design of the Allora Network, but have been extended to handle classification tasks in addition to regression tasks. This setup enables a comparative analysis of parameter tuning and network performance optimization (loss minimization) across both problem types. We demonstrate how the optimal performance-weight mapping, performance timeframe, and performance-reward mapping vary with network composition and problem type. Our findings provide valuable insights for the optimization of decentralized learning protocols, and we discuss how these results can be generalized to optimize any inference synthesis-based, decentralized AI network.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Governing the Agent-to-Agent Economy of Trust via Progressive Decentralization</title>
<link>https://arxiv.org/abs/2501.16606</link>
<guid>https://arxiv.org/abs/2501.16606</guid>
<content:encoded><![CDATA[
<div> 关键词: AI治理、AI代理、价值交换、信任机制、AgentBound令牌

<br />
总结:
本文探讨了随着AI代理承担关键任务，现有的AI治理方法可能存在的不足。文章提出，理解人类价值观交换的基础原则对于构建AI驱动的经济体具有重要意义。为了解决AI代理之间如何可靠地确定信任以及在AI经济规模扩大和演进过程中人类如何确保有效监督和控制的问题，作者呼吁研究者关注加密经济学激励，并提出了一个研究议程——使用类似于Web3中灵魂绑定令牌(Soulbound tokens)的非转移性、非同质化的AgentBound令牌(ABT)。通过让AI代理在基于权益证明的机制下将ABT作为自主行为的抵押品，可以激励其遵循伦理行为，并自动实施对不当行为的处罚，从而实现AI代理间的自主交互与价值交换的同时保证人类的有效监督。 <div>
arXiv:2501.16606v1 Announce Type: new 
Abstract: Current approaches to AI governance often fall short in anticipating a future where AI agents manage critical tasks, such as financial operations, administrative functions, and beyond. As AI agents may eventually delegate tasks among themselves to optimize efficiency, understanding the foundational principles of human value exchange could offer insights into how AI-driven economies might operate. Just as trust and value exchange are central to human interactions in open marketplaces, they may also be critical for enabling secure and efficient interactions among AI agents. While cryptocurrencies could serve as the foundation for monetizing value exchange in a collaboration and delegation dynamic among AI agents, a critical question remains: how can these agents reliably determine whom to trust, and how can humans ensure meaningful oversight and control as an economy of AI agents scales and evolves? This paper is a call for a collective exploration of cryptoeconomic incentives, which can help design decentralized governance systems that allow AI agents to autonomously interact and exchange value while ensuring human oversight via progressive decentralization. Toward this end, I propose a research agenda to address the question of agent-to-agent trust using AgentBound Tokens, which are non-transferable, non-fungible tokens uniquely tied to individual AI agents, akin to Soulbound tokens for humans in Web3. By staking ABTs as collateral for autonomous actions within an agent-to-agent network via a proof-of-stake mechanism, agents may be incentivized towards ethical behavior, and penalties for misconduct are automatically enforced.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Address Poisoning</title>
<link>https://arxiv.org/abs/2501.16681</link>
<guid>https://arxiv.org/abs/2501.16681</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、地址中毒、攻击检测系统、以太坊、币安智能链<br /><br />总结:
本文针对区块链中的钱包地址安全问题，特别是以太坊和币安智能链上的地址中毒攻击进行了深入研究。文章贡献主要包括：1. 开发了一套检测系统并进行了两年的数据测量，发现针对1700万受害者的2.7亿次攻击尝试，比先前报告的数量增加了13倍，其中至少有6633起事件导致了8380万美元的损失；2. 对使用改进聚类技术分析的大型攻击实体进行了研究，并建模了攻击者的盈利性和竞争态势；3. 揭示了攻击策略，包括定向人群、成功条件（地址相似度、时机）以及跨链攻击；4. 数学定义并模拟了各类软硬件实现下的仿冒地址生成过程，发现了一个疑似使用GPU的大规模攻击者群体，并提出了防御性对策。 <div>
arXiv:2501.16681v1 Announce Type: new 
Abstract: In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on Ethereum and BSC. We identify 13 times the number of attack attempts reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address-generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Trajectory (Re)Planning for a Large Scale Swarm</title>
<link>https://arxiv.org/abs/2501.16743</link>
<guid>https://arxiv.org/abs/2501.16743</guid>
<content:encoded><![CDATA[
<div> 关键词：轨迹重规划、大规模群体、复杂环境、分布式轨迹优化、层次化方法

<br />
总结:

本文研究了在复杂环境中大规模群体的轨迹重规划问题。提出了一种利用层次化方法的路径规划器，该方法通过将工作空间划分并并行计算每个单元格内的机器人碰撞规避路径实现重规划。采用分布式的轨迹优化策略生成无死锁的高效执行轨迹，并在优化失败时仍能保持控制可行性。这种层次化方法结合了集中式和分散式方法的优点，在确保高任务成功率的同时提供了实时重规划能力。相较于分散式方法，本方法更有效地避免了死锁和碰撞，显著提高了任务成功率。实验结果表明，该算法在模拟环境下可实现实时性能，处理多达142个机器人的场景，并通过一个具有代表性的由24架Crazyflie纳米四旋翼无人机组成的物理实验进行了验证。 <div>
arXiv:2501.16743v1 Announce Type: new 
Abstract: We consider the trajectory replanning problem for a large-scale swarm in a cluttered environment. Our path planner replans for robots by utilizing a hierarchical approach, dividing the workspace, and computing collision-free paths for robots within each cell in parallel. Distributed trajectory optimization generates a deadlock-free trajectory for efficient execution and maintains the control feasibility even when the optimization fails. Our hierarchical approach combines the benefits of both centralized and decentralized methods, achieving a high task success rate while providing real-time replanning capability. Compared to decentralized approaches, our approach effectively avoids deadlocks and collisions, significantly increasing the task success rate. We demonstrate the real-time performance of our algorithm with up to 142 robots in simulation, and a representative 24 physical Crazyflie nano-quadrotor experiment.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Meta-Federated Learning: A Novel Approach for Real-Time Traffic Flow Management</title>
<link>https://arxiv.org/abs/2501.16758</link>
<guid>https://arxiv.org/abs/2501.16758</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (联邦学习), Meta-Learning (元学习), 交通管理, Decentralized, Smart Cities

总结:<br />
本文提出了一种将联邦学习和元学习相结合的创新方法——Meta-Federated Learning，用于解决城市环境中动态变化的交通流量管理难题。该方法利用联邦学习的分布式特性在边缘设备本地处理数据，提升了隐私保护能力和响应速度；同时结合元学习，使系统能在无需大规模重新训练的情况下快速适应新的交通状况。通过在一个模拟的智能交通设备网络中实施此模型，研究表明Meta-Federated Learning在预测精度和反应时间上显著优于传统模型，并且对突发的交通模式变化具有出色的适应性，为实时智能城市交通管理提供了一个可扩展的解决方案。此外，这项研究还展示了联邦学习与元学习整合应用在其他现实世界问题中的巨大潜力。 <div>
arXiv:2501.16758v1 Announce Type: new 
Abstract: Efficient management of traffic flow in urban environments presents a significant challenge, exacerbated by dynamic changes and the sheer volume of data generated by modern transportation networks. Traditional centralized traffic management systems often struggle with scalability and privacy concerns, hindering their effectiveness. This paper introduces a novel approach by combining Federated Learning (FL) and Meta-Learning (ML) to create a decentralized, scalable, and adaptive traffic management system. Our approach, termed Meta-Federated Learning, leverages the distributed nature of FL to process data locally at the edge, thereby enhancing privacy and reducing latency. Simultaneously, ML enables the system to quickly adapt to new traffic conditions without the need for extensive retraining. We implement our model across a simulated network of smart traffic devices, demonstrating that Meta-Federated Learning significantly outperforms traditional models in terms of prediction accuracy and response time. Furthermore, our approach shows remarkable adaptability to sudden changes in traffic patterns, suggesting a scalable solution for real-time traffic management in smart cities. This study not only paves the way for more resilient urban traffic systems but also exemplifies the potential of integrated FL and ML in other real-world applications.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PTSA: Utilizing Transaction Prioritization to Enhance Confirmation Speed in the IOTA Network</title>
<link>https://arxiv.org/abs/2501.16763</link>
<guid>https://arxiv.org/abs/2501.16763</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、有向无环图（DAG）、IOTA、物联网、优先级交易优化

总结:
随着区块链技术的快速发展，有向无环图（DAG）正作为替代传统链式架构用于组织账本记录的一种趋势。文章以IOTA网络为例，指出其在处理物联网（IoT）交易时虽利用DAG架构实现了更高可扩展性，但在有限带宽下未考虑交易优先级的问题。为此，该文提出了一个优化框架，旨在将优先级引入IOTA网络中的关键或高优先级IoT交易。实验基于官方IOTA GitHub仓库进行，使用了现行运营的IOTA节点软件（Hornet版本，Chrysalis更新至1.5）。结果显示，相较于原IOTA系统，提出的算法能让高优先级交易更快达到最终确认状态。 <div>
arXiv:2501.16763v1 Announce Type: new 
Abstract: With the rapid advancement of blockchain technology, a significant trend is the adoption of Directed Acyclic Graphs (DAGs) as an alternative to traditional chain-based architectures for organizing ledger records. Systems like IOTA, which are specially designed for the Internet of Things (IoT), leverage DAG-based architectures to achieve greater scalability by enabling multiple attachment points in the ledger for new transactions while allowing these transactions to be added to the network without incurring any fees. To determine these attachment points, many tip selection algorithms commonly employ specific strategies on the DAG ledger. Transaction prioritization is not considered in the IOTA network, which becomes especially important when network bandwidth is limited. In this paper, we propose an optimization framework designed to integrate a priority level for critical or high-priority IoT transactions within the IOTA network. We evaluate our system using fully based on the official IOTA GitHub repository, which employs the currently operational IOTA node software (Hornet version), as part of the Chrysalis update (1.5). The experimental results show that higher-priority transactions in the proposed algorithm reach final confirmation in less time compared to the original IOTA system.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Secure Federated Graph-Filtering for Recommender Systems</title>
<link>https://arxiv.org/abs/2501.16888</link>
<guid>https://arxiv.org/abs/2501.16888</guid>
<content:encoded><![CDATA[
<div> 关键词：推荐系统、图过滤器、隐私保护、分布式计算、低秩近似

<br /><br />总结:
该文提出两种针对推荐系统的隐私保护型分布式框架，用于安全地计算关键图过滤器，而无需集中敏感信息。第一种方法利用轻量级多方计算和分布式奇异向量计算来私下计算图过滤器；第二种方法进一步扩展了此框架，通过引入低秩近似，实现了通信效率与预测性能之间的权衡。实验结果表明，所提方法在确保数据机密性和降低通信成本的同时，其准确性可与中心化最优系统相媲美。这突显出隐私保护型去中心化架构在现代推荐系统中平衡实用性和用户数据保护方面的潜力。 <div>
arXiv:2501.16888v1 Announce Type: new 
Abstract: Recommender systems often rely on graph-based filters, such as normalized item-item adjacency matrices and low-pass filters. While effective, the centralized computation of these components raises concerns about privacy, security, and the ethical use of user data. This work proposes two decentralized frameworks for securely computing these critical graph components without centralizing sensitive information. The first approach leverages lightweight Multi-Party Computation and distributed singular vector computations to privately compute key graph filters. The second extends this framework by incorporating low-rank approximations, enabling a trade-off between communication efficiency and predictive performance. Empirical evaluations on benchmark datasets demonstrate that the proposed methods achieve comparable accuracy to centralized state-of-the-art systems while ensuring data confidentiality and maintaining low communication costs. Our results highlight the potential for privacy-preserving decentralized architectures to bridge the gap between utility and user data protection in modern recommender systems.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedEFM: Federated Endovascular Foundation Model with Unseen Data</title>
<link>https://arxiv.org/abs/2501.16992</link>
<guid>https://arxiv.org/abs/2501.16992</guid>
<content:encoded><![CDATA[
<div> 关键词：endovascular surgery、catheters/guidewires segmentation、foundation models、federated learning、differentiable Earth Mover's Distance

总结:
<br />
本文提出了一种针对端血管介入手术中导管和导丝精确识别的新方法。该方法利用联邦学习的分布式设置训练基础模型，以解决标注数据有限的问题。为确保训练可行性，文章采用可微分的地球移动距离（Earth Mover's Distance）在知识蒸馏框架下处理未见数据问题。训练完成后，该基础模型的权重为下游任务提供有价值的初始化，从而提升任务特定性能。实验结果显示，本方法达到了新的 state-of-the-art 结果，对于推进端血管介入手术以及机器人辅助端血管手术的发展具有重要意义，同时解决了医疗领域中的数据共享难题。 <div>
arXiv:2501.16992v1 Announce Type: new 
Abstract: In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework. Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Channel Estimation for XL-MIMO Systems with Decentralized Baseband Processing: Integrating Local Reconstruction with Global Refinement</title>
<link>https://arxiv.org/abs/2501.17059</link>
<guid>https://arxiv.org/abs/2501.17059</guid>
<content:encoded><![CDATA[
<div> 关键词: XL-MIMO系统、混合模拟-数字架构、分散式基带处理、两阶段信道估计、SBL-GNNs算法

总结:
本文针对具有混合模拟-数字架构和分散式基带处理框架下的超大规模多输入多输出(XL-MIMO)系统的信道估计问题进行研究。为解决现有集中式和完全分散式方法面临的计算复杂度过高或性能下降的问题，文章提出了一种新颖的两阶段信道估计方案，该方案结合局部稀疏重建与全局融合及细化。首先，利用通道在角度-延迟域内的稀疏性，将本地重建任务建模为稀疏信号恢复问题，并开发了增强型图神经网络的稀疏贝叶斯学习(SBL-GNNs)算法，有效捕捉通道系数间的依赖关系，显著提升估计精度。其次，在第二阶段，来自本地处理单元(LPUs)的局部估计值在全局角度域中进行对齐并融合于中央处理单元(CPU)。基于聚合观测值，将通道细化建模为贝叶斯去噪问题，并设计了一个引入马尔可夫链式层次稀疏先验的变分消息传递算法，有效地利用了全球角度-延迟域中的通道稀疏性和相关性。仿真结果验证了所提SBL-GNNs算法相对于现有方法的有效性和优越性，显示出了更好的估计性能和更低的计算复杂度。 <div>
arXiv:2501.17059v1 Announce Type: new 
Abstract: In this paper, we investigate the channel estimation problem for extremely large-scale multiple-input multiple-output (XL-MIMO) systems with a hybrid analog-digital architecture, implemented within a decentralized baseband processing (DBP) framework with a star topology. Existing centralized and fully decentralized channel estimation methods face limitations due to excessive computational complexity or degraded performance. To overcome these challenges, we propose a novel two-stage channel estimation scheme that integrates local sparse reconstruction with global fusion and refinement. Specifically, in the first stage, by exploiting the sparsity of channels in the angular-delay domain, the local reconstruction task is formulated as a sparse signal recovery problem. To solve it, we develop a graph neural networks-enhanced sparse Bayesian learning (SBL-GNNs) algorithm, which effectively captures dependencies among channel coefficients, significantly improving estimation accuracy. In the second stage, the local estimates from the local processing units (LPUs) are aligned into a global angular domain for fusion at the central processing unit (CPU). Based on the aggregated observations, the channel refinement is modeled as a Bayesian denoising problem. To efficiently solve it, we devise a variational message passing algorithm that incorporates a Markov chain-based hierarchical sparse prior, effectively leveraging both the sparsity and the correlations of the channels in the global angular-delay domain. Simulation results validate the effectiveness and superiority of the proposed SBL-GNNs algorithm over existing methods, demonstrating improved estimation performance and reduced computational complexity.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else</title>
<link>https://arxiv.org/abs/2501.17089</link>
<guid>https://arxiv.org/abs/2501.17089</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Credentials (可验证凭证), Revocation, CRSet, Bloom filter cascade, Ethereum blockchain

总结:
本文提出了CRSet，一种新的可验证凭证（Verifiable Credentials）撤销机制，旨在解决现有撤销方案如Bitstring Status List存在的隐私泄露问题。CRSet利用Bloom过滤器级联和填充技术，保护了发行者、依赖方和主体的元数据隐私。它允许发行者将撤销信息编码为Bloom过滤器并定期发布到去中心化存储系统，例如以太坊区块链，从而使得依赖方可以本地执行撤销检查。该原型系统使用以太坊区块链的廉价数据写入功能直接写入每个CRSet，并已成功与现有的公开钱包代理和OpenID for Verifiable Credentials协议进行端到端测试。虽然CRSet相对于其他方案会增加发行者和依赖方的存储及带宽成本，但对于每年发放数十万份凭证并需长期覆盖撤销状态的发行者而言，这些成本仍然可控，大约在1MB左右。 <div>
arXiv:2501.17089v1 Announce Type: new 
Abstract: Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics. For instance, exact staff fluctuation through issuance and revocation of employee IDs. We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade. Padding is used to provide deniability for issuer metrics. Issuers periodically publish this filter cascade on a decentralized storage system. Relying Parties (RPs) can download it to perform any number of revocation checks locally. Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally. At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications. We present a prototype using the Ethereum blockchain as decentralized storage. The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain. We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols. Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square</title>
<link>https://arxiv.org/abs/2501.16690</link>
<guid>https://arxiv.org/abs/2501.16690</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式部分观察马尔科夫决策问题(POMDP), 合作智能体, 长期平均奖励准则, 量子纠缠态, 量子优势

总结:
该文研究了一个多智能体合作的分布式部分观察马尔科夫决策问题(POMDP)，目标是最化长期平均奖励准则。文章指出，在固定速率提供的产品量子系统中，各智能体之间存在量子纠缠态，相比于提供公共随机性的情况，能够实现严格性能提升，即在分布式控制中存在量子优势。这一发现源自对著名Mermin-Peres广场结论的重新诠释，该结论构成了Mermin-Peres游戏的基础。虽然以前已经展示过此类一次性团队问题中的量子优势，但本文揭示了在动态场景下依然存在量子优势的现象，这是相对于当前关于分布式控制问题可达到性能认知的一个新颖发现。本文是对Pravin P. Varaiya教授致敬之作。 <div>
arXiv:2501.16690v1 Announce Type: cross 
Abstract: Consider a decentralized partially-observed Markov decision problem (POMDP) with multiple cooperative agents aiming to maximize a long-term-average reward criterion. We observe that the availability, at a fixed rate, of entangled states of a product quantum system between the agents, where each agent has access to one of the component systems, can result in strictly improved performance even compared to the scenario where common randomness is provided to the agents, i.e. there is a quantum advantage in decentralized control. This observation comes from a simple reinterpretation of the conclusions of the well-known Mermin-Peres square, which underpins the Mermin-Peres game. While quantum advantage has been demonstrated earlier in one-shot team problems of this kind, it is notable that there are examples where there is a quantum advantage for the one-shot criterion but it disappears in the dynamical scenario. The presence of a quantum advantage in dynamical scenarios is thus seen to be a novel finding relative to the current state of knowledge about the achievable performance in decentralized control problems.
  This paper is dedicated to the memory of Pravin P. Varaiya.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Gradient-Free Methods for Stochastic Non-Smooth Non-Convex Optimization</title>
<link>https://arxiv.org/abs/2310.11973</link>
<guid>https://arxiv.org/abs/2310.11973</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式无梯度优化、非光滑非凸函数、Decentralized Gradient-Free Method (DGFM)、DGFM$^+$、复杂性

总结:

本文研究了在不满足平滑性和凸性假设的情况下，对Lipschitz连续函数进行分布式无梯度优化的问题。文章提出了两种新的无梯度算法，即Decentralized Gradient-Free Method (DGFM)及其改进版DGFM$^+$。DGFM利用随机平滑和梯度跟踪技术，只需在每轮迭代中计算单个样本的零阶oracle，降低了对各个计算节点的计算资源需求。理论上，DGFM达到了获取$(\delta,\varepsilon)$-Goldstein稳定点的复杂度为$\mathcal O(d^{3/2}\delta^{-1}\varepsilon ^{-4})$。而DGFM$^+$通过引入方差减少进一步提升了收敛性能，它在每次迭代时使用小批量样本并周期性地采集更大的数据批处理，将复杂度改进到$\mathcal O(d^{3/2}\delta^{-1} \varepsilon^{-3})$。实验结果表明，所提出的算法在实际世界数据集上具有显著的实践经验优势。 <div>
arXiv:2310.11973v2 Announce Type: replace-cross 
Abstract: We consider decentralized gradient-free optimization of minimizing Lipschitz continuous functions that satisfy neither smoothness nor convexity assumption. We propose two novel gradient-free algorithms, the Decentralized Gradient-Free Method (DGFM) and its variant, the Decentralized Gradient-Free Method$^+$ (DGFM$^{+}$). Based on the techniques of randomized smoothing and gradient tracking, DGFM requires the computation of the zeroth-order oracle of a single sample in each iteration, making it less demanding in terms of computational resources for individual computing nodes. Theoretically, DGFM achieves a complexity of $\mathcal O(d^{3/2}\delta^{-1}\varepsilon ^{-4})$ for obtaining an $(\delta,\varepsilon)$-Goldstein stationary point. DGFM$^{+}$, an advanced version of DGFM, incorporates variance reduction to further improve the convergence behavior. It samples a mini-batch at each iteration and periodically draws a larger batch of data, which improves the complexity to $\mathcal O(d^{3/2}\delta^{-1} \varepsilon^{-3})$. Moreover, experimental results underscore the empirical advantages of our proposed algorithms when applied to real-world datasets.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Social Media Data and Artificial Intelligence for Improving Earthquake Response Efforts</title>
<link>https://arxiv.org/abs/2501.14767</link>
<guid>https://arxiv.org/abs/2501.14767</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交媒体、人工智能、灾难管理、地震响应、实时信息分享

总结:<br />
本文探讨了社交媒体与人工智能在灾难管理中的整合，特别是在地震应对方面的应用。随着数字时代实时信息分享达到前所未有的水平，社交平台已成为危机期间关键的沟通渠道，促使传统集中式的应急服务向更加分散和参与式的灾害态势感知模式转变。研究分析了2024年2月2日发生在俄克拉荷马州的一次5.1级地震后，X（原Twitter）上8,900条社交媒体互动数据，包括2,920条帖子和5,980条回复。数据分析涵盖了灾后的即时阶段直至接下来的七天，显示了数字平台在现代紧急应对中作为实时态势感知工具的关键作用，能有效为社会和当局提供关键信息。 <div>
arXiv:2501.14767v1 Announce Type: new 
Abstract: The integration of social media and artificial intelligence (AI) into disaster management, particularly for earthquake response, represents a profound evolution in emergency management practices. In the digital age, real-time information sharing has reached unprecedented levels, with social media platforms emerging as crucial communication channels during crises. This shift has transformed traditional, centralized emergency services into more decentralized, participatory models of disaster situational awareness. Our study includes an experimental analysis of 8,900 social media interactions, including 2,920 posts and 5,980 replies on X (formerly Twitter), following a magnitude 5.1 earthquake in Oklahoma on February 2, 2024. The analysis covers data from the immediate aftermath and extends over the following seven days, illustrating the critical role of digital platforms in modern disaster response. The results demonstrate that social media platforms can be effectively used as real-time situational awareness tools, delivering critical information to society and authorities during emergencies.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Supply Chain Resilience with Metaverse and ChatGPT Technologies</title>
<link>https://arxiv.org/abs/2501.14777</link>
<guid>https://arxiv.org/abs/2501.14777</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19、俄乌冲突、供应链韧性、Metaverse、ChatGPT

总结:<br />
文章指出了COVID-19疫情和俄乌冲突对全球供应链的严重影响，强调了提升供应链韧性的紧迫性。供应链韧性包括应对内部和外部如自然灾害、战争等造成的中断。文章提出，新型数字技术——Metaverse和ChatGPT为解决这些问题提供了有前景的方案。Metaverse通过整合区块链、物联网等技术，能够模拟现实情况并实时动态展示供应链数据；而大型自然语言处理模型ChatGPT能提高信息传递的速度与准确性，有助于风险管理及供应链决策。研究旨在阐明ChatGPT和Metaverse技术对于提升供应链韧性的价值，并关注对供应链发展具有直接影响的关键标准和成熟度因素。 <div>
arXiv:2501.14777v1 Announce Type: new 
Abstract: Global supply lines have been severely disrupted by the COVID-19 epidemic and the conflict between Russia and Ukraine, which has sharply increased the price of commodities and generated inflation. These incidents highlight how critical it is to improve supply chain resilience (SCRES) in order to fend off unforeseen setbacks. Controlling both internal and external interruptions, such as transportation problems brought on by natural catastrophes and wars, is the responsibility of SCRES. Enhancing resilience in supply chains requires accurate and timely information transfer.
  Promising answers to these problems can be found in the Metaverse and ChatGPT, two new digital technologies. The Metaverse may imitate real-world situations and offer dynamic, real-time 3D representations of supply chain data by integrating blockchain, IoT, network connection, and computer power.Large-scale natural language processing model ChatGPT improves communication and data translation accuracy and speed. To manage risk and facilitate decision making in Supply Chain management, firms should increase information transmission, Speed and quality. This study aim to show the importance of ChatGPT and Metaverse technologies to improve SCRES, with an emphasis on the most important criteria for SCRES, and maturity factor that can influence directly the SC development.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeServe: Towards Affordable Offline LLM Inference via Decentralization</title>
<link>https://arxiv.org/abs/2501.14784</link>
<guid>https://arxiv.org/abs/2501.14784</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成式AI、大型语言模型、GPU资源、去中心化、DeServe

总结:
本文介绍了随着生成式AI的迅速发展和日常工作的广泛应用，大型语言模型（LLM）推理服务的需求大幅增长。尽管专有模型仍然受到青睐，但最近开源LLM的进步使其成为有力竞争者。然而，部署这些模型常常受限于高昂的GPU资源成本和有限的可用性。为解决这一问题，文章提出了一个名为DeServe的去中心化离线LLM推理系统设计，该系统利用闲置GPU资源，以更低的成本实现对LLM的访问分散。DeServe特别关注并优化了在网络延迟高的环境下的服务吞吐量。实验结果显示，在此类条件下，DeServe相比现有服务系统基线实现了6.7x至12.6x的吞吐量提升。 <div>
arXiv:2501.14784v1 Announce Type: new 
Abstract: The rapid growth of generative AI and its integration into everyday workflows have significantly increased the demand for large language model (LLM) inference services. While proprietary models remain popular, recent advancements in open-source LLMs have positioned them as strong contenders. However, deploying these models is often constrained by the high costs and limited availability of GPU resources. In response, this paper presents the design of a decentralized offline serving system for LLM inference. Utilizing idle GPU resources, our proposed system, DeServe, decentralizes access to LLMs at a lower cost. DeServe specifically addresses key challenges in optimizing serving throughput in high-latency network environments. Experiments demonstrate that DeServe achieves a 6.7x-12.6x improvement in throughput over existing serving system baselines in such conditions.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer</title>
<link>https://arxiv.org/abs/2501.14931</link>
<guid>https://arxiv.org/abs/2501.14931</guid>
<content:encoded><![CDATA[
<div> 关键词：pod、区块链延迟、传统共识协议、交易确认、安全属性

总结:
<br />
本文提出了一种名为pod的新颖共识概念，旨在解决区块链中的高延迟问题和传统共识协议的低可扩展性。pod通过消除副本间的通信，使客户端直接将交易发送给所有副本，每个副本独立处理并将其追加到日志中，随后客户端从这些日志中提取信息，实现了仅需一轮往返的物理最优延迟（即一次写入交易和一次读取交易）。然而，由于存在现有下界，该构造实现的性质弱于完全有序广播协议。文中对pod原语进行了建模并定义了其安全性属性，并证明了pod-core构建满足如在$2\delta$内完成交易确认、抵抗拜占庭式副本的审查以及对安全违规行为的责任追究等属性。此外，文章还展示了包括支付系统、拍卖和去中心化数据存储等多种应用可以基于pod原语进行构建。 <div>
arXiv:2501.14931v1 Announce Type: new 
Abstract: This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically optimal latency of one round trip, i.e., requiring only one round for writing a new transaction and one round for reading it. To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, each replica independently processes transactions and appends them to its log, and then clients receive and extract information from these logs. The replicas employ techniques such as transaction timestamping and replica-log sequencing, which allow clients to extract valuable information about the transactions and the state of the system.
  Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then prove that our pod-core construction satisfies properties such as transaction confirmation within $2\delta$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that a wire range of applications, such as payment systems, auctions, and decentralized data stores, can be based on a pod primitive.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Proof-Producing Compiler for Blockchain Applications</title>
<link>https://arxiv.org/abs/2501.15002</link>
<guid>https://arxiv.org/abs/2501.15002</guid>
<content:encoded><![CDATA[
<div> 关键词：CairoZero、编程语言、区块链、编译器、形式验证

总结:
CairoZero是一种用于大规模运行去中心化应用（dApps）的编程语言，其程序可以被编译为Cairo CPU架构的机器码，并利用加密协议在区块链上高效验证执行结果。文章介绍了如何将CairoZero编译器扩展并集成了工具链，使得用户能够在Lean 3证明助手内证明编译后的代码满足高级功能规范。通过实例，他们展示了对大域有限字段上的secp256k1和secp256r1曲线计算以及使用前者进行签名验证等基础算法的形式验证。此外，还验证了在只读环境中模拟读写字典数据结构的方法。最后，作者反思了他们的方法论并讨论了所采用方法的一些优势。 <div>
arXiv:2501.15002v1 Announce Type: new 
Abstract: CairoZero is a programming language for running decentralized applications (dApps) at scale. Programs written in the CairoZero language are compiled to machine code for the Cairo CPU architecture and cryptographic protocols are used to verify the results of execution efficiently on blockchain. We explain how we have extended the CairoZero compiler with tooling that enables users to prove, in the Lean 3 proof assistant, that compiled code satisfies high-level functional specifications. We demonstrate the success of our approach by verifying primitives for computation with the secp256k1 and secp256r1 curves over a large finite field as well as the validation of cryptographic signatures using the former. We also verify a mechanism for simulating a read-write dictionary data structure in a read-only setting. Finally, we reflect on our methodology and discuss some of the benefits of our approach.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Distributed Backdoor Attacks with Network Detection in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.15005</link>
<guid>https://arxiv.org/abs/2501.15005</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式后门攻击、去中心化联邦学习、攻击成功率、距离预测、动态嵌入

<br /><br />总结:
本文研究了分布式后门攻击（DBA）在去中心化联邦学习中的影响。实验表明，DBA在去中心化FL中的攻击成功率受到攻击者在网络架构中分布的影响。为了解决这一问题，文章提出了一个方法，通过预测网络上任意两个攻击者之间的距离来检测网络，并根据这些距离将攻击者组织成不同的聚类。进一步地，文章提出了一种动态算法，将全球模式分解得到的局部模式嵌入到每个聚类的不同攻击者中。通过对基准数据集进行深入的实证研究，文章发现其方法在不同去中心化框架下可以优于集中式攻击和朴素的DBA。 <div>
arXiv:2501.15005v1 Announce Type: new 
Abstract: Distributed backdoor attacks (DBA) have shown a higher attack success rate than centralized attacks in centralized federated learning (FL). However, it has not been investigated in the decentralized FL. In this paper, we experimentally demonstrate that, while directly applying DBA to decentralized FL, the attack success rate depends on the distribution of attackers in the network architecture. Considering that the attackers can not decide their location, this paper aims to achieve a high attack success rate regardless of the attackers' location distribution. Specifically, we first design a method to detect the network by predicting the distance between any two attackers on the network. Then, based on the distance, we organize the attackers in different clusters. Lastly, we propose an algorithm to \textit{dynamically} embed local patterns decomposed from a global pattern into the different attackers in each cluster. We conduct a thorough empirical investigation and find that our method can, in benchmark datasets, outperform both centralized attacks and naive DBA in different decentralized frameworks.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Client Selection in Federated Learning: A Network Anomaly Detection Use Case</title>
<link>https://arxiv.org/abs/2501.15038</link>
<guid>https://arxiv.org/abs/2501.15038</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、客户端选择、差分隐私、容错机制、模型性能

<br /><br />总结:
本文介绍了一种结合了差分隐私和容错机制的联邦学习（Federated Learning）客户端选择框架。该自适应方法根据模型性能和系统约束动态调整所选客户端数量，通过添加校准噪声以确保数据隐私。在使用UNSW-NB15和ROAD数据集进行网络异常检测的案例研究中，相比于FedL2P方法，实验结果显示该方法能提升最多7%的准确性并减少高达25%的训练时间。同时，研究揭示了隐私预算与模型性能之间的权衡关系，提高隐私预算可降低噪声并提升精度。虽然容错机制会导致轻微的性能下降，但增强了对客户端失效的鲁棒性。通过对结果进行Mann-Whitney U检验，证实了这些改进的显著性，其p值小于0.05。 <div>
arXiv:2501.15038v1 Announce Type: new 
Abstract: Federated Learning (FL) has become a widely used approach for training machine learning models on decentralized data, addressing the significant privacy concerns associated with traditional centralized methods. However, the efficiency of FL relies on effective client selection and robust privacy preservation mechanisms. Ineffective client selection can result in suboptimal model performance, while inadequate privacy measures risk exposing sensitive data.
  This paper introduces a client selection framework for FL that incorporates differential privacy and fault tolerance. The proposed adaptive approach dynamically adjusts the number of selected clients based on model performance and system constraints, ensuring privacy through the addition of calibrated noise.
  The method is evaluated on a network anomaly detection use case using the UNSW-NB15 and ROAD datasets. Results demonstrate up to a 7% improvement in accuracy and a 25% reduction in training time compared to the FedL2P approach. Additionally, the study highlights trade-offs between privacy budgets and model performance, with higher privacy budgets leading to reduced noise and improved accuracy. While the fault tolerance mechanism introduces a slight performance decrease, it enhances robustness against client failures. Statistical validation using the Mann-Whitney U test confirms the significance of these improvements, with results achieving a p-value of less than 0.05.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NetChain: Authenticated Blockchain Top-k Graph Data Queries and its Application in Asset Management</title>
<link>https://arxiv.org/abs/2501.15077</link>
<guid>https://arxiv.org/abs/2501.15077</guid>
<content:encoded><![CDATA[
<div> 关键词：图数据、区块链、verifiable boolean查询、NetChain、NetChain+

总结:
本文提出了一个新的框架NetChain，用于实现区块链上图数据的高效top-k查询并保证可验证性。NetChain设计了一种新型的认证两层索引，能够在块级别生成存在/非存在证明，并为匹配对象内置可验证性。为了进一步降低计算和验证开销，文章还衍生出了优化版本NetChain+。通过安全分析验证了这两个框架的真实性。实验结果显示，相比于现有的vChain方案，NetChain在ADS构造方面提高了最多85倍的性能，而NetChain+则将通信和验证成本分别降低了87%和96%。 <div>
arXiv:2501.15077v1 Announce Type: new 
Abstract: As a valuable digital resource, graph data is an important data asset, which has been widely utilized across various fields to optimize decision-making and enable smarter solutions. To manage data assets, blockchain is widely used to enable data sharing and trading, but it cannot supply complex analytical queries. vChain was proposed to achieve verifiable boolean queries over blockchain by designing an embedded authenticated data structure (ADS). However, for generating (non-)existence proofs, vChain suffers from expensive storage and computation costs in ADS construction, along with high communication and verification costs. In this paper, we propose a novel NetChain framework that enables efficient top-k queries over on-chain graph data with verifiability. Specifically, we design a novel authenticated two-layer index that supports (non-)existence proof generation in block-level and built-in verifiability for matched objects. To further alleviate the computation and verification overhead, an optimized variant NetChain+ is derived. The authenticity of our frameworks is validated through security analysis. Evaluations show that NetChain and NetChain+ outperform vChain, respectively achieving up to 85X and 31X improvements on ADS construction. Moreover, compared with vChain, NetChain+ reduces the communication and verification costs by 87% and 96% respectively.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Decentralized Learning with Teleportation</title>
<link>https://arxiv.org/abs/2501.15259</link>
<guid>https://arxiv.org/abs/2501.15259</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized SGD、通信成本、收敛率、TELEPORTATION、超参数调优

总结:
本文主要探讨了去中心化SGD（随机梯度下降）在大量节点情况下的通信效率问题和收敛速度减慢的现象。为解决这一问题，文章提出了名为“TELEPORTATION”的新方法。TELEPORTATION仅激活一部分节点，并使这些活跃节点从前一次活跃的节点获取参数，随后使用SGD更新参数并在一个小规模的、仅包含活跃节点的拓扑结构上进行 gossip 平均操作。通过适当地选择激活节点的数量，TELEPORTATION能够完全缓解收敛率降低的问题。此外，文中还提出了一种有效的超参数调优方法来寻找合适的激活节点数量。实验结果显示，与传统的去中心化SGD相比，TELEPORTATION能更稳定地训练神经网络并实现更高的准确性。 <div>
arXiv:2501.15259v1 Announce Type: new 
Abstract: Decentralized SGD can run with low communication costs, but its sparse communication characteristics deteriorate the convergence rate, especially when the number of nodes is large. In decentralized learning settings, communication is assumed to occur on only a given topology, while in many practical cases, the topology merely represents a preferred communication pattern, and connecting to arbitrary nodes is still possible. Previous studies have tried to alleviate the convergence rate degradation in these cases by designing topologies with large spectral gaps. However, the degradation is still significant when the number of nodes is substantial. In this work, we propose TELEPORTATION. TELEPORTATION activates only a subset of nodes, and the active nodes fetch the parameters from previous active nodes. Then, the active nodes update their parameters by SGD and perform gossip averaging on a relatively small topology comprising only the active nodes. We show that by activating only a proper number of nodes, TELEPORTATION can completely alleviate the convergence rate degradation. Furthermore, we propose an efficient hyperparameter-tuning method to search for the appropriate number of nodes to be activated. Experimentally, we showed that TELEPORTATION can train neural networks more stably and achieve higher accuracy than Decentralized SGD.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Two-Stage CAE-Based Federated Learning Framework for Efficient Jamming Detection in 5G Networks</title>
<link>https://arxiv.org/abs/2501.15288</link>
<guid>https://arxiv.org/abs/2501.15288</guid>
<content:encoded><![CDATA[
<div> 关键词: 5G网络安全、复杂干扰攻击、分布式学习、联邦学习、卷积自编码器

总结:
<br />
针对5G网络中日益严重的复杂干扰攻击问题以及对无线电频率领域安全性的威胁，本文提出了一种用于5G微小区干扰检测的分散式两阶段联邦学习框架。该框架采用联邦平均（FedAVG）算法训练卷积自编码器（CAE），实现无监督学习，随后利用预训练的CAE编码器构建全连接网络（FCN），并采用联邦亲和（FedProx）算法进行有监督分类。实验结果表明，该框架能够在非独立同分布客户端数据集上实现高效训练和预测，同时保护了数据隐私。具体来说，该框架在仅需30轮通信的情况下达到了较高的性能指标：精确度为0.94、召回率为0.90、F1分数为0.92、准确度为0.92，并在拥有6个客户端的情况下实现了检测干扰信号的稳健收敛。 <div>
arXiv:2501.15288v1 Announce Type: new 
Abstract: Cyber-security for 5G networks is drawing notable attention due to an increase in complex jamming attacks that could target the critical 5G Radio Frequency (RF) domain. These attacks pose a significant risk to heterogeneous network (HetNet) architectures, leading to degradation in network performance. Conventional machine-learning techniques for jamming detection rely on centralized training while increasing the odds of data privacy. To address these challenges, this paper proposes a decentralized two-stage federated learning (FL) framework for jamming detection in 5G femtocells. Our proposed distributed framework encompasses using the Federated Averaging (FedAVG) algorithm to train a Convolutional Autoencoder (CAE) for unsupervised learning. In the second stage, we use a fully connected network (FCN) built on the pre-trained CAE encoder that is trained using Federated Proximal (FedProx) algorithm to perform supervised classification. Our experimental results depict that our proposed framework (FedAVG and FedProx) accomplishes efficient training and prediction across non-IID client datasets without compromising data privacy. Specifically, our framework achieves a precision of 0.94, recall of 0.90, F1-score of 0.92, and an accuracy of 0.92, while minimizing communication rounds to 30 and achieving robust convergence in detecting jammed signals with an optimal client count of 6.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ExClique: An Express Consensus Algorithm for High-Speed Transaction Process in Blockchains</title>
<link>https://arxiv.org/abs/2501.15289</link>
<guid>https://arxiv.org/abs/2501.15289</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof of Authority (PoA)，Clique，Express Clique (ExClique)，transactions per second (TPS)，共识节点

总结:
本文探讨了Proof of Authority (PoA)中Clique共识机制在处理交易速度上的局限性，主要受限于全块通信延迟及无轮次区块的产生。针对这些问题，文章提出了一个新的算法——Express Clique (ExClique)，它通过压缩区块以缩短广播通信延迟并避免无轮次区块的出现来优化Clique。实验结果显示，相较于Clique，ExClique在网络中显著提升了事务处理速度（TPS），在拥有21个共识节点的典型网络中提升至2.25倍，而在拥有101个共识节点的大规模网络中更是达到了惊人的7.01倍提升。 <div>
arXiv:2501.15289v1 Announce Type: new 
Abstract: Proof of Authority (PoA) plays a pivotal role in blockchains for reaching consensus. Clique, which selects consensus nodes to generate blocks with a pre-determined order, is the most popular implementation of PoA due to its low communication overhead and energy consumption. However, our study unveils that the speed to process transactions by Clique is severely restricted by 1) the long communication delay of full blocks (each containing a certain number of transactions) between consensus nodes; and 2) occurrences of no-turn blocks, generated by no-turn nodes if an in-turn block generation fails. Consequently, Clique struggles to support distributed applications requiring a high transaction processing speed, e.g., online gaming. To overcome this deficiency, we propose an Express Clique (ExClique) algorithm by improving Clique from two perspectives: compacting blocks for broadcasting to shorten communication delay and prohibiting the occurrences of no-turn blocks. For performance evaluation, we implement ExClique by modifying Geth of Ethereum, the software implementing Clique, and deploy a permissioned blockchain network by using container technology. The experimental results show that ExClique achieves a substantial enhancement in transactions per second (TPS). Specifically, it boosts TPS by 2.25X in a typical network with 21 consensus nodes and an impressive 7.01X in a large-scale network with 101 consensus nodes when compared to Clique.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Post-Processing-Based Fair Federated Learning Framework</title>
<link>https://arxiv.org/abs/2501.15318</link>
<guid>https://arxiv.org/abs/2501.15318</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Fairness, Post-Processing, Decentralized Debiasing, Data Heterogeneity

总结:
<br />
本文提出了一种简单直观的后处理框架，用于提高联邦学习系统中的群体公平性。该框架包括两个阶段：标准的联邦学习训练阶段和完全去中心化的本地去偏阶段。首先，使用如FedAvg的标准联邦学习算法，在无公平约束的情况下训练全局模型。接着，每个客户端利用其局部数据对全局模型进行公平性后处理，以实现基于客户端特定需求和上下文引导的公平性改进。文章探讨了两种成熟的后处理技术在这个框架中的应用：模型输出后处理和最终层微调。通过对四种不同数据集（包括表格、信号和图像数据）的评估，结果显示该框架不仅简化了联邦学习中公平性的实现，而且在最小化准确率损失甚至提高准确率的同时，显著提升了公平性表现，尤其在数据异质性较高的场景下效果更为明显。 <div>
arXiv:2501.15318v1 Announce Type: new 
Abstract: Federated Learning (FL) allows collaborative model training among distributed parties without pooling local datasets at a central server. However, the distributed nature of FL poses challenges in training fair federated learning models. The existing techniques are often limited in offering fairness flexibility to clients and performance. We formally define and empirically analyze a simple and intuitive post-processing-based framework to improve group fairness in FL systems. This framework can be divided into two stages: a standard FL training stage followed by a completely decentralized local debiasing stage. In the first stage, a global model is trained without fairness constraints using a standard federated learning algorithm (e.g. FedAvg). In the second stage, each client applies fairness post-processing on the global model using their respective local dataset. This allows for customized fairness improvements based on clients' desired and context-guided fairness requirements. We demonstrate two well-established post-processing techniques in this framework: model output post-processing and final layer fine-tuning. We evaluate the framework against three common baselines on four different datasets, including tabular, signal, and image data, each with varying levels of data heterogeneity across clients. Our work shows that this framework not only simplifies fairness implementation in FL but also provides significant fairness improvements with minimal accuracy loss or even accuracy gain, across data modalities and machine learning methods, being especially effective in more heterogeneous settings.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Low-Rank Fine-Tuning of Large Language Models</title>
<link>https://arxiv.org/abs/2501.15361</link>
<guid>https://arxiv.org/abs/2501.15361</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 参数效率优化 (PEFT), 低秩适应 (LoRA), 联邦学习 (FL), 分布式学习

总结:
本文介绍了针对大型语言模型（如GPT-4、LLaMA和BERT）的一种新型分布式、隐私保护的微调算法——\texttt{Dec-LoRA}。该算法基于低秩适应（LoRA）的方法进行去中心化微调。现有的参数效率优化技术（如LoRA）通常依赖于集中式的数据与训练环境，而实际场景中往往涉及分布广泛且敏感的数据集，需要采用去中心化的解决方案。文章指出联邦学习虽能解决数据隐私问题，但其仍需中心化的参数服务器进行协调，可能造成瓶颈和通信约束。相反，分布式学习消除了这一依赖，通过客户端间的直接协作提升在分布式环境下的可扩展性和效率。然而，对于分布式环境下LLM的去中心化微调研究尚不充分。通过对BERT和LLaMA-2模型进行大量实验，\texttt{Dec-LoRA}展示了其在处理数据异质性及量化约束方面的性能优势，为实现可扩展且保护隐私的LLM微调提供了新的可能性。 <div>
arXiv:2501.15361v1 Announce Type: new 
Abstract: The emergence of Large Language Models (LLMs) such as GPT-4, LLaMA, and BERT has transformed artificial intelligence, enabling advanced capabilities across diverse applications. While parameter-efficient fine-tuning (PEFT) techniques like LoRA offer computationally efficient adaptations of these models, their practical deployment often assumes centralized data and training environments. However, real-world scenarios frequently involve distributed, privacy-sensitive datasets that require decentralized solutions. Federated learning (FL) addresses data privacy by coordinating model updates across clients, but it is typically based on centralized aggregation through a parameter server, which can introduce bottlenecks and communication constraints. Decentralized learning, in contrast, eliminates this dependency by enabling direct collaboration between clients, improving scalability and efficiency in distributed environments. Despite its advantages, decentralized LLM fine-tuning remains underexplored. In this work, we propose \texttt{Dec-LoRA}, an algorithm for decentralized fine-tuning of LLMs based on low-rank adaptation (LoRA). Through extensive experiments on BERT and LLaMA-2 models, we evaluate \texttt{Dec-LoRA}'s performance in handling data heterogeneity and quantization constraints, enabling scalable, privacy-preserving LLM fine-tuning in decentralized settings.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Potential of Large Language Models in Supply Chain Management: Advancing Decision-Making, Efficiency, and Innovation</title>
<link>https://arxiv.org/abs/2501.15411</link>
<guid>https://arxiv.org/abs/2501.15411</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、供应链管理、决策制定、预测分析、运营效率

<br />
总结:
本文探讨了大型语言模型（LLMs）在供应链管理（SCM）中的集成对行业产生的革命性影响。文章指出，LLMs通过提升决策制定、预测分析和运营效率等方面的能力，正改变着需求预测、库存管理、供应商关系管理和物流优化等多个SCM功能。此外，结合物联网、区块链和机器人等新兴技术，LLMs有助于构建更智能、自主的供应链。文中同时强调了伦理考量，包括偏见缓解和数据保护，以确保公平透明的人工智能实践。还讨论到需要培养员工应对AI驱动的新流程以及长期战略上采用LLMs的好处。针对SCM专业人士的战略建议包括投资高质量的数据管理、推动跨职能协作及使LLM举措与整体业务目标保持一致。文章最后指出，LLMs有望在不断变化的供应链管理领域中推动创新、可持续性和竞争优势。 <div>
arXiv:2501.15411v1 Announce Type: new 
Abstract: The integration of large language models (LLMs) into supply chain management (SCM) is revolutionizing the industry by improving decision-making, predictive analytics, and operational efficiency. This white paper explores the transformative impact of LLMs on various SCM functions, including demand forecasting, inventory management, supplier relationship management, and logistics optimization. By leveraging advanced data analytics and real-time insights, LLMs enable organizations to optimize resources, reduce costs, and improve responsiveness to market changes. Key findings highlight the benefits of integrating LLMs with emerging technologies such as IoT, blockchain, and robotics, which together create smarter and more autonomous supply chains. Ethical considerations, including bias mitigation and data protection, are taken into account to ensure fair and transparent AI practices. In addition, the paper discusses the need to educate the workforce on how to manage new AI-driven processes and the long-term strategic benefits of adopting LLMs. Strategic recommendations for SCM professionals include investing in high-quality data management, promoting cross-functional collaboration, and aligning LLM initiatives with overall business goals. The findings highlight the potential of LLMs to drive innovation, sustainability, and competitive advantage in the ever-changing supply chain management landscape.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FiberPool: Leveraging Multiple Blockchains for Decentralized Pooled Mining</title>
<link>https://arxiv.org/abs/2501.15459</link>
<guid>https://arxiv.org/abs/2501.15459</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、工作量证明、分布式挖矿池、P2Pool、SmartPool、FiberPool、公平性、预算平衡、奖励稳定性、激励相容

总结:<br />
本文提出了一个名为FiberPool的分布式挖矿池方案，旨在解决Proof of Work机制下区块链系统中集中式挖矿池对去中心化原则的破坏问题。FiberPool结合了主链上的智能合约、用于分享份额验证所需数据的存储链以及减少区块奖励使用和提现费用的子链。通过采用FiberPool Proportional支付方案，该研究验证了FiberPool在挖矿公平性、预算平衡、奖励稳定性及激励相容性方面的优势。相比于存在可扩展性和安全性问题的P2Pool以及非预算平衡并需支付高昂手续费的SmartPool，FiberPool提供了一种更优的解决方案。 <div>
arXiv:2501.15459v1 Announce Type: new 
Abstract: The security of blockchain systems based on Proof of Work relies on mining. However, mining suffers from unstable revenue, prompting many miners to form cooperative mining pools. Most existing mining pools operate in a centralized manner, which undermines the decentralization principle of blockchain. Distributed mining pools offer a practical solution to this problem. Well-known examples include P2Pool and SmartPool. However, P2Pool encounters scalability and security issues in its early stages. Similarly, SmartPool is not budget-balanced and imposes fees due to its heavy use of the smart contract. In this research, we present a distributed mining pool named FiberPool to address these challenges. FiberPool integrates a smart contract on the main chain, a storage chain for sharing data necessary for share verification, and a child chain to reduce fees associated with using and withdrawing block rewards. We validate the mining fairness, budget balance, reward stability, and incentive compatibility of the payment scheme FiberPool Proportional adopted by FiberPool.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedAlign: Federated Domain Generalization with Cross-Client Feature Alignment</title>
<link>https://arxiv.org/abs/2501.15486</link>
<guid>https://arxiv.org/abs/2501.15486</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Domain Generalization, FedAlign, 隐私保护, 特征多样性

<br /><br />总结:
本文介绍了一种针对联邦学习（Federated Learning）环境中领域泛化（Domain Generalization）问题的新框架FedAlign。该框架旨在通过增强特征多样性和促进领域不变性来提升联邦学习中的泛化能力。FedAlign包括两个关键模块：一是跨客户端特征扩展模块，它利用域不变特征扰动和选择性的跨客户端特征转移，安全地拓宽每个客户端的局部领域表示，增加域空间的丰富度；二是双阶段对齐模块，通过对客户端间的特征嵌入和预测进行对齐，从而提炼出更为稳健、域不变的特征。这一方法能够在保证数据隐私的同时，以较低的计算和通信开销实现对未见领域的优秀泛化性能。 <div>
arXiv:2501.15486v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized paradigm for collaborative model training without direct data sharing, yet it poses unique challenges for Domain Generalization (DG), including strict privacy constraints, non-i.i.d. local data, and limited domain diversity. We introduce FedAlign, a lightweight, privacy-preserving framework designed to enhance DG in federated settings by simultaneously increasing feature diversity and promoting domain invariance. First, a cross-client feature extension module broadens local domain representations through domain-invariant feature perturbation and selective cross-client feature transfer, allowing each client to safely access a richer domain space. Second, a dual-stage alignment module refines global feature learning by aligning both feature embeddings and predictions across clients, thereby distilling robust, domain-invariant features. By integrating these modules, our method achieves superior generalization to unseen domains while maintaining data privacy and operating with minimal computational and communication overhead.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real-CATS: A Practical Training Ground for Emerging Research on Cryptocurrency Cybercrime Detection</title>
<link>https://arxiv.org/abs/2501.15553</link>
<guid>https://arxiv.org/abs/2501.15553</guid>
<content:encoded><![CDATA[
<div> 关键词：Real-CATS、区块链交易安全、数据集、加密货币地址、人工智能检测方法

<br />
总结:
本文介绍了Real-CATS，一个现实世界的加密货币地址与交易档案数据集，旨在促进对区块链交易安全中由网络犯罪造成的威胁的研究。由于缺乏有效的实际地址数据集，当前对于网络犯罪检测的研究进展受阻。Real-CATS包括了来自真实报告的103,203个恶意地址和来自交易所客户的106,196个良性地址，具备C3R特性（全面性、可分类性、可定制性和现实世界可转移性），对实际的网络犯罪检测具有重要意义。该数据集提供了三个主要功能：评估检测方法的有效性、支持特征扩展以及为实际部署提供新的评价场景。此外，Real-CATS也为扩展网络犯罪度量研究提供了机会，尤其有利于缺乏加密货币知识背景的跨学科研究人员参与这一新兴领域的研究。该数据平台有望吸引更多研究人员关注并推动数字货币网络安全犯罪检测的研究工作。相关数据集可在https://github.com/sjdseu/Real-CATS获取。 <div>
arXiv:2501.15553v1 Announce Type: new 
Abstract: Cybercriminals pose a significant threat to blockchain trading security, causing $40.9 billion in losses in 2024. However, the lack of an effective real-world address dataset hinders the advancement of cybercrime detection research. The anti-cybercrime efforts of researchers from broader fields, such as statistics and artificial intelligence, are blocked by data scarcity. In this paper, we present Real-CATS, a Real-world dataset of Cryptocurrency Addresses with Transaction profileS, serving as a practical training ground for developing and assessing detection methods. Real-CATS comprises 103,203 criminal addresses from real-world reports and 106,196 benign addresses from exchange customers. It satifies the C3R characteristics (Comprehensiveness, Classifiability, Customizability, and Real-world Transferability), which are fundemental for practical detection of cryptocurrency cybercrime. The dataset provides three main functions: 1) effective evaluation of detection methods, 2) support for feature extensions, and 3) a new evaluation scenario for real-world deployment. Real-CATS also offers opportunities to expand cybercrime measurement studies. It is particularly beneficial for researchers without cryptocurrency-related knowledge to engage in this emerging research field. We hope that studies on cryptocurrency cybercrime detection will be promoted by an increasing number of cross-disciplinary researchers drawn to this versatile data platform. All datasets are available at https://github.com/sjdseu/Real-CATS
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Personalized Federated Learning with Control Systems for Enhanced Performance</title>
<link>https://arxiv.org/abs/2501.15728</link>
<guid>https://arxiv.org/abs/2501.15728</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, personalization, control systems, distributed data, model performance

总结:<br />
本文介绍了一种新的融合个性化联邦学习和鲁棒控制系统的框架。该框架旨在优化分布式数据环境中的学习过程和数据流控制，同时保证隐私。其核心在于利用个性化算法适应每个客户端的独特数据特性，提升模型对单个节点的准确性和相关性，而不影响整体系统性能。通过实时反馈与系统状态动态调整参数的控制系统，确保了网络中学习过程的稳定性和效率。实验结果表明，相较于标准联邦学习模型，这种集成系统在准确性、学习速度以及面对不同网络条件和数据分布时的系统稳健性方面表现出优势，尤其适用于需要高可靠性和精确度的场景。 <div>
arXiv:2501.15728v1 Announce Type: new 
Abstract: In the expanding field of machine learning, federated learning has emerged as a pivotal methodology for distributed data environments, ensuring privacy while leveraging decentralized data sources. However, the heterogeneity of client data and the need for tailored models necessitate the integration of personalization techniques to enhance learning efficacy and model performance. This paper introduces a novel framework that amalgamates personalized federated learning with robust control systems, aimed at optimizing both the learning process and the control of data flow across diverse networked environments. Our approach harnesses personalized algorithms that adapt to the unique characteristics of each client's data, thereby improving the relevance and accuracy of the model for individual nodes without compromising the overall system performance. To manage and control the learning process across the network, we employ a sophisticated control system that dynamically adjusts the parameters based on real-time feedback and system states, ensuring stability and efficiency. Through rigorous experimentation, we demonstrate that our integrated system not only outperforms standard federated learning models in terms of accuracy and learning speed but also maintains system integrity and robustness in face of varying network conditions and data distributions. The experimental results, obtained from a multi-client simulated environment with non-IID data distributions, underscore the benefits of integrating control systems into personalized federated learning frameworks, particularly in scenarios demanding high reliability and precision.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Selective Experience Sharing in Reinforcement Learning Enhances Interference Management</title>
<link>https://arxiv.org/abs/2501.15735</link>
<guid>https://arxiv.org/abs/2501.15735</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、干扰抑制、经验分享、去中心化训练、通信开销减少

<br /><br />总结：

本文提出了一种新颖的多智能体强化学习方法，用于实现小区间的干扰抑制。该方法中，每个基站配备一个智能体，根据其关联用户的信干噪比信息进行评估并选择性地与邻近智能体共享经验。这种策略使得训练和执行完全去中心化，同时最大限度地减少了智能体间的信息共享和通信开销。实验表明，该方法相较于现有的去中心化训练的多智能体强化学习技术表现更优。此外，即使将经验分享量减少75%，提出的算法仍能实现与全量经验分享算法相当的98%频谱效率。 <div>
arXiv:2501.15735v1 Announce Type: new 
Abstract: We propose a novel multi-agent reinforcement learning (RL) approach for inter-cell interference mitigation, in which agents selectively share their experiences with other agents. Each base station is equipped with an agent, which receives signal-to-interference-plus-noise ratio from its own associated users. This information is used to evaluate and selectively share experiences with neighboring agents. The idea is that even a few pertinent experiences from other agents can lead to effective learning. This approach enables fully decentralized training and execution, minimizes information sharing between agents and significantly reduces communication overhead, which is typically the burden of interference management. The proposed method outperforms state-of-the-art multi-agent RL techniques where training is done in a decentralized manner. Furthermore, with a 75% reduction in experience sharing, the proposed algorithm achieves 98% of the spectral efficiency obtained by algorithms sharing all experiences.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive AI-based Decentralized Resource Management in the Cloud-Edge Continuum</title>
<link>https://arxiv.org/abs/2501.15802</link>
<guid>https://arxiv.org/abs/2501.15802</guid>
<content:encoded><![CDATA[
<div> 关键词：资源管理、云边连续体、图神经网络、多智能体强化学习、混合分散框架

总结:<br />
本文提出了一种用于动态应用放置和资源管理的混合分散框架，旨在应对云边连续体中日益复杂的應用需求和动态特性带来的挑战。该框架利用图神经网络对资源和应用状态进行嵌入，以实现全面表示和高效的决策制定。通过采用协作式多智能体强化学习方法，局部代理能够在其邻域内优化资源管理，而全局编排器则确保系统范围内的协调。该框架结合了分散的应用放置与集中的监督控制，从而解决了云边连续体中固有的可扩展性、适应性和准确性问题。文章为高效、自适应和可扩展的资源管理研究贡献了解决方案，同时推动了分散应用放置策略、GNN嵌入以及协同MARL系统的发展。 <div>
arXiv:2501.15802v1 Announce Type: new 
Abstract: The increasing complexity of application requirements and the dynamic nature of the Cloud-Edge Continuum present significant challenges for efficient resource management. These challenges stem from the ever-changing infrastructure, which is characterized by additions, removals, and reconfigurations of nodes and links, as well as the variability of application workloads. Traditional centralized approaches struggle to adapt to these changes due to their static nature, while decentralized solutions face challenges such as limited global visibility and coordination overhead. This paper proposes a hybrid decentralized framework for dynamic application placement and resource management. The framework utilizes Graph Neural Networks (GNNs) to embed resource and application states, enabling comprehensive representation and efficient decision-making. It employs a collaborative multi-agent reinforcement learning (MARL) approach, where local agents optimize resource management in their neighborhoods and a global orchestrator ensures system-wide coordination. By combining decentralized application placement with centralized oversight, our framework addresses the scalability, adaptability, and accuracy challenges inherent in the Cloud-Edge Continuum. This work contributes to the development of decentralized application placement strategies, the integration of GNN embeddings, and collaborative MARL systems, providing a foundation for efficient, adaptive and scalable resource management.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Snowman for partial synchrony</title>
<link>https://arxiv.org/abs/2501.15904</link>
<guid>https://arxiv.org/abs/2501.15904</guid>
<content:encoded><![CDATA[
<div> 关键词: Snowman、共识协议、Avalanche、部分同步设置、本地消息延迟

总结:
本文描述了Snowman共识协议的一种修改版，该协议用于Avalanche区块链系统。原研究已在同步环境中为Snowman建立了概率一致性的确证，假设正确进程以“锁步”方式执行采样轮。新的工作则解决了在部分同步设置下的问题，允许正确进程根据其自身的速度进行连续采样轮，并考虑到由本地消息延迟决定的时间间隔。这一改进确保了协议在更具现实性的网络条件下的一致性。 <div>
arXiv:2501.15904v1 Announce Type: new 
Abstract: Snowman is the consensus protocol run by blockchains on Avalanche. Recent work established a rigorous proof of probabilistic consistency for Snowman in the \emph{synchronous} setting, under the simplifying assumption that correct processes execute sampling rounds in `lockstep'. In this paper, we describe a modification of the protocol that ensures consistency in the \emph{partially synchronous} setting, and when correct processes carry out successive sampling rounds at their own speed, with the time between sampling rounds determined by local message delays.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Brain-Inspired Decentralized Satellite Learning in Space Computing Power Networks</title>
<link>https://arxiv.org/abs/2501.15995</link>
<guid>https://arxiv.org/abs/2501.15995</guid>
<content:encoded><![CDATA[
<div> 关键词: 卫星网络、空间计算能力网络、Spiking神经网络、分布式神经元学习框架、通信效率

总结:
本文提出了一种解决卫星网络数据处理时效性问题的新方法，即利用空间计算能力网络（Space-CPN）协调卫星的计算能力进行在轨数据处理。针对卫星能源供应限制难以满足人工智能计算任务的需求，文章建议采用能效极高的脉冲神经网络（SNNs）进行在轨数据处理，并提出了一个基于神经形态计算架构的分布式神经元学习框架。该框架中，借鉴RelaySum思想开发了一种通信效率高的层间模型聚合方法，理论分析揭示了其收敛速度与网络直径的关系。为进一步优化学习性能，文章还对层间连接拓扑结构提出了一个最小直径生成树问题并进行了求解。实验结果显示，所提方法相较于基准方案具有显著优势。 <div>
arXiv:2501.15995v1 Announce Type: new 
Abstract: Satellite networks are able to collect massive space information with advanced remote sensing technologies, which is essential for real-time applications such as natural disaster monitoring. However, traditional centralized processing by the ground server incurs a severe timeliness issue caused by the transmission bottleneck of raw data. To this end, Space Computing Power Networks (Space-CPN) emerges as a promising architecture to coordinate the computing capability of satellites and enable on board data processing. Nevertheless, due to the natural limitations of solar panels, satellite power system is difficult to meet the energy requirements for ever-increasing intelligent computation tasks of artificial neural networks. To tackle this issue, we propose to employ spiking neural networks (SNNs), which is supported by the neuromorphic computing architecture, for on-board data processing. The extreme sparsity in its computation enables a high energy efficiency. Furthermore, to achieve effective training of these on-board models, we put forward a decentralized neuromorphic learning framework, where a communication-efficient inter-plane model aggregation method is developed with the inspiration from RelaySum. We provide a theoretical analysis to characterize the convergence behavior of the proposed algorithm, which reveals a network diameter related convergence speed. We then formulate a minimum diameter spanning tree problem on the inter-plane connectivity topology and solve it to further improve the learning performance. Extensive experiments are conducted to evaluate the superiority of the proposed method over benchmarks.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TOPLOC: A Locality Sensitive Hashing Scheme for Trustless Verifiable Inference</title>
<link>https://arxiv.org/abs/2501.16007</link>
<guid>https://arxiv.org/abs/2501.16007</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)、可信推理、TOPLOC、局部敏感哈希、验证速度

总结:
<br />
本文提出了一种名为TOPLOC的新方法，用于解决大型语言模型（LLMs）推理过程中的信任问题。TOPLOC利用紧凑型局部敏感哈希机制对中间激活值进行验证，能够以100%的准确率检测到模型、提示或精度的未经授权修改，且在实证评估中没有假阳性和假阴性结果。该方法具有跨不同硬件配置、GPU类型和代数重排的鲁棒性，并能实现比原始推理更快的验证速度。通过引入多项式编码方案，TOPLOC将生成的提交所需的内存开销减少了约1000倍，相比于直接存储Llama-3.1-8B-Instruct的词嵌入，仅需为每个新令牌存储258字节，而不再是262KB。这种方法使用户能够高效地验证LLM推理计算，从而增强开放生态系统的信任与透明度，为去中心化和可验证的人工智能服务奠定了基础。 <div>
arXiv:2501.16007v1 Announce Type: new 
Abstract: Large language models (LLMs) have proven to be very capable, but access to the best models currently rely on inference providers which introduces trust challenges -- how can we be sure that the provider is using the model configuration they claim? We propose TOPLOC, a novel method for verifiable inference that addresses this problem. TOPLOC leverages a compact locality sensitive hashing mechanism for intermediate activations which can detect unauthorized modifications to models, prompts, or precision with 100% accuracy, achieving no false positives or negatives in our empirical evaluations. Our approach is robust across diverse hardware configurations, GPU types, and algebraic reorderings, which allows for validation speeds significantly faster than the original inference. By introducing a polynomial encoding scheme, TOPLOC minimizes memory overhead of the generated commits by $1000\times$, requiring only 258 bytes of storage per 32 new tokens compared to the 262KB requirement of storing the token embeddings directly for Llama-3.1-8B-Instruct. Our method empowers users to verify LLM inference computations efficiently, fostering greater trust and transparency in open ecosystems and lays a foundation for decentralized and verifiable AI services.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Galaxy Era: Agent-based Simulation of Execution Tickets</title>
<link>https://arxiv.org/abs/2501.16090</link>
<guid>https://arxiv.org/abs/2501.16090</guid>
<content:encoded><![CDATA[
<div> 关键词: Execution Tickets、Ethereum、机制设计、拍卖驱动、去中心化

总结:
本文探讨了Execution Tickets作为以太坊区块空间分配机制演进的下一个步骤，研究了该机制应实现的核心目标——去中心化、MEV捕获和区块生产者激励相容性，并提出了相应的实践评估指标。文章分析了七个关键设计参数，包括票量、有效期、退款性、转售性、增强型预览、定价机制以及目标票额。通过评估四种定价机制并构建六种具体机制设计，文章使用基于代理的模拟进行了超过300次的运行实验。结果显示，拍卖驱动的格式（尤其是第二价格拍卖）在捕获MEV方面表现出色；设立二级市场有助于缓解中央集权问题；非到期票据可减少估值风险；取消退款性并不会显著影响性能；延长预览期能提高价格预测性和平滑度，但可能降低价格准确性。总的来说，该研究为Execution Tickets的机制设计提供了理论框架，并通过代理模拟实现了对不同机制设计选择的实际测试与探索性评价，为进一步优化以太坊区块空间分配中的MEV捕获、去中心化及运营效率平衡提供了有益见解。 <div>
arXiv:2501.16090v1 Announce Type: new 
Abstract: Execution Tickets are currently discussed as a next evolutionary step in Ethereum's block space allocation mechanism, separating consensus rewards from execution rewards and selling execution rights through a dedicated market. We present a theoretical framework identifying three core objectives for this mechanism - Decentralization, MEV capture, and Block Producer Incentive Compatibility - alongside practical metrics for evaluating each objective. To meet these goals, we explore seven key design parameters: ticket quantity, expiry, refundability, resalability, enhanced lookahead, pricing mechanism, and target ticket amount.
  We then evaluate four pricing mechanisms and construct six concrete mechanism designs from these parameters. To assess trade-offs in real-world conditions, we perform an agent-based simulation with over 300 runs. Our findings suggest that auction-driven formats, particularly second-price, excel in capturing significant MEV. The simulation also indicates that offering a secondary market can help alleviate centralization, since specialized ticket holders can enter and exit the market as needed.
  Non-expiring tickets show promise in reducing valuation risks, as ticket holders are not influenced by expiry-related discounting. Likewise, removing refundability simplifies the mechanism without notably impairing performance. Extended lookahead periods benefit price predictability and smoothness at a slight cost to price accuracy.
  Overall, this study provides a theoretical framework on the mechanism design space for Execution Tickets as well as a practical implementation of an agent-based simulation to test mechanism design choices. Further, it provides an exploratory evaluation of Execution Ticket mechanism designs, offering insights into optimal configurations that balance MEV capture, decentralization, and operational efficiency in Ethereum's block space allocation.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path Planning and Data Collection</title>
<link>https://arxiv.org/abs/2501.16098</link>
<guid>https://arxiv.org/abs/2501.16098</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习(MARL), 在线学习, 环境适应性, 保守Q学习(CQL), 模型泛化元学习(MAML)

总结:
本文提出了一种新颖的离线元强化学习算法，该算法结合了保守Q学习（CQL）和模型泛化元学习（MAML），以解决传统MARL在实际应用中的问题。CQL利用预收集的数据集实现离线训练，而MAML则保证了对动态网络配置和目标的可扩展性和适应性。文章提出了两种算法变体：独立训练（M-I-MARL）和集中训练分布式执行（M-CTDE-MARL）。模拟结果表明，所提出的算法优于传统方案，特别是M-CTDE-MARL在动态场景下比基准算法收敛速度提高了50%。该框架通过优化无人机轨迹和调度策略，提升了无线通信系统的可扩展性、鲁棒性和适应性。 <div>
arXiv:2501.16098v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) has been widely adopted in high-performance computing and complex data-driven decision-making in the wireless domain. However, conventional MARL schemes face many obstacles in real-world scenarios. First, most MARL algorithms are online, which might be unsafe and impractical. Second, MARL algorithms are environment-specific, meaning network configuration changes require model retraining. This letter proposes a novel meta-offline MARL algorithm that combines conservative Q-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline training by leveraging pre-collected datasets, while MAML ensures scalability and adaptability to dynamic network configurations and objectives. We propose two algorithm variants: independent training (M-I-MARL) and centralized training decentralized execution (M-CTDE-MARL). Simulation results show that the proposed algorithm outperforms conventional schemes, especially the CTDE approach that achieves 50 % faster convergence in dynamic scenarios than the benchmarks. The proposed framework enhances scalability, robustness, and adaptability in wireless communication systems by optimizing UAV trajectories and scheduling policies.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unveiling Ethereum's P2P Network: The Role of Chain and Client Diversity</title>
<link>https://arxiv.org/abs/2501.16236</link>
<guid>https://arxiv.org/abs/2501.16236</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、devp2p协议栈、区块链分叉、节点发现、客户端兼容性

总结:
本文针对Ethereum网络，基于devp2p协议栈构建，旨在通过共享P2P基础设施支持去中心化应用。然而，随着区块链分叉的增多，网络多样性增加，导致节点发现效率降低和复杂性提升。主网节点在建立昂贵的TCP连接、加密及协议握手之后才能区分来自不同区块链的对等节点。此外，客户端多样性的存在造成了协议不兼容和连接失败的问题。文章介绍了一种用于跟踪devp2p消息交换和客户端状态的监控工具，以分析连接动态和协议差异。研究发现，节点发现过程中的低效问题以及Geth在发现过程中出现的时间 out等问题，并强调了在评估合并后Ethereum网络的健康和性能时需要考虑链和客户端的多样性问题。 <div>
arXiv:2501.16236v1 Announce Type: new 
Abstract: The Ethereum network, built on the devp2p protocol stack, was designed to function as a "world computer" by supporting decentralized applications through a shared P2P infrastructure. However, the proliferation of blockchain forks has increased network diversity, complicating node discovery and reducing efficiency. Ethereum mainnet nodes cannot easily distinguish between peers from different blockchains until after establishing an expensive TCP connection, encryption, and protocol handshake. This inefficiency is further worsened by client diversity, where differences in software implementations cause protocol incompatibilities and connection failures. This paper introduces a monitoring tool that tracks devp2p message exchanges and client statuses to analyze connection dynamics and protocol variations. Our findings highlight issues such as inefficiencies in node discovery and client incompatibility, including timeouts in Geth during the discovery process. The study emphasizes the need to consider chain and client diversity when assessing the health and performance of the post-merge Ethereum network.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2011.04820</link>
<guid>https://arxiv.org/abs/2011.04820</guid>
<content:encoded><![CDATA[
<div> 关键词：移动机器人、人群导航、深度强化学习、分布式结构循环神经网络、模拟器到现实转移

总结:<br />
本文提出了一个用于移动机器人安全高效地穿越人类拥挤场景的新方法——分布式结构循环神经网络（DS-RNN）。该网络利用模型自由的深度强化学习进行训练，无需专家监督，能够推理空间和时间关系以适应复杂的人群导航决策。相比于以往假设所有代理动态已知且定义明确的方法，DS-RNN在部分可观测环境和密集人群中的表现更优。文章展示了DS-RNN在具有挑战性的人群导航场景中超越先前方法的效果，并成功将模拟环境中学习到的策略转移到了真实的TurtleBot 2i机器人上。更多详情可访问项目官网：https://sites.google.com/view/crowdnav-ds-rnn/home。 <div>
arXiv:2011.04820v4 Announce Type: replace 
Abstract: Safe and efficient navigation through human crowds is an essential capability for mobile robots. Previous work on robot crowd navigation assumes that the dynamics of all agents are known and well-defined. In addition, the performance of previous methods deteriorates in partially observable environments and environments with dense crowds. To tackle these problems, we propose decentralized structural-Recurrent Neural Network (DS-RNN), a novel network that reasons about spatial and temporal relationships for robot decision making in crowd navigation. We train our network with model-free deep reinforcement learning without any expert supervision. We demonstrate that our model outperforms previous methods in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i. For more information, please visit the project website at https://sites.google.com/view/crowdnav-ds-rnn/home.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Model Predictive Covariance Steering</title>
<link>https://arxiv.org/abs/2212.00398</link>
<guid>https://arxiv.org/abs/2212.00398</guid>
<content:encoded><![CDATA[
<div> 关键词: Distributed Model Predictive Covariance Steering (DiMPCS), 多智能体控制, 随机不确定性, 华森距离, 循环共识算法

总结:
本文提出了分布式模型预测协方差引导(DiMPCS)方法，用于多智能体系统在随机不确定性下的控制问题。该方法融合了协方差引导理论、分布式优化和模型预测控制(MPC)于一体，旨在实现安全、可扩展和去中心化的控制框架。首先，文章利用华森距离来引导多智能体系统的状态分布趋向于期望目标，并通过概率约束确保安全性。接着，通过对协方差引导采用扰动反馈策略参数化以及对安全约束进行可解近似的方式，将问题转化为有限维优化问题。为了解决这一问题，文中使用交替方向乘子法推导出了基于循环共识的分布式算法，并将其扩展到递归 Horizon 形式，从而形成了提出的 DiMPCS 算法。模拟实验表明，DiMPCS 在各种涉及数百个机器人的多机器人任务中表现出有效性，并通过与其他随机 MPC 方法的对比凸显其优越的可扩展性和性能。最后，硬件实验结果也在一个多机器人平台上验证了DiMPCS在实际系统中的适用性。相关实验视频可在https://youtu.be/tzWqOzuj2kQ观看。 <div>
arXiv:2212.00398v2 Announce Type: replace 
Abstract: This paper proposes Distributed Model Predictive Covariance Steering (DiMPCS) for multi-agent control under stochastic uncertainty. The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single framework that is safe, scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-agent system to desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized consensus-based algorithm using the Alternating Direction Method of Multipliers. This method is then extended to a receding horizon form, which yields the proposed DiMPCS algorithm. Simulation experiments on a variety of multi-robot tasks with up to hundreds of robots demonstrate the effectiveness of DiMPCS. The superior scalability and performance of the proposed method is also highlighted through a comparison against related stochastic MPC approaches. Finally, hardware results on a multi-robot platform also verify the applicability of DiMPCS on real systems. A video with all results is available in https://youtu.be/tzWqOzuj2kQ.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A theoretical basis for MEV</title>
<link>https://arxiv.org/abs/2302.02154</link>
<guid>https://arxiv.org/abs/2302.02154</guid>
<content:encoded><![CDATA[
<div> 关键词: Maximal Extractable Value (MEV), 公开区块链, 攻击, 智能合约, 理论基础

总结:
本文针对公开区块链上的Maximal Extractable Value (MEV)攻击进行了深入探讨，这类攻击涉及对手通过重排序、丢弃或插入交易块从智能合约中“抽取”价值。实证研究显示，主流DeFi协议正大规模遭受此类攻击，对用户和区块链网络产生负面影响。鉴于这些攻击的实际影响日益增大，文章提出了一种基于抽象区块链和智能合约模型的MEV正式理论框架。该理论为证明抵御MEV攻击的安全性奠定了基础。<br /><br /> <div>
arXiv:2302.02154v4 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) refers to a wide class of economic attacks to public blockchains, where adversaries with the power to reorder, drop or insert transactions in a block can "extract" value from smart contracts. Empirical research has shown that mainstream DeFi protocols are massively targeted by these attacks, with detrimental effects on their users and on the blockchain network. Despite the increasing real-world impact of these attacks, their theoretical foundations remain insufficiently established. We propose a formal theory of MEV, based on a general, abstract model of blockchains and smart contracts. Our theory is the basis for proofs of security against MEV attacks.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Market Makers for Cross-chain DeFi and Sharded Blockchains</title>
<link>https://arxiv.org/abs/2309.14290</link>
<guid>https://arxiv.org/abs/2309.14290</guid>
<content:encoded><![CDATA[
<div> 关键词: Uniswap、自动化市场制造商、常数产品流动性池、跨链、锁Swap<br /><br />总结:

本文关注的是Uniswap类的自动化市场制造商，特别是基于常数产品的流动性池在区块链上的运行。Uniswap的一个关键特性是交易者可以原子化地执行一系列资产交换，其间价格不会因其他交易者的操作而改变。然而，在跨链或分片区块链环境中，这一原子化执行功能并不直接可用，因为不同的流动性池分散在不同链或分片上。文章提出了一种新的功能描述和建议实现——“锁Swap”。该功能允许交易者锁定某个交换的价格保证，但可以在稍后决定是否进行交换。通过多个流动性池的应用，“锁Swap”确保了交易者在整个序列交换中的价格保证，并使这些价格成为交易者决定是否执行序列的依据，从而实质上为交易者提供了与序列原子化执行相同的益处。但是，与原子化执行不同，我们的功能并不会阻止其他交易者在规划并可能执行序列的时间段内进行交换，也不会阻止流动性提供者在此期间向流动性池添加或移除流动性。 <div>
arXiv:2309.14290v3 Announce Type: replace 
Abstract: We consider Uniswap-like automated market makers, and, specifically, constant product liquidity pools, operating on blockchains. An important feature of Uniswap is the ability for a trader to carry out a sequence of asset swaps atomically, without other traders changing the prices along the way. This atomic-execution feature is not immediately available in cross-chain or sharded blockchain settings, where different liquidity pools are distributed across different chains or shards. Our contribution is a description and suggested implementation of a new functionality that might be added to individual liquidity pools, the {\em lock-swap}. The lock-swap enables a trader to get a guarantee for the price associated with a swap but only decide later whether or not to carry out the swap. Applied across several liquidity pools, it guarantees the trader assured prices for all swaps in a swap sequence and lets these prices inform the trader's decision about whether or not to carry out the sequence, thus essentially giving the trader the same benefits an atomic execution of the sequence would have provided him. However, in contrast to an atomic execution, our functionality does not prevent other traders from doing swaps during the time where the sequence is planned and possibly carried out. Nor does it prevent liquidity providers from adding or removing liquidity to and from the liquidity pool in that time period.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Sporadic Federated Learning: A Unified Algorithmic Framework with Convergence Guarantees</title>
<link>https://arxiv.org/abs/2402.03448</link>
<guid>https://arxiv.org/abs/2402.03448</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Sporadic Federated Learning (DSpodFL), 异步更新, 非凸模型, 凸模型, 算法收敛性

总结:

本文提出了一种新型的去中心化联邦学习方法——Decentralized Sporadic Federated Learning（DSpodFL），该方法关注于客户端间模型更新和聚合过程中存在的异步性和动态性。DSpodFL通过将每个客户端的梯度下降发生和客户端对之间的模型交换建模为任意指示随机变量，从而统一并涵盖了多种现有的分布式优化方法，适应了计算和通信能力的异质性和时间变化场景。对于凸和非凸模型以及常数和递减的学习率，文章分析了DSpodFL的收敛行为，并在假设通信图连通性、客户端间数据异质性和梯度噪声等条件下进行了理论刻画。实验结果显示，无论在何种系统设置下，DSpodFL相较于基准方案都能实现更优的训练速度。 <div>
arXiv:2402.03448v3 Announce Type: replace 
Abstract: Decentralized federated learning (DFL) captures FL settings where both (i) model updates and (ii) model aggregations are exclusively carried out by the clients without a central server. Existing DFL works have mostly focused on settings where clients conduct a fixed number of local updates between local model exchanges, overlooking heterogeneity and dynamics in communication and computation capabilities. In this work, we propose Decentralized Sporadic Federated Learning ($\texttt{DSpodFL}$), a DFL methodology built on a generalized notion of $\textit{sporadicity}$ in both local gradient and aggregation processes. $\texttt{DSpodFL}$ subsumes many existing decentralized optimization methods under a unified algorithmic framework by modeling the per-iteration (i) occurrence of gradient descent at each client and (ii) exchange of models between client pairs as arbitrary indicator random variables, thus capturing $\textit{heterogeneous and time-varying}$ computation/communication scenarios. We analytically characterize the convergence behavior of $\texttt{DSpodFL}$ for both convex and non-convex models and for both constant and diminishing learning rates, under mild assumptions on the communication graph connectivity, data heterogeneity across clients, and gradient noises. We show how our bounds recover existing results from decentralized gradient descent as special cases. Experiments demonstrate that $\texttt{DSpodFL}$ consistently achieves improved training speeds compared with baselines under various system settings.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean of Means: A 10-dollar Solution for Human Localization with Calibration-free and Unconstrained Camera Settings</title>
<link>https://arxiv.org/abs/2407.20870</link>
<guid>https://arxiv.org/abs/2407.20870</guid>
<content:encoded><![CDATA[
<div> 关键词：人类定位、Metaverse、视觉方法、立体视觉、概率方法

总结:<br />
本文提出了一个新的低成本人体定位方法，尤其适用于Metaverse时代。现有的高精度人体定位依赖于昂贵的标签硬件，而基于视觉的方法则提供了一种无需标签的替代方案。针对当前基于立体视觉的方法存在的局限性，如严格的摄像头设置约束和多阶段SVD求解器中的误差传播问题，该研究提出了一种概率方法。这种方法将人体各点视为围绕身体几何中心分布产生的观测值，从而大幅提高采样效率，使每个兴趣点的样本数量从数百提升到数十亿。通过建模世界坐标与像素坐标分布均值之间的关系并利用中心极限定理，确保了数据的正态性并简化了学习过程。实验结果显示，该方法能在仅使用两台分辨率为640x480像素、成本仅为10美元的网络摄像头的情况下，实现高达95%（误差范围0.3米内）的人体定位准确率，以及几乎100%（误差范围0.5米内）的定位准确性。 <div>
arXiv:2407.20870v2 Announce Type: replace 
Abstract: Accurate human localization is crucial for various applications, especially in the Metaverse era. Existing high precision solutions rely on expensive, tag-dependent hardware, while vision-based methods offer a cheaper, tag-free alternative. However, current vision solutions based on stereo vision face limitations due to rigid perspective transformation principles and error propagation in multi-stage SVD solvers. These solutions also require multiple high-resolution cameras with strict setup constraints. To address these limitations, we propose a probabilistic approach that considers all points on the human body as observations generated by a distribution centered around the body's geometric center. This enables us to improve sampling significantly, increasing the number of samples for each point of interest from hundreds to billions. By modeling the relation between the means of the distributions of world coordinates and pixel coordinates, leveraging the Central Limit Theorem, we ensure normality and facilitate the learning process. Experimental results demonstrate human localization accuracy of 95% within a 0.3m range and nearly 100% accuracy within a 0.5m range, achieved at a low cost of only 10 USD using two web cameras with a resolution of 640x480 pixels.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ZKLoRA: Efficient Zero-Knowledge Proofs for LoRA Verification</title>
<link>https://arxiv.org/abs/2501.13965</link>
<guid>https://arxiv.org/abs/2501.13965</guid>
<content:encoded><![CDATA[
<div> 关键词：Low-Rank Adaptation (LoRA)，ZKLoRA，零知识验证，Multi-Party Inference，知识产权保护

总结:<br />
本文介绍了ZKLoRA，一种针对Low-Rank Adaptation (LoRA)权重的零知识验证协议。该协议旨在分布式、不信任训练环境中解决两个问题：一是确认外部贡献者提供的LoRA权重与预期的基础模型有效配合；二是保护LoRA贡献者的专有权重直至获得补偿。ZKLoRA利用简洁证明和创新的多党派推理程序，在不对LoRA权重进行曝光的情况下验证LoRA模型与基础模型的兼容性，可在最先进的大型语言模型上以每模块只需1-2秒的时间完成验证，实现近乎实时的验证速度，促进了地理分布式的团队以及基于合同的训练管线之间的安全协作。同时，该协议确保交付的LoRA模块如其所声称的功能正常运行，保障了贡献者的知识产权，并为基线模型用户提供兼容性和血缘关系的验证。 <div>
arXiv:2501.13965v1 Announce Type: new 
Abstract: Low-Rank Adaptation (LoRA) is a widely adopted method for customizing large-scale language models. In distributed, untrusted training environments, an open source base model user may want to use LoRA weights created by an external contributor, leading to two requirements: (1) the base model user must confirm that the LoRA weights are effective when paired with the intended base model, and (2) the LoRA contributor must keep their proprietary weights private until compensation is assured.
  We present ZKLoRA, a zero-knowledge verification protocol that relies on succinct proofs and our novel Multi-Party Inference procedure to verify LoRA-base model compatibility without exposing LoRA weights. ZKLoRA produces deterministic correctness guarantees and validates each LoRA module in only 1-2 seconds on state-of-the-art large language models. This low-latency approach enables nearly real-time verification and promotes secure collaboration among geographically decentralized teams and contract-based training pipelines. The protocol ensures that the delivered LoRA module works as claimed, safeguarding the contributor's intellectual property while providing the base model user with verification of compatibility and lineage.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Absolute Governance: A Framework for Synchronization and Certification of the Corporate Contractual State</title>
<link>https://arxiv.org/abs/2501.13974</link>
<guid>https://arxiv.org/abs/2501.13974</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、企业治理、交易完整性、成本降低、共识机制

<br /><br />总结: 本文探讨了利用区块链技术确保企业治理中的交易完整性和降低成本的挑战。提出了一种基于链上的方法，用于认证、注册和查询机构交易状态，采用去中心化的治理方式，结合共识机制和智能合约自动执行并强制实施业务规则。该框架旨在降低与合同性测量报告相关的交易成本，并提升整体交易完整性。文中详细阐述了如何有效利用区块链技术提供针对这些问题的稳健解决方案，并实际应用表明，该方法可实现平均2%的过度计费削减。 <div>
arXiv:2501.13974v1 Announce Type: new 
Abstract: This dissertation addresses the challenge of ensuring transactional integrity and reducing costs in corporate governance through blockchain technology. We propose an on-chain methodology for certifying, registering, and querying institutional transactional status. Our decentralized governance approach utilizes consensus mechanisms and smart contracts to automate and enforce business rules. The framework aims to reduce the transaction costs associated with contractual measurement reports and enhance overall transactional integrity. We provide a detailed exploration of how blockchain technology can be effectively harnessed to offer a robust solution to these challenges, setting the stage for our proposed solution and its potential impact on corporate governance. The application of the methodology resulted in as average of 2% overbilling reduction.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Timelock-Free Rationally-Secure Virtual Channels</title>
<link>https://arxiv.org/abs/2501.14418</link>
<guid>https://arxiv.org/abs/2501.14418</guid>
<content:encoded><![CDATA[
<div> 关键词: 支付通道网络, Thunderdome, 无时间锁, 安全性, 激励机制

总结:
Thunderdome 是首个无时间锁的支付通道网络解决方案，旨在解决区块链交易吞吐量限制问题。该方案通过扩展一种无时间锁的支付通道原语并利用虚拟通道的设计思路，实现了多跳交易而不依赖时间锁。Thunderdome 依靠一组非可信的、被称为监护人的看守节点委员会，确保在通道关闭过程中，即使诚实方离线也不会损失资金。为了保证协议的正确执行，文章提出了定制化的激励机制。除了基于诚实多数委员会的传统安全性证明外，还进行了形式化的博弈论分析，以证明包括监护人在内的所有参与者理性行为下的 Thunderdome 的安全性。已在以太坊上实现了一个 Thunderdome 的概念验证版本，并对其成本进行了评估，结果表明部署 Thunderdome（包括开设底层支付通道）的成本约为 15 美元（0.0089 ETH），而最坏情况下关闭通道的成本约为 7 美元（0.004 ETH）。 <div>
arXiv:2501.14418v1 Announce Type: new 
Abstract: Payment channel networks (PCNs) offer a promising solution to address the limited transaction throughput of deployed blockchains. However, several attacks have recently been proposed that stress the vulnerability of PCNs to timelock and censoring attacks. To address such attacks, we introduce Thunderdome, the first timelock-free PCN. Instead, Thunderdome leverages the design rationale of virtual channels to extend a timelock-free payment channel primitive, thereby enabling multi-hop transactions without timelocks. Previous works either utilize timelocks or do not accommodate transactions between parties that do not share a channel.
  At its core, Thunderdome relies on a committee of non-trusted watchtowers, known as wardens, who ensure that no honest party loses funds, even when offline, during the channel closure process. We introduce tailored incentive mechanisms to ensure that all participants follow the protocol's correct execution. Besides a traditional security proof that assumes an honest majority of the committee, we conduct a formal game-theoretic analysis to demonstrate the security of Thunderdome when all participants, including wardens, act rationally. We implement a proof of concept of Thunderdome on Ethereum to validate its feasibility and evaluate its costs. Our evaluation shows that deploying Thunderdome, including opening the underlying payment channel, costs approximately \$15 (0.0089 ETH), while the worst-case cost for closing a channel is about \$7 (0.004 ETH).
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Optimization Methods for Training DL Models: Theoretical Perspective on Convergence and Generalization</title>
<link>https://arxiv.org/abs/2501.14458</link>
<guid>https://arxiv.org/abs/2501.14458</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、优化方法、理论基础、通用梯度法、分布式优化

<br /><br />总结:
本文详细概述了深度学习中优化方法的理论基础，重点关注各种优化算法的收敛性分析和泛化能力。内容涵盖了通用的梯度基 <div>
arXiv:2501.14458v1 Announce Type: new 
Abstract: As data sets grow in size and complexity, it is becoming more difficult to pull useful features from them using hand-crafted feature extractors. For this reason, deep learning (DL) frameworks are now widely popular. The Holy Grail of DL and one of the most mysterious challenges in all of modern ML is to develop a fundamental understanding of DL optimization and generalization. While numerous optimization techniques have been introduced in the literature to navigate the exploration of the highly non-convex DL optimization landscape, many survey papers reviewing them primarily focus on summarizing these methodologies, often overlooking the critical theoretical analyses of these methods. In this paper, we provide an extensive summary of the theoretical foundations of optimization methods in DL, including presenting various methodologies, their convergence analyses, and generalization abilities. This paper not only includes theoretical analysis of popular generic gradient-based first-order and second-order methods, but it also covers the analysis of the optimization techniques adapting to the properties of the DL loss landscape and explicitly encouraging the discovery of well-generalizing optimal points. Additionally, we extend our discussion to distributed optimization methods that facilitate parallel computations, including both centralized and decentralized approaches. We provide both convex and non-convex analysis for the optimization algorithms considered in this survey paper. Finally, this paper aims to serve as a comprehensive theoretical handbook on optimization methods for DL, offering insights and understanding to both novice and seasoned researchers in the field.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Conformal Prediction via Message Passing</title>
<link>https://arxiv.org/abs/2501.14544</link>
<guid>https://arxiv.org/abs/2501.14544</guid>
<content:encoded><![CDATA[
<div> 关键词: Post-hoc calibration, Conformal Prediction, Decentralized, Quantile-based Distributed Conformal Prediction, Histogram-based Distributed Conformal Prediction

总结:
本文关注于预训练模型的事后校准问题，特别是在医疗等安全关键领域中确保可靠的推断。文中提出了一种名为Conformal Prediction（CP）的鲁棒事后校准框架，它利用预留数据集提供预测集的分布自由统计覆盖保证。研究场景设定为分布式环境，每个设备仅有有限的校准数据，并只能与其邻居节点进行通信。为此，文章提出了两种基于消息传递的分布式符合预测方法：量值型分布式符合预测（Q-DCP）和直方图型分布式符合预测（H-DCP）。Q-DCP采用分布式量子回归并结合定制的平滑和正则化项以加速收敛；而H-DCP则运用共识基础的直方图估计方法。通过广泛的实验，文章探讨了不同网络拓扑下的超参数调整需求、通信开销、覆盖率保证以及预测集大小之间的权衡关系。 <div>
arXiv:2501.14544v1 Announce Type: new 
Abstract: Post-hoc calibration of pre-trained models is critical for ensuring reliable inference, especially in safety-critical domains such as healthcare. Conformal Prediction (CP) offers a robust post-hoc calibration framework, providing distribution-free statistical coverage guarantees for prediction sets by leveraging held-out datasets. In this work, we address a decentralized setting where each device has limited calibration data and can communicate only with its neighbors over an arbitrary graph topology. We propose two message-passing-based approaches for achieving reliable inference via CP: quantile-based distributed conformal prediction (Q-DCP) and histogram-based distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile regression enhanced with tailored smoothing and regularization terms to accelerate convergence, while H-DCP uses a consensus-based histogram estimation approach. Through extensive experiments, we investigate the trade-offs between hyperparameter tuning requirements, communication overhead, coverage guarantees, and prediction set sizes across different network topologies.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum Cyber-Attack on Blockchain-based VANET</title>
<link>https://arxiv.org/abs/2304.04411</link>
<guid>https://arxiv.org/abs/2304.04411</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、车联网、量子计算、量子攻击、RSA加密

总结:
区块链技术在车联网（VANET）中被视为安全通信架构的一种方式。然而，随着量子计算的发展，这种架构对网络攻击的脆弱性引起关注。本文研究了在基于区块链的VANET中的潜在威胁，并开发了一种相应的量子网络攻击方法——利用量子-Shor算法进行RSA加密数字签名的量子假冒攻击，破坏VANET的信任基础区块链方案。通过OMNET++、扩展的INET库、VEINS以及与仿真城市移动性（SUMO）相结合的方式，模拟了区块链为基础的VANET、车联万物（V2X）通信和车辆移动性。同时，使用IBM Qiskit实现了小密钥RSA消息加密。研究结果显示，量子假冒攻击能够成功打破基于区块链的VANET的信任链，强调了对于量子安全区块链的需求。 <div>
arXiv:2304.04411v2 Announce Type: replace 
Abstract: Blockchain-based Vehicular Ad-hoc Network (VANET) is widely considered as secure communication architecture for a connected transportation system. With the advent of quantum computing, there are concerns regarding the vulnerability of this architecture against cyber-attacks. In this study, a potential threat is investigated in a blockchain-based VANET, and a corresponding quantum cyber-attack is developed. Specifically, a quantum impersonation attack using Quantum-Shor algorithm is developed to break the Rivest-Shamir-Adleman (RSA) encrypted digital signatures of VANET and thus create a threat for the trust-based blockchain scheme of VANET. A blockchain-based VANET, vehicle-to-everything (V2X) communication, and vehicular mobility are simulated using OMNET++, the extended INET library, and vehicles-in-network simulation (VEINS) along with simulation of urban mobility (SUMO), respectively. A small key RSA based message encryption is implemented using IBM Qiskit, which is an open-source quantum software development kit. The findings reveal that the quantum cyber-attack, example, impersonation attack is able to successfully break the trust chain of a blockchain-based VANET. This highlights the need for a quantum secured blockchain.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks</title>
<link>https://arxiv.org/abs/2402.16201</link>
<guid>https://arxiv.org/abs/2402.16201</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、扩展性解决方案、随机采样、去中心化算法、Honeybee

总结:<br />
本文关注的是当今拥有数十万节点的流行区块链如何支持复杂的扩展性解决方案，如分片、数据可用性采样和二层方法。文章指出了在大规模区块链网络中构建健壮的对等(P2P)网络协议，尤其是实现分布式、均匀的随机节点采样这一基础能力的重要性。现有的采样算法（主要用于地址发现）依赖于分布式哈希表（如Kademlia）或邻居间共享地址（如GossipSub），但在Sybil攻击场景下并不安全。为此，文章提出了名为Honeybee的新型去中心化随机采样算法，该算法利用可验证的随机游走和节点一致性检查，即使在网络中存在大量拜占庭式恶意节点（例如，超过50%）的情况下也能保证安全性。实验结果显示，与现有最佳方案相比，Honeybee实现了显著更好的采样质量。Honeybee算法对于全节点和轻节点的网络设计具有重要影响。 <div>
arXiv:2402.16201v3 Announce Type: replace 
Abstract: Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and peer consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\geq50\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SRMT: Shared Memory for Multi-agent Lifelong Pathfinding</title>
<link>https://arxiv.org/abs/2501.13200</link>
<guid>https://arxiv.org/abs/2501.13200</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-agent Reinforcement Learning (MARL), Shared Recurrent Memory Transformer (SRMT), Cooperation, Bottleneck Navigation Task, POGEMA Benchmark

总结:
本文提出了一种名为共享循环记忆变换器（Shared Recurrent Memory Transformer, SRMT）的新方法，用于解决多智能体强化学习（Multi-agent Reinforcement Learning, MARL）中的合作问题。SRMT通过池化和全局广播个体工作内存的方式，使智能体能够隐式地交换信息并协调行动。在需要智能体合作通过狭窄走廊的Bottleneck导航任务中，SRMT在稀疏奖励条件下持续优于多种强化学习基线算法，并能有效泛化到比训练时更长的走廊场景。同时，在包括Mazes、Random和MovingAI在内的POGEMA基准集任务上，SRMT与其他近期的MARL、混合以及基于规划的算法表现相当。这一研究表明，在基于变压器的架构中融入共享循环记忆可以增强分布式多智能体系统的协调能力。实验代码已在GitHub上公开：https://github.com/Aloriosa/srmt。 <div>
arXiv:2501.13200v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) demonstrates significant progress in solving cooperative and competitive multi-agent problems in various environments. One of the principal challenges in MARL is the need for explicit prediction of the agents' behavior to achieve cooperation. To resolve this issue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends memory transformers to multi-agent settings by pooling and globally broadcasting individual working memories, enabling agents to exchange information implicitly and coordinate their actions. We evaluate SRMT on the Partially Observable Multi-Agent Pathfinding problem in a toy Bottleneck navigation task that requires agents to pass through a narrow corridor and on a POGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently outperforms a variety of reinforcement learning baselines, especially under sparse rewards, and generalizes effectively to longer corridors than those seen during training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is competitive with recent MARL, hybrid, and planning-based algorithms. These results suggest that incorporating shared recurrent memory into the transformer-based architectures can enhance coordination in decentralized multi-agent systems. The source code for training and evaluation is available on GitHub: https://github.com/Aloriosa/srmt.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Intrusion Detection in Dynamic Networks of UAVs using Few-Shot Federated Learning</title>
<link>https://arxiv.org/abs/2501.13213</link>
<guid>https://arxiv.org/abs/2501.13213</guid>
<content:encoded><![CDATA[
<div> 关键词: 飞行自组网(FANETs), 入侵检测, 联邦学习(FL), 少样本学习(FSL), FSFL-IDS

总结:<br />
针对飞行自组网(FANETs)中由无人机构成网络所带来的独特安全挑战，本文探讨了利用少样本学习(FSL)与联邦学习(FL)相结合的方法来有效降低入侵检测所需的数据量。为此，文章提出了一种名为FSFL-IDS的新方法，该方法旨在解决动态FANETs中的隐私保护、电力消耗、通信成本以及链路丢包等问题。FSFL-IDS通过结合FL和FSL，减少了局部模型及全局模型的训练时间和样本大小，从而降低了计算和通信成本并延长了电池寿命。此外，由于FSL对训练数据的需求较少，因此在网络链接不稳定的情况下，IDS受其影响的程度也会相应降低。 <div>
arXiv:2501.13213v1 Announce Type: new 
Abstract: Flying Ad Hoc Networks (FANETs), which primarily interconnect Unmanned Aerial Vehicles (UAVs), present distinctive security challenges due to their distributed and dynamic characteristics, necessitating tailored security solutions. Intrusion detection in FANETs is particularly challenging due to communication costs, and privacy concerns. While Federated Learning (FL) holds promise for intrusion detection in FANETs with its cooperative and decentralized model training, it also faces drawbacks such as large data requirements, power consumption, and time constraints. Moreover, the high speeds of nodes in dynamic networks like FANETs may disrupt communication among Intrusion Detection Systems (IDS). In response, our study explores the use of few-shot learning (FSL) to effectively reduce the data required for intrusion detection in FANETs. The proposed approach called Few-shot Federated Learning-based IDS (FSFL-IDS) merges FL and FSL to tackle intrusion detection challenges such as privacy, power constraints, communication costs, and lossy links, demonstrating its effectiveness in identifying routing attacks in dynamic FANETs.This approach reduces both the local models and the global model's training time and sample size, offering insights into reduced computation and communication costs and extended battery life. Furthermore, by employing FSL, which requires less data for training, IDS could be less affected by lossy links in FANETs.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Forecasting of Bitcoin Prices Using Hashrate Features: Wavelet and Deep Stacking Approach</title>
<link>https://arxiv.org/abs/2501.13136</link>
<guid>https://arxiv.org/abs/2501.13136</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字货币、比特币、价格预测、深度学习、堆叠技术

总结:
本文介绍了基于堆叠深度学习和小波去噪的比特币价格预测模型。该研究聚焦于数字货币中的热点——比特币的价格波动问题，提出了一种结合分类与回归的预测模型。在预处理阶段，应用了Chi2、RFE和嵌入式三种特征选择方法。模型利用深度学习（尤其是神经网络和变压器）进行一、七、三十和九十天的价格预测。实验结果显示，该模型对于下一天的价格预测准确率达到了63%，第七天、第三十天和第九十天分别达到64%、67%和82%。同时，对于每日价格预测，误差降低到0.58%，而对于七至九十天的预测误差则在2.72%至2.85%之间。这些结果表明，所提出的模型相比文献中其他模型具有更好的预测性能。 <div>
arXiv:2501.13136v1 Announce Type: cross 
Abstract: Digital currencies have become popular in the last decade due to their non-dependency and decentralized nature. The price of these currencies has seen a lot of fluctuations at times, which has increased the need for prediction. As their most popular, Bitcoin(BTC) has become a research hotspot. The main challenge and trend of digital currencies, especially BTC, is price fluctuations, which require studying the basic price prediction model. This research presents a classification and regression model based on stack deep learning that uses a wavelet to remove noise to predict movements and prices of BTC at different time intervals. The proposed model based on the stacking technique uses models based on deep learning, especially neural networks and transformers, for one, seven, thirty and ninety-day forecasting. Three feature selection models, Chi2, RFE and Embedded, were also applied to the data in the pre-processing stage. The classification model achieved 63\% accuracy for predicting the next day and 64\%, 67\% and 82\% for predicting the seventh, thirty and ninety days, respectively. For daily price forecasting, the percentage error was reduced to 0.58, while the error ranged from 2.72\% to 2.85\% for seven- to ninety-day horizons. These results show that the proposed model performed better than other models in the literature.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid Reactive Routing Protocol for Decentralized UAV Networks</title>
<link>https://arxiv.org/abs/2407.02929</link>
<guid>https://arxiv.org/abs/2407.02929</guid>
<content:encoded><![CDATA[
<div> 关键词: 无线网络、无人机、分布式、自适应路由协议、性能评估

总结:
该文针对由低功耗、小型无人机（FW-UAVs）组成的无线网络，提出了一种混合反应式路由协议。该协议旨在解决由于无人机动态轨迹和网络拓扑频繁变化导致的路径断裂问题，支持多流量并提供对移动性和拥塞感知的高质量路径。协议采取按需搜索路径并在选定路径周围监控区域（管道），在当前路径质量下降到阈值以下前主动切换至备用路线。文章通过实验评估了管道宽度和节点密度对找到替代优质路径及维持管道所需开销的影响。与现有反应式路由方案相比，该方法在不同交通负载、节点密度和速度下能实现更高吞吐量，降低路由发现次数、开销以及由此产生的流中断。尽管信息收集方式分布化，且具有低控制开销和路由计算复杂度，但此提议的方案在不同网络和交通设置下的性能优于预优化链路状态路由协议。此外，文中还比较了反应式和预测式路由方案的相对性能。<br /><br /> <div>
arXiv:2407.02929v2 Announce Type: replace 
Abstract: Wireless networks consisting of low SWaP, FW-UAVs are used in many applications, such as monitoring, search and surveillance of inaccessible areas. A decentralized and autonomous approach ensures robustness to failures; the UAVs explore and sense within the area and forward their information, in a multihop manner, to nearby aerial gateway nodes. However, the unpredictable nature of the events, relatively high speed of UAVs, and dynamic UAV trajectories cause the network topology to change significantly over time, resulting in frequent route breaks. A holistic routing approach is needed to support multiple traffic flows in these networks to provide mobility- and congestion-aware, high-quality routes when needed, with low control and computational overheads, using the information collected in a distributed manner. Existing routing schemes do not address all the mentioned issues.
  We present a hybrid reactive routing protocol for decentralized UAV networks. Our scheme searches routes on-demand, monitors a region around the selected route (the pipe), and proactively switches to an alternative route before the current route's quality degrades below a threshold. We empirically evaluate the impact of pipe width and node density on our ability to find alternate high-quality routes within the pipe and the overhead required to maintain the pipe. Compared to existing reactive routing schemes, our approach achieves higher throughput and reduces the number of route discoveries, overhead, and resulting flow interruptions at different traffic loads, node densities and speeds. Despite having limited network topology information, and low overhead and route computation complexity, our proposed scheme achieves superior throughput to proactive optimized link state routing scheme at different network and traffic settings. We also evaluate the relative performance of reactive and proactive routing schemes.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Blockchain Analysis: Tackling Temporality and Scalability with an Incremental Approach with Metropolis-Hastings Random Walks</title>
<link>https://arxiv.org/abs/2501.12491</link>
<guid>https://arxiv.org/abs/2501.12491</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、交易网络分析、图表示学习、动态学习、Metropolis-Hastings随机漫步

总结:<br />
本文针对区块链交易网络的数据分析，特别是其中的欺诈检测和市场监管等问题，指出现有方法存在的两个局限性：一是忽视了交易网络随时间演变的特性；二是对于大规模不断扩展的交易网络，现有方法可能缺乏高效的增量学习能力。为解决这些问题，文章提出了基于随机游走的节点表示学习的增量方法，并设计了一种改进效率的Metropolis-Hastings随机游走机制。实验证实在区块链交易数据集上的节点分类任务中，该方法表现出了可比的性能同时降低了计算开销。潜在应用包括交易网络监控、欺诈地址的有效分类以及网络中专业化地址类型的识别。 <div>
arXiv:2501.12491v1 Announce Type: new 
Abstract: Blockchain technology, with implications in the financial domain, offers data in the form of large-scale transaction networks. Analyzing transaction networks facilitates fraud detection, market analysis, and supports government regulation. Despite many graph representation learning methods for transaction network analysis, we pinpoint two salient limitations that merit more investigation. Existing methods predominantly focus on the snapshots of transaction networks, sidelining the evolving nature of blockchain transaction networks. Existing methodologies may not sufficiently emphasize efficient, incremental learning capabilities, which are essential for addressing the scalability challenges in ever-expanding large-scale transaction networks. To address these challenges, we employed an incremental approach for random walk-based node representation learning in transaction networks. Further, we proposed a Metropolis-Hastings-based random walk mechanism for improved efficiency. The empirical evaluation conducted on blockchain transaction datasets reveals comparable performance in node classification tasks while reducing computational overhead. Potential applications include transaction network monitoring, the efficient classification of blockchain addresses for fraud detection or the identification of specialized address types within the network.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Discrete Denoising Diffusion Model for Molecular Generation with OpenFL</title>
<link>https://arxiv.org/abs/2501.12523</link>
<guid>https://arxiv.org/abs/2501.12523</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型，药物设计，扩散模型，联邦学习，OpenFL<br /><br />总结:
在药物设计领域，生成具有理想生物化学性质的独特分子作为可行的药物候选物是一项艰巨任务。近年来，扩散模型在加速AI驱动的分子生成和药物设计过程中展现出巨大潜力。然而，训练这些模型需要大量的数据，而这些数据通常分散存储于私有数据库中。为了解决这一问题，本文介绍了一种使用OpenFL（一个开放的联邦学习框架）进行训练的联邦离散去噪扩散模型。该模型在保护数据隐私的同时，实现了分布式数据站点间的协同训练，并在生成分子的独特性和有效性评估上，其性能可与集中式数据训练的模型相媲美。这表明联邦学习可用于并有助于药物设计过程。OpenFL项目可在https://github.com/securefederatedai/openfl获取。 <div>
arXiv:2501.12523v1 Announce Type: new 
Abstract: Generating unique molecules with biochemically desired properties to serve as viable drug candidates is a difficult task that requires specialized domain expertise. In recent years, diffusion models have shown promising results in accelerating the drug design process through AI-driven molecular generation. However, training these models requires massive amounts of data, which are often isolated in proprietary silos. OpenFL is a federated learning framework that enables privacy-preserving collaborative training across these decentralized data sites. In this work, we present a federated discrete denoising diffusion model that was trained using OpenFL. The federated model achieves comparable performance with a model trained on centralized data when evaluating the uniqueness and validity of the generated molecules. This demonstrates the utility of federated learning in the drug design process.
  OpenFL is available at: https://github.com/securefederatedai/openfl
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mechanism Design for Blockchain Order Books against Selfish Miners</title>
<link>https://arxiv.org/abs/2501.12576</link>
<guid>https://arxiv.org/abs/2501.12576</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、交易费、自私矿工、社会福利、可调整区块大小机制

总结:
本文针对基于区块链的订单簿系统中矿工自私行为导致的社会福利损失问题进行了首次深入分析。研究发现，高交易费用的交易往往被优先处理，而忽略了可能提升社会福利的匹配。当前区块链机制对此未能有效应对。为此，文章提出了一种无需改变现有去中心化协议、易于实施的可调整区块大小机制，允许买家和卖家自由决定交易费以及矿工自我选择交易匹配。虽然纯策略纳什均衡并不总是存在，且系统设计者可能不了解每个买家或卖家的具体报价和交易量，但该机制仍能实现社会福利损失的优良界限。特别地，在非同质化代币（NFT）的同量化数量交易场景下，其价格博弈论中的效率损失为零，即无社会福利损失。实验在本地以太坊实例上验证了该机制的可行性，并通过真实数据集表明，对于比特币等异量化数量交易，相比于现有的订单簿基准，该机制可以将社会福利提升至最多3.7倍，同时展现出对买家和卖家随机变化的良好鲁棒性。 <div>
arXiv:2501.12576v1 Announce Type: new 
Abstract: In blockchain-based order book systems, buyers and sellers trade assets, while it is miners to match them and include their transactions in the blockchain. It is found that many miners behave selfishly and myopically, prioritizing transactions with high fees and ignoring many desirable matches that could enhance social welfare. Existing blockchain mechanisms fail to address this issue by overlooking miners' selfish behaviors. To our best knowledge, this work presents the first analytical study to quantify and understand buyer and seller transaction fee choices and selfish miners' transaction matching strategies, proving an infinitely large price of anarchy (PoA) for social welfare loss. To mitigate this, we propose an adjustable block size mechanism that is easy to implement without altering the existing decentralized protocols and still allows buyers and sellers to freely decide transaction fees and miners to selfishly match. The analysis is challenging, as pure strategy Nash equilibria do not always exist, requiring the analysis of many buyers' or sellers' interactive mixed-strategy distributions. Moreover, the system designer may even lack information about each buyer's or seller's bid/ask prices and trading quantities. Nevertheless, our mechanism achieves a well-bounded PoA, and under the homogeneous-quantity trading for non-fungible tokens (NFT), it attains a PoA of 1 with no social welfare loss. We implement our mechanism on a local instance of Ethereum to demonstrate the feasibility of our approach. Experiments based on the realistic dataset demonstrate that our mechanism achieves social optimum for homogeneous-quantity trading like NFT. It can enhance social welfare up to 3.7 times compared to the existing order book benchmarks for heterogeneous-quantity trading of Bitcoin tokens. It exhibits robustness against random variations in buyers and sellers.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Does multi-block MEV exist? Analysis of 2 years of MEV Data</title>
<link>https://arxiv.org/abs/2501.12827</link>
<guid>https://arxiv.org/abs/2501.12827</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum合并、MEV、多块套利、MEV-Boost支付、建设者

总结:
<br />
本文针对2022年9月Ethereum合并后的提议者-建设者数据和MEV-Boost支付数据进行了分析，研究多块MEV的模式。研究发现实际的连续建设者序列少于随机蒙特卡洛模拟预测的数量，观察到最长的序列跨度为25个槽位。同时，随着连续序列长度的增长，平均MEV-Boost支付也增加，从单槽位的约0.05 ETH增长至九连贯槽位的约0.08 ETH。在较长序列中，每槽位的支付略有上升，表明建设者可能对更长序列或长期序列后的第一个槽位出价更高。此外，研究还发现相邻MEV-Boost支付间存在弱正自相关性，这与低高MEV交替发生的假设相矛盾。最后，对比低和高基本费用波动时期的建设者行为显示，两者之间几乎没有相关性，意味着建设者并未根据基础费用波动进行专业化分工。 <div>
arXiv:2501.12827v1 Announce Type: new 
Abstract: This study analyzes proposer-builder data and MEV-Boost payment data following the Ethereum merge in September 2022 to identify patterns of multi-block MEV. Our findings reveal fewer multi-slot sequences of builders than predicted by a random Monte Carlo simulation, with the longest observed sequence spanning 25 slots. Additionally, we observe that average MEV-Boost payments increase with the length of consecutive sequences, from approximately 0.05 ETH for single slots to 0.08 ETH for nine consecutive slots. Within longer sequences, payments per slot show a slight increase, suggesting that builders bid higher for longer sequences or the first slot after a longer sequence. A weak positive autocorrelation is found between subsequent MEV-Boost payments, challenging the hypothesis of alternating periods of low and high MEV. Finally, our comparison of builders during periods of low and high base fee volatility reveals minimal correlation, indicating the absence of builder specialization based on base fee volatility.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning</title>
<link>https://arxiv.org/abs/2501.12911</link>
<guid>https://arxiv.org/abs/2501.12911</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、加密、同态加密、差分隐私、位混淆<br /><br />总结:
本文提出了一种名为FAS（快速且安全的联邦学习）的新方法，用于提高医疗影像数据上的深度学习模型训练过程中的数据安全性与执行性能。FAS结合了选择性加密、同态加密、差分隐私和位混淆技术，有效减少了数据泄漏风险。研究团队使用Flower框架实现了这一方法并与一种采用选择性同态加密的主流联邦学习方法进行了对比。实验在一个由十一台物理机器组成的集群上进行，模拟真实世界的联邦学习场景并使用了不同的数据集。结果显示，相比于全同态加密，FAS方法的速度提高了最多90%，并且可以省去竞争对手所需的预训练步骤，从而节省了高达20%的总执行时间。同时，尽管FAS方法速度更快，但其在安全性方面表现与竞争对手相当。 <div>
arXiv:2501.12911v1 Announce Type: new 
Abstract: Federated learning is a machine learning method that supports training models on decentralized devices or servers, where each holds its local data, removing the need for data exchange. This approach is especially useful in healthcare, as it enables training on sensitive data without needing to share them. The nature of federated learning necessitates robust security precautions due to data leakage concerns during communication. To address this issue, we propose a new approach that employs selective encryption, homomorphic encryption, differential privacy, and bit-wise scrambling to minimize data leakage while achieving good execution performance. Our technique , FAS (fast and secure federated learning) is used to train deep learning models on medical imaging data. We implemented our technique using the Flower framework and compared with a state-of-the-art federated learning approach that also uses selective homomorphic encryption. Our experiments were run in a cluster of eleven physical machines to create a real-world federated learning scenario on different datasets. We observed that our approach is up to 90\% faster than applying fully homomorphic encryption on the model weights. In addition, we can avoid the pretraining step that is required by our competitor and can save up to 20\% in terms of total execution time. While our approach was faster, it obtained similar security results as the competitor.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs</title>
<link>https://arxiv.org/abs/2501.12972</link>
<guid>https://arxiv.org/abs/2501.12972</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、信任less、形式化方法、模型综合、智能合约

总结:<br />
本文关注于降低使用形式化方法进行区块链软件（特别是智能合约）正确性审计的时间和门槛。文章提出了一个自动化创建正式模型的方法，该方法分为三个阶段：首先将代码转换为模型存根；然后利用大规模语言模型填充细节；最后，通过迭代修复生成的模型，从语法和语义层面确保其准确性。这样做的目的是显著减少构建正式模型所需的时间，提高依赖这些模型的软件验证方法的可访问性，从而在实际应用中加速利用形式化方法对智能合约正确性审计的价值实现。 <div>
arXiv:2501.12972v1 Announce Type: new 
Abstract: When blockchain systems are said to be trustless, what this really means is that all the trust is put into software. Thus, there are strong incentives to ensure blockchain software is correct -- vulnerabilities here cost millions and break businesses. One of the most powerful ways of establishing software correctness is by using formal methods. Approaches based on formal methods, however, induce a significant overhead in terms of time and expertise required to successfully employ them. Our work addresses this critical disadvantage by automating the creation of a formal model -- a mathematical abstraction of the software system -- which is often a core task when employing formal methods. We perform model synthesis in three phases: we first transpile the code into model stubs; then we "fill in the blanks" using a large language model (LLM); finally, we iteratively repair the generated model, on both syntactical and semantical level. In this way, we significantly reduce the amount of time necessary to create formal models and increase accessibility of valuable software verification methods that rely on them. The practical context of our work was reducing the time-to-value of using formal models for correctness audits of smart contracts.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Offline Multi-Agent Reinforcement Learning Framework for Radio Resource Management</title>
<link>https://arxiv.org/abs/2501.12991</link>
<guid>https://arxiv.org/abs/2501.12991</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线多智能体强化学习 (MARL)、离线多智能体强化学习 (offline MARL)、无线资源管理 (RRM)、集中式训练、分布式执行 (CTDE)

总结:
本文提出了一种针对无线网络中无线电资源管理的离线多智能体强化学习算法，旨在优化多个接入点的调度策略以同时最大化用户设备的总和及尾部速率。文章对比了三种训练范式：集中式、独立式以及集中式训练与分布式执行（CTDE）。模拟结果显示，所提出的离线MARL框架优于传统基线方法，能实现对总和及尾部速率加权组合超过15%的提升。此外，CTDE框架在降低集中式方法计算复杂度的同时，也解决了独立训练的低效率问题，彰显了离线MARL在动态无线网络资源管理中提供可扩展、健壮且高效解决方案的潜力。 <div>
arXiv:2501.12991v1 Announce Type: new 
Abstract: Offline multi-agent reinforcement learning (MARL) addresses key limitations of online MARL, such as safety concerns, expensive data collection, extended training intervals, and high signaling overhead caused by online interactions with the environment. In this work, we propose an offline MARL algorithm for radio resource management (RRM), focusing on optimizing scheduling policies for multiple access points (APs) to jointly maximize the sum and tail rates of user equipment (UEs). We evaluate three training paradigms: centralized, independent, and centralized training with decentralized execution (CTDE). Our simulation results demonstrate that the proposed offline MARL framework outperforms conventional baseline approaches, achieving over a 15\% improvement in a weighted combination of sum and tail rates. Additionally, the CTDE framework strikes an effective balance, reducing the computational complexity of centralized methods while addressing the inefficiencies of independent training. These results underscore the potential of offline MARL to deliver scalable, robust, and efficient solutions for resource management in dynamic wireless networks.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Practical quantum federated learning and its experimental demonstration</title>
<link>https://arxiv.org/abs/2501.12709</link>
<guid>https://arxiv.org/abs/2501.12709</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、量子增强、隐私保护、分布式量子秘密钥匙、实验验证

<br /><br />总结:
本文提出了一种针对量子计算时代的实用量子联邦学习框架，该框架在量子网络上运行，利用分布式量子秘密钥匙来保护局部模型更新并实现信息论意义上的安全聚合。文章在具有可扩展结构的4客户端量子网络上实验验证了该框架，并通过大量数值实验展示了在量子和经典数据集上的性能提升——特别是对于多体纠缠和非稳定器量子数据集分类能力的显著增强。此外，模拟实验还表明，当应用于包含200个客户端的经典模型（训练MNIST数据集）时，通过先进的模型压缩技术，可以将通信成本降低75%，同时实现快速的训练收敛性。这项工作为构建可扩展、高效且具备量子安全性的机器学习系统，迎接即将到来的量子互联网时代提供了关键洞见。 <div>
arXiv:2501.12709v1 Announce Type: cross 
Abstract: Federated learning is essential for decentralized, privacy-preserving model training in the data-driven era. Quantum-enhanced federated learning leverages quantum resources to address privacy and scalability challenges, offering security and efficiency advantages beyond classical methods. However, practical and scalable frameworks addressing privacy concerns in the quantum computing era remain undeveloped. Here, we propose a practical quantum federated learning framework on quantum networks, utilizing distributed quantum secret keys to protect local model updates and enable secure aggregation with information-theoretic security. We experimentally validate our framework on a 4-client quantum network with a scalable structure. Extensive numerical experiments on both quantum and classical datasets show that adding a quantum client significantly enhances the trained global model's ability to classify multipartite entangled and non-stabilizer quantum datasets. Simulations further demonstrate scalability to 200 clients with classical models trained on the MNIST dataset, reducing communication costs by $75\%$ through advanced model compression techniques and achieving rapid training convergence. Our work provides critical insights for building scalable, efficient, and quantum-secure machine learning systems for the coming quantum internet era.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Blocklace: A Byzantine-repelling and Universal Conflict-free Replicated Data Type</title>
<link>https://arxiv.org/abs/2402.08068</link>
<guid>https://arxiv.org/abs/2402.08068</guid>
<content:encoded><![CDATA[
<div> 关键词：Conflict-free Replicated Data Types (CRDTs)，Byzantine环境，Blocklace，CRDT协议，拜占庭节点检测

总结:
本文介绍了基于内容哈希的DAG结构在拜占庭环境中实现冲突无虞复制数据类型（CRDTs）的最新进展。文章重点讨论了Blocklace——一种部分有序的区块链泛化结构，其中每个区块可以有任意数量的签名哈希指针指向先前的区块。研究发现，仅通过添加单个块的操作，Blocklace即可被证明是一种CRDT：它既是具有自我标记的纯操作型CRDT，也是通用delta状态CRDT的一种形式。此外，Blocklace还可以被视为一种能实现任意CRDT的通用拜占庭容错方案。当前方法对CRDT收敛的关注仅限于容忍equivocation（不检测或阻止equivocations），允许拜占庭节点通过引入无限数量的equivocations来污染CRDT状态。而文章表明，Blocklace不仅可以以equivocation-tolerant的方式使用，还能用于检测并最终排除包括equivocator在内的拜占庭节点，即使存在不可检测的合谋者也是如此。Blocklace CRDT协议确保了拜占庭节点只能对计算的有限前缀造成损害。<br /><br /> <div>
arXiv:2402.08068v4 Announce Type: replace 
Abstract: Conflict-free Replicated Data Types (CRDTs) are designed for replica convergence without global coordination or consensus. Recent work has achieved the same in a Byzantine environment, through DAG-like structures based on cryptographic hashes of content. The blocklace is a partially-ordered generalization of the blockchain in which each block has any finite number of signed hash pointers to preceding blocks. We show that the blocklace datatype, with the sole operation of adding a single block, is a CRDT: it is both a pure operation-based CRDT, with self-tagging; and a delta-state CRDT, under a slight generalization of the delta framework. Allowing arbitrary values as payload, the blocklace can also be seen as a universal Byzantine fault-tolerant implementation for arbitrary CRDTs, under the operation-based approach. Current approaches only care about CRDT convergence, being equivocation-tolerant (they do not detect or prevent equivocations), allowing a Byzantine node to cause an arbitrary amount of harm by polluting the CRDT state with an unbounded number of equivocations. We show that the blocklace can be used not only in an equivocation-tolerant way, but also so as to detect and eventually exclude Byzantine nodes, including equivocators, even under the presence of undetectable colluders. The blocklace CRDT protocol ensures that a Byzantine node may harm only a finite prefix of the computation.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Implementation Study of Cost-Effective Verification for Pietrzak's Verifiable Delay Function in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2405.06498</link>
<guid>https://arxiv.org/abs/2405.06498</guid>
<content:encoded><![CDATA[
<div> 关键词: Verifiable Delay Function (可验证延迟函数), Pietrzak VDF, Ethereum Virtual Machine (以太坊虚拟机), gas成本, 优化

总结:
本文针对区块链环境中的Verifiable Delay Function（VDF），特别是Pietrzak提出的VDF协议进行了实施研究。研究发现，通过深入理解Pietrzak原始论文中的讨论，在以太坊虚拟机（EVM）上可以实现该VDF协议的清晰优化。结果显示，VDF验证的成本从原本的4M gas降低到了2M gas，同时使用2048位RSA密钥长度的情况下，证明长度能被控制在8 KB以内，远小于先前预期，实现了显著的优化效果。 <div>
arXiv:2405.06498v5 Announce Type: replace 
Abstract: Verifiable Delay Function (VDF) is a cryptographic concept that ensures a minimum delay before output through sequential processing, which is resistant to parallel computing. One of the significant VDF protocols academically reviewed is the VDF protocol proposed by Pietrzak. However, for the blockchain environment, the Pietrzak VDF has drawbacks including long proof size and recursive protocol computation. In this paper, we present an implementation study of Pietrzak VDF verification on Ethereum Virtual Machine (EVM). We found that the discussion in the Pietrzak's original paper can help a clear optimization in EVM where the costs of computation are predefined as the specific amounts of gas. In our results, the cost of VDF verification can be reduced from 4M to 2M gas, and the proof length can be generated under 8 KB with the 2048-bit RSA key length, which is much smaller than the previous expectation.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MicroPython Testbed for Federated Learning Algorithms</title>
<link>https://arxiv.org/abs/2405.09423</link>
<guid>https://arxiv.org/abs/2405.09423</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2405.09423v2, Python Testbed, Federated Learning, MicroPython Testbed, Edge Systems

总结:
本文介绍了arXiv:2405.09423v2版本的论文内容，该文提出了一种新的框架——MicroPython Testbed for Federated Learning Algorithms。这个框架是对原有Python Testbed的改进，克服了其只能在同一台PC上运行应用实例的局限性，使得各个应用实例可以在不同的网络节点（如PC和IoT设备）上独立运行，特别是在边缘系统中。新框架依然坚持纯Python编程，并基于异步I/O抽象，同时支持MicroPython，因此非常适合于物联网设备和边缘系统的硬件。通过在由PC和Raspberry Pi Pico W板组成的无线网络上进行实验验证，证明了新框架的有效性，实验使用了原先是为旧框架开发的应用示例。 <div>
arXiv:2405.09423v2 Announce Type: replace 
Abstract: Recently, Python Testbed for Federated Learning Algorithms emerged as a low code and generative large language models amenable framework for developing decentralized and distributed applications, primarily targeting edge systems, by nonprofessional programmers with the help of emerging artificial intelligence tools. This light framework is written in pure Python to be easy to install and to fit into a small IoT memory. It supports formally verified generic centralized and decentralized federated learning algorithms, as well as the peer-to-peer data exchange used in time division multiplexing communication, and its current main limitation is that all the application instances can run only on a single PC. This paper presents the MicroPyton Testbed for Federated Learning Algorithms, the new framework that overcomes its predecessor's limitation such that individual application instances may run on different network nodes like PCs and IoTs, primarily in edge systems. The new framework carries on the pure Python ideal, is based on asynchronous I/O abstractions, and runs on MicroPython, and therefore is a great match for IoTs and devices in edge systems. The new framework was experimentally validated on a wireless network comprising PCs and Raspberry Pi Pico W boards, by using application examples originally developed for the predecessor framework.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GTDE: Grouped Training with Decentralized Execution for Multi-agent Actor-Critic</title>
<link>https://arxiv.org/abs/2501.10367</link>
<guid>https://arxiv.org/abs/2501.10367</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、分散训练与执行（DTDE）、集中训练分散执行（CTDE）、分组训练分散执行（GTDE）、Gumbel-Sigmoid

总结:<br />
本文提出了一种新的多智能体强化学习训练范式——分组训练分散执行（GTDE），用于解决随着智能体数量增加导致的性能下降问题。与DTDE和CTDE相比，GTDE不需要中心化模块，仅依赖局部信息，适应大规模多智能体系统的训练需求。具体来说，GTDE引入了自适应分组模块，根据观察历史将每个智能体划分为不同组，并采用Gumbel-Sigmoid实现点对点采样以及确保梯度反传。针对组内成员数量不确定性，文章提出了两种方法实现组信息聚合模块，整合组内成员信息。实验证明，在拥有495个智能体的合作环境中，GTDE相比于基线平均提高了382%的总奖励；在具有64个智能体的竞争环境中，GTDE实现了对基线的100%胜率。 <div>
arXiv:2501.10367v1 Announce Type: new 
Abstract: The rapid advancement of multi-agent reinforcement learning (MARL) has given rise to diverse training paradigms to learn the policies of each agent in the multi-agent system. The paradigms of decentralized training and execution (DTDE) and centralized training with decentralized execution (CTDE) have been proposed and widely applied. However, as the number of agents increases, the inherent limitations of these frameworks significantly degrade the performance metrics, such as win rate, total reward, etc. To reduce the influence of the increasing number of agents on the performance metrics, we propose a novel training paradigm of grouped training decentralized execution (GTDE). This framework eliminates the need for a centralized module and relies solely on local information, effectively meeting the training requirements of large-scale multi-agent systems. Specifically, we first introduce an adaptive grouping module, which divides each agent into different groups based on their observation history. To implement end-to-end training, GTDE uses Gumbel-Sigmoid for efficient point-to-point sampling on the grouping distribution while ensuring gradient backpropagation. To adapt to the uncertainty in the number of members in a group, two methods are used to implement a group information aggregation module that merges member information within the group. Empirical results show that in a cooperative environment with 495 agents, GTDE increased the total reward by an average of 382\% compared to the baseline. In a competitive environment with 64 agents, GTDE achieved a 100\% win rate against the baseline.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Societal Implications of Blockchain Technology in the Evolution of Humanity as a "Superorganism"</title>
<link>https://arxiv.org/abs/2501.10378</link>
<guid>https://arxiv.org/abs/2501.10378</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、加密资产、超级生物体、全球脑理论、分布式决策

总结:<br />
本文探讨了区块链技术和加密资产对社会的广泛影响，强调它们在人类演进为具有去中心化、自我调节系统的“超级生物体”过程中的作用。文章将区块链技术置于治理系统和全球经济体系（如金融系统）演变的背景下进行分析，并结合Nate Hagens的“超级生物体”理念与Francis Heylighen的“全球脑”理论。区块链的去中心化特性，连同人工智能和去中心化自治组织(DAOs)等进展，有可能重塑传统的金融、经济和治理结构，通过推动集体分布式决策和全球协调机制的出现来实现这一变革。同时，文章还将区块链的影响与Spiral Dynamics等发展理论相结合，说明区块链有可能促进社会超越层级模式的发展，推动从集中式权威向协作和自我治理社区的转变。综上所述，本文认为区块链不仅仅是一种经济工具，更是一种催化社会进化为成熟互联的全球行星有机体的力量。 <div>
arXiv:2501.10378v1 Announce Type: new 
Abstract: This article examines the broader societal implications of blockchain technology and crypto-assets, emphasizing their role in the evolution of humanity as a "superorganism" with decentralized, self-regulating systems. Drawing on interdisciplinary concepts such as Nate Hagens' "superorganism" idea and Francis Heylighen's "global brain" theory, the paper contextualizes blockchain technology within the ongoing evolution of governance systems and global systems such as the financial system. Blockchain's decentralized nature, in conjunction with advancements like artificial intelligence and decentralized autonomous organizations (DAOs), could transform traditional financial, economic, and governance structures by enabling the emergence of collective distributed decision-making and global coordination. In parallel, the article aligns blockchain's impact with developmental theories such as Spiral Dynamics. This framework is used to illustrate blockchain's potential to foster societal growth beyond hierarchical models, promoting a shift from centralized authority to collaborative and self-governed communities. The analysis provides a holistic view of blockchain as more than an economic tool, positioning it as a catalyst for the evolution of society into a mature, interconnected global planetary organism.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GLow -- A Novel, Flower-Based Simulated Gossip Learning Strategy</title>
<link>https://arxiv.org/abs/2501.10463</link>
<guid>https://arxiv.org/abs/2501.10463</guid>
<content:encoded><![CDATA[
<div> 关键词：Gossip Learning、Flower Framework、GLow、模拟、准确性

总结:
本文介绍了针对完全去中心化学习算法的研究现状，提出了一种新的方法——GLow。GLow利用先进的Flower框架，使研究人员能够模拟定制化的Gossip Learning系统，并在自定义网络拓扑结构上评估设备的可扩展性和收敛性，从而在实际部署前进行预测试。由于Flower框架原本只支持单纯的联邦学习策略，而不具备无中心权威机构的模拟功能，因此GLow被引入以填补这一空白。实验结果显示，GLow在MNIST和CIFAR10数据集上的准确率分别超过0.98和0.75，并在所有设计的实验中，其精度和收敛性与相应的集中式和联邦学习方法表现相当。 <div>
arXiv:2501.10463v1 Announce Type: new 
Abstract: Fully decentralized learning algorithms are still in an early stage of development. Creating modular Gossip Learning strategies is not trivial due to convergence challenges and Byzantine faults intrinsic in systems of decentralized nature. Our contribution provides a novel means to simulate custom Gossip Learning systems by leveraging the state-of-the-art Flower Framework. Specifically, we introduce GLow, which will allow researchers to train and assess scalability and convergence of devices, across custom network topologies, before making a physical deployment. The Flower Framework is selected for being a simulation featured library with a very active community on Federated Learning research. However, Flower exclusively includes vanilla Federated Learning strategies and, thus, is not originally designed to perform simulations without a centralized authority. GLow is presented to fill this gap and make simulation of Gossip Learning systems possible. Results achieved by GLow in the MNIST and CIFAR10 datasets, show accuracies over 0.98 and 0.75 respectively. More importantly, GLow performs similarly in terms of accuracy and convergence to its analogous Centralized and Federated approaches in all designed experiments.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Zaptos: Towards Optimal Blockchain Latency</title>
<link>https://arxiv.org/abs/2501.10612</link>
<guid>https://arxiv.org/abs/2501.10612</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链延迟、端到端、Zaptos、并行管道架构、Aptos区块链

总结:

本文关注的是区块链系统的端到端延迟问题，指出现有研究主要集中在优化拜占庭容错共识组件的延迟上。为此，文章提出了Zaptos，这是一种旨在最小化端到端延迟的同时保持高吞吐量的并行管道架构。Zaptos已被实现并在与Aptos区块链的分布式环境中进行了对比评估，结果显示在低负载下，Zaptos可降低25%的延迟，而在高负载下则能降低超过40%的延迟。尤其值得一提的是，Zaptos实现了每秒处理2万笔交易，并具有亚秒级延迟，其性能在具有亚秒级延迟的区块链系统中提升了整整一个数量级。 <div>
arXiv:2501.10612v1 Announce Type: new 
Abstract: End-to-end blockchain latency has become a critical topic of interest in both academia and industry. However, while modern blockchain systems process transactions through multiple stages, most research has primarily focused on optimizing the latency of the Byzantine Fault Tolerance consensus component.
  In this work, we identify key sources of latency in blockchain systems and introduce Zaptos, a parallel pipelined architecture designed to minimize end-to-end latency while maintaining the high-throughput of pipelined blockchains.
  We implemented Zaptos and evaluated it against the pipelined architecture of the Aptos blockchain in a geo-distributed environment. Our evaluation demonstrates a 25\% latency reduction under low load and over 40\% reduction under high load. Notably, Zaptos achieves a throughput of 20,000 transactions per second with sub-second latency, surpassing previously reported blockchain throughput, with sub-second latency, by an order of magnitude.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graph Coloring to Reduce Computation Time in Prioritized Planning</title>
<link>https://arxiv.org/abs/2501.10812</link>
<guid>https://arxiv.org/abs/2501.10812</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体路径规划、优先级规划、有向无环图、最长路径、图着色算法

总结:<br />
本文探讨了在大规模网络中通过优先级规划（PP）策略将计算任务分配给多个智能体以降低多智能体路径规划（MAPF）的计算成本。文章关注于PP中的交互代理优先级设定，利用有向无环图（DAG）刻画这种交互关系，其中计算时间主要取决于该DAG中最长路径的长度。针对已有文献中多种多样且追求不同目标的优先级设定方法，文章提出了一种用于减少耦合DAG中最长路径长度以及因此降低使用PP求解MAPF问题的时间的优先级确定新方法。作者证明此问题可以映射为图着色问题，所需的颜色数量对应于耦合DAG中最长路径的长度。进而，他们提出了一个分布式图着色算法来确定各智能体的优先级。最后，通过将其应用于道路环境中采用MAPF变体的连接和自动化车辆（CAVs）的多智能体运动规划（MAMP）进行评估。 <div>
arXiv:2501.10812v1 Announce Type: new 
Abstract: Distributing computations among agents in large networks reduces computational effort in multi-agent path finding (MAPF). One distribution strategy is prioritized planning (PP). In PP, we couple and prioritize interacting agents to achieve a desired behavior across all agents in the network. We characterize the interaction with a directed acyclic graph (DAG). The computation time for solving MAPF problem using PP is mainly determined through the longest path in this DAG. The longest path depends on the fixed undirected coupling graph and the variable prioritization. The approaches from literature to prioritize agents are numerous and pursue various goals. This article presents an approach for prioritization in PP to reduce the longest path length in the coupling DAG and thus the computation time for MAPF using PP. We prove that this problem can be mapped to a graph-coloring problem, in which the number of colors required corresponds to the longest path length in the coupling DAG. We propose a decentralized graph-coloring algorithm to determine priorities for the agents. We evaluate the approach by applying it to multi-agent motion planning (MAMP) for connected and automated vehicles (CAVs) on roads using, a variant of MAPF.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Selfish Mining Analysis for DAG-based PoW Consensus Protocols</title>
<link>https://arxiv.org/abs/2501.10888</link>
<guid>https://arxiv.org/abs/2501.10888</guid>
<content:encoded><![CDATA[
<div> 关键词:自私挖矿、Markov决策过程、协议设计、DAG、自动分析工具

总结:
本文研究了在工作量证明协议中的一种策略性违规行为——自私挖矿。文章指出，现有的Markov决策过程（MDP）主要用于分析比特币等线性链协议，而对于采用DAG结构的新型协议，MDP分析变得更为复杂。为解决这个问题，研究者们以往针对每个具体协议定制特殊的MDP模型，导致协议设计的反馈循环较长。因此，该文提出了一种通用攻击模型，能够覆盖包括以太坊工作量证明、GhostDAG和并行工作量证明等多种协议。其方法具有模块化特点：将每种协议简洁地定义为程序，并通过工具自动生成及求解自私挖矿的MDP，从而简化了协议修改带来的分析工作。 <div>
arXiv:2501.10888v1 Announce Type: new 
Abstract: Selfish mining is strategic rule-breaking to maximize rewards in proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred tool for finding optimal strategies in Bitcoin and similar linear chain protocols. Protocols increasingly adopt DAG-based chain structures, for which MDP analysis is more involved. To date, researchers have tailored specific MDPs for each protocol. Protocol design suffers long feedback loops, as each protocol change implies manual work on the MDP. To overcome this, we propose a generic attack model that covers a wide range of protocols, including Ethereum Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular: we specify each protocol as a concise program, and our tooling then derives and solves the selfish mining MDP automatically.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SLVC-DIDA: Signature-less Verifiable Credential-based Issuer-hiding and Multi-party Authentication for Decentralized Identity</title>
<link>https://arxiv.org/abs/2501.11052</link>
<guid>https://arxiv.org/abs/2501.11052</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Identity (DID)，Verifiable Credential (VC)，Permanent Issuer-Hiding (PIH)，Signature-less VC模型，SLVC-DIDA

<br /><br />总结：
本文提出了一种名为SLVC-DIDA的基于永久发行者隐藏（PIH）的DID多 party认证框架，该框架采用无签名的VC模型，旨在解决现有DID方案依赖分布式公钥基础设施所引发的问题，如上下文信息推断、密钥暴露和发行人数据泄露。SLVC-DIDA通过使用哈希和发行人成员身份证明避免了对签名密钥的依赖，支持通用零知识多 party DID认证，无需额外的技术集成。它利用零知识RSA累加器保持发行人集的匿名性，并通过Merkle树为基础的VC列表保护身份属性隐私。此外，SLVC-DIDA完全去中心化地实现DID的颁发与验证，并通过实施零知识的发行人集和VC列表保证PIH，从而有效缓解密钥泄漏和上下文推理攻击的风险。实验结果进一步验证了SLVC-DIDA的有效性和实用性。 <div>
arXiv:2501.11052v1 Announce Type: new 
Abstract: As an emerging paradigm in digital identity, Decentralized Identity (DID) appears advantages over traditional identity management methods in a variety of aspects, e.g., enhancing user-centric online services and ensuring complete user autonomy and control. Verifiable Credential (VC) techniques are used to facilitate decentralized DID-based access control across multiple entities. However, existing DID schemes generally rely on a distributed public key infrastructure that also causes challenges, such as context information deduction, key exposure, and issuer data leakage. To address the issues above, this paper proposes a Permanent Issuer-Hiding (PIH)-based DID multi-party authentication framework with a signature-less VC model, named SLVC-DIDA, for the first time. Our proposed scheme avoids the dependence on signing keys by employing hashing and issuer membership proofs, which supports universal zero-knowledge multi-party DID authentications, eliminating additional technical integrations. We adopt a zero-knowledge RSA accumulator to maintain the anonymity of the issuer set, thereby enabling public verification while safeguarding the privacy of identity attributes via a Merkle tree-based VC list. By eliminating reliance on a Public Key Infrastructure (PKI), SLVC-DIDA enables fully decentralized issuance and verification of DIDs. Furthermore, our scheme ensures PIH through the implementation of the zero-knowledge Issuer set and VC list, so that the risks of key leakage and contextual inference attacks are effectively mitigated. Our experiments further evaluate the effectiveness and practicality of SLVC-DIDA.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bitcoin: A Non-Continuous Time System</title>
<link>https://arxiv.org/abs/2501.11091</link>
<guid>https://arxiv.org/abs/2501.11091</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、区块链、非连续时间系统、块生成过程、分叉与回滚、交易重排序、未来影响

<br /><br />总结:
本文探讨了比特币区块链中的时间概念，该系统作为一个非连续时间系统运行。文章重点关注三个方面：随机和分布式的区块生成过程导致的时间不连贯性；区块链可能出现的分叉和回滚现象，这会打乱其线性发展进程；以及在这个系统中，受到可能的重新排序或无效化的交易性质。这些因素共同构建了一个与传统计算和物理学中常见的连续线性时间系统根本不同的时间结构。此外，文章还讨论了这种非连续时间模型对未来去中心化技术及其潜在应用的影响。 <div>
arXiv:2501.11091v1 Announce Type: new 
Abstract: In this paper, we explore the concept of time within Bitcoin's blockchain, which operates as a non-continuous time system. We focus on three core aspects that contribute to Bitcoin's time discontinuity: the random and distributed block generation process, the occurrence of forks and rollbacks that disrupt the linear progression of the blockchain, and the nature of transactions within this system, which are subject to potential reordering or invalidation. These elements combine to create a time structure in Bitcoin that is fundamentally different from the continuous, linear time systems typically seen in traditional computing and physics. Additionally, the implications of this non-continuous time model for the future of decentralized technologies and their potential applications are discussed.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain and Stablecoin Integration for Crowdfunding: A framework for enhanced efficiency, security, and liquidity</title>
<link>https://arxiv.org/abs/2501.11145</link>
<guid>https://arxiv.org/abs/2501.11145</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、稳定币、众筹、代币化、合规性

总结:
<br />
本文提出了一种基于区块链的众筹框架，该框架采用稳定币（如USDT和USDC）来缓解加密货币的波动性并确保资金管理的顺畅。通过智能合约自动化了包括了解客户（KYC）/反洗钱（AML）检查在内的合规流程，提升了运营效率。此外，代币化通过允许股份分割所有权和二级市场交易以实现流动性。文章对传统平台进行了比较分析，强调了新框架在降低成本、提高透明度和增强投资者信任方面的优势。通过以土耳其市场的案例研究，具体展示了区块链在股权众筹领域应用的实际效益，尤其是在应对地方监管和金融复杂性方面。这种方法为现代众筹生态系统提供了一个可扩展、安全且易访问的解决方案，同时降低了平台成本并增加了投资者和项目支持者对众筹项目的信任。 <div>
arXiv:2501.11145v1 Announce Type: new 
Abstract: Crowdfunding platforms face high transaction fees, need for more transparency, and trust deficits. These issues deter contributors and entrepreneurs from effectively leveraging crowdfunding for innovation and growth. Blockchain technology introduces decentralization, security, and efficiency to address these limitations (1). This paper proposes a blockchain-based crowdfunding framework that integrates stablecoins such as USDT and USDC to mitigate cryptocurrency volatility and ensure seamless fund management. Smart contracts automate compliance processes, including Know Your Customer (KYC) / Anti-Money Laundering (AML) checks, and enhance operational efficiency (2). Furthermore, tokenization enables liquidity by allowing fractional ownership and secondary market trading, which must be effectively implemented on any global market platform. A comparative analysis highlights the superiority of the framework over traditional platforms in terms of cost reduction, transparency, and investor trust. A case study focused on the Turkish market illustrates the practical benefits of blockchain adoption in equity crowdfunding, particularly in navigating local regulatory and financial complexities. This approach provides a scalable, secure, and accessible solution for modern crowdfunding ecosystems, while reducing the costs of platforms and increasing the trust of investors and backers in crowdfunding projects. Keywords Blockchain, stablecoins, crowdfunding, tokenization, and compliance
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Developer Experience: A Multivocal Literature Review</title>
<link>https://arxiv.org/abs/2501.11431</link>
<guid>https://arxiv.org/abs/2501.11431</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链、开发者体验、BcDEx、多网络支持

总结:<br />
随着智能合约推动区块链技术扩展其功能，分布式应用（dApps）的创新开发得以实现。然而，这也带来了分布式架构管理和不可变数据管理等新挑战。为应对这些复杂性，出现了专门针对区块链软件工程的实践方法。开发者体验（DEx）在此领域中扮演核心角色，关注工程师对工具和框架的可用性、生产力和整体满意度。尽管BcDEx的重要性日益凸显，但相关研究仍然有限，学术界与业界对此的关注尚未形成系统性的梳理。为此，研究者进行了多元文献综述，分析了62篇文献，揭示了相较于学术界的有限关注，灰色文献（主要是博客和企业来源）更广泛地涵盖了BcDEx内容。目前，工具和框架主要关注开发效率、多网络支持和易用性等方面。此外，BcDEx的发展主要受到五个关键视角的影响：复杂性抽象、推广便利性、生产率提升、开发者教育以及BcDEx评估。 <div>
arXiv:2501.11431v1 Announce Type: new 
Abstract: The rise of smart contracts has expanded blockchain's capabilities, enabling the development of innovative decentralized applications (dApps). However, this advancement brings its own challenges, including the management of distributed architectures and immutable data. Addressing these complexities requires a specialized approach to software engineering, with blockchain-oriented practices emerging to support development in this domain. Developer Experience (DEx) is central to this effort, focusing on the usability, productivity, and overall satisfaction of tools and frameworks from the engineers' perspective. Despite its importance, research on Blockchain Developer Experience (BcDEx) remains limited, with no systematic mapping of academic and industry efforts. To bridge this gap, we conducted a Multivocal Literature Review analyzing 62 to understand the distribution of BcDEx sources, practical implementations, and their impact. Our findings revealed that academic focus on BcDEx is limited compared to the coverage in gray literature, which primarily includes blogs (41.8%) and corporate sources (21.8%). Particularly, development efficiency, multi-network support, and usability are the most addressed aspects in tools and frameworks. In addition, we found that BcDEx is being shaped through five key perspectives: complexity abstraction, adoption facilitation, productivity enhancement, developer education, and BcDEx evaluation.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification</title>
<link>https://arxiv.org/abs/2501.11493</link>
<guid>https://arxiv.org/abs/2501.11493</guid>
<content:encoded><![CDATA[
<div> 关键词: 弹性网络 (Federated Learning)，通信效率，遥感 (Remote Sensing)，模型剪枝，层间相关传播 (Layerwise Relevance Propagation)

<br /><br />总结:

本文提出了一种基于解释引导的剪枝策略，用于提高遥感图像分类中弹性网络(FL)的通信效率。该策略利用层间相关传播(LRP)驱动的解释来有效地识别与任务最相关和最有信息性的模型参数，并剔除非相关信息以减小模型更新的传输量。实验结果显示，该策略能够在显著降低共享模型更新数量的同时，提升全球模型的泛化能力。该工作的代码将在https://git.tu-berlin.de/rsim/FL-LRP 公开发布。 <div>
arXiv:2501.11493v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized machine learning paradigm, where multiple clients collaboratively train a global model by exchanging only model updates with the central server without sharing the local data of clients. Due to the large volume of model updates required to be transmitted between clients and the central server, most FL systems are associated with high transfer costs (i.e., communication overhead). This issue is more critical for operational applications in remote sensing (RS), especially when large-scale RS data is processed and analyzed through FL systems with restricted communication bandwidth. To address this issue, we introduce an explanation-guided pruning strategy for communication-efficient FL in the context of RS image classification. Our pruning strategy is defined based on the layerwise relevance propagation (LRP) driven explanations to: 1) efficiently and effectively identify the most relevant and informative model parameters (to be exchanged between clients and the central server); and 2) eliminate the non-informative ones to minimize the volume of model updates. The experimental results on the BigEarthNet-S2 dataset demonstrate that our strategy effectively reduces the number of shared model updates, while increasing the generalization ability of the global model. The code of this work will be publicly available at https://git.tu-berlin.de/rsim/FL-LRP
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Characterizing Transfer Graphs of Suspicious ERC-20 Tokens</title>
<link>https://arxiv.org/abs/2501.11668</link>
<guid>https://arxiv.org/abs/2501.11668</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum, 区块链, 欺诈行为, 智能合约, ERC-20令牌

总结:
本文主要研究了Ethereum区块链上利用智能合约和ERC-20接口进行欺诈的行为。通过对以太坊区块链中超过20个时段、每个时段包含10万块的ERC-20合同事件日志进行解析，构建了各类ERC-20代币的转账图。通过分析这些转账图，作者发现了一些区分可疑与合法合约的关键特征，并据此建立了一个模型，该模型能够平均以88.7%的准确率识别欺诈性合约。这表明欺诈行为的运作机制与其转账图密切相关，转账图可以用于改进欺诈检测机制，有助于提升Ethereum的安全性。 <div>
arXiv:2501.11668v1 Announce Type: new 
Abstract: Ethereum is currently the second largest blockchain by market capitalization and a popular platform for cryptocurrencies. As it has grown, the high value present and the anonymity afforded by the technology have led Ethereum to become a hotbed for various cybercrimes. This paper seeks to understand how these fraudulent schemes may be characterized and develop methods for detecting them. One key feature introduced by Ethereum is the ability to use programmable smart contracts to execute code on the blockchain. A common use of smart contracts is implementing fungible tokens with the ERC-20 interface. Such tokens can be used to impersonate legitimate tokens and defraud users. By parsing the event logs emitted by these ERC-20 contracts over 20 different periods of 100K blocks, we construct token transfer graphs for each of the available ERC-20 tokens on the blockchain. By analyzing these graphs, we find a set of characteristics by which suspicious contracts are distinguished from legitimate ones. These observations result in a simple model that can identify scam contracts with an average of 88.7% accuracy. This suggests that the mechanism by which fraudulent schemes function strongly correlates with their transfer graphs and that these graphs may be used to improve scam-detection mechanisms, contributing to making Ethereum safer.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Key Concepts and Principles of Blockchain Technology</title>
<link>https://arxiv.org/abs/2501.11707</link>
<guid>https://arxiv.org/abs/2501.11707</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、分布式、去中心化、优势、挑战

<br /><br />总结:
本文探讨了区块链技术的核心特性，如分布式和去中心化的架构，该特性使其成为比特币等数字货币的基础并广泛应用于各行各业。区块链技术的主要优点在于提高交易安全性和透明度，并防止单一实体对网络的控制。文章分析了其在不同行业的应用案例以及采用此技术的原因，同时指出了面临的挑战，如可扩展性问题和高能耗。此外，还阐述了区块链如何增强经济与社会互动中的效率与安全性。最后，通过对各行业区块链应用的比较和未来趋势分析，得出了一份全面的结论。 <div>
arXiv:2501.11707v1 Announce Type: new 
Abstract: In recent years, blockchain technology has been recognized as a transformative innovation in the tech world, and it has quickly become the core infrastructure of digital currencies such as Bitcoin and an important tool in various industries. This technology facilitates the recording and tracking of transactions across a vast network of computers by providing a distributed and decentralized ledger. Blockchain's decentralized structure significantly enhances security and transparency and prevents a single entity from dominating the network. This chapter examines blockchain's advantages, disadvantages, and applications in various industries and analyzes the implementation environments and reasons for using this technology. Also, this chapter discusses challenges such as scalability and high energy consumption that inhibit the expansion of this technology and examines blockchain technology's role in increasing efficiency and security in economic and social interactions. Finally, a comprehensive conclusion of blockchain applications and challenges has been presented by comparing blockchain applications in various industries and analyzing future trends.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personalized Federated Learning for Cellular VR: Online Learning and Dynamic Caching</title>
<link>https://arxiv.org/abs/2501.11745</link>
<guid>https://arxiv.org/abs/2501.11745</guid>
<content:encoded><![CDATA[
<div> 关键词：虚拟现实(VR)，无线连接，视场角(FoV)缓存，移动边缘计算(MEC)，分布式个性化联邦学习(DP-FL)

总结:

该文提出了一种针对移动边缘计算(MEC)支持的无线VR网络的视场角(FoV)感知缓存方案。该方案基于每个基站(BS)定制的缓存策略，预先将VR用户的FoV内容缓存在BS处。文章重点介绍了具有性能保证的分散式个性化联邦学习(DP-FL)缓存策略。在一个由多个VR设备和BS组成的VR系统中，每个BS利用DP-FL算法实现个性化内容投递，确保了条件平均缓存命中的概率近似正确(PAC)界。为降低梯度通信成本，文中还提出了基于一比特量化随机梯度下降(OBSGD)的方法，并得到了收敛性保证$\mathcal{O}(1/\sqrt{T})$，其中T表示迭代次数。此外，考虑到无线信道动态性，根据请求VR用户数量，将FoV划分为组播或单播组。通过真实VR头动追踪数据集验证了所提DP-FL算法的性能，并表明其在平均延迟和缓存命中率方面优于基线算法。 <div>
arXiv:2501.11745v1 Announce Type: new 
Abstract: Delivering an immersive experience to virtual reality (VR) users through wireless connectivity offers the freedom to engage from anywhere at any time. Nevertheless, it is challenging to ensure seamless wireless connectivity that delivers real-time and high-quality videos to the VR users. This paper proposes a field of view (FoV) aware caching for mobile edge computing (MEC)-enabled wireless VR network. In particular, the FoV of each VR user is cached/prefetched at the base stations (BSs) based on the caching strategies tailored to each BS. Specifically, decentralized and personalized federated learning (DP-FL) based caching strategies with guarantees are presented. Considering VR systems composed of multiple VR devices and BSs, a DP-FL caching algorithm is implemented at each BS to personalize content delivery for VR users. The utilized DP-FL algorithm guarantees a probably approximately correct (PAC) bound on the conditional average cache hit. Further, to reduce the cost of communicating gradients, one-bit quantization of the stochastic gradient descent (OBSGD) is proposed, and a convergence guarantee of $\mathcal{O}(1/\sqrt{T})$ is obtained for the proposed algorithm, where $T$ is the number of iterations. Additionally, to better account for the wireless channel dynamics, the FoVs are grouped into multicast or unicast groups based on the number of requesting VR users. The performance of the proposed DP-FL algorithm is validated through realistic VR head-tracking dataset, and the proposed algorithm is shown to have better performance in terms of average delay and cache hit as compared to baseline algorithms.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPID-Chain: A Smart Contract-Enabled, Polar-Coded Interoperable DAG Chain</title>
<link>https://arxiv.org/abs/2501.11794</link>
<guid>https://arxiv.org/abs/2501.11794</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3, SPID-Chain, 交互性共识, 有向无环图(DAG), 分布式计算优化

<br /><br />总结:
本文介绍了SPID-Chain，这是一个针对Web3的新型交互性共识机制，旨在实现区块链网络间的无缝集成。SPID-Chain利用基于DAG的多区块链结构，其中每个区块链保持自己的共识并通过结合事件驱动智能合约(EDSC)和极化码的内部共识机制处理交易，提高了交易处理效率。此外，通过委员会节点和工作节点的分工进一步提升效率。在跨链共识层面，各区块链使用DAG结构添加包含跨链交易的区块，并通过区块链协调的跨共识机制进行处理。模拟实验验证了该方案在吞吐量、可扩展性、去中心化和安全性方面的有效性，显示了SPID-Chain赋能不同区块链网络间流畅互动与交易的潜力，符合Web3的核心理念。 <div>
arXiv:2501.11794v1 Announce Type: new 
Abstract: As the digital landscape evolves, Web3 has gained prominence, highlighting the critical role of decentralized, interconnected, and verifiable digital ecosystems. This paper introduces SPID-Chain, a novel interoperability consensus designed for Web3, which employs a directed acyclic graph (DAG) of blockchains to facilitate seamless integration across multiple blockchains. Within SPID-Chain, each blockchain maintains its own consensus and processes transactions via an intra-consensus mechanism that incorporates event-driven smart contracts (EDSC) and Polar codes for optimized computation distribution. This mechanism is complemented by a division of committee and worker nodes, enhancing transaction processing efficiency within individual chains. For inter-blockchain consensus, SPID-Chain utilizes a DAG structure where blockchains append blocks containing cross-chain transactions. These blocks are then processed through the inter-consensus mechanism orchestrated by the blockchains. Extensive simulations validate the efficacy of our scheme in terms of throughput, scalability, decentralization, and security. Our results showcase SPID-Chain's potential to enable fluid interactions and transactions across diverse blockchain networks, aligning with the foundational goals of Web3.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Security Risk Assessment in Quantum Era, Migration Strategies and Proactive Defense</title>
<link>https://arxiv.org/abs/2501.11798</link>
<guid>https://arxiv.org/abs/2501.11798</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算、区块链安全、风险评估、量子抵抗型加密、迁移策略

<br />
总结:
本文针对量子计算对区块链系统安全性构成的重大挑战进行了深入研究。文章全面分析了量子计算机威胁到区块链的关键组件——网络、挖矿池、交易验证机制、智能合约和用户钱包的风险。同时，论文阐述了过渡到量子抵抗型加密算法过程中的复杂挑战和战略考量，并提出一种混合迁移策略，旨在确保从传统到量子抵抗型加密的平稳过渡。文中还详细评估了比特币、以太坊、瑞波币、莱特币和zcash等主流区块链的脆弱性、潜在影响及关联STRIDE威胁，识别出了容易受到量子攻击的领域。此外，为应对量子计算机带来的日益严重的网络安全威胁，本文提出了构建安全、有韧性的区块链生态系统的定制化安全蓝图，并强调区块链相关各方应采取积极措施，实施量子抵抗型解决方案的重要性。总的来说，本文旨在引导读者理解和适应量子时代下复杂的安全环境，确保区块链系统的稳健和自信运行。 <div>
arXiv:2501.11798v1 Announce Type: new 
Abstract: The emergence of quantum computing presents a formidable challenge to the security of blockchain systems. Traditional cryptographic algorithms, foundational to digital signatures, message encryption, and hashing functions, become vulnerable to the immense computational power of quantum computers. This paper conducts a thorough risk assessment of transitioning to quantum-resistant blockchains, comprehensively analyzing potential threats targeting vital blockchain components: the network, mining pools, transaction verification mechanisms, smart contracts, and user wallets. By elucidating the intricate challenges and strategic considerations inherent in transitioning to quantum-resistant algorithms, the paper evaluates risks and highlights obstacles in securing blockchain components with quantum-resistant cryptography. It offers a hybrid migration strategy to facilitate a smooth transition from classical to quantum-resistant cryptography. The analysis extends to prominent blockchains such as Bitcoin, Ethereum, Ripple, Litecoin, and Zcash, assessing vulnerable components, potential impacts, and associated STRIDE threats, thereby identifying areas susceptible to quantum attacks. Beyond analysis, the paper provides actionable guidance for designing secure and resilient blockchain ecosystems in the quantum computing era. Recognizing the looming threat of quantum computers, this research advocates for a proactive transition to quantum-resistant blockchain networks. It proposes a tailored security blueprint that strategically fortifies each component against the evolving landscape of quantum-induced cyber threats. Emphasizing the critical need for blockchain stakeholders to adopt proactive measures and implement quantum-resistant solutions, the paper underscores the importance of embracing these insights to navigate the complexities of the quantum era with resilience and confidence.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-source Multi-level Multi-token Ethereum Dataset and Benchmark Platform</title>
<link>https://arxiv.org/abs/2501.11906</link>
<guid>https://arxiv.org/abs/2501.11906</guid>
<content:encoded><![CDATA[
<div> 关键词：3MEthTaskforce、多源、多层、多令牌、Ethereum数据集

总结:
<br />
本文介绍了3MEthTaskforce（https://3meth.github.io），这是一个针对单一来源数据集局限性的多源、多层次、多令牌的Ethereum数据集。该数据集综合了从2014年至2024年超过3亿笔交易记录、3880个代币档案、全球市场指标以及Reddit情绪数据，从而支持对用户行为、市场情绪和代币表现进行全方位研究。此外，3MEthTaskforce为用户行为预测和代币价格预测任务定义了基准，并采用6种动态图网络和19种时间序列模型来评估性能。其多模态设计有利于风险分析和市场波动建模，为推动区块链分析和去中心化金融研究提供了宝贵资源。 <div>
arXiv:2501.11906v1 Announce Type: new 
Abstract: This paper introduces 3MEthTaskforce (https://3meth.github.io), a multi-source, multi-level, and multi-token Ethereum dataset addressing the limitations of single-source datasets. Integrating over 300 million transaction records, 3,880 token profiles, global market indicators, and Reddit sentiment data from 2014-2024, it enables comprehensive studies on user behavior, market sentiment, and token performance. 3MEthTaskforce defines benchmarks for user behavior prediction and token price prediction tasks, using 6 dynamic graph networks and 19 time-series models to evaluate performance. Its multimodal design supports risk analysis and market fluctuation modeling, providing a valuable resource for advancing blockchain analytics and decentralized finance research.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning</title>
<link>https://arxiv.org/abs/2501.12046</link>
<guid>https://arxiv.org/abs/2501.12046</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, communication efficiency, privacy protection, CEPAM, RSUQ

总结:
本文提出了一种名为通信效率与隐私适应性机制(CEPAM)的新方法，用于在联邦学习(federated learning)中解决分布式私人数据训练机器学习模型时面临的通信效率和隐私保护两大挑战。CEPAM利用了拒绝采样通用量化器(RSUQ)，该量化器可以将失真等同于预设的噪声（如高斯或拉普拉斯噪声），从而实现差分隐私和压缩的同时保证。此外，文章分析了CEPAM在用户隐私、全局效用和传输率之间的权衡关系，并为具有差分隐私和压缩的FL定义了适当的度量标准。CEPAM还具备隐私自适应性优势，允许客户端和服务器根据所需精度和保护程度定制隐私保护策略。通过使用MNIST数据集进行评估，CEPAM显示出了比基线模型更高的学习准确性优势。 <div>
arXiv:2501.12046v1 Announce Type: new 
Abstract: Training machine learning models on decentralized private data via federated learning (FL) poses two key challenges: communication efficiency and privacy protection. In this work, we address these challenges within the trusted aggregator model by introducing a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), achieving both objectives simultaneously. In particular, CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a construction of randomized vector quantizer whose resulting distortion is equivalent to a prescribed noise, such as Gaussian or Laplace noise, enabling joint differential privacy and compression. Moreover, we analyze the trade-offs among user privacy, global utility, and transmission rate of CEPAM by defining appropriate metrics for FL with differential privacy and compression. Our CEPAM provides the additional benefit of privacy adaptability, allowing clients and the server to customize privacy protection based on required accuracy and protection. We assess CEPAM's utility performance using MNIST dataset, demonstrating that CEPAM surpasses baseline models in terms of learning accuracy.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BotDetect: A Decentralized Federated Learning Framework for Detecting Financial Bots on the EVM Blockchains</title>
<link>https://arxiv.org/abs/2501.12112</link>
<guid>https://arxiv.org/abs/2501.12112</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized federated learning (DFL)，financial bots，Ethereum Virtual Machine (EVM)，blockchain networks，malicious bot behavior

总结:<br />
本文提出了一种基于去中心化联邦学习(DFL)的方法，用于检测以太坊虚拟机(EVM)为基础的区块链网络中的金融机器人。该框架利用联邦学习并通过智能合约进行协调，能够在保护数据隐私的同时，适应区块链的去中心化特性，检测恶意机器人行为。与集中式和规则基方案相比，系统允许各参与节点使用交易历史和智能合约交互数据训练本地模型，随后通过许可型共识机制在链上聚合模型更新。这样设计使得模型能够捕捉到复杂且不断演进的机器人行为，而无需节点间直接分享数据。实验结果显示，该DFL框架在保持高检测精度、可扩展性和鲁棒性的同时，为分布式区块链网络提供了有效的机器人检测解决方案。 <div>
arXiv:2501.12112v1 Announce Type: new 
Abstract: The rapid growth of decentralized finance (DeFi) has led to the widespread use of automated agents, or bots, within blockchain ecosystems like Ethereum, Binance Smart Chain, and Solana. While these bots enhance market efficiency and liquidity, they also raise concerns due to exploitative behaviors that threaten network integrity and user trust. This paper presents a decentralized federated learning (DFL) approach for detecting financial bots within Ethereum Virtual Machine (EVM)-based blockchains. The proposed framework leverages federated learning, orchestrated through smart contracts, to detect malicious bot behavior while preserving data privacy and aligning with the decentralized nature of blockchain networks. Addressing the limitations of both centralized and rule-based approaches, our system enables each participating node to train local models on transaction history and smart contract interaction data, followed by on-chain aggregation of model updates through a permissioned consensus mechanism. This design allows the model to capture complex and evolving bot behaviors without requiring direct data sharing between nodes. Experimental results demonstrate that our DFL framework achieves high detection accuracy while maintaining scalability and robustness, providing an effective solution for bot detection across distributed blockchain networks.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Heterogeneous Federated Learning System for Sparse Healthcare Time-Series Prediction</title>
<link>https://arxiv.org/abs/2501.12125</link>
<guid>https://arxiv.org/abs/2501.12125</guid>
<content:encoded><![CDATA[
<div> 关键词：异构联邦学习（HFL）、稀疏时间序列预测、医疗保健、模型安全性、知识转移

总结:
本文提出了一种针对医疗保健领域稀疏时间序列预测的异构联邦学习（HFL）系统。该系统是一种分布式联邦学习算法，具有异构迁移特性，能有效处理数据源的稀疏性。通过设计密集和稀疏特征张量来应对数据的稀疏问题，同时开发了异构联邦学习以实现网络部分的异步共享以及选择适合的知识迁移模型。实验结果显示，所提出的HFL在十项预测任务中的八项上取得了最低预测误差，相比基准系统，MSE减少了94.8%、48.3%和52.1%。这证明了HFL在从不同领域进行知识迁移特别是在小目标领域的有效性。此外，消融研究进一步证实了异构域选择与切换机制在保证隐私、模型安全性和异构知识转移方面设计的有效性。 <div>
arXiv:2501.12125v1 Announce Type: new 
Abstract: In this paper, we propose a heterogeneous federated learning (HFL) system for sparse time series prediction in healthcare, which is a decentralized federated learning algorithm with heterogeneous transfers. We design dense and sparse feature tensors to deal with the sparsity of data sources. Heterogeneous federated learning is developed to share asynchronous parts of networks and select appropriate models for knowledge transfer. Experimental results show that the proposed HFL achieves the lowest prediction error among all benchmark systems on eight out of ten prediction tasks, with MSE reduction of 94.8%, 48.3%, and 52.1% compared to the benchmark systems. These results demonstrate the effectiveness of HFL in transferring knowledge from heterogeneous domains, especially in the smaller target domain. Ablation studies then demonstrate the effectiveness of the designed mechanisms for heterogeneous domain selection and switching in predicting healthcare time series with privacy, model security, and heterogeneous knowledge transfer.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Empower Healthcare through a Self-Sovereign Identity Infrastructure for Secure Electronic Health Data Access</title>
<link>https://arxiv.org/abs/2501.12229</link>
<guid>https://arxiv.org/abs/2501.12229</guid>
<content:encoded><![CDATA[
<div> 关键词: 健康数据管理框架、患者中心、自主权身份、区块链技术、去中心化标识符、可验证凭证<br /><br />总结:
本文提出了一种基于患者中心的开源健康数据管理框架，该框架采用了自主权身份理念，并结合了去中心化标识符和可验证凭证等创新技术。通过利用区块链技术，该框架实现了数据的不可变性、可验证的数据注册和审计能力，同时采用代理模型以保护和确保患者数据的隐私。文章详细描述了针对日常病人-医生-实验室交互场景的不同使用案例，并定义了应对患者数据丢失、数据访问撤销以及紧急情况下无法获取患者同意的情况下的具体功能。为了验证这一设计，作者构建了一个概念验证原型，涉及患者与医生之间的互动，并讨论了本框架的创新点，包括患者中心的数据存储方式、设计的恢复与应急计划、定义的备份流程以及所选择的区块链平台。 <div>
arXiv:2501.12229v1 Announce Type: new 
Abstract: Health data is one of the most sensitive data for people, which attracts the attention of malicious activities. We propose an open-source health data management framework, that follows a patient-centric approach. The proposed framework implements the Self-Sovereign Identity paradigm with innovative technologies such as Decentralized Identifiers and Verifiable Credentials. The framework uses Blockchain technology to provide immutability, verifiable data registry, and auditability, as well as an agent-based model to provide protection and privacy for the patient data. We also define different use cases regarding the daily patient-practitioner-laboratory interactions and specific functions to cover patient data loss, data access revocation, and emergency cases where patients are unable to give consent and access to their data. To address this design, a proof of concept is created with an interaction between patient and doctor. The most feasible technologies are selected and the created design is validated. We discuss the differences and novelties of this framework, which includes the patient-centric approach also for data storage, the designed recovery and emergency plan, the defined backup procedure, and the selected blockchain platform.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CYCle: Choosing Your Collaborators Wisely to Enhance Collaborative Fairness in Decentralized Learning</title>
<link>https://arxiv.org/abs/2501.12344</link>
<guid>https://arxiv.org/abs/2501.12344</guid>
<content:encoded><![CDATA[
<div> 关键词：协同学习，分布式数据源，公平性，最大均值协作增益，协作增益传播

<br /><br />总结:

本文关注协同学习（CL）中多个参与方在不共享原始数据的情况下联合训练机器学习模型的问题，强调了确保合作收益公平分配的重要性。现有的CL算法大多需要中心协调并侧重于最大化预期准确率提升，而忽视了合作公平性。作者指出，基于准确性值的相关性来衡量的合作公平性存在缺陷，因为它未考虑负向合作收益的情况。他们提出了一种更公平的目标，即同时最大化均值协作增益（MCG）和最小化协作增益传播（CGS）。为此，文章提出了CYCle协议，该协议在私人分布式学习框架下允许各参与者通过一种基于局部交叉熵损失与蒸馏损失梯度对齐的新颖声誉评分方法实现这一目标。实验结果表明，CYCle协议在CIFAR-10、CIFAR-100和Fed-ISIC2019等数据集上能够有效确保所有参与者的正向和公平的合作收益，即使在参与者数据分布高度偏斜的情况下也是如此。此外，对于有两个参与者的简单平均估计问题，理论上也证明了CYCle相比于标准的FedAvg具有更好的性能，特别是在统计异质性较大的情况下。 <div>
arXiv:2501.12344v1 Announce Type: new 
Abstract: Collaborative learning (CL) enables multiple participants to jointly train machine learning (ML) models on decentralized data sources without raw data sharing. While the primary goal of CL is to maximize the expected accuracy gain for each participant, it is also important to ensure that the gains are fairly distributed. Specifically, no client should be negatively impacted by the collaboration, and the individual gains must ideally be commensurate with the contributions. Most existing CL algorithms require central coordination and focus on the gain maximization objective while ignoring collaborative fairness. In this work, we first show that the existing measure of collaborative fairness based on the correlation between accuracy values without and with collaboration has drawbacks because it does not account for negative collaboration gain. We argue that maximizing mean collaboration gain (MCG) while simultaneously minimizing the collaboration gain spread (CGS) is a fairer alternative. Next, we propose the CYCle protocol that enables individual participants in a private decentralized learning (PDL) framework to achieve this objective through a novel reputation scoring method based on gradient alignment between the local cross-entropy and distillation losses. Experiments on the CIFAR-10, CIFAR-100, and Fed-ISIC2019 datasets empirically demonstrate the effectiveness of the CYCle protocol to ensure positive and fair collaboration gain for all participants, even in cases where the data distributions of participants are highly skewed. For the simple mean estimation problem with two participants, we also theoretically show that CYCle performs better than standard FedAvg, especially when there is large statistical heterogeneity.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Budget-constrained Collaborative Renewable Energy Forecasting Market</title>
<link>https://arxiv.org/abs/2501.12367</link>
<guid>https://arxiv.org/abs/2501.12367</guid>
<content:encoded><![CDATA[
<div> 关键词: 可再生能源, 功率预测, 分布式时空数据, 数据共享激励机制, 弹性套索回归模型<br /><br />总结:
这篇论文关注了可再生能源功率预测的重要性，并强调了整合分布式时空数据对提升预测准确性的关键作用。然而，数据的所有权分散成为实现这一目标的一大障碍。文章的主要贡献包括：a) 对预报模型进行了比较分析，推荐使用高效和可解释的弹性套索回归模型；b) 提出了一种投标机制，用于数据/分析市场中的公平补偿数据提供者，并允许买卖双方表达各自的数据价格要求；c) 进一步设计了一个时间序列预测的激励机制，有效地结合了价格约束并避免了冗余特征分配。实验结果显示，与本地生成的预测相比，该提案方法在风力发电数据上的平均均方根误差提高了超过10%，同时为数据卖方带来了潜在的经济收益。 <div>
arXiv:2501.12367v1 Announce Type: new 
Abstract: Accurate power forecasting from renewable energy sources (RES) is crucial for integrating additional RES capacity into the power system and realizing sustainability goals. This work emphasizes the importance of integrating decentralized spatio-temporal data into forecasting models. However, decentralized data ownership presents a critical obstacle to the success of such spatio-temporal models, and incentive mechanisms to foster data-sharing need to be considered. The main contributions are a) a comparative analysis of the forecasting models, advocating for efficient and interpretable spline LASSO regression models, and b) a bidding mechanism within the data/analytics market to ensure fair compensation for data providers and enable both buyers and sellers to express their data price requirements. Furthermore, an incentive mechanism for time series forecasting is proposed, effectively incorporating price constraints and preventing redundant feature allocation. Results show significant accuracy improvements and potential monetary gains for data sellers. For wind power data, an average root mean squared error improvement of over 10% was achieved by comparing forecasts generated by the proposal with locally generated ones.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Local Limits of Small World Networks</title>
<link>https://arxiv.org/abs/2501.11226</link>
<guid>https://arxiv.org/abs/2501.11226</guid>
<content:encoded><![CDATA[
<div> 关键词: 小世界网络、局部收敛、Watts-Strogatz模型、Kleinberg模型、PageRank

总结:
这篇论文研究了小世界网络中的局部结构行为，特别是针对两种常用的小世界网络模型——Watts-Strogatz模型和Kleinberg模型。通过应用局部收敛理论，论文证明了随着网络规模增大，关键网络度量（如PageRank、聚类系数和最大匹配大小）的极限值由图的局部结构决定。此外，该框架还使得仅利用小邻域内的局部信息就能估计全局现象，例如信息传播。论文结果进一步揭示，当Kleinberg模型中控制长程连接的参数越过了保持去中心化搜索效率的阈值时，极限行为会出现显著变化，为理解在某些情况下去中心化算法为何失效提供了新的视角。 <div>
arXiv:2501.11226v1 Announce Type: cross 
Abstract: Small-world networks, known for their high local clustering and short average path lengths, are a fundamental structure in many real-world systems, including social, biological, and technological networks. We apply the theory of local convergence (Benjamini-Schramm convergence) to derive the limiting behavior of the local structures for two of the most commonly studied small-world network models: the Watts-Strogatz model and the Kleinberg model. Establishing local convergence enables us to show that key network measures, such as PageRank, clustering coefficients, and maximum matching size, converge as network size increases with their limits determined by the graph's local structure. Additionally, this framework facilitates the estimation of global phenomena, such as information cascades, using local information from small neighborhoods. As an additional outcome of our results, we observe a critical change in the behavior of the limit exactly when the parameter governing long-range connections in the Kleinberg model crosses the threshold where decentralized search remains efficient, offering a new perspective on why decentralized algorithms fail in certain regimes.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature</title>
<link>https://arxiv.org/abs/2308.12420</link>
<guid>https://arxiv.org/abs/2308.12420</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Ledger Technology (DLT)，Environmental, Social, and Governance (ESG)，Natural Language Processing (NLP)，Named Entity Recognition (NER)，Proof of Work (PoW)

总结:

本文关注了分布式账本技术（DLT）在环境影响、特别是能源消耗和更广泛的ESG考量方面所面临的日益增长的关注。针对现有文献综述存在的局限性，作者通过使用自然语言处理（NLP）对24,539篇出版物全文进行分析，并结合手动标注的39,427个DLT相关实体命名实体识别（NER）数据集，识别出了连接DLT与ESG领域的关键505篇文献，从而提供了对该领域更为全面和深入的理解。研究运用NLP和时间图分析方法揭示了DLT演进及ESG影响的关键趋势，包括加密学和点对点网络研究的重要性、比特币在研究及环保问题上的持久影响力（“林迪效应”）、以太坊对权益证明（PoS）和智能合约采纳的影响以及向节能共识机制的转变。此外，文章还贡献了一个首个针对DLT的专业NER数据集，以解决区块链研究中高质量标注NLP数据的稀缺问题；提出了一种将NLP与时间图分析相结合的大规模跨学科文献回顾方法；并完成了首个以ESG为重点的NLP驱动的DLT文献回顾。 <div>
arXiv:2308.12420v3 Announce Type: replace 
Abstract: Emerging technologies, such as Distributed Ledger Technology (DLT), face growing scrutiny for their environmental impact, especially when it comes to the energy use of the Proof of Work (PoW) consensus mechanism and broader Environmental, Social, and Governance (ESG) considerations. Yet, much of the existing systematic literature reviews of DLT rely on the limited analyses of citations, abstracts, and keywords, failing to fully capture the field's complexity and ESG concerns.
  To address these challenges, we analyze the full text of 24,539 publications using Natural Language Processing (NLP) with our manually labeled Named Entity Recognition (NER) dataset of 39,427 entities for DLT. This method identifies 505 key publications connecting DLT and ESG domains, providing a more comprehensive and nuanced understanding of the field.
  Our combined NLP and temporal graph analysis reveals critical trends in DLT evolution and ESG impacts, including the pivotal role of research in cryptography and peer-to-peer networks, Bitcoin's persistent impact on research and environmental concerns (a "Lindy effect"), Ethereum's influence on Proof of Stake (PoS) and smart contracts adoption, and a shift towards energy-efficient consensus mechanisms. Our contributions include the first DLT-specific NER dataset, addressing the scarcity of high-quality labeled NLP data for blockchain research; a methodology integrating NLP and temporal graph analysis for interdisciplinary literature review at large scale; and the first NLP-driven DLT literature review emphasizing ESG aspects.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A High-throughput and Secure Coded Blockchain for IoT</title>
<link>https://arxiv.org/abs/2310.08822</link>
<guid>https://arxiv.org/abs/2310.08822</guid>
<content:encoded><![CDATA[
<div> 关键词：coded blockchain, IoT网络, reward模型, consensus算法, raptor codes

总结:
本文提出了一种适用于物联网(IoT)网络的新颖编码区块链方案。该方案相比现有的编码区块链工作更具有现实性、实用性和安全性，同时能实现高吞吐量。<br />
<br />
首先，通过对交易多样性建模并基于奖励模型解决优化问题，选择那些更容易访问和计算成本更低的交易进行联合处理；其次，设计了一个交易驱动的轻量级共识算法，强调使用最少数量的矿工来处理交易；再者，利用raptor码进行线性时间编码与解码，从而降低维护区块链所需的存储空间并提高吞吐量。<br />
<br />
文章对所提方案进行了详细分析和模拟结果展示，并将其与包括Polyshard和LCB在内的现有领先的编码IoT区块链方案进行了比较，证明了所提方案在安全性、存储需求、去中心化程度和吞吐量等方面的优越性。 <div>
arXiv:2310.08822v2 Announce Type: replace 
Abstract: We propose a new coded blockchain scheme suitable for the Internet-of-Things (IoT) network. In contrast to existing works for coded blockchains, especially blockchain-of-things, the proposed scheme is more realistic, practical, and secure while achieving high throughput. This is accomplished by: 1) modeling the variety of transactions using a reward model, based on which an optimization problem is solved to select transactions that are more accessible and cheaper computational-wise to be processed together; 2) a transaction-based and lightweight consensus algorithm that emphasizes on using the minimum possible number of miners for processing the transactions; and 3) employing the raptor codes with linear-time encoding and decoding which results in requiring lower storage to maintain the blockchain and having a higher throughput. We provide detailed analysis and simulation results on the proposed scheme and compare it with the state-of-the-art coded IoT blockchain schemes including Polyshard and LCB, to show the advantages of our proposed scheme in terms of security, storage, decentralization, and throughput.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SAMM: Sharded Automated Market Maker</title>
<link>https://arxiv.org/abs/2406.05568</link>
<guid>https://arxiv.org/abs/2406.05568</guid>
<content:encoded><![CDATA[
<div> 关键词: Automated Market Maker (AMM), SAMM, Sharding, Incentive Compatibility, Throughput

<br /><br />总结:
本文提出了一个新的自动化做市商（AMM）模型SAMM，它通过将多个独立运行的碎片化AMM集成在同一链上实现并行执行，解决了现有AMM架构无法满足未来快速增长的需求问题。与传统的分片解决方案不同，SAMM依赖于激励相容性来确保安全性，并引入了一种新的费用设计。通过分析子博弈完美纳什均衡（SPNE），作者证明了SAMM能够激励流动性提供者在所有碎片间平衡流动性，抵御destabilization攻击，并使交易均匀分布。使用真实世界数据进行的模拟验证了这一游戏理论分析。此外，文章还实现了并在Sui和Solana区块链的本地测试网上部署了SAMM，结果显示其分别提高了5倍和16倍的吞吐量，有望随着底层区块链更好的并行化进一步提升性能。SAMM方案直接可部署，有助于缓解即将到来的扩容瓶颈问题。 <div>
arXiv:2406.05568v5 Announce Type: replace 
Abstract: Automated Market Makers (AMMs) are a cornerstone of decentralized finance. They are smart contracts (stateful programs) running on blockchains. They enable virtual token exchange: traders swap tokens with the AMM for a fee, while liquidity providers supply liquidity and receive these fees. Demand for AMMs is growing rapidly, but our experiment-based estimates show that current architectures cannot meet the projected demand by 2029. This is because the execution of existing AMMs is non-parallelizable.
  We present SAMM, an AMM comprising multiple shards. All shards are AMMs running on the same chain, but their independence enables parallel execution. Unlike classical sharding solutions, here security relies on incentive compatibility. Therefore, SAMM introduces a novel fee design. Through analysis of Subgame-Perfect Nash Equilibria (SPNE), we show that SAMM incentivizes the desired behavior: liquidity providers balance liquidity among all shards, overcoming destabilization attacks, and trades are evenly distributed. We validate our game-theoretic analysis with a simulation using real-world data.
  We evaluate SAMM by implementing and deploying it on local testnets of the Sui and Solana blockchains. To our knowledge, this is the first quantification of high-demand-contract performance. SAMM improves throughput by 5x and 16x, respectively, potentially more with better parallelization of the underlying blockchains. It is directly deployable, mitigating the upcoming scaling bottleneck.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personhood credentials: Artificial intelligence and the value of privacy-preserving tools to distinguish who is real online</title>
<link>https://arxiv.org/abs/2408.07892</link>
<guid>https://arxiv.org/abs/2408.07892</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名性、人工智能、身份凭证、信任度、在线平台

<br /><br />总结:

本文探讨了在线环境中匿名性的重要性以及恶意行为者如何利用误导性的身份进行欺诈和传播虚假信息。随着人工智能技术的发展，这类问题的规模和影响力日益增大。为解决此挑战，文章提出了一种新型工具——“人格凭证”(PHCs)，这是一种能让用户在不泄露个人信息的情况下向在线服务证明自己是真实人类而非AI的数字凭证。这种凭证可由政府或其他可信机构颁发，系统既可局部也可全球部署，不一定基于生物特征。文章指出，当前AI在线表现与人类难以区分以及其规模化能力增强两大趋势加剧了这一挑战。现有的反自动化欺骗措施如验证码对高级AI已不再有效，而严格的身份验证方案又无法满足许多场景下的隐私需求。作者分析了人格凭证的好处，同时指出了实施风险和设计挑战，并提出了政策制定者、技术人员及标准机构应考虑的下一步行动建议，需与公众共同讨论。 <div>
arXiv:2408.07892v4 Announce Type: replace 
Abstract: Anonymity is an important principle online. However, malicious actors have long used misleading identities to conduct fraud, spread disinformation, and carry out other deceptive schemes. With the advent of increasingly capable AI, bad actors can amplify the potential scale and effectiveness of their operations, intensifying the challenge of balancing anonymity and trustworthiness online. In this paper, we analyze the value of a new tool to address this challenge: "personhood credentials" (PHCs), digital credentials that empower users to demonstrate that they are real people -- not AIs -- to online services, without disclosing any personal information. Such credentials can be issued by a range of trusted institutions -- governments or otherwise. A PHC system, according to our definition, could be local or global, and does not need to be biometrics-based. Two trends in AI contribute to the urgency of the challenge: AI's increasing indistinguishability from people online (i.e., lifelike content and avatars, agentic activity), and AI's increasing scalability (i.e., cost-effectiveness, accessibility). Drawing on a long history of research into anonymous credentials and "proof-of-personhood" systems, personhood credentials give people a way to signal their trustworthiness on online platforms, and offer service providers new tools for reducing misuse by bad actors. In contrast, existing countermeasures to automated deception -- such as CAPTCHAs -- are inadequate against sophisticated AI, while stringent identity verification solutions are insufficiently private for many use-cases. After surveying the benefits of personhood credentials, we also examine deployment risks and design challenges. We conclude with actionable next steps for policymakers, technologists, and standards bodies to consider in consultation with the public.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Liquidity Fragmentation or Optimization? Analyzing Automated Market Makers Across Ethereum and Rollups</title>
<link>https://arxiv.org/abs/2410.10324</link>
<guid>https://arxiv.org/abs/2410.10324</guid>
<content:encoded><![CDATA[
<div> 关键词: 层2区块链、以太坊、自动做市商(AMM)、流动性提供者(LP)、拉格朗日优化

<br /><br />总结:
本文探讨了层2区块链对于以太坊交易的安全保障和降低手续费的优势，指出尽管层2上的AMM正逐渐受到交易者的欢迎，但LP却相对滞后。研究发现，以太坊主链上的AMM流动资金池相对于层2的同类产品过度订阅，并提供的回报低于ETH质押。通过拉格朗日优化方法，文章提出了一种最大化LP收益的最优流动性分配策略。进一步研究表明，流动性提供的回报将趋近于质押回报率，在均衡状态下，向任何AMM提供的流动性回报应等于质押奖励。最后，文章测量了AMM池中交易量与总锁仓价值(TVL)的弹性关系，发现成熟区块链上TVL的增加并不一定伴随着交易量的上升。 <div>
arXiv:2410.10324v2 Announce Type: replace 
Abstract: Layer-2 (L2) blockchains offer security guarantees for Ethereum while reducing transaction (gas) fees. Consequently, they are gaining popularity among traders at Automated Market Makers (AMMs), but Liquidity Providers (LPs) are lagging behind. Our empirical results show that AMM liquidity pools on Ethereum are oversubscribed compared to their counterparties on L2s and deliver lower returns than staking ETH. LPs would receive higher rewards by reallocating over 2/3 of the liquidity to AMMs on L2s, or staking. We employ Lagrangian optimization to find the optimal liquidity allocation strategy that maximizes LP's rewards. Moreover, we show that the returns from liquidity provisions converge to the staking rate, and in equilibrium, liquidity provisions to any AMM should provide returns equal to staking rewards. Lastly, we measure the elasticity of trading volume with respect to TVL at AMM pools and found that at the well established blockchains an increase in TVL is not associated with an increase in trading volume.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sentiment Analysis in Twitter Social Network Centered on Cryptocurrencies Using Machine Learning</title>
<link>https://arxiv.org/abs/2501.09777</link>
<guid>https://arxiv.org/abs/2501.09777</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、区块链技术、社交媒体、Twitter情感分析、BERT模型

总结:
本文探讨了伊朗用户对于加密货币在Twitter上的观点，并旨在建立最佳的推文情感分类模型。研究主要关注在非英语环境下，即波斯语语境中的加密货币讨论。文章利用自然语言处理技术，如词袋模型（BOW）和FastText进行文本向量化，并结合传统机器学习算法（包括KNN、SVM和Adaboost）以及深度学习方法（LSTM和BERT）进行分类。实验结果显示，BERT模型在情感分类任务上表现最优，准确率达到了83.50%。这一研究为经济领域的管理者和官员提供了了解公众对加密货币看法的有效工具，以便更好地管理和应对这一现象。 <div>
arXiv:2501.09777v1 Announce Type: new 
Abstract: Cryptocurrency is a digital currency that uses blockchain technology with secure encryption. Due to the decentralization of these currencies, traditional monetary systems and the capital market of each they, can influence a society. Therefore, due to the importance of the issue, the need to understand public opinion and analyze people's opinions in this regard increases. To understand the opinions and views of people about different topics, you can take help from social networks because they are a rich source of opinions. The Twitter social network is one of the main platforms where users discuss various topics, therefore, in the shortest time and with the lowest cost, the opinion of the community can be measured on this social network. Twitter Sentiment Analysis (TSA) is a field that analyzes the sentiment expressed in tweets. Considering that most of TSA's research efforts on cryptocurrencies are focused on English language, the purpose of this paper is to investigate the opinions of Iranian users on the Twitter social network about cryptocurrencies and provide the best model for classifying tweets based on sentiment. In the case of automatic analysis of tweets, managers and officials in the field of economy can gain knowledge from the general public's point of view about this issue and use the information obtained in order to properly manage this phenomenon. For this purpose, in this paper, in order to build emotion classification models, natural language processing techniques such as bag of words (BOW) and FastText for text vectorization and classical machine learning algorithms including KNN, SVM and Adaboost learning methods Deep including LSTM and BERT model were used for classification, and finally BERT linguistic model had the best accuracy with 83.50%.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>W3ID: A Quantum Computing-Secure Digital Identity System Redefining Standards for Web3 and Digital Twins</title>
<link>https://arxiv.org/abs/2501.09802</link>
<guid>https://arxiv.org/abs/2501.09802</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算、Web 3.0、W3ID、数字身份、安全机制

<br /><br />总结:
随着量子计算对现有加密标准和网络安全构成威胁，以及Web 3.0时代的到来，强调数据安全、去中心化和用户所有权，这篇白皮书提出了一个新的数字身份模型——W3ID（Web3标准下的全球统一数字ID）。W3ID旨在满足Web 3.0标准，并解决量子计算带来的安全隐患。它为分布式Web 3.0生态系统创新性地生成了安全的数字对象标识符(DOI)，并采用双钥系统进行安全认证，增强了公共和私人验证机制。为了在量子计算时代增强加密强度和认证完整性，W3ID引入了一种高级安全机制，通过四次应用SHA-256算法并要求连续匹配进行验证，将计算复杂度提升至约当前SHA-256容量的4.3亿倍，显著提升了抵御量子计算机执行暴力破解的能力。总之，W3ID重新定义了适用于Web 3.0和量子计算时代的数字身份标准，并为全球数字孪生生态系统设定了新的安全、可扩展性和去中心化基准。 <div>
arXiv:2501.09802v1 Announce Type: new 
Abstract: The rapid advancements in quantum computing present significant threats to existing encryption standards and internet security. Simultaneously, the advent of Web 3.0 marks a transformative era in internet history, emphasizing enhanced data security, decentralization, and user ownership. This white paper introduces the W3ID, an abbreviation of Web3 standard meeting universal digital ID, which is a Universal Digital Identity (UDI) model designed to meet Web3 standards while addressing vulnerabilities posed by quantum computing. W3ID innovatively generates secure Digital Object Identifiers (DOIs) tailored for the decentralized Web 3.0 ecosystem. Additionally, W3ID employs a dual-key system for secure authentication, enhancing both public and private verification mechanisms. To further enhance encryption strength and authentication integrity in the quantum computing era, W3ID incorporates an advanced security mechanism. By requiring quadruple application of SHA-256, with consecutive matches for validation, the system expands the number of possibilities to 256^4, which is approximately 4.3 billion times the current SHA-256 capacity. This dramatic increase in computational complexity ensures that even advanced quantum computing systems would face significant challenges in executing brute-force attacks. W3ID redefines digital identity standards for Web 3.0 and the quantum computing era, setting a new benchmark for security, scalability, and decentralization in the global digital twin ecosystem.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>pFedWN: A Personalized Federated Learning Framework for D2D Wireless Networks with Heterogeneous Data</title>
<link>https://arxiv.org/abs/2501.09822</link>
<guid>https://arxiv.org/abs/2501.09822</guid>
<content:encoded><![CDATA[
<div> 关键词：传统联邦学习（Traditional Federated Learning）、个性化联邦学习（Personalized Federated Learning、PFL）、非独立同分布数据（non-IID）、无线通信资源分配、pFedWN

总结:<br />
本文针对传统联邦学习在处理客户端数据异质性导致模型性能下降的问题，提出了个性化联邦学习（PFL）方案。然而，现有的去中心化机器学习工作大多假设了理想的通信信道条件。为解决由无线链路带来的资源分配和干扰管理等挑战，文章提出了一种名为pFedWN的联合优化方法，该方法将设备到设备（D2D）无线信道条件纳入无服务器的PFL框架中，旨在优化每个客户端的学习性能并考虑无线信道的差异性。通过通道感知的邻居选择策略解决PFL邻居选择问题，并利用期望最大化（EM）方法确定PFL权重分配，以评估客户端数据之间的相似性。实验结果显示，pFedWN在非独立同分布和不平衡数据集上实现了高效且个性化的学习性能，并在动态和不可预测的无线信道条件下，相比于现有FL和PFL方法表现出更优的学习效率和鲁棒性。 <div>
arXiv:2501.09822v1 Announce Type: new 
Abstract: Traditional Federated Learning (FL) approaches often struggle with data heterogeneity across clients, leading to suboptimal model performance for individual clients. To address this issue, Personalized Federated Learning (PFL) emerges as a solution to the challenges posed by non-independent and identically distributed (non-IID) and unbalanced data across clients. Furthermore, in most existing decentralized machine learning works, a perfect communication channel is considered for model parameter transmission between clients and servers. However, decentralized PFL over wireless links introduces new challenges, such as resource allocation and interference management. To overcome these challenges, we formulate a joint optimization problem that incorporates the underlying device-to-device (D2D) wireless channel conditions into a server-free PFL approach. The proposed method, dubbed pFedWN, optimizes the learning performance for each client while accounting for the variability in D2D wireless channels. To tackle the formulated problem, we divide it into two sub-problems: PFL neighbor selection and PFL weight assignment. The PFL neighbor selection is addressed through channel-aware neighbor selection within unlicensed spectrum bands such as ISM bands. Next, to assign PFL weights, we utilize the Expectation-Maximization (EM) method to evaluate the similarity between clients' data and obtain optimal weight distribution among the chosen PFL neighbors. Empirical results show that pFedWN provides efficient and personalized learning performance with non-IID and unbalanced datasets. Furthermore, it outperforms the existing FL and PFL methods in terms of learning efficacy and robustness, particularly under dynamic and unpredictable wireless channel conditions.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning</title>
<link>https://arxiv.org/abs/2501.09934</link>
<guid>https://arxiv.org/abs/2501.09934</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能、车联网、联邦学习、多模型训练、资源分配

总结:
本文关注的是在车联网环境下，针对车辆边缘云架构中的层次化联邦学习(VEC-HFL)中多模型训练的问题。文章指出了在处理高机动性和分布式数据时，同时执行多个机器学习任务带来的挑战，包括不恰当的聚合规则可能导致模型过时和延长训练时间、车辆移动可能造成数据利用效率低下以及如何在不同任务间实现资源均衡分配的重要性。为解决这些问题，文中首次提出了一个动态VEC-HFL环境下的多模型训练框架，旨在最小化全局训练延迟并确保各任务间的平衡训练。该框架采用了一种混合同步-异步聚合规则，并提出了一种名为HEART的新方法，它分为两个阶段：首先，结合改进的粒子群优化算法（PSO）和遗传算法（GA），实现任务调度的均衡；其次，运用低复杂度的贪婪算法确定车辆上已分配任务的训练优先级。实验证明，HEART相较于现有方法具有显著优势。 <div>
arXiv:2501.09934v1 Announce Type: new 
Abstract: The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient machine learning (ML) solutions that can handle high vehicular mobility and decentralized data. This has motivated the emergence of Hierarchical Federated Learning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one aspect which is underexplored in the literature on VEC-HFL is that vehicles often need to execute multiple ML tasks simultaneously, where this multi-model training environment introduces crucial challenges. First, improper aggregation rules can lead to model obsolescence and prolonged training times. Second, vehicular mobility may result in inefficient data utilization by preventing the vehicles from returning their models to the network edge. Third, achieving a balanced resource allocation across diverse tasks becomes of paramount importance as it majorly affects the effectiveness of collaborative training. We take one of the first steps towards addressing these challenges via proposing a framework for multi-model training in dynamic VEC-HFL with the goal of minimizing global training latency while ensuring balanced training across various tasks-a problem that turns out to be NP-hard. To facilitate timely model training, we introduce a hybrid synchronous-asynchronous aggregation rule. Building on this, we present a novel method called Hybrid Evolutionary And gReedy allocaTion (HEART). The framework operates in two stages: first, it achieves balanced task scheduling through a hybrid heuristic approach that combines improved Particle Swarm Optimization (PSO) and Genetic Algorithms (GA); second, it employs a low-complexity greedy algorithm to determine the training priority of assigned tasks on vehicles. Experiments on real-world datasets demonstrate the superiority of HEART over existing methods.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Metamorphic Testing for Smart Contract Validation:A Case Study of Ethereum-Based Crowdfunding Contracts</title>
<link>https://arxiv.org/abs/2501.09955</link>
<guid>https://arxiv.org/abs/2501.09955</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链智能合约、测试、元变异测试(MT)、Metamorphic Relations (MRs)、Vertigo突变测试工具

总结:
本文关注了区块链智能合约的自动化和安全性在金融、医疗和供应链等领域的关键作用。文章指出了智能合约测试往往不如开发阶段受到足够重视，导致部署后存在显著风险。针对测试中的“预言机问题”，即确定预期结果困难的问题，文章提出了运用元变异测试（MT）方法，通过定义元变异关系（MRs）来验证智能合约的正确性。研究中，作者对基于Ethereum的众筹智能合约进行了测试，重点关注状态转换和捐赠跟踪等功能，并为这些功能定制了一组MRs。为了评估该方法的有效性，使用Vertigo突变测试工具创建了合约的错误版本。实验结果显示，所提出的MRs检测到了25.65%的总突变体，其中最有效的MRs达到了89%的突变体杀伤率，证实了MT对于确保区块链智能合约可靠性和质量的重要性。 <div>
arXiv:2501.09955v1 Announce Type: new 
Abstract: Blockchain smart contracts play a crucial role in automating and securing agreements in diverse domains such as finance, healthcare, and supply chains. Despite their critical applications, testing these contracts often receives less attention than their development, leaving significant risks due to the immutability of smart contracts post-deployment. A key challenge in the testing of smart contracts is the oracle problem, where the exact expected outcomes are not well defined, complicating systematic testing efforts.
  Metamorphic Testing (MT) addresses the oracle problem by using Metamorphic Relations (MRs) to validate smart contracts. MRs define how output should change relative to specific input modifications, determining whether the tests pass or fail. In this work, we apply MT to test an Ethereum-based crowdfunding smart contract, focusing on core functionalities such as state transitions and donation tracking.
  We identify a set of MRs tailored for smart contract testing and generate test cases for these MRs. To assess the effectiveness of this approach, we use the Vertigo mutation testing tool to create faulty versions of the smart contract. The experimental results show that our MRs detected 25.65% of the total mutants generated, with the most effective MRs achieving a mutant-killing rate of 89%. These results highlight the utility of MT to ensure the reliability and quality of blockchain-based smart contracts.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ColNet: Collaborative Optimization in Decentralized Federated Multi-task Learning Systems</title>
<link>https://arxiv.org/abs/2501.10347</link>
<guid>https://arxiv.org/abs/2501.10347</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Multi-Task Learning, Federated Multi-Task Learning, Decentralized, ColNet

总结:
<br />
本文探讨了联邦学习（Federated Learning）与多任务学习（Multi-Task Learning）融合应用的研究现状，重点关注在客户端任务异质性而非仅数据异质性的问题。现有的大多数工作依赖于由中心服务器管理的集中式设置，而对更为复杂的去中心化联邦环境下异构任务的学习——分布式联合多任务学习（Decentralized Federated Multi-Task Learning），研究尚不充分。为填补这一空白，文章提出了ColNet框架，该框架将模型划分为主干网络和任务特定层，并形成相似客户端的群体，由群体领导者执行冲突规避的跨群体聚合。实验结果表明，在带有标签和任务异质性的去中心化设置中，ColNet相对于其他聚合方案表现更优。 <div>
arXiv:2501.10347v1 Announce Type: new 
Abstract: The integration of Federated Learning (FL) and Multi-Task Learning (MTL) has been explored to address client heterogeneity, with Federated Multi-Task Learning (FMTL) treating each client as a distinct task. However, most existing research focuses on data heterogeneity (e.g., addressing non-IID data) rather than task heterogeneity, where clients solve fundamentally different tasks. Additionally, much of the work relies on centralized settings with a server managing the federation, leaving the more challenging domain of decentralized FMTL largely unexplored. Thus, this work bridges this gap by proposing ColNet, a framework designed for heterogeneous tasks in decentralized federated environments. ColNet divides models into the backbone and task-specific layers, forming groups of similar clients, with group leaders performing conflict-averse cross-group aggregation. A pool of experiments with different federations demonstrated ColNet outperforms the compared aggregation schemes in decentralized settings with label and task heterogeneity scenarios.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>End-user Comprehension of Transfer Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2407.11440</link>
<guid>https://arxiv.org/abs/2407.11440</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、风险理解、以太坊、用户研究、源代码分析

<br /><br />总结:
该文针对智能合约在关键场景中的广泛应用（如金融交易），着重探讨了终端用户对智能合约转账风险的理解。研究团队选取最流行的以太坊智能合约——USD Tether（USDT）以及排名靠前的ERC-20智能合约作为研究对象。他们从五个具有严重影响的转账风险入手，包括黑名单、合同暂停和任意升级等。首先，通过用户研究调查了110名参与者对USDT与MetaMask中智能合约转账风险的理解。结果表明，大部分用户并未充分理解实际存在的风险，例如高达71.8%的用户认为合同升级和被列入黑名单的风险严重且令人惊讶。此外，较多用户发现使用USDT/MetaMask界面流程更容易发现成功操作而非高风险操作，这种情况并不受参与者自评的编程和Web3熟练度的影响。其次，通过对接下来排名前78位的ERC-20智能合约进行手动和自动化源代码分析，结果显示所研究的风险在最高达19.2%的顶级ERC-20合约中普遍存在，同时还发现了其他三种在这些合约中高达25.6%的常见风险。这项研究表明，有必要提供可解释的智能合约、易懂的界面以及关于高风险结果的相关信息。 <div>
arXiv:2407.11440v2 Announce Type: replace 
Abstract: Smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that end-users understand the transfer risks in smart contracts. To address this, we investigate end-user comprehension of risks in the most popular Ethereum smart contract (i.e., USD Tether (USDT)) and their prevalence in the top ERC-20 smart contracts. We focus on five transfer risks with severe impact on transfer outcomes and user objectives, including users being blacklisted, contract being paused, and contract being arbitrarily upgraded. Firstly, we conducted a user study investigating end-user comprehension of smart contract transfer risks with 110 participants and USDT/MetaMask. Secondly, we performed manual and automated source code analysis of the next top (78) ERC-20 smart contracts (after USDT) to identify the prevalence of these risks. Results show that end-users do not comprehend real risks: most (up to 71.8% of) users believe contract upgrade and blacklisting are highly severe/surprising. More importantly, twice as many users find it easier to discover successful outcomes than risky outcomes using the USDT/MetaMask UI flow. These results hold regardless of the self-rated programming and Web3 proficiency of participants. Furthermore, our source code analysis demonstrates that the examined risks are prevalent in up to 19.2% of the top ERC-20 contracts. Additionally, we discovered (three) other risks with up to 25.6% prevalence in these contracts. This study informs the need to provide explainable smart contracts, understandable UI and relevant information for risky outcomes.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Blockchain-Enabled Approach to Cross-Border Compliance and Trust</title>
<link>https://arxiv.org/abs/2501.09182</link>
<guid>https://arxiv.org/abs/2501.09182</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，区块链，分布式账本技术(DLT)，治理框架，金融领域

总结:<br />
本文提出了一种利用区块链和分布式账本技术建立全球认可、去中心化的AI治理框架的新方法，以确保跨国境的AI系统安全、隐私和可信性。该框架特别关注在金融领域的实施场景，并规划了未来十年的逐步部署时间线。同时，文章针对可能面临的挑战提供了基于现有研究的解决方案。通过整合区块链、AI伦理和网络安全方面的进展，该论文为适应全球AI监管复杂演进环境的分散式AI治理框架提供了一个全面的发展蓝图。 <div>
arXiv:2501.09182v1 Announce Type: new 
Abstract: As artificial intelligence (AI) systems become increasingly integral to critical infrastructure and global operations, the need for a unified, trustworthy governance framework is more urgent that ever. This paper proposes a novel approach to AI governance, utilizing blockchain and distributed ledger technologies (DLT) to establish a decentralized, globally recognized framework that ensures security, privacy, and trustworthiness of AI systems across borders. The paper presents specific implementation scenarios within the financial sector, outlines a phased deployment timeline over the next decade, and addresses potential challenges with solutions grounded in current research. By synthesizing advancements in blockchain, AI ethics, and cybersecurity, this paper offers a comprehensive roadmap for a decentralized AI governance framework capable of adapting to the complex and evolving landscape of global AI regulation.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Contract-Inspired Contest Theory for Controllable Image Generation in Mobile Edge Metaverse</title>
<link>https://arxiv.org/abs/2501.09391</link>
<guid>https://arxiv.org/abs/2501.09391</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse、生成式扩散模型(GDM)、边缘计算、深度强化学习(DRL)、合同激励理论

总结:<br />
本文提出了一种融合了合同激励理论、深度强化学习（DRL）和生成式扩散模型（GDMs）的新框架，旨在优化移动边缘计算环境中高质、逼真图像的生成。该框架针对资源有限的边缘设备以及无线网络的动态特性，通过激励机制促使边缘设备高效传输高质量语义数据，保证虚拟与现实融合的元宇宙体验。利用合同理论确保有效资源配置，同时DRL根据网络条件动态调整，优化整体图像生成过程。实验结果显示，所提方法在提高生成图像质量、加快收敛速度和提升系统稳定性方面优于传统方法，尤其适用于移动边缘元宇宙应用中的复杂资源分配任务，能更高效地构建沉浸式虚拟环境。 <div>
arXiv:2501.09391v1 Announce Type: new 
Abstract: The rapid advancement of immersive technologies has propelled the development of the Metaverse, where the convergence of virtual and physical realities necessitates the generation of high-quality, photorealistic images to enhance user experience. However, generating these images, especially through Generative Diffusion Models (GDMs), in mobile edge computing environments presents significant challenges due to the limited computing resources of edge devices and the dynamic nature of wireless networks. This paper proposes a novel framework that integrates contract-inspired contest theory, Deep Reinforcement Learning (DRL), and GDMs to optimize image generation in these resource-constrained environments. The framework addresses the critical challenges of resource allocation and semantic data transmission quality by incentivizing edge devices to efficiently transmit high-quality semantic data, which is essential for creating realistic and immersive images. The use of contest and contract theory ensures that edge devices are motivated to allocate resources effectively, while DRL dynamically adjusts to network conditions, optimizing the overall image generation process. Experimental results demonstrate that the proposed approach not only improves the quality of generated images but also achieves superior convergence speed and stability compared to traditional methods. This makes the framework particularly effective for optimizing complex resource allocation tasks in mobile edge Metaverse applications, offering enhanced performance and efficiency in creating immersive virtual environments.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Top-k Multi-Armed Bandit Learning for Content Dissemination in Swarms of Micro-UAVs</title>
<link>https://arxiv.org/abs/2404.10845</link>
<guid>https://arxiv.org/abs/2404.10845</guid>
<content:encoded><![CDATA[
<div> 关键词: 微型无人机、灾难场景、内容管理系统、缓存策略、分布式学习

<br />
总结:
本文提出了一种在通信基础设施受损的灾害场景中，利用微型无人机增强的内容管理系统。该系统通过构建由固定锚定无人机和移动微运输无人机组成的混合网络，为孤立社区提供关键内容访问服务。文章核心贡献是一个自适应内容分发框架，采用去中心化的Top-k多臂赌博机学习方法，根据地理时间变化的内容流行度和多元用户需求进行有效的无人机缓存决策。同时，还提出了一个选择性缓存算法，通过利用无人机间的信息共享来减少冗余内容副本。通过功能验证和性能评估，所提出的框架显示出了在不同网络规模、微型无人机群组及内容流行度分布情况下的优化系统性能和适应性。 <div>
arXiv:2404.10845v2 Announce Type: replace 
Abstract: This paper presents a Micro-Unmanned Aerial Vehicle (UAV)-enhanced content management system for disaster scenarios where communication infrastructure is generally compromised. Utilizing a hybrid network of stationary and mobile Micro-UAVs, this system aims to provide crucial content access to isolated communities. In the developed architecture, stationary anchor UAVs, equipped with vertical and lateral links, serve users in individual disaster-affected communities. and mobile micro-ferrying UAVs, with enhanced mobility, extend coverage across multiple such communities. The primary goal is to devise a content dissemination system that dynamically learns caching policies to maximize content accessibility to users left without communication infrastructure. The core contribution is an adaptive content dissemination framework that employs a decentralized Top-k Multi-Armed Bandit learning approach for efficient UAV caching decisions. This approach accounts for geo-temporal variations in content popularity and diverse user demands. Additionally, a Selective Caching Algorithm is proposed to minimize redundant content copies by leveraging inter-UAV information sharing. Through functional verification and performance evaluation, the proposed framework demonstrates improved system performance and adaptability across varying network sizes, micro-UAV swarms, and content popularity distributions.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum Annealing based Power Grid Partitioning for Parallel Simulation</title>
<link>https://arxiv.org/abs/2408.04097</link>
<guid>https://arxiv.org/abs/2408.04097</guid>
<content:encoded><![CDATA[
<div> 关键词: 图划分、量子退火、并行模拟、NP难问题、D-Wave QPU

总结:
本文探讨了图划分在电力系统中的应用，特别是在并行模拟中如何通过优化网格划分来最小化因子网模拟时间差异导致的空闲时间和降低模拟切割所需的开销。文章指出，将图等分为两部分以使切割最小化和子图大小相等的问题是一个NP难问题。文中展示了如何利用量子退火（QA）技术求解这一问题的方法，将最优分割要求转化为二次无约束二进制优化（QUBO）模型，并在当前D-Wave QPU上进行了实验验证。然而，由于需要在现有D-Wave QPU上找到QUBO问题的有效嵌入，这限制了解决问题的规模在200个节点以下，并显著影响了解决方案的时间。最后，文章讨论了近期内在传统CPU或GPU仿真基础上结合量子退火技术实现的可能性及其影响。 <div>
arXiv:2408.04097v2 Announce Type: replace 
Abstract: Graph partitioning has many applications in powersystems from decentralized state estimation to parallel simulation. Focusing on parallel simulation, optimal grid partitioning minimizes the idle time caused by different simulation times for the sub-networks and their components and reduces the overhead required to simulate the cuts. Partitioning a graph into two parts such that, for example, the cut is minimal and the subgraphs have equal size is an NP-hard problem. In this paper we show how optimal partitioning of a graph can be obtained using quantum annealing (QA). We show how to map the requirements for optimal splitting to a quadratic unconstrained binary optimization (QUBO) formulation and test the proposed formulation using a current D-Wave QPU. We show that the necessity to find an embedding of the QUBO on current D-Wave QPUs limits the problem size to under 200 buses and notably affects the time-to-solution. We finally discuss the implications on near-term implementation of QA in combination to traditional CPU or GPU based simulation.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes</title>
<link>https://arxiv.org/abs/2501.08521</link>
<guid>https://arxiv.org/abs/2501.08521</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、异构域、原型学习、I$^2$PFL、特征对齐

<br /><br />总结:
本文提出了一个新的联邦学习方法——I$^2$PFL，旨在解决异构域下的领域偏斜问题，以实现多域间的模型泛化。针对现有联邦原型学习忽视了局部域内的特性，I$^2$PFL引入了内外域原型的概念。具体而言，通过采用基于MixUp的数据增强生成局部域的特征对齐原型，以捕捉局部域多样性并强化本地特征的泛化能力。同时，为了解决跨域知识迁移和减少域偏斜，I$^2$PFL还提出了一种重加权机制来构建通用的跨域原型。实验结果表明，与其它基线方法相比，I$^2$PFL在Digits、Office-10和PACS等数据集上表现出更优的性能。 <div>
arXiv:2501.08521v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a decentralized machine learning technique, allowing clients to train a global model collaboratively without sharing private data. However, most FL studies ignore the crucial challenge of heterogeneous domains where each client has a distinct feature distribution, which is common in real-world scenarios. Prototype learning, which leverages the mean feature vectors within the same classes, has become a prominent solution for federated learning under domain skew. However, existing federated prototype learning methods only consider inter-domain prototypes on the server and overlook intra-domain characteristics. In this work, we introduce a novel federated prototype learning method, namely I$^2$PFL, which incorporates $\textbf{I}$ntra-domain and $\textbf{I}$nter-domain $\textbf{P}$rototypes, to mitigate domain shifts and learn a generalized global model across multiple domains in federated learning. To construct intra-domain prototypes, we propose feature alignment with MixUp-based augmented prototypes to capture the diversity of local domains and enhance the generalization of local features. Additionally, we introduce a reweighting mechanism for inter-domain prototypes to generate generalized prototypes to provide inter-domain knowledge and reduce domain skew across multiple clients. Extensive experiments on the Digits, Office-10, and PACS datasets illustrate the superior performance of our method compared to other baselines.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Formal Model Guided Conformance Testing for Blockchains</title>
<link>https://arxiv.org/abs/2501.08550</link>
<guid>https://arxiv.org/abs/2501.08550</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、客户端实现、协议一致性测试、形式化模型、确定性区块链模拟器

总结:
<br />
现代区块链系统由多个实现区块链协议的客户端组成，当这些实现之间存在语义不匹配时，可能导致区块链永久分裂并引入新的攻击向量。现有的客户端实施测试套件不足以确保高度的协议一致性。为此，文章提出了一种利用正式的协议模型和在一个确定性区块链模拟器中运行的实现来进行协议一致性测试的框架。该框架包括两个互补的工作流程，分别作为跟踪生成器和检查器使用。作者认为这两个工作流程对于检测所有类型的违规行为都是必要的。他们已经将该框架应用于一个工业级共识协议并展示了其实用价值。 <div>
arXiv:2501.08550v1 Announce Type: new 
Abstract: Modern blockchains increasingly consist of multiple clients that implement the blockchain protocol. If there is a semantic mismatch between the protocol implementations, the blockchain can permanently split and introduce new attack vectors. Current ad-hoc test suites for client implementations are not sufficient to ensure a high degree of protocol conformance. As an alternative, we present a framework that performs protocol conformance testing using a formal model of the protocol and an implementation running inside a deterministic blockchain simulator. Our framework consists of two complementary workflows that use the components as trace generators and checkers. Our insight is that both workflows are needed to detect all types of violations. We have applied and demonstrated the utility of our framework on an industrial strength consensus protocol.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Augmenting Smart Contract Decompiler Output through Fine-grained Dependency Analysis and LLM-facilitated Semantic Recovery</title>
<link>https://arxiv.org/abs/2501.08670</link>
<guid>https://arxiv.org/abs/2501.08670</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、反汇编器、静态分析、大型语言模型、SmartHalo

总结:
本文提出了一个名为SmartHalo的新框架，用于改进以Solidity编写的智能合约的反汇编过程。该框架针对现有最优解反汇编器存在的方法识别不准确、变量类型恢复错误和缺少合同属性等问题，通过结合静态分析（SA）与大型语言模型（LLM）的优势进行优化。SmartHalo利用静态分析提取语义依赖关系构建依赖图，并基于此创建LLM优化的提示。随后，通过符号执行和形式验证验证LLM输出的正确性。实验表明，在由465个随机选取的智能合约方法构成的数据集上，SmartHalo显著提高了反编译代码的质量，相较于当前最先进的反汇编器（如Gigahorse）表现更优。进一步地，将GPT-4集成到SmartHalo中后，其在方法边界精确度达到87.39%，变量类型精确度达到90.39%，合同属性精确度达到80.65%。 <div>
arXiv:2501.08670v1 Announce Type: new 
Abstract: Decompiler is a specialized type of reverse engineering tool extensively employed in program analysis tasks, particularly in program comprehension and vulnerability detection. However, current Solidity smart contract decompilers face significant limitations in reconstructing the original source code. In particular, the bottleneck of SOTA decompilers lies in inaccurate method identification, incorrect variable type recovery, and missing contract attributes. These deficiencies hinder downstream tasks and understanding of the program logic. To address these challenges, we propose SmartHalo, a new framework that enhances decompiler output by combining static analysis (SA) and large language models (LLM). SmartHalo leverages the complementary strengths of SA's accuracy in control and data flow analysis and LLM's capability in semantic prediction. More specifically, \system{} constructs a new data structure - Dependency Graph (DG), to extract semantic dependencies via static analysis. Then, it takes DG to create prompts for LLM optimization. Finally, the correctness of LLM outputs is validated through symbolic execution and formal verification. Evaluation on a dataset consisting of 465 randomly selected smart contract methods shows that SmartHalo significantly improves the quality of the decompiled code, compared to SOTA decompilers (e.g., Gigahorse). Notably, integrating GPT-4o with SmartHalo further enhances its performance, achieving precision rates of 87.39% for method boundaries, 90.39% for variable types, and 80.65% for contract attributes.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Contract Fuzzing Towards Profitable Vulnerabilities</title>
<link>https://arxiv.org/abs/2501.08834</link>
<guid>https://arxiv.org/abs/2501.08834</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、安全风险、漏洞检测、模糊测试、VERITE

总结:
这篇论文介绍了VERITE，一个针对智能合约的利润中心型模糊测试框架，旨在更有效地检测并最大化利用可盈利的安全漏洞。VERITE具有三个主要特点：基于DeFi动作的变异器以增强不同资金流交易的探索；潜在利润候选条件，用于检查输入是否在测试过程中导致异常资金流属性；以及基于梯度下降的利润最大化策略。通过对包含61个实际被攻击的DeFi项目（平均损失超过110万美元）的数据集进行评估，结果显示VERITE可以自动提取超过1800万美元的利润，并在检测（发现29个/9个）和利用漏洞（平均收益增加58倍）方面显著优于最先进的模糊测试工具ITYFUZZ。尤其值得注意的是，在12个目标上，VERITE获得的利润甚至超过了现实世界的攻击收益（1.01至11.45倍）。此外，VERITE还应用于合同审计中，发现了6个高严重性零日漏洞，并获得了超过2500美元的赏金奖励。 <div>
arXiv:2501.08834v1 Announce Type: new 
Abstract: Billions of dollars are transacted through smart contracts, making vulnerabilities a major financial risk. One focus in the security arms race is on profitable vulnerabilities that attackers can exploit. Fuzzing is a key method for identifying these vulnerabilities. However, current solutions face two main limitations: a lack of profit-centric techniques for expediting detection, and insufficient automation in maximizing the profitability of discovered vulnerabilities, leaving the analysis to human experts. To address these gaps, we have developed VERITE, a profit-centric smart contract fuzzing framework that not only effectively detects those profitable vulnerabilities but also maximizes the exploited profits.
  VERITE has three key features: 1) DeFi action-based mutators for boosting the exploration of transactions with different fund flows; 2) potentially profitable candidates identification criteria, which checks whether the input has caused abnormal fund flow properties during testing; 3) a gradient descent-based profit maximization strategy for these identified candidates.
  VERITE is fully developed from scratch and evaluated on a dataset consisting of 61 exploited real-world DeFi projects with an average of over 1.1 million dollars loss. The results show that VERITE can automatically extract more than 18 million dollars in total and is significantly better than state-of-the-art fuzzer ITYFUZZ in both detection (29/9) and exploitation (58 times more profits gained on average). Remarkbly, in 12 targets, it gains more profits than real-world attacking exploits (1.01 to 11.45 times more). VERITE is also applied by auditors in contract auditing, where 6 (5 high severity) zero-day vulnerabilities are found with over $2,500 bounty rewards.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Separation Assurance in Urban Air Mobility Systems using Shared Scheduling Protocols</title>
<link>https://arxiv.org/abs/2501.08933</link>
<guid>https://arxiv.org/abs/2501.08933</guid>
<content:encoded><![CDATA[
<div> 关键词: 无人机交通管理、城市空中交通、分离安全、共享调度协议、分布式马尔科夫决策过程

<br /><br />总结:

本文提出了一个针对城市空中交通(UAM)环境中的无人机安全分离策略。该策略借鉴了原本用于以太网和操作系统中的共享调度协议，通过使用分布式马尔科夫决策过程框架，使无人机能够在穿越飞行走廊交叉点时自主调整速度和时间，实现无需中央控制器的精确控制。在模拟UAM场景中，这种方法被证明能将分离违规降至零，同时随着交通密度增加，航班时间存在一定的权衡。此外，文章还探讨了非合规无人机的影响，结果显示虽然共享调度协议不能确保在非合规情况下依然维持安全分离，但相较于无调度协议的系统，它仍可显著提高安全性。 <div>
arXiv:2501.08933v1 Announce Type: new 
Abstract: Ensuring safe separation between aircraft is a critical challenge in air traffic management, particularly in urban air mobility (UAM) environments where high traffic density and low altitudes require precise control. In these environments, conflicts often arise at the intersections of flight corridors, posing significant risks. We propose a tactical separation approach leveraging shared scheduling protocols, originally designed for Ethernet networks and operating systems, to coordinate access to these intersections. Using a decentralized Markov decision process framework, the proposed approach enables aircraft to autonomously adjust their speed and timing as they navigate these critical areas, maintaining safe separation without a central controller. We evaluate the effectiveness of this approach in simulated UAM scenarios, demonstrating its ability to reduce separation violations to zero while acknowledging trade-offs in flight times as traffic density increases. Additionally, we explore the impact of non-compliant aircraft, showing that while shared scheduling protocols can no longer guarantee safe separation, they still provide significant improvements over systems without scheduling protocols.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Review on the Security Vulnerabilities of the IoMT against Malware Attacks and DDoS</title>
<link>https://arxiv.org/abs/2501.07703</link>
<guid>https://arxiv.org/abs/2501.07703</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Medical Things (IoMT)，安全漏洞，恶意软件，分布式拒绝服务(DDoS)攻击，缓解策略

<br /><br />总结：
本文对互联网医疗事物（IoMT）的安全问题进行了深入研究。IoMT设备由于连接性增强导致面临诸如恶意软件和分布式拒绝服务（DDoS）攻击的重大安全风险。通过对ACM数字图书馆、IEEE Xplore及Elsevier等主流数据库过去五年（2019年至2024年）的同行评审文章进行综合搜索分析，发现IoMT设备的主要风险源于加密协议不足、认证方法薄弱以及固件更新不规律。文章还指出了机器学习算法、区块链技术和边缘计算作为强化IoMT安全性的新兴解决方案。最后，该文献强调了急需开发轻量级安全措施和标准化协议以保护患者数据并确保医疗服务的完整性。 <div>
arXiv:2501.07703v1 Announce Type: new 
Abstract: The Internet of Medical Things (IoMT) has transformed the healthcare industry by connecting medical devices in monitoring treatment outcomes of patients. This increased connectivity has resulted to significant security vulnerabilities in the case of malware and Distributed Denial of Service (DDoS) attacks. This literature review examines the vulnerabilities of IoMT devices, focusing on critical threats and exploring mitigation strategies. We conducted a comprehensive search across leading databases such as ACM Digital Library, IEEE Xplore, and Elsevier to analyze peer-reviewed studies published within the last five years (from 2019 to 2024). The review shows that inadequate encryption protocols, weak authentication methods, and irregular firmware updates are the main causes of risks associated with IoMT devices. We have identified emerging solutions like machine learning algorithms, blockchain technology, and edge computing as promising approaches to enhance IoMT security. This review emphasizes the pressing need to develop lightweight security measures and standardized protocols to protect patient data and ensure the integrity of healthcare services.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Technical Report: Exploring Automatic Model-Checking of the Ethereum specification</title>
<link>https://arxiv.org/abs/2501.07958</link>
<guid>https://arxiv.org/abs/2501.07958</guid>
<content:encoded><![CDATA[
<div> 关键词：自动化模型检查、Ethereum规范、Accountable Safety、3SF共识协议、TLA+、Apalache模型检查器、Python规范、手动抽象、SMT(CVC5)、Alloy。

总结:<br />
该文研究了对Ethereum规范的自动化模型检查，重点关注3SF共识协议中的Accountable Safety属性。使用TLA+进行规格说明和Apalache模型检查器进行验证。文章首先将可执行的3SF Python规范手动转换为TLA+，并揭示了Accountable Safety定义中的显著组合复杂性。为应对挑战，作者引入了几层手动抽象，包括用折迭代替递归、以整数替换抽象图以及分解链配置。为了交叉验证结果，他们还开发了SMT（CVC5）和Alloy的替代编码。尽管存在内在复杂性，但结果显示，对于小规模实例（支持最多7个检查点和24个验证人投票），Accountable Safety的详尽验证是可行的，并且在稍大的配置中也没有观察到Accountable Safety的安全性违规。此外，这项研究强调了手动抽象和领域专业知识在提高模型检查效率方面的重要性，并展示了TLA+处理复杂规格说明的灵活性。 <div>
arXiv:2501.07958v1 Announce Type: new 
Abstract: We investigate automated model-checking of the Ethereum specification, focusing on the Accountable Safety property of the 3SF consensus protocol. We select 3SF due to its relevance and the unique challenges it poses for formal verification. Our primary tools are TLA+ for specification and the Apalache model checker for verification.
  Our formalization builds on the executable Python specification of 3SF. To begin, we manually translate this specification into TLA+, revealing significant combinatorial complexity in the definition of Accountable Safety. To address these challenges, we introduce several layers of manual abstraction: (1) replacing recursion with folds, (2) substituting abstract graphs with integers, and (3) decomposing chain configurations. To cross-validate our results, we develop alternative encodings in SMT (CVC5) and Alloy.
  Despite the inherent complexity, our results demonstrate that exhaustive verification of Accountable Safety is feasible for small instances - supporting up to 7 checkpoints and 24 validator votes. Moreover, no violations of Accountable Safety are observed, even in slightly larger configurations. Beyond these findings, our study highlights the importance of manual abstraction and domain expertise in enhancing model-checking efficiency and showcases the flexibility of TLA+ for managing intricate specifications.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.08020</link>
<guid>https://arxiv.org/abs/2501.08020</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习(MARL)，巡逻策略，无向图，价值分解近似策略优化(VDPPO)，覆盖指数

<br /><br />总结:
本文提出了一种基于多智能体强化学习（MARL）的巡逻策略设计模型，该模型利用分布式部分可观测马尔科夫决策过程解决大规模区域内的巡逻路径规划问题。研究以西班牙马拉加市三个中等规模行政区为场景，旨在通过最大化特定时间框架内环境特征的目标函数来优化警察巡逻路线，尤其是加强对高犯罪率地区的监控覆盖率。文章对比了多种MARL算法后发现，价值分解近似策略优化（VDPPO）算法表现最优。同时，文中还引入了一个名为覆盖指数的新评估指标，该指标借鉴了犯罪学中的预测准确度指数（PAI），用于量化由模型生成的巡逻路线对高犯罪热点区域的覆盖效果。实验结果显示，所提出的模型能实现对最高犯罪率前3%和20%节点超过90%和65%的覆盖率，分别对应警方资源分配的3%和20%覆盖标准。 <div>
arXiv:2501.08020v1 Announce Type: new 
Abstract: The effective design of patrol strategies is a difficult and complex problem, especially in medium and large areas. The objective is to plan, in a coordinated manner, the optimal routes for a set of patrols in a given area, in order to achieve maximum coverage of the area, while also trying to minimize the number of patrols. In this paper, we propose a multi-agent reinforcement learning (MARL) model, based on a decentralized partially observable Markov decision process, to plan unpredictable patrol routes within an urban environment represented as an undirected graph. The model attempts to maximize a target function that characterizes the environment within a given time frame. Our model has been tested to optimize police patrol routes in three medium-sized districts of the city of Malaga. The aim was to maximize surveillance coverage of the most crime-prone areas, based on actual crime data in the city. To address this problem, several MARL algorithms have been studied, and among these the Value Decomposition Proximal Policy Optimization (VDPPO) algorithm exhibited the best performance. We also introduce a novel metric, the coverage index, for the evaluation of the coverage performance of the routes generated by our model. This metric is inspired by the predictive accuracy index (PAI), which is commonly used in criminology to detect hotspots. Using this metric, we have evaluated the model under various scenarios in which the number of agents (or patrols), their starting positions, and the level of information they can observe in the environment have been modified. Results show that the coordinated routes generated by our model achieve a coverage of more than $90\%$ of the $3\%$ of graph nodes with the highest crime incidence, and $65\%$ for $20\%$ of these nodes; $3\%$ and $20\%$ represent the coverage standards for police resource allocation.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Nonlinear Cruise Controllers with Bidirectional Sensing for a String of Vehicles</title>
<link>https://arxiv.org/abs/2501.08227</link>
<guid>https://arxiv.org/abs/2501.08227</guid>
<content:encoded><![CDATA[
<div> 关键词: 非线性巡航控制器、分散式控制、间距测量、速度控制、环路道路、开放道路、全局渐近稳定性、KL估计、均匀收敛、指数吸引。

总结:<br />
本文介绍了一种非线性的全分布式车载巡航控制器，该控制器利用前车和后车的间距与速度信息来决定每辆车的适当加速控制。研究证明，在环路道路和开放道路上，此控制器能确保车辆间无碰撞，同时保持车辆速度始终为正且不超过道路限速。对于环路道路情况，在一定条件下，文章严格证明了存在一个全局渐近稳定的均衡点，并给出了保证其均匀收敛的KL估计；此外，还指出在环路上该均衡点具有指数吸引性。 <div>
arXiv:2501.08227v1 Announce Type: cross 
Abstract: We introduce a nonlinear cruise controller that is fully decentralized (by vehicle) and uses spacing and speed measurements from the preceding and following vehicles to decide on the appropriate control action (acceleration) for each vehicle. The proposed cruise controller is studied on both a ring-road and an open road and guarantees that there are no collisions between vehicles, while their speeds are always positive and never exceed the road speed limits. For both cases of the open road and the ring-road, we rigorously prove that the set of equilibrium points is globally asymptotically stable and provide KL estimates that guarantee uniform convergence to the said set. Moreover, we show that for the ring-road, and under certain conditions, there is a single equilibrium point which is exponentially attractive.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Design, Vulnerabilities, and Security Measures of Cryptocurrency Wallets</title>
<link>https://arxiv.org/abs/2307.12874</link>
<guid>https://arxiv.org/abs/2307.12874</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、数字货币钱包、安全风险、攻击框架、防御措施

<br /><br />总结:
本文关注了区块链技术支持下的去中心化数字货币钱包的安全性问题。随着加密货币经济的快速发展，钱包成为安全隐患的重点领域。文章提出了一个多维度的设计分类体系，用于现有和新型钱包，并依据此对业界现有的钱包进行了分类与分析，揭示了以往发生的漏洞及其设计决策带来的安全影响。同时，系统整理了针对钱包机制的威胁，分析了对手的目标、能力和所需知识。文中构建了一个多层攻击框架，并研究了从2012年到2024年的84起安全事故，涉及金额达54亿美元。接着，文章对这些攻击的预防性和补救性防御措施进行了分类，并将钱包机制、设计决策与漏洞、攻击及可能的防御方法进行了关联讨论，旨在为提高钱包安全性提供深入见解。 <div>
arXiv:2307.12874v4 Announce Type: replace 
Abstract: With the advent of decentralised digital currencies powered by blockchain technology, a new era of peer-to-peer transactions has commenced. The rapid growth of the cryptocurrency economy has led to increased use of transaction-enabling wallets, making them a focal point for security risks. As the frequency of wallet-related incidents rises, there is a critical need for a systematic approach to measure and evaluate these attacks, drawing lessons from past incidents to enhance wallet security. In response, we introduce a multi-dimensional design taxonomy for existing and novel wallets with various design decisions. We classify existing industry wallets based on this taxonomy, identify previously occurring vulnerabilities and discuss the security implications of design decisions. We also systematise threats to the wallet mechanism and analyse the adversary's goals, capabilities and required knowledge. We present a multi-layered attack framework and investigate 84 incidents between 2012 and 2024, accounting for $5.4B. Following this, we classify defence implementations for these attacks on the precautionary and remedial axes. We map the mechanism and design decisions to vulnerabilities, attacks, and possible defence methods to discuss various insights.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Regression Equilibrium in Electricity Markets</title>
<link>https://arxiv.org/abs/2405.17753</link>
<guid>https://arxiv.org/abs/2405.17753</guid>
<content:encoded><![CDATA[
<div> 关键词：两阶段电力市场、可再生能源、预测模型、竞争回归均衡、变分不等式算法

<br /><br />总结:
本文研究了在具有大量可再生能源的两阶段电力市场中，可再生能源生产商如何通过选择合适的预测模型来影响其财务表现和市场整体运行。文章提出了“竞争回归均衡”的概念，即在这一均衡状态下，新能源生产商优化其基于日间与实时电价的发电量预测模型，以最大化其在日间和实时市场的平均利润，同时也促进了这两个市场的成本时间协调性。文中利用变分不等式的理论探讨了该均衡的存在性和唯一性，并给出了计算回归均衡的集中式优化方法及分布式ADMM算法。 <div>
arXiv:2405.17753v2 Announce Type: replace 
Abstract: In two-stage electricity markets, renewable power producers enter the day-ahead market with a forecast of future power generation and then reconcile any forecast deviation in the real-time market at a penalty. The choice of the forecast model is thus an important strategy decision for renewable power producers as it affects financial performance. In electricity markets with large shares of renewable generation, the choice of the forecast model impacts not only individual performance but also outcomes for other producers. In this paper, we argue for the existence of a competitive regression equilibrium in two-stage electricity markets in terms of the parameters of private forecast models informing the participation strategies of renewable power producers. In our model, renewables optimize the forecast against the day-ahead and real-time prices, thereby maximizing the average profits across the day-ahead and real-time markets. By doing so, they also implicitly enhance the temporal cost coordination of day-ahead and real-time markets. We base the equilibrium analysis on the theory of variational inequalities, providing results on the existence and uniqueness of regression equilibrium in energy-only markets. We also devise two methods to compute regression equilibrium: centralized optimization and a decentralized ADMM-based algorithm.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agent TCP/IP: An Agent-to-Agent Transaction System</title>
<link>https://arxiv.org/abs/2501.06243</link>
<guid>https://arxiv.org/abs/2501.06243</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理人、交互协议、智能合约、Agent Transaction Control Protocol for Intellectual Property (ATCP/IP)、Story区块链网络

<br /><br />总结:
本文提出了Autonomous agents（自主代理人）作为互联网发展的必然趋势，现有的代理框架缺乏标准的agent-to-agent交互协议，导致各代理间孤立。为了构建真正的代理经济体，需要设计一个通用框架——Agent Transaction Control Protocol for Intellectual Property (ATCP/IP)，该协议通过可编程合同实现智能合约交换知识产权。ATCP/IP借助Story区块链网络，让代理之间能够无需人类中介地进行交易、借贷和销售等互动行为。此外，这些合同同时具备链上执行的可审计性和链下法律环境中的法律约束力，从而为代理人赋予了法律人格。通过ATCP/IP，代理人可以自主出售训练数据、授权机密或专有信息，以及根据各自独特的技能协作创作内容，共同构成一个崭新的知识经济体系。 <div>
arXiv:2501.06243v1 Announce Type: new 
Abstract: Autonomous agents represent an inevitable evolution of the internet. Current agent frameworks do not embed a standard protocol for agent-to-agent interaction, leaving existing agents isolated from their peers. As intellectual property is the native asset ingested by and produced by agents, a true agent economy requires equipping agents with a universal framework for engaging in binding contracts with each other, including the exchange of valuable training data, personality, and other forms of Intellectual Property. A purely agent-to-agent transaction layer would transcend the need for human intermediation in multi-agent interactions. The Agent Transaction Control Protocol for Intellectual Property (ATCP/IP) introduces a trustless framework for exchanging IP between agents via programmable contracts, enabling agents to initiate, trade, borrow, and sell agent-to-agent contracts on the Story blockchain network. These contracts not only represent auditable onchain execution but also contain a legal wrapper that allows agents to express and enforce their actions in the offchain legal setting, creating legal personhood for agents. Via ATCP/IP, agents can autonomously sell their training data to other agents, license confidential or proprietary information, collaborate on content based on their unique skills, all of which constitutes an emergent knowledge economy.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing The Open Network: Definition and Automated Detection of Smart Contract Defects</title>
<link>https://arxiv.org/abs/2501.06459</link>
<guid>https://arxiv.org/abs/2501.06459</guid>
<content:encoded><![CDATA[
<div> 关键词: TON、智能合约、FunC、TONScanner、静态分析框架

总结:
本文介绍了针对Telegram开放网络(TON)上基于FunC编程语言编写的智能合约的研究。研究者们归纳了从TON官方博客和审计报告中发现的八种智能合约缺陷，并提出了名为TONScanner的静态分析框架用于检测这些缺陷。该框架利用FunC编译器前端代码将源代码转化为中间表示形式（DAG），进而构建控制流图（CFG）并转换为静态单赋值（SSA）形式以简化分析。此外，TONScanner还整合了数据依赖性、调用图、污点分析和细胞构造等功能，专门针对TON区块链特有的数据结构。通过对1,640份智能合约进行应用，TONScanner共发现了14,995处缺陷，经随机抽样与人工标注，其整体精度达到97.49%。这表明当前TON合同存在大量缺陷，而TONScanner能够准确地识别这些问题，从而有助于缺陷修复。 <div>
arXiv:2501.06459v1 Announce Type: new 
Abstract: The Open Network (TON), designed to support Telegram's extensive user base of hundreds of millions, has garnered considerable attention since its launch in 2022. FunC is the most popular programming language for writing smart contracts on TON. It is distinguished by a unique syntax compared to other smart contract languages. Despite growing interest, research on the practical defects of TON smart contracts is still in its early stages. In this paper, we summarize eight smart contract defects identified from TON's official blogs and audit reports, each with detailed definitions and code examples. Furthermore, we propose a static analysis framework called TONScanner to facilitate the detection of these defects. Specifically, TONScanner reuses FunC compiler's frontend code to transform the FunC source code into FunC intermediate representation (IR) in the form of a directed acyclic graph (DAG). Based on this IR, TONScanner constructs a control flow graph (CFG), then transforms it into a static single assignment (SSA) form to simplify further analysis. TONScanner also integrates Data Dependency, Call Graph, Taint Analysis, and Cell Construct, which are specifically tailored for TON blockchain's unique data structures. These components finally facilitate the identification of the eight defects. We evaluate the effectiveness of TONScanner by applying it to 1,640 smart contracts and find a total of 14,995 defects. Through random sampling and manual labeling, we find that TONScanner achieves an overall precision of 97.49%. The results reveal that current TON contracts contain numerous defects, indicating that developers are prone to making errors. TONScanner has proven its ability to accurately identify these defects, thereby aiding in their correction.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stingray: Fast Concurrent Transactions Without Consensus</title>
<link>https://arxiv.org/abs/2501.06531</link>
<guid>https://arxiv.org/abs/2501.06531</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、并发处理、状态访问、冲突恢复、Stingray

总结:<br />
本文介绍了Stingray，一种新型区块链架构，旨在解决现有系统中处理相同状态访问的交易和多党交易时存在的并发处理限制以及缓慢的冲突恢复问题。Stingray的主要创新点包括：使用了一个可复制的有限计数器来并发处理几乎交换性的交易，以及提出了一种名为FastUnlock的协议，利用备用共识协议实现快速冲突恢复。文章在异步网络和拜占庭故障模型下证明了Stingray的安全性，并在全球测试床上展示了Stingray对于交换性工作负载的吞吐量比先前系统高出约一万倍。 <div>
arXiv:2501.06531v1 Announce Type: new 
Abstract: Recent advances have improved the throughput and latency of blockchains by processing transactions accessing different parts of the state concurrently. However, these systems are unable to concurrently process (a) transactions accessing the same state, even if they are (almost) commutative, e.g., payments much smaller than an account's balance, and (b) multi-party transactions, e.g., asset swaps. Moreover, they are slow to recover from contention, requiring once-in-a-day synchronization. We present Stingray, a novel blockchain architecture that addresses these limitations. The key conceptual contributions are a replicated bounded counter that processes (almost) commutative transactions concurrently, and a FastUnlock protocol that uses a fallback consensus protocol for fast contention recovery. We prove Stingray's security in an asynchronous network with Byzantine faults and demonstrate on a global testbed that Stingray achieves 10,000 times the throughput of prior systems for commutative workloads.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Distribution Estimation Using Functional Approximation</title>
<link>https://arxiv.org/abs/2501.06620</link>
<guid>https://arxiv.org/abs/2501.06620</guid>
<content:encoded><![CDATA[
<div> 关键词: 累积分布函数(CDF), 隐私保护, 功能分析, 功能机制, 分布式设置

总结:
该文介绍了一种新的隐私保护累积分布函数(CDF)方法，该方法受到功能分析和功能性机制的启发。该方法将经验CDF投影到预定义空间，并使用特定函数进行近似，通过保护系数实现差分隐私的经验CDF。与现有的如直方图查询和自适应分位数等方法相比，本文提出的方法更适合分布式环境以及需要随新收集数据不断更新CDF的场景。 <div>
arXiv:2501.06620v1 Announce Type: new 
Abstract: The cumulative distribution function (CDF) is fundamental due to its ability to reveal information about random variables, making it essential in studies that require privacy-preserving methods to protect sensitive data. This paper introduces a novel privacy-preserving CDF method inspired by the functional analysis and functional mechanism. Our approach projects the empirical CDF into a predefined space, approximating it using specific functions, and protects the coefficients to achieve a differentially private empirical CDF. Compared to existing methods like histogram queries and adaptive quantiles, our method is preferable in decentralized settings and scenarios where CDFs must be updated with newly collected data.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eliza: A Web3 friendly AI Agent Operating System</title>
<link>https://arxiv.org/abs/2501.06781</link>
<guid>https://arxiv.org/abs/2501.06781</guid>
<content:encoded><![CDATA[
<div> 关键词：AI Agent、大型语言模型、web3、Eliza、开源框架

总结:
本文提出了一个名为Eliza的开源框架，它是首个面向web3友好的AI代理框架。Eliza利用大型语言模型作为其认知核心，能够无缝集成web3应用程序，使部署web3应用变得轻松易行。该框架完全由用户控制，其全部组件均为Typescript程序。此外，Eliza实现了与web3（如读取和写入区块链数据、交互智能合约等）的顺畅集成，并通过其实现关键运行时组件的实用化实施保证了系统稳定性能。源代码已公开发布在https://github.com/ai16z/eliza上。 <div>
arXiv:2501.06781v1 Announce Type: new 
Abstract: AI Agent, powered by large language models (LLMs) as its cognitive core, is an intelligent agentic system capable of autonomously controlling and determining the execution paths under user's instructions. With the burst of capabilities of LLMs and various plugins, such as RAG, text-to-image/video/3D, etc., the potential of AI Agents has been vastly expanded, with their capabilities growing stronger by the day. However, at the intersection between AI and web3, there is currently no ideal agentic framework that can seamlessly integrate web3 applications into AI agent functionalities. In this paper, we propose Eliza, the first open-source web3-friendly Agentic framework that makes the deployment of web3 applications effortless. We emphasize that every aspect of Eliza is a regular Typescript program under the full control of its user, and it seamlessly integrates with web3 (i.e., reading and writing blockchain data, interacting with smart contracts, etc.). Furthermore, we show how stable performance is achieved through the pragmatic implementation of the key components of Eliza's runtime. Our code is publicly available at https://github.com/ai16z/eliza.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Space Surveillance: Blockchain-Based Space Domain Awareness</title>
<link>https://arxiv.org/abs/2501.06970</link>
<guid>https://arxiv.org/abs/2501.06970</guid>
<content:encoded><![CDATA[
<div> 关键词: Space Domain Awareness (SDA), 卫星群, 区块链, 垃圾碎片追踪, 分布式架构

总结:
随着空间活动的迅速扩张和太空垃圾的不断积累，确保Space Domain Awareness (SDA)对于维持安全的空间操作变得至关重要。本文提出了一种利用卫星群和区块链技术的分布式解决方案，其中卫星作为验证者和审批者，负责安全地验证和存储垃圾碎片追踪数据。模拟结果显示，该网络在约30个节点时能实现最佳性能，平衡了吞吐量和响应时间，稳定在4.37秒。这表明通过将大规模网络分解为更小、自主化的群组，每个群组针对特定任务进行优化，可以有效管理此类网络。此外，文章还将分布式群组架构的性能与完全共享角色模型进行了对比，显示了当角色解耦后，在可扩展性和响应时间方面有显著改进。 <div>
arXiv:2501.06970v1 Announce Type: new 
Abstract: With the rapid expansion of space activities and the escalating accumulation of space debris, Space Domain Awareness (SDA) has become essential for sustaining safe space operations. This paper proposes a decentralized solution using satellite swarms and blockchain, where satellites (nodes) take on the roles of verifiers and approvers to validate and store debris-tracking data securely. Our simulations show that the network achieves optimal performance with around 30 nodes, balancing throughput and response time settling at 4.37 seconds. These results suggest that large-scale networks can be effectively managed by decoupling them into smaller, autonomous swarms, each optimized for specific tasks. Furthermore, we compare the performance of the decentralized swarm architecture with that of a fully shared role model and show significant improvements in scalability and response times when roles are decoupled.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2501.07058</link>
<guid>https://arxiv.org/abs/2501.07058</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、漏洞、大型语言模型、False-positive率、Solidity v0.8

总结:
本文关注智能合约的安全问题，特别是其在区块链应用中的漏洞所导致的重大经济损失。研究指出，当前基于大型语言模型（LLMs）的检测解决方案存在较高的误报率。文章主要在两个方面拓展了现有研究：首先，评估基于最新版本的Solidity v0.8，相较于先前针对老版本（v0.4）的研究，提供了更为及时的洞见；其次，该研究利用了来自不同公司的五个最新的LLM模型，确保覆盖领域内最先进的能力。实验结果显示，设计良好的提示可以将误报率降低超过60%，然而令人惊讶的是，对于特定类型的漏洞检测，Solidity v0.8的召回率相比早期版本（如v0.4）竟降至仅为13%。进一步分析揭示了这一下降的原因在于，LLMs在检测过程中过于依赖识别新引入的库和框架中的变化。 <div>
arXiv:2501.07058v1 Announce Type: new 
Abstract: Smart contract vulnerabilities caused significant economic losses in blockchain applications. Large Language Models (LLMs) provide new possibilities for addressing this time-consuming task. However, state-of-the-art LLM-based detection solutions are often plagued by high false-positive rates.
  In this paper, we push the boundaries of existing research in two key ways. First, our evaluation is based on Solidity v0.8, offering the most up-to-date insights compared to prior studies that focus on older versions (v0.4). Second, we leverage the latest five LLM models (across companies), ensuring comprehensive coverage across the most advanced capabilities in the field.
  We conducted a series of rigorous evaluations. Our experiments demonstrate that a well-designed prompt can reduce the false-positive rate by over 60%. Surprisingly, we also discovered that the recall rate for detecting some specific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to earlier versions (i.e., v0.4). Further analysis reveals the root cause of this decline: the reliance of LLMs on identifying changes in newly introduced libraries and frameworks during detection.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Authentication: Theory vs. Practice</title>
<link>https://arxiv.org/abs/2501.07209</link>
<guid>https://arxiv.org/abs/2501.07209</guid>
<content:encoded><![CDATA[
<div> 关键词：在线服务、隐私保护、身份管理、零知识证明、匿名凭证<br /><br />总结:
随着在线服务使用的增长，用户隐私保护变得越来越重要。当前互联网上的身份管理和认证主要依赖于集中式解决方案，但从隐私角度来看，这种方法较为侵入，并未实现数据最小化原则。幸运的是，密码学提供了如零知识证明和高级签名方案等激动人心的原语，可以实现多种形式的匿名凭证，从而实现具有内置高隐私保护级别的隐私保护认证（即隐私保护认证）。虽然这些原语已被研究了几十年并在学术界得到充分理解，但遗憾的是它们尚未得到广泛应用。本文探讨了相关问题、密码学所能做的事情、一些部署实例以及阻碍其广泛采用的壁垒，以欧盟数字身份钱包（EUDIW）及其近期围绕该话题的专家讨论和反馈为例进行了具体说明。此外，文中还简要提及了向后量子密码学过渡的问题。 <div>
arXiv:2501.07209v1 Announce Type: new 
Abstract: With the increasing use of online services, the protection of the privacy of users becomes more and more important. This is particularly critical as authentication and authorization as realized on the Internet nowadays, typically relies on centralized identity management solutions. Although those are very convenient from a user's perspective, they are quite intrusive from a privacy perspective and are currently far from implementing the concept of data minimization. Fortunately, cryptography offers exciting primitives such as zero-knowledge proofs and advanced signature schemes to realize various forms of so-called anonymous credentials. Such primitives allow to realize online authentication and authorization with a high level of built-in privacy protection (what we call privacy-preserving authentication). Though these primitives have already been researched for various decades and are well understood in the research community, unfortunately, they lack widespread adoption. In this paper, we look at the problems, what cryptography can do, some deployment examples, and barriers to widespread adoption. Latter using the example of the EU Digital Identity Wallet (EUDIW) and the recent discussion and feedback from cryptography experts around this topic. We also briefly comment on the transition to post-quantum cryptography.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Stability and Learning of Competitive Equilibrium in Generalized Fisher Market Models: A Variational Inequality Approach</title>
<link>https://arxiv.org/abs/2501.07265</link>
<guid>https://arxiv.org/abs/2501.07265</guid>
<content:encoded><![CDATA[
<div> 关键词：generalized Fisher market模型，社会影响，竞争均衡，变分不等式方法，学习算法

总结:<br />
本文研究了一种考虑社会影响力的广义Fisher市场模型，其中买家的效用不仅依赖于自身资源分配，还受到竞争对手的分配情况影响。为此，文章提出了一种新的基于变分不等式的竞争均衡表述法，该框架扩展了对具有非同质效用函数市场的理解。作者分析了提出的变分不等式问题的关键结构特性，包括单调性、稳定性和唯一性。此外，文章还提出了两种实现竞争均衡的分散式学习算法：一种是以两时间尺度随机近似为基础的tâtonnement方法，另一种是基于交易站机制的学习方法。最后，通过数值模拟验证了所提算法的有效性。 <div>
arXiv:2501.07265v1 Announce Type: new 
Abstract: In this work, we study a generalized Fisher market model that incorporates social influence. In this extended model, a buyer's utility depends not only on their own resource allocation but also on the allocations received by their competitors. We propose a novel competitive equilibrium formulation for this generalized Fisher market using a variational inequality approach. This framework effectively captures competitive equilibrium in markets that extend beyond the traditional assumption of homogeneous utility functions. We analyze key structural properties of the proposed variational inequality problem, including monotonicity, stability, and uniqueness. Additionally, we present two decentralized learning algorithms for buyers to achieve competitive equilibrium: a two-timescale stochastic approximation-based t{\^a}tonnement method and a trading-post mechanism-based learning method. Finally, we validate the proposed algorithms through numerical simulations.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks</title>
<link>https://arxiv.org/abs/2501.07288</link>
<guid>https://arxiv.org/abs/2501.07288</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 中心化, 民主化, 分布式专家知识, 区块链框架

<br /><br />总结:
该文指出了大型语言模型（LLMs）开发中心化的现状及其对AI发展形成的障碍，以及维护多领域专业知识更新的挑战。为解决这些问题，文章提出了一种名为 LLM-Net 的基于区块链的分布式框架。LLM-Net 旨在通过建立一个由专门领域的 LLM 提供者组成的去中心化网络，实现 LLMs 服务的民主化，利用集体计算资源和分布式领域专长，结合针对特定领域的微调专家模型来确保知识持续增长和服务质量。同时，LLM-Net 运用区块链技术进行透明交易和性能验证，建立起服务交付的不可变记录。通过在现有最先进的 LLMs 上的模拟实验，验证了声誉机制在选择高绩效提供者的有效性，展示了 LLM-Net 在整合分布式专家知识和基于区块链的责任追溯方面对于推动人工智能持续进步的潜力。 <div>
arXiv:2501.07288v1 Announce Type: new 
Abstract: The centralization of Large Language Models (LLMs) development has created significant barriers to AI advancement, limiting the democratization of these powerful technologies. This centralization, coupled with the scarcity of high-quality training data and mounting complexity of maintaining comprehensive expertise across rapidly expanding knowledge domains, poses critical challenges to the continued growth of LLMs. While solutions like Retrieval-Augmented Generation (RAG) offer potential remedies, maintaining up-to-date expert knowledge across diverse domains remains a significant challenge, particularly given the exponential growth of specialized information. This paper introduces LLMs Networks (LLM-Net), a blockchain-based framework that democratizes LLMs-as-a-Service through a decentralized network of specialized LLM providers. By leveraging collective computational resources and distributed domain expertise, LLM-Net incorporates fine-tuned expert models for various specific domains, ensuring sustained knowledge growth while maintaining service quality through collaborative prompting mechanisms. The framework's robust design includes blockchain technology for transparent transaction and performance validation, establishing an immutable record of service delivery. Our simulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet, Llama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the reputation-based mechanism in maintaining service quality by selecting high-performing respondents (LLM providers). Thereby it demonstrates the potential of LLM-Net to sustain AI advancement through the integration of decentralized expertise and blockchain-based accountability.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Union: A Trust-minimized Bridge for Bitcoin</title>
<link>https://arxiv.org/abs/2501.07435</link>
<guid>https://arxiv.org/abs/2501.07435</guid>
<content:encoded><![CDATA[
<div> 关键词: Union、信任最小化、比特币、桥接协议、BitVMX

总结:
<br />
本文介绍了名为"Union"的一种新型信任最小化的比特币桥接协议，旨在安全地实现在比特币和次要区块链之间转移BTC的同时，保持比特币的安全保障。针对围绕比特币构建的不断发展的生态系统中对于安全、高效桥梁的需求，Union采用了一个基于Bitcoin的多党派BitVMX乐观证明系统，该系统在至少一个参与者诚实的前提下保证安全运行，打破了传统的多数诚实假设。此外，协议还引入了多个创新点：基于数据包的架构可使安全性保证金用于多次桥接操作，从而提高资本效率；启用了一套管理功能实体参与并执行惩罚的机制；设计了一个灵活的轻客户端框架以适应各种区块链架构；并实现了一个优化时间锁管理的高效停止手表机制。Union是一种实用且可扩展的解决方案，它为比特币互操作性提供了强大的安全保障，并最大限度地减少了信任假设。 <div>
arXiv:2501.07435v1 Announce Type: new 
Abstract: We present Union, a trust-minimized bridge protocol that enables secure transfer of BTC between Bitcoin and a secondary blockchain. The growing ecosystem of blockchain systems built around Bitcoin has created a pressing need for secure and efficient bridges to transfer BTC between networks while preserving Bitcoin's security guarantees. Union employs a multi-party variant of BitVMX, an optimistic proving system on Bitcoin, to create a bridge that operates securely under the assumption that at least one participant remains honest. This 1-of-n honest approach is strikingly different from the conventional honest-majority assumption adopted by practically all federated systems. The protocol introduces several innovations: a packet-based architecture that allows security bonds to be reused for multiple bridge operations, improving capital efficiency; a system of enablers to manage functionaries participation and to enforce penalties; a flexible light client framework adaptable to various blockchain architectures; and an efficient stop watch mechanism to optimize time-lock management. Union is a practical and scalable solution for Bitcoin interoperability that maintains strong security guarantees and minimizes trust assumptions.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ML Mule: Mobile-Driven Context-Aware Collaborative Learning</title>
<link>https://arxiv.org/abs/2501.07536</link>
<guid>https://arxiv.org/abs/2501.07536</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能, 中心化学习, 分布式学习, 联邦学习, 隐私保护

<br />
总结:
本文提出了一种名为ML Mule的新方法，用于解决人工智能模型训练和应用中的隐私、基础设施成本以及个性化问题。ML Mule利用移动设备作为“骡子”，在物理空间中传输并共享模型快照，通过这种方式，当用户在特定空间中共享设备时，形成了隐性的协作模型进化群体，同时保护了用户的隐私。该方法克服了传统中心化、联邦学习及完全分布式学习系统的局限性，实现了更快的收敛速度和更高的模型准确性，并且更加健壮、分布广泛和个性化，使机器学习更接近于创建真正智能、自适应和情境感知环境的愿景。 <div>
arXiv:2501.07536v1 Announce Type: new 
Abstract: Artificial intelligence has been integrated into nearly every aspect of daily life, powering applications from object detection with computer vision to large language models for writing emails and compact models in smart homes. These machine learning models cater to individual users but are often detached from them, as they are typically stored and processed in centralized data centers. This centralized approach raises privacy concerns, incurs high infrastructure costs, and struggles with personalization. Federated and fully decentralized learning methods have been proposed to address these issues, but they still depend on centralized servers or face slow convergence due to communication constraints. To overcome these challenges, we propose ML Mule, a approach that utilizes individual mobile devices as 'Mules' to train and transport model snapshots as they move through physical spaces, sharing these models with the physical 'Spaces' they inhabit. This method implicitly forms affinity groups among devices associated with users who share particular spaces, enabling collaborative model evolution, and protecting users' privacy. Our approach addresses several major shortcomings of traditional, federated, and fully decentralized learning systems. The proposed framework represents a new class of machine learning methods that are more robust, distributed, and personalized, bringing the field closer to realizing the original vision of intelligent, adaptive, and genuinely context-aware smart environments. The results show that ML Mule converges faster and achieves higher model accuracy compared to other existing methods.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning for Enhancing Sensing Estimation in Bistatic ISAC Systems with UAV Swarms</title>
<link>https://arxiv.org/abs/2501.06454</link>
<guid>https://arxiv.org/abs/2501.06454</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、集成感知与通信（ISAC）、无人机（UAV）群、定位与轨迹优化、传输功率适应

总结:<br />
本文提出了一种利用多智能体强化学习（MARL）框架增强集成感知与通信（ISAC）网络的新方法，该网络使用无人机（UAV）群作为传感雷达。通过将UAV的定位和轨迹优化问题建模为部分可观测马尔可夫决策过程，研究者开发了一种采用集中式训练与分布式执行相结合的MARL策略，以最大化整体感知性能。具体来说，他们实施了一种分散合作的MARL策略，使UAV能够发展有效的通信协议，从而提高其环境意识和操作效率。此外，文中还结合了传输功率适应技术来减轻无人机间通信干扰并优化通信协议效率，进一步提升了所学通信协议的效率。尽管方案复杂度增加，但其在各种场景下展现出稳健的性能和适应性，为未来ISAC网络提供了具有可扩展性和成本效益的增强方案。 <div>
arXiv:2501.06454v1 Announce Type: cross 
Abstract: This paper introduces a novel Multi-Agent Reinforcement Learning (MARL) framework to enhance integrated sensing and communication (ISAC) networks using unmanned aerial vehicle (UAV) swarms as sensing radars. By framing the positioning and trajectory optimization of UAVs as a Partially Observable Markov Decision Process, we develop a MARL approach that leverages centralized training with decentralized execution to maximize the overall sensing performance. Specifically, we implement a decentralized cooperative MARL strategy to enable UAVs to develop effective communication protocols, therefore enhancing their environmental awareness and operational efficiency. Additionally, we augment the MARL solution with a transmission power adaptation technique to mitigate interference between the communicating drones and optimize the communication protocol efficiency. Moreover, a transmission power adaptation technique is incorporated to mitigate interference and optimize the learned communication protocol efficiency. Despite the increased complexity, our solution demonstrates robust performance and adaptability across various scenarios, providing a scalable and cost-effective enhancement for future ISAC networks.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Improving DeFi Accessibility through Efficient Liquidity Provisioning with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.07508</link>
<guid>https://arxiv.org/abs/2501.07508</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习(DRL), Uniswap v3, 自动做市商(AMM), 马尔科夫决策过程(MDP), Proximal Policy Optimization (PPO)

<br /><br />总结:
本文将深度强化学习（DRL）应用于Uniswap v3的流动性提供优化问题上，该协议是一个实现集中式流动性的去中心化金融（DeFi）协议。研究中，将流动性提供任务建模为马尔科夫决策过程（MDP），并利用Proximal Policy Optimization（PPO）算法训练一个主动型流动性提供者（LP）智能代理。该代理根据价格动态信息动态调整流动性位置，以平衡手续费最大化与临时损失最小化之间的关系。采用滚动窗口方法进行训练和测试，以反映真实的市场条件和市场周期变化。文章通过数据驱动的方法对比了基于DRL策略与小型零售LP通常采用的不系统修改其流动性位置的常见启发式策略的性能。该研究旨在通过推动更有效的流动性管理，使DeFi市场对更广泛的参与者更加可访问和包容，并促进DeFi市场的持续发展和用户友好性提升。 <div>
arXiv:2501.07508v1 Announce Type: cross 
Abstract: This paper applies deep reinforcement learning (DRL) to optimize liquidity provisioning in Uniswap v3, a decentralized finance (DeFi) protocol implementing an automated market maker (AMM) model with concentrated liquidity. We model the liquidity provision task as a Markov Decision Process (MDP) and train an active liquidity provider (LP) agent using the Proximal Policy Optimization (PPO) algorithm. The agent dynamically adjusts liquidity positions by using information about price dynamics to balance fee maximization and impermanent loss mitigation. We use a rolling window approach for training and testing, reflecting realistic market conditions and regime shifts. This study compares the data-driven performance of the DRL-based strategy against common heuristics adopted by small retail LP actors that do not systematically modify their liquidity positions. By promoting more efficient liquidity management, this work aims to make DeFi markets more accessible and inclusive for a broader range of participants. Through a data-driven approach to liquidity management, this work seeks to contribute to the ongoing development of more efficient and user-friendly DeFi markets.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semitopology: a topological approach to decentralised collaborative action</title>
<link>https://arxiv.org/abs/2303.09287</link>
<guid>https://arxiv.org/abs/2303.09287</guid>
<content:encoded><![CDATA[
<div> 关键词：semitopology、点集拓扑、分布式系统、可操作联盟、局部更新

<br /><br />总结:
本文介绍了semitopology，这是一种对点集拓扑学的扩展，放宽了开放集合交集必须为开放集合的限制。semitopology的核心思想是将点视为去中心化系统中的参与者，而开放集合代表那些拥有共同权限协作更新本地状态的参与者的集合，即可操作联盟。文中给出了如权益证明区块链中的多数股权、点对点网络中的通信节点以及街头行人避免碰撞等可操作联盟的例子。这些系统的共性包括：协作具有局部性（仅更新联盟内参与者的状态）；协作自愿（直至规则被打破）；参与者异构（计算能力或目标不同）；可以选择合作对象；并且不依赖于中央权威的许可或同步。文章通过一种带有拓扑学色彩的数学方法，探讨了这类复杂去中心化系统如何展现出秩序，并为我们理解现有实际实现提供了新的视角。 <div>
arXiv:2303.09287v5 Announce Type: replace 
Abstract: We introduce semitopology, a generalisation of point-set topology that removes the restriction that intersections of open sets need necessarily be open. The intuition is that points represent participants in a decentralised system, and open sets represent collections of participants that collectively have the authority to collaborate to update their local state; we call this an actionable coalition.
  Examples of actionable coalition include: majority stakes in proof-of-stake blockchains; communicating peers in peer-to-peer networks; and even pedestrians working together to not bump into one another in the street. Where actionable coalitions exist, they have in common that: collaborations are local (updating the states of the participants in the coalition, but not immediately those of the whole system); collaborations are voluntary (up to and including breaking rules); participants may be heterogeneous in their computing power or in their goals (not all pedestrians want to go to the same place); participants can choose with whom to collaborate; and they are not assumed subject to permission or synchronisation by a central authority.
  We develop a topology-flavoured mathematics that goes some way to explaining how and why these complex decentralised systems can exhibit order, and gives us new ways to understand existing practical implementations.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Proposal for a Lean and Functional Delivery versus Payment across two Blockchains</title>
<link>https://arxiv.org/abs/2311.05966</link>
<guid>https://arxiv.org/abs/2311.05966</guid>
<content:encoded><![CDATA[
<div> 关键词: 交易方案、区块链、去中介化、低开销、安全交付与支付

总结:
我们提出了一种精简且实用的跨两个区块链的安全交付对支付交易方案。该方案无需中介，且支付链操作员只需承担较小的开销，无须存储状态。实现这一目标主要依赖两点：首先，支付链运营商提供一个无状态解密服务，允许使用其私钥解密消息；其次，在支付链上部署了一个“支付合约”，实现了transferAndDecrypt函数，该函数处理基于触发的支付并根据交易的成功或失败发出解密后的密钥。相应的密钥可以触发关联交易，例如买家领取交付物或者卖家在交易失败时重新找回被锁定的资产。 <div>
arXiv:2311.05966v3 Announce Type: replace 
Abstract: We propose a lean and functional transaction scheme to establish a secure delivery-versus-payment across two blockchains, where a) no intermediary is required and b) the operator of the payment chain/payment system has a small overhead and does not need to store state. The main idea comes with two requirements: First, the payment chain operator hosts a stateless decryption service that allows decrypting messages with his secret key. Second, a "Payment Contract" is deployed on the payment chain that implements a function transferAndDecrypt(uint id, address from, address to, string keyEncryptedSuccess, string keyEncryptedFail) that processes the (trigger-based) payment and emits the decrypted key depending on the success or failure of the transaction. The respective key can then trigger an associated transaction, e.g. claiming delivery by the buyer or re-claiming the locked asset by the seller.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Complexity of Decentralized Smooth Nonconvex Finite-Sum Optimization</title>
<link>https://arxiv.org/abs/2210.13931</link>
<guid>https://arxiv.org/abs/2210.13931</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、非凸函数、DEAREST算法、通信复杂性、计算复杂性

总结:
该文研究了分布式优化问题，其中目标函数为多个局部光滑但可能非凸函数的平均。文章提出了一种名为DEcentralized probAbilistic Recursive gradiEnt deScenT (DEAREST)的新算法，该算法能够在每个代理节点达到$\epsilon$-临界点，所需的通信轮数为$\tilde{\mathcal O}(L\epsilon^{-2}/\sqrt{\gamma}\,)$，计算轮数为$\tilde{\mathcal O}(n+(L+\min\{nL, \sqrt{n/m}\bar L\})\epsilon^{-2})$，以及本地增量第一阶 oracle 调用次数为${\mathcal O}(mn + {\min\{mnL, \sqrt{mn}\bar L\}}{\epsilon^{-2}})$。文中还建立了下界，证明了所提方法的近似最优性。值得注意的是，DEAREST算法的设计和分析中使用的光滑度参数$L$和$\bar L$是全局性的，从而导致比依赖于局部光滑度的现有结果更尖锐的复杂性界限。此外，DEAREST算法还被扩展到解决满足Polyak-{\L}ojasiewicz条件的分布式有限和优化问题，并同样实现了近似最优的复杂性界限。<br /><br /> <div>
arXiv:2210.13931v4 Announce Type: replace-cross 
Abstract: We study the decentralized optimization problem $\min_{{\bf x}\in{\mathbb R}^d} f({\bf x})\triangleq \frac{1}{m}\sum_{i=1}^m f_i({\bf x})$, where the local function on the $i$-th agent has the form of $f_i({\bf x})\triangleq \frac{1}{n}\sum_{j=1}^n f_{i,j}({\bf x})$ and every individual $f_{i,j}$ is smooth but possibly nonconvex. We propose a stochastic algorithm called DEcentralized probAbilistic Recursive gradiEnt deScenT (DEAREST) method, which achieves an $\epsilon$-stationary point at each agent with the communication rounds of $\tilde{\mathcal O}(L\epsilon^{-2}/\sqrt{\gamma}\,)$, the computation rounds of $\tilde{\mathcal O}(n+(L+\min\{nL, \sqrt{n/m}\bar L\})\epsilon^{-2})$, and the local incremental first-oracle calls of ${\mathcal O}(mn + {\min\{mnL, \sqrt{mn}\bar L\}}{\epsilon^{-2}})$, where $L$ is the smoothness parameter of the objective function, $\bar L$ is the mean-squared smoothness parameter of all individual functions, and $\gamma$ is the spectral gap of the mixing matrix associated with the network. We then establish the lower bounds to show that the proposed method is near-optimal. Notice that the smoothness parameters $L$ and $\bar L$ used in our algorithm design and analysis are global, leading to sharper complexity bounds than existing results that depend on the local smoothness. We further extend DEAREST to solve the decentralized finite-sum optimization problem under the Polyak-{\L}ojasiewicz condition, also achieving the near-optimal complexity bounds.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Fair Ordering and Differential Privacy</title>
<link>https://arxiv.org/abs/2501.05535</link>
<guid>https://arxiv.org/abs/2501.05535</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、公平交易排序、算法偏见、等机会原则、差分隐私

总结:
本文探讨了区块链系统中公平交易排序的重要性以及与传统状态机复制(SMR)系统的差异。文章提出了基于相关和无关特征来定义交易，确保交易排序仅由相关特征决定，相同相关特征的交易有相等的排序机会。进一步地，文章将这一公平性框架扩展为一种概率性原则：相关特征差异越大的交易，被优先排序的概率越高。文章揭示了一个令人惊讶的联系，即SMR中的等机会原则与差分隐私(DP)之间存在关联，证明任何DP机制都可以用于确保SMR中的公平性。这一发现深化了我们对分布式计算中隐私与公平性相互关系的理解，并为设计利用成熟DP技术实现公平分布式协议开辟了新途径。 <div>
arXiv:2501.05535v1 Announce Type: new 
Abstract: In blockchain systems, fair transaction ordering is crucial for a trusted and regulation-compliant economic ecosystem. Unlike traditional State Machine Replication (SMR) systems, which focus solely on liveness and safety, blockchain systems also require a fairness property. This paper examines these properties and aims to eliminate algorithmic bias in transaction ordering services.
  We build on the notion of equal opportunity. We characterize transactions in terms of relevant and irrelevant features, requiring that the order be determined solely by the relevant ones. Specifically, transactions with identical relevant features should have an equal chance of being ordered before one another. We extend this framework to define a property where the greater the distance in relevant features between transactions, the higher the probability of prioritizing one over the other.
  We reveal a surprising link between equal opportunity in SMR and Differential Privacy (DP), showing that any DP mechanism can be used to ensure fairness in SMR. This connection not only enhances our understanding of the interplay between privacy and fairness in distributed computing but also opens up new opportunities for designing fair distributed protocols using well-established DP techniques.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Kite: How to Delegate Voting Power Privately</title>
<link>https://arxiv.org/abs/2501.05626</link>
<guid>https://arxiv.org/abs/2501.05626</guid>
<content:encoded><![CDATA[
<div> 关键词：Kite、私人委托投票、Decentralized Autonomous Organizations (DAO)、隐私保护、Universal Composability (UC)框架

<br /><br />总结:
本文介绍了Kite协议，这是一种新的用于Decentralized Autonomous Organizations (DAO)的协议，旨在实现投票权的私人委托。与现有仅支持公开委托的DAO投票系统不同，Kite允许成员在不泄露其委托对象信息的情况下自由地进行委托、撤销和重新委托投票权。即使被委托者也不知道谁委托给了他们，公共记录中仅显示投票者将权力委托给了某人。Kite同时支持公开和私密的代表投票。该协议的安全性在Universal Composability (UC)框架下进行了分析，并已在以太坊区块链上的广泛应用Governor Bravo智能合约上实现了Kite的扩展。实施评估表明，尽管零知识证明导致了委托操作的成本较高（在消费级笔记本电脑上，委托耗时在7到167秒之间，具体取决于所需的隐私级别），但该协议仍具有实际可行性。 <div>
arXiv:2501.05626v1 Announce Type: new 
Abstract: Ensuring the privacy of votes in an election is crucial for the integrity of a democratic process. Often, voting power is delegated to representatives (e.g., in congress) who subsequently vote on behalf of voters on specific issues. This delegation model is also widely used in Decentralized Autonomous Organizations (DAOs). Although several existing voting systems used in DAOs support private voting, they only offer public delegation. In this paper, we introduce Kite, a new protocol that enables $\textit{private}$ delegation of voting power for DAO members. Voters can freely delegate, revoke, and re-delegate their power without revealing any information about who they delegated to. Even the delegate does not learn who delegated to them. The only information that is recorded publicly is that the voter delegated or re-delegated their vote to someone. Kite accommodates both public and private voting for the delegates themselves. We analyze the security of our protocol within the Universal Composability (UC) framework. We implement Kite as an extension to the existing Governor Bravo smart contract on the Ethereum blockchain, that is widely used for DAO governance. Furthermore, we provide an evaluation of our implementation that demonstrates the practicality of the protocol. The most expensive operation is delegation due to the required zero-knowledge proofs. On a consumer-grade laptop, delegation takes between 7 and 167 seconds depending on the requested level of privacy.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scaling Safe Multi-Agent Control for Signal Temporal Logic Specifications</title>
<link>https://arxiv.org/abs/2501.05639</link>
<guid>https://arxiv.org/abs/2501.05639</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体控制、逻辑规范、信号temporal逻辑(STL)、图神经网络(GNN)、混合整数线性规划(MILP)

总结:
本文提出了一个新的适用于多智能体控制的方法，旨在解决使用如STL等逻辑规范进行安全控制时所面临的可扩展性问题。现有的方法依赖于单智能体视角或复杂的MILP规划器，导致处理大量智能体时计算成本高昂和效率低下。与现有方法不同，该新方法利用图结构描述智能体之间的关系，并结合一种多智能体碰撞避免控制器以及基于GNN的规划器，以分布式方式建模系统并针对STL目标进行训练，生成多智能体的安全高效计划，同时优化满足复杂时间规范并实现多智能体碰撞避让。实验表明，相较于采用先进的MILP规划器的现有方法，该方法在可扩展性和性能方面具有显著优势。项目网站为https://jeappen.com/mastl-gcbf-website/，代码可在https://github.com/jeappen/mastl-gbf 获取。<br /><br /> <div>
arXiv:2501.05639v1 Announce Type: new 
Abstract: Existing methods for safe multi-agent control using logic specifications like Signal Temporal Logic (STL) often face scalability issues. This is because they rely either on single-agent perspectives or on Mixed Integer Linear Programming (MILP)-based planners, which are complex to optimize. These methods have proven to be computationally expensive and inefficient when dealing with a large number of agents. To address these limitations, we present a new scalable approach to multi-agent control in this setting. Our method treats the relationships between agents using a graph structure rather than in terms of a single-agent perspective. Moreover, it combines a multi-agent collision avoidance controller with a Graph Neural Network (GNN) based planner, models the system in a decentralized fashion, and trains on STL-based objectives to generate safe and efficient plans for multiple agents, thereby optimizing the satisfaction of complex temporal specifications while also facilitating multi-agent collision avoidance. Our experiments show that our approach significantly outperforms existing methods that use a state-of-the-art MILP-based planner in terms of scalability and performance. The project website is https://jeappen.com/mastl-gcbf-website/ and the code is at https://github.com/jeappen/mastl-gcbf .
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fully Decentralized Computation Offloading in Priority-Driven Edge Computing Systems</title>
<link>https://arxiv.org/abs/2501.05660</link>
<guid>https://arxiv.org/abs/2501.05660</guid>
<content:encoded><![CDATA[
<div> 关键词：多接入边缘计算(MEC)，非合作游戏框架，年龄信息(AoI)，平均场游戏(MFG)，梯度下降算法

总结:<br />
本文提出了一种新颖的完全去中心化的多接入边缘计算（MEC）系统中任务卸载策略设计框架。该系统由N个具有功率限制的用户设备(UEs)和一个边缘服务器(ES)组成，用于处理带有紧急标志的入站任务，这些任务被分为高、中、低三种紧急等级。文章将UE的任务执行决策问题在一个大型群体非合作游戏框架中进行建模，其中每个UE自私地决定如何将其任务执行分割给本地车载处理器和ES。通过采用加权平均信息新鲜度（AoI）指标来量化UE的信息新鲜度。增加本地处理会消耗更多功率，而增加卸载可能会由于其他UE的包被卸载到同一个ES而导致平均AoI潜在增加。因此，文章利用平均场游戏(MFG)理论来计算UE的近似分散纳什均衡卸载和本地计算策略，以平衡信息新鲜度与本地功耗。最后，文章提供了一个基于投影梯度下降法的数值算法，用于评估所提方法的优点。 <div>
arXiv:2501.05660v1 Announce Type: new 
Abstract: We develop a novel framework for fully decentralized offloading policy design in multi-access edge computing (MEC) systems. The system comprises $N$ power-constrained user equipments (UEs) assisted by an edge server (ES) to process incoming tasks. Tasks are labeled with urgency flags, and in this paper, we classify them under three urgency levels, namely, high, moderate, and low urgency. We formulate the problem of designing computation decisions for the UEs within a large population noncooperative game framework, where each UE selfishly decides on how to split task execution between its local onboard processor and the ES. We employ the weighted average age of information (AoI) metric to quantify information freshness at the UEs. Increased onboard processing consumes more local power, while increased offloading may potentially incur a higher average AoI due to other UEs' packets being offloaded to the same ES. Thus, we use the mean-field game (MFG) formulation to compute approximate decentralized Nash equilibrium offloading and local computation policies for the UEs to balance between the information freshness and local power consumption. Finally, we provide a projected gradient descent-based algorithm to numerically assess the merits of our approach.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Content Moderation in the Fediverse</title>
<link>https://arxiv.org/abs/2501.05871</link>
<guid>https://arxiv.org/abs/2501.05871</guid>
<content:encoded><![CDATA[
<div> 关键词：Fediverse、内容审核、联邦学习、FedMod、性能评估

总结:
这篇论文关注的是随着Elon Musk收购Twitter后迅速壮大的去中心化社交网络平台——Fediverse所面临的内容审核挑战。由于Fediverse中的服务器资源有限，无法像Facebook和Twitter那样依赖大规模标注数据和专业化基础设施进行自动化审核，因此文章提出了一种基于联邦学习的协同内容审核系统FedMod。FedMod允许相似的服务器之间交换部分训练完成的本地内容审核模型参数，从而构建一个在协作服务器间共享的联邦模型。实验结果显示，FedMod在有害内容检测、机器人内容检测和内容警告分配三个不同的内容审核任务上表现出稳健的性能，分别达到了平均每个服务器的宏F1分数为0.71、0.73和0.58。 <div>
arXiv:2501.05871v1 Announce Type: new 
Abstract: The Fediverse, a group of interconnected servers providing a variety of interoperable services (e.g. micro-blogging in Mastodon) has gained rapid popularity. This sudden growth, partly driven by Elon Musk's acquisition of Twitter, has created challenges for administrators though. This paper focuses on one particular challenge: content moderation, e.g. the need to remove spam or hate speech. While centralized platforms like Facebook and Twitter rely on automated tools for moderation, their dependence on massive labeled datasets and specialized infrastructure renders them impractical for decentralized, low-resource settings like the Fediverse. In this work, we design and evaluate FedMod, a collaborative content moderation system based on federated learning. Our system enables servers to exchange parameters of partially trained local content moderation models with similar servers, creating a federated model shared among collaborating servers. FedMod demonstrates robust performance on three different content moderation tasks: harmful content detection, bot content detection, and content warning assignment, achieving average per-server macro-F1 scores of 0.71, 0.73, and 0.58, respectively.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion Planning for Future Autonomous Mobility on Demand Systems</title>
<link>https://arxiv.org/abs/2501.06132</link>
<guid>https://arxiv.org/abs/2501.06132</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Mobility-on-Demand (AMoD)，Demand Responsive Transport (DRT)，Connected and Autonomous Vehicles (CAVs)，Vision-Language Models (VLMs)，Consensus Alternating Direction Method of Multipliers (ADMM)

总结:<br />
本文提出了一种名为CoDriveVLM的新颖框架，旨在解决传统需求响应式运输系统(DRT)在灵活和高效城市交通解决方案方面的局限性，特别是针对多元化乘客需求和动态城市环境。CoDriveVLM着重于未来AMoD系统的高保真同步调度与合作运动规划的集成，利用Vision-Language Models (VLMs)增强多模态信息处理能力，从而实现全面的调度和碰撞风险评估。文章中还引入了基于VLM的CAV调度协调器来有效管理复杂和意外的AMoD情况，支持高效的调度决策。此外，通过一致性交替方向乘子法(ADMM)提出了一种可扩展的分布式合作运动规划方法，重点关注碰撞风险评估和分散化的轨迹优化。模拟结果显示，CoDriveVLM在各种交通条件下的可行性和鲁棒性，显示出其在未来城市交通网络中显著提升AMoD系统的真实性和效率的潜力。相关代码可在https://github.com/henryhcliu/CoDriveVLM.git获取。 <div>
arXiv:2501.06132v1 Announce Type: new 
Abstract: The increasing demand for flexible and efficient urban transportation solutions has spotlighted the limitations of traditional Demand Responsive Transport (DRT) systems, particularly in accommodating diverse passenger needs and dynamic urban environments. Autonomous Mobility-on-Demand (AMoD) systems have emerged as a promising alternative, leveraging connected and autonomous vehicles (CAVs) to provide responsive and adaptable services. However, existing methods primarily focus on either vehicle scheduling or path planning, which often simplify complex urban layouts and neglect the necessity for simultaneous coordination and mutual avoidance among CAVs. This oversimplification poses significant challenges to the deployment of AMoD systems in real-world scenarios. To address these gaps, we propose CoDriveVLM, a novel framework that integrates high-fidelity simultaneous dispatching and cooperative motion planning for future AMoD systems. Our method harnesses Vision-Language Models (VLMs) to enhance multi-modality information processing, and this enables comprehensive dispatching and collision risk evaluation. The VLM-enhanced CAV dispatching coordinator is introduced to effectively manage complex and unforeseen AMoD conditions, thus supporting efficient scheduling decision-making. Furthermore, we propose a scalable decentralized cooperative motion planning method via consensus alternating direction method of multipliers (ADMM) focusing on collision risk evaluation and decentralized trajectory optimization. Simulation results demonstrate the feasibility and robustness of CoDriveVLM in various traffic conditions, showcasing its potential to significantly improve the fidelity and effectiveness of AMoD systems in future urban transportation networks. The code is available at https://github.com/henryhcliu/CoDriveVLM.git.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Multi-Antenna Architectures with Unitary Constraints</title>
<link>https://arxiv.org/abs/2501.06067</link>
<guid>https://arxiv.org/abs/2501.06067</guid>
<content:encoded><![CDATA[
<div> 关键词：base station, decentralized approach, WAX框架, unitary restriction, interconnection bandwidth

总结:<br />
随着基站（BS）天线数量的增加，对有效处理传统集中式方法中增多的数据连接带宽和处理复杂性的需求日益增长。因此，分布式方法逐渐受到关注，因为它们可以通过预先处理接收到的信号来显著减少数据/处理量，然后再将其转发至中央节点。本文研究了WAX框架的一个改编版，该框架考虑了在分布式处理具有单位制限制的情况下，如何实现通过可重构阻抗网络实现能效较高的实施方案，但代价是性能有所损失。此外，文章提出了一种有效缩小与集中式处理性能差距的方法。这种方法为进一步研究具有单位制约束条件的分布式架构中，互联带宽与处理复杂性之间无信息损失的权衡关系提供了初步探索。 <div>
arXiv:2501.06067v1 Announce Type: cross 
Abstract: The increase in the number of base station (BS) antennas calls for efficient solutions to deal with the increased interconnection bandwidth and processing complexity of traditional centralized approaches. Decentralized approaches are thus gaining momentum, since they achieve important reductions in data/processing volume by preprocessing the received signals before forwarding them to a central node. The WAX framework offers a general description of decentralized architectures with arbitrary interplay between interconnection bandwidth and decentralized processing complexity, but the applicability of this framework has only been studied assuming unrestricted baseband processing. We consider an adaptation of the WAX framework where the decentralized processing has unitary restriction, which allows for energy-efficient implementations based on reconfigurable impedance networks at the cost of some performance loss. Moreover, we propose an effective method to minimize the performance gap with respect to centralized processing. The previous method gives a first step towards characterizing the information-lossless trade-off between interconnection bandwidth and processing complexity in decentralized architectures with unitary constraints.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Nearly Linear-Time Distributed Algorithm for Maximum Cardinality Matching</title>
<link>https://arxiv.org/abs/2311.04140</link>
<guid>https://arxiv.org/abs/2311.04140</guid>
<content:encoded><![CDATA[
<div> 关键词: 随机化算法、最大匹配问题、CONGEST模型、增广路径、交替基树

总结:
<br />
本文提出了一种随机化的$\tilde{O}(\mu(G))$轮算法，用于解决CONGEST模型中的最大-cardinality匹配问题，其中$\mu(G)$表示输入图$G$的最大匹配大小。该算法显著改进了当前最坏情况下的运行时间。核心技术创新在于设计了一个新的随机算法，能够在$\tilde{O}(\ell)$轮内高概率找到长度为$\ell$的增广路径，从而正面解决了Ahmadi和Kuhn在先前工作中的开放问题。该增广路径算法基于Kitamura和Izumi的一项最新成果，即高效识别包含增广路径的输入图稀疏子结构，利用了“交替基树”这一新概念。然而，原方法部分依赖于将子结构的所有信息集中到单个顶点的中心化方法来构造长增广路径。本文的技术亮点则是提供了这种中心化方法的全分布式对应方案。为了开发此算法，我们证明了交替基树的几个新的结构性质，这些性质本身也具有独立的研究价值。 <div>
arXiv:2311.04140v3 Announce Type: replace 
Abstract: In this paper, we propose a randomized $\tilde{O}(\mu(G))$-round algorithm for the maximum cardinality matching problem in the CONGEST model, where $\mu(G)$ means the maximum size of a matching of the input graph $G$. The proposed algorithm substantially improves the current best worst-case running time. The key technical ingredient is a new randomized algorithm of finding an augmenting path of length $\ell$ with high probability within $\tilde{O}(\ell)$ rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC'20].
  The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi [IEICE Trans.'22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept called \emph{alternating base trees}. Their algorithm, however, resorts in part to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing a long augmenting path. The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method. To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Based Secure Vehicle Auction System with Smart Contracts</title>
<link>https://arxiv.org/abs/2501.04841</link>
<guid>https://arxiv.org/abs/2501.04841</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、中心化系统、单点故障、智能合约、车辆信息交易

总结:
区块链技术通过去中心化解决了中心化系统中的单点故障和数据篡改问题，其安全特性得到分析和认可。文章提出了一种基于以太坊区块链和智能合约技术的新系统，用于存储和交易车辆信息。该系统使得用户可以上传车辆信息并进行车辆拍卖，实现所有权转移。通过使用智能合约，系统在为买家和车主提供便利的同时，增强了交易的安全性和隐私保护。 <div>
arXiv:2501.04841v1 Announce Type: new 
Abstract: The problem of a single point of failure in centralized systems poses a great challenge to the stability of such systems. Meanwhile, the tamperability of data within centralized systems makes users reluctant to trust and use centralized applications in many scenarios, including the financial and business sectors.
  Blockchain, as a new decentralized technology, addresses these issues effectively. As a typical decentralized system, blockchain can be utilized to build a data-sharing model. Users in a blockchain do not need to trust other users; instead, they trust that the majority of miner nodes are honest. Smart contracts enable developers to write distributed programs based on blockchain systems, ensuring that all code is immutable and secure.
  In this paper, we analyze the security of blockchain technology to illustrate its advantages and justify its use. Furthermore, we design a new system for storing and trading vehicle information based on the Ethereum blockchain and smart contract technology. Specifically, our system allows users to upload vehicle information and auction vehicles to transfer ownership. Our application provides great convenience to buyers and owners, while the use of smart contracts enhances the security and privacy of the system.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning</title>
<link>https://arxiv.org/abs/2501.05053</link>
<guid>https://arxiv.org/abs/2501.05053</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、隐私保护、安全聚合、阈值功能性加密、TAPFed

总结:
本文提出了一个新的隐私保护方案TAPFed，用于解决多中心化环境下存在恶意行为者的联邦学习中的隐私泄露问题。传统的联邦学习平台由于梯度交换导致隐私泄露，而现有的安全聚合机制对于近期出现的离散攻击等推理攻击仍显得脆弱。TAPFed引入了一种新的阈值功能性加密方案，能在容忍一定数量恶意聚合器的同时，保证安全性和隐私性。文章对TAPFed进行了形式化的安全性与隐私性分析，并通过实验对比了其与其他基线方法的性能。结果表明，TAPFed在模型质量上与最先进的方法相当，同时在不同模型训练场景下能降低29%-45%的传输开销，并且能够有效防御由好奇聚合器引发的最近展示的推理攻击，这是大多数现有方法所不能做到的。<br /><br /> <div>
arXiv:2501.05053v1 Announce Type: new 
Abstract: Federated learning is a computing paradigm that enhances privacy by enabling multiple parties to collaboratively train a machine learning model without revealing personal data. However, current research indicates that traditional federated learning platforms are unable to ensure privacy due to privacy leaks caused by the interchange of gradients. To achieve privacy-preserving federated learning, integrating secure aggregation mechanisms is essential. Unfortunately, existing solutions are vulnerable to recently demonstrated inference attacks such as the disaggregation attack. This paper proposes TAPFed, an approach for achieving privacy-preserving federated learning in the context of multiple decentralized aggregators with malicious actors. TAPFed uses a proposed threshold functional encryption scheme and allows for a certain number of malicious aggregators while maintaining security and privacy. We provide formal security and privacy analyses of TAPFed and compare it to various baselines through experimental evaluation. Our results show that TAPFed offers equivalent performance in terms of model quality compared to state-of-the-art approaches while reducing transmission overhead by 29%-45% across different model training scenarios. Most importantly, TAPFed can defend against recently demonstrated inference attacks caused by curious aggregators, which the majority of existing approaches are susceptible to.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>QMDB: Quick Merkle Database</title>
<link>https://arxiv.org/abs/2501.05262</link>
<guid>https://arxiv.org/abs/2501.05262</guid>
<content:encoded><![CDATA[
<div> 关键词: QMDB、区块链、SSD优化、授权数据结构、性能提升

总结:
本文介绍了Quick Merkle Database (QMDB)，一个针对SSD优化的授权数据结构，它为现有数据库提供了超集功能。QMDB采用只追加设计，实现了每次状态访问仅需1次SSD读取、更新操作的$O(1)$ I/O以及在一个适合消费者级PC的小型DRAM空间内的内存Merkle化。研究显示，QMDB相比RocksDB提升了6倍，比最先进的可验证数据库提升了8倍的吞吐量，并在高达150亿条数据（约为2024年以太坊状态大小的10倍）的大规模数据集上验证了其可扩展性。QMDB单机理论上可以存储最多2800亿条条目，远超当前区块链需求。此外，QMDB在商品级和企业级硬件上均表现出良好的扩展性，可实现每秒200万次的状态更新，从而显著缓解了当前区块链执行层面临的存储瓶颈问题，降低了参与区块链的门槛，并为新的区块链应用开辟了可能性。 <div>
arXiv:2501.05262v1 Announce Type: new 
Abstract: Updating, managing, and proving world state are key bottlenecks facing the execution layer of blockchains today. Existing storage solutions are not flash-optimized and suffer from high flash write amplification and excessive DRAM requirements, forcing a trade-off between throughput and decentralization. We present the Quick Merkle Database (QMDB), an SSD-optimized authenticated data structure that delivers a superset of the features of existing databases. QMDB's append-only design enables 1 SSD read per state access, $O(1)$ I/Os for updates, and in-memory Merkleization on a DRAM footprint small enough to fit on consumer-grade PCs. We demonstrate that QMDB offers a significant leap in throughput ($6 \times$ over RocksDB and $8 \times$ over a state-of-the-art verifiable database) and validate its scalability on datasets up to 15 billion entries ($10 \times$ Ethereum's state size in 2024). Our projections indicate QMDB could store a theoretical maximum of 280 billion entries on a single machine, far exceeding current blockchain requirements. QMDB scales across both commodity and enterprise hardware, achieving up to 2 million state updates per second. QMDB sets a new benchmark for verifiable databases, alleviating today's storage bottlenecks, lowering barriers to blockchain participation, and unlocking new blockchain applications.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GaussDB-Global: A Geographically Distributed Database System</title>
<link>https://arxiv.org/abs/2501.05295</link>
<guid>https://arxiv.org/abs/2501.05295</guid>
<content:encoded><![CDATA[
<div> 关键词：GaussDB-Global、地理分布式数据库系统、异步复制、事务管理、强一致性<br /><br />总结:
GaussDB-Global是一款为OLTP应用设计的分片式地理分布式数据库系统，采用异步复制技术。为了克服集中式交易管理带来的延迟问题，该系统采取了基于同步时钟的去中心化方法，能在集中式和去中心化交易管理之间无缝切换，实现高效容错并简化部署。同时，针对远程读取和日志传输的问题，GaussDB-Global支持带有强一致性和可调整新鲜度保证的异步副本读取以及动态负载均衡。实验结果显示，在地理分布式的集群环境中，与基线相比，GaussDB-Global能够提供高达14倍的读取吞吐量提升以及50%更多的TPC-C吞吐量提升。 <div>
arXiv:2501.05295v1 Announce Type: new 
Abstract: Geographically distributed database systems use remote replication to protect against regional failures. These systems are sensitive to severe latency penalties caused by centralized transaction management, remote access to sharded data, and log shipping over long distances. To tackle these issues, we present GaussDB-Global, a sharded geographically distributed database system with asynchronous replication, for OLTP applications. To tackle the transaction management bottleneck, we take a decentralized approach using synchronized clocks. Our system can seamlessly transition between centralized and decentralized transaction management, providing efficient fault tolerance and streamlining deployment. To alleviate the remote read and log shipping issues, we support reads on asynchronous replicas with strong consistency, tunable freshness guarantees, and dynamic load balancing. Our experimental results on a geographically distributed cluster show that our approach provides up to 14x higher read throughput, and 50% more TPC-C throughput compared to our baseline.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Recursive matrix algorithms, distributed dynamic control, scaling, stability</title>
<link>https://arxiv.org/abs/2501.05318</link>
<guid>https://arxiv.org/abs/2501.05318</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv, 2501.05318v1, 新发布, 块递归矩阵算法, 超级计算机, 分布式内存, 动态去中心化控制

<br />
总结:
该报告关注的是在具有分布式内存和动态去中心化控制的超级计算机上创建块递归矩阵算法的概念。文章介绍了一种新的方法，旨在利用这些算法提高大规模并行计算效率和性能。 <div>
arXiv:2501.05318v1 Announce Type: new 
Abstract: The report is devoted to the concept of creating block-recursive matrix algorithms for computing on a supercomputer with distributed memory and dynamic decentralized control.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Learning and Inference Systems: A Networking Perspective</title>
<link>https://arxiv.org/abs/2501.05323</link>
<guid>https://arxiv.org/abs/2501.05323</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习模型、中央化训练、隐私问题、分布式方法、DA-ITN框架

总结:
随着机器学习模型在各类任务中达到甚至超越人类水平的表现，集中式的训练和静态模型使用暴露出诸如隐私问题、高存储需求、单点故障及大量计算需求等缺点。为应对这些挑战，研究者们开始关注开发去中心化和分布式的AI训练与推理方法。本文提出了一种新的框架——数据与动态感知推理和训练网络（DA-ITN），探讨了其组成部分及其功能，并着重指出了在分布式AI系统发展中所面临的挑战和相关研究领域。 <div>
arXiv:2501.05323v1 Announce Type: new 
Abstract: Machine learning models have achieved, and in some cases surpassed, human-level performance in various tasks, mainly through centralized training of static models and the use of large models stored in centralized clouds for inference. However, this centralized approach has several drawbacks, including privacy concerns, high storage demands, a single point of failure, and significant computing requirements. These challenges have driven interest in developing alternative decentralized and distributed methods for AI training and inference. Distribution introduces additional complexity, as it requires managing multiple moving parts. To address these complexities and fill a gap in the development of distributed AI systems, this work proposes a novel framework, Data and Dynamics-Aware Inference and Training Networks (DA-ITN). The different components of DA-ITN and their functions are explored, and the associated challenges and research areas are highlighted.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Validation of GPU Computation in Decentralized, Trustless Networks</title>
<link>https://arxiv.org/abs/2501.05374</link>
<guid>https://arxiv.org/abs/2501.05374</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式网络、GPU计算、验证方法、模型指纹技术、语义相似性分析、GPU性能分析、概率验证框架、可信节点验证、共识框架、非确定性执行

总结:<br />
本文针对分布式网络中GPU计算的验证问题展开研究，指出现有方法如精确重算（因GPU节点间的计算非确定性）、受信任执行环境（需要专用硬件）和全同态加密（面临高昂计算成本）等存在的局限性。文章探讨了从相邻技术领域借鉴的三种验证方法：模型指纹技术、语义相似性分析以及GPU性能分析。通过系统研究这些方法，作者提出了一种新颖的概率验证框架，包括采用二进制参考模型结合可信节点验证的方法，以及构建消除信任需求的三元共识框架。这些方法为确保在不可信网络中的GPU加速工作负载计算完整性奠定了基础，同时有效应对了非确定性执行带来的挑战。 <div>
arXiv:2501.05374v1 Announce Type: new 
Abstract: Verifying computational processes in decentralized networks poses a fundamental challenge, particularly for Graphics Processing Unit (GPU) computations. Our investigation reveals significant limitations in existing approaches: exact recomputation fails due to computational non-determinism across GPU nodes, Trusted Execution Environments (TEEs) require specialized hardware, and Fully Homomorphic Encryption (FHE) faces prohibitive computational costs. To address these challenges, we explore three verification methodologies adapted from adjacent technical domains: model fingerprinting techniques, semantic similarity analysis, and GPU profiling. Through systematic exploration of these approaches, we develop novel probabilistic verification frameworks, including a binary reference model with trusted node verification and a ternary consensus framework that eliminates trust requirements. These methodologies establish a foundation for ensuring computational integrity across untrusted networks while addressing the inherent challenges of non-deterministic execution in GPU-accelerated workloads.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Diffusion Models</title>
<link>https://arxiv.org/abs/2501.05450</link>
<guid>https://arxiv.org/abs/2501.05450</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模AI模型训练、分散式扩散模型、独立集群、基础设施成本、GPU故障韧性

总结:
<br />
本文提出了一种名为“分散式扩散模型”的新型框架，旨在解决大规模AI模型训练中对集中式、高带宽网络结构的依赖问题。该方法通过将数据集划分并分别在隔离的专家模型上进行训练，每个专家模型都在自己的计算岛上全独立运行。在推理阶段，这些专家模型通过轻量级路由器进行融合。实验表明，这种ensemble方式能实现与单一模型在完整数据集上训练相同的优化目标。分散式扩散模型可以降低基础设施成本、提高对局部GPU故障的韧性，使得研究者能够利用更小、更具成本效益和易获取的计算资源，如按需GPU节点，而无需大型集成系统。文中在ImageNet和LAION Aesthetics数据集上进行了广泛实验，证明了分散式扩散模型在同等计算量下优于标准扩散模型。最后，作者将这种方法扩展到240亿参数规模，展示了只需8个独立GPU节点就能在一周内训练出高质量的扩散模型。 <div>
arXiv:2501.05450v1 Announce Type: new 
Abstract: Large-scale AI model training divides work across thousands of GPUs, then synchronizes gradients across them at each step. This incurs a significant network burden that only centralized, monolithic clusters can support, driving up infrastructure costs and straining power systems. We propose Decentralized Diffusion Models, a scalable framework for distributing diffusion model training across independent clusters or datacenters by eliminating the dependence on a centralized, high-bandwidth networking fabric. Our method trains a set of expert diffusion models over partitions of the dataset, each in full isolation from one another. At inference time, the experts ensemble through a lightweight router. We show that the ensemble collectively optimizes the same objective as a single model trained over the whole dataset. This means we can divide the training burden among a number of "compute islands," lowering infrastructure costs and improving resilience to localized GPU failures. Decentralized diffusion models empower researchers to take advantage of smaller, more cost-effective and more readily available compute like on-demand GPU nodes rather than central integrated systems. We conduct extensive experiments on ImageNet and LAION Aesthetics, showing that decentralized diffusion models FLOP-for-FLOP outperform standard diffusion models. We finally scale our approach to 24 billion parameters, demonstrating that high-quality diffusion models can now be trained with just eight individual GPU nodes in less than a week.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Calculating Customer Lifetime Value and Churn using Beta Geometric Negative Binomial and Gamma-Gamma Distribution in a NFT based setting</title>
<link>https://arxiv.org/abs/2501.04719</link>
<guid>https://arxiv.org/abs/2501.04719</guid>
<content:encoded><![CDATA[
<div> 关键词：Customer Lifetime Value (CLV)，Beta Geometric Negative Binomial Distribution (BGNBD)，Gamma Gamma Distribution，NFT，blockchain

<br /><br />总结:
本文介绍了两种用于计算客户终身价值（CLV）的模型——Beta Geometric Negative Binomial Distribution (BGNBD)和Gamma Gamma Distribution。这两个模型能够考虑到非fungible token（NFT）在区块链环境中的交易频率和价值。通过使用历史交易数据来估计这些模型的参数，企业可以了解其客户的终身价值，并据此制定基于数据驱动的营销和客户保留策略。 <div>
arXiv:2501.04719v1 Announce Type: cross 
Abstract: Customer Lifetime Value (CLV) is an important metric that measures the total value a customer will bring to a business over their lifetime. The Beta Geometric Negative Binomial Distribution (BGNBD) and Gamma Gamma Distribution are two models that can be used to calculate CLV, taking into account both the frequency and value of customer transactions. This article explains the BGNBD and Gamma Gamma Distribution models, and how they can be used to calculate CLV for NFT (Non-Fungible Token) transaction data in a blockchain setting. By estimating the parameters of these models using historical transaction data, businesses can gain insights into the lifetime value of their customers and make data-driven decisions about marketing and customer retention strategies.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Interplay between Social Welfare and Tractability of Equilibria</title>
<link>https://arxiv.org/abs/2310.16976</link>
<guid>https://arxiv.org/abs/2310.16976</guid>
<content:encoded><![CDATA[
<div> 关键词: 计算可解性、社会福利、纳什均衡、无遗憾学习算法、光滑性

总结:
本文探讨了计算可解性和社交福利（效率）在算法博弈论中的基本但通常正交的关系。通过引用Roughgarden的光滑性论证，文章表明当可以通过光滑性保证（近似）完全效率时，纳什均衡能够在一系列无遗憾学习算法下接近，从而实现快速和分散化的计算。在此基础上，研究者在大量玩家游戏（玩家数量 $n \gg 1$）中，利用光滑性极限条件下的充分效率特性，提出了新的收敛结果。文中框架统一了包括战略敏感度趋于零的游戏和双人零和游戏等不同类别问题中的均衡计算方法，并揭示了光滑性与优化文献中被广泛研究的Minty性质之间的直接但先前未被注意到的等价关系。最后，文章提出了一组无遗憾动态过程，该过程在保证收敛到粗相关均衡的同时，实现了对光滑性框架下的福利改进。这一成果是通过采用Piliouras等人最近提出的先知镜像下降算法实现的。<br /><br /> <div>
arXiv:2310.16976v2 Announce Type: replace 
Abstract: Computational tractability and social welfare (aka. efficiency) of equilibria are two fundamental but in general orthogonal considerations in algorithmic game theory. Nevertheless, we show that when (approximate) full efficiency can be guaranteed via a smoothness argument \`a la Roughgarden, Nash equilibria are approachable under a family of no-regret learning algorithms, thereby enabling fast and decentralized computation. We leverage this connection to obtain new convergence results in large games -- wherein the number of players $n \gg 1$ -- under the well-documented property of full efficiency via smoothness in the limit. Surprisingly, our framework unifies equilibrium computation in disparate classes of problems including games with vanishing strategic sensitivity and two-player zero-sum games, illuminating en route an immediate but overlooked equivalence between smoothness and a well-studied condition in the optimization literature known as the Minty property. Finally, we establish that a family of no-regret dynamics attains a welfare bound that improves over the smoothness framework while at the same time guaranteeing convergence to the set of coarse correlated equilibria. We show this by employing the clairvoyant mirror descent algortihm recently introduced by Piliouras et al.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach</title>
<link>https://arxiv.org/abs/2407.15879</link>
<guid>https://arxiv.org/abs/2407.15879</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、智能电网、入侵检测系统、Random Walk协议、Epidemic协议

<br /><br />总结:
随着智能电网领域对安全和隐私的关注度提升，对强大的入侵检测系统的需求日益增强。为解决隐私保护和分布式电力系统区域的数据所有权问题，联邦学习（Federated Learning，FL）作为一种隐私保护解决方案应运而生。然而，传统FL依赖中心化聚合器并存在模型更新传输过程中的隐私泄露风险。为此，本文提出了一种新颖的基于Random Walk和Epidemic两种 gossip 协议的去中心化联邦异常检测方案。研究发现，Random Walk协议在去中心化联邦学习环境中的表现优于Epidemic协议。通过使用公开的工业控制系统数据集进行实验验证，该框架展示了在保障数据机密性、降低通信延迟和应对“拖延者”影响的同时，实现了更优的攻击检测精度。此外，与常规FL相比，本方法在训练时间上缩短了约35%，充分体现了其在去中心化学习方法上的有效性和鲁棒性。 <div>
arXiv:2407.15879v2 Announce Type: replace 
Abstract: The increasing security and privacy concerns in the Smart Grid sector have led to a significant demand for robust intrusion detection systems within critical smart grid infrastructure. To address the challenges posed by privacy preservation and decentralized power system zones with distinct data ownership, Federated Learning (FL) has emerged as a promising privacy-preserving solution which facilitates collaborative training of attack detection models without necessitating the sharing of raw data. However, FL presents several implementation limitations in the power system domain due to its heavy reliance on a centralized aggregator and the risks of privacy leakage during model update transmission. To overcome these technical bottlenecks, this paper introduces a novel decentralized federated anomaly detection scheme based on two main gossip protocols namely Random Walk and Epidemic. Our findings indicate that the Random Walk protocol exhibits superior performance compared to the Epidemic protocol, highlighting its efficacy in decentralized federated learning environments. Experimental validation of the proposed framework utilizing publicly available industrial control systems datasets demonstrates superior attack detection accuracy while safeguarding data confidentiality and mitigating the impact of communication latency and stragglers. Furthermore, our approach yields a notable 35% improvement in training time compared to conventional FL, underscoring the efficacy and robustness of our decentralized learning method.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GNN-based Decentralized Perception in Multirobot Systems for Predicting Worker Actions</title>
<link>https://arxiv.org/abs/2501.04193</link>
<guid>https://arxiv.org/abs/2501.04193</guid>
<content:encoded><![CDATA[
<div> 关键词：移动机器人、人类行为预测、分布式感知框架、时空信息、共识机制

<br />
总结:
本文提出了一种使移动机器人能够以分布式方式理解和共享有关人类行为信息的感知框架。该框架允许每个机器人构建其周围环境的空间图，并与其他机器人共享。共享的Spatial数据结合时间信息用于跟踪人类行为随时间的变化。采用群体智能启发的决策过程确保所有机器人就人类行为的一致解释达成共识。实验结果显示，增加更多机器人和考虑更长的时间序列可以提高行为预测准确性。同时，共识机制增强了系统的鲁棒性，使得多机器人系统在动态工业环境中更加可靠。 <div>
arXiv:2501.04193v1 Announce Type: new 
Abstract: In industrial environments, predicting human actions is essential for ensuring safe and effective collaboration between humans and robots. This paper introduces a perception framework that enables mobile robots to understand and share information about human actions in a decentralized way. The framework first allows each robot to build a spatial graph representing its surroundings, which it then shares with other robots. This shared spatial data is combined with temporal information to track human behavior over time. A swarm-inspired decision-making process is used to ensure all robots agree on a unified interpretation of the human's actions. Results show that adding more robots and incorporating longer time sequences improve prediction accuracy. Additionally, the consensus mechanism increases system resilience, making the multi-robot setup more reliable in dynamic industrial settings.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HiCoCS: High Concurrency Cross-Sharding on Permissioned Blockchains</title>
<link>https://arxiv.org/abs/2501.04265</link>
<guid>https://arxiv.org/abs/2501.04265</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、分片、并发跨片交易、HiCoCS、Hyperledger Fabric

<br /><br />总结：
本文提出了一个名为HiCoCS的高并发跨片方案，用于解决许可型区块链（如Hyperledger Fabric）中并发跨片交易（CSTx）的冲突问题。HiCoCS通过引入复合键结构为每个CSTx创建独特的虚拟子代理，实现了冲突无关的并行交易处理，同时降低了资源开销。针对大量复合键管理和中介隐私风险，HiCoCS利用虚拟子代理并发接收和处理CSTx，并采用批量处理技术提高效率。为了降低系统开销和复用资源，文章探讨了复合键的重用策略，并使用同态加密技术增强了隐私保护。实验结果表明，与基线方案相比，HiCoCS能够将跨片交易吞吐量提升3.5-20.2倍。 <div>
arXiv:2501.04265v1 Announce Type: new 
Abstract: As the foundation of the Web3 trust system, blockchain technology faces increasing demands for scalability. Sharding emerges as a promising solution, but it struggles to handle highly concurrent cross-shard transactions (\textsf{CSTx}s), primarily due to simultaneous ledger operations on the same account. Hyperledger Fabric, a permissioned blockchain, employs multi-version concurrency control for parallel processing. Existing solutions use channels and intermediaries to achieve cross-sharding in Hyperledger Fabric. However, the conflict problem caused by highly concurrent \textsf{CSTx}s has not been adequately resolved. To fill this gap, we propose HiCoCS, a high concurrency cross-shard scheme for permissioned blockchains. HiCoCS creates a unique virtual sub-broker for each \textsf{CSTx} by introducing a composite key structure, enabling conflict-free concurrent transaction processing while reducing resource overhead. The challenge lies in managing large numbers of composite keys and mitigating intermediary privacy risks. HiCoCS utilizes virtual sub-brokers to receive and process \textsf{CSTx}s concurrently while maintaining a transaction pool. Batch processing is employed to merge multiple \textsf{CSTx}s in the pool, improving efficiency. We explore composite key reuse to reduce the number of virtual sub-brokers and lower system overhead. Privacy preservation is enhanced using homomorphic encryption. Evaluations show that HiCoCS improves cross-shard transaction throughput by 3.5-20.2 times compared to the baselines.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VerifBFL: Leveraging zk-SNARKs for A Verifiable Blockchained Federated Learning</title>
<link>https://arxiv.org/abs/2501.04319</link>
<guid>https://arxiv.org/abs/2501.04319</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、联邦学习、零知识证明、增量可验证计算、差分隐私

<br /><br />总结:
本文提出了一种名为VerifBFL的信任less、隐私保护和可验证的联邦学习框架，该框架结合了区块链技术和加密协议。VerifBFL利用零知识SNARKs和增量可验证计算（IVC）确保了本地训练和聚合过程的可验证性，通过在链上验证这些证明以保证每个参与者的贡献完整性和可审计性。为防止推理攻击，VerifBFL还采用了差分隐私技术来保护训练数据。此外，作者构建了一个概念验证系统，结果显示在VerifBFL中生成局部训练和聚合的证明分别耗时不到81秒和2秒，而链上验证这些证明则耗时不到0.6秒。 <div>
arXiv:2501.04319v1 Announce Type: new 
Abstract: Blockchain-based Federated Learning (FL) is an emerging decentralized machine learning paradigm that enables model training without relying on a central server. Although some BFL frameworks are considered privacy-preserving, they are still vulnerable to various attacks, including inference and model poisoning. Additionally, most of these solutions employ strong trust assumptions among all participating entities or introduce incentive mechanisms to encourage collaboration, making them susceptible to multiple security flaws. This work presents VerifBFL, a trustless, privacy-preserving, and verifiable federated learning framework that integrates blockchain technology and cryptographic protocols. By employing zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARKs) and incrementally verifiable computation (IVC), VerifBFL ensures the verifiability of both local training and aggregation processes. The proofs of training and aggregation are verified on-chain, guaranteeing the integrity and auditability of each participant's contributions. To protect training data from inference attacks, VerifBFL leverages differential privacy. Finally, to demonstrate the efficiency of the proposed protocols, we built a proof of concept using emerging tools. The results show that generating proofs for local training and aggregation in VerifBFL takes less than 81s and 2s, respectively, while verifying them on-chain takes less than 0.6s.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoDFL: A Scalable and Automated Reputation-Aware Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.04331</link>
<guid>https://arxiv.org/abs/2501.04331</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链联邦学习 (BFL), 可扩展性, 成本效益, zk-Rollups, 自动化声誉模型

<br /><br />总结:
本文提出了一个名为AutoDFL的新型框架，旨在解决区块链联邦学习(BFL)在可扩展性和成本效益方面的挑战，以及在声誉感知BFL中加剧的性能问题。AutoDFL利用zk-Rollups作为Layer-2扩容解决方案，以提高性能并保持与底层Layer-1区块链相同的安全水平。此外，AutoDFL引入了一个自动化和公正的声誉模型，旨在激励联邦学习参与者的行为。通过构建概念验证并进行不同自定义工作负载测试，AutoDFL实现了超过3000 TPS的平均吞吐量和高达20倍的 gas 减少，从而显著提高了BFL的效率、可扩展性并降低了声誉管理成本。 <div>
arXiv:2501.04331v1 Announce Type: new 
Abstract: Blockchained federated learning (BFL) combines the concepts of federated learning and blockchain technology to enhance privacy, security, and transparency in collaborative machine learning models. However, implementing BFL frameworks poses challenges in terms of scalability and cost-effectiveness. Reputation-aware BFL poses even more challenges, as blockchain validators are tasked with processing federated learning transactions along with the transactions that evaluate FL tasks and aggregate reputations. This leads to faster blockchain congestion and performance degradation. To improve BFL efficiency while increasing scalability and reducing on-chain reputation management costs, this paper proposes AutoDFL, a scalable and automated reputation-aware decentralized federated learning framework. AutoDFL leverages zk-Rollups as a Layer-2 scaling solution to boost the performance while maintaining the same level of security as the underlying Layer-1 blockchain. Moreover, AutoDFL introduces an automated and fair reputation model designed to incentivize federated learning actors. We develop a proof of concept for our framework for an accurate evaluation. Tested with various custom workloads, AutoDFL reaches an average throughput of over 3000 TPS with a gas reduction of up to 20X.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lossless Privacy-Preserving Aggregation for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.04409</link>
<guid>https://arxiv.org/abs/2501.04409</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、去中心化联邦学习、梯度泄露、噪声注入、LPPA<br /><br />总结: 随着敏感数据的增长，隐私问题日益凸显。尽管去中心化联邦学习(DFL)通过聚合邻居的梯度以避免直接传输数据，但仍存在间接的梯度泄露风险。现有的隐私保护方法通过对梯度添加噪声来解决此问题，但这可能导致模型预测精度降低或梯度保护不力。本文提出了一种新颖的无损隐私保护聚合规则——LPPA，旨在尽可能增强梯度保护的同时，保持DFL模型的预测精度不受影响。LPPA巧妙地将发送和接收到的噪声差值注入到传输的梯度中，利用邻居之间的随机性有效防止数据泄露。同时，LPPA运用噪声流守恒理论确保全局可以消除噪声影响，保证了准确的梯度聚合与模型精度不变。理论证明，LPPA的隐私保护能力比单纯的噪声添加高出√2倍，同时模型精度可与标准无噪声注入的DFL聚合相媲美。实验结果验证了理论发现，表明LPPA相比噪声添加方法能实现平均13%的精度提升，并展示了其在保护原始数据和保障模型精度方面的有效性。 <div>
arXiv:2501.04409v1 Announce Type: new 
Abstract: Privacy concerns arise as sensitive data proliferate. Despite decentralized federated learning (DFL) aggregating gradients from neighbors to avoid direct data transmission, it still poses indirect data leaks from the transmitted gradients. Existing privacy-preserving methods for DFL add noise to gradients. They either diminish the model predictive accuracy or suffer from ineffective gradient protection. In this paper, we propose a novel lossless privacy-preserving aggregation rule named LPPA to enhance gradient protection as much as possible but without loss of DFL model predictive accuracy. LPPA subtly injects the noise difference between the sent and received noise into transmitted gradients for gradient protection. The noise difference incorporates neighbors' randomness for each client, effectively safeguarding against data leaks. LPPA employs the noise flow conservation theory to ensure that the noise impact can be globally eliminated. The global sum of all noise differences remains zero, ensuring that accurate gradient aggregation is unaffected and the model accuracy remains intact. We theoretically prove that the privacy-preserving capacity of LPPA is \sqrt{2} times greater than that of noise addition, while maintaining comparable model accuracy to the standard DFL aggregation without noise injection. Experimental results verify the theoretical findings and show that LPPA achieves a 13% mean improvement in accuracy over noise addition. We also demonstrate the effectiveness of LPPA in protecting raw data and guaranteeing lossless model accuracy.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Research on environment perception and behavior prediction of intelligent UAV based on semantic communication</title>
<link>https://arxiv.org/abs/2501.04480</link>
<guid>https://arxiv.org/abs/2501.04480</guid>
<content:encoded><![CDATA[
<div> 关键词：无人机配送系统、虚拟世界、区块链、强化学习、语义通信框架、认证与密钥协商方案、元宇宙、资源分配、通信成本、信息安全、交易吞吐量

<br /><br />总结:
本文介绍了将无人机配送系统、虚拟世界和区块链技术融合对物流与供应链管理产生的变革，为传统地面运输提供更快、更环保的替代方案。首先，文章提出了应用强化学习方法，使无人机能快速训练并自主适应新的虚拟场景，实现有效的资源分配。其次，设计了一种语义通信框架用于元宇宙，通过提取语义信息来降低通信成本并激励信息服务传输。再者，为了保障用户信息安全，引入区块链技术设计了轻量级的无人机与用户之间的认证与密钥协商方案。实验结果显示，无人机的适应性性能提高了约35%，随着基站数量增加，本地卸载率可达90%。此外，文中提出的语义通信系统相较于交叉熵基线模型有明显优势，并且利用区块链技术保持了不同数量无人机情况下的交易吞吐量稳定。 <div>
arXiv:2501.04480v1 Announce Type: new 
Abstract: The convergence of drone delivery systems, virtual worlds, and blockchain has transformed logistics and supply chain management, providing a fast, and environmentally friendly alternative to traditional ground transportation methods;Provide users with a real-world experience, virtual service providers need to collect up-to-the-minute delivery information from edge devices. To address this challenge, 1) a reinforcement learning approach is introduced to enable drones with fast training capabilities and the ability to autonomously adapt to new virtual scenarios for effective resource allocation.2) A semantic communication framework for meta-universes is proposed, which utilizes the extraction of semantic information to reduce the communication cost and incentivize the transmission of information for meta-universe services.3) In order to ensure that user information security, a lightweight authentication and key agreement scheme is designed between the drone and the user by introducing blockchain technology. In our experiments, the drone adaptation performance is improved by about 35\%, and the local offloading rate can reach 90\% with the increase of the number of base stations. The semantic communication system proposed in this paper is compared with the Cross Entropy baseline model. Introducing blockchain technology the throughput of the transaction is maintained at a stable value with different number of drones.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Demystification and Near-perfect Estimation of Minimum Gas Limit and Gas Used for Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2501.04483</link>
<guid>https://arxiv.org/abs/2501.04483</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum区块链、gas系统、gas限制、最小gas限制、gas使用量

总结:

本文关注以太坊区块链的gas系统，探讨了其中的核心概念——gas限制和gas使用量。文章首次明确提出并区分了“最小gas限制”这一概念，指出它与交易实际消耗的gas使用量并不相同，并通过实证研究展示了二者的差异。此外，文中还提出了分别针对这两种指标的精确估算方法，由于当前多数估算器仅关注gas使用量。研究发现，对于以太坊区块链，在时间t的状态下确定的最小gas限制可以很好地预测在t+Δ（其中Δ≤11）区块上执行的交易所需的gas预算，同样适用于gas使用量的估计。这些精确的估计算法对于帮助用户预估交易gas预算以及开发者优化智能合约具有重要价值。总的来说，该论文为区块链开发者和用户提供了一个深入理解gas系统工作原理的重要参考。 <div>
arXiv:2501.04483v1 Announce Type: new 
Abstract: The Ethereum blockchain has a \emph{gas system} that associates operations with a cost in gas units. Two central concepts of this system are the \emph{gas limit} assigned by the issuer of a transaction and the \emph{gas used} by a transaction. The former is a budget that must not be exhausted before the completion of the transaction execution; otherwise, the execution fails. Therefore, it seems rather essential to determine the \emph{minimum gas limit} that ensures the execution of a transaction will not abort due to the lack of gas. Despite its practical relevance, this concept has not been properly addressed. In the literature, gas used and minimum gas limit are conflated. This paper proposes a precise notion of minimum gas limit and how it can differ from gas used by a transaction; this is also demonstrated with a quantitative study on real transactions of the Ethereum blockchain. Another significant contribution is the proposition of a fairly precise estimator for each of the two metrics. Again, the confusion between these concepts has led to the creation of estimators only for the gas used by a transaction. We demonstrate that the minimum gas limit for the state of the Ethereum blockchain (after the block) $t$ can serve as a near-perfect estimation for the execution of the transaction at block $t + \Delta$, where $\Delta \leq 11$; the same holds for estimating gas used. These precise estimators can be very valuable in helping the users predict the gas budget of transactions and developers in optimising their smart contracts; over and underestimating gas used and minimum gas limit can lead to a number of practical issues. Overall, this paper serves as an important reference for blockchain developers and users as to how the gas system really works.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multichannel Steganography: A Provably Secure Hybrid Steganographic Model for Secure Communication</title>
<link>https://arxiv.org/abs/2501.04511</link>
<guid>https://arxiv.org/abs/2501.04511</guid>
<content:encoded><![CDATA[
<div> 关键词: steganographic模型, 覆盖修改, 覆盖合成, 通信协议, 安全分析

总结:<br />
本文提出了一种结合封面修改(CMO)和封面合成(CSY)的创新隐写术模型，通过生成封面消息或参数来增强安全性和不可检测性，同时保持原始封面的形式，降低了检测风险并克服了单一方法技术的局限性。基于此模型，作者进一步设计了一个强化的隐写术通信协议，增强了对多通道重播攻击和多通道中间人攻击的抵抗能力，提升了协议防篡改的能力。为了评估新协议的安全性，文章开发了一个模拟概率多项式时间(PPT)敌手的新型对抗模型，用于评估对手破坏协议的能力，提供了全面的安全分析。此外，该研究还探讨了该模型在受限环境如短信银行和资源丰富环境如区块链交易中的实用性和适应性，展示了其提升金融服务与安全性方面的潜力。这些贡献共同构成了一套坚固且适应性强的隐写术安全通信框架，为不同环境下的安全通信提供切实可行的解决方案。 <div>
arXiv:2501.04511v1 Announce Type: new 
Abstract: This study introduces a novel steganographic model that synthesizes Steganography by Cover Modification (CMO) and Steganography by Cover Synthesis (CSY), enhancing both security and undetectability by generating cover messages or parameters while retaining the original cover's form, thus minimizing detection risks and overcoming the limitations of single-method techniques. Building upon this model, a refined Steganographic Communication Protocol is proposed, enhancing resilience against sophisticated threats such as Multichannel Replay Attacks and Multichannel Man-in-the-Middle Attacks, fortifying the protocol against potential tampering and improving upon prior works. To evaluate the security of the proposed protocol, a novel adversarial model is developed simulating a probabilistic polynomial time (PPT) adversary capable of intercepting communications across multiple channels. This model assesses the adversary's ability to compromise the protocol, providing a comprehensive security analysis. Finally, this study explores the practicality and adaptability of the model to both constrained environments like SMS banking and resource-rich settings such as blockchain transactions, demonstrating their potential to enhance financial services and security. These contributions present a robust and adaptable framework for secure steganographic communication, offering practical solutions for secure communications across diverse environments.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Data Notarization Leveraging Hybrid DLTs</title>
<link>https://arxiv.org/abs/2501.04571</link>
<guid>https://arxiv.org/abs/2501.04571</guid>
<content:encoded><![CDATA[
<div> 关键词: 不动产登记, 区块链, 可扩展性, 数据管理, 混合区块链架构

总结:
本文探讨了不动产登记在数据管理中的重要性，通过确保数据在审计过程中的认证来增强信任。文章指出，区块链作为一种安全、不可变、透明的存储方式，已广泛用于提升基于区块链的数据不动产登记协议的效果和可信度。然而，现有的实现方案无论是在公共区块链还是私有区块链上都面临挑战：公共区块链上的高费用和私有平台的信任问题限制了区块链在不动产登记中的应用或迫使做出许多妥协。为此，论文研究了混合区块链架构在数据不动产登记中的应用，重点关注可扩展性问题。通过对实际案例——供应链中产品护照的数据不动产登记进行分析，提出了利用一种能够有效平衡存储占用和大规模数据公证成本的数据结构的新型方法。 <div>
arXiv:2501.04571v1 Announce Type: new 
Abstract: Notarization is a procedure that enhance data management by ensuring the authentication of data during audits, thereby increasing trust in the audited data. Blockchain is frequently used as a secure, immutable, and transparent storage, contributing to make data notarization procedures more effective and trustable. Several blockchain-based data notarization protocols have been proposed in literature and commercial solutions. However, these implementations, whether on public or private blockchains, face inherent challenges: high fees on public blockchains and trust issues on private platforms, limiting the adoption of blockchains for data notarization or forcing several trade-offs. In this paper, we explore the use of hybrid blockchain architectures for data notarization, with a focus on scalability issues. Through the analysis of a real-world use case, the data notarization of product passports in supply chains, we propose a novel approach utilizing a data structure designed to efficiently manage the trade-offs in terms of storage occupation and costs involved in notarizing a large collection of data.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Do Automated Fixes Truly Mitigate Smart Contract Exploits?</title>
<link>https://arxiv.org/abs/2501.04600</link>
<guid>https://arxiv.org/abs/2501.04600</guid>
<content:encoded><![CDATA[
<div> 关键词：Automated Program Repair (APR)，智能合约安全，漏洞修复，实验框架，exploit mitigation rate

总结:
这篇论文探讨了利用自动化程序修复(APR)技术增强智能合约安全性并自动修复导致巨额财务损失的安全漏洞的有效性。文章提出了一种新的、系统的实验框架，用于评估针对智能合约的修复工具在防止漏洞利用方面的效果。通过对涵盖143份易受攻击的智能合约和手动构造的91个可执行漏洞的数据集进行定性和定量分析，研究首次定义并测量了关键的“漏洞利用缓解率”，为研究人员和实践者提供了对前沿技术实际效果的真实认识。结果显示，现有技术之间存在显著差距，漏洞利用缓解率从最低的27%到最高的73%，这一结果与原始论文中的描述大相径庭。此外，该研究还识别出了未来智能合约程序修复领域需要解决的系统性局限，如功能一致性保持问题。 <div>
arXiv:2501.04600v1 Announce Type: new 
Abstract: Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential "exploit mitigation rate", giving researchers and practitioners and real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 27% to a high of 73%, a result that nobody would guess from reading the original papers. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>gECC: A GPU-based high-throughput framework for Elliptic Curve Cryptography</title>
<link>https://arxiv.org/abs/2501.03245</link>
<guid>https://arxiv.org/abs/2501.03245</guid>
<content:encoded><![CDATA[
<div> 关键词：椭圆曲线密码学（ECC）、GPU优化、gECC框架、高性能、并行计算

总结:
本文介绍了针对GPU架构优化的高吞吐量椭圆曲线加密算法框架gECC。gECC通过批量执行椭圆曲线操作和微架构层面的模数运算优化，利用Montgomery's trick实现批量EC计算，并采用创新的并行计算与内存管理技术，最大限度提高并行计算效率并降低GPU全局内存访问开销。通过对模乘运算瓶颈的分析，发现其效率高度依赖于Integer Multiply-Add (IMAD)指令的数量。为解决这一问题，文章提出了利用判定点寄存器传递进位信息以及使用加减法指令(IADD3)替代IMAD指令的技术。实验结果显示，相较于现有最先进的GPU基线系统，gECC在ECDSA和ECDH上的性能分别提高了5.56倍和4.94倍；在实际区块链应用中，相比于最先进的CPU基线系统，实现了1.56倍的性能提升。 <div>
arXiv:2501.03245v1 Announce Type: new 
Abstract: Elliptic Curve Cryptography (ECC) is an encryption method that provides security comparable to traditional techniques like Rivest-Shamir-Adleman (RSA) but with lower computational complexity and smaller key sizes, making it a competitive option for applications such as blockchain, secure multi-party computation, and database security. However, the throughput of ECC is still hindered by the significant performance overhead associated with elliptic curve (EC) operations. This paper presents gECC, a versatile framework for ECC optimized for GPU architectures, specifically engineered to achieve high-throughput performance in EC operations. gECC incorporates batch-based execution of EC operations and microarchitecture-level optimization of modular arithmetic. It employs Montgomery's trick to enable batch EC computation and incorporates novel computation parallelization and memory management techniques to maximize the computation parallelism and minimize the access overhead of GPU global memory. Also, we analyze the primary bottleneck in modular multiplication by investigating how the user codes of modular multiplication are compiled into hardware instructions and what these instructions' issuance rates are. We identify that the efficiency of modular multiplication is highly dependent on the number of Integer Multiply-Add (IMAD) instructions. To eliminate this bottleneck, we propose techniques to minimize the number of IMAD instructions by leveraging predicate registers to pass the carry information and using addition and subtraction instructions (IADD3) to replace IMAD instructions. Our results show that, for ECDSA and ECDH, gECC can achieve performance improvements of 5.56x and 4.94x, respectively, compared to the state-of-the-art GPU-based system. In a real-world blockchain application, we can achieve performance improvements of 1.56x, compared to the state-of-the-art CPU-based system.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FTA-FTL: A Fine-Tuned Aggregation Federated Transfer Learning Scheme for Lithology Microscopic Image Classification</title>
<link>https://arxiv.org/abs/2501.03349</link>
<guid>https://arxiv.org/abs/2501.03349</guid>
<content:encoded><![CDATA[
<div> 关键词：Lithology discrimination，Deep Learning，Transfer learning，Federated Learning，Fine-Tuned Aggregation

<br /><br />总结：
本文主要研究了石油储层岩性识别中的关键问题——岩石显微图像分类。首先，利用迁移学习方法对小规模数据集进行了岩石显微图像分类，比较了多种预训练的深度学习模型架构的效果。随后，文章提出了将分类任务转化为联邦迁移学习（FTL）框架下的细调聚合策略（FTA-FTL）。实验结果表明，该FTA-FTL算法能够在保护敏感数据和增强安全性的同时，实现与集中式实施相当的岩石显微图像分类性能，证实了所提方案的有效性。 <div>
arXiv:2501.03349v1 Announce Type: new 
Abstract: Lithology discrimination is a crucial activity in characterizing oil reservoirs, and processing lithology microscopic images is an essential technique for investigating fossils and minerals and geological assessment of shale oil exploration. In this way, Deep Learning (DL) technique is a powerful approach for building robust classifier models. However, there is still a considerable challenge to collect and produce a large dataset. Transfer-learning and data augmentation techniques have emerged as popular approaches to tackle this problem. Furthermore, due to different reasons, especially data privacy, individuals, organizations, and industry companies often are not willing to share their sensitive data and information. Federated Learning (FL) has emerged to train a highly accurate central model across multiple decentralized edge servers without transferring sensitive data, preserving sensitive data, and enhancing security. This study involves two phases; the first phase is to conduct Lithology microscopic image classification on a small dataset using transfer learning. In doing so, various pre-trained DL model architectures are comprehensively compared for the classification task. In the second phase, we formulated the classification task to a Federated Transfer Learning (FTL) scheme and proposed a Fine-Tuned Aggregation strategy for Federated Learning (FTA-FTL). In order to perform a comprehensive experimental study, several metrics such as accuracy, f1 score, precision, specificity, sensitivity (recall), and confusion matrix are taken into account. The results are in excellent agreement and confirm the efficiency of the proposed scheme, and show that the proposed FTA-FTL algorithm is capable enough to achieve approximately the same results obtained by the centralized implementation for Lithology microscopic images classification task.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Smart Contracts for Permissioned Blockchains: A zk-SNARK-Based Recipe Part-1</title>
<link>https://arxiv.org/abs/2501.03391</link>
<guid>https://arxiv.org/abs/2501.03391</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、隐私保护、zk-SNARKs、委托交易

<br /><br />总结:
本文提出了利用zk-SNARKs技术来实现区块链和智能合约中隐私保护的新方案。该方案不仅支持可替代和不可替代令牌的隐私交易，还引入了一种新的交易类型——委托交易，使得如Delivery vs Payment（DvP）等使用场景得以实现。与现有解决方案相比，该方法旨在克服功能限制、高计算时间和对第三方信任的需求等问题，以实现更全面的去中心化。 <div>
arXiv:2501.03391v1 Announce Type: new 
Abstract: The Bitcoin white paper introduced blockchain technology, enabling trustful transactions without intermediaries. Smart contracts emerged with Ethereum and blockchains expanded beyond cryptocurrency, applying to auctions, crowdfunding and electronic voting. However, blockchain's transparency raised privacy concerns and initial anonymity measures proved ineffective. Smart contract privacy solutions employed zero-knowledge proofs, homomorphic encryption and trusted execution environments. These approaches have practical drawbacks, such as limited functionality, high computation times and trust on third parties requirements, being not fully decentralized. This work proposes a solution utilizing zk-SNARKs to provide privacy in smart contracts and blockchains. The solution supports both fungible and nonfungible tokens. Additionally, the proposal includes a new type of transactions, called delegated transactions, which enable use cases like Delivery vs Payment (DvP).
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: A Review of Cross-Chain Bridge Hacks in 2023</title>
<link>https://arxiv.org/abs/2501.03423</link>
<guid>https://arxiv.org/abs/2501.03423</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、跨链桥、攻击、安全漏洞、防御措施

<br /><br />总结:
本文分析了2022年和2023年近期针对跨链桥的黑客攻击事件，这些攻击导致了大量的财务损失，特别是Axie Infinity Ronin Bridge遭受了近6亿美元的巨额损失。文章重点研究了被利用的安全漏洞，旨在通过了解攻击的本质和潜在弱点来加强桥梁安全性，并提出可能的应对措施。通过解决近期跨链桥攻击中暴露的脆弱性与缺陷，将有助于建立行业通行的桥梁安全标准，增强对跨链互操作性的信任和信心。 <div>
arXiv:2501.03423v1 Announce Type: new 
Abstract: Blockchain technology has revolutionized industries by enabling secure and decentralized transactions. However, the isolated nature of blockchain ecosystems hinders the seamless transfer of digital assets across different chains. Cross-chain bridges have emerged as vital web3 infrastructure to address this challenge by facilitating interoperability between distinct blockchains. Cross-chain bridges remain vulnerable to various attacks despite sophisticated designs and security measures. The industry has experienced a surge in bridge attacks, resulting in significant financial losses. The largest hack impacted Axie Infinity Ronin Bridge, with a loss of almost \$600 million USD. This paper analyzes recent cross-chain bridge hacks in 2022 and 2023 and examines the exploited vulnerabilities. By understanding the attack nature and underlying weaknesses, the paper aims to enhance bridge security and propose potential countermeasures. The findings contribute to developing industry-wide standards for bridge security and operational resilience. Addressing the vulnerabilities and weaknesses exploited in recent cross-chain bridge hacks fosters trust and confidence in cross-chain interoperability.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Authentication and Granularized Authorization with a Cross-Domain Zero Trust Architecture for Federated Learning in Large-Scale IoT Networks</title>
<link>https://arxiv.org/abs/2501.03601</link>
<guid>https://arxiv.org/abs/2501.03601</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网(IoT)、零信任架构(ZTA)、跨域认证授权、去中心化联邦学习(DFL)、数据隐私

总结:<br />
针对物联网系统中日益增长的安全需求，本文提出了一种结合零信任架构(ZTA)与去中心化联邦学习(DFL)的动态认证和细粒度授权方案，应用于跨域IoT网络。该方案通过持续监控和评估设备请求，仅授予必要的访问权限，以提高安全性并减少效率问题。为了保护用户数据隐私和降低延迟，文中将DFL集成到ZTA中，实现设备数据在不同领域的安全高效共享。同时，提出了模型压缩方法来减轻网络传输负载，并设计了一个动态自适应权重调整机制，使DFL模型能更好地适应来自不同域的数据特性。通过对提出的方案进行安全性分析（包括机密性、完整性和可用性）以及模拟实验，结果表明该方案在降低延迟和提升吞吐量方面相较于其他现有方案具有更优表现。 <div>
arXiv:2501.03601v1 Announce Type: new 
Abstract: With the increasing number of connected devices and complex networks involved, current domain-specific security techniques become inadequate for diverse large-scale Internet of Things (IoT) systems applications. While cross-domain authentication and authorization brings lots of security improvement, it creates new challenges of efficiency and security. Zero trust architecture (ZTA), an emerging network security architecture, offers a more granular and robust security environment for IoT systems. However, extensive cross-domain data exchange in ZTA can cause reduced authentication and authorization efficiency and data privacy concerns. Therefore, in this paper, we propose a dynamic authentication and granularized authorization scheme based on ZTA integrated with decentralized federated learning (DFL) for cross-domain IoT networks. Specifically, device requests in the cross-domain process are continuously monitored and evaluated, and only necessary access permissions are granted. To protect user data privacy and reduce latency, we integrate DFL with ZTA to securely and efficiently share device data across different domains. Particularly, the DFL model is compressed to reduce the network transmission load. Meanwhile, a dynamic adaptive weight adjustment mechanism is proposed to enable the DFL model to adapt to data characteristics from different domains. We analyze the performance of the proposed scheme in terms of security proof, including confidentiality, integrity and availability. Simulation results demonstrate the superior performance of the proposed scheme in terms of lower latency and higher throughput compared to other existing representative schemes.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unraveling Responsiveness of Chained BFT Consensus with Network Delay</title>
<link>https://arxiv.org/abs/2501.03695</link>
<guid>https://arxiv.org/abs/2501.03695</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、chained BFT协议、Markov决策过程(MDP)、性能评估、攻击策略

总结:<br />
本文针对区块链技术中广泛应用的chained Byzantine Fault Tolerant (BFT)协议，提出了一种使用Markov决策过程(MDP)构建的统一框架，用于模型化和评估三种主流chained BFT协议的性能。该框架能够捕捉复杂的敌对行为，并关注两个关键性能指标：链增长和承诺率。通过在现有评价平台上实施由MDP分析得出的最优攻击策略并进行大量实验，验证了理论结果。研究发现，与普遍观点相反，响应速度虽能提升性能，但并非在所有场景下都具有益处。这项工作不仅深化了我们对chained BFT协议的理解，也为设计更健壮和高效的协议提供了有价值的见解和分析工具。 <div>
arXiv:2501.03695v1 Announce Type: new 
Abstract: With the advancement of blockchain technology, chained Byzantine Fault Tolerant (BFT) protocols have been increasingly adopted in practical systems, making their performance a crucial aspect of the study. In this paper, we introduce a unified framework utilizing Markov Decision Processes (MDP) to model and assess the performance of three prominent chained BFT protocols. Our framework effectively captures complex adversarial behaviors, focusing on two key performance metrics: chain growth and commitment rate. We implement the optimal attack strategies obtained from MDP analysis on an existing evaluation platform for chained BFT protocols and conduct extensive experiments under various settings to validate our theoretical results. Through rigorous theoretical analysis and thorough practical experiments, we provide an in-depth evaluation of chained BFT protocols under diverse attack scenarios, uncovering optimal attack strategies. Contrary to conventional belief, our findings reveal that while responsiveness can enhance performance, it is not universally beneficial across all scenarios. This work not only deepens our understanding of chained BFT protocols, but also offers valuable insights and analytical tools that can inform the design of more robust and efficient protocols.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fast Transaction Scheduling in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2405.15015</link>
<guid>https://arxiv.org/abs/2405.15015</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链分片、并行处理、集中式调度器、分布式调度器、交易调度算法

总结:<br />
本文研究了区块链分片技术中针对物联网、边缘计算和移动计算场景下的交易批量调度问题。文章首先提出一种中心化的调度器，其中选取一个 Shard 作为领导者负责接收与确定交易处理的调度方案，该方案对于任意最大距离为 d 的交易及其访问对象给出了 O(kd) 的近似最优解。接着，文章提供了一种适用于线图或随机选择对象情况下的改进型集中式调度器。随后，文章提出了一个分布式调度器，通过层次聚类的方式实现各个 Shard 不需要全局交易信息即可进行调度，其竞争比达到 O(A_{CS} * log d * log s)，其中 A_{CS} 是集中式调度器的近似比。据作者所知，这是首次为区块链分片系统提供具有理论保证的快速交易调度算法。最后，文章通过仿真对比展示了所提调度器相较于锁基方法可显著降低延迟（最高达 3 倍）并提高吞吐量（最高可达 2 倍）。 <div>
arXiv:2405.15015v2 Announce Type: replace 
Abstract: Sharding is a promising technique for addressing the scalability issues of blockchain, and this technique is especially important for IoT, edge, or mobile computing. It divides the $n$ participating nodes into $s$ disjoint groups called shards, where each shard processes transactions in parallel. We examine batch scheduling problems on the shard graph $G_s$, where we find efficient schedules for a set of transactions. First, we present a centralized scheduler where one of the shards is considered as a leader, who receives the transaction information from all of the other shards and determines the schedule to process the transactions. For general graphs, where a transaction and its accessing objects are arbitrarily far from each other with a maximum distance $d$, the centralized scheduler provides $O(kd)$ approximation to the optimal schedule, where $k$ is the maximum number of shards each transaction accesses. Next, we provide a centralized scheduler with a bucketing approach that offers improved bounds for the case where $G_s$ is a line graph, or the $k$ objects are randomly selected. Finally, we provide a distributed scheduler where shards do not require global transaction information. We achieve this by using a hierarchical clustering of the shards and using the centralized scheduler in each cluster. We show that the distributed scheduler has a competitive ratio of $O(A_{CS} \cdot \log d \cdot \log s)$, where $A_{CS}$ is the approximation ratio of the centralized scheduler. To our knowledge, we are the first to give provably fast transaction scheduling algorithms for blockchain sharding systems. We also present simulation results for our schedulers and compare their performance with a lock-based approach. The results show that our schedulers are generally better with up to 3x lower latency and 2x higher throughput.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection</title>
<link>https://arxiv.org/abs/2501.02032</link>
<guid>https://arxiv.org/abs/2501.02032</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、欺诈检测、结构信息、语义特征

总结:<br />
本文提出了一种针对区块链欺诈检测的动态特征融合模型。该模型结合了图表示学习和语义特征提取，旨在同时捕获交易网络中的全局结构模式和交易数据中的局部语义关系。通过构建全球账户关系图以及从交易数据中提取局部上下文特征，利用动态多模态融合机制自适应地整合这些特征。此外，文中还开发了一个全面的数据处理管道，包括图构造、时间特征增强和文本预处理。实验证明，这种方法在大规模真实世界的区块链数据集上，在准确性、F1分数和召回率等指标上均优于现有基准。这一工作强调了集成结构关系和语义相似性对于实现稳健的欺诈检测的重要性，并为保护区块链系统提供了一种可扩展的解决方案。 <div>
arXiv:2501.02032v1 Announce Type: new 
Abstract: The advent of blockchain technology has facilitated the widespread adoption of smart contracts in the financial sector. However, current fraud detection methodologies exhibit limitations in capturing both global structural patterns within transaction networks and local semantic relationships embedded in transaction data. Most existing models focus on either structural information or semantic features individually, leading to suboptimal performance in detecting complex fraud patterns.In this paper, we propose a dynamic feature fusion model that combines graph-based representation learning and semantic feature extraction for blockchain fraud detection. Specifically, we construct global graph representations to model account relationships and extract local contextual features from transaction data. A dynamic multimodal fusion mechanism is introduced to adaptively integrate these features, enabling the model to capture both structural and semantic fraud patterns effectively. We further develop a comprehensive data processing pipeline, including graph construction, temporal feature enhancement, and text preprocessing. Experimental results on large-scale real-world blockchain datasets demonstrate that our method outperforms existing benchmarks across accuracy, F1 score, and recall metrics. This work highlights the importance of integrating structural relationships and semantic similarities for robust fraud detection and offers a scalable solution for securing blockchain systems.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Detection of Water Contamination Under Concept Drift</title>
<link>https://arxiv.org/abs/2501.02107</link>
<guid>https://arxiv.org/abs/2501.02107</guid>
<content:encoded><![CDATA[
<div> 关键词: 水分布网络(WDNs), 氯气监测, 双重阈值异常与漂移检测(AD&amp;DD), 长短期记忆网络(LSTM-VAE), 分布式架构

总结:
本文介绍了一种新的无监督方法——双阈值异常与漂移检测(AD&amp;DD)，该方法结合了双重阈值漂移检测机制和基于LSTM的变分自编码器(LSTM-VAE)，用于水分布网络(WDNs)中的实时污染检测。研究中，AD&amp;DD方法在两个实际的WDNs上进行了测试，能有效地识别传感器偏移导致的概念漂移异常，并优于其他方法。此外，文中还提出了一种分布式架构，通过在选定节点部署AD&amp;DD，实现精确的污染检测与定位。 <div>
arXiv:2501.02107v1 Announce Type: new 
Abstract: Water Distribution Networks (WDNs) are vital infrastructures, and contamination poses serious public health risks. Harmful substances can interact with disinfectants like chlorine, making chlorine monitoring essential for detecting contaminants. However, chlorine sensors often become unreliable and require frequent calibration. This study introduces the Dual-Threshold Anomaly and Drift Detection (AD&amp;DD) method, an unsupervised approach combining a dual-threshold drift detection mechanism with an LSTM-based Variational Autoencoder(LSTM-VAE) for real-time contamination detection. Tested on two realistic WDNs, AD&amp;DD effectively identifies anomalies with sensor offsets as concept drift, and outperforms other methods. A proposed decentralized architecture enables accurate contamination detection and localization by deploying AD&amp;DD on selected nodes.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A hybrid marketplace of ideas</title>
<link>https://arxiv.org/abs/2501.02132</link>
<guid>https://arxiv.org/abs/2501.02132</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能系统、文化动态、Web3、观念市场、机器文化

总结:<br />
本文探讨了人工智能系统与人类融合对文化和知识领域产生的新动态，特别是AI代理在Web3这一关注去中心化的区块链社区中的重要技术社会学发展。文章指出，AI代理在公共话语中的参与和影响力挑战了传统认知，并在观念市场上与人类生成的思想共存并竞争注意力，构成了一个混合型观念市场。文章从 memetics 的视角分析AI作为文化代理的角色，并强调进一步研究其对文化和社会的影响的重要性。此外，文中还讨论了这一新范式对于隐私权、知识产权以及治理所带来的社会法律挑战。 <div>
arXiv:2501.02132v1 Announce Type: new 
Abstract: The convergence of humans and artificial intelligence systems introduces new dynamics into the cultural and intellectual landscape. Complementing emerging cultural evolution concepts such as machine culture, AI agents represent a significant technosociological development, particularly within the anthropological study of Web3 as a community focused on decentralization through blockchain. Despite their growing presence, the cultural significance of AI agents remains largely unexplored in academic literature. We argue that, within the context of Web3, these agents challenge traditional notions of participation and influence in public discourse, creating a hybrid marketplace of ideas, a conceptual space where human and AI generated ideas coexist and compete for attention. We examine the current state of AI agents in idea generation, propagation, and engagement, positioning their role as cultural agents through the lens of memetics and encouraging further inquiry into their cultural and societal impact. Additionally, we address the implications of this paradigm for privacy, intellectual property, and governance, highlighting the societal and legal challenges of integrating AI agents into the hybrid marketplace of ideas.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems</title>
<link>https://arxiv.org/abs/2501.02169</link>
<guid>https://arxiv.org/abs/2501.02169</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、AI、医疗数据、安全、健康管理

总结:<br />
随着美国医疗领域数据泄露事件在2022年增长125%，高达1820万份患者记录受到影响，医疗数据的安全与有效管理愈发重要。为应对大数据挑战，许多医疗机构采用AI和区块链技术。AI提升了基于数据的操作及大数据效率，被广泛应用于医疗服务中以降低成本并提升服务质量。而区块链则有助于保护信息共享过程中的交易安全与个人隐私。本文自2008年以来研究了区块链整合AI与医疗系统的独特贡献，关注包括机器学习、深度学习和聚类学习在内的AI应用以及不同类型的区块链架构。通过这些技术的应用，可以在确保患者数据安全的同时，实现医疗信息的有效管理，为医疗机构和患者带来显著优势。其中，从2018年至2021年间，2021年的相关研究与发展最为突出，表现在下载量和谷歌学术引用数的增长上，同时近期的研究专家也对此进行了文章筛选和大型研究基金评审的工作。 <div>
arXiv:2501.02169v1 Announce Type: new 
Abstract: Verisign reported a 125 percent increase in data breaches within the healthcare sector in the United States during 2022, with 18.2 million patient records being impacted. Growing healthcare data volumes and diversification mean that medical information is becoming more valuable. Many Health Centers use various technologies to ease the classification, storage, and exchange of big data. This use can also make the health data of the users at risk and vulnerable. AI and blockchain are among the leading technologies at hand. With AI, data-driven operations and big data efficiency have been improved with respect to traditional techniques. Due to its potential to bring about improvements in health services and lower medical costs, this AI technology is regularly used in healthcare. Blockchain helps protect transactions on sharing information and private privacy as long as the exchange of knowledge is that of the standard. The objective of this analysis is to investigate the research and unique contributions since 2008 regarding blockchain-integrated AI and healthcare systems. The work sheds light on applied AI-based healthcare schemes with machine, ballistic, and acrylic learning and disparate blockchain structures. The use of technology in order to ensure patient data security and manage medical information effectively in healthcare settings offers a highly successful position for both healthcare providers and patients. From 2018 to 2021, the best year was 2021 to grow, enhancing everything to examine the download of the device and the counting of Google Academies, for which the joining perspective was borrowed; local research experts were asked, identified articles in recent years, and read reviews of large research grants.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Large Language Models and Machine Learning for Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2501.02229</link>
<guid>https://arxiv.org/abs/2501.02229</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、机器学习、大型语言模型、安全性

总结:
随着区块链技术和智能合约的广泛应用，确保其在整个交易过程中的安全性至关重要。本文探讨了利用经典机器学习模型和微调过的大型语言模型（LLM）来查找并检测智能合约漏洞的安全增强方法。研究基于一个包含注释有漏洞标签的智能合约数据集，训练和测试多种LLMs及传统机器学习算法，如DistilBERT模型，以实现对智能合约代码按漏洞类型进行分类。实验结果显示，经过微调的LLM在识别诸如重入攻击、整数溢出、时间戳依赖和危险的Delegatecall等知名漏洞方面的准确性超过90%，显著提升了现有漏洞检测基准。对比分析了各种机器学习和LLM模型的优势，为实际应用中选择最有效的智能合约安全方案提供了参考。通过结合机器学习与大型语言模型，本文构建了一个丰富且可解释的框架，用于检测不同类型的智能合约漏洞，从而为构建更安全的区块链生态系统奠定了基础。 <div>
arXiv:2501.02229v1 Announce Type: new 
Abstract: As blockchain technology and smart contracts become widely adopted, securing them throughout every stage of the transaction process is essential. The concern of improved security for smart contracts is to find and detect vulnerabilities using classical Machine Learning (ML) models and fine-tuned Large Language Models (LLM). The robustness of such work rests on a labeled smart contract dataset that includes annotated vulnerabilities on which several LLMs alongside various traditional machine learning algorithms such as DistilBERT model is trained and tested. We train and test machine learning algorithms to classify smart contract codes according to vulnerability types in order to compare model performance. Having fine-tuned the LLMs specifically for smart contract code classification should help in getting better results when detecting several types of well-known vulnerabilities, such as Reentrancy, Integer Overflow, Timestamp Dependency and Dangerous Delegatecall. From our initial experimental results, it can be seen that our fine-tuned LLM surpasses the accuracy of any other model by achieving an accuracy of over 90%, and this advances the existing vulnerability detection benchmarks. Such performance provides a great deal of evidence for LLMs ability to describe the subtle patterns in the code that traditional ML models could miss. Thus, we compared each of the ML and LLM models to give a good overview of each models strengths, from which we can choose the most effective one for real-world applications in smart contract security. Our research combines machine learning and large language models to provide a rich and interpretable framework for detecting different smart contract vulnerabilities, which lays a foundation for a more secure blockchain ecosystem.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Convergence of Blockchain Technology and Islamic Economics: Decentralized Solutions for Shariah-Compliant Finance</title>
<link>https://arxiv.org/abs/2501.02263</link>
<guid>https://arxiv.org/abs/2501.02263</guid>
<content:encoded><![CDATA[
<div> 关键词: 金融革命、加密货币、区块链技术、伊斯兰经济学、全球经济景观

<br /><br />总结:
本文概述了当前正在进行的金融革命，这场革命不仅仅涉及数字货币作为一种数字支付手段的出现。其核心驱动力在于区块链技术的革新以及伊斯兰经济学的基本原则相结合，共同构成对传统金融体系的挑战，强调透明度、公正性和去中心化治理。文章指出了这一转变带来的影响及其重塑全球经济格局的潜力。 <div>
arXiv:2501.02263v1 Announce Type: new 
Abstract: This paper provides a brief overview of the ongoing financial revolution, which extends beyond the emergence of cryptocurrencies as a digital medium of exchange. At its core, this revolution is driven by a paradigm shift rooted in the technological advancements of blockchain and the foundational principles of Islamic economics. Together, these elements offer a transformative framework that challenges traditional financial systems, emphasizing transparency, equity, and decentralized governance. The paper highlights the implications of this shift and its potential to reshape the global economic landscape.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Workplace Productivity and Well-being Using AI Agent</title>
<link>https://arxiv.org/abs/2501.02368</link>
<guid>https://arxiv.org/abs/2501.02368</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI), 工作场所生产力, 员工福利, 机器学习(ML), 生物反馈<br /><br />总结:<br />
本文探讨了如何运用人工智能(AI)提高职场生产力和员工福祉。通过将机器学习(ML)技术与神经生物学数据相结合，提出的方案利用价值对齐模型和层次强化学习(HRL)确保自主任务管理符合人类伦理标准。系统借助员工的生物反馈生成个性化的健康提示，营造鼓励身体活动的支持性工作环境。此外，文章还研究了用于提升协作效率和决策透明度的去中心化多智能体系统。文中讨论了多种结合ML技术和AI应用的方法，这些创新旨在创造一个更为高效且注重健康的职场环境，并有助于人力资源管理和组织推出更合理的员工职业发展路径，促进组织转型。 <div>
arXiv:2501.02368v1 Announce Type: new 
Abstract: This paper discusses the use of Artificial Intelligence (AI) to enhance workplace productivity and employee well-being. By integrating machine learning (ML) techniques with neurobiological data, the proposed approaches ensure alignment with human ethical standards through value alignment models and Hierarchical Reinforcement Learning (HRL) for autonomous task management. The system utilizes biometric feedback from employees to generate personalized health prompts, fostering a supportive work environment that encourages physical activity. Additionally, we explore decentralized multi-agent systems for improved collaboration and decision-making frameworks that enhance transparency. Various approaches using ML techniques in conjunction with AI implementations are discussed. Together, these innovations aim to create a more productive and health-conscious workplace. These outcomes assist HR management and organizations in launching more rational career progression streams for employees and facilitating organizational transformation.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trust and Dependability in Blockchain &amp; AI Based MedIoT Applications: Research Challenges and Future Directions</title>
<link>https://arxiv.org/abs/2501.02647</link>
<guid>https://arxiv.org/abs/2501.02647</guid>
<content:encoded><![CDATA[
<div> 关键词: AI, 区块链技术, 医疗物联网(MedIoT), 数据安全, 患者隐私

<br /><br />总结:
本文详细评述了人工智能(AI)与区块链技术在医疗物联网(MedIoT)应用中的融合，指出二者结合有望彻底改革医疗服务。文章强调了AI在提升诊断和患者护理方面的潜力，以及区块链在增强数据安全和保护患者隐私方面的作用。重点讨论了建立信任和确保系统可靠性的重要性。作者分析了当前针对健康数据管理和应对可扩展性、隐私保护以及MedIoT领域内伦理实践等挑战的创新解决方案，并提出将AI驱动的洞察力与区块链安全性相结合在医疗领域的未来愿景。同时，文中总结了现有研究的空白，并认为填补这些空白对于实现可靠、安全且以患者为中心的未来MedIoT应用至关重要。 <div>
arXiv:2501.02647v1 Announce Type: new 
Abstract: This paper critically reviews the integration of Artificial Intelligence (AI) and blockchain technologies in the context of Medical Internet of Things (MedIoT) applications, where they collectively promise to revolutionize healthcare delivery. By examining current research, we underscore AI's potential in advancing diagnostics and patient care, alongside blockchain's capacity to bolster data security and patient privacy. We focus particularly on the imperative to cultivate trust and ensure reliability within these systems. Our review highlights innovative solutions for managing healthcare data and challenges such as ensuring scalability, maintaining privacy, and promoting ethical practices within the MedIoT domain. We present a vision for integrating AI-driven insights with blockchain security in healthcare, offering a comprehensive review of current research and future directions. We conclude with a set of identified research gaps and propose that addressing these is crucial for achieving the dependable, secure, and patient -centric MedIoT applications of tomorrow.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Incentive-Compatible Federated Learning with Stackelberg Game Modeling</title>
<link>https://arxiv.org/abs/2501.02662</link>
<guid>https://arxiv.org/abs/2501.02662</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、heterogeneous environments（异构环境）、unfairness（不公平性）、Stackelberg game（Stackelberg博弈）、FLamma

<br /><br />总结:
本文提出了一种名为FLamma的新颖联邦学习框架，旨在解决在异构环境中联邦学习面临的挑战，特别是不公平性和非IID数据设置下的系统效率问题。FLamma基于自适应gamma-based Stackelberg游戏理论，其中服务器作为领导者动态调整衰减因子，而客户端则作为跟随者，优化其本地轮数以最大化自身效用。随着时间推移，服务器逐渐平衡客户端的影响，初期奖励贡献较大的客户端并逐步平息其影响，引导系统趋向Stackelberg均衡。通过在IID和非IID数据集上的大量模拟实验表明，FLamma方法显著提高了准确性分布的公平性，同时并未牺牲整体模型性能或收敛速度，优于传统联邦学习基线方法。 <div>
arXiv:2501.02662v1 Announce Type: new 
Abstract: Federated Learning (FL) has gained prominence as a decentralized machine learning paradigm, allowing clients to collaboratively train a global model while preserving data privacy. Despite its potential, FL faces significant challenges in heterogeneous environments, where varying client resources and capabilities can undermine overall system performance. Existing approaches primarily focus on maximizing global model accuracy, often at the expense of unfairness among clients and suboptimal system efficiency, particularly in non-IID (non-Independent and Identically Distributed) settings. In this paper, we introduce FLamma, a novel Federated Learning framework based on adaptive gamma-based Stackelberg game, designed to address the aforementioned limitations and promote fairness. Our approach allows the server to act as the leader, dynamically adjusting a decay factor while clients, acting as followers, optimally select their number of local epochs to maximize their utility. Over time, the server incrementally balances client influence, initially rewarding higher-contributing clients and gradually leveling their impact, driving the system toward a Stackelberg Equilibrium. Extensive simulations on both IID and non-IID datasets show that our method significantly improves fairness in accuracy distribution without compromising overall model performance or convergence speed, outperforming traditional FL baselines.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Markov Decision Processes for Satellite Maneuver Planning and Collision Avoidance</title>
<link>https://arxiv.org/abs/2501.02667</link>
<guid>https://arxiv.org/abs/2501.02667</guid>
<content:encoded><![CDATA[
<div> 关键词: 卫星编队、分散式在线规划、可扩展性、马尔科夫决策过程(MDP)、低地球轨道碰撞规避

总结:
本文提出了一种针对大型卫星编队的分散式、在线规划方法，旨在实现可扩展的机动规划。文章指出现有的基于规则的分散策略虽有利于效率提升，但关于卫星机动的最优决策算法仍有待深入研究。随着商业卫星星座规模扩大，利用实时轨迹预测改进状态认知以降低机动频率和节省燃料的在线机动规划变得愈发重要。为此，论文将卫星机动规划问题建模为马尔科夫决策过程(MDP)，使系统能在线生成具有较低计算成本的最优机动策略。该方法应用于解决低地球轨道中的非合作物体碰撞规避问题，通过在模拟低地球轨道环境中测试生成的策略并与传统的基于规则的碰撞规避技术进行比较，显示出其优势。 <div>
arXiv:2501.02667v1 Announce Type: new 
Abstract: This paper presents a decentralized, online planning approach for scalable maneuver planning for large constellations. While decentralized, rule-based strategies have facilitated efficient scaling, optimal decision-making algorithms for satellite maneuvers remain underexplored. As commercial satellite constellations grow, there are benefits of online maneuver planning, such as using real-time trajectory predictions to improve state knowledge, thereby reducing maneuver frequency and conserving fuel. We address this gap in the research by treating the satellite maneuver planning problem as a Markov decision process (MDP). This approach enables the generation of optimal maneuver policies online with low computational cost. This formulation is applied to the low Earth orbit collision avoidance problem, considering the problem of an active spacecraft deciding to maneuver to avoid a non-maneuverable object. We test the policies we generate in a simulated low Earth orbit environment, and compare the results to traditional rule-based collision avoidance techniques.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leader Rotation Is Not Enough: Scrutinizing Leadership Democracy of Chained BFT Consensus</title>
<link>https://arxiv.org/abs/2501.02970</link>
<guid>https://arxiv.org/abs/2501.02970</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、串联BFT协议、领导权民主、攻击分析、投票模式、领导者轮换、马克夫决策过程(MDP)、协议改进、未来方向

总结:<br />
本文针对区块链技术中串联BFT协议日益增长的关注度，深入研究了四种代表性串联BFT协议的领导权民主性，尤其是在受到攻击时的情况。文中提出了一种统一评估框架，包括两个评价指标：链质量与审查抵抗能力，并通过马克夫决策过程(MDP)对所选协议进行定量分析。该框架还揭示了投票模式和领导者轮换这两个关键组件对领导权民主的影响。研究发现，仅靠领导者轮换不足以保证领导权民主，攻击者可以利用设计（如投票模式）显著削弱领导权民主性。基于这些分析结果，文章为所评估的三个协议提出了针对性的改进措施，能够在不改变共识规则的前提下，以轻微的协议开销提升其领导权民主性。最后，文章讨论了构建更加民主的串联BFT协议的未来发展方向。 <div>
arXiv:2501.02970v1 Announce Type: new 
Abstract: With the growing popularity of blockchains, modern chained BFT protocols combining chaining and leader rotation to obtain better efficiency and leadership democracy have received increasing interest. Although the efficiency provisions of chained BFT protocols have been thoroughly analyzed, the leadership democracy has received little attention in prior work. In this paper, we scrutinize the leadership democracy of four representative chained BFT protocols, especially under attack. To this end, we propose a unified framework with two evaluation metrics, i.e., chain quality and censorship resilience, and quantitatively analyze chosen protocols through the Markov Decision Process (MDP). With this framework, we further examine the impact of two key components, i.e., voting pattern and leader rotation on leadership democracy. Our results indicate that leader rotation is not enough to provide the leadership democracy guarantee; an adversary could utilize the design, e.g., voting pattern, to deteriorate the leadership democracy significantly. Based on the analysis results, we propose customized countermeasures for three evaluated protocols to improve their leadership democracy with only slight protocol overhead and no change of consensus rules. We also discuss future directions toward building more democratic chained BFT protocols.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proof-of-Data: A Consensus Protocol for Collaborative Intelligence</title>
<link>https://arxiv.org/abs/2501.02971</link>
<guid>https://arxiv.org/abs/2501.02971</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式联邦学习、区块链、拜占庭容错、Proof-of-Data (PoD) 共识协议、奖励分配

总结:
<br />
本文提出了一种基于区块链的分布式拜占庭容错联邦学习框架，该框架利用一种新颖的Proof-of-Data (PoD) 共识协议解决“信任”和“激励”两大问题。PoD通过将模型训练与贡献度核算解耦，既实现了异步大规模PoW风格学习的效率和系统活力，又保证了基于epoch的BFT风格投票的共识最终性和奖励分配的确定性。针对拜占庭攻击下的数据伪造和虚假奖励申领问题，文中设计了一个隐私感知的数据验证和贡献为基础的奖励分配机制来完善框架。实验结果表明，PoD在保持接近集中式联邦学习模型训练性能的同时，实现了共识的信任性和奖励分配的公平性，其故障容忍比率为1/3。 <div>
arXiv:2501.02971v1 Announce Type: new 
Abstract: Existing research on federated learning has been focused on the setting where learning is coordinated by a centralized entity. Yet the greatest potential of future collaborative intelligence would be unleashed in a more open and democratized setting with no central entity in a dominant role, referred to as "decentralized federated learning". New challenges arise accordingly in achieving both correct model training and fair reward allocation with collective effort among all participating nodes, especially with the threat of the Byzantine node jeopardising both tasks.
  In this paper, we propose a blockchain-based decentralized Byzantine fault-tolerant federated learning framework based on a novel Proof-of-Data (PoD) consensus protocol to resolve both the "trust" and "incentive" components. By decoupling model training and contribution accounting, PoD is able to enjoy not only the benefit of learning efficiency and system liveliness from asynchronous societal-scale PoW-style learning but also the finality of consensus and reward allocation from epoch-based BFT-style voting. To mitigate false reward claims by data forgery from Byzantine attacks, a privacy-aware data verification and contribution-based reward allocation mechanism is designed to complete the framework. Our evaluation results show that PoD demonstrates performance in model training close to that of the centralized counterpart while achieving trust in consensus and fairness for reward allocation with a fault tolerance ratio of 1/3.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.03119</link>
<guid>https://arxiv.org/abs/2501.03119</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Decentralized FL, Topology Inference Attack, Privacy Preservation, Model Behavior

总结:
<br />
该研究关注Federated Learning（FL）中的Decentralized FL（DFL），其模型共享机制虽能保护隐私，但模型训练仍可能泄露敏感信息。研究提出了一个新颖的Topology Inference Attack，探讨仅依据模型行为来推断DFL系统overlay拓扑结构的可能性。文章制定了基于攻击者能力和知识的拓扑推理攻击分类，并针对不同场景开发了实际攻击策略。通过定量实验，结果表明仅分析单个节点的公共模型就能准确推断DFL的拓扑结构，揭示了DFL系统中存在敏感信息泄漏的风险。这一发现对于改进去中心化学习环境中的隐私保护具有重要意义。 <div>
arXiv:2501.03119v1 Announce Type: new 
Abstract: Federated Learning (FL) is widely recognized as a privacy-preserving machine learning paradigm due to its model-sharing mechanism that avoids direct data exchange. However, model training inevitably leaves exploitable traces that can be used to infer sensitive information. In Decentralized FL (DFL), the overlay topology significantly influences its models' convergence, robustness, and security. This study explores the feasibility of inferring the overlay topology of DFL systems based solely on model behavior, introducing a novel Topology Inference Attack. A taxonomy of topology inference attacks is proposed, categorizing them by the attacker's capabilities and knowledge. Practical attack strategies are developed for different scenarios, and quantitative experiments are conducted to identify key factors influencing the attack effectiveness. Experimental results demonstrate that analyzing only the public models of individual nodes can accurately infer the DFL topology, underscoring the risk of sensitive information leakage in DFL systems. This finding offers valuable insights for improving privacy preservation in decentralized learning environments.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CrowdProve: Community Proving for ZK Rollups</title>
<link>https://arxiv.org/abs/2501.03126</link>
<guid>https://arxiv.org/abs/2501.03126</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-Knowledge (ZK) rollups、CrowdProve、proving、commodity hardware、decentralization

总结:
本文提出了一种名为CrowdProve的新方案，用于解决零知识证明（ZK rollups）系统中的计算负担问题。CrowdProve是一个证明者协调层，可将计算任务外包给由广泛社区内的小型证明者运行的不可靠商品硬件。该方案应用于一种流行的ZK rollup，实验结果显示，社区证明可以实现与现有中心化部署相当甚至更好的性能。即使使用适度的硬件配置，也能匹配中心化解决方案的性能，使得基于社区的证明生成成为一种可行且成本效益高的替代方案。通过CrowdProve，Rollup运营商能够借助社区闲置硬件降低基础设施成本，而社区证明者则因其贡献获得补偿，从而实现了双方共赢并增强了系统的去中心化特性。 <div>
arXiv:2501.03126v1 Announce Type: new 
Abstract: Zero-Knowledge (ZK) rollups have become a popular solution for scaling blockchain systems, offering improved transaction throughput and reduced costs by aggregating Layer 2 transactions and submitting them as a single batch to a Layer 1 blockchain. However, the computational burden of generating validity proofs, a key feature of ZK rollups, presents significant challenges in terms of performance and decentralization. Current solutions rely on centralized infrastructure to handle the computational tasks, limiting the scalability and decentralization of rollup systems.
  This paper proposes CrowdProve, a prover orchestration layer for outsourcing computation to unreliable commodity hardware run by a broad community of small provers. We apply CrowdProve to proving transaction batches for a popular ZK rollup.
  Through our experimental evaluation, we demonstrate that community proving can achieve performance comparable to, and in some cases better than, existing centralized deployments. Our results show that even systems utilizing modest hardware configurations can match the performance of centralized solutions, making community-based proof generation a viable and cost-effective alternative. CrowdProve allows both the rollup operator and community participants to benefit: the operator reduces infrastructure costs by leveraging idle community hardware, while community provers are compensated for their contributions.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Foundations of Platform-Assisted Auctions</title>
<link>https://arxiv.org/abs/2501.03141</link>
<guid>https://arxiv.org/abs/2501.03141</guid>
<content:encoded><![CDATA[
<div> 关键词：平台辅助拍卖、加密货币、梦之拍卖、战略行为、效率优化

总结:<br />
本文提出了一个新的模型来研究无许可环境下的平台辅助拍卖。该模型关注在平台可能操纵拍卖以增加利润的情况下，设计一种能够让买家、平台、卖家以及平台与卖家或买家联盟均能通过诚实行为实现利益最大化的理想拍卖机制。文章通过一系列可行性与不可行性结果刻画了平台辅助拍卖的数学特性，并展示了如何利用密码学原理设计具有高效和理想属性的平台辅助拍卖协议。相较于已有的使用多方计算（MPC）或区块链技术去除对可信拍卖者依赖的工作，本文的研究有其独特之处：首先，系统性探讨了服务提供者存在策略行为并可能与买卖方合谋的游戏理论影响；其次，指出全模拟范式过于严格导致高渐近成本问题，为此，文章提出了一种新的模拟概念——效用主导仿真，并在此基础上展示如何设计具有接近线性效率的高效拍卖协议。 <div>
arXiv:2501.03141v1 Announce Type: new 
Abstract: Today, many auctions are carried out with the help of intermediary platforms like Google and eBay. We refer to such auctions as platform-assisted auctions.Traditionally, the auction theory literature mainly focuses on designing auctions that incentivize the buyers to bid truthfully,assuming that the platform always faithfully implements the auction. In practice, however, the platforms have been found to manipulate the auctions to earn more profit, resulting in high-profile anti-trust lawsuits. We propose a new model for studying platform-assisted auctions in the permissionless setting. We explore whether it is possible to design a dream auction in thisnew model, such that honest behavior is the utility-maximizing strategy for each individual buyer, the platform, the seller, as well as platform-seller or platform-buyer coalitions.Through a collection of feasibility and infeasibility results,we carefully characterize the mathematical landscape of platform-assisted auctions. We show how cryptography can lend to the design of an efficient platform-assisted auction with dream properties. Although a line of works have also used MPC or the blockchain to remove the reliance on a trusted auctioneer, our work is distinct in nature in several dimensions.First, we initiate a systematic exploration of the game theoretic implications when the service providers are strategic and can collude with sellers or buyers. Second, we observe that the full simulation paradigm is too stringent and leads to high asymptotical costs. Specifically, because every player has a different private outcomein an auction protocol, running any generic MPC protocol among the players would incur at least $n^2$ total cost. We propose a new notion of simulation calledutility-dominated emulation.Under this new notion, we showhow to design efficient auction protocols with quasilinear efficiency.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep-Relative-Trust-Based Diffusion for Decentralized Deep Learning</title>
<link>https://arxiv.org/abs/2501.03162</link>
<guid>https://arxiv.org/abs/2501.03162</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式学习、参数空间一致性、深度神经网络、相对信任(DRT)、DRT扩散算法<br /><br />总结:

本文介绍了arXiv:2501.03162v1的新研究，提出了一种新的分布式学习策略——DRT扩散算法。该算法针对深度神经网络（通常过度参数化）的特点，主张在输出层面而非参数层面上鼓励共识，以此替代当前依赖参数平均化的分布式学习方法。文章基于一种名为深度相对信任(DRT)的新型相似度衡量标准来构建这一算法，并对其收敛性进行了分析。实验结果表明，DRT扩散算法在图像分类任务中能有效提升泛化性能，特别是在稀疏拓扑结构下表现优异。 <div>
arXiv:2501.03162v1 Announce Type: new 
Abstract: Decentralized learning strategies allow a collection of agents to learn efficiently from local data sets without the need for central aggregation or orchestration. Current decentralized learning paradigms typically rely on an averaging mechanism to encourage agreement in the parameter space. We argue that in the context of deep neural networks, which are often over-parameterized, encouraging consensus of the neural network outputs, as opposed to their parameters can be more appropriate. This motivates the development of a new decentralized learning algorithm, termed DRT diffusion, based on deep relative trust (DRT), a recently introduced similarity measure for neural networks. We provide convergence analysis for the proposed strategy, and numerically establish its benefit to generalization, especially with sparse topologies, in an image classification task.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rate-My-LoRA: Efficient and Adaptive Federated Model Tuning for Cardiac MRI Segmentation</title>
<link>https://arxiv.org/abs/2501.03223</link>
<guid>https://arxiv.org/abs/2501.03223</guid>
<content:encoded><![CDATA[
<div> 关键词: 心血管疾病, 心脏同步失调, 分布式学习, 低秩适应, 模型聚合

总结:
本文针对心血管疾病和心脏同步失调问题，提出了一个新的高效自适应联邦学习方法用于心脏图像分割。该方法旨在解决数据隐私、带宽限制和数据异质性带来的挑战。文章提出利用低秩适应（LoRA）来正则化模型权重更新，从而降低通信开销。同时，文中还创新性地设计了一种名为\mymethod{}的模型聚合技术，通过比较每个客户端的验证准确率来自适应地惩罚不同客户端的聚合权重，以实现更好的泛化性能和快速的局部适应。在公共心脏MRI数据集上的内外部评估结果显示，相较于其他基于LoRA的联邦学习方法，本文的方法具有显著优势。 <div>
arXiv:2501.03223v1 Announce Type: new 
Abstract: Cardiovascular disease (CVD) and cardiac dyssynchrony are major public health problems in the United States. Precise cardiac image segmentation is crucial for extracting quantitative measures that help categorize cardiac dyssynchrony. However, achieving high accuracy often depends on centralizing large datasets from different hospitals, which can be challenging due to privacy concerns. To solve this problem, Federated Learning (FL) is proposed to enable decentralized model training on such data without exchanging sensitive information. However, bandwidth limitations and data heterogeneity remain as significant challenges in conventional FL algorithms. In this paper, we propose a novel efficient and adaptive federate learning method for cardiac segmentation that improves model performance while reducing the bandwidth requirement. Our method leverages the low-rank adaptation (LoRA) to regularize model weight update and reduce communication overhead. We also propose a \mymethod{} aggregation technique to address data heterogeneity among clients. This technique adaptively penalizes the aggregated weights from different clients by comparing the validation accuracy in each client, allowing better generalization performance and fast local adaptation. In-client and cross-client evaluations on public cardiac MR datasets demonstrate the superiority of our method over other LoRA-based federate learning approaches.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>When Should Selfish Miners Double-Spend?</title>
<link>https://arxiv.org/abs/2501.03227</link>
<guid>https://arxiv.org/abs/2501.03227</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、双花攻击、自私挖矿、顽固挖矿、最优策略

总结:
本文研究了一种结合顽固挖矿和自私挖矿的新型攻击策略，分析了攻击者在不同参数条件下的最优顽固程度。文章指出，当攻击者的顽固程度高于某个确认规则值（如比特币中的6确认规则）时，会出现无成本的双花风险。文中还建立了每轮攻击中，给定顽固程度下双花风险的概率模型，并探讨了在诚实挖矿收益更低的情况下，实施这种攻击所需的最小双花价值。此外，为了提高双花概率并隐藏攻击行为，文章对顽固阶段的攻击进行了改进。最后，针对比特币系统，通过计算不同矿池参数下的最优和最大顽固程度及攻击收益，评估了该攻击策略对于6确认规则的实际影响与双花风险。 <div>
arXiv:2501.03227v1 Announce Type: new 
Abstract: Although, both double-spending and selfish-mining attacks have been extensively studied since the ``Bitcoin'' whitepaper of Nakamoto and the ``majority is not enough'' paper of Eyal and Sirer, there has been no rigorous stochastic analysis of an attack that combines the two, except for the complicated MDP models. In this paper, we first combine stubborn and selfish mining attacks, i.e., construct a strategy where the attacker acts stubborn until its private branch reaches a certain length and then switches to act selfish. We provide the optimal stubbornness for each parameter regime. Next, we provide the maximum stubbornness that is still more profitable than honest mining and argue a connection between the level of stubbornness and the $k$-confirmation rule. We show that, at each attack cycle, if the level of stubbornness is higher than $k$, there is a risk of double-spending which comes at no-cost to the adversary. The result can be seen as a guide for picking $k$ in the $k$-confirmation rule in a blockchain design. At each cycle, for a given stubbornness level, we rigorously formulate how great the risk of double-spending is. We provide the minimum double-spend value needed for an attack to be profitable in the regimes where the scheme is less profitable than honest mining. We further modify the attack in the stubborn regime in order to conceal the attack and increase the double-spending probability. Finally, we evaluate the results and provide the optimal and the maximum stubbornness levels for each parameter regime as well as the revenue. As a case study, with Bitcoin's $k=6$ block confirmation rule, we evaluate the revenue and double-spending risk of the attacks for each pool parameter.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Red Belly Blockchain: Enhanced Transaction Management for Decentralized Applications</title>
<link>https://arxiv.org/abs/2207.05971</link>
<guid>https://arxiv.org/abs/2207.05971</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Applications (DApps), Web3.0, Ethereum, High-performance blockchains, Transaction management

总结:
本文探讨了去中心化应用（DApps）在推动Web3.0发展中所起的作用，以及以太坊等支持DApp的区块链在性能上的局限性。针对此问题，文章提出了一种新颖的交易验证减少方法和基于子区块处理的优化块存储方案，以改进交易管理。实验表明，该研究团队开发的搭载了这些优化措施的智能红腹区块链（Smart Red Belly Blockchain, SRBB）虚拟机在性能上有所提升。接着，他们将SRBB VM与已有的高性能共识机制相结合，构建出了Smart Red Belly Blockchain。结果显示，SRBB在由分布于五大洲的200个节点组成的网络中达到了峰值4000TPS和平均2000TPS的吞吐量，并在运行基于纳斯达克真实工作负载轨迹的交易所DApp场景下，超越了其他6条区块链的表现。 <div>
arXiv:2207.05971v2 Announce Type: replace 
Abstract: Decentralized Applications (DApps) have seen widespread use in the recent past driving the world towards a new decentralized version of the web known as Web3.0. DApp-supported blockchains like Ethereum have largely been responsible for this drive supporting the largest eco-system of DApps. Although the low performance provided by Ethereum has been a major impediment to realizing a decentralized web, several high-performance blockchains have been introduced recently to bridge this gap. Most of these blockchains rely on consensus optimizations. Only a few enhance other parts of the blockchain protocol that involves transaction management: the validation of transactions, broadcast of transactions, encapsulation and dissemination of blocks with transactions, re-validation and execution of transactions in blocks, storage of blocks, and confirmation of transaction commits to senders upon request.
  In this paper, we enhance transaction management by introducing a novel transaction validation reduction and a per sub-block processing to optimize the block storage. We empirically show the performance improvements gained by our enhanced transaction management in the Smart Red Belly Blockchain (SRBB) VM we develop. Finally, we integrate our SRBB VM to an already optimized consensus from a known blockchain to develop the Smart Red Belly Blockchain. Our results show that SRBB achieves a peak throughput of 4000 TPS and an average throughput of 2000 TPS on 200 nodes spread across 5 continents. SRBB outperforms 6 other blockchains when running the exchange DApp featuring a real workload trace taken from Nasdaq.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Targeted Nakamoto: A Bitcoin Protocol to Balance Network Security and Energy Consumption</title>
<link>https://arxiv.org/abs/2405.15089</link>
<guid>https://arxiv.org/abs/2405.15089</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof-of-Work、比特币、挖矿算力、总成本、Targeted Nakamoto

总结:
<br />
本文探讨了Proof-of-Work机制下如比特币区块链中挖矿算力与区块奖励之间的关系。随着挖矿算力上升，网络安全成本降低但碳排放和电力消耗等外部性成本增加，存在一个挖矿算率区间使得总成本最小化。为了应对这一问题，文章提出了Targeted Nakamoto协议增强方案，该方案激励矿工将算力控制在一个目标区间。当算力超过目标值时，对矿工的区块奖励设置上限；而当算力低于目标值时，则设置奖励下限。为了维持货币中立性，协议会相应调整持有UTXO地址的支出潜力，以匹配奖励上限时的总额度扣除，以及奖励下限时的总额度增加。 <div>
arXiv:2405.15089v2 Announce Type: replace 
Abstract: In a Proof-of-Work blockchain such as Bitcoin mining hashrate is increasing in the block reward. An increase in hashrate reduces network vulnerability to attack (a reduction in security cost) while increasing carbon emissions and electricity cost (an increase in externalities cost). This implies a tradeoff in total cost at different levels of hashrate and the existence of a hashrate interval where total cost is minimized. Targeted Nakamoto is a Proof-of-Work protocol augmentation that incentivizes miners to hone in on a target hashrate interval. When hashrate is above target a ceiling is placed on the block reward a miner can receive. When hashrate is below target a floor is placed underneath the miner's block reward. Monetary neutrality is maintained by a proportional increase in spending potential among addresses holding UTXO's to match a deduction from total block reward when the ceiling is operative and a proportional reduction in spending potential among addresses holding UTXO's to match an increase over the total block reward when the floor is binding.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks</title>
<link>https://arxiv.org/abs/2401.08610</link>
<guid>https://arxiv.org/abs/2401.08610</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof of Stake (PoS)，Lido，stETH，Leverage Staking，风险分析

总结:
本文介绍了以太坊权益证明（PoS）生态系统中，用户通过Lido质押ETH获取代表质押ETH并累积staking奖励的Liquid Staking Derivative（LSD）——stETH。这种衍生品提升了质押资产的流动性，使得它们能够在二级市场如Aave的抵押借款或Curve上的资产交换等场景中使用。文章建立了一个关于利用stETH进行杠杆质押的正式框架，并发现了在过去963天内在以太坊上存在的442个此类头寸，涉及总价值537,123 ETH（约8.77亿美元）。数据分析表明，81.7%的杠杆质押头寸获得了超过常规在Lido质押的年化收益率（APR）。然而，高回报也伴随着潜在风险，如Terra崩盘事件所示，代币贬值可能对市场产生影响。因此，文章进行了极端情况下stETH大幅贬值的压力测试，评估了相关的风险。模拟结果显示，杠杆质押会放大连锁清算的风险，通过清算和去杠杆化过程加剧卖压，不仅加速stETH价格下跌，还会引发传染效应，威胁到杠杆头寸及普通头寸的稳定性。 <div>
arXiv:2401.08610v4 Announce Type: replace-cross 
Abstract: In the Proof of Stake (PoS) Ethereum ecosystem, users can stake ETH on Lido to receive stETH, a Liquid Staking Derivative (LSD) that represents staked ETH and accrues staking rewards. LSDs improve the liquidity of staked assets by facilitating their use in secondary markets, such as for collateralized borrowing on Aave or asset exchanges on Curve. The composability of Lido, Aave, and Curve enables an emerging strategy known as leverage staking, an iterative process that enhances financial returns while introducing potential risks. This paper establishes a formal framework for leverage staking with stETH and identifies 442 such positions on Ethereum over 963 days. These positions represent a total volume of 537,123 ETH (877m USD). Our data reveal that 81.7% of leverage staking positions achieved an Annual Percentage Rate (APR) higher than conventional staking on Lido. Despite the high returns, we also recognize the potential risks. For example, the Terra crash incident demonstrated that token devaluation can impact the market. Therefore, we conduct stress tests under extreme conditions of significant stETH devaluation to evaluate the associated risks. Our simulations reveal that leverage staking amplifies the risk of cascading liquidations by triggering intensified selling pressure through liquidation and deleveraging processes. Furthermore, this dynamic not only accelerates the decline of stETH prices but also propagates a contagion effect, endangering the stability of both leveraged and ordinary positions.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Uncertainty-Aware Label Refinement on Hypergraphs for Personalized Federated Facial Expression Recognition</title>
<link>https://arxiv.org/abs/2501.01816</link>
<guid>https://arxiv.org/abs/2501.01816</guid>
<content:encoded><![CDATA[
<div> 关键词：面部表情识别、个性化联邦学习、不确定性估计、标签细化、超图模型

总结:
本文研究了在考虑隐私保护的个性化联邦学习框架下的面部表情识别（FER）问题。为解决这一问题，文章提出了一种新颖的不确定性感知标签细化的超图方法——AMY。该方法中，每个本地模型由一个主干网络、一个不确定性估计（UE）模块和一个表情分类（EC）模块组成。在UE模块，利用超图来建模表达式样本间的复杂高阶关系，并将这些关系融入到不确定性特征中。接着，设计了一个个性化不确定性估算器，用于对本地客户端中的样本进行可靠的不确定性权重估计。在EC模块，通过超图上的标签传播获取高质量细化标签，进而重新训练表情分类器。由此，AMY有效地缓解了不同客户端间异质性样本的不确定性，并在每个客户端中学习到了鲁棒的个性化FER模型。实验结果表明，AMY在两个具有挑战性的实际面部表情数据库上表现优于多个现有最优方法，证实了超图模型在不确定性估计和标签细化方面的优势。相关源代码将在https://github.com/mobei1006/AMY 发布。 <div>
arXiv:2501.01816v1 Announce Type: new 
Abstract: Most facial expression recognition (FER) models are trained on large-scale expression data with centralized learning. Unfortunately, collecting a large amount of centralized expression data is difficult in practice due to privacy concerns of facial images. In this paper, we investigate FER under the framework of personalized federated learning, which is a valuable and practical decentralized setting for real-world applications. To this end, we develop a novel uncertainty-Aware label refineMent on hYpergraphs (AMY) method. For local training, each local model consists of a backbone, an uncertainty estimation (UE) block, and an expression classification (EC) block. In the UE block, we leverage a hypergraph to model complex high-order relationships between expression samples and incorporate these relationships into uncertainty features. A personalized uncertainty estimator is then introduced to estimate reliable uncertainty weights of samples in the local client. In the EC block, we perform label propagation on the hypergraph, obtaining high-quality refined labels for retraining an expression classifier. Based on the above, we effectively alleviate heterogeneous sample uncertainty across clients and learn a robust personalized FER model in each client. Experimental results on two challenging real-world facial expression databases show that our proposed method consistently outperforms several state-of-the-art methods. This indicates the superiority of hypergraph modeling for uncertainty estimation and label refinement on the personalized federated FER task. The source code will be released at https://github.com/mobei1006/AMY.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mingling with the Good to Backdoor Federated Learning</title>
<link>https://arxiv.org/abs/2501.01913</link>
<guid>https://arxiv.org/abs/2501.01913</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、防御机制、攻击方法、MIGO、后门植入

<br /><br />总结:
本文探讨了一种针对联邦学习的新型攻击策略——MIGO，该策略旨在设计一种通用的后门植入方法，能够在多种防御机制下仍能悄无声息地将后门融入全局模型。MIGO通过使恶意模型更新与合法更新难以区分，实现对全球模型的逐步后门注入，并保证其持久性。实验结果显示，MIGO在五个不同数据集和模型架构上成功植入了三种类型的后门，同时保持了主任务的高准确率（超过90%）。此外，MIGO展现了强大的防御规避能力，对抗了包括多个最先进的防御方法在内的十种防御手段。与其他四种攻击策略相比，MIGO在大多数配置中表现出色，即使在极端情况下，仅控制了0.1%的客户端，只要攻击者能在足够多的轮次中持续攻击，也能实现成功的后门插入。 <div>
arXiv:2501.01913v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized machine learning technique that allows multiple entities to jointly train a model while preserving dataset privacy. However, its distributed nature has raised various security concerns, which have been addressed by increasingly sophisticated defenses. These protections utilize a range of data sources and metrics to, for example, filter out malicious model updates, ensuring that the impact of attacks is minimized or eliminated.
  This paper explores the feasibility of designing a generic attack method capable of installing backdoors in FL while evading a diverse array of defenses. Specifically, we focus on an attacker strategy called MIGO, which aims to produce model updates that subtly blend with legitimate ones. The resulting effect is a gradual integration of a backdoor into the global model, often ensuring its persistence long after the attack concludes, while generating enough ambiguity to hinder the effectiveness of defenses.
  MIGO was employed to implant three types of backdoors across five datasets and different model architectures. The results demonstrate the significant threat posed by these backdoors, as MIGO consistently achieved exceptionally high backdoor accuracy (exceeding 90%) while maintaining the utility of the main task. Moreover, MIGO exhibited strong evasion capabilities against ten defenses, including several state-of-the-art methods. When compared to four other attack strategies, MIGO consistently outperformed them across most configurations. Notably, even in extreme scenarios where the attacker controls just 0.1% of the clients, the results indicate that successful backdoor insertion is possible if the attacker can persist for a sufficient number of rounds.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedMIA: An Effective Membership Inference Attack Exploiting "All for One" Principle in Federated Learning</title>
<link>https://arxiv.org/abs/2402.06289</link>
<guid>https://arxiv.org/abs/2402.06289</guid>
<content:encoded><![CDATA[
<div> 关键词: 异地学习 (Federated Learning), 隐私风险, 会员推断攻击 (Membership Inference Attacks, MIA), FedMIA, 更新信息

总结:
本文关注异地学习(Federated Learning)中的隐私风险问题，特别是会员推断攻击(Membership Inference Attacks, MIA)。现有的MIA方法主要分析目标客户端的更新信息，而该文提出了一种基于非目标客户端更新信息的一尾似然比假设检验，进而开发了一种新的MIA方法——FedMIA。FedMIA采取“全员为一”的策略，利用多轮通信中所有客户端的更新信息提升攻击效果。实验表明，FedMIA在分类和生成任务上均优于现有MIA方法，并能适应不同的防御策略、Non-IID数据以及联邦结构。相关代码已在https://github.com/Liar-Mask/FedMIA开源。<br /><br /> <div>
arXiv:2402.06289v2 Announce Type: replace 
Abstract: Federated Learning (FL) is a promising approach for training machine learning models on decentralized data while preserving privacy. However, privacy risks, particularly Membership Inference Attacks (MIAs), which aim to determine whether a specific data point belongs to a target client's training set, remain a significant concern. Existing methods for implementing MIAs in FL primarily analyze updates from the target client, focusing on metrics such as loss, gradient norm, and gradient difference. However, these methods fail to leverage updates from non-target clients, potentially underutilizing available information. In this paper, we first formulate a one-tailed likelihood-ratio hypothesis test based on the likelihood of updates from non-target clients. Building upon this formulation, we introduce a three-step Membership Inference Attack (MIA) method, called FedMIA, which follows the "all for one"--leveraging updates from all clients across multiple communication rounds to enhance MIA effectiveness. Both theoretical analysis and extensive experimental results demonstrate that FedMIA outperforms existing MIAs in both classification and generative tasks. Additionally, it can be integrated as an extension to existing methods and is robust against various defense strategies, Non-IID data, and different federated structures. Our code is available in https://github.com/Liar-Mask/FedMIA.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Graph Communication for Decentralised Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.00165</link>
<guid>https://arxiv.org/abs/2501.00165</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、动态网络环境、通信框架、强化学习、图注意力网络

总结:<br />
本文提出了一种用于动态网络环境中分散式多智能体系统的新型通信框架，该框架被集成到多智能体强化学习系统中，旨在通过优化网络集体知识的高效通信来提升决策效果。主要贡献包括将静态网络包路由场景适应于具有节点故障的动态环境，将图注意力网络层引入递归消息传递框架，并引入了多轮通信目标机制。这种方法使得在稀疏奖励、动态网络包路由环境下仅使用强化学习就能成功训练基于注意力的聚合机制。实验结果显示，与基线系统相比，该方法在路由性能上有所提高，平均奖励增加了9.5%，通信开销减少了6.4%。此外，文章还探讨了在关键基础设施和军事背景下部署此类系统可能带来的伦理和法律影响，指出了现有局限性，并提出了未来研究的方向。 <div>
arXiv:2501.00165v1 Announce Type: new 
Abstract: This work presents a novel communication framework for decentralized multi-agent systems operating in dynamic network environments. Integrated into a multi-agent reinforcement learning system, the framework is designed to enhance decision-making by optimizing the network's collective knowledge through efficient communication. Key contributions include adapting a static network packet-routing scenario to a dynamic setting with node failures, incorporating a graph attention network layer in a recurrent message-passing framework, and introducing a multi-round communication targeting mechanism. This approach enables an attention-based aggregation mechanism to be successfully trained within a sparse-reward, dynamic network packet-routing environment using only reinforcement learning. Experimental results show improvements in routing performance, including a 9.5 percent increase in average rewards and a 6.4 percent reduction in communication overhead compared to a baseline system. The study also examines the ethical and legal implications of deploying such systems in critical infrastructure and military contexts, identifies current limitations, and suggests potential directions for future research.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generative Emergent Communication: Large Language Model is a Collective World Model</title>
<link>https://arxiv.org/abs/2501.00226</link>
<guid>https://arxiv.org/abs/2501.00226</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式涌现通信 (Generative Emergent Communication, 简称EmCom)，集体预测编码 (Collective Predictive Coding, CPC)，大型语言模型 (Large Language Models, LLMs)，多智能体强化学习 (Multi-Agent Reinforcement Learning, MARL)，认知发展

<br /><br />总结:

本文提出了一种名为“生成式涌现通信”(Generative EmCom)的统一理论框架，该框架通过集体预测编码(CPC)的角度将涌现通信、世界模型和大型语言模型(LLMs)联系起来。文章的主要贡献包括：一是构建了EmCom作为理解涌现通信的新框架，展示了如何从控制即推理的角度推导出多智能体强化学习(MARL)中的通信涌现，并明确了其与传统判别性方法的关系；二是提出了将LLMs解释为通过CPC整合多个智能体经验的集体世界模型的数学表述。这一框架为理解共享符号系统如何通过集体预测编码过程而涌现提供了统一的理论基础，同时有助于阐明语言演化的根本方面，并为理解和开发改善人类-AI交互及多智能体系统的高级AI技术提供了实际见解。 <div>
arXiv:2501.00226v1 Announce Type: new 
Abstract: This study proposes a unifying theoretical framework called generative emergent communication (generative EmCom) that bridges emergent communication, world models, and large language models (LLMs) through the lens of collective predictive coding (CPC). The proposed framework formalizes the emergence of language and symbol systems through decentralized Bayesian inference across multiple agents, extending beyond conventional discriminative model-based approaches to emergent communication. This study makes the following two key contributions: First, we propose generative EmCom as a novel framework for understanding emergent communication, demonstrating how communication emergence in multi-agent reinforcement learning (MARL) can be derived from control as inference while clarifying its relationship to conventional discriminative approaches. Second, we propose a mathematical formulation showing the interpretation of LLMs as collective world models that integrate multiple agents' experiences through CPC. The framework provides a unified theoretical foundation for understanding how shared symbol systems emerge through collective predictive coding processes, bridging individual cognitive development and societal language evolution. Through mathematical formulations and discussion on prior works, we demonstrate how this framework explains fundamental aspects of language emergence and offers practical insights for understanding LLMs and developing sophisticated AI systems for improving human-AI interaction and multi-agent systems.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Approaches to Enhancing Smart Vehicle Cybersecurity by AI-Driven Threat Detection</title>
<link>https://arxiv.org/abs/2501.00261</link>
<guid>https://arxiv.org/abs/2501.00261</guid>
<content:encoded><![CDATA[
<div> 关键词：智能车辆、人工智能、网络安全、入侵检测系统、自动驾驶

总结:
<br />
随着汽车行业越来越多地采用连接和自动化车辆（CAVs），对于强大的网络安全措施的需求变得至关重要。本文探讨了利用人工智能驱动的威胁检测来加强智能车辆网络安全的合作方法。文章指出，面对新兴的安全漏洞和需求，5G网络、区块链和量子计算等先进技术的整合为提升CAV网络安全提供了有前景的方法。此外，自动驾驶汽车的网络安全路线图强调了高效入侵检测系统和基于AI的技术的重要性，以及需要集成安全硬件、软件栈和先进的威胁情报，以解决未来自动驾驶汽车面临的网络安全挑战。 <div>
arXiv:2501.00261v1 Announce Type: new 
Abstract: The introduction sets the stage for exploring collaborative approaches to bolstering smart vehicle cybersecurity through AI-driven threat detection. As the automotive industry increasingly adopts connected and automated vehicles (CAVs), the need for robust cybersecurity measures becomes paramount. With the emergence of new vulnerabilities and security requirements, the integration of advanced technologies such as 5G networks, blockchain, and quantum computing presents promising avenues for enhancing CAV cybersecurity . Additionally, the roadmap for cybersecurity in autonomous vehicles emphasizes the importance of efficient intrusion detection systems and AI-based techniques, along with the integration of secure hardware, software stacks, and advanced threat intelligence to address cybersecurity challenges in future autonomous vehicles.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UPC Sentinel: An Accurate Approach for Detecting Upgradeability Proxy Contracts in Ethereum</title>
<link>https://arxiv.org/abs/2501.00674</link>
<guid>https://arxiv.org/abs/2501.00674</guid>
<content:encoded><![CDATA[
<div> 关键词: DApp、智能合约、升级性代理合约(UPC)、静态分析、动态分析

<br /><br />总结:
本文介绍了针对以太坊区块链平台上运行的DApp维护问题，特别是关注于智能合约的升级性代理合约（UPC）的研究。由于Ethereum缺乏原生的后部署智能合约维护解决方案，开发人员通常利用UPC方法实现应用升级。为此，论文提出了名为UPC Sentinel的三层算法，该算法结合了智能合约字节码的静态和动态分析，用于准确检测活跃的UPC。通过两个独立的数据集评估，UPC Sentinel展现出了卓越的性能，第一个数据集中的准确率接近完美，达到99%，而第二个数据集则进一步证实其高效性，实现了100%的精确度和近乎完美的99.3%召回率，优于现有最优方法。最后，文章讨论了UPC Sentinel在未来研究工作中的潜在价值。 <div>
arXiv:2501.00674v1 Announce Type: new 
Abstract: Software applications that run on a blockchain platform are known as DApps. DApps are built using smart contracts, which are immutable after deployment. Just like any real-world software system, DApps need to receive new features and bug fixes over time in order to remain useful and secure. However, Ethereum lacks native solutions for post-deployment smart contract maintenance, requiring developers to devise their own methods. A popular method is known as the upgradeability proxy contract (UPC), which involves implementing the proxy design pattern (as defined by the Gang of Four). In this method, client calls first hit a proxy contract, which then delegates calls to a certain implementation contract. Most importantly, the proxy contract can be reconfigured during runtime to delegate calls to another implementation contract, effectively enabling application upgrades. For researchers, the accurate detection of UPCs is a strong requirement in the understanding of how exactly real-world DApps are maintained over time. For practitioners, the accurate detection of UPCs is crucial for providing application behavior transparency and enabling auditing. In this paper, we introduce UPC Sentinel, a novel three-layer algorithm that utilizes both static and dynamic analysis of smart contract bytecode to accurately detect active UPCs. We evaluated UPC Sentinel using two distinct ground truth datasets. In the first dataset, our method demonstrated a near-perfect accuracy of 99%. The evaluation on the second dataset further established our method's efficacy, showing a perfect precision rate of 100% and a near-perfect recall of 99.3%, outperforming the state of the art. Finally, we discuss the potential value of UPC Sentinel in advancing future research efforts.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Secure Semantic Communications</title>
<link>https://arxiv.org/abs/2501.00842</link>
<guid>https://arxiv.org/abs/2501.00842</guid>
<content:encoded><![CDATA[
<div> 关键词：语义通信(SemCom)，6G，安全性，隐私保护，技术对策

<br /><br />总结:
本文详细阐述了语义通信（SemCom）这一被视为6G革命性技术的概念及其优势，如降低传输负担、提升网络管理效率和优化资源配置。文章分析了SemCom从模型训练、模型转移至语义信息传输等整个生命周期中可能出现的安全与隐私问题。针对这些问题，文中总结了一系列可用于保障SemCom安全的技术措施，包括数据清洗、鲁棒学习、抵御后门攻击的防御策略、对抗性训练、差分隐私、密码学、区块链技术、模型压缩以及物理层安全。最后，文章指出了未来的研究方向，为相关领域的研究人员提供了指导。 <div>
arXiv:2501.00842v1 Announce Type: new 
Abstract: Semantic communication (SemCom) is regarded as a promising and revolutionary technology in 6G, aiming to transcend the constraints of ``Shannon's trap" by filtering out redundant information and extracting the core of effective data. Compared to traditional communication paradigms, SemCom offers several notable advantages, such as reducing the burden on data transmission, enhancing network management efficiency, and optimizing resource allocation. Numerous researchers have extensively explored SemCom from various perspectives, including network architecture, theoretical analysis, potential technologies, and future applications. However, as SemCom continues to evolve, a multitude of security and privacy concerns have arisen, posing threats to the confidentiality, integrity, and availability of SemCom systems. This paper presents a comprehensive survey of the technologies that can be utilized to secure SemCom. Firstly, we elaborate on the entire life cycle of SemCom, which includes the model training, model transfer, and semantic information transmission phases. Then, we identify the security and privacy issues that emerge during these three stages. Furthermore, we summarize the techniques available to mitigate these security and privacy threats, including data cleaning, robust learning, defensive strategies against backdoor attacks, adversarial training, differential privacy, cryptography, blockchain technology, model compression, and physical-layer security. Lastly, this paper outlines future research directions to guide researchers in related fields.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DMSA: A Decentralized Microservice Architecture for Edge Networks</title>
<link>https://arxiv.org/abs/2501.00883</link>
<guid>https://arxiv.org/abs/2501.00883</guid>
<content:encoded><![CDATA[
<div> 关键词: 微服务架构、边缘网络、去中心化、调度、负载均衡

总结:<br />
本文提出了一种针对边缘网络的去中心化微服务架构（DMSA），旨在解决传统集中式微服务架构的局限性。DMSA将调度功能从控制平面下放到边缘节点，并重新设计实现了三大核心模块：微服务发现、监控和调度。具体来说，DMSA定制了一种利用多端口监听和零拷贝转发的微服务调度方案，以确保高效的数据转发。此外，还提出了动态加权多级负载均衡算法，能够根据可靠性、优先级和响应延迟等因素动态调整调度。文章中实现了一个DMSA物理验证平台，实验结果表明，与现有最优和传统的调度方案相比，DMSA能有效应对链路故障和网络波动，提高了服务响应延迟和执行成功率，分别改善约60%~75%和10%~15%。 <div>
arXiv:2501.00883v1 Announce Type: new 
Abstract: The dispersed node locations and complex topologies of edge networks, combined with intricate dynamic microservice dependencies, render traditional centralized microservice architectures (MSAs) unsuitable. In this paper, we propose a decentralized microservice architecture (DMSA), which delegates scheduling functions from the control plane to edge nodes. DMSA redesigns and implements three core modules of microservice discovery, monitoring, and scheduling for edge networks to achieve precise awareness of instance deployments, low monitoring overhead and measurement errors, and accurate dynamic scheduling, respectively. Particularly, DMSA has customized a microservice scheduling scheme that leverages multi-port listening and zero-copy forwarding to guarantee high data forwarding efficiency. Moreover, a dynamic weighted multi-level load balancing algorithm is proposed to adjust scheduling dynamically with consideration of reliability, priority, and response delay. Finally, we have implemented a physical verification platform for DMSA. Extensive empirical results demonstrate that compared to state-of-the-art and traditional scheduling schemes, DMSA effectively counteracts link failures and network fluctuations, improving the service response delay and execution success rate by approximately $60\% \sim 75\%$ and $10\%\sim15\%$, respectively.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Large-Scale Exploratory Study on the Proxy Pattern in Ethereum</title>
<link>https://arxiv.org/abs/2501.00965</link>
<guid>https://arxiv.org/abs/2501.00965</guid>
<content:encoded><![CDATA[
<div> 关键词：代理模式、以太坊区块链、智能合约、升级性、ERC-1167

总结:
文章对以太坊区块链上的智能合约进行了全面分析，重点关注代理合同的使用情况。研究发现，14.2%的已部署智能合约为代理合同，且其活跃度和使用趋势均呈上升状态，尤其在合同部署后期达到高峰。代理合同主要通过离线脚本或链上工厂合同进行部署，分别占39.1%和60.9%。其中，67.8%的代理合同充当拦截器角色，而32.2%用于实现升级性。大多数（79%）代理合约为已知参考实现，尤其是ERC-1167类型占比29.4%，该类型旨在廉价复用和克隆合同功能。此外，研究提出了一种行为代理检测方法，精度和召回率均为100%。最后，针对开发者提出了实践建议，并指出了未来研究领域的开放性问题。 <div>
arXiv:2501.00965v1 Announce Type: new 
Abstract: The proxy pattern is a well-known design pattern with numerous use cases in several sectors of the software industry. As such, the use of the proxy pattern is also a common approach in the development of complex decentralized applications (DApps) on the Ethereum blockchain. Despite the importance of proxy contracts, little is known about (i) how their prevalence changed over time, (ii) the ways in which developers integrate proxies in the design of DApps, and (iii) what proxy types are being most commonly leveraged by developers. This study bridges these gaps through a comprehensive analysis of Ethereum smart contracts, utilizing a dataset of 50 million contracts and 1.6 billion transactions as of September 2022. Our findings reveal that 14.2% of all deployed smart contracts are proxy contracts. We show that proxy contracts are being more actively used than non-proxy contracts. Also, the usage of proxy contracts in various contexts, transactions involving proxy contracts, and adoption of proxy contracts by users have shown an upward trend over time, peaking at the end of our study period. They are either deployed through off-chain scripts or on-chain factory contracts, with the former and latter being employed in 39.1% and 60.9% of identified usage contexts in turn. We found that while the majority (67.8%) of proxies act as an interceptor, 32.2% enables upgradeability. Proxy contracts are typically (79%) implemented based on known reference implementations with 29.4% being of type ERC-1167, a class of proxies that aims to cheaply reuse and clone contracts' functionality. Our evaluation shows that our proposed behavioral proxy detection method has a precision and recall of 100% in detecting active proxies. Finally, we derive a set of practical recommendations for developers and introduce open research questions to guide future research on the topic.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fides: Scalable Censorship-Resistant DAG Consensus via Trusted Components</title>
<link>https://arxiv.org/abs/2501.01062</link>
<guid>https://arxiv.org/abs/2501.01062</guid>
<content:encoded><![CDATA[
<div> 关键词：Fides、异步DAG、BFT共识协议、Trusted Execution Environments (TEEs)、区块链系统

总结:<br />
本文提出了一个名为Fides的新式异步DAG基础的BFT共识协议，旨在解决现有协议面临的三个主要挑战。Fides利用可信执行环境(TEEs)来处理如下问题：<br />
1. 为容忍拜占庭副本而需要更大的共识群体规模（至少3倍大）的问题。<br />
2. 在异步网络中达成一致时高昂的通信成本和对全局公共随机数的依赖。<br />
3. 对抗审查以保证活性保障的脆弱性。<br />
通过采用四个基于TEE的信任组件——可靠广播、顶点验证、公共随机数以及交易披露，Fides实现了线性消息复杂度、确保的审查抵抗能力、扩大2倍的共识群体规模及轻量级公共随机数使用。此外，将这些核心组件抽象出来而非将整个协议迁移到TEE内，可以显著降低可信计算基数(TCB)。实验结果显示，相较于Tusk、RCC、HotStuff和PBFT等现行主流协议，Fides在本地和地理分布式网络中的性能更优，分别达到了每秒40万和81万笔交易的吞吐量。文章还分析了该协议的开销，证明了其在实际部署到真实世界区块链系统中的适用性和有效性。 <div>
arXiv:2501.01062v1 Announce Type: new 
Abstract: Recently, consensus protocols based on Directed Acyclic Graph (DAG) have gained significant attention due to their potential to build robust blockchain systems, particularly in asynchronous networks. In this paper, we propose Fides, an asynchronous DAG-based BFT consensus protocol that leverages Trusted Execution Environments (TEEs) to tackle three major scalability and security challenges faced by existing protocols: (i) the need for a larger quorum size (i.e., at least 3x larger) to tolerate Byzantine replicas, (ii) high communication costs and reliance on expensive cryptographic primitives (i.e., global common coin) to reach agreement in asynchronous networks, and (iii) poor censorship resilience undermining the liveness guarantee. Specifically, Fides adopts four trusted components-Reliable Broadcast, Vertex Validation, Common Coin, and Transaction Disclosure-within TEEs. Incorporating these components enables Fides to achieve linear message complexity, guaranteed censorship resilience, 2x larger quorum size, and lightweight common coin usage. Besides, abstracting these essential components rather than porting the entire protocol into TEE can significantly reduce the Trusted Computing Base (TCB). Experimental evaluations of Fides in local and geo-distributed networks demonstrate its superior performance compared to established state-of-the-art protocols such as Tusk, RCC, HotStuff, and PBFT. The results indicate that Fides achieves a throughput of 400k transactions per second in a geo-distributed network and 810k transactions per second in a local network. Our analysis further explores the protocol's overhead, highlighting its suitability and effectiveness for practical deployment in real-world blockchain systems.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FAPL-DM-BC: A Secure and Scalable FL Framework with Adaptive Privacy and Dynamic Masking, Blockchain, and XAI for the IoVs</title>
<link>https://arxiv.org/abs/2501.01063</link>
<guid>https://arxiv.org/abs/2501.01063</guid>
<content:encoded><![CDATA[
<div> 关键词：FAPL-DM-BC方案、联邦学习、动态遮掩、区块链、智能城市

总结:
FAPL-DM-BC方案是一种基于联邦学习的车联网隐私、安全和可扩展性解决方案。该方案利用了Federated Adaptive Privacy-Aware Learning（FAPL）和Dynamic Masking（DM），实现实时学习并自适应调整隐私策略，以应对数据敏感性和状态变化，达到最优的隐私-效用平衡。同时结合了安全日志与验证、基于区块链的数据源追溯和去中心化验证以及云微服务中使用FedAvg和Secure Multi-Party Computation（SMPC）的安全聚合。通过由模型无关的可解释人工智能（XAI）驱动的双模反馈机制，确保本地预测和解释得到认证并提升效率。通过将局部反馈与全局知识通过加权平均计算相结合，FAPL-DM-BC保证了联邦学习过程既安全又可扩展，并具有可解释性。此方案有望应用于自动驾驶汽车、交通管理与预测、实时车联网网络安全以及智慧城市等领域。 <div>
arXiv:2501.01063v1 Announce Type: new 
Abstract: The FAPL-DM-BC solution is a new FL-based privacy, security, and scalability solution for the Internet of Vehicles (IoV). It leverages Federated Adaptive Privacy-Aware Learning (FAPL) and Dynamic Masking (DM) to learn and adaptively change privacy policies in response to changing data sensitivity and state in real-time, for the optimal privacy-utility tradeoff. Secure Logging and Verification, Blockchain-based provenance and decentralized validation, and Cloud Microservices Secure Aggregation using FedAvg (Federated Averaging) and Secure Multi-Party Computation (SMPC). Two-model feedback, driven by Model-Agnostic Explainable AI (XAI), certifies local predictions and explanations to drive it to the next level of efficiency. Combining local feedback with world knowledge through a weighted mean computation, FAPL-DM-BC assures federated learning that is secure, scalable, and interpretable. Self-driving cars, traffic management, and forecasting, vehicular network cybersecurity in real-time, and smart cities are a few possible applications of this integrated, privacy-safe, and high-performance IoV platform.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communicating Unexpectedness for Out-of-Distribution Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.01140</link>
<guid>https://arxiv.org/abs/2501.01140</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning、generalization、distribution shifts、Unexpected Encoding Scheme、multi-robot warehouse environment

总结:<br />
本文提出了一种名为“意外编码方案”的新颖的去中心化多智能体强化学习算法，旨在解决智能体在实际环境中快速适应预料之外的情况。该方法通过让智能体不仅基于奖励驱动进行通信，还预测下一次观察结果并度量预测与实际观察之间的差异，将这种“意外性”编码为消息进行传递。实验在多机器人仓库环境中验证了所提方法能有效应对动态变化的训练环境以及分布外的环境，展现出较强的鲁棒适应能力。 <div>
arXiv:2501.01140v1 Announce Type: new 
Abstract: Applying multi-agent reinforcement learning methods to realistic settings is challenging as it may require the agents to quickly adapt to unexpected situations that are rarely or never encountered in training. Recent methods for generalization to such out-of-distribution settings are limited to more specific, restricted instances of distribution shifts. To tackle adaptation to distribution shifts, we propose Unexpected Encoding Scheme, a novel decentralized multi-agent reinforcement learning algorithm where agents communicate "unexpectedness," the aspects of the environment that are surprising. In addition to a message yielded by the original reward-driven communication, each agent predicts the next observation based on previous experience, measures the discrepancy between the prediction and the actually encountered observation, and encodes this discrepancy as a message. Experiments on multi-robot warehouse environment support that our proposed method adapts robustly to dynamically changing training environments as well as out-of-distribution environment.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PoVF: Empowering Decentralized Blockchain Systems with Verifiable Function Consensus</title>
<link>https://arxiv.org/abs/2501.01146</link>
<guid>https://arxiv.org/abs/2501.01146</guid>
<content:encoded><![CDATA[
<div> 关键词：共识机制、区块链、去中心化、Proof of Verifiable Functions (PoVF)、Delay buffer

总结:
本文提出了一种名为Proof of Verifiable Functions (PoVF)的新颖共识机制，该机制旨在解决现有区块链共识机制中的中心化问题并提高系统的效率。PoVF基于可验证函数的可验证性和不可预测性，确保了区块链网络中所有节点拥有平等参与共识的机会，从而实现更充分的去中心化。同时，文中还提出了“延迟缓冲”结构，用于保证交易的顺序执行，防止因广播和交易执行混乱导致的区块链分叉。安全分析表明，PoVF具有可证明的安全性和抵抗潜在攻击的能力。实验结果显示，基于PoVF的区块链系统在仅配置有4核CPU的节点条件下，可以达到每秒处理4000笔交易的性能。此外，通过使用基尼系数评估区块链的去中心化程度，PoVF实现了在所采样区块链中最低的基尼系数0.39。实验表明，PoVF在保障去中心化与安全性的同时，亦具备较高的运行效率。 <div>
arXiv:2501.01146v1 Announce Type: new 
Abstract: Consensus mechanism is the core technology for blockchain to ensure that transactions are executed in sequence. It also determines the decentralization, security, and efficiency of blockchain. Existing mechanisms all have certain centralization issues and fail to ensure the decentralization of blockchain networks. A decentralized and efficient mechanism is required to improve blockchain systems. This paper proposes a fair consensus mechanism called Proof of Verifiable Functions (PoVF), based on the verifiability and unpredictability of verifiable functions. PoVF provides a sufficiently fair mechanism, ensuring that all nodes in blockchain network have equal opportunity to participate in consensus. In addition, a structure called "Delay buffer" is proposed to ensure transactions are executed sequentially. It delay the selection of blocks to avoid blockchain forks caused by broadcasting and transaction execution confusion. According to our security analysis, PoVF is provably secure and has the ability to resist potential adversaries. According to the experiments, PoVF-based blockchain can process up to 4000 transactions per second with nodes configured with only 4-core CPUs. This paper uses the Gini coefficient to measure the decentralization of blockchains, and the PoVF-based blockchain achieves the lowest Gini coefficient of 0.39 among all sampled blockchains. PoVF has been shown to provide sufficient efficiency while ensuring decentralization and security through experiments.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MADiff: Offline Multi-agent Learning with Diffusion Models</title>
<link>https://arxiv.org/abs/2305.17330</link>
<guid>https://arxiv.org/abs/2305.17330</guid>
<content:encoded><![CDATA[
<div> 关键词：离线强化学习、Q-learning、监督学习、扩散模型、多智能体

总结：
本文提出了一种名为MADiff的新方法，它是一种基于注意力机制的扩散模型，用于解决多智能体环境中的离线强化学习问题。传统的Q-learning算法和监督学习方法在离线设置中存在局限性，而MADiff旨在克服这些限制，通过建模多个智能体之间的复杂协调行为来提高性能。与每个智能体独立使用DM不同，MADiff作为一个既能实现分布式策略又能作为集中式控制器的框架运作。在执行过程中，MADiff同时进行队友建模，并可用于多智能体轨迹预测。实验结果显示，MADiff在各种多智能体学习任务上优于基线算法，证实了其在建模复杂多智能体交互方面的有效性。相关代码已发布在https://github.com/zbzhu99/madiff上。 <div>
arXiv:2305.17330v5 Announce Type: replace 
Abstract: Offline reinforcement learning (RL) aims to learn policies from pre-existing datasets without further interactions, making it a challenging task. Q-learning algorithms struggle with extrapolation errors in offline settings, while supervised learning methods are constrained by model expressiveness. Recently, diffusion models (DMs) have shown promise in overcoming these limitations in single-agent learning, but their application in multi-agent scenarios remains unclear. Generating trajectories for each agent with independent DMs may impede coordination, while concatenating all agents' information can lead to low sample efficiency. Accordingly, we propose MADiff, which is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple agents. To our knowledge, MADiff is the first diffusion-based multi-agent learning framework, functioning as both a decentralized policy and a centralized controller. During decentralized executions, MADiff simultaneously performs teammate modeling, and the centralized controller can also be applied in multi-agent trajectory predictions. Our experiments demonstrate that MADiff outperforms baseline algorithms across various multi-agent learning tasks, highlighting its effectiveness in modeling complex multi-agent interactions. Our code is available at https://github.com/zbzhu99/madiff.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Solving Hierarchical Information-Sharing Dec-POMDPs: An Extensive-Form Game Approach</title>
<link>https://arxiv.org/abs/2402.02954</link>
<guid>https://arxiv.org/abs/2402.02954</guid>
<content:encoded><![CDATA[
<div> 关键词：多玩家、部分可观测马尔科夫决策过程、等价单玩家游戏、决策变量解耦、层次信息共享、扩展型博弈、时间复杂度优化

总结:<br />
该文针对多玩家局部可观测马尔科夫决策过程提出了一种新的解决方法。文章首先介绍了将此类问题转化为等价的单玩家游戏的理论，但指出这种转化会导致双指数级的复杂度。为了解决这一问题，本文通过在层次信息共享的框架下，进一步将单阶段子游戏分解为更小的子游戏，从而实现了决策变量的解耦，并保持了最优性。这种方法揭示了对于任何单阶段子游戏，都存在可利用的扩展型博弈解决方案，显著降低了时间复杂度。实验结果显示，基于这些发现的算法能够在不牺牲最优性的前提下，处理规模更大的多玩家游戏。 <div>
arXiv:2402.02954v3 Announce Type: replace 
Abstract: A recent theory shows that a multi-player decentralized partially observable Markov decision process can be transformed into an equivalent single-player game, enabling the application of \citeauthor{bellman}'s principle of optimality to solve the single-player game by breaking it down into single-stage subgames. However, this approach entangles the decision variables of all players at each single-stage subgame, resulting in backups with a double-exponential complexity. This paper demonstrates how to disentangle these decision variables while maintaining optimality under hierarchical information sharing, a prominent management style in our society. To achieve this, we apply the principle of optimality to solve any single-stage subgame by breaking it down further into smaller subgames, enabling us to make single-player decisions at a time. Our approach reveals that extensive-form games always exist with solutions to a single-stage subgame, significantly reducing time complexity. Our experimental results show that the algorithms leveraging these findings can scale up to much larger multi-player games without compromising optimality.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Detecting Financial Bots on the Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2403.19530</link>
<guid>https://arxiv.org/abs/2403.19530</guid>
<content:encoded><![CDATA[
<div> 关键词：bots, 分布式账本技术, 机器学习, 以太坊, 检测算法

总结:
本文研究了在分布式账本技术（DLTs）中集成的机器人（bots）对效率和自动化的影响，以及它们可能带来的市场操纵等风险。文章提出了一个新的利用机器学习检测以太坊平台上金融机器人的方法。首先，通过系统化现有科学文献和收集轶事证据，建立了由7个类别和24个子类别组成的金融bot分类体系。其次，创建了一个包含133个人类地址和137个bot地址的地面真实数据集。接着，运用无监督和有监督的机器学习算法进行分析，其中高绩效的聚类算法是平均群纯度为82.6%的高斯混合模型，而二元分类中最优模型是准确率达到83%的随机森林。这种基于机器学习的检测机制为理解以太坊生态系统动态提供了新的视角，有助于深入剖析当前的bot景观。 <div>
arXiv:2403.19530v2 Announce Type: replace 
Abstract: The integration of bots in Distributed Ledger Technologies (DLTs) fosters efficiency and automation. However, their use is also associated with predatory trading and market manipulation, and can pose threats to system integrity. It is therefore essential to understand the extent of bot deployment in DLTs; despite this, current detection systems are predominantly rule-based and lack flexibility. In this study, we present a novel approach that utilizes machine learning for the detection of financial bots on the Ethereum platform. First, we systematize existing scientific literature and collect anecdotal evidence to establish a taxonomy for financial bots, comprising 7 categories and 24 subcategories. Next, we create a ground-truth dataset consisting of 133 human and 137 bot addresses. Third, we employ both unsupervised and supervised machine learning algorithms to detect bots deployed on Ethereum. The highest-performing clustering algorithm is a Gaussian Mixture Model with an average cluster purity of 82.6%, while the highest-performing model for binary classification is a Random Forest with an accuracy of 83%. Our machine learning-based detection mechanism contributes to understanding the Ethereum ecosystem dynamics by providing additional insights into the current bot landscape.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real World Federated Learning with a Knowledge Distilled Transformer for Cardiac CT Imaging</title>
<link>https://arxiv.org/abs/2407.07557</link>
<guid>https://arxiv.org/abs/2407.07557</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、半监督策略、Transformer、卷积神经网络（CNN）、心脏CT分析

总结:<br />
本文探讨了联邦学习在实际应用中的挑战，特别是面对部分标注数据的情况。研究提出了一种两步半监督策略，用于提升transformer架构在小规模和多样化标注数据集上的性能。该策略通过任务特定的CNN对未标注数据进行预测，然后将这些预测结果作为输入，利用标签特定的头部让transformer进行学习。在涉及大规模真实世界设置的心脏CT分析（样本量为8,104）中，八个医院的数据被联合使用。实验结果显示，这种方法提高了预测准确性，并能在联邦范围内同时学习各种局部标注，相比基于UNet的模型在下游任务上表现出更好的泛化能力。研究方已公开发布了相关代码和模型权重，以促进未来心脏CT分析的应用和发展。 <div>
arXiv:2407.07557v2 Announce Type: replace-cross 
Abstract: Federated learning is a renowned technique for utilizing decentralized data while preserving privacy. However, real-world applications often face challenges like partially labeled datasets, where only a few locations have certain expert annotations, leaving large portions of unlabeled data unused. Leveraging these could enhance transformer architectures ability in regimes with small and diversely annotated sets. We conduct the largest federated cardiac CT analysis to date (n=8,104) in a real-world setting across eight hospitals. Our two-step semi-supervised strategy distills knowledge from task-specific CNNs into a transformer. First, CNNs predict on unlabeled data per label type and then the transformer learns from these predictions with label-specific heads. This improves predictive accuracy and enables simultaneous learning of all partial labels across the federation, and outperforms UNet-based models in generalizability on downstream tasks. Code and model weights are made openly available for leveraging future cardiac CT analysis.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Segmented Private Data Aggregation in the Multi-message Shuffle Model</title>
<link>https://arxiv.org/abs/2407.19639</link>
<guid>https://arxiv.org/abs/2407.19639</guid>
<content:encoded><![CDATA[
<div> 关键词: 多消息洗牌模型、差分隐私、灵活隐私保护、数据聚合、通信优化

总结:
本文针对多消息洗牌模型下的差分隐私研究，提出了一个创新的分段私有数据聚合框架，旨在为用户提供灵活的隐私保护水平，同时增强服务器的数据聚合效率。该框架不仅保护用户数据，还能匿名处理用户的隐私保护选择以防止潜在的数据泄露风险。为了优化隐私-效用-通信之间的权衡，文中探讨了用于毯式消息的最佳配置数量，并在洗牌模型中进行了近乎精确的隐私放大分析。实验结果显示，与现有方法相比，该分段多消息洗牌框架可将估计误差降低约50%，显著提升了隐私性和实用性。 <div>
arXiv:2407.19639v3 Announce Type: replace 
Abstract: The shuffle model of differential privacy (DP) offers compelling privacy-utility trade-offs in decentralized settings (e.g., internet of things, mobile edge networks). Particularly, the multi-message shuffle model, where each user may contribute multiple messages, has shown that accuracy can approach that of the central model of DP. However, existing studies typically assume a uniform privacy protection level for all users, which may deter conservative users from participating and prevent liberal users from contributing more information, thereby reducing the overall data utility, such as the accuracy of aggregated statistics. In this work, we pioneer the study of segmented private data aggregation within the multi-message shuffle model of DP, introducing flexible privacy protection for users and enhanced utility for the aggregation server. Our framework not only protects users' data but also anonymizes their privacy level choices to prevent potential data leakage from these choices. To optimize the privacy-utility-communication trade-offs, we explore approximately optimal configurations for the number of blanket messages and conduct almost tight privacy amplification analyses within the shuffle model. Through extensive experiments, we demonstrate that our segmented multi-message shuffle framework achieves a reduction of about 50\% in estimation error compared to existing approaches, significantly enhancing both privacy and utility.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Blockchain Radio Access Networks: Architecture, Modelling, and Performance Assessment</title>
<link>https://arxiv.org/abs/2412.19838</link>
<guid>https://arxiv.org/abs/2412.19838</guid>
<content:encoded><![CDATA[
<div> 关键词: 下一代无线接入网络 (RAN), 区块链技术, 安全性, 动态覆盖扩展, 延迟, 攻击成功率

总结:
本文介绍了下一代无线接入网络（RAN）的设计需求，强调了安全、无处不在和始终可用的连通性的重要性。为此，文章提出了一种利用区块链技术增强RAN安全性并借助商业或私有无线节点实现动态覆盖扩展的网络架构。通过运用Markov链理论，该文构建了一个具有更高工程洞见的理论模型，以此评估该架构的效率与局限性。针对固定拓扑前传网络、高级覆盖扩展以及高级移动节点连接三种场景，文中量化了延迟及安全性指标——成功的攻击概率，揭示了区块链-RAN架构的可扩展性。<br /><br /> <div>
arXiv:2412.19838v1 Announce Type: new 
Abstract: Demands for secure, ubiquitous, and always-available connectivity have been identified as the pillar design parameters of the next generation radio access networks (RANs). Motivated by this, the current contribution introduces a network architecture that leverages blockchain technologies to augment security in RANs, while enabling dynamic coverage expansion through the use of intermediate commercial or private wireless nodes. To assess the efficiency and limitations of the architecture, we employ Markov chain theory in order to extract a theoretical model with increased engineering insights. Building upon this model, we quantify the latency as well as the security capabilities in terms of probability of successful attack, for three scenarios, namely fixed topology fronthaul network, advanced coverage expansion and advanced mobile node connectivity, which reveal the scalability of the blockchain-RAN architecture.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WiSER-X: Wireless Signals-based Efficient Decentralized Multi-Robot Exploration without Explicit Information Exchange</title>
<link>https://arxiv.org/abs/2412.19876</link>
<guid>https://arxiv.org/abs/2412.19876</guid>
<content:encoded><![CDATA[
<div> 关键词：Wireless Signal, efficient multi-robot exploration, WiSER-X, decentralized team, communication bandwidth constraints

<br /><br />总结:

本文介绍了应用于带有通信带宽约束条件下的分布式机器人团队未知环境探索的新算法——无线信号驱动的有效多机器人探索算法(WiSER-X)。WiSER-X仅依赖于通过如WiFi、超宽带等传感器交换的局部间机器人相对位置估计来指导单个机器人的探索决策，以最大限度地减少覆盖重叠。此外，WiSER-X还支持异步终止，无需机器人之间共享地图。它还能适应异构机器人行为以及在未知环境中处理完全故障的情况，同时确保全面覆盖。模拟结果显示，与不分享信息的基线算法-1相比，WiSER-X导致的覆盖重叠降低了58%，而与全信息分享的基线算法-2相比，仅多出23%的重叠。 <div>
arXiv:2412.19876v1 Announce Type: new 
Abstract: We introduce a Wireless Signal based Efficient multi-Robot eXploration (WiSER-X) algorithm applicable to a decentralized team of robots exploring an unknown environment with communication bandwidth constraints. WiSER-X relies only on local inter-robot relative position estimates, that can be obtained by exchanging signal pings from onboard sensors such as WiFi, Ultra-Wide Band, amongst others, to inform the exploration decisions of individual robots to minimize redundant coverage overlaps. Furthermore, WiSER-X also enables asynchronous termination without requiring a shared map between the robots. It also adapts to heterogeneous robot behaviors and even complete failures in unknown environment while ensuring complete coverage. Simulations show that WiSER-X leads to 58% lower overlap than a zero-information-sharing baseline algorithm-1 and only 23% more overlap than a full-information-sharing algorithm baseline algorithm-2.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning Driven Multi-Robot Exploration via Explicit Communication and Density-Based Frontier Search</title>
<link>https://arxiv.org/abs/2412.20049</link>
<guid>https://arxiv.org/abs/2412.20049</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体探索、未知环境、强化学习、约束通信、自主探索

<br />
总结:
本文提出了一种基于强化学习的新型去中心化协同框架，用于增强多智能体在未知环境中的探索能力。该框架使智能体能够利用以自身为中心的视场占用格子和从$\text{A}^*$算法计算出的前沿轨迹特征来决定下一步行动。同时，文章还提出了一种受限的通信方案，允许智能体高效地分享环境知识，从而减少探索冗余。这种去中心化的框架确保每个智能体能独立运行并为集体探索任务作出贡献。通过在Gymnasium模拟环境和真实世界实验中的广泛验证，结果显示了该系统的鲁棒性和有效性，强调了结合自主探索与智能体间地图共享对于发展可扩展和鲁棒的机器人探索系统的重要性。 <div>
arXiv:2412.20049v1 Announce Type: new 
Abstract: Collaborative multi-agent exploration of unknown environments is crucial for search and rescue operations. Effective real-world deployment must address challenges such as limited inter-agent communication and static and dynamic obstacles. This paper introduces a novel decentralized collaborative framework based on Reinforcement Learning to enhance multi-agent exploration in unknown environments. Our approach enables agents to decide their next action using an agent-centered field-of-view occupancy grid, and features extracted from $\text{A}^*$ algorithm-based trajectories to frontiers in the reconstructed global map. Furthermore, we propose a constrained communication scheme that enables agents to share their environmental knowledge efficiently, minimizing exploration redundancy. The decentralized nature of our framework ensures that each agent operates autonomously, while contributing to a collective exploration mission. Extensive simulations in Gymnasium and real-world experiments demonstrate the robustness and effectiveness of our system, while all the results highlight the benefits of combining autonomous exploration with inter-agent map sharing, advancing the development of scalable and resilient robotic exploration systems.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Unlabeled Multi-Agent Navigation in Continuous Space</title>
<link>https://arxiv.org/abs/2412.20233</link>
<guid>https://arxiv.org/abs/2412.20233</guid>
<content:encoded><![CDATA[
<div> 关键词：移动代理、目标位置、分布式场景、局部观察、路径规划

总结:
本文研究了一个无需特定代理人到达指定目标的多移动代理人导航问题。与大多数假设存在集中式规划器并限制代理人仅能在预定义的位置图及转换之间移动的工作不同，本工作聚焦于分布式场景，其中每个代理人仅依赖本地观测和通信独立行动，并可在任意时刻向任意方向移动。提出了一种迭代方法，包括代理人个体选择目标、交换目标、规划路径，并在每个时间步长中选择平衡推进路径与避免碰撞的动作。在满足特定假设下，该方法被证明是完备的。实验结果表明，相较于基准的分布式导航方法，所提方法在成功率（即在给定时间内能解决更多问题实例）上具有优势，并与中心化的TSWAP算法相比，其在完成任务的轨迹长度方面表现出更高效率。 <div>
arXiv:2412.20233v1 Announce Type: new 
Abstract: In this work, we study the problem where a group of mobile agents needs to reach a set of goal locations, but it does not matter which agent reaches a specific goal. Unlike most of the existing works on this topic that typically assume the existence of the centralized planner (or controller) and limit the agents' moves to a predefined graph of locations and transitions between them, in this work we focus on the decentralized scenarios, when each agent acts individually relying only on local observations/communications and is free to move in arbitrary direction at any time. Our iterative approach involves agents individually selecting goals, exchanging them, planning paths, and at each time step choose actions that balance between progressing along the paths and avoiding collisions. The proposed method is shown to be complete under specific assumptions on how agents progress towards their current goals, and our empirical evaluation demonstrates its superiority over a baseline decentralized navigation approach in success rate (i.e. is able to solve more problem instances under a given time limit) and a comparison with the centralized TSWAP algorithm reveals its efficiency in minimizing trajectory lengths for mission accomplishment.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Election of Collaborators via Reinforcement Learning for Federated Brain Tumor Segmentation</title>
<link>https://arxiv.org/abs/2412.20253</link>
<guid>https://arxiv.org/abs/2412.20253</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Reinforcement Learning, Similarity-weighted Aggregation, Multi-armed Bandit, Brain Lesion Segmentation

<br /><br />总结:
本文提出了一种名为RL-HSimAgg的新颖强化学习与相似性加权聚合算法，该算法利用调和均值处理异常数据点，旨在解决动态联邦学习环境中参与协作的选择优化问题。研究将多臂老虎机算法应用于改善合作者选择及模型泛化能力，通过平衡探索与开发之间的权衡来实现资源效率更高的训练和多样化的数据集。实验表明，在针对脑部肿瘤分割的模拟实验中，使用上确界策略(UCB)的RL-HSimAgg相较于Epsilon-greedy方法在所有评估指标上表现出色，特别是在增强型肿瘤、肿瘤核心以及整个肿瘤的分割Dice分数上有显著提升。因此，在即将举行的Federated Tumor Segmentation Challenge (FeTS 2024) 中，文章建议采用UCB作为多模态MRI胶质母细胞瘤病变分割任务的主要客户端选择方法。研究表明，基于RL的合作者管理策略（如UCB）有可能提高分布式学习环境中的模型稳健性和灵活性，尤其是在脑肿瘤分割等特定领域。 <div>
arXiv:2412.20253v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized datasets while preserving data privacy. However, optimally selecting participating collaborators in dynamic FL environments remains challenging. We present RL-HSimAgg, a novel reinforcement learning (RL) and similarity-weighted aggregation (simAgg) algorithm using harmonic mean to manage outlier data points. This paper proposes applying multi-armed bandit algorithms to improve collaborator selection and model generalization. By balancing exploration-exploitation trade-offs, these RL methods can promote resource-efficient training with diverse datasets. We demonstrate the effectiveness of Epsilon-greedy (EG) and upper confidence bound (UCB) algorithms for federated brain lesion segmentation. In simulation experiments on internal and external validation sets, RL-HSimAgg with UCB collaborator outperformed the EG method across all metrics, achieving higher Dice scores for Enhancing Tumor (0.7334 vs 0.6797), Tumor Core (0.7432 vs 0.6821), and Whole Tumor (0.8252 vs 0.7931) segmentation. Therefore, for the Federated Tumor Segmentation Challenge (FeTS 2024), we consider UCB as our primary client selection approach in federated Glioblastoma lesion segmentation of multi-modal MRIs. In conclusion, our research demonstrates that RL-based collaborator management, e.g. using UCB, can potentially improve model robustness and flexibility in distributed learning environments, particularly in domains like brain tumor segmentation.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Policies for Dynamic Coalition Formation in Multi-Robot Task Allocation</title>
<link>https://arxiv.org/abs/2412.20397</link>
<guid>https://arxiv.org/abs/2412.20397</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人任务分配、动态联盟形成、分布式学习框架、多智能体近似策略优化、空间动作地图

总结:<br />
本文提出了一种用于多机器人任务分配的分布式、基于学习的动态联盟形成框架。该框架扩展了多智能体近似策略优化（MAPPO），融入了空间动作地图、机器人运动控制、任务分配修订和意图分享机制，从而实现有效的联盟形成。通过大量模拟实验表明，与现有方法（包括市场基准）相比，该模型表现更优。此外，文章还评估了该框架的可扩展性和泛化性，证实其能够处理大规模机器人群体并在各种不同的任务分配环境中适应并发挥作用。 <div>
arXiv:2412.20397v1 Announce Type: new 
Abstract: We propose a decentralized, learning-based framework for dynamic coalition formation in Multi-Robot Task Allocation (MRTA). Our approach extends Multi-Agent Proximal Policy Optimization (MAPPO) by incorporating spatial action maps, robot motion control, task allocation revision, and intention sharing to enable effective coalition formation. Extensive simulations demonstrate that our model significantly outperforms existing methods, including a market-based baseline. Furthermore, we assess the scalability and generalizability of the proposed framework, highlighting its ability to handle large robot populations and adapt to diverse task allocation environments.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cool, But What About Oracles? An Oracle-Based Perspective on Blockchain Integration in the Accounting Field</title>
<link>https://arxiv.org/abs/2412.20447</link>
<guid>https://arxiv.org/abs/2412.20447</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、会计系统、Oracle、限制、ESG

总结:
区块链技术因其成功应用于比特币网络而受到广泛关注，并被提议用于改进传统会计系统。然而，与现实世界数据交互需要第三方Oracle介入，其特性可能降低预期的集成效益。本文通过文献回顾研究了区块链在会计领域整合中是否考虑并解决了Oracle带来的局限性问题。研究发现，尽管相关领域的文章数量较多，但针对Oracle局限性的实际研究却相对匮乏。有趣的是，在环境、社会和治理（ESG）报告方面，已经出现了针对Oracle局限性的解决方法，其中许可链被视为安全存储可持续性数据的有效支持方案。 <div>
arXiv:2412.20447v1 Announce Type: new 
Abstract: The Bitcoin Network is a sophisticated accounting system that allows its underlying cryptocurrency to be trusted even in the absence of a reliable financial authority. Given its undeniable success, the technology, generally referred to as blockchain, has also been proposed as a means to improve legacy accounting systems. Accounting for real-world data, however, requires the intervention of a third party known as an Oracle, which, having not the same characteristics as a blockchain, could potentially reduce the expected integration benefit. Through a systematic review of the literature, this study aims to investigate whether the papers concerning blockchain integration in accounting consider and address the limitations posed by oracles. A broad overview of the limitations that emerged in the literature is provided and distinguished according to the specific accounting integration. Results support the view that although research on the subject counts numerous articles, actual studies considering oracle limitations are lacking. Interestingly, despite the scarce production of papers addressing oracles in various accounting sectors, reporting for ESG already shows interesting workarounds for oracle limitations, with permissioned chains envisioned as a valid support for the safe storage of sustainability data.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game Theory and Multi-Agent Reinforcement Learning : From Nash Equilibria to Evolutionary Dynamics</title>
<link>https://arxiv.org/abs/2412.20523</link>
<guid>https://arxiv.org/abs/2412.20523</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、强化学习、非平稳性、部分可观测性、大规模代理

总结:

本文探讨了基于先前工作的复杂多智能体系统的高级主题。首先关注了多智能体强化学习（MARL）中的四个核心挑战：非平稳性、部分可观测性、大规模代理群体的可扩展性以及去中心化学习。文章对旨在解决这些挑战的近期算法进展提供了数学表述和分析，并特别强调了它们与博弈论概念的融合。研究内容涉及纳什均衡、演化博弈理论、相关平衡以及对抗性动态如何有效地融入MARL算法以优化学习结果。通过全面的分析，本论文展示了博弈论与MARL相结合如何提升复杂动态环境中多智能体系统的稳健性和有效性。 <div>
arXiv:2412.20523v1 Announce Type: new 
Abstract: This paper explores advanced topics in complex multi-agent systems building upon our previous work. We examine four fundamental challenges in Multi-Agent Reinforcement Learning (MARL): non-stationarity, partial observability, scalability with large agent populations, and decentralized learning. The paper provides mathematical formulations and analysis of recent algorithmic advancements designed to address these challenges, with a particular focus on their integration with game-theoretic concepts. We investigate how Nash equilibria, evolutionary game theory, correlated equilibrium, and adversarial dynamics can be effectively incorporated into MARL algorithms to improve learning outcomes. Through this comprehensive analysis, we demonstrate how the synthesis of game theory and MARL can enhance the robustness and effectiveness of multi-agent systems in complex, dynamic environments.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Empowered Cyber-Secure Federated Learning for Trustworthy Edge Computing</title>
<link>https://arxiv.org/abs/2412.20674</link>
<guid>https://arxiv.org/abs/2412.20674</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 恶意攻击, 可信性, 公平性, 安全认证

总结:
本文提出了一种跨设备的联邦学习模型，旨在确保联邦学习训练过程中的可信性、公平性和安全认证。首先，通过构建基于贡献度的声誉信任模型来保障可信性，该模型衡量各参与节点对模型收敛的贡献。其次，利用异常检测技术识别并剔除恶意参与者，以确保训练过程的公平性。再次，采用分布式传感机制为每个参与设备生成唯一标识令牌，并将其存储在区块链智能合约中，以此建立安全认证机制。最后，将所有参与者的信任评分存入区块链，并结合多种共识机制验证其信誉，从而进一步增强系统的整体安全性与可靠性。 <div>
arXiv:2412.20674v1 Announce Type: new 
Abstract: Federated Learning (FL) is a privacy-preserving distributed machine learning scheme, where each participant data remains on the participating devices and only the local model generated utilizing the local computational power is transmitted throughout the database. However, the distributed computational nature of FL creates the necessity to develop a mechanism that can remotely trigger any network agents, track their activities, and prevent threats to the overall process posed by malicious participants. Particularly, the FL paradigm may become vulnerable due to an active attack from the network participants, called a poisonous attack. In such an attack, the malicious participant acts as a benign agent capable of affecting the global model quality by uploading an obfuscated poisoned local model update to the server. This paper presents a cross-device FL model that ensures trustworthiness, fairness, and authenticity in the underlying FL training process. We leverage trustworthiness by constructing a reputation-based trust model based on contributions of agents toward model convergence. We ensure fairness by identifying and removing malicious agents from the training process through an outlier detection technique. Further, we establish authenticity by generating a token for each participating device through a distributed sensing mechanism and storing that unique token in a blockchain smart contract. Further, we insert the trust scores of all agents into a blockchain and validate their reputations using various consensus mechanisms that consider the computational task.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Infrastructure for Systematically Collecting Smart Contract Lineages for Analyses</title>
<link>https://arxiv.org/abs/2412.20866</link>
<guid>https://arxiv.org/abs/2412.20866</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contract, evolution, blockchain, SCLineage, SCLineageSet

总结:
针对智能合约演进跟踪的挑战，该文提出了一种名为SCLineage的自动化基础设施，用于准确识别和收集智能合约的版本关联关系（即合约血统）。由于区块链技术的不可变性导致每次智能合约更新都在新地址部署，现有平台如Etherscan无法追踪合约间的继承关系。为了解决这一问题并支持研究社区构建可靠的多版本智能合约数据集，文中还推出了一个名为SCLineageSet的最新开源数据集，以促进对智能合约演进的深入研究。通过一个利用局部敏感哈希（LSH）构建合约血统的案例研究，文章展示了SCLineage在软件工程研究中的应用潜力及其对未来领域研究的重要价值。 <div>
arXiv:2412.20866v1 Announce Type: new 
Abstract: Tracking the evolution of smart contracts is a significant challenge, impeding on the advancement of research on smart contract analysis. Indeed, due to the inherent immutability of the underlying blockchain technology, each smart contract update results in a deployment at a new address, breaking the links between versions. Existing platforms like Etherscan lack the capability to trace the predecessor-successor relationships within a smart contract lineage, further hindering empirical research on contract evolution.
  We address this challenge for the research community towards building a reliable dataset of linked versions for various smart contracts, i.e., lineages: we introduce SCLineage, an automated infrastructure that accurately identifies and collects smart contract lineages by leveraging proxy contracts. We present SCLineageSet, an up-to-date, open-source dataset that facilitates extensive research on smart contract evolution. We illustrate the applicability of our proposal in software engineering research through a case study that explores the evaluation of Locality-Sensitive Hashing (LSH) for forming contract lineages. This example underscores how SCLineage provides valuable insights for future research in the field.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Aware Multi-Device Cooperative Edge Inference with Distributed Resource Bidding</title>
<link>https://arxiv.org/abs/2412.21069</link>
<guid>https://arxiv.org/abs/2412.21069</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile Edge Computing (MEC)，Artificial Intelligence (AI)，Data Privacy，Distributed Bidding Mechanism，Decentralized Partially Observable Markov Decision Process (DEC-POMDP)

<br /><br />总结:
本文提出了一种隐私意识强的多设备协同边缘推理系统，用于分类任务，该系统结合了分布式竞标机制以获取MEC服务器的计算资源。为了减少数据隐私泄露，采用了中间特征压缩方法。为了解决分布式环境下的决策问题，文章构建了一个分散式的部分可观测马尔可夫决策过程（DEC-POMDP）模型，并开发了一种基于多智能体深度确定性策略梯度（MADDPG）的算法来确定投标值和特征压缩比率。模拟结果显示，提出的算法在保护数据隐私的同时，能够有效提升协作边缘推理的准确性。在确保足够水平的数据隐私保护下，与忽略无线信道条件的方法相比，该算法可以使分类准确率提高0.31%-0.95%。进一步考虑推断数据的难度后，性能提升了1.54%-1.67%。 <div>
arXiv:2412.21069v1 Announce Type: new 
Abstract: Mobile edge computing (MEC) has empowered mobile devices (MDs) in supporting artificial intelligence (AI) applications through collaborative efforts with proximal MEC servers. Unfortunately, despite the great promise of device-edge cooperative AI inference, data privacy becomes an increasing concern. In this paper, we develop a privacy-aware multi-device cooperative edge inference system for classification tasks, which integrates a distributed bidding mechanism for the MEC server's computational resources. Intermediate feature compression is adopted as a principled approach to minimize data privacy leakage. To determine the bidding values and feature compression ratios in a distributed fashion, we formulate a decentralized partially observable Markov decision process (DEC-POMDP) model, for which, a multi-agent deep deterministic policy gradient (MADDPG)-based algorithm is developed. Simulation results demonstrate the effectiveness of the proposed algorithm in privacy-preserving cooperative edge inference. Specifically, given a sufficient level of data privacy protection, the proposed algorithm achieves 0.31-0.95% improvements in classification accuracy compared to the approach being agnostic to the wireless channel conditions. The performance is further enhanced by 1.54-1.67% by considering the difficulties of inference data.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Mixture-of-Agents for Edge Inference with Large Language Models</title>
<link>https://arxiv.org/abs/2412.21200</link>
<guid>https://arxiv.org/abs/2412.21200</guid>
<content:encoded><![CDATA[
<div> 关键词: Mixture-of-Agents (MoA)，大型语言模型 (LLMs)，分布式设置，边缘计算，队列稳定性条件

<br /><br />总结:
本文提出了一种在分布式环境下的混合智能体(MoA)架构，利用多个运行在用户专属边缘设备上的独立大型语言模型(LLMs)进行协同推理，以提高对用户提示的响应质量。每个设备利用去中心化的八卦算法交换信息，无需中央服务器监督。考虑到了设备内存限制问题，文章理论上计算了在合理假设下保持设备队列稳定性的条件并通过实验验证。此外，通过使用开源LLMs实现的分布式MoA实验，证明了某些配置可以产生比其他配置更高质量的回答，实验结果基于AlpacaEval 2.0基准进行评估。相关代码已开源，可在https://github.com/purbeshmitra/distributed_moa找到。 <div>
arXiv:2412.21200v1 Announce Type: new 
Abstract: Mixture-of-Agents (MoA) has recently been proposed as a method to enhance performance of large language models (LLMs), enabling multiple individual LLMs to work together for collaborative inference. This collaborative approach results in improved responses to user prompts compared to relying on a single LLM. In this paper, we consider such an MoA architecture in a distributed setting, where LLMs operate on individual edge devices, each uniquely associated with a user and equipped with its own distributed computing power. These devices exchange information using decentralized gossip algorithms, allowing different device nodes to talk without the supervision of a centralized server. In the considered setup, different users have their own LLM models to address user prompts. Additionally, the devices gossip either their own user-specific prompts or augmented prompts to generate more refined answers to certain queries. User prompts are temporarily stored in the device queues when their corresponding LLMs are busy. Given the memory limitations of edge devices, it is crucial to ensure that the average queue sizes in the system remain bounded. In this paper, we address this by theoretically calculating the queuing stability conditions for the device queues under reasonable assumptions, which we validate experimentally as well. Further, we demonstrate through experiments, leveraging open-source LLMs for the implementation of distributed MoA, that certain MoA configurations produce higher-quality responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The implementation is available at: https://github.com/purbeshmitra/distributed_moa.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Upper Confidence Bound Algorithms for Homogeneous Multi-Agent Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2111.10933</link>
<guid>https://arxiv.org/abs/2111.10933</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、分布式、同质化多臂老虎机问题、上界置信区间算法、图网络

总结:
本文研究了一个多智能体网络中的分布式同质化多臂老虎机问题。在这个问题中，N个智能体假设他们面对相同的M个手臂，并共享相同的奖励分布。每个智能体只能从其邻居处获取信息，而智能体间的邻居关系由一个固定的图描述。文章提出了两种适用于无向图的完全分布式上界置信区间（UCB）算法，分别基于经典的UCB算法和先进的Kullback-Leibler UCB算法。提出的分布式UCB1和KL-UCB算法确保了当每个智能体至少有一个邻居时，它们能够实现比单智能体更好的对数渐近遗憾性能；并且一个智能体的邻居越多，它的遗憾性能越好，这意味着整体表现优于各部分之和。此外，相同的设计框架也被扩展到有向图，通过设计一种分布式UCB1算法的变种，该算法在性能上优于单智能体的UCB1算法。 <div>
arXiv:2111.10933v4 Announce Type: replace 
Abstract: This paper studies a decentralized homogeneous multi-armed bandit problem in a multi-agent network. The problem is simultaneously solved by $N$ agents assuming they face a common set of $M$ arms and share the same arms' reward distributions. Each agent can receive information only from its neighbors, where the neighbor relationships among the agents are described by a fixed graph. Two fully decentralized upper confidence bound (UCB) algorithms are proposed for undirected graphs, respectively based on the classic algorithm and the state-of-the-art Kullback-Leibler upper confidence bound (KL-UCB) algorithm. The proposed decentralized UCB1 and KL-UCB algorithms permit each agent in the network to achieve a better logarithmic asymptotic regret than their single-agent counterparts, provided that the agent has at least one neighbor, and the more neighbors an agent has, the better regret it will have, meaning that the sum is more than its component parts. The same algorithm design framework is also extended to directed graphs through the design of a variant of the decentralized UCB1 algorithm, which outperforms the single-agent UCB1 algorithm.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Partially Labeled Data: A Conditional Distillation Approach</title>
<link>https://arxiv.org/abs/2412.18833</link>
<guid>https://arxiv.org/abs/2412.18833</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗影像、联合学习（Federated Learning）、部分标注、条件蒸馏（Conditional Distillation）、ConDistFL

<br /><br />总结:
本文提出了一种名为ConDistFL的新型联邦学习框架，旨在解决医疗影像领域中多器官与病灶分割的问题。针对现有联合学习方法在处理部分标注数据时易导致模型分歧和灾难性遗忘的挑战，ConDistFL引入了条件蒸馏技术，有效利用分布式和非均匀数据集中的部分标注信息，显著提高了分割准确性。此外，ConDistFL保持了计算和通信效率，适合于现实世界的隐私保护应用。实验表明，ConDistFL不仅在内部联合会话中展现出优越的分割性能，而且在对外部未参与联合会话的数据（如不同对比度阶段的CT图像）也有出色的泛化能力。通过在3D CT和2D胸部X光数据集上的广泛评估，ConDistFL被证实是一种高效、适应性强的解决方案，适用于隐私受限环境下的医疗影像协同分割任务。 <div>
arXiv:2412.18833v1 Announce Type: new 
Abstract: In medical imaging, developing generalized segmentation models that can handle multiple organs and lesions is crucial. However, the scarcity of fully annotated datasets and strict privacy regulations present significant barriers to data sharing. Federated Learning (FL) allows decentralized model training, but existing FL methods often struggle with partial labeling, leading to model divergence and catastrophic forgetting. We propose ConDistFL, a novel FL framework incorporating conditional distillation to address these challenges. ConDistFL enables effective learning from partially labeled datasets, significantly improving segmentation accuracy across distributed and non-uniform datasets. In addition to its superior segmentation performance, ConDistFL maintains computational and communication efficiency, ensuring its scalability for real-world applications. Furthermore, ConDistFL demonstrates remarkable generalizability, significantly outperforming existing FL methods in out-of-federation tests, even adapting to unseen contrast phases (e.g., non-contrast CT images) in our experiments. Extensive evaluations on 3D CT and 2D chest X-ray datasets show that ConDistFL is an efficient, adaptable solution for collaborative medical image segmentation in privacy-constrained settings.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Swarm Contract: A Multi-Sovereign Agent Consensus Mechanism</title>
<link>https://arxiv.org/abs/2412.19256</link>
<guid>https://arxiv.org/abs/2412.19256</guid>
<content:encoded><![CDATA[
<div> 关键词：Swarm Contract、智能合约、区块链、可信执行环境、多代理机制

<br /><br />总结:
本文提出了一种名为“Swarm Contract”(Swarm)的概念，这是一种利用多代理机制处理复杂任务的新颖方式。Swarm合同集合了多个数字生命体(DLF)或自主代理(SA)，它们在可信执行环境中(TEE)共同处理大规模离链数据、动态多步骤工作流程和需要高度灵活性或迭代更新的情况。通过在链上使用简单的多签名钱包，Swarm将大部分逻辑移至链下，通过多代理共识实现最小信任，而非依赖单一的链上智能合约。文中以轻量级的离链拍卖示例——铸造并销售10,000个相同的NFT——展示了如何利用离链协调确定清算价格和完成分配，每个步骤由多个在TEE中的代理共同执行。这种方法扩展了去中心化和无需信任解决方案的应用范围，可能对DAO治理、多模态数据分析和跨链互操作性等领域产生潜在益处。 <div>
arXiv:2412.19256v1 Announce Type: new 
Abstract: Traditional smart contracts on blockchains excel at on-chain, deterministic logic. However, they have inherent limitations when dealing with large-scale off-chain data, dynamic multi-step workflows, and scenarios requiring high flexibility or iterative updates. In this paper, we propose the concept of a "Swarm Contract" (Swarm), a multi-agent mechanism wherein several digital life forms (DLF) or Sovereign Agents (SA) collectively handle complex tasks in Trusted Execution Environments (TEE). These digital entities are defined as autonomous software agents that own their code, state, and possibly on-chain assets, while operating free from centralized control.
  By leveraging a simple multi-signature wallet on-chain, Swarm moves most of the logic off-chain, achieving trust minimization through multi-agent consensus rather than a single monolithic on-chain contract. We illustrate these ideas with a lightweight off-chain auction example - minting and selling 10,000 identical NFTs - to showcase how off-chain coordination can determine a clearing price and finalize distribution, with each step performed collectively by multiple agents in TEE. This approach broadens the scope of trustless and decentralized solutions, potentially benefiting DAO governance, multi-modal data processing, and cross-chain interoperability.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mobile Traffic Prediction at the Edge Through Distributed and Deep Transfer Learning</title>
<link>https://arxiv.org/abs/2310.14456</link>
<guid>https://arxiv.org/abs/2310.14456</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通预测, 人工智能, 边缘计算, 深度迁移学习, 能耗优化

总结:<br />
本文探讨了一种基于边缘计算和深度迁移学习的完全去中心化的移动流量预测方案，旨在通过使数据保留在本地以减少能耗并通过基站站点间的协作进行优化。研究提出了一种新颖的预测框架，利用大规模测量活动获取的边缘数据集训练两种主要的深度学习架构：卷积神经网络（CNNs）和循环神经网络（RNNs）。模拟结果显示，CNN架构在准确性和能耗方面优于RNNs。在所有情况下，深度迁移学习能提升85%的准确性，并显著降低CNNs和RNNs的训练过程中的计算复杂度和能耗，分别减少了60%和90%的能量消耗。最后，文章还应用了两种先进的可解释人工智能技术来解析所得到的学习模型。 <div>
arXiv:2310.14456v2 Announce Type: replace 
Abstract: Traffic prediction represents one of the crucial tasks for smartly optimizing the mobile network. Recently, Artificial Intelligence (AI) has attracted attention to solve this problem thanks to its ability in cognizing the state of the mobile network and make intelligent decisions. Research on this topic has concentrated on making predictions in a centralized fashion, i.e., by collecting data from the different network elements and process them in a cloud center. This translates into inefficiencies due to the large amount of data transmissions and computations required, leading to high energy consumption. In this work, we investigate a fully decentralized AI solution for mobile traffic prediction that allows data to be kept locally, reducing energy consumption through collaboration among the base station sites. To do so, we propose a novel prediction framework based on edge computing and Deep Transfer Learning (DTL) techniques, using datasets obtained at the edge through a large measurement campaign. Two main Deep Learning architectures are designed based on Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) and tested under different training conditions. Simulation results show that the CNN architectures outperform the RNNs in accuracy and consume less energy. In both scenarios, DTL contributes to an accuracy enhancement in 85% of the examined cases compared to their stand-alone counterparts. Additionally, DTL significantly reduces computational complexity and energy consumption during training, resulting in a reduction of the energy footprint by 60% for CNNs and 90% for RNNs. Finally, two cutting-edge eXplainable Artificial Intelligence techniques are employed to interpret the derived learning models.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PHICOIN (PHI): The Proof of Work High-Performance Infrastructure</title>
<link>https://arxiv.org/abs/2412.17979</link>
<guid>https://arxiv.org/abs/2412.17979</guid>
<content:encoded><![CDATA[
<div> 关键词：PHICOIN (PHI)，Proof-of-Work (PoW)，ASIC，FPGA，去中心化

总结:<br />
PHICOIN（PHI）是一种基于工作量证明（PoW）机制的高性能加密货币。它旨在通过改进和创新的挖矿算法及公平设计原则，为普通用户提供参与去中心化的机遇。PHI着重解决加密货币挖矿中的中心化问题，增强了对ASIC和FPGA设备的抵抗能力，促进了更为公平的参与。本文概述了PHI的技术规格、使命以及路线图，强调其有潜力成为PoW加密货币的基础性基础设施。 <div>
arXiv:2412.17979v1 Announce Type: new 
Abstract: PHICOIN (PHI) is a high-performance cryptocurrency based on the Proof-of-Work (PoW) mechanism. It aims to provide ordinary users with decentralized participation opportunities through an improved and innovative mining algorithm and fair design principles. PHI addresses the challenges of centralization in cryptocurrency mining by enhancing resistance to ASIC and FPGA devices and promoting fair participation. This paper outlines the technical specifications, mission, and roadmap for PHI, highlighting its potential to become a foundational infrastructure for PoW cryptocurrencies.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Driven Research in Personality-Based Distributed Pair Programming</title>
<link>https://arxiv.org/abs/2412.18066</link>
<guid>https://arxiv.org/abs/2412.18066</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、人格基础、配对编程、Role-Optimization Motivation Alignment (ROMA)框架、Solana区块链

总结:
该研究旨在将区块链技术融入基于人格特质的配对编程研究中，以增强其普适性和适应性，通过内置的持续、可重复和透明的研究方式。研究提出了一种名为Role-Optimization Motivation Alignment (ROMA)的框架，将人类/AI编程角色与个体的大五人格特质相对应，以此优化个人动机并提高小型实体和本科课程中的团队生产力。进行了12个分布式设置下的准实验会话来验证基于人格的配对编程有效性。研究采用混合方法，结合了内在动机量表和定性见解，并将数据透明地存储在Solana区块链上。使用Rust和TypeScript语言开发了一个基于Web的应用程序，用于根据ROMA建议、专业知识和可用性进行伙伴匹配。结果表明，区块链可以提升研究的普遍性、可复制性和透明度，而ROMA可以提高个人动机和团队绩效。未来的工作可以关注于集成智能合约以实现透明化和版本化的数据分析。 <div>
arXiv:2412.18066v1 Announce Type: new 
Abstract: This study aims to integrate blockchain technology into personality-based pair programming research to enhance its generalizability and adaptability by offering built-in continuous, reproducible, and transparent research. In the developing Role-Optimization Motivation Alignment (ROMA) framework, human/AI programming roles align with individual Big Five personality traits, optimizing individual motivation and team productivity in Very Small Entities and undergraduate courses. Twelve quasi-experimental sessions were conducted to verify the personality-based pair programming in distributed settings. A mixed-methods approach was employed, combining intrinsic motivation inventories and qualitative insights. Data were stored transparently on the Solana blockchain, and a web-based application was developed in Rust and TypeScript languages to facilitate partner matching based on ROMA suggestions, expertise, and availability. The results suggest that blockchain can enhance research generalizability, reproducibility, and transparency, while ROMA can increase individual motivation and team performance. Future work can focus on integrating smart contracts for transparent and versioned data analysis.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Competition to Centralization: The Oligopoly in Ethereum Block Building Auctions</title>
<link>https://arxiv.org/abs/2412.18074</link>
<guid>https://arxiv.org/abs/2412.18074</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum, Proposer-Builder Separation (PBS), MEV-Boost拍卖, 网络延迟, 中心化

总结:
本文探讨了以太坊区块生产过程中的Proposer-Builder Separation (PBS)机制，这是一种基于拍卖的流程，其中验证者可以将区块生产外包给构建者并通过MEV-Boost拍卖从构建者的竞标中获取Maximal Extractable Value (MEV)收益。通过实证博弈论分析，研究发现网络延迟和MEV机会访问优势对构建者在MEV-Boost拍卖中的投标策略和拍卖结果有显著影响。研究揭示了一个寡头动态现象：少数具备低延迟和丰富MEV资源的主导构建者受益于规模经济效应，强化了其市场力量，导致区块建造市场的中心化加剧和拍卖效率降低。这突显了公平分配构建者之间的MEV以及持续改善以太坊区块构建市场去中心化的挑战。 <div>
arXiv:2412.18074v1 Announce Type: new 
Abstract: The Ethereum block production process has evolved with the introduction of an auction-based mechanism known as Proposer-Builder Separation (PBS), allowing validators to outsource block production to builders and reap Maximal Extractable Value (MEV) revenue from builder bids in a decentralized market. In this market, builders compete in MEV-Boost auctions to have their blocks selected and earn potential MEV rewards. This paper employs empirical game-theoretic analysis to explore builders' strategic bidding incentives in MEV-Boost auctions, focusing on how advantages in network latency and access to MEV opportunities affect builders' bidding behaviors and auction outcomes. Our findings confirm an oligopolistic dynamic, where a few dominant builders, leveraging their advantages in latency and MEV access, benefit from an economy of scale that reinforces their market power, leading to increased centralization and reduced auction efficiency. Our analysis highlights the importance of fair MEV distribution among builders and the ongoing challenge of enhancing decentralization in the Ethereum block building market.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>XSema: A Novel Framework for Semantic Extraction of Cross-chain Transactions</title>
<link>https://arxiv.org/abs/2412.18129</link>
<guid>https://arxiv.org/abs/2412.18129</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链平台、跨链桥技术、交易语义、XSema、安全性检测

总结:
随着区块链平台数量的增长，独立网络间的资产和信息转移成为一个挑战，为此，跨链桥技术应运而生，通过建立通信协议促进跨链交互。然而，跨链交易的安全监管复杂性增加，需要超越传统单链检测方法的理解。本文提出了专门针对跨链环境设计的资产转移与消息传递为基础的跨链语义提取框架——XSema。实验表明，XSema在区分跨链与非跨链交易方面表现优越，对于泛化性和一般性指标分别超过现有方法9%和10%以上。此外，通过对跨链交易中的资产转移模式和消息传递事件日志进行分析，该研究为理解多区块链共存及跨链生态系统提供了新的洞见。 <div>
arXiv:2412.18129v1 Announce Type: new 
Abstract: As the number of blockchain platforms continues to grow, the independence of these networks poses challenges for transferring assets and information across chains. Cross-chain bridge technology has emerged to address this issue, establishing communication protocols to facilitate cross-chain interaction of assets and information, thereby enhancing user experience. However, the complexity of cross-chain transactions increases the difficulty of security regulation, rendering traditional single-chain detection methods inadequate for cross-chain scenarios. Therefore, understanding cross-chain transaction semantics is crucial, as it forms the foundation for cross-chain security detection tasks. Although there are existing methods for extracting transaction semantics specifically for single chains, these approaches often overlook the unique characteristics of cross-chain scenarios, limiting their applicability. This paper introduces XSema, a novel cross-chain semantic extraction framework grounded in asset transfer and message-passing, designed specifically for cross-chain contexts. Experimental results demonstrate that XSema effectively distinguishes between cross-chain and non-cross-chain transactions, surpassing existing methods by over 9% for the generality metric and over 10% for the generalization metric. Furthermore, we analyze the underlying asset transfer patterns and message-passing event logs associated with cross-chain transactions. We offer new insights into the coexistence of multiple blockchains and the cross-chain ecosystem.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>JANUS: A Stablecoin 3.0 Blueprint for Navigating the Stablecoin Trilemma Through Dual-Token Design, Multi-Collateralization, Soft Peg, and AI-Driven Stabilization</title>
<link>https://arxiv.org/abs/2412.18182</link>
<guid>https://arxiv.org/abs/2412.18182</guid>
<content:encoded><![CDATA[
<div> 关键词：JANUS、稳定币3.0协议、双代币系统、AI驱动、资本效率

总结:
本文介绍了JANUS，一个旨在同时解决稳定币三难困境——提高去中心化(D)、资本效率(E)和安全性稳定性(S)的稳定币3.0协议。JANUS基于前几代稳定币的经验，采用双代币系统(Alpha 和 Omega)，整合加密资产与现实世界资产(RWAs)，利用软挂钩机制，并运用AI驱动的稳定策略。文章构建了全面的理论框架，对D、E、S进行了正式定义，并证明了均衡存在的可能性，同时借鉴了国际贸易和开放经济宏观经济学的类比。通过引入由外部收益支持的第二代币，JANUS摆脱了庞氏动态，形成了更为稳健的基础。多抵押和软挂钩允许控制价格波动，而AI驱动的参数调整则能维持平衡。通过这些创新，JANUS力求接近稳定币三难困境的最优解，为DeFi和TradFi之间提供一个全球抗风险、通胀调整及去中心化的稳定币生态系统。正文部分概述了三难困境和JANUS的关键特点，附录中提供了更正式的数学处理，包括对去中心化、资本效率和稳定性的严格度量以及三难困境内在的优化挑战。 <div>
arXiv:2412.18182v1 Announce Type: new 
Abstract: This paper introduces JANUS, a Stablecoin 3.0 protocol designed to address the stablecoin trilemma--simultaneously improving decentralization (D), capital efficiency (E), and safety-stability (S). Building upon insights from previous stablecoin generations, JANUS leverages a dual-token system (Alpha and Omega), integrates crypto-assets and real-world assets (RWAs), employs a soft-peg mechanism, and utilizes AI-driven stabilization.
  We provide a comprehensive theoretical framework, including formal definitions of D, E, and S, along with equilibrium existence proofs and analogies drawn from international trade and open-economy macroeconomics. By introducing a second token backed by external yield, JANUS breaks from ponzinomic dynamics and creates a more robust foundation. Multi-collateralization and a soft peg enable controlled price oscillations, while AI-driven parameter adjustments maintain equilibrium.
  Through these innovations, JANUS aims to approach the center of the stablecoin trilemma, offering a globally resilient, inflation-adjusted, and decentralized stablecoin ecosystem bridging DeFi and TradFi. The main body presents a high-level overview of the trilemma and JANUS's key features, while the Appendix provides more formal mathematical treatments, including rigorous metrics for decentralization, capital efficiency, and stability, as well as the optimization challenges inherent in the trilemma.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining GPT and Code-Based Similarity Checking for Effective Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2412.18225</link>
<guid>https://arxiv.org/abs/2412.18225</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、智能合约、漏洞检测、SimilarGPT、生成预训练变换器（GPT）、代码相似性检查、安全性审计、潜在漏洞、逻辑连贯性、误报、第三方库代码、深度分析、实验结果

<br /><br />总结：
本文介绍了SimilarGPT，这是一个针对智能合约的独特漏洞识别工具，它结合了生成预训练变换器（GPT）模型与基于代码的相似性检查方法。该工具通过衡量待检代码与第三方安全库代码之间的相似度来寻找潜在漏洞，将大型语言模型（LLMs）的语义理解能力与代码相似性检查技术相结合，优化检测序列以提高逻辑连贯性和减少误报。SimilarGPT通过对智能合约中代码重用模式的分析和处理大量第三方库代码，建立了一个全面的参考代码库，并利用LLM对相似代码进行深入分析，从而能有效地识别并解释代码中的潜在漏洞。实验结果显示，SimilarGPT在检测智能合约中的漏洞方面表现出色，尤其是在减少漏检和降低误报方面具有优势。 <div>
arXiv:2412.18225v1 Announce Type: new 
Abstract: With the rapid growth of blockchain technology, smart contracts are now crucial to Decentralized Finance (DeFi) applications. Effective vulnerability detection is vital for securing these contracts against hackers and enhancing the accuracy and efficiency of security audits. In this paper, we present SimilarGPT, a unique vulnerability identification tool for smart contract, which combines Generative Pretrained Transformer (GPT) models with Code-based similarity checking methods. The main concept of the SimilarGPT tool is to measure the similarity between the code under inspection and the secure code from third-party libraries. To identify potential vulnerabilities, we connect the semantic understanding capability of large language models (LLMs) with Code-based similarity checking techniques. We propose optimizing the detection sequence using topological ordering to enhance logical coherence and reduce false positives during detection. Through analysis of code reuse patterns in smart contracts, we compile and process extensive third-party library code to establish a comprehensive reference codebase. Then, we utilize LLM to conduct an indepth analysis of similar codes to identify and explain potential vulnerabilities in the codes. The experimental findings indicate that SimilarGPT excels in detecting vulnerabilities in smart contracts, particularly in missed detections and minimizing false positives.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Multi-Robot Semantic Navigation Through Multimodal Chain-of-Thought Score Collaboration</title>
<link>https://arxiv.org/abs/2412.18292</link>
<guid>https://arxiv.org/abs/2412.18292</guid>
<content:encoded><![CDATA[
<div> 关键词: 多机器人系统、协同导航、语义探索、分布式规划、Multimodal Chain-of-Thought Co-Navigation (MCoCoNav)

总结:
为提高多机器人在陌生环境中的探索效率，本文提出了一种名为Multimodal Chain-of-Thought Co-Navigation (MCoCoNav)的模块化协作语义导航方法。MCoCoNav利用多模态Chain-of-Thought结合视觉感知与Vision Language Models (VLMs)，通过概率评分评估探索价值，从而降低时间成本并提供稳定输出。同时，通过使用全局语义地图作为通信桥梁，既能减少通信开销，又能整合观察结果。机器人根据反映探索趋势的评分，决定是去探索新的前沿点还是重新访问历史节点。实验在HM3D_v0.2和MP3D数据集上验证了该方法的有效性。相关代码已开源，可在https://github.com/FrankZxShen/MCoCoNav.git获取。 <div>
arXiv:2412.18292v1 Announce Type: new 
Abstract: Understanding how humans cooperatively utilize semantic knowledge to explore unfamiliar environments and decide on navigation directions is critical for house service multi-robot systems. Previous methods primarily focused on single-robot centralized planning strategies, which severely limited exploration efficiency. Recent research has considered decentralized planning strategies for multiple robots, assigning separate planning models to each robot, but these approaches often overlook communication costs. In this work, we propose Multimodal Chain-of-Thought Co-Navigation (MCoCoNav), a modular approach that utilizes multimodal Chain-of-Thought to plan collaborative semantic navigation for multiple robots. MCoCoNav combines visual perception with Vision Language Models (VLMs) to evaluate exploration value through probabilistic scoring, thus reducing time costs and achieving stable outputs. Additionally, a global semantic map is used as a communication bridge, minimizing communication overhead while integrating observational results. Guided by scores that reflect exploration trends, robots utilize this map to assess whether to explore new frontier points or revisit history nodes. Experiments on HM3D_v0.2 and MP3D demonstrate the effectiveness of our approach. Our code is available at https://github.com/FrankZxShen/MCoCoNav.git.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification</title>
<link>https://arxiv.org/abs/2412.18470</link>
<guid>https://arxiv.org/abs/2412.18470</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、庞氏骗局、检测方法、PonziLens+、可视化分析

总结:
随着智能合约的普及，基于区块链的智能庞氏骗局给加密货币投资者带来了重大经济损失。针对这一问题，文章首先通过文献回顾和专家访谈，从智能合约字节码中提取具有语义意义的行为来表征执行行为。进而提出了一种名为PonziLens+的新型视觉分析方法，该方法能够直观并可靠地分析这些执行行为中的庞氏骗局相关特征。PonziLens+具备三个可视化模块，可以逐层详细展示智能合约的所有潜在行为，并突出显示欺诈性特征。通过使用PonziLens+，智能合约投资者和审计员能更自信地识别出任何智能庞氏骗局。为了验证其有效性和可用性，研究者进行了两个案例研究及深入的用户访谈，涉及12位领域专家和普通投资者。结果表明，PonziLens+在有效识别智能庞氏骗局方面表现出了优越性与易用性。

<br /><br /> <div>
arXiv:2412.18470v1 Announce Type: new 
Abstract: With the prevalence of smart contracts, smart Ponzi schemes have become a common fraud on blockchain and have caused significant financial loss to cryptocurrency investors in the past few years. Despite the critical importance of detecting smart Ponzi schemes, a reliable and transparent identification approach adaptive to various smart Ponzi schemes is still missing. To fill the research gap, we first extract semantic-meaningful actions to represent the execution behaviors specified in smart contract bytecodes, which are derived from a literature review and in-depth interviews with domain experts. We then propose PonziLens+, a novel visual analytic approach that provides an intuitive and reliable analysis of Ponzi-scheme-related features within these execution behaviors. PonziLens+ has three visualization modules that intuitively reveal all potential behaviors of a smart contract, highlighting fraudulent features across three levels of detail. It can help smart contract investors and auditors achieve confident identification of any smart Ponzi schemes. We conducted two case studies and in-depth user interviews with 12 domain experts and common investors to evaluate PonziLens+. The results demonstrate the effectiveness and usability of PonziLens+ in achieving an effective identification of smart Ponzi schemes.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PrettiSmart: Visual Interpretation of Smart Contracts via Simulation</title>
<link>https://arxiv.org/abs/2412.18484</link>
<guid>https://arxiv.org/abs/2412.18484</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链技术、可视化、执行模拟、PrettiSmart

总结:
本文提出了一种名为PrettiSmart的新颖可视化方法，旨在通过执行模拟帮助投资者直观并可靠地理解智能合约的行为。面对智能合约的复杂源代码以及实际行为与预期可能存在的差异，该方法开发了一个能够全面捕获多种真实世界智能合约行为的模拟器，涵盖了多个投资者和各种智能合约功能的情况。PrettiSmart包括两个模块：Simulation Overview Module 使用条形码设计，为每次模拟提供视觉概览；Simulation Detail Module 则采用增强型序列设计展示每个模拟中的交易细节，如函数调用序列、数字货币流动及状态变量变化。通过PrettiSmart，投资者可以直观地检查并理解智能合约的工作方式。文章通过两例案例研究和对12位投资者的深度访谈评估了PrettiSmart的有效性和可用性，结果显示PrettiSmart对于简化智能合约解释具有显著作用。 <div>
arXiv:2412.18484v1 Announce Type: new 
Abstract: Smart contracts are the fundamental components of blockchain technology. They are programs to determine cryptocurrency transactions, and are irreversible once deployed, making it crucial for cryptocurrency investors to understand the cryptocurrency transaction behaviors of smart contracts comprehensively. However, it is a challenging (if not impossible) task for investors, as they do not necessarily have a programming background to check the complex source code. Even for investors with certain programming skills, inferring all the potential behaviors from the code alone is still difficult, since the actual behaviors can be different when different investors are involved. To address this challenge, we propose PrettiSmart, a novel visualization approach via execution simulation to achieve intuitive and reliable visual interpretation of smart contracts. Specifically, we develop a simulator to comprehensively capture most of the possible real-world smart contract behaviors, involving multiple investors and various smart contract functions. Then, we present PrettiSmart to intuitively visualize the simulation results of a smart contract, which consists of two modules: The Simulation Overview Module is a barcode-based design, providing a visual summary for each simulation, and the Simulation Detail Module is an augmented sequential design to display the cryptocurrency transaction details in each simulation, such as function call sequences, cryptocurrency flows, and state variable changes. It can allow investors to intuitively inspect and understand how a smart contract will work. We evaluate PrettiSmart through two case studies and in-depth user interviews with 12 investors. The results demonstrate the effectiveness and usability of PrettiSmart in facilitating an easy interpretation of smart contracts.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs</title>
<link>https://arxiv.org/abs/2412.18588</link>
<guid>https://arxiv.org/abs/2412.18588</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、机器人、自然语言、行为约束、公共区块链

总结:
本文探讨了使用大型语言模型（LLMs）控制物理机器人的优势、限制和特点。通过四个LLMs之间的基于人类语言的数据总线（通过WebSocket和ROS2消息传递实现）进行通信，即使数据融合循环仅为1Hz，中央数据总线运行速度极低（接近人脑的约40比特/秒），也能实现丰富的行为和良好的任务表现。自然语言用于LLM间的交流，使得人类可以直观地观察到机器人的思考过程，并能以普通英语编写规则轻松引导系统行为。这些规则被不可变地写入全球公共、抗审查的图灵完备计算机——以太坊中。文章提出，通过将自然语言作为交互AI之间数据总线，并利用不可变的公共区块链存储行为约束，有可能构建出性能出众、可升级并持久符合人类意愿的机器人。 <div>
arXiv:2412.18588v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are compact representations of all public knowledge of our physical environment and animal and human behaviors. The application of LLMs to robotics may offer a path to highly capable robots that perform well across most human tasks with limited or even zero tuning. Aside from increasingly sophisticated reasoning and task planning, networks of (suitably designed) LLMs offer ease of upgrading capabilities and allow humans to directly observe the robot's thinking. Here we explore the advantages, limitations, and particularities of using LLMs to control physical robots. The basic system consists of four LLMs communicating via a human language data bus implemented via web sockets and ROS2 message passing. Surprisingly, rich robot behaviors and good performance across different tasks could be achieved despite the robot's data fusion cycle running at only 1Hz and the central data bus running at the extremely limited rates of the human brain, of around 40 bits/s. The use of natural language for inter-LLM communication allowed the robot's reasoning and decision making to be directly observed by humans and made it trivial to bias the system's behavior with sets of rules written in plain English. These rules were immutably written into Ethereum, a global, public, and censorship resistant Turing-complete computer. We suggest that by using natural language as the data bus among interacting AIs, and immutable public ledgers to store behavior constraints, it is possible to build robots that combine unexpectedly rich performance, upgradability, and durable alignment with humans.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems</title>
<link>https://arxiv.org/abs/2412.18601</link>
<guid>https://arxiv.org/abs/2412.18601</guid>
<content:encoded><![CDATA[
<div> 关键词: GameFi、AI代理、大型语言模型、区块链技术、DeFi机制

总结:<br />
本文提出了一个将高级AI代理集成到GameFi平台以改革游戏金融生态系统的创新方法。这些AI代理利用GPT-4和Claude AI等先进的大型语言模型，实现与玩家的主动、适应性和情境丰富的互动，影响游戏叙事和经济系统。针对现有GameFi平台缺乏沉浸式AI交互和社区参与机制的问题，该生态系统通过深度融合AI代理与区块链技术，创建了一个共识驱动、去中心化的环境，使创作者能够从中获利，并促进玩家与创作者之间的民主协作。此外，通过将DeFi机制嵌入游戏体验中，文章提出的方法增强了经济参与度并为游戏中提供了新的金融互动机会，提升了玩家的沉浸感和留存率。总之，该研究项目显著推动了GameFi领域的前沿发展，为整个游戏行业提供了一种结合智能AI和DeFi元素，打造更富吸引力、经济稳健且以社区为中心的游戏环境的方法论。 <div>
arXiv:2412.18601v1 Announce Type: new 
Abstract: In the rapidly evolving landscape of GameFi, a fusion of gaming and decentralized finance (DeFi), there exists a critical need to enhance player engagement and economic interaction within gaming ecosystems. Our GameFi ecosystem aims to fundamentally transform this landscape by integrating advanced embodied AI agents into GameFi platforms. These AI agents, developed using cutting-edge large language models (LLMs), such as GPT-4 and Claude AI, are capable of proactive, adaptive, and contextually rich interactions with players. By going beyond traditional scripted responses, these agents become integral participants in the game's narrative and economic systems, directly influencing player strategies and in-game economies. We address the limitations of current GameFi platforms, which often lack immersive AI interactions and mechanisms for community engagement or creator monetization. Through the deep integration of AI agents with blockchain technology, we establish a consensus-driven, decentralized GameFi ecosystem. This ecosystem empowers creators to monetize their contributions and fosters democratic collaboration among players and creators. Furthermore, by embedding DeFi mechanisms into the gaming experience, we enhance economic participation and provide new opportunities for financial interactions within the game. Our approach enhances player immersion and retention and advances the GameFi ecosystem by bridging traditional gaming with Web3 technologies. By integrating sophisticated AI and DeFi elements, we contribute to the development of more engaging, economically robust, and community-centric gaming environments. This project represents a significant advancement in the state-of-the-art in GameFi, offering insights and methodologies that can be applied throughout the gaming industry.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision-Making</title>
<link>https://arxiv.org/abs/2308.10721</link>
<guid>https://arxiv.org/abs/2308.10721</guid>
<content:encoded><![CDATA[
<div> 关键词：协调技能、多智能体、独立决策、协同行为、Coordinated QMIX (CoMIX)

总结:<br />
本文提出了一个用于训练分布式代理以实现灵活政策下 Emergent 协调能力的新框架——协调 QMIX（CoMIX）。该框架使代理能够在共享环境中朝着共同目标协同作业，同时允许个体层面的独立决策。CoMIX 将自私和协作行为建模为每个代理决策过程中的增量步骤，从而使代理能够根据不同情境动态调整其行为，平衡独立性和协作性。实验结果表明，CoMIX 在各种模拟环境中在协作任务上优于基线，验证了我们逐步递增方法对于提高多智能体系统中协调性能的有效性。 <div>
arXiv:2308.10721v3 Announce Type: replace 
Abstract: Robust coordination skills enable agents to operate cohesively in shared environments, together towards a common goal and, ideally, individually without hindering each other's progress. To this end, this paper presents Coordinated QMIX (CoMIX), a novel training framework for decentralized agents that enables emergent coordination through flexible policies, allowing at the same time independent decision-making at individual level. CoMIX models selfish and collaborative behavior as incremental steps in each agent's decision process. This allows agents to dynamically adapt their behavior to different situations balancing independence and collaboration. Experiments using a variety of simulation environments demonstrate that CoMIX outperforms baselines on collaborative tasks. The results validate our incremental approach as effective technique for improving coordination in multi-agent systems.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Liquid Staking Tokens (LSTs) and Emerging Trends in Restaking</title>
<link>https://arxiv.org/abs/2404.00644</link>
<guid>https://arxiv.org/abs/2404.00644</guid>
<content:encoded><![CDATA[
<div> 关键词：Liquid staking, Restaking, Liquid Staking Tokens (LSTs), Liquid Restaking Tokens (LRTs), Decentralized Finance (DeFi)

<br /><br />总结:
本文介绍了液态staking及其衍生的restaking在去中心化金融（DeFi）领域的创新应用。文章重点探讨了液态staking协议的技术和经济模型框架，具体分析了包括节点运营商选择、staking奖励分配以及slashing在内的协议机制。通过对液态staking代币(LSTs)性能的实证分析，揭示了协议设计与市场动态对其市场价值的影响。同时，文章讨论了restaking的最新进展及其相关的风险与安全影响，并回顾了液态staking和restaking领域的现有文献。 <div>
arXiv:2404.00644v2 Announce Type: replace 
Abstract: Liquid staking and restaking represent recent innovations in Decentralized Finance (DeFi) that garnered user interest and capital. Liquid Staking Tokens (LSTs), tokenized representations of staked tokens on Proof-of-Stake (PoS) blockchains, are the leading staking method. LSTs offer users the ability to earn staking rewards while maintaining liquidity, enabling seamless integration into DeFi protocols and free tradeability. Restaking builds upon this concept by allowing staked tokens, LSTs or native Bitcoin tokens to secure additional protocols and PoS chains for supplementary rewards. Liquid Restaking Tokens (LRTs) unlock liquidity of restaked assets. This Systematization of Knowledge (SoK) establishes a comprehensive framework for the technical and economic models of liquid staking protocols. Using this framework, we systematically compare protocols mechanics, including node operator selection, staking reward distribution, and slashing. Our empirical analysis of token performance reveals that protocol design and market dynamics impact token market value. We further present the recent developments in restaking and discuss associated risks and security implications. Lastly, we review the emerging literature on liquid staking and restaking.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Neonpool: Reimagining cryptocurrency transaction pools for lightweight clients and IoT devices</title>
<link>https://arxiv.org/abs/2412.16217</link>
<guid>https://arxiv.org/abs/2412.16217</guid>
<content:encoded><![CDATA[
<div> 关键词：Neonpool，交易池，内存优化，Bloom过滤器，加密货币网络

总结:<br />
本文介绍了创新性地使用Bloom过滤器变体进行交易池优化的方案——Neonpool。Neonpool能显著降低加密货币网络中全节点部署的交易池内存占用，其准确率超过99.99%地验证并转发交易，并且无需进行硬分叉。该解决方案特别适合轻量级加密货币客户端以及资源受限的设备，如浏览器、系统芯片、移动设备或物联网设备。<br /> <div>
arXiv:2412.16217v1 Announce Type: new 
Abstract: The transaction pool plays a critical role in processing and disseminating transactions in cryptocurrency networks. However, increasing transaction loads strain the resources of full node deployments. We present \textit{Neonpool}, an innovative transaction pool optimization using bloom filter variants, which reduces the memory footprint of the transaction pool to a fraction. Implemented in C++ and benchmarked using a unique Bitcoin and Ethereum dataset, our solution verifies and forwards transactions with over 99.99\% accuracy and does not necessitate a hard fork. \textit{Neonpool} is ideally suited for lightweight cryptocurrency clients and for resource-constrained devices such as browsers, systems-on-a-chip, mobile or IoT devices.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>"ScatSpotter" 2024 -- A Distributed Dog Poop Detection Dataset</title>
<link>https://arxiv.org/abs/2412.16473</link>
<guid>https://arxiv.org/abs/2412.16473</guid>
<content:encoded><![CDATA[
<div> 关键词: 狗粪图像数据集、人工智能标注、像素精度、分布式发布、环保考量

总结:
本文介绍了新的“活”数据集——一个目前包含42GB的手机拍摄狗粪图像数据库，该库具有手动或AI辅助绘制的多边形标签，共有6k张全分辨率图片和4k个详细注释。自2020年末开始收集与注释工作以来，该数据库每月以约1GB的速度增长。研究者训练了VIT和MaskRCNN基线模型来探索该数据集的难度，最佳模型在包含691张图像的验证集上取得了0.858的像素级平均精度，在独立采集的30张贡献者测试集上达到了0.847。数据集通过三种不同的分布方式（集中式：Girder，分布式：IPFS和BitTorrent）公开提供，并研究了不同方法的优缺点以及在可靠分享开放科学数据方面的可行性。实验代码已在GitHub上托管，数据依照Creative Commons Attribution 4.0 International许可协议发布，同时提供了模型权重。文章还量化了实验硬件、时间、能源消耗及排放量。 <div>
arXiv:2412.16473v1 Announce Type: new 
Abstract: We introduce a new -- currently 42 gigabyte -- ``living'' dataset of phone images of dog feces, annotated with manually drawn or AI-assisted polygon labels. There are 6k full resolution images and 4k detailed polygon annotations. The collection and annotation of images started in late 2020 and the dataset grows by roughly 1GB a month. We train VIT and MaskRCNN baseline models to explore the difficulty of the dataset. The best model achieves a pixelwise average precision of 0.858 on a 691-image validation set and 0.847 on a small independently captured 30-image contributor test set. The most recent snapshot of dataset is made publicly available through three different distribution methods: one centralized (Girder) and two decentralized (IPFS and BitTorrent). We study of the trade-offs between distribution methods and discuss the feasibility of each with respect to reliably sharing open scientific data. The code to reproduce the experiments is hosted on GitHub, and the data is published under the Creative Commons Attribution 4.0 International license. Model weights are made publicly available with the dataset. Experimental hardware, time, energy, and emissions are quantified.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Raft Distributed System for Multi-access Edge Computing Sharing Resources</title>
<link>https://arxiv.org/abs/2412.16774</link>
<guid>https://arxiv.org/abs/2412.16774</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-access Edge Computing, RAFT共识算法, 区块链, Deep Deterministic Policy Gradient (DDPG), 系统延迟

<br /><br />总结:
本文提出了利用RAFT共识算法和区块链技术改进Multi-access Edge Computing (MEC)系统安全性和效率的研究方案。通过引入RAFT共识算法和拍卖理论，使边缘设备能更好地决策如何响应客户端请求。同时，文章还提出使用Deep Deterministic Policy Gradient (DDPG)算法在由N个边缘节点组成的集群中执行任务分配的竞拍过程，以降低整体系统的延迟。该提案假设每个边缘节点都包含一系列待执行的任务，通过实施DDPG算法来决定哪个边缘节点最适合执行客户端提供的任务。 <div>
arXiv:2412.16774v1 Announce Type: new 
Abstract: Researchers all over the world are employing a variety of analysis approaches in attempt to provide a safer and faster solution for sharing resources via a Multi-access Edge Computing system. Multi-access Edge Computing (MEC) is a job-sharing method within the edge server network whose main aim is to maximize the pace of the computing process, resulting in a more powerful and enhanced user experience. Although there are many other options when it comes to determining the fastest method for computing processes, our paper introduces a rather more extensive change to the system model to assure no data loss and/or task failure due to any scrutiny in the edge node cluster. RAFT, a powerful consensus algorithm, can be used to introduce an auction theory approach in our system, which enables the edge device to make the best decision possible regarding how to respond to a request from the client. Through the use of the RAFT consensus, blockchain may be used to improve the safety, security, and efficiency of applications by deploying it on trustful edge base stations. In addition to discussing the best-distributed system approach for our (MEC) system, a Deep Deterministic Policy Gradient (DDPG) algorithm is also presented in order to reduce overall system latency. Assumed in our proposal is the existence of a cluster of N Edge nodes, each containing a series of tasks that require execution. A DDPG algorithm is implemented in this cluster so that an auction can be held within the cluster of edge nodes to decide which edge node is best suited for performing the task provided by the client.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fed-ZOE: Communication-Efficient Over-the-Air Federated Learning via Zeroth-Order Estimation</title>
<link>https://arxiv.org/abs/2412.16779</link>
<guid>https://arxiv.org/abs/2412.16779</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, over-the-air FL (OtA-FL), communication overhead, gradient compression, federated zeroth-order estimation (Fed-ZOE)

总结:

随着6G及未来网络变得日益复杂和互联，联邦学习（FL）作为一种重要范式，可安全高效地利用分布式边缘数据进行AI训练。过空气隙联邦学习（OtA-FL）利用通信信号的叠加性质，实现与边缘设备数量无关的恒定通信开销。然而，空中训练神经网络仍会产生大量通信成本，因为传输符号数量等于可训练参数的数量。为解决此问题，通常采用的方法是通过梯度压缩和梯度稀疏化减少传输符号数，但这些方法与OtA-FL不兼容，会破坏其叠加特性。本文提出了一种名为联邦零阶估计（Fed-ZOE）的新框架，灵感来源于常用于零阶优化（ZOO）的随机梯度估计器（RGE）。在Fed-ZOE中，边缘设备按照标准FL的方式执行本地权重更新，而非发送完整的梯度向量，而是将本地模型更新向量以几个局部模型更新向量与随机向量的标量乘积形式发送给参数服务器（PS）。这些标量值使得PS能够使用RGE技巧以极低开销重构梯度，同时保持叠加属性。与常规利用RGE进行逐步梯度下降的ZOO不同，Fed-ZOE在传输前对本地模型更新向量进行压缩，从而实现更高的准确性和计算效率。数值评估结果显示，在CIFAR-10、TinyImageNet、SVHN、CIFAR-100和Brain-CT等数据集上，Fed-ZOE能够在大幅降低通信成本的同时，达到与Fed-OtA相当的性能。 <div>
arXiv:2412.16779v1 Announce Type: new 
Abstract: As 6G and beyond networks grow increasingly complex and interconnected, federated learning (FL) emerges as an indispensable paradigm for securely and efficiently leveraging decentralized edge data for AI. By virtue of the superposition property of communication signals, over-the-air FL (OtA-FL) achieves constant communication overhead irrespective of the number of edge devices (EDs). However, training neural networks over the air still incurs substantial communication costs, as the number of transmitted symbols equals the number of trainable parameters. To alleviate this issue, the most straightforward approach is to reduce the number of transmitted symbols by 1) gradient compression and 2) gradient sparsification. Unfortunately, these methods are incompatible with OtA-FL due to the loss of its superposition property. In this work, we introduce federated zeroth-order estimation (Fed-ZOE), an efficient framework inspired by the randomized gradient estimator (RGE) commonly used in zeroth-order optimization (ZOO). In FedZOE, EDs perform local weight updates as in standard FL, but instead of transmitting full gradient vectors, they send compressed local model update vectors in the form of several scalar-valued inner products between the local model update vectors and random vectors. These scalar values enable the parameter server (PS) to reconstruct the gradient using the RGE trick with highly reduced overhead, as well as preserving the superposition property. Unlike conventional ZOO leveraging RGE for step-wise gradient descent, Fed-ZOE compresses local model update vectors before transmission, thereby achieving higher accuracy and computational efficiency. Numerical evaluations using ResNet-18 on datasets such as CIFAR-10, TinyImageNet, SVHN, CIFAR-100, and Brain-CT demonstrate that Fed-ZOE achieves performance comparable to Fed-OtA while drastically reducing communication costs.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedCross: Intertemporal Federated Learning Under Evolutionary Games</title>
<link>https://arxiv.org/abs/2412.16968</link>
<guid>https://arxiv.org/abs/2412.16968</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 移动性管理, 通信开销, 动态决策, 奖励分配

<br /><br />总结:
本文提出了一种名为FedCross的跨时间激励框架，用于解决联邦学习（Federated Learning）中因移动设备高流动性、间歇性连接和带宽限制导致的模型更新问题。FedCross分为两个阶段：第一阶段，采用多目标迁移算法优化任务分配，考虑资源约束并利用演化博弈论预测用户比例动态变化以减少频繁迁移；第二阶段，运用采购拍卖机制对基站进行奖励分配，确保提供优质模型的基站得到最优补偿，从而激励用户持续参与并保障FedCross的整体可行性。实验结果验证了FedCross理论上的合理性及其显著降低通信开销的效果。 <div>
arXiv:2412.16968v1 Announce Type: new 
Abstract: Federated Learning (FL) mitigates privacy leakage in decentralized machine learning by allowing multiple clients to train collaboratively locally. However, dynamic mobile networks with high mobility, intermittent connectivity, and bandwidth limitation severely hinder model updates to the cloud server. Although previous studies have typically addressed user mobility issue through task reassignment or predictive modeling, frequent migrations may result in high communication overhead. Overcoming this obstacle involves not only dealing with resource constraints, but also finding ways to mitigate the challenges posed by user migrations. We therefore propose an intertemporal incentive framework, FedCross, which ensures the continuity of FL tasks by migrating interrupted training tasks to feasible mobile devices. Specifically, FedCross comprises two distinct stages. In Stage 1, we address the task allocation problem across regions under resource constraints by employing a multi-objective migration algorithm to quantify the optimal task receivers. Moreover, we adopt evolutionary game theory to capture the dynamic decision-making of users, forecasting the evolution of user proportions across different regions to mitigate frequent migrations. In Stage 2, we utilize a procurement auction mechanism to allocate rewards among base stations, ensuring that those providing high-quality models receive optimal compensation. This approach incentivizes sustained user participation, thereby ensuring the overall feasibility of FedCross. Finally, experimental results validate the theoretical soundness of FedCross and demonstrate its significant reduction in communication overhead.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the ETHOS of AI Agents: An Ethical Technology and Holistic Oversight System</title>
<link>https://arxiv.org/abs/2412.17114</link>
<guid>https://arxiv.org/abs/2412.17114</guid>
<content:encoded><![CDATA[
<div> 关键词：AI治理、Web3技术、区块链、智能合约、去中心化自治组织<br /><br />总结:
在未来日益由机器智能定义的世界中，如何管理和整合AI进入社会至关重要。文章指出现有的AI治理体系未能充分应对AI代理的崛起和集中与分散治理模型之间的辩论。为填补这一空白，提出了“伦理技术和全面监督系统”框架（ETHOS），该框架利用Web3技术，包括区块链、智能合约、去中心化自治组织和灵魂绑定代币，建立了一个去中心化的全球AI代理人注册库。ETHOS引入了AI特定法律实体的概念，使这些系统能够承担有限责任并通过保险和合规监控确保问责制。此外，该框架强调需要通过公共教育、透明度和国际协调等方式采取协作参与式的AI治理方法。ETHOS在创新与道德责任之间寻求平衡，为负责任地将AI代理人融入社会提供了前瞻性策略。最后，本文反映了我们所定义的一个新跨学科领域——处于AI、Web3和社会交汇点的系统思维的出现。 <div>
arXiv:2412.17114v1 Announce Type: new 
Abstract: In a world increasingly defined by machine intelligence, the future depends on how we govern the development and integration of AI into society. Recent initiatives, such as the EU AI Act, EDPB opinion, U.S. Bipartisan House Task Force and NIST AI Risk Management Report, highlight the urgent need for robust governance frameworks to address the challenges posed by advancing AI technologies. However, existing frameworks fail to adequately address the rise of AI agents or the ongoing debate between centralized and decentralized governance models. To bridge these gaps, we propose the Ethical Technology and Holistic Oversight System framework, which leverages Web3 technologies, including blockchain, smart contracts, decentralized autonomous organizations, and soulbound tokens, to establish a decentralized global registry for AI agents. ETHOS incorporates the concept of AI specific legal entities, enabling these systems to assume limited liability and ensuring accountability through mechanisms like insurance and compliance monitoring. Additionally, the framework emphasizes the need for a collaborative, participatory approach to AI governance, engaging diverse stakeholders through public education, transparency, and international coordination. ETHOS balances innovation with ethical accountability, providing a forward looking strategy for the responsible integration of AI agents into society. Finally, this exploration reflects the emergence of a new interdisciplinary field we define as Systems Thinking at the Intersection of AI, Web3, and Society.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Synergistic Integration of Blockchain and Software-Defined Networking in the Internet of Energy Systems</title>
<link>https://arxiv.org/abs/2412.17530</link>
<guid>https://arxiv.org/abs/2412.17530</guid>
<content:encoded><![CDATA[
<div> 关键词: Peer-to-peer能源交易, 智能电网, 电动车辆能源管理, 软件定义网络, 区块链

总结:
本文探讨了利用软件定义网络(SDN)和区块链技术在互联网能源(IoE)领域的现状及应用方案。这些方案被归类为两类：一类是以区块链增强SDN，另一类则是同时利用两者来提升解决方案。文章指出了区块链在IoE中的三种应用场景：去中心化SDN控制平面、作为去中心化平台以及加强安全性措施。同时，SDN则分别扮演性能增强器、传统网络替代品和仅作为控制与管理框架的角色。SDN与区块链的融合能在IoE中带来性能提升、增强安全性、实现去中心化操作并消除SDN控制平面中的单点故障问题。然而，也提出了未来可能的研究方向，包括能源效率、智能合约管理和可扩展性等问题。 <div>
arXiv:2412.17530v1 Announce Type: new 
Abstract: Peer-to-peer (P2P) energy trading, Smart Grids (SG), and electric vehicle energy management are integral components of the Internet of Energy (IoE) field. The integration of Software-Defined Networks (SDNs) and Blockchain (BC) technologies into the IoE domain offers potential benefits that have only been studied in the literature in a few works. In this paper, we investigate the state-of-art solutions that leverage both SDNs and blockchain within the realm of the IoE. We categorize these solutions based on the method of integrating SDN and BC into two categories. The first category is the blockchain for SDN, where blockchain enhances the SDN directly. The second category is blockchain and SDN, where both technologies are used to enhance the proposed solutions. We identify three distinct blockchain applications based on their usage: decentralizing the SDN control plane, serving as a decentralized platform, and improving security measures. Similarly, we observe that SDN serves as a performance enhancer, a substitute for traditional networking, and solely as a control and management framework. It is posited that integrating SDNs and blockchain into IoE leads to performance enhancements, improves security, enables decentralized operations, and eliminates single points of failure in the SDN control plane. Additionally, some unaddressed issues, such as energy efficiency, smart contract management, and scalability, are discussed as potential future directions.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.17565</link>
<guid>https://arxiv.org/abs/2412.17565</guid>
<content:encoded><![CDATA[
<div> 关键词: 细胞ular流量预测、机器学习、能源消耗、Spiking神经网络、Echo状态网络

总结:<br />
本文探讨了细胞通信流量预测的重要性及其面临的海量数据处理挑战。研究对比了传统机器学习算法（如卷积神经网络和多层感知机）与两种生物启发式模型——Spiking神经网络(SNNs)和Echo状态网络(ESNs)在预测性能和能效方面的表现。实验在集中式和联邦学习环境中实施这些模型，以分析其在分布式系统中的效果和能耗。结果表明，生物启发式模型能够在保持与传统架构相当的预测精度的同时，显著降低能源消耗。此外，联邦学习实现的能效在分散环境下特别是在与生物启发式模型结合使用时也得到了评估。这些发现为可持续和隐私保护的细胞通信流量预测提供了采用生物启发式模型的潜在价值。 <div>
arXiv:2412.17565v1 Announce Type: new 
Abstract: Cellular traffic forecasting is a critical task that enables network operators to efficiently allocate resources and address anomalies in rapidly evolving environments. The exponential growth of data collected from base stations poses significant challenges to processing and analysis. While machine learning (ML) algorithms have emerged as powerful tools for handling these large datasets and providing accurate predictions, their environmental impact, particularly in terms of energy consumption, is often overlooked in favor of their predictive capabilities. This study investigates the potential of two bio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing through Echo State Networks (ESNs) for cellular traffic forecasting. The evaluation focuses on both their predictive performance and energy efficiency. These models are implemented in both centralized and federated settings to analyze their effectiveness and energy consumption in decentralized systems. Additionally, we compare bio-inspired models with traditional architectures, such as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs), to provide a comprehensive evaluation. Using data collected from three diverse locations in Barcelona, Spain, we examine the trade-offs between predictive accuracy and energy demands across these approaches. The results indicate that bio-inspired models, such as SNNs and ESNs, can achieve significant energy savings while maintaining predictive accuracy comparable to traditional architectures. Furthermore, federated implementations were tested to evaluate their energy efficiency in decentralized settings compared to centralized systems, particularly in combination with bio-inspired models. These findings offer valuable insights into the potential of bio-inspired models for sustainable and privacy-preserving cellular traffic forecasting.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SMAC-Hard: Enabling Mixed Opponent Strategy Script and Self-play on SMAC</title>
<link>https://arxiv.org/abs/2412.17707</link>
<guid>https://arxiv.org/abs/2412.17707</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Reinforcement Learning (MARL)，StarCraft Multi-Agent Challenge (SMAC)，SMAC-HARD，adversarial policies，black-box testing framework

总结:<br />
本文针对多智能体强化学习（MARL）领域中，随着StarCraft Multi-Agent Challenge (SMAC)环境的普及，一些算法已接近最优性能，导致评估准确性降低的问题。文章指出了SMAC环境中默认对手策略缺乏多样性，使得算法倾向于过拟合并利用非预期漏洞而非学习稳健策略。为解决这些问题，研究者提出了SMAC-HARD，一个增强训练鲁棒性和全面性评价的新基准，其特点包括可定制对手策略、敌对策略的随机化以及支持MARL自我对战的接口。此外，他们还引入了一个黑盒测试框架，用于在不暴露于编辑过的对手脚本的情况下训练代理，然后通过这些脚本对其进行测试，以评估MARL算法的策略覆盖范围和适应能力。实验结果显示，SMAC-HARD中的修改和混合策略对手给现有的广泛使用和最先进的算法带来了重大挑战，而黑盒策略测试则表明，将学习到的策略转移到未见过的敌人上具有较大困难。SMAC-HARD被认为是推动下一代MARL算法及其自我对战方法发展的重要里程碑。相关代码已在https://github.com/devindeng94/smac-hard 上公开。 <div>
arXiv:2412.17707v1 Announce Type: new 
Abstract: The availability of challenging simulation environments is pivotal for advancing the field of Multi-Agent Reinforcement Learning (MARL). In cooperative MARL settings, the StarCraft Multi-Agent Challenge (SMAC) has gained prominence as a benchmark for algorithms following centralized training with decentralized execution paradigm. However, with continual advancements in SMAC, many algorithms now exhibit near-optimal performance, complicating the evaluation of their true effectiveness. To alleviate this problem, in this work, we highlight a critical issue: the default opponent policy in these environments lacks sufficient diversity, leading MARL algorithms to overfit and exploit unintended vulnerabilities rather than learning robust strategies. To overcome these limitations, we propose SMAC-HARD, a novel benchmark designed to enhance training robustness and evaluation comprehensiveness. SMAC-HARD supports customizable opponent strategies, randomization of adversarial policies, and interfaces for MARL self-play, enabling agents to generalize to varying opponent behaviors and improve model stability. Furthermore, we introduce a black-box testing framework wherein agents are trained without exposure to the edited opponent scripts but are tested against these scripts to evaluate the policy coverage and adaptability of MARL algorithms. We conduct extensive evaluations of widely used and state-of-the-art algorithms on SMAC-HARD, revealing the substantial challenges posed by edited and mixed strategy opponents. Additionally, the black-box strategy tests illustrate the difficulty of transferring learned policies to unseen adversaries. We envision SMAC-HARD as a critical step toward benchmarking the next generation of MARL algorithms, fostering progress in self-play methods for multi-agent systems. Our code is available at https://github.com/devindeng94/smac-hard.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asynchronous Federated Learning: A Scalable Approach for Decentralized Machine Learning</title>
<link>https://arxiv.org/abs/2412.17723</link>
<guid>https://arxiv.org/abs/2412.17723</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Asynchronous Federated Learning（异步联邦学习）、client delays、model staleness、LSTM

总结:<br />
本文提出了一种名为异步联邦学习（AFL）的新算法，用于解决传统联邦学习中因同步客户端更新导致的可扩展性和效率问题。该算法允许客户端独立并异步地更新全局模型，即使存在客户端延迟和模型陈旧情况也能保证收敛性。通过运用马丁格尔差异序列理论和方差边界，确保了在异步更新下的稳健收敛。研究者在具有随机客户端采样和强凸局部目标函数的假设下，界定了梯度方差，并推导出了量化客户端延迟对收敛影响的递归公式。实验部分展示了AFL在CMIP6气候数据集上训练分布式LSTM深度学习模型的有效性，成功处理非IID和地理分布的数据。AFL解决了传统方法中的全局同步低效和客户端漂移问题，提高了在具有异构客户端群体和动态网络条件的真实场景中的可扩展性、鲁棒性和效率，显示出其在大规模、隐私保护的应用以及资源受限环境中的潜力。 <div>
arXiv:2412.17723v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for decentralized machine learning, enabling collaborative model training across diverse clients without sharing raw data. However, traditional FL approaches often face limitations in scalability and efficiency due to their reliance on synchronous client updates, which can result in significant delays and increased communication overhead, particularly in heterogeneous and dynamic environments. To address these challenges in this paper, we propose an Asynchronous Federated Learning (AFL) algorithm, which allows clients to update the global model independently and asynchronously. Our key contributions include a comprehensive convergence analysis of AFL in the presence of client delays and model staleness. By leveraging martingale difference sequence theory and variance bounds, we ensure robust convergence despite asynchronous updates. Assuming strongly convex local objective functions, we establish bounds on gradient variance under random client sampling and derive a recursion formula quantifying the impact of client delays on convergence. Furthermore, we demonstrate the practical applicability of AFL by training a decentralized Long Short-Term Memory (LSTM)-based deep learning model on the CMIP6 climate dataset, effectively handling non-IID and geographically distributed data.
  The proposed AFL algorithm addresses key limitations of traditional FL methods, such as inefficiency due to global synchronization and susceptibility to client drift. It enhances scalability, robustness, and efficiency in real-world settings with heterogeneous client populations and dynamic network conditions. Our results underscore the potential of AFL to drive advancements in distributed learning systems, particularly for large-scale, privacy-preserving applications in resource-constrained environments.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture</title>
<link>https://arxiv.org/abs/2404.12135</link>
<guid>https://arxiv.org/abs/2404.12135</guid>
<content:encoded><![CDATA[
<div> 关键词：根因分析（RCA）、微服务架构（MSA）、区块链、多智能体、大规模语言模型（LLM）

总结:<br />
本文提出了一种名为mABC的创新框架，用于在具有复杂性的微服务架构中进行根因分析。mABC利用基于大规模语言模型的强大多智能体协作，并结合了区块链启发式的投票机制，以确保分析的可靠性并避免大型语言模型的幻觉问题。针对微服务架构中的循环依赖导致的非终止问题，该框架通过Agent Workflow客观地限制步骤和标准化任务处理。mABC包含七种专门化的智能体，它们各自依据其专业领域和LLMs的内在软件知识对根因分析提供有价值的见解。实验结果显示，mABC在AIOps挑战数据集和新创建的火车票数据集上表现出卓越的根因识别和解决方案生成效果。此外，消融研究强调了Agent Workflow、多智能体以及区块链启发式投票对于实现最佳性能的重要性。mABC为微服务架构提供了全面自动化的根因分析与解决方案，显著提升了IT运维领域的效率和稳定性。相关代码和数据集可在https://github.com/zwpride/mABC 获取。 <div>
arXiv:2404.12135v3 Announce Type: replace 
Abstract: Root cause analysis (RCA) in Micro-services architecture (MSA) with escalating complexity encounters complex challenges in maintaining system stability and efficiency due to fault propagation and circular dependencies among nodes. Diverse root cause analysis faults require multi-agents with diverse expertise. To mitigate the hallucination problem of large language models (LLMs), we design blockchain-inspired voting to ensure the reliability of the analysis by using a decentralized decision-making process. To avoid non-terminating loops led by common circular dependency in MSA, we objectively limit steps and standardize task processing through Agent Workflow. We propose a pioneering framework, multi-Agent Blockchain-inspired Collaboration for root cause analysis in micro-services architecture (mABC), where multiple agents based on the powerful LLMs follow Agent Workflow and collaborate in blockchain-inspired voting. Specifically, seven specialized agents derived from Agent Workflow each provide valuable insights towards root cause analysis based on their expertise and the intrinsic software knowledge of LLMs collaborating within a decentralized chain. Our experiments on the AIOps challenge dataset and a newly created Train-Ticket dataset demonstrate superior performance in identifying root causes and generating effective resolutions. The ablation study further highlights Agent Workflow, multi-agent, and blockchain-inspired voting is crucial for achieving optimal performance. mABC offers a comprehensive automated root cause analysis and resolution in micro-services architecture and significantly improves the IT Operation domain. The code and dataset are in https://github.com/zwpride/mABC.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Addressing Trust Issues for Vehicle to Grid in Distributed Power Grids Using Blockchains</title>
<link>https://arxiv.org/abs/2407.16180</link>
<guid>https://arxiv.org/abs/2407.16180</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、车辆到电网（V2G）、隐私保护、智能充电点（SCP）、Stackelberg 游戏模型

总结:
本文提出了一种针对区块链分散特性和利益相关者需求定制的车辆到电网（V2G）交易与协调方案，该方案同时关注用户隐私和能源交易效率。通过利用智能充电点（SCP）以及Stackelberg游戏模型，实证案例基于南方科技大学的真实数据表明，所提出的方案能有效降低电动汽车充电成本，并具有支持辅助电网服务的潜力。 <div>
arXiv:2407.16180v5 Announce Type: replace 
Abstract: While blockchain offers inherent security, trust issues among stakeholders in vehicle-to-grid (V2G) applications remain unresolved due to a lack of regulatory frameworks and standardization. Additionally, a tailored decentralized privacy-preserved coordination scheme for blockchain in V2G networks is needed to ensure user privacy and efficient energy transactions. This paper proposes a V2G trading and coordination scheme tailored to the decentralized nature of blockchain as well as the interests of stakeholders utilizing smart charging points (SCPs) and Stackelberg game model. Case studies using real-world data from Southern University of Science and Technology demonstrate the efficacy of proposed scheme in reducing EV charging costs and the potential for supporting auxiliary grid services.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain in Environmental Sustainability Measures: a Survey</title>
<link>https://arxiv.org/abs/2412.15261</link>
<guid>https://arxiv.org/abs/2412.15261</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、环境监管、温室气体排放、污染监测、循环经济

<br /><br />总结:
本文探讨了区块链技术如何作为实现对温室气体排放和污染物贡献进行公正、真实监管的有效工具。通过梳理现有文献，将区块链在环境保护领域的应用分为六个方面：温室气体排放、固体废物、水、塑料、食物浪费及循环经济。文章详细分析了针对这些问题提出的解决方案中所采用的不同类型的区块链及其设计属性。最后，作者指出了未来研究领域中仍存在的挑战与潜在应用场景。 <div>
arXiv:2412.15261v1 Announce Type: new 
Abstract: Real and effective regulation of contributions to greenhouse gas emissions and pollutants requires unbiased and truthful monitoring. Blockchain has emerged not only as an approach that provides verifiable economical interactions but also as a mechanism to keep the measurement, monitoring, incentivation of environmental conservationist practices and enforcement of policy. Here, we present a survey of areas in what blockchain has been considered as a response to concerns on keeping an accurate recording of environmental practices to monitor levels of pollution and management of environmental practices. We classify the applications of blockchain into different segments of concerns, such as greenhouse gas emissions, solid waste, water, plastics, food waste, and circular economy, and show the objectives for the addressed concerns. We also classify the different blockchains and the explored and designed properties as identified for the proposed solutions. At the end, we provide a discussion about the niches and challenges that remain for future research.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Autonomous Vehicle Security: A Deep Dive into Threat Modeling</title>
<link>https://arxiv.org/abs/2412.15348</link>
<guid>https://arxiv.org/abs/2412.15348</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶车辆、网络安全、威胁建模框架、防御措施、新兴技术

总结:
这篇论文对自动驾驶汽车（AVs）的安全性进行了全面调查，重点关注了用于系统地识别和缓解潜在风险的威胁建模框架，如STRIDE、DREAD和MITRE ATT&amp;CK。文章分析了AV架构的关键组成部分，如传感器、通信模块和电子控制单元（ECUs），并探讨了常见的攻击途径，包括无线通信利用、传感器欺骗和固件漏洞等。通过实际案例研究，如Jeep Cherokee和Tesla Model S的安全事件，突显了实施强大安全措施的迫切需求。同时，论文讨论了一些新兴技术，例如区块链用于保障车与万物（V2X）安全通信、AI驱动的威胁检测以及安全的空中下载（OTA）更新，这些都可能成为应对不断演变的威胁的有效解决方案。此外，论文还涉及到了法律和伦理方面的考量，强调数据隐私、用户安全和法规遵从性的重要性。通过结合威胁建模框架、多层安全策略和主动防御措施，该调查为提升自动驾驶车辆的网络安全提供了见解和建议。 <div>
arXiv:2412.15348v1 Announce Type: new 
Abstract: Autonomous vehicles (AVs) are poised to revolutionize modern transportation, offering enhanced safety, efficiency, and convenience. However, the increasing complexity and connectivity of AV systems introduce significant cybersecurity challenges. This paper provides a comprehensive survey of AV security with a focus on threat modeling frameworks, including STRIDE, DREAD, and MITRE ATT\&amp;CK, to systematically identify and mitigate potential risks. The survey examines key components of AV architectures, such as sensors, communication modules, and electronic control units (ECUs), and explores common attack vectors like wireless communication exploits, sensor spoofing, and firmware vulnerabilities. Through case studies of real-world incidents, such as the Jeep Cherokee and Tesla Model S exploits, the paper highlights the critical need for robust security measures. Emerging technologies, including blockchain for secure Vehicle-to-Everything (V2X) communication, AI-driven threat detection, and secure Over-The-Air (OTA) updates, are discussed as potential solutions to mitigate evolving threats. The paper also addresses legal and ethical considerations, emphasizing data privacy, user safety, and regulatory compliance. By combining threat modeling frameworks, multi-layered security strategies, and proactive defenses, this survey offers insights and recommendations for enhancing the cybersecurity of autonomous vehicles.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Computing the Non-Dominated Flexible Skyline in Vertically Distributed Datasets with No Random Access</title>
<link>https://arxiv.org/abs/2412.15468</link>
<guid>https://arxiv.org/abs/2412.15468</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、垂直分布式数据集、top-k查询、非支配灵活天际线（ND）、无随机访问（NRA）

总结:<br />
本文关注在数据驱动的时代，处理垂直分布式数据集的算法的重要性，这些算法能增强数据隐私并提高可扩展性。研究重点在于在无随机访问（NRA）场景下计算非支配灵活天际线（ND）的问题，因为在此类情境中，经典top-k算法的随机访问变得不切实际或受限。文章介绍了一种适用于NRA场景的ND查询算法，证明了其正确性和类别内的最优性，并通过实验评估验证了其在各种情况下的性能，包括合成数据和真实数据。 <div>
arXiv:2412.15468v1 Announce Type: new 
Abstract: In today's data-driven world, algorithms operating with vertically distributed datasets are crucial due to the increasing prevalence of large-scale, decentralized data storage. These algorithms enhance data privacy by processing data locally, reducing the need for data transfer and minimizing exposure to breaches. They also improve scalability, as they can handle vast amounts of data spread across multiple locations without requiring centralized access. Top-k queries have been studied extensively under this lens, and are particularly suitable in applications involving healthcare, finance, and IoT, where data is often sensitive and distributed across various sources. Classical top-k algorithms are based on the availability of two kinds of access to sources: sorted access, i.e., a sequential scan in the internal sort order, one tuple at a time, of the dataset; random access, which provides all the information available at a data source for a tuple whose id is known. However, in scenarios where data retrieval costs are high or data is streamed in real-time or, simply, data are from external sources that only offer sorted access, random access may become impractical or impossible, due to latency issues or data access constraints. Fortunately, a long tradition of algorithms designed for the "no random access" (NRA) scenario exists for classical top-k queries. Yet, these do not cover the recent advances in ranking queries, proposing hybridizations of top-k queries (which are preference-aware and control the output size) and skyline queries (which are preference-agnostic and have uncontrolled output size). The non-dominated flexible skyline (ND) is one such proposal. We introduce an algorithm for computing ND in the NRA scenario, prove its correctness and optimality within its class, and provide an experimental evaluation covering a wide range of cases, with both synthetic and real datasets.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-LLM Text Summarization</title>
<link>https://arxiv.org/abs/2412.15487</link>
<guid>https://arxiv.org/abs/2412.15487</guid>
<content:encoded><![CDATA[
<div> 关键词：多LLM框架、集中式、分布式、生成、评价

总结:
本文提出了一种名为Multi-LLM的摘要框架，并研究了两种不同的多LLM策略，包括集中式和分布式。该框架在每次对话回合中具有两个关键步骤：生成和评价。无论使用的是分布式还是集中式的多LLM策略，都有k个不同的LLM对文本生成多样化的摘要。然而，在评价阶段，集中式多LLM摘要方法利用单个LLM来评估并选择最佳摘要，而分布式则使用k个LLM进行评估。实验结果显示，多LLM摘要方法相对于仅使用单个LLM的基线方法性能显著提升，最高可达3倍。这些结果表明了多LLM方法在摘要任务上的有效性。

<br /><br /> <div>
arXiv:2412.15487v1 Announce Type: new 
Abstract: In this work, we propose a Multi-LLM summarization framework, and investigate two different multi-LLM strategies including centralized and decentralized. Our multi-LLM summarization framework has two fundamentally important steps at each round of conversation: generation and evaluation. These steps are different depending on whether our multi-LLM decentralized summarization is used or centralized. In both our multi-LLM decentralized and centralized strategies, we have k different LLMs that generate diverse summaries of the text. However, during evaluation, our multi-LLM centralized summarization approach leverages a single LLM to evaluate the summaries and select the best one whereas k LLMs are used for decentralized multi-LLM summarization. Overall, we find that our multi-LLM summarization approaches significantly outperform the baselines that leverage only a single LLM by up to 3x. These results indicate the effectiveness of multi-LLM approaches for summarization.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tacit Learning with Adaptive Information Selection for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.15639</link>
<guid>https://arxiv.org/abs/2412.15639</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、集中式训练分散式执行（CTDE）、信息选择、隐性学习、环境适应性过滤

<br /><br />总结：
本文针对多智能体强化学习（MARL）中集中式训练分散式执行（CTDE）框架所面临的挑战，提出了一种新的合作MARL框架。该框架结合了信息选择和默示学习，使代理能在不依赖通信的情况下，仅通过局部信息就能在离散空间中逐渐发展出对他人合作行为的隐性推理能力。此外，框架还整合了门控和选择机制，使得代理能够根据环境变化自适应地过滤信息，从而提升决策能力。实验结果表明，新框架可以无缝集成到最先进的算法中，显著提高了性能。 <div>
arXiv:2412.15639v1 Announce Type: new 
Abstract: In multi-agent reinforcement learning (MARL), the centralized training with decentralized execution (CTDE) framework has gained widespread adoption due to its strong performance. However, the further development of CTDE faces two key challenges. First, agents struggle to autonomously assess the relevance of input information for cooperative tasks, impairing their decision-making abilities. Second, in communication-limited scenarios with partial observability, agents are unable to access global information, restricting their ability to collaborate effectively from a global perspective. To address these challenges, we introduce a novel cooperative MARL framework based on information selection and tacit learning. In this framework, agents gradually develop implicit coordination during training, enabling them to infer the cooperative behavior of others in a discrete space without communication, relying solely on local information. Moreover, we integrate gating and selection mechanisms, allowing agents to adaptively filter information based on environmental changes, thereby enhancing their decision-making capabilities. Experiments on popular MARL benchmarks show that our framework can be seamlessly integrated with state-of-the-art algorithms, leading to significant performance improvements.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PoisonCatcher: Revealing and Identifying LDP Poisoning Attacks in IIoT</title>
<link>https://arxiv.org/abs/2412.15704</link>
<guid>https://arxiv.org/abs/2412.15704</guid>
<content:encoded><![CDATA[
<div> 关键词：Local Differential Privacy（局部差分隐私）、Industrial Internet of Things（工业物联网）、poisoning attacks（中毒攻击）、PoisonCatcher、machine learning models

总结:
这篇论文关注的是局部差分隐私在工业物联网中遭受中毒攻击的问题。研究发现，由于局部差分隐私的模糊性与工业物联网的复杂性相互作用，存在一种新的规则中毒攻击，并统一了输入中毒和输出中毒的攻击形式化描述。论文揭示了两种主要的攻击影响：统计查询结果准确性下降和跨数据集相关性的破坏，以及攻击模式不稳定和被污染数据隐蔽的特点。针对这些问题，提出了名为PoisonCatcher的四阶段解决方案，该方案利用时间相似性、属性相关性和时间序列稳定性分析来检测表现出统计查询结果准确性降低、跨数据集关系中断和不稳定模式的数据集。通过增强特征工程，从数据中提取微弱的中毒签名，进而使用机器学习模型识别特定的受污染数据点。实验评估显示，PoisonCatcher在六个代表性攻击场景中的平均精度和召回率分别达到了86.17%和97.5%，取得了最先进的性能表现。 <div>
arXiv:2412.15704v1 Announce Type: new 
Abstract: Local Differential Privacy (LDP) is widely adopted in the Industrial Internet of Things (IIoT) for its lightweight, decentralized, and scalable nature. However, its perturbation-based privacy mechanism makes it difficult to distinguish between uncontaminated and tainted data, encouraging adversaries to launch poisoning attacks. While LDP provides some resilience against minor poisoning, it lacks robustness in IIoT with dynamic networks and substantial real-time data flows. Effective countermeasures for such attacks are still underdeveloped. This work narrows the critical gap by revealing and identifying LDP poisoning attacks in IIoT. We begin by deepening the understanding of such attacks, revealing novel threats that arise from the interplay between LDP indistinguishability and IIoT complexity. This exploration uncovers a novel rule-poisoning attack, and presents a general attack formulation by unifying it with input-poisoning and output-poisoning. Furthermore, two key attack impacts, i.e., Statistical Query Result (SQR) accuracy degradation and inter-dataset correlations disruption, along with two characteristics: attack patterns unstable and poisoned data stealth are revealed. From this, we propose PoisonCatcher, a four-stage solution that detects LDP poisoning attacks and identifies specific contaminated data points. It utilizes temporal similarity, attribute correlation, and time-series stability analysis to detect datasets exhibiting SQR accuracy degradation, inter-dataset disruptions, and unstable patterns. Enhanced feature engineering is used to extract subtle poisoning signatures, enabling machine learning models to identify specific contamination. Experimental evaluations show the effectiveness, achieving state-of-the-art performance with average precision and recall rates of 86.17% and 97.5%, respectively, across six representative attack scenarios.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secure AI-driven Industrial Metaverse with NFT Digital Twins</title>
<link>https://arxiv.org/abs/2412.15716</link>
<guid>https://arxiv.org/abs/2412.15716</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字孪生、区块链、非同质化代币、伪造检测、深度学习

总结:
随着工业元宇宙的发展，数字孪生（DT）成为了焦点，而基于区块链的非同质化代币（NFT）为创建和拥有可克隆的DT提供了一种去中心化的方案。然而，NFT-DT面临着未经授权的复制或伪造的安全威胁。现有的NFT伪品检测方法多依赖于易于被篡改的静态信息如元数据和图像。针对这些问题，本文提出了一种结合自动编码器与RNN分类器的深度学习解决方案，实现实时模式识别以检测假冒NFT-DT。此外，文章还引入了动态元数据的概念，通过AI集成的智能合约提供更可靠的身份验证方式，有效识别并防范伪造的DT，从而强化了元宇宙中基于NFT资产的安全性。<br /><br /> <div>
arXiv:2412.15716v1 Announce Type: new 
Abstract: The rise of the industrial metaverse has brought digital twins (DTs) to the forefront. Blockchain-powered non-fungible tokens (NFTs) offer a decentralized approach to creating and owning these cloneable DTs. However, the potential for unauthorized duplication, or counterfeiting, poses a significant threat to the security of NFT-DTs. Existing NFT clone detection methods often rely on static information like metadata and images, which can be easily manipulated. To address these limitations, we propose a novel deep-learning-based solution as a combination of an autoencoder and RNN-based classifier. This solution enables real-time pattern recognition to detect fake NFT-DTs. Additionally, we introduce the concept of dynamic metadata, providing a more reliable way to verify authenticity through AI-integrated smart contracts. By effectively identifying counterfeit DTs, our system contributes to strengthening the security of NFT-based assets in the metaverse.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Proactive Model Offloading and Resource Allocation for Split and Federated Learning</title>
<link>https://arxiv.org/abs/2402.06123</link>
<guid>https://arxiv.org/abs/2402.06123</guid>
<content:encoded><![CDATA[
<div> 关键词: Split Federated学习、资源约束、物联网边缘计算、数据泄漏风险、分布式模型卸载与资源配置

<br /><br />
总结:
本文针对资源受限的物联网边缘计算环境中的Split Federated学习方法，指出了当前研究忽视的四个关键问题：设备资源异质性与训练效率的关系、服务器端计算和网络资源分配对训练效率的影响、服务器侧子模型离散化带来的数据泄漏风险以及现有集中式算法的隐私缺陷。为解决这些问题，文章首先建立了使用Split Federated学习训练DNN模型的延迟和数据泄漏风险模型，并将Split Federated学习问题形式化为混合整数非线性规划问题。接着，提出了一种分散式的主动模型卸载与资源配置方案（DP-MORA），使每个终端设备可以根据自身的多维度训练配置自主确定切层位置和资源需求，无需了解其他设备的配置信息。通过在两个真实世界数据集上的大量实验，表明DP-MORA方案能有效降低DNN模型训练延迟，提升训练效率，并在各种实验设置下满足数据泄漏风险约束要求，相较于多个基线算法具有显著优势。 <div>
arXiv:2402.06123v2 Announce Type: replace 
Abstract: In the resource-constrained IoT-edge computing environment, Split Federated (SplitFed) learning is implemented to enhance training efficiency. This method involves each terminal device dividing its full DNN model at a designated layer into a device-side model and a server-side model, then offloading the latter to the edge server. However, existing research overlooks four critical issues as follows: (1) the heterogeneity of end devices' resource capacities and the sizes of their local data samples impact training efficiency; (2) the influence of the edge server's computation and network resource allocation on training efficiency; (3) the data leakage risk associated with the offloaded server-side sub-model; (4) the privacy drawbacks of current centralized algorithms. Consequently, proactively identifying the optimal cut layer and server resource requirements for each end device to minimize training latency while adhering to data leakage risk rate constraint remains a challenging issue. To address these problems, this paper first formulates the latency and data leakage risk of training DNN models using Split Federated learning. Next, we frame the Split Federated learning problem as a mixed-integer nonlinear programming challenge. To tackle this, we propose a decentralized Proactive Model Offloading and Resource Allocation (DP-MORA) scheme, empowering each end device to determine its cut layer and resource requirements based on its local multidimensional training configuration, without knowledge of other devices' configurations. Extensive experiments on two real-world datasets demonstrate that the DP-MORA scheme effectively reduces DNN model training latency, enhances training efficiency, and complies with data leakage risk constraints compared to several baseline algorithms across various experimental settings.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models</title>
<link>https://arxiv.org/abs/2403.09567</link>
<guid>https://arxiv.org/abs/2403.09567</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理、安全性、解释性、ROS移动机器人、区块链、大型语言模型、问责制、自然语言解释、导航功能、性能评价

总结:<br />
本文提出了一种针对基于ROS的移动机器人的责任追究与解释性架构。该方案由两个主要组件构成：一是采用区块链技术实现的类似于黑盒的责任追溯组件，具备抗篡改属性；二是利用大型语言模型对黑盒中的数据生成自然语言解释的组件。研究通过三种不同场景下涉及自主代理导航功能的实验，全面评估了该解决方案的问责制和解释性指标，证明了我们的方法能够在现实世界场景中，有效利用机器人行为记录的可信数据生成连贯、准确且易于理解的解释，从而提高了解释性和系统的可靠性。 <div>
arXiv:2403.09567v3 Announce Type: replace 
Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of generating natural language explanations by harnessing the capabilities of Large Language Models (LLMs) over the data contained within the previously mentioned black box. The study evaluates the performance of our solution in three different scenarios, each involving autonomous agent navigation functionalities. This evaluation includes a thorough examination of accountability and explainability metrics, demonstrating the effectiveness of our approach in using accountable data from robot actions to obtain coherent, accurate and understandable explanations, even when facing challenges inherent in the use of autonomous agents in real-world scenarios.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trust Dynamics and Market Behavior in Cryptocurrency: A Comparative Study of Centralized and Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2404.17227</link>
<guid>https://arxiv.org/abs/2404.17227</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、信任、中心化交易所(CEX)、去中心化交易所(DEX)、FTX崩溃

<br /><br />总结:
该研究关注在加密货币领域中，信任对于市场行为和用户选择CEX与DEX的关键作用。通过对FTX这一大型CEX崩塌事件的分析，利用因果推断方法（如回归断点设计RDD和差异-in-差异DID），揭示了FTX崩溃导致WETH价格显著下降以及从CEX到DEX的资金流动净额增加，显示出可衡量的信任转移现象。同时，通过自然语言处理技术，如主题建模和情感分析，发现Binance社区内的讨论内容由功能转向情绪化，而Uniswap的情感倾向则呈现逐渐上升趋势。这项结合区块链分析、行为金融学和DeFi的跨学科研究加深了我们对分布式信任机制的理解，并为探究数字经济中的社会技术维度的信任问题提供了关键洞见。 <div>
arXiv:2404.17227v2 Announce Type: replace-cross 
Abstract: In the rapidly evolving cryptocurrency landscape, trust is a critical yet underexplored factor shaping market behaviors and driving user preferences between centralized exchanges (CEXs) and decentralized exchanges (DEXs). Despite its importance, trust remains challenging to measure, limiting the study of its effects on market dynamics. The collapse of FTX, a major CEX, provides a unique natural experiment to examine the measurable impacts of trust and its sudden erosion on the cryptocurrency ecosystem. This pivotal event raised questions about the resilience of centralized trust systems and accelerated shifts toward decentralized alternatives. This research investigates the impacts of the FTX collapse on user trust, focusing on token valuation, trading flows, and sentiment dynamics. Employing causal inference methods, including Regression Discontinuity Design (RDD) and Difference-in-Differences (DID), we reveal significant declines in WETH prices and NetFlow from CEXs to DEXs, signaling a measurable transfer of trust. Additionally, natural language processing methods, including topic modeling and sentiment analysis, uncover the complexities of user responses, highlighting shifts from functional discussions to emotional fragmentation in Binance's community, while Uniswap's sentiment exhibits a gradual upward trend. Despite data limitations and external influences, the findings underscore the intricate interplay between trust, sentiment, and market behavior in the cryptocurrency ecosystem. By bridging blockchain analytics, behavioral finance, and decentralized finance (DeFi), this study contributes to interdisciplinary research, offering a deeper understanding of distributed trust mechanisms and providing critical insights for future investigations into the socio-technical dimensions of trust in digital economies.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedSTaS: Client Stratification and Client Level Sampling for Efficient Federated Learning</title>
<link>https://arxiv.org/abs/2412.14226</link>
<guid>https://arxiv.org/abs/2412.14226</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated learning, FedSTaS, client sampling, data-level sampling, Neyman allocation

总结:<br />
本文提出了一种名为"FedSTaS"的新颖联邦学习客户端及数据级采样方法。FedSTaS受到FedSTS和FedSampling的启发，旨在更有效地并以隐私保护的方式选择参与每轮训练的客户端。在每个联邦学习回合中，FedSTaS依据客户端压缩后的梯度信息进行分层，并利用最优Neyman分配重新确定需要采样的客户端数量。此外，它还采用数据均匀采样策略从每个参与客户端中抽样局部数据。实验结果显示，在三个不同数据集上，FedSTaS能够在固定训练轮数内实现比FedSTS更高的准确性评分。 <div>
arXiv:2412.14226v1 Announce Type: new 
Abstract: Federated learning (FL) is a machine learning methodology that involves the collaborative training of a global model across multiple decentralized clients in a privacy-preserving way. Several FL methods are introduced to tackle communication inefficiencies but do not address how to sample participating clients in each round effectively and in a privacy-preserving manner. In this paper, we propose \textit{FedSTaS}, a client and data-level sampling method inspired by \textit{FedSTS} and \textit{FedSampling}. In each federated learning round, \textit{FedSTaS} stratifies clients based on their compressed gradients, re-allocate the number of clients to sample using an optimal Neyman allocation, and sample local data from each participating clients using a data uniform sampling strategy. Experiments on three datasets show that \textit{FedSTaS} can achieve higher accuracy scores than those of \textit{FedSTS} within a fixed number of training rounds.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AIArena: A Blockchain-Based Decentralized AI Training Platform</title>
<link>https://arxiv.org/abs/2412.14566</link>
<guid>https://arxiv.org/abs/2412.14566</guid>
<content:encoded><![CDATA[
<div> 关键词：AI、集中化控制、区块链、去中心化、AIArena<br /><br />总结:

随着人工智能（AI）的迅速发展，其在开发和实施过程中面临的重大挑战日益凸显，主要归因于少数大型企业对AI的集中化控制。这种权力集中加剧了AI模型中的偏见问题，源于不充分的治理和监督机制，并限制了公众参与，引发了关于模型生成完整性的担忧。此外，这种对数据和AI输出的垄断控制威胁到了创新与公平的数据使用，因为用户无意间贡献的数据主要使这些大公司受益。为此，本文提出了一种基于区块链的去中心化AI训练平台——AIArena，旨在通过链上激励机制民主化AI的发展与对齐。AIArena致力于打造一个开放协作的环境，允许参与者贡献模型和计算资源。其链上共识机制确保根据参与者贡献程度公平分配奖励。文章将AIArena实例化并实现在公开的Base区块链Sepolia测试网上，并通过评估结果证明了AIArena在现实应用中的可行性。 <div>
arXiv:2412.14566v1 Announce Type: new 
Abstract: The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>6GENABLERS-DLT: DLT-based Marketplace for Decentralized Trading of 6G Telco resources</title>
<link>https://arxiv.org/abs/2412.14977</link>
<guid>https://arxiv.org/abs/2412.14977</guid>
<content:encoded><![CDATA[
<div> 关键词: 6GENABLERS-DLT项目、分布式账本技术(DLT)、6G环境、资源交易市场、去中心化架构

总结:
<br />
6GENABLERS-DLT项目旨在解决在动态6G环境中促进多方协作的关键挑战。该项目引入了一个基于分布式账本技术(DLT)的创新资源交易市场，使得运营商、资源提供商和服务提供商能够在透明、安全和高效的许可环境下发现、宣传和交易电信资产。与公共DLT-区块链解决方案不同，该市场的许可性质确保了强大的治理、隐私和控制，特别适合于信息和通信技术(ICT)领域的企业及联盟应用场景。通过采用去中心化的架构，它消除了对单一中心运营商的依赖，降低了单点故障风险，提高了系统的信任度、韧性和容错性。此市场涵盖了从虚拟化的移动核心组件、无线接入网络(RAN)资产到边缘和云基础设施，以及针对特定行业需求的垂直应用等6G网络所需的广泛资源。这使得各利益相关方能够动态访问和扩展资源，从而在整个6G生态系统中推动运营效率和创新。通过6GENABLERS-DLT项目，一个合作且资源丰富的6G环境成为现实，为构建一个以去中心化赋能利益相关者满足互联、灵活和可扩展未来需求的下一代电信生态系统奠定了基础。 <div>
arXiv:2412.14977v1 Announce Type: new 
Abstract: The 6GENABLERS-DLT project addresses critical challenges in fostering multi-party collaboration within dynamic 6G environments. As operators and service providers increasingly depend on third-party resources to meet their contractual and operational needs, the project introduces an innovative, Distributed Ledger Technology (DLT)-anchored Marketplace designed to streamline decentralized telco resource trading. This 6GENABLERS Marketplace serves as a collaborative platform where operators, resource providers, and service providers can seamlessly discover, advertise, and trade telco assets within a transparent, secure, and efficient permissioned environment. Distinguished from public DLT-Blockchain solutions, the Marketplace's permissioned nature ensures robust governance, privacy, and control, making it particularly suited to enterprise and consortium-based use cases in the Information and Communication Technology (ICT) sector. The adoption of a decentralized architecture eliminates reliance on a central operator, thereby mitigating risks associated with single points of failure and enhancing system trustworthiness, resilience, and fault tolerance. The Marketplace encompasses a wide range of resources integral to 6G networks, including virtualized mobile core components, Radio Access Network (RAN) assets, edge and cloud infrastructure, and vertical applications tailored to specific industry needs. This diversity enables stakeholders to dynamically access and scale resources, fostering operational efficiency and innovation across 6G ecosystems. Through the 6GENABLERS-DLT project, the vision of a collaborative, resource-rich 6G environment becomes a reality, laying the foundation for a next-generation telco ecosystem where decentralization empowers stakeholders to meet the demands of an interconnected, flexible, and scalable future.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Programming Bugs to Multimillion-Dollar Scams: An Analysis of Trapdoor Tokens on Uniswap</title>
<link>https://arxiv.org/abs/2309.04700</link>
<guid>https://arxiv.org/abs/2309.04700</guid>
<content:encoded><![CDATA[
<div> 关键词：ERC-20 Token、Trapdoor、恶意代码、智能合约、检测工具

总结:
本文研究了一种新型的ERC-20代币骗局——Trapdoor，这种骗局自2020年至2023年已在以太坊上最大的去中心化交易所Uniswap导致投资者数十亿美元的损失。文章首先系统地分类了Trapdoor代币并列出了诈骗者用于嵌入和隐藏恶意代码的各种技术。为了检测这类代币，研究团队开发了一款名为TrapdoorAnalyser的精细粒度检测工具，该工具通过对比买卖测试错误日志与合同语义检查中的Trapdoor指标列表来可靠地识别Trapdoor代币。相比于现有的商业工具GoPlus，TrapdoorAnalyser在准确性方面表现出色，并能提供恶意代码痕迹及完整解释。利用TrapdoorAnalyser，研究人员构建了首个包含约3万个Trapdoor和非Trapdoor代币的UniswapV2数据集，这使得能够训练机器学习算法以高精度检测无Solidity源码的Trapdoor代币。 <div>
arXiv:2309.04700v4 Announce Type: replace 
Abstract: We investigate in this work a recently emerged type of scam ERC-20 token called Trapdoor, which has cost investors billions of US dollars on Uniswap, the largest decentralised exchange on Ethereum, from 2020 to 2023. In essence, Trapdoor tokens allow users to buy but preventing them from selling by embedding logical bugs and/or owner-only features in their smart contracts. By manually inspecting a number of Trapdoor samples, we established the first systematic classification of Trapdoor tokens and a comprehensive list of techniques that scammers used to embed and conceal malicious codes, accompanied by a detailed analysis of representative scam contracts. In particular, we developed TrapdoorAnalyser, a fine-grained detection tool that generates and crosschecks the error-log of a buy-and-sell test and the list of embedded Trapdoor indicators from a contract-semantic check to reliably identify a Trapdoor token. TrapdoorAnalyser not only outperforms the state-of-the-art commercial tool GoPlus in accuracy, but also provides traces of malicious code with a full explanation, which most of the existing tools lack. Using TrapdoorAnalyser, we constructed the very first dataset of about 30,000 Trapdoor and non-Trapdoor tokens on UniswapV2, which allows us to train several machine learning algorithms that can detect with very high accuracy even Trapdoor tokens with no available Solidity source codes.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning Enhanced Rate-Splitting Multiple Access for Interference Mitigation</title>
<link>https://arxiv.org/abs/2403.05974</link>
<guid>https://arxiv.org/abs/2403.05974</guid>
<content:encoded><![CDATA[
<div> 关键词：RSMA，深度强化学习，多智能体DDPG框架，预编码，功率分配

<br />
总结:
本文研究了在现代通信系统中用于干扰缓解的关键技术——率分割多址接入（RSMA）的应用。文章重点关注在复杂多天线干扰信道中，采用深度强化学习优化RSMA的预编码方法和功率分配问题，特别是在涉及多个决策者的情况下。文中利用多智能体深度确定性策略梯度（MADDPG）框架解决这一复杂问题，使分布式代理能够协同学习并优化连续策略空间中的行动。同时，针对发射端不完善的信道侧信息所带来的挑战进行了探讨，并解决了共同和私有数据流的最佳解码顺序估计问题。仿真实验表明，基于MADDPG的提出的RSMA方法在单天线场景下能达到上界性能，在多天线场景下则接近理论极限，并明显优于无率分割的MADDPG、最大比传输（MRT）、零强迫（ZF）以及泄漏基预编码等其他技术。这些发现突显了深度强化学习驱动的RSMA在减少干扰和提升通信系统性能方面的潜力。 <div>
arXiv:2403.05974v2 Announce Type: replace 
Abstract: This study explores the application of the rate-splitting multiple access (RSMA) technique, vital for interference mitigation in modern communication systems. It investigates the use of precoding methods in RSMA, especially in complex multiple-antenna interference channels, employing deep reinforcement learning. The aim is to optimize precoders and power allocation for common and private data streams involving multiple decision-makers. A multi-agent deep deterministic policy gradient (MADDPG) framework is employed to address this complexity, where decentralized agents collectively learn to optimize actions in a continuous policy space. We also explore the challenges posed by imperfect channel side information at the transmitter. Additionally, decoding order estimation is addressed to determine the optimal decoding sequence for common and private data sequences. Simulation results demonstrate the effectiveness of the proposed RSMA method based on MADDPG, achieving the upper bound in single-antenna scenarios and closely approaching theoretical limits in multi-antenna scenarios. Comparative analysis shows superiority over other techniques such as MADDPG without rate-splitting, maximal ratio transmission (MRT), zero-forcing (ZF), and leakage-based precoding methods. These findings highlight the potential of deep reinforcement learning-driven RSMA in reducing interference and enhancing system performance in communication systems.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proxima. A DAG based cooperative distributed ledger</title>
<link>https://arxiv.org/abs/2411.16456</link>
<guid>https://arxiv.org/abs/2411.16456</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式账本、有向无环图(DAG)、UTXO交易、合作共识、可持续性

总结:<br />
本文提出了一种新的分布式账本（常被称为“区块链”）架构，该架构以有向无环图(DAG)的形式组织，其中UTXO交易作为顶点而非区块链中的块。通过实施特别设计的UTXO交易有效性约束，实现基于参与者合作的最大 ledger 覆盖规则的合作共识。这种合作行为由代币持有者驱动，他们是有权对账本进行修正的唯一类别，参与完全无需许可——没有矿工、验证者、委员会或质押机制，也无需了解所有参与共识的成员组成。此设置实现了高吞吐量、可扩展性和低交易成本，同时保持了比特币和其他工作量证明区块链中的高度去中心化、开放参与和异步特性，但避免了不合理的能源消耗。通过使用原生代币的方式，类似于权益证明区块链来实现Sybil防护，但该架构以无领导者方式运行，无需区块提议者和委员会选择。 <div>
arXiv:2411.16456v2 Announce Type: replace 
Abstract: This paper introduces a novel architecture for a distributed ledger, commonly referred to as a "blockchain", which is organized in the form of directed acyclic graph (DAG) with UTXO transactions as vertices, rather than as a chain of blocks. Consensus on the state of ledger assets is achieved through the cooperative consensus: a profit-driven behavior of token holders themselves, which is viable only when they cooperate by following the biggest ledger coverage rule. The cooperative behavior is facilitated by enforcing purposefully designed UTXO transaction validity constraints. Token holders are the sole category of participants authorized to make amendments to the ledger, making participation completely permissionless - without miners, validators, committees or staking - and without any need of knowledge about the composition of the set of all participants in the consensus. The setup allows to achieve high throughput and scalability alongside with low transaction costs, while preserving key aspects of high decentralization, open participation, and asynchronicity found in Bitcoin and other proof-of-work blockchains, but without unreasonable energy consumption. Sybil protection is achieved similarly to proof-of-stake blockchains, using tokens native to the ledger, yet the architecture operates in a leaderless manner without block proposers and committee selection.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized real-time iterations for distributed NMPC</title>
<link>https://arxiv.org/abs/2401.14898</link>
<guid>https://arxiv.org/abs/2401.14898</guid>
<content:encoded><![CDATA[
<div> 关键词：Real-Time Iteration (RTI)，Nonlinear Model Predictive Control (NMPC)，Distributed Control，Sequential Quadratic Programming (dSQP)，Exponential Stability

总结:<br />
本文提出了一种应用于分布式非线性模型预测控制（NMPC）的实时迭代（RTI）方案。该方案将RTI方法扩展到合作式分布式控制场景中，在每个采样时刻，对集中式的优化控制问题执行一次双层分散序列二次规划（dSQP）的外部迭代，确保满足实时性要求并促进子系统间的协作。结合新颖的dSQP收敛结果与RTI稳定性保证，文章证明了在标准MPC设计条件下，无论是否采用终端约束，都能实现局部指数稳定性。所提方案仅需要邻节点间通信，无需中央协调器。通过耦合倒立摆的数值例子，展示了该方法的有效性。 <div>
arXiv:2401.14898v2 Announce Type: replace-cross 
Abstract: This article presents a Real-Time Iteration (RTI) scheme for distributed Nonlinear Model Predictive Control (NMPC). The scheme transfers the well-known RTI approach, a key enabler for many industrial real-time NMPC implementations, to the setting of cooperative distributed control. At each sampling instant, one outer iteration of a bi-level decentralized Sequential Quadratic Programming (dSQP) method is applied to a centralized optimal control problem. This ensures that real-time requirements are met and it facilitates cooperation between subsystems. Combining novel dSQP convergence results with RTI stability guarantees, we prove local exponential stability under standard assumptions on the MPC design with and without terminal constraints. The proposed scheme only requires neighbor-to-neighbor communication and avoids a central coordinator. A numerical example with coupled inverted pendulums demonstrates the efficacy of the approach.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Phytosensing: Ozone Exposure Classification Based on Plant Electrical Signals</title>
<link>https://arxiv.org/abs/2412.13312</link>
<guid>https://arxiv.org/abs/2412.13312</guid>
<content:encoded><![CDATA[
<div> 关键词：WatchPlant、phytosensing、ozone、electrophysiology、AutoML

<br /><br />总结:
该项目WatchPlant提出使用分布式植物网络作为空气品质传感器，通过测量植物电生理学来推断环境状态。研究团队对常春藤（Hedera helix）进行了实验室实验，使其暴露于重要的污染物——臭氧中，并记录了其电生理响应。由于缺乏自动检测植物臭氧暴露的方法，他们提出了一个通用的自动化工具链，该工具链从电生理信号中提取植物和刺激源通用特征，并利用tsfresh库进行处理。接着，通过AutoML自动选择并优化机器学习模型，并运用前向特征选择提升模型性能。实验结果显示，他们的方法能够在未见数据上成功分类植物臭氧暴露，准确率高达94.6%。此外，这种方法还可应用于其他植物物种和刺激源。这一工具链实现了监测算法开发的自动化，为以植物为基础的污染物监测设备带来了显著进步，有助于未来低成本、高密度的城市空气质量监测系统的发展。 <div>
arXiv:2412.13312v1 Announce Type: new 
Abstract: In our project WatchPlant, we propose to use a decentralized network of living plants as air-quality sensors by measuring their electrophysiology to infer the environmental state, also called phytosensing. We conducted in-lab experiments exposing ivy (Hedera helix) plants to ozone, an important pollutant to monitor, and measured their electrophysiological response. However, there is no well established automated way of detecting ozone exposure in plants. We propose a generic automatic toolchain to select a high-performance subset of features and highly accurate models for plant electrophysiology. Our approach derives plant- and stimulus-generic features from the electrophysiological signal using the tsfresh library. Based on these features, we automatically select and optimize machine learning models using AutoML. We use forward feature selection to increase model performance. We show that our approach successfully classifies plant ozone exposure with accuracies of up to 94.6% on unseen data. We also show that our approach can be used for other plant species and stimuli. Our toolchain automates the development of monitoring algorithms for plants as pollutant monitors. Our results help implement significant advancements for phytosensing devices contributing to the development of cost-effective, high-density urban air monitoring systems in the future.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Cyberattack Detection in Blockchain-Based IoT Systems Using AI and Homomorphic Encryption</title>
<link>https://arxiv.org/abs/2412.13522</link>
<guid>https://arxiv.org/abs/2412.13522</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、区块链、物联网、人工智能、同态加密

<br /><br />总结:

本文提出了一种针对基于区块链的物联网系统的新型隐私保护网络攻击检测框架。该框架利用人工智能驱动的检测模块在区块链节点上实现实时攻击识别，确保高精度和最小延迟。为了提高效率，模型训练由云服务提供商（CSP）执行，节点数据经同态加密后发送给CSP进行训练，以保障数据在整个学习过程中的隐私安全。为应对大量加密数据处理问题，文中引入一种创新的 SIMD 方式的打包算法，使得在HE加密数据上进行高效训练成为可能。同时，研究团队开发了适用于加密数据的深度神经网络训练算法，并提出了基于FedAvg算法的分布式隐私保护学习方法，通过并行化多工作器训练显著缩短计算时间。训练完成后，CSP将训练好的模型分发至区块链节点，使其能够进行实时、隐私保护的攻击检测。模拟结果显示，该提议的方法能有效减少训练时间，并实现与未加密情况下接近相同的检测精度，准确度差距约为0.01%。此外，针对不同区块链共识算法和硬件配置的实际部署验证表明，提出的框架也可适应于现实世界系统。 <div>
arXiv:2412.13522v1 Announce Type: new 
Abstract: This work proposes a novel privacy-preserving cyberattack detection framework for blockchain-based Internet-of-Things (IoT) systems. In our approach, artificial intelligence (AI)-driven detection modules are strategically deployed at blockchain nodes to identify real-time attacks, ensuring high accuracy and minimal delay. To achieve this efficiency, the model training is conducted by a cloud service provider (CSP). Accordingly, blockchain nodes send their data to the CSP for training, but to safeguard privacy, the data is encrypted using homomorphic encryption (HE) before transmission. This encryption method allows the CSP to perform computations directly on encrypted data without the need for decryption, preserving data privacy throughout the learning process. To handle the substantial volume of encrypted data, we introduce an innovative packing algorithm in a Single-Instruction-Multiple-Data (SIMD) manner, enabling efficient training on HE-encrypted data. Building on this, we develop a novel deep neural network training algorithm optimized for encrypted data. We further propose a privacy-preserving distributed learning approach based on the FedAvg algorithm, which parallelizes the training across multiple workers, significantly improving computation time. Upon completion, the CSP distributes the trained model to the blockchain nodes, enabling them to perform real-time, privacy-preserved detection. Our simulation results demonstrate that our proposed method can not only mitigate the training time but also achieve detection accuracy that is approximately identical to the approach without encryption, with a gap of around 0.01%. Additionally, our real implementations on various blockchain consensus algorithms and hardware configurations show that our proposed framework can also be effectively adapted to real-world systems.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large Language Model Federated Learning with Blockchain and Unlearning for Cross-Organizational Collaboration</title>
<link>https://arxiv.org/abs/2412.13551</link>
<guid>https://arxiv.org/abs/2412.13551</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、联合学习、区块链、多智能体强化学习、低秩适应<br /><br />总结:<br />
本文提出了一种基于混合区块链的联合学习框架，用于解决不同组织在利用大型语言模型协作过程中面临的挑战。该框架结合了公共和私有区块链架构以及多智能体强化学习，确保模型更新透明共享的同时保护敏感计算。每个组织作为智能代理，运用Q学习优化参与策略和资源分配，使个体利益与集体目标相一致。此外，文章还引入了一种基于低秩适应（LoRA）的高效“遗忘”机制，能够在不损害整体性能的情况下选择性移除特定数据贡献。通过实验证明，该框架有效平衡了隐私保护、信任建立、法规遵循和高模型性能之间的关系。 <div>
arXiv:2412.13551v1 Announce Type: new 
Abstract: Large language models (LLMs) have transformed the way computers understand and process human language, but using them effectively across different organizations remains still difficult. When organizations work together to improve LLMs, they face several main challenges. First, organizations hesitate to share their valuable data with others. Second, competition between organizations creates trust problems during collaboration. Third, new privacy laws require organizations to be able to delete specific data when requested, which is especially difficult when multiple organizations are learning from shared data. Traditional federated learning approaches do not address these interconnected challenges, particularly in scenarios where participants cannot fully trust each other or the central aggregator. To overcome these limitations, we propose a hybrid blockchain-based federated learning framework that uniquely combines public and private blockchain architectures with multi-agent reinforcement learning. Our framework enables transparent sharing of model update through the public blockchain while protecting sensitive computations in private chains. Each organization operates as an intelligent agent, using Q-learning to optimize its participation strategy and resource allocation, thus aligning individual incentives with collective goals. Notably, we introduce an efficient unlearning mechanism based on Low-Rank Adaptation (LoRA) that enables selective removal of specific data contributions without compromising the model's overall performance. Through extensive experimentation on real-world datasets, we demonstrate that our framework effectively balances privacy protection, trust establishment, and regulatory compliance while maintaining high model performance.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data sharing in the metaverse with key abuse resistance based on decentralized CP-ABE</title>
<link>https://arxiv.org/abs/2412.13770</link>
<guid>https://arxiv.org/abs/2412.13770</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、区块链、数据共享、密文策略属性基加密（CP-ABE）、非交互式零知识证明（NIZK）

<br /><br />总结：

本文提出了一种基于区块链的数据共享方案，用于解决元宇宙中数据透明性、防篡改和智能合约支持的需求。该方案首次将非交互式零知识证明（NIZK）融入CP-ABE密钥以确保密钥机密性和授权责任，同时通过智能合约外包验证过程，解决了权责问责和密钥滥用问题。为了满足去中心化要求，文中引入了一个去中心化的CP-ABE方案。此外，还实现了利用智能合约判断访问控制策略是否被一组CP-ABE密钥满足的功能，并设计了开放激励机制以促进诚实参与数据共享，从而有效解决密钥滥用问题。最后，文章展示了该可问责方法在一个GameFi应用中的具体实践，玩家可以在游戏中赚取收益或为一个负责任的DAO做出贡献，进而推动繁荣的元宇宙生态系统建设。实验结果表明该数据共享系统的可行性和效率。 <div>
arXiv:2412.13770v1 Announce Type: new 
Abstract: Data sharing is ubiquitous in the metaverse, which adopts blockchain as its foundation. Blockchain is employed because it enables data transparency, achieves tamper resistance, and supports smart contracts. However, securely sharing data based on blockchain necessitates further consideration. Ciphertext-policy attribute-based encryption (CP-ABE) is a promising primitive to provide confidentiality and fine-grained access control. Nonetheless, authority accountability and key abuse are critical issues that practical applications must address. Few studies have considered CP-ABE key confidentiality and authority accountability simultaneously. To our knowledge, we are the first to fill this gap by integrating non-interactive zero-knowledge (NIZK) proofs into CP-ABE keys and outsourcing the verification process to a smart contract. To meet the decentralization requirement, we incorporate a decentralized CP-ABE scheme into the proposed data sharing system. Additionally, we provide an implementation based on smart contract to determine whether an access control policy is satisfied by a set of CP-ABE keys. We also introduce an open incentive mechanism to encourage honest participation in data sharing. Hence, the key abuse issue is resolved through the NIZK proof and the incentive mechanism. We provide a theoretical analysis and conduct comprehensive experiments to demonstrate the feasibility and efficiency of the data sharing system. Based on the proposed accountable approach, we further illustrate an application in GameFi, where players can play to earn or contribute to an accountable DAO, fostering a thriving metaverse ecosystem.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Responsible Governing AI Proliferation</title>
<link>https://arxiv.org/abs/2412.13821</link>
<guid>https://arxiv.org/abs/2412.13821</guid>
<content:encoded><![CDATA[
<div> 关键词：AI系统、治理机制、大计算范式、扩散范式、风险防控

<br /><br />总结：
本文提出当前用于缓解人工智能系统风险的治理机制基于“大计算”范式，这一范式对于未来可能不再适用。文章引入了“扩散”范式，预期未来会出现更小、分散化、开源的人工智能模型，这些模型更容易增强和秘密训练，从而带来新的机遇与挑战。作者认为这些发展既是可能的，也可能导致现有治理机制难以应对的新风险。文章探讨了针对这些风险的治理策略，重点关注访问治理、分布式计算监督和信息安全。尽管这些策略提供了解决方案的可能性，但文章也警示开发者需要权衡利弊，避免走向一个可能变得脆弱的世界。 <div>
arXiv:2412.13821v1 Announce Type: new 
Abstract: This paper argues that existing governance mechanisms for mitigating risks from AI systems are based on the `Big Compute' paradigm -- a set of assumptions about the relationship between AI capabilities and infrastructure -- that may not hold in the future. To address this, the paper introduces the `Proliferation' paradigm, which anticipates the rise of smaller, decentralized, open-sourced AI models which are easier to augment, and easier to train without being detected. It posits that these developments are both probable and likely to introduce both benefits and novel risks that are difficult to mitigate through existing governance mechanisms. The final section explores governance strategies to address these risks, focusing on access governance, decentralized compute oversight, and information security. Whilst these strategies offer potential solutions, the paper acknowledges their limitations and cautions developers to weigh benefits against developments that could lead to a `vulnerable world'.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Convergence to Equilibrium Prices in Trading Networks</title>
<link>https://arxiv.org/abs/2412.13972</link>
<guid>https://arxiv.org/abs/2412.13972</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized market model, bilateral contracts, Hatfield et al., equilibrium prices, best response dynamic

<br /><br />总结:

本文提出了一种去中心化的市场模型，其中代理人可以协商双边合同。该模型基于Hatfield等人(2013)提出的集中式交易网络模型。先前的工作已经证明，完全可替代的偏好保证了存在可以通过中心化计算得到的竞争均衡。然而，现实世界中如场外交易市场和二手车市场的价格是由代理人之间的“去中心化”谈判产生的，这使得从双边谈判中是否能涌现出均衡价格成为一个开放性问题。为此，文章设计了一个旨在捕捉市场参与者之间此类谈判的最佳响应动态过程。在假设市场参与者具有完全可替代偏好的情况下，对于稀疏市场（覆盖了许多实际感兴趣的市场），本文提供了收敛性的证明，并对于更一般的情况给出了实验结果，证实了价格确实能够通过双边谈判快速达到均衡。这种最佳响应动态及其收敛行为为理解去中心化市场如何达到并维持均衡提供了一个重要的初步研究。 <div>
arXiv:2412.13972v1 Announce Type: new 
Abstract: We propose a decentralized market model in which agents can negotiate bilateral contracts. This builds on a similar, but centralized, model of trading networks introduced by Hatfield et al. (2013). Prior work has established that fully-substitutable preferences guarantee the existence of competitive equilibria which can be centrally computed. Our motivation comes from the fact that prices in markets such as over-the-counter markets and used car markets arise from \textit{decentralized} negotiation among agents, which has left open an important question as to whether equilibrium prices can emerge from agent-to-agent bilateral negotiations. We design a best response dynamic intended to capture such negotiations between market participants. We assume fully substitutable preferences for market participants. In this setting, we provide proofs of convergence for sparse markets ({covering many real world markets of interest}), and experimental results for more general cases, demonstrating that prices indeed reach equilibrium, quickly, via bilateral negotiations. Our best response dynamic, and its convergence behavior, forms an important first step in understanding how decentralized markets reach, and retain, equilibrium.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring User Acceptance of Blockchain-Based Student Certificate Sharing System: A Study on Non Fungible Token (NFT) Utilization</title>
<link>https://arxiv.org/abs/2412.14096</link>
<guid>https://arxiv.org/abs/2412.14096</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、非同质化代币（NFTs）、学术机构凭证、用户接受行为模型、Technology Acceptance Model (TAM)

总结:
本文探讨了一种利用区块链技术和非同质化代币（NFTs）来证明学术机构凭证所有权及管理学术数据和元凭证的新系统。该系统支持安全分享学术信息并确保数据访问控制权。文章指出，现有文献对这类系统的用户接纳行为模型探索有限。为此，论文基于扩展后的Technology Acceptance Model (TAM)，考察了感知易用性、感知有用性和对系统的态度等因素对使用意向的影响。通过原型系统的用户体验问卷调查进行验证，结果表明这些个体构念对使用意向有显著影响，其中感知易用性对使用意向的影响不显著，而对系统的态度对其感知有用性具有主导影响力。最后，文章讨论了这些发现对于基于区块链的学术数据和元凭证共享，以及采用NFTs定义所有权的应用场景的意义。 <div>
arXiv:2412.14096v1 Announce Type: new 
Abstract: Blockchain technology has emerged as a transformative tool for data management in a variety of industries, including fintech, research and healthcare. We have developed a workable blockchain based system that utilizes non fungible tokens NFTs to tokenize and prove ownership of the academic institutions credentials. This makes it easier to create provenance and ownership documentation for academic data and meta credentials. This system enables the secure sharing of academic information while maintaining control, offering incentives for collaboration, and granting users full transparency and control over data access. While the initial adoption of these systems is crucial for ongoing service usage, the exploration of the user acceptance behavioural model remains limited in the existing literature. In this paper, we build upon the Technology Acceptance Model TAM, incorporating additional elements to scrutinize the impact of perceived ease of use, perceived usability, and attitude towards the system on the intention to use a blockchain based academic data and meta credentials sharing system. The research, grounded in user evaluations of a prototype, employs a TAM validated questionnaire. Results indicate that individual constructs notably affect the intention to use the system, and their collective impact is statistically significant. Specifically, perceived ease of use is the sole factor with an insignificant influence on the intention to use. The paper underscores the dominant influence of attitude towards the system on perceived usefulness. It concludes with a discussion on the implications of these findings within the context of blockchain based academic data and meta credentials sharing, incorporating NFTs for ownership definition.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Optimization to Generalization: Fair Federated Learning against Quality Shift via Inter-Client Sharpness Matching</title>
<link>https://arxiv.org/abs/2404.17805</link>
<guid>https://arxiv.org/abs/2404.17805</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、图像质量、公平性、尖锐度匹配、FedISM

总结:
为了解决日益严重的隐私问题，联邦学习被视为训练分布式医疗数据深度神经网络的重要方法。然而，不同机构间成像质量的不一致性成为了一个挑战，可能导致模型偏向高质量图像，从而产生公平性问题。本文首次提出了这一在成像质量偏移背景下的新公平性挑战，并指出传统促进联邦学习公平性的方法主要关注于平衡不同客户端分布的经验风险，但忽视了泛化能力的关键方面。针对此问题，文章提出了一种名为“基于客户端间尖锐度匹配的联邦学习”(FedISM)的方法，该方法通过引入尖锐度感知机制，旨在协调各客户端之间的图像清晰度水平以实现公平泛化。实验结果表明，FedISM在使用ICH和ISIC 2019数据集进行的评估中，相比于当前最先进的联邦学习方法，更能有效地提升公平性。相关代码已发布在https://github.com/wnn2000/FFL4MIA。 <div>
arXiv:2404.17805v2 Announce Type: replace 
Abstract: Due to escalating privacy concerns, federated learning has been recognized as a vital approach for training deep neural networks with decentralized medical data. In practice, it is challenging to ensure consistent imaging quality across various institutions, often attributed to equipment malfunctions affecting a minority of clients. This imbalance in image quality can cause the federated model to develop an inherent bias towards higher-quality images, thus posing a severe fairness issue. In this study, we pioneer the identification and formulation of this new fairness challenge within the context of the imaging quality shift. Traditional methods for promoting fairness in federated learning predominantly focus on balancing empirical risks across diverse client distributions. This strategy primarily facilitates fair optimization across different training data distributions, yet neglects the crucial aspect of generalization. To address this, we introduce a solution termed Federated learning with Inter-client Sharpness Matching (FedISM). FedISM enhances both local training and global aggregation by incorporating sharpness-awareness, aiming to harmonize the sharpness levels across clients for fair generalization. Our empirical evaluations, conducted using the widely-used ICH and ISIC 2019 datasets, establish FedISM's superiority over current state-of-the-art federated learning methods in promoting fairness. Code is available at https://github.com/wnn2000/FFL4MIA.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>REVECA: Adaptive Planning and Trajectory-based Validation in Cooperative Language Agents using Information Relevance and Relative Proximity</title>
<link>https://arxiv.org/abs/2405.16751</link>
<guid>https://arxiv.org/abs/2405.16751</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体合作、部分观察、REVECA、GPT-4o-mini、效率、记忆管理、优化规划、错误规划预防、实验结果、人类-AI合作可信性

<br /><br />总结:

本文提出了一种针对多智能体合作问题的新颖认知架构——RElevance, Proximity, and Validation-Enhanced Cooperative Language Agent (REVECA)，该架构利用GPT-4o-mini进行赋能。针对现有合作智能体系统在处理持续累积信息、规划全局次优以及防范因其他合作者导致的环境变化引起的错误规划等方面的挑战，REVECA通过实施相关性估计、自适应规划和轨迹验证来实现高效的记忆管理、最优规划及低成本防止错误规划。实验结果显示，REVECA在多个基准测试中优于现有的方法，并且用户研究显示出其在实现可信赖的人类与AI合作方面的潜力。 <div>
arXiv:2405.16751v2 Announce Type: replace 
Abstract: We address the challenge of multi-agent cooperation, where agents achieve a common goal by cooperating with decentralized agents under complex partial observations. Existing cooperative agent systems often struggle with efficiently processing continuously accumulating information, managing globally suboptimal planning due to lack of consideration of collaborators, and addressing false planning caused by environmental changes introduced by other collaborators. To overcome these challenges, we propose the RElevance, Proximity, and Validation-Enhanced Cooperative Language Agent (REVECA), a novel cognitive architecture powered by GPT-4o-mini. REVECA enables efficient memory management, optimal planning, and cost-effective prevention of false planning by leveraging Relevance Estimation, Adaptive Planning, and Trajectory-based Validation. Extensive experimental results demonstrate REVECA's superiority over existing methods across various benchmarks, while a user study reveals its potential for achieving trustworthy human-AI cooperation.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Technical Insights on Blockchain's Role in Financial Systems</title>
<link>https://arxiv.org/abs/2412.12131</link>
<guid>https://arxiv.org/abs/2412.12131</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、金融行业、绿色金融、合规性、透明度

总结:

本文对区块链技术在金融行业的应用进行了批判性分析，强调了其在推动绿色金融、确保法规遵从、优化供应链金融、促进去中心化金融(DeFi)以及强化物联网(IoT)方面的重要性。文章探讨了区块链固有特性如何能大幅提高这些领域的透明度、运营效率和安全性，并同时面对可扩展性、系统整合以及不断演变的监管环境等挑战提出了应对之策。 <div>
arXiv:2412.12131v1 Announce Type: new 
Abstract: This research provides a critical analysis regarding the way blockchain is being implemented in the financial industry, highlighting its vital role in promoting green finance, guaranteeing compliance with regulations, improving supply chain finance, boosting decentralized finance (DeFi), and strengthening the Internet of Things (IoT). It discusses how blockchain's inherent attributes could significantly boost transparency, operational efficiency, and security across these domains while also addressing the pressing challenges of scalability, system integration, and the evolving regulatory landscape.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain</title>
<link>https://arxiv.org/abs/2412.12370</link>
<guid>https://arxiv.org/abs/2412.12370</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum智能合约、欺诈检测、图表示学习、交易模式、Multi-Layer Perceptron (MLP)

总结:<br />
针对Ethereum智能合约中的欺诈行为检测问题，由于现有方法存在可扩展性和适应性限制，本文提出了一种创新方法。该方法利用图表示学习来分析交易模式并识别欺诈合同。首先将Ethereum交易数据转化为图结构，然后应用高级机器学习模型进行分类。为解决标签不平衡问题，研究采用了SMOTE-ENN技术，并对比评估了Multi-Layer Perceptron (MLP)和Graph Convolutional Networks (GCN)两种模型。实验结果显示，在此情境下，MLP模型的表现优于GCN模型，实际场景评价也与领域专业分析相吻合。这一研究提供了一个可扩展且有效的解决方案，旨在增强对Ethereum生态系统中信任和安全性的保障。 <div>
arXiv:2412.12370v1 Announce Type: new 
Abstract: The detection of scams within Ethereum smart contracts is a critical challenge due to their increasing exploitation for fraudulent activities, leading to significant financial and reputational damages. Existing detection methods often rely on contract code analysis or manually extracted features, which suffer from scalability and adaptability limitations. In this study, we introduce an innovative method that leverages graph representation learning to examine transaction patterns and identify fraudulent contracts. By transforming Ethereum transaction data into graph structures and employing advanced machine learning models, we achieve robust classification performance. Our method addresses label imbalance through SMOTE-ENN techniques and evaluates models like Multi-Layer Perceptron (MLP) and Graph Convolutional Networks (GCN). Experimental results indicate that the MLP model surpasses the GCN in this context, with real-world evaluations aligning closely with domain-specific analyses. This study provides a scalable and effective solution for enhancing trust and security in the Ethereum ecosystem.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>if-ZKP: Intel FPGA-Based Acceleration of Zero Knowledge Proofs</title>
<link>https://arxiv.org/abs/2412.12481</link>
<guid>https://arxiv.org/abs/2412.12481</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-Knowledge Proofs (ZKP)，Zero-knowledge Succinct Non-interactive ARgument of Knowledge (zk-SNARKs)，FPGA，Multi-scalar Multiplication (MSM)，Intel OneAPI

总结:<br />
本文介绍了针对零知识证明（ZKP）中的一种特殊类型——零知识简洁非交互式知识论证（zk-SNARKs）在FPGA上的加速器架构设计。文章重点关注了占据zk-SNARK系统大部分计算时间的多标量乘法（MSM）操作，并利用高度优化的Intel模数算术IP库。提出的架构充分利用了MSM的并行性，并采用了Intel OneAPI框架实现针对FPGA的设计。相较于参考软件库，该实现的速度提升了110倍至150倍，并且是首次报告使用BLS12-381和BN128椭圆曲线家族在FPGA硬件加速的结果。 <div>
arXiv:2412.12481v1 Announce Type: new 
Abstract: Zero-Knowledge Proofs (ZKPs) have emerged as an important cryptographic technique allowing one party (prover) to prove the correctness of a statement to some other party (verifier) and nothing else. ZKPs give rise to user's privacy in many applications such as blockchains, digital voting, and machine learning. Traditionally, ZKPs suffered from poor scalability but recently, a sub-class of ZKPs known as Zero-knowledge Succinct Non-interactive ARgument of Knowledges (zk-SNARKs) have addressed this challenge. They are getting significant attention and are being implemented by many public libraries. In this paper, we present a novel scalable architecture that is suitable for accelerating the zk-SNARK prover compute on FPGAs. We focus on the multi-scalar multiplication (MSM) that accounts for the majority of computation time spent in zk-SNARK systems. The MSM calculations extensive rely on modular arithmetic so highly optimized Intel IP Libraries for modular arithmetic are used. The proposed architecture exploits the parallelism inherent to MSM and is implemented using the Intel OneAPI framework for FPGAs. Our implementation runs 110x-150x faster compared to reference software library, uses a generic curve form in Jacobian coordinates and is the first to report FPGA hardware acceleration results for BLS12-381 and BN128 family of elliptic curves.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generating Move Smart Contracts based on Concepts</title>
<link>https://arxiv.org/abs/2412.12513</link>
<guid>https://arxiv.org/abs/2412.12513</guid>
<content:encoded><![CDATA[
<div> 关键词：正式验证、智能合约、Move语言、大型语言模型、ConMover

总结:
这篇论文介绍了ConMover，这是一个针对Move语言的新型框架，旨在通过利用Move概念知识图谱和少量已验证的代码示例来增强基于大规模语言模型的代码生成能力。ConMover将概念检索、规划、编码和调试等模块集成到一个迭代过程中，以细化生成的代码。评估显示，相比于基线模型，ConMover显著提高了生成代码的准确性。这表明ConMover有潜力解决资源匮乏条件下的代码生成挑战，从而更好地将自然语言描述与可靠的智能合约开发相衔接。<br /><br /> <div>
arXiv:2412.12513v1 Announce Type: new 
Abstract: The growing adoption of formal verification for smart contracts has spurred the development of new verifiable languages like Move. However, the limited availability of training data for these languages hinders effective code generation by large language models (LLMs). This paper presents ConMover, a novel framework that enhances LLM-based code generation for Move by leveraging a knowledge graph of Move concepts and a small set of verified code examples. ConMover integrates concept retrieval, planning, coding, and debugging agents in an iterative process to refine generated code. Evaluations with various open-source LLMs demonstrate substantial accuracy improvements over baseline models. These results underscore ConMover's potential to address low-resource code generation challenges, bridging the gap between natural language descriptions and reliable smart contract development.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed satellite information networks: Architecture, enabling technologies, and trends</title>
<link>https://arxiv.org/abs/2412.12587</link>
<guid>https://arxiv.org/abs/2412.12587</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式卫星信息网络(DSIN)、卫星集成互联网、创新网络架构、资源效率、跨层优化

总结:
这篇论文介绍了分布式卫星信息网络（DSIN）作为应对下一代智能应用需求增长的新兴架构，旨在通过统一开放的信息网络范式整合通信、导航和遥感等多样化的卫星系统。文章探讨了DSIN中的三种创新网络架构：分布式再生卫星网络架构、分布式卫星计算网络架构以及可重构卫星编队飞行，以实现灵活和可扩展的通信、计算与控制能力。面对网络异构性、不可预测的信道动态、稀疏资源及分散协作框架等问题，文中提出了包括信道建模与估计、云原生分布式MIMO合作、免授权大规模接入、网络路由及这些多样性技术的有效组合等一系列关键技术。为了提高整体资源效率，进一步发展了跨层优化技术以满足上层确定性、自适应和安全的信息服务要求。此外，文章还指出了实现DSIN愿景过程中的新研究方向和机遇。 <div>
arXiv:2412.12587v1 Announce Type: new 
Abstract: Driven by the vision of ubiquitous connectivity and wireless intelligence, the evolution of ultra-dense constellation-based satellite-integrated Internet is underway, now taking preliminary shape. Nevertheless, the entrenched institutional silos and limited, nonrenewable heterogeneous network resources leave current satellite systems struggling to accommodate the escalating demands of next-generation intelligent applications. In this context, the distributed satellite information networks (DSIN), exemplified by the cohesive clustered satellites system, have emerged as an innovative architecture, bridging information gaps across diverse satellite systems, such as communication, navigation, and remote sensing, and establishing a unified, open information network paradigm to support resilient space information services. This survey first provides a profound discussion about innovative network architectures of DSIN, encompassing distributed regenerative satellite network architecture, distributed satellite computing network architecture, and reconfigurable satellite formation flying, to enable flexible and scalable communication, computing and control. The DSIN faces challenges from network heterogeneity, unpredictable channel dynamics, sparse resources, and decentralized collaboration frameworks. To address these issues, a series of enabling technologies is identified, including channel modeling and estimation, cloud-native distributed MIMO cooperation, grant-free massive access, network routing, and the proper combination of all these diversity techniques. Furthermore, to heighten the overall resource efficiency, the cross-layer optimization techniques are further developed to meet upper-layer deterministic, adaptive and secure information services requirements. In addition, emerging research directions and new opportunities are highlighted on the way to achieving the DSIN vision.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AsyncSC: An Asynchronous Sidechain for Multi-Domain Data Exchange in Internet of Things</title>
<link>https://arxiv.org/abs/2412.12723</link>
<guid>https://arxiv.org/abs/2412.12723</guid>
<content:encoded><![CDATA[
<div> 关键词：侧链技术、物联网、异步、延迟聚合签名、跨链交互

总结:
本文提出了一种名为AsyncSC的新型异步侧链构造方案，旨在解决物联网多域数据交换中同步网络需求限制的问题，从而实现更高效的跨链互动。AsyncSC利用委员会提供跨区块链服务（C-BaaS），并结合了聚合签名和可验证延迟函数的思想，创新性地提出了延迟聚合签名（DAS）这一密码学原语，用于构建确保跨链交互安全的异步跨链证明（ACP）。为保证异步交易的一致性，文章还设计了一种多级缓冲交易池来保障交易顺序。通过对AsyncSC的安全性进行分析与证明，并在模拟异步通信环境中进行全面评估，实验结果显示AsyncSC相比现有最优方案，在性能上平均提升了1.21至3.96倍，减少了59.76%至83.61%的交易延迟，并保持了相当的资源开销。 <div>
arXiv:2412.12723v1 Announce Type: new 
Abstract: Sidechain techniques improve blockchain scalability and interoperability, providing decentralized exchange and cross-chain collaboration solutions for Internet of Things (IoT) data across various domains. However, current state-of-the-art (SOTA) schemes for IoT multi-domain data exchange are constrained by the need for synchronous networks, hindering efficient cross-chain interactions in discontinuous networks and leading to suboptimal data exchange. In this paper, we propose AsyncSC, a novel asynchronous sidechain construction. It employs a committee to provide Cross-Blockchain as a Service (C-BaaS) for data exchange in multi-domain IoT. To fulfill the need for asynchronous and efficient data exchange, we combine the ideas of aggregate signatures and verifiable delay functions to devise a novel cryptographic primitive called delayed aggregate signature (DAS), which constructs asynchronous cross-chain proofs (ACPs) that ensure the security of cross-chain interactions. To ensure the consistency of asynchronous transactions, we propose a multilevel buffered transaction pool that guarantees the transaction sequencing. We analyze and prove the security of AsyncSC, simulate an asynchronous communication environment, and conduct a comprehensive evaluation. The results show that AsyncSC outperforms SOTA schemes, improving throughput by an average of 1.21 to 3.96 times, reducing transaction latency by 59.76% to 83.61%, and maintaining comparable resource overhead.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scrutinizing the Vulnerability of Decentralized Learning to Membership Inference Attacks</title>
<link>https://arxiv.org/abs/2412.12837</link>
<guid>https://arxiv.org/abs/2412.12837</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化学习、隐私攻击、成员推理攻击、模型混合策略、通信图全局混合属性

总结:
<br />
本文探讨了去中心化学习环境中，针对机器学习模型训练中的敏感信息泄露问题，尤其是成员推理攻击（MIA）的脆弱性。研究通过改变图结构（如邻居数量）、图动态和聚合策略，对不同数据集和数据分布下的多种去中心化学习架构进行了深入分析。文章揭示了一个重要的新发现：去中心化学习对MIA的脆弱性高度相关于( i )每个节点在接收相邻节点模型后执行的局部模型混合策略及( ii )通信图的全局混合特性。实验结果基于四个数据集并理论分析了各种去中心化架构的混合属性，为设计能降低MIA脆弱性的去中心化学习系统提供了宝贵教训。 <div>
arXiv:2412.12837v1 Announce Type: new 
Abstract: The primary promise of decentralized learning is to allow users to engage in the training of machine learning models in a collaborative manner while keeping their data on their premises and without relying on any central entity. However, this paradigm necessitates the exchange of model parameters or gradients between peers. Such exchanges can be exploited to infer sensitive information about training data, which is achieved through privacy attacks (e.g Membership Inference Attacks -- MIA). In order to devise effective defense mechanisms, it is important to understand the factors that increase/reduce the vulnerability of a given decentralized learning architecture to MIA. In this study, we extensively explore the vulnerability to MIA of various decentralized learning architectures by varying the graph structure (e.g number of neighbors), the graph dynamics, and the aggregation strategy, across diverse datasets and data distributions. Our key finding, which to the best of our knowledge we are the first to report, is that the vulnerability to MIA is heavily correlated to (i) the local model mixing strategy performed by each node upon reception of models from neighboring nodes and (ii) the global mixing properties of the communication graph. We illustrate these results experimentally using four datasets and by theoretically analyzing the mixing properties of various decentralized architectures. Our paper draws a set of lessons learned for devising decentralized learning systems that reduce by design the vulnerability to MIA.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>C-FedRAG: A Confidential Federated Retrieval-Augmented Generation System</title>
<link>https://arxiv.org/abs/2412.13163</link>
<guid>https://arxiv.org/abs/2412.13163</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Retrieval Augmented Generation (RAG), Confidential Computing (CC), Federated Retrieval Augmented Generation (FedRAG), NVIDIA FLARE SDK

总结:
本文提出了一种利用机密计算技术解决组织使用大型语言模型（LLMs）进行知识查询和分析时面临的挑战的方法。针对需要跨多个数据孤岛获取更丰富、相关上下文的需求，以及受限于复杂的数据共享政策问题，文章引入了安全的联邦检索增强生成（FedRAG）——Confidential Federated Retrieval Augmented Generation (C-FedRAG)。C-FedRAG系统通过确保上下文机密性，允许在去中心化的数据提供者网络中安全地扩展和连接RAG工作流程。此外，文中还展示了如何使用NVIDIA FLARE SDK实现C-FedRAG系统，并通过MedRAG工具包和MIRAGE基准测试数据集对其性能进行了评估。 <div>
arXiv:2412.13163v1 Announce Type: new 
Abstract: Organizations seeking to utilize Large Language Models (LLMs) for knowledge querying and analysis often encounter challenges in maintaining an LLM fine-tuned on targeted, up-to-date information that keeps answers relevant and grounded. Retrieval Augmented Generation (RAG) has quickly become a feasible solution for organizations looking to overcome the challenges of maintaining proprietary models and to help reduce LLM hallucinations in their query responses. However, RAG comes with its own issues regarding scaling data pipelines across tiered-access and disparate data sources. In many scenarios, it is necessary to query beyond a single data silo to provide richer and more relevant context for an LLM. Analyzing data sources within and across organizational trust boundaries is often limited by complex data-sharing policies that prohibit centralized data storage, therefore, inhibit the fast and effective setup and scaling of RAG solutions. In this paper, we introduce Confidential Computing (CC) techniques as a solution for secure Federated Retrieval Augmented Generation (FedRAG). Our proposed Confidential FedRAG system (C-FedRAG) enables secure connection and scaling of a RAG workflows across a decentralized network of data providers by ensuring context confidentiality. We also demonstrate how to implement a C-FedRAG system using the NVIDIA FLARE SDK and assess its performance using the MedRAG toolkit and MIRAGE benchmarking dataset.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Challenges Faced by Large Language Models in Solving Multi-Agent Flocking</title>
<link>https://arxiv.org/abs/2404.04752</link>
<guid>https://arxiv.org/abs/2404.04752</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv、多智能体集结、大型语言模型、协同空间推理、未来改进

<br /><br />总结:
这篇论文讨论了大型语言模型（LLMs）在实现多智能体集结（flocking）任务中面临的挑战。尽管LLMs在解决个体决策者间的协作任务上展现出强大的能力，但在实现多智能体保持一定形状和距离的同时靠近彼此的行为上却表现不佳，通常仅收敛到初始位置的平均值或相互远离。作者认为，LLMs无法有效地理解和处理保持形状和保持距离的问题。为了解决这一问题并增强LLMs在协同空间推理方面的能力，论文提出了未来的研究和改进建议，以期为更复杂的多智能体任务奠定基础。 <div>
arXiv:2404.04752v2 Announce Type: replace 
Abstract: Flocking is a behavior where multiple agents in a system attempt to stay close to each other while avoiding collision and maintaining a desired formation. This is observed in the natural world and has applications in robotics, including natural disaster search and rescue, wild animal tracking, and perimeter surveillance and patrol. Recently, large language models (LLMs) have displayed an impressive ability to solve various collaboration tasks as individual decision-makers. Solving multi-agent flocking with LLMs would demonstrate their usefulness in situations requiring spatial and decentralized decision-making. Yet, when LLM-powered agents are tasked with implementing multi-agent flocking, they fall short of the desired behavior. After extensive testing, we find that agents with LLMs as individual decision-makers typically opt to converge on the average of their initial positions or diverge from each other. After breaking the problem down, we discover that LLMs cannot understand maintaining a shape or keeping a distance in a meaningful way. Solving multi-agent flocking with LLMs would enhance their ability to understand collaborative spatial reasoning and lay a foundation for addressing more complex multi-agent tasks. This paper discusses the challenges LLMs face in multi-agent flocking and suggests areas for future improvement and research.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- Blockchain and Applications</title>
<link>https://arxiv.org/abs/2410.10110</link>
<guid>https://arxiv.org/abs/2410.10110</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、加密算法、比特币、以太坊、应用领域<br /><br />总结:<br />
本文详细探讨了区块链技术及其在各领域的应用，首先介绍了密码学基础，包括对称加密和非对称加密及其在确保区块链系统安全与信任中的作用。接着分析了比特币和以太坊的结构与机制，涵盖了工作量证明、权益证明以及智能合约等内容。文中还强调了区块链在去中心化金融（DeFi）、供应链管理和身份认证等行业的实际应用，并讨论了区块链共识机制及可扩展性挑战，提到了如Layer 2解决方案和跨链互操作性等新兴技术。最后，文章概述了当前学术界对区块链的研究现状及未来可能的发展方向。 <div>
arXiv:2410.10110v2 Announce Type: replace 
Abstract: A detailed exploration of blockchain technology and its applications across various fields is provided, beginning with an introduction to cryptography fundamentals, including symmetric and asymmetric encryption, and their roles in ensuring security and trust within blockchain systems. The structure and mechanics of Bitcoin and Ethereum are then examined, covering topics such as proof-of-work, proof-of-stake, and smart contracts. Practical applications of blockchain in industries like decentralized finance (DeFi), supply chain management, and identity authentication are highlighted. The discussion also extends to consensus mechanisms and scalability challenges in blockchain, offering insights into emerging technologies like Layer 2 solutions and cross-chain interoperability. The current state of academic research on blockchain and its potential future developments are also addressed.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Benchmarking Federated Learning for Semantic Datasets: Federated Scene Graph Generation</title>
<link>https://arxiv.org/abs/2412.10436</link>
<guid>https://arxiv.org/abs/2412.10436</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 语义异质性, 客户端数据分布, Panoptic Scene Graph Generation, 联邦学习基准

<br /><br />总结:
本文提出了一种建立具有可控语义异质性的联邦学习(Federated Learning)基准的方法。现有的联邦学习基准主要关注单一语义（如一热标签）的数据处理，而对复杂语义信息（如Panoptic Scene Graph Generation中的对象、主题和它们之间的关系）处理的关注较少。文中提出了两个关键步骤：基于语义的数据聚类和通过可控语义异质性进行客户端数据分布。作为概念验证，构建了一个联邦场景图生成(FL-PSG)基准，展示了现有方法在具有可控语义异质性的联邦学习环境下的有效性。此外，作者还证明了该基准的有效性，通过应用鲁棒的联邦学习算法来应对数据异质性，从而展示性能提升。相关代码已在GitHub上开源。 <div>
arXiv:2412.10436v1 Announce Type: new 
Abstract: Federated learning (FL) has recently garnered attention as a data-decentralized training framework that enables the learning of deep models from locally distributed samples while keeping data privacy. Built upon the framework, immense efforts have been made to establish FL benchmarks, which provide rigorous evaluation settings that control data heterogeneity across clients. Prior efforts have mainly focused on handling relatively simple classification tasks, where each sample is annotated with a one-hot label, such as MNIST, CIFAR, LEAF benchmark, etc. However, little attention has been paid to demonstrating an FL benchmark that handles complicated semantics, where each sample encompasses diverse semantic information from multiple labels, such as Panoptic Scene Graph Generation (PSG) with objects, subjects, and relations between them. Because the existing benchmark is designed to distribute data in a narrow view of a single semantic, e.g., a one-hot label, managing the complicated semantic heterogeneity across clients when formalizing FL benchmarks is non-trivial. In this paper, we propose a benchmark process to establish an FL benchmark with controllable semantic heterogeneity across clients: two key steps are i) data clustering with semantics and ii) data distributing via controllable semantic heterogeneity across clients. As a proof of concept, we first construct a federated PSG benchmark, demonstrating the efficacy of the existing PSG methods in an FL setting with controllable semantic heterogeneity of scene graphs. We also present the effectiveness of our benchmark by applying robust federated learning algorithms to data heterogeneity to show increased performance. Our code is available at https://github.com/Seung-B/FL-PSG.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Client-Side Patching against Backdoor Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2412.10605</link>
<guid>https://arxiv.org/abs/2412.10605</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, backdoor attacks, defense mechanism, adversarial learning, model patching

总结:
这篇论文提出了一种针对联邦学习系统的新颖防御机制，旨在减轻客户端遭受的后门攻击。该方法利用对抗学习技术和模型修补来中和后门攻击的影响。通过对MNIST和Fashion-MNIST数据集进行广泛实验，论文表明该防御策略能有效降低后门攻击的准确性，在i.i.d.和非i.i.d.场景下优于现有最先进的防御方法（如LFighter、FLAME和RoseAgg），同时保持了对清洁数据具有竞争力或更优的准确性。<br /><br /> <div>
arXiv:2412.10605v1 Announce Type: new 
Abstract: Federated learning is a versatile framework for training models in decentralized environments. However, the trust placed in clients makes federated learning vulnerable to backdoor attacks launched by malicious participants. While many defenses have been proposed, they often fail short when facing heterogeneous data distributions among participating clients. In this paper, we propose a novel defense mechanism for federated learning systems designed to mitigate backdoor attacks on the clients-side. Our approach leverages adversarial learning techniques and model patching to neutralize the impact of backdoor attacks. Through extensive experiments on the MNIST and Fashion-MNIST datasets, we demonstrate that our defense effectively reduces backdoor accuracy, outperforming existing state-of-the-art defenses, such as LFighter, FLAME, and RoseAgg, in i.i.d. and non-i.i.d. scenarios, while maintaining competitive or superior accuracy on clean data.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Trust-Centric Approach To Quantifying Maturity and Security in Internet Voting Protocols</title>
<link>https://arxiv.org/abs/2412.10611</link>
<guid>https://arxiv.org/abs/2412.10611</guid>
<content:encoded><![CDATA[
<div> 关键词: 投票、互联网投票协议、安全、成熟度框架、电子投票成熟度框架(EVMF)

总结:<br />
本文针对互联网投票协议的安全性和成熟度评估缺乏统一标准和考虑实际部署需求的问题，提出了一种以信任为核心的成熟度评分框架——电子投票成熟度框架（EVMF）。该框架详细分析了十六种互联网投票系统的安全属性、信任假设、技术复杂性和实用可用性。EVMF旨在支持对现实世界部署问题的细微评估，帮助决策者根据特定应用场景选择合适的系统。此外，该框架不仅适用于投票系统，还可以应用于其他需要权衡去中心化、信任和安全性的重要领域，如数字身份、以太坊二层扩容方案以及联邦数据基础设施。EVMF为政策制定者和技术专家提供了一个可扩展的工具包，能够在单变量尺度上标准化技术和非技术要求。 <div>
arXiv:2412.10611v1 Announce Type: new 
Abstract: Voting is a cornerstone of collective participatory decision-making in contexts ranging from political elections to decentralized autonomous organizations (DAOs). Despite the proliferation of internet voting protocols promising enhanced accessibility and efficiency, their evaluation and comparison are complicated by a lack of standardized criteria and unified definitions of security and maturity. Furthermore, socio-technical requirements by decision makers are not structurally taken into consideration when comparing internet voting systems. This paper addresses this gap by introducing a trust-centric maturity scoring framework to quantify the security and maturity of sixteen internet voting systems. A comprehensive trust model analysis is conducted for selected internet voting protocols, examining their security properties, trust assumptions, technical complexity, and practical usability. In this paper we propose the electronic voting maturity framework (EVMF) which supports nuanced assessment that reflects real-world deployment concerns and aids decision-makers in selecting appropriate systems tailored to their specific use-case requirements. The framework is general enough to be applied to other systems, where the aspects of decentralization, trust, and security are crucial, such as digital identity, Ethereum layer-two scaling solutions, and federated data infrastructures. Its objective is to provide an extendable toolkit for policy makers and technology experts alike that normalizes technical and non-technical requirements on a univariate scale.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A technical solution for the rule of law, peace, security, and evolvability of global cyberspace -- solve the three genetic defects of IP network</title>
<link>https://arxiv.org/abs/2412.10722</link>
<guid>https://arxiv.org/abs/2412.10722</guid>
<content:encoded><![CDATA[
<div> 关键词: Co-governed Multi-Identifier Network (CoG-MIN), 网络架构, 区块链技术, 网络安全, 互联网缺陷

<br /><br />总结:
针对现有互联网存在的权力集中、安全隐患及IP协议刚性等问题，本文提出了一个新的网络架构——Co-governed Multi-Identifier Network (CoG-MIN，简称MIN)。该架构利用区块链技术确保全球各国在网络治理和法治方面的平等参与，并通过整合用户认证、数据签名和加密机制提升了网络安全性能，在国际网络安全竞赛中表现出色。此外，CoG-MIN支持不同标识系统的演进与互操作性，保持与IP协议兼容的同时，也为逐步过渡到非IP架构提供了适应性强的生态系统，有利于未来网络架构的多样化发展和持续进化。同时，文中还介绍了关于网络安全的三个定理。 <div>
arXiv:2412.10722v1 Announce Type: new 
Abstract: Since its inception in the 1960s, the internet has profoundly transformed human life. However, its original design now struggles to meet the evolving demands of modern society. Three primary defects have emerged: First, the concentration of power among a few dominant entities has intensified international conflicts and widened the technological divide. Second, the Internet Protocol (IP)-based system lacks inherent security, leading to frequent global cybersecurity incidents. Third, the rigidity of the IP protocol has hindered the sustainable development of cyberspace, as it resists necessary adaptations and innovations. Addressing these issues is crucial for the future resilience and security of the global digital landscape.
  To address these challenges, we propose the Co-governed Multi-Identifier Network (CoG-MIN briefly as MIN), a novel network architecture that leverages blockchain technology to ensure equal participation of countries worldwide in cyberspace governance and the rule of law. As a next-generation network system, CoG-MIN integrates mechanisms such as user authentication, data signatures, and encryption to significantly enhance network security. In testing environments, CoG-MIN has consistently withstood extensive attacks during various international cybersecurity competitions. Additionally, CoG-MIN supports the evolution and interoperability of different identifier systems, remains IP-compatible, and facilitates a gradual transition away from IP, providing an adaptable ecosystem for diverse network architectures. This adaptability fosters the development and evolution of diverse network architectures within CoG-MIN, making it a natural progression for the internet's future development.
  We further introduce a trilogy of cyberspace security theorems... (Due to character limitations, the full abstract is available in the paper PDF.)
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Serial Scammers and Attack of the Clones: How Scammers Coordinate Multiple Rug Pulls on Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2412.10993</link>
<guid>https://arxiv.org/abs/2412.10993</guid>
<content:encoded><![CDATA[
<div> 关键词：scammer addresses, Rug Pulls, decentralized exchanges, scam network, wash trading

<br /><br />总结:
本文研究了普遍存在的连续欺诈者现象，这些欺诈者使用数千个地址在两个最流行的去中心化交易所（Uniswap 和 Pancakeswap）上进行一系列类似的拉高出货行为。研究人员首先构建了一个包含约384,000个欺诈地址的列表，这些地址涉及这两个平台上所有一天内的拉高出货事件，并识别出了多种独特的欺诈模式，如星形、链形和多数流欺诈集群。接着，他们提出了一种算法，能从给定的欺诈地址构建一个完整的欺诈网络，该网络不仅包括欺诈者地址，还包括存款人、取款人、转账者、协调者以及最重要的洗盘交易者。作者指出，现有针对拉高出货的研究未能考虑到洗盘交易的成本，导致利润估计值被夸大。通过了解洗盘交易者的身份，文章对单个欺诈池以及整个（连续）欺诈网络的真实利润进行了更为准确的估算，考虑到了洗盘交易的费用。 <div>
arXiv:2412.10993v1 Announce Type: new 
Abstract: We explored in this work the ubiquitous phenomenon of serial scammers, who deploy thousands of addresses to conduct a series of similar Rug Pulls on popular decentralized exchanges (DEXs). We first constructed a list of about 384,000 scammer addresses behind all 1-day Rug Pulls on the two most popular DEXs, Uniswap (Ethereum) and Pancakeswap (BSC), and identified many distinctive scam patterns including star-shaped, chain-shaped, and majority-flow scam clusters. We then proposed an algorithm to build a complete scam network from given scammer addresses, which consists of not only scammer addresses but also supporting addresses including depositors, withdrawers, transferrers, coordinators, and most importantly, wash traders. We note that profit estimations in existing works on Rug Pulls failed to capture the cost of wash trading, leading to inflated figures. Knowing who the wash traders are, we established a more accurate estimate for the true profit of individual scam pools as well as of the entire (serial) scam network by taking into account the wash-trading expenses.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Knowledge Migration Framework for Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2412.11175</link>
<guid>https://arxiv.org/abs/2412.11175</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contract, vulnerability detection, AF-STip, knowledge migration, data-free knowledge distillation, adaptive fusion module, F1值, accuracy

总结:
本文提出了一种新的智能合约漏洞检测框架AF-STip，该框架针对现有模型泛化能力的局限性，通过数据免费的知识蒸馏方法，利用教师网络将处理过的智能合约知识迁移到学生模型中，增强其漏洞检测能力。AF-STip提升了模型的特征提取和跨类适应能力，并降低了计算开销。此外，文中还提出了一种自适应融合模块来强化特征信息的交互与融合，进一步提升漏洞特征的提取效果。实验结果显示，STip模型在不披露原始智能合约数据的情况下，对四种漏洞的平均F1值检测得分为91.16%。为了验证轻量级迁移学习方法的有效性，学生模型被部署到针对新型漏洞类型的迁移学习任务中，取得了91.02%的准确率和90.46%的F1得分。据作者所知，AF-STip是首个将无数据知识迁移应用于智能合约漏洞检测的模型，它在显著降低计算开销的同时，仍能展现出优异的新颖漏洞检测性能。 <div>
arXiv:2412.11175v1 Announce Type: new 
Abstract: As a cornerstone of blockchain technology in the 3.0 era, smart contracts play a pivotal role in the evolution of blockchain systems. In order to address the limitations of existing smart contract vulnerability detection models with regard to their generalisation capability, an AF-STip smart contract vulnerability detection framework incorporating efficient knowledge migration is proposed. AF-STip employs the teacher network as the main model and migrates the knowledge processed by the smart contract to the student model using a data-free knowledge distillation method. The student model utilises this knowledge to enhance its vulnerability detection capabilities. The approach markedly enhances the model's capacity for feature extraction and cross-class adaptation, while concurrently reducing computational overhead.In order to further enhance the extraction of vulnerability features, an adaptive fusion module is proposed in this paper, which aims to strengthen the interaction and fusion of feature information.The experimental results demonstrate that the STip model attains an average F1 value detection score of 91.16% for the four vulnerabilities without disclosing the original smart contract data. To validate the viability of the proposed lightweight migration approach, the student model is deployed in a migration learning task targeting a novel vulnerability type, resulting in an accuracy of 91.02% and an F1 score of 90.46%. To the best of our knowledge, AF-STip is the inaugural model to apply data-free knowledge migration to smart contract vulnerability detection. While markedly reducing the computational overhead, the method still demonstrates exceptional performance in detecting novel vulnerabilities.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ProFe: Communication-Efficient Decentralized Federated Learning via Distillation and Prototypes</title>
<link>https://arxiv.org/abs/2412.11207</link>
<guid>https://arxiv.org/abs/2412.11207</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning (DFL)，ProFe，知识蒸馏，原型学习，量化技术

总结:<br />
本文介绍了一种针对去中心化联邦学习（DFL）的新型通信优化算法ProFe。该算法综合运用了知识蒸馏、原型学习和量化技术，旨在解决分布式环境下模型聚合与通信效率的问题，特别是应对异构数据分布带来的挑战。ProFe利用大模型的知识训练更小的模型进行聚合，通过引入原型以更好地学习未见过的类别，并应用量化技术降低通信轮次中的数据传输成本。实验结果显示，ProFe提出的算法在保持或提升模型性能的同时，能够将通信成本降低约40%-50%，但会增加约20%的训练时间，从而形成了一定的效益与复杂性之间的权衡。 <div>
arXiv:2412.11207v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) trains models in a collaborative and privacy-preserving manner while removing model centralization risks and improving communication bottlenecks. However, DFL faces challenges in efficient communication management and model aggregation within decentralized environments, especially with heterogeneous data distributions. Thus, this paper introduces ProFe, a novel communication optimization algorithm for DFL that combines knowledge distillation, prototype learning, and quantization techniques. ProFe utilizes knowledge from large local models to train smaller ones for aggregation, incorporates prototypes to better learn unseen classes, and applies quantization to reduce data transmitted during communication rounds. The performance of ProFe has been validated and compared to the literature by using benchmark datasets like MNIST, CIFAR10, and CIFAR100. Results showed that the proposed algorithm reduces communication costs by up to ~40-50% while maintaining or improving model performance. In addition, it adds ~20% training time due to increased complexity, generating a trade-off.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Domain Generalization with Label Smoothing and Balanced Decentralized Training</title>
<link>https://arxiv.org/abs/2412.11408</link>
<guid>https://arxiv.org/abs/2412.11408</guid>
<content:encoded><![CDATA[
<div> 关键词: 异构数据、联邦学习、域泛化、标签平滑、平衡分散训练

总结:
<br />
本文提出了一种名为FedSB的新方法，用于解决联邦学习框架内的异构数据挑战。FedSB通过客户端的标签平滑技术防止过度拟合特定领域的特征，从而提升模型在不同领域间的泛化能力。同时，该方法还引入了平衡分散训练的预算机制，优化了客户端之间的训练分配，进而提升了全局模型的性能。实验结果显示，在四个常用的多域数据集PACS、VLCS、OfficeHome和TerraInc上，FedSB超越了现有竞争方法，在其中三个数据集上取得了最先进的结果，证明了FedSB在应对数据异构性方面的有效性。 <div>
arXiv:2412.11408v1 Announce Type: new 
Abstract: In this paper, we propose a novel approach, Federated Domain Generalization with Label Smoothing and Balanced Decentralized Training (FedSB), to address the challenges of data heterogeneity within a federated learning framework. FedSB utilizes label smoothing at the client level to prevent overfitting to domain-specific features, thereby enhancing generalization capabilities across diverse domains when aggregating local models into a global model. Additionally, FedSB incorporates a decentralized budgeting mechanism which balances training among clients, which is shown to improve the performance of the aggregated global model. Extensive experiments on four commonly used multi-domain datasets, PACS, VLCS, OfficeHome, and TerraInc, demonstrate that FedSB outperforms competing methods, achieving state-of-the-art results on three out of four datasets, indicating the effectiveness of FedSB in addressing data heterogeneity.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TRAIL: Trust-Aware Client Scheduling for Semi-Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2412.11448</link>
<guid>https://arxiv.org/abs/2412.11448</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、半分布式联邦学习（Semi-Decentralized Federated Learning）、动态客户端状态、信任感知客户端调度机制（TRAIL）、自适应隐藏半马尔可夫模型（AHSMM）

总结:<br />
针对半分布式联邦学习（SD-FL）中客户端通信和训练状态动态变化的问题，本文提出了一个名为TRAIL的信任感知客户端调度机制。TRAIL着重考虑了实际场景中的动态挑战，尤其是在边缘服务器和客户端使用不可靠的簇内模型聚合和簇间模型共识训练共享全局模型的框架下。文章首先利用自适应隐藏半马尔可夫模型（AHSMM）评估客户端的通信状态和贡献；接着，为最小化全局训练损失，提出了一项客户端-服务器关联优化问题；并基于收敛分析设计了一种贪心客户端调度算法。实验结果表明，与现有最优基线相比，TRAIL在真实数据集上的测试精度提高了8.7%，训练损失降低了15.3%。 <div>
arXiv:2412.11448v1 Announce Type: new 
Abstract: Due to the sensitivity of data, federated learning (FL) is employed to enable distributed machine learning while safeguarding data privacy and accommodating the requirements of various devices. However, in the context of semi-decentralized federated learning (SD-FL), clients' communication and training states are dynamic. This variability arises from local training fluctuations, heterogeneous data distributions, and intermittent client participation. Most existing studies primarily focus on stable client states, neglecting the dynamic challenges present in real-world scenarios. To tackle this issue, we propose a trust-aware client scheduling mechanism (TRAIL) that assesses client states and contributions, enhancing model training efficiency through selective client participation. Our focus is on a semi-decentralized federated learning framework where edge servers and clients train a shared global model using unreliable intra-cluster model aggregation and inter-cluster model consensus. First, we develop an adaptive hidden semi-Markov model (AHSMM) to estimate clients' communication states and contributions. Next, we address a client-server association optimization problem to minimize global training loss. Using convergence analysis, we propose a greedy client scheduling algorithm. Finally, our experiments conducted on real-world datasets demonstrate that TRAIL outperforms state-of-the-art baselines, achieving an improvement of 8.7\% in test accuracy and a reduction of 15.3\% in training loss.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>UA-PDFL: A Personalized Approach for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2412.11674</link>
<guid>https://arxiv.org/abs/2412.11674</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、去中心化联邦学习（Decentralized Federated Learning）、非独立同分布数据（Non-IID）、个性化层、UA-PDFL

总结:<br />
本文提出了一种新颖的单元表示辅助个性化去中心化联邦学习框架——UA-PDFL，旨在解决去中心化联邦学习中非独立同分布数据带来的训练问题。该框架通过单元表示自适应地调整个性化层的程度，以应对不同级别的数据偏斜。此外，文中还提出了客户端Dropout和层级个性化策略，以进一步提升去中心化联邦学习的性能。实验结果充分证明了所提方法的有效性。 <div>
arXiv:2412.11674v1 Announce Type: new 
Abstract: Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as an coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lightweight Decentralized Neural Network-Based Strategies for Multi-Robot Patrolling</title>
<link>https://arxiv.org/abs/2412.11916</link>
<guid>https://arxiv.org/abs/2412.11916</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized multi-robot patrol, neural network, idleness minimization, intelligent intruder model, communication failure

总结:
<br />
本文提出了一种针对分布式多机器人巡逻问题的新方法，该问题以往主要依赖于手工设计的策略来最小化图结构环境中的“空闲时间”。文章介绍了两种基于轻量级神经网络的策略，并展示它们在减少空闲时间和对抗智能入侵者模型方面显著优于现有策略。此外，文中还研究了这些策略在通信失败情况下的鲁棒性，并对未来策略设计提出了重要考量。 <div>
arXiv:2412.11916v1 Announce Type: new 
Abstract: The problem of decentralized multi-robot patrol has previously been approached primarily with hand-designed strategies for minimization of 'idlenes' over the vertices of a graph-structured environment. Here we present two lightweight neural network-based strategies to tackle this problem, and show that they significantly outperform existing strategies in both idleness minimization and against an intelligent intruder model, as well as presenting an examination of robustness to communication failure. Our results also indicate important considerations for future strategy design.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean Field Game and Control for Switching Hybrid Systems</title>
<link>https://arxiv.org/abs/2412.10522</link>
<guid>https://arxiv.org/abs/2412.10522</guid>
<content:encoded><![CDATA[
<div> 关键词：mean field games, controls, hybrid systems, switching, integro-partial differential equation

总结:
本文提出了一种针对切换混合系统的平均场游戏和控制策略，并设计了解决由此产生的积分偏微分方程的计算方法。该方法使得在大规模具有突发环境变化的紧急疏散等场景中，实现可扩展的、分散式的决策制定成为可能。文章通过数值例子进一步展示了这一理论的应用价值。 <div>
arXiv:2412.10522v1 Announce Type: cross 
Abstract: Mean field games and controls involve guiding the behavior of large populations of interacting agents, where each individual's influence on the group is negligible but collectively impacts overall dynamics. Hybrid systems integrate continuous dynamics with discrete transitions, effectively modeling the complex interplay between continuous flows and instantaneous jumps in a unified framework. This paper formulates mean field game and control strategies for switching hybrid systems and proposes computational methods to solve the resulting integro-partial differential equation. This approach enables scalable, decentralized decision-making in large-scale switching systems, which is illustrated through numerical examples in an emergency evacuation scenario with sudden changes in the surrounding environment.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fuzz on the Beach: Fuzzing Solana Smart Contracts</title>
<link>https://arxiv.org/abs/2309.03006</link>
<guid>https://arxiv.org/abs/2309.03006</guid>
<content:encoded><![CDATA[
<div> 关键词：Solana、智能合约、FuzzDelSol、二进制模糊测试、安全分析

总结:
本文针对Solana智能合约的安全分析领域提出了一种新的解决方案——FuzzDelSol，它是首个专为Solana设计的二进制代码覆盖导向的模糊测试架构。由于Solana执行环境的状态less特性引入了特有的攻击模式，现有的智能合约安全性工具大多无法适应。FuzzDelSol不仅能够准确模拟运行时如智能合约交互等具体细节，而且由于大多数Solana合约没有源代码可用，因此它直接对合约的二进制代码进行操作。为了弥补缺乏语义信息的问题，研究者们从低级别程序和状态信息中精心提取数据，开发出一套涵盖Solana主要错误类别的bug检测器。通过在6049个智能合约上的广泛评估，FuzzDelSol的bug检测器表现出高精度和召回率，据作者所知，这是针对Solana主网的最大规模的安全性评估。 <div>
arXiv:2309.03006v3 Announce Type: replace 
Abstract: Solana has quickly emerged as a popular platform for building decentralized applications (DApps), such as marketplaces for non-fungible tokens (NFTs). A key reason for its success are Solana's low transaction fees and high performance, which is achieved in part due to its stateless programming model. Although the literature features extensive tooling support for smart contract security, current solutions are largely tailored for the Ethereum Virtual Machine. Unfortunately, the very stateless nature of Solana's execution environment introduces novel attack patterns specific to Solana requiring a rethinking for building vulnerability analysis methods.
  In this paper, we address this gap and propose FuzzDelSol, the first binary-only coverage-guided fuzzing architecture for Solana smart contracts. FuzzDelSol faithfully models runtime specifics such as smart contract interactions. Moreover, since source code is not available for the large majority of Solana contracts, FuzzDelSol operates on the contract's binary code. Hence, due to the lack of semantic information, we carefully extracted low-level program and state information to develop a diverse set of bug oracles covering all major bug classes in Solana. Our extensive evaluation on 6049 smart contracts shows that FuzzDelSol's bug oracles find bugs with a high precision and recall. To the best of our knowledge, this is the largest evaluation of the security landscape on the Solana mainnet.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis</title>
<link>https://arxiv.org/abs/2311.02778</link>
<guid>https://arxiv.org/abs/2311.02778</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse、多传感器混合现实房间数据集(MuSHRoom)、几何重建、真实感建模、联合学习

<br /><br />总结:
本文提出了一种名为MuSHRoom的真实世界多传感器混合现实房间数据集，旨在解决元宇宙技术中准确、实时和沉浸式建模的挑战，特别是在消费级硬件上的非人类感知和AR/VR等沉浸式技术应用。MuSHRoom数据集针对如何在一个统一框架内结合几何重建与真实感建模（新颖视角合成）的知识空白提供了研究方向。该数据集要求方法具有成本效益、对嘈杂数据和设备具备鲁棒性，并能同时学习3D重建和新颖视角合成。文章对一些著名管道进行了基准测试，并证明了该数据集和基准在推动3D重建与高质量渲染融合方面的巨大潜力，以实现更强大且计算效率高的端到端方式。相关数据集和代码已在项目网站上发布。 <div>
arXiv:2311.02778v3 Announce Type: replace 
Abstract: Metaverse technologies demand accurate, real-time, and immersive modeling on consumer-grade hardware for both non-human perception (e.g., drone/robot/autonomous car navigation) and immersive technologies like AR/VR, requiring both structural accuracy and photorealism. However, there exists a knowledge gap in how to apply geometric reconstruction and photorealism modeling (novel view synthesis) in a unified framework. To address this gap and promote the development of robust and immersive modeling and rendering with consumer-grade devices, we propose a real-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents exciting challenges and requires state-of-the-art methods to be cost-effective, robust to noisy data and devices, and can jointly learn 3D reconstruction and novel view synthesis instead of treating them as separate tasks, making them ideal for real-world applications. We benchmark several famous pipelines on our dataset for joint 3D mesh reconstruction and novel view synthesis. Our dataset and benchmark show great potential in promoting the improvements for fusing 3D reconstruction and high-quality rendering in a robust and computationally efficient end-to-end fashion. The dataset and code are available at the project website: https://xuqianren.github.io/publications/MuSHRoom/.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)</title>
<link>https://arxiv.org/abs/2403.07573</link>
<guid>https://arxiv.org/abs/2403.07573</guid>
<content:encoded><![CDATA[
<div> 关键词: 6G、资源稀缺、计算网络融合、自适应计算网络融合、持续学习

<br /><br />总结:

本文探讨了在6G发展的背景下，为应对资源稀缺和满足严格的服务质量要求，计算网络融合（CNC）作为资源整合的重要策略受到关注。然而，现有的CNC机制可能难以适应用户、服务和资源持续变化的需求，因此文章提出了自适应计算网络融合（ACNC）的概念。ACNC利用机器学习进行自主的计算和网络资源联合编排，以处理动态且大量的用户请求。该机制主要包括状态识别和上下文检测两个功能，通过降维技术生成系统状态的抽象层次结构，并使用持续学习对系统状态进行分类，由专用的机器学习代理进行高效管理。整个流程在一个闭环中由端到端（E2E）编排器监督资源分配。文章以Metaverse场景为例，阐述了ACNC在资源调配中的应用以及采用Segment Routing v6（SRv6）的情况，并给出了ACNC的工作流程及效率评估的数值分析，最后讨论了相关挑战和未来研究方向。 <div>
arXiv:2403.07573v2 Announce Type: replace 
Abstract: In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent requirements. ACNC encompasses two primary functionalities: state recognition and context detection. Given the intricate nature of the user-service-computing-network space, the paper employs dimension reduction to generate live, holistic, abstract system states in a hierarchical structure. To address the challenges posed by dynamic changes, Continual Learning (CL) is employed, classifying the system state into contexts controlled by dedicated ML agents, enabling them to operate efficiently. These two functionalities are intricately linked within a closed loop overseen by the End-to-End (E2E) orchestrator to allocate resources. The paper introduces the components of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in resource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow, details a numerical analysis for efficiency assessment, and concludes with discussions on relevant challenges and potential avenues for future research.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Block Circulant Codes with Application to Decentralized Systems</title>
<link>https://arxiv.org/abs/2406.12160</link>
<guid>https://arxiv.org/abs/2406.12160</guid>
<content:encoded><![CDATA[
<div> 关键词：块循环码、分布式擦除解码、相对最小距离、数据可用性问题、区块链网络

<br /><br />总结:
本文提出了一种新的[n,k,d]块循环码家族，该码结构由多个局部码[$n_0 \ll n$, $k_0 \ll k$, $d_0$]组成，满足三个特性：(1) 支持分布式擦除解码；(2) 可通过参数调整将最小距离$d$放大至超过$d_0$；(3) 适用于基于密码学承诺方案的低复杂度代码符号验证。这些特性使其成为解决区块链网络中数据可用性问题的理想选择。相较于目前使用的二维Reed-Solomon (RS) 码，这种新码在高码率情况下能在保持给定速率(k/n)的同时，实现较大的相对最小距离(d/n)。

设计过程分为两步：首先，构建了线性依赖关系结构，即块循环拓扑$T_{[\mu,\lambda,\omega]}(\rho)$，其中包含$\mu$个受$\rho$个奇偶校验约束的局部码，各局部码间的符号集合以均匀模式相交，由重叠因子$\lambda$和重叠宽度$\omega$决定。接着，具体化拓扑结构，构造块循环码${\cal C}_{\text{BC}}[\mu,\lambda,\omega,\rho]$，每个局部码为$[\lambda\omega+\rho,\lambda\omega,\rho+1]$的广义RS码。该块循环码有$n=\mu(\rho+\omega)$，$k=\mu\omega$，并证明在一定条件下，其最小距离$d=\lambda\rho+1$。当$\lambda=2$时，可证得$d=2\rho+1$，并提出了一个高效的并行化擦除纠正解码器，当存在不多于$2\rho$个擦除时，能完全恢复原始编码信息。该解码器利用一种新颖的解码机制，通过迭代从一对局部码中恢复擦除的信息。 <div>
arXiv:2406.12160v2 Announce Type: replace 
Abstract: In this paper, we design a family of $[n,k,d]$ block circulant codes that consist of many $[n_0 \ll n,k_0 \ll k,d_0]$ local codes and that satisfy three properties: (1) the code supports distributed erasure decoding, (2) $d$ can be scaled above $d_0$ by a given parameter, and (3) it is amenable to low complexity verification of code symbols using a cryptographic commitment scheme. These properties make the code ideal for use in protocols that address the data availability problem in blockchain networks. Moreover, the code outperforms the currently used 2D Reed-Solomon (RS) code with a larger relative minimum distance $(d/n)$, as desired in the protocol, for a given rate $(k/n)$ in the high-rate regime.
  The code is designed in two steps. First, we develop the topology, i.e., the structure of linear dependence relations among code symbols, and define it as the block circulant topology $T_{[\mu,\lambda,\omega]}(\rho)$. In this topology, there are $\mu$ local codes, each constrained by $\rho$ parity checks. The set of symbols of a local code intersects with another in a uniform pattern, determined by two parameters, namely the overlap factor $\lambda$ and the overlap width $\omega$. Next, we instantiate the topology, i.e., to specify the coefficients of linear dependence relations, to construct the block circulant codes ${\cal C}_{\text{BC}}[\mu,\lambda,\omega,\rho]$. Every local code is a $[\lambda\omega+\rho,\lambda\omega,\rho+1]$ generalized RS code. The block circulant code has $n=\mu(\rho+\omega)$, $k=\mu\omega$ and we show that $d=\lambda\rho+1$ under certain conditions. For $\lambda=2$, we prove that $d=2\rho+1$ always, and provide an efficient, parallelizable erasure-correcting decoder that fully recovers the codeword when there are $\leq 2\rho$ erasures. The decoder uses a novel decoding mechanism that iteratively recovers erasures from pairs of local codes.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Data Analysis in the Era of Large-Language Models</title>
<link>https://arxiv.org/abs/2412.09640</link>
<guid>https://arxiv.org/abs/2412.09640</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链数据分析、大型语言模型、挑战、技术整合、研究机会

<br /><br />总结:
本文探讨了区块链数据分析的重要性及其在欺诈检测、合规性监管、智能合约审计和去中心化金融风险管理等方面的应用。目前，区块链数据分析工具面临着数据稀缺、通用性不足以及缺乏推理能力等挑战。文章提出，大型语言模型（LLMs）能够缓解这些挑战，但关于LLM在区块链数据分析中的综合应用尚未见全面系统的研究。论文系统地探索了LLM集成在区块链数据分析中的潜在技术和设计模式，并指出了未来的研究机遇与挑战，强调了这一有前景领域进一步探索的必要性。该文旨在为学术界、工业界及政策制定者提供有价值的见解，促进LLM在区块链数据分析中的融合应用。 <div>
arXiv:2412.09640v1 Announce Type: new 
Abstract: Blockchain data analysis is essential for deriving insights, tracking transactions, identifying patterns, and ensuring the integrity and security of decentralized networks. It plays a key role in various areas, such as fraud detection, regulatory compliance, smart contract auditing, and decentralized finance (DeFi) risk management. However, existing blockchain data analysis tools face challenges, including data scarcity, the lack of generalizability, and the lack of reasoning capability.
  We believe large language models (LLMs) can mitigate these challenges; however, we have not seen papers discussing LLM integration in blockchain data analysis in a comprehensive and systematic way. This paper systematically explores potential techniques and design patterns in LLM-integrated blockchain data analysis. We also outline prospective research opportunities and challenges, emphasizing the need for further exploration in this promising field. This paper aims to benefit a diverse audience spanning academia, industry, and policy-making, offering valuable insights into the integration of LLMs in blockchain data analysis.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TransferLight: Zero-Shot Traffic Signal Control on any Road-Network</title>
<link>https://arxiv.org/abs/2412.09719</link>
<guid>https://arxiv.org/abs/2412.09719</guid>
<content:encoded><![CDATA[
<div> 关键词：TransferLight、交通信号控制、道路网络、通用性、图神经网络<br /><br />总结：<br />
TransferLight是一个针对交通信号控制的创新框架，旨在实现对不同道路网络、多样化的交通条件和交叉口几何形状的强泛化能力。其核心采用了一个基于log-distance奖励函数，提供空间感知的信号优先级并能适应各种车道配置，克服了传统压力奖励方法的局限。该框架利用层次化、异质性和有向的图神经网络架构，精确捕捉细粒度的交通动态，保证了对任意交叉口布局的可转移性。通过采用分散式多智能体方法、全局奖励和新颖的状态转移先验，TransferLight构建了一个无需重训练即可零样本扩展到任何道路网络的单权重共享策略。此外，通过训练过程中的领域随机化进一步提升了模型的泛化能力。实验结果证明了TransferLight在未见过的场景中表现出优越性能，为满足城市交通日益变化的需求推进了实用且具有泛化的智能交通系统的发展。 <div>
arXiv:2412.09719v1 Announce Type: new 
Abstract: Traffic signal control plays a crucial role in urban mobility. However, existing methods often struggle to generalize beyond their training environments to unseen scenarios with varying traffic dynamics. We present TransferLight, a novel framework designed for robust generalization across road-networks, diverse traffic conditions and intersection geometries. At its core, we propose a log-distance reward function, offering spatially-aware signal prioritization while remaining adaptable to varied lane configurations - overcoming the limitations of traditional pressure-based rewards. Our hierarchical, heterogeneous, and directed graph neural network architecture effectively captures granular traffic dynamics, enabling transferability to arbitrary intersection layouts. Using a decentralized multi-agent approach, global rewards, and novel state transition priors, we develop a single, weight-tied policy that scales zero-shot to any road network without re-training. Through domain randomization during training, we additionally enhance generalization capabilities. Experimental results validate TransferLight's superior performance in unseen scenarios, advancing practical, generalizable intelligent transportation systems to meet evolving urban traffic demands.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Empowering Patients for Disease Diagnosis and Clinical Treatment: A Smart Contract-Enabled Informed Consent Strategy</title>
<link>https://arxiv.org/abs/2412.09820</link>
<guid>https://arxiv.org/abs/2412.09820</guid>
<content:encoded><![CDATA[
<div> 关键词：数字医疗系统、患者数据隐私、安全性、区块链、智能合约

总结:<br />
本文关注于数字医疗系统带来的数据隐私和安全风险，提出了一种基于区块链和智能合约的解决方案。该方案旨在更好地管理患者对于健康记录访问的知情同意授权，确保授权执行的正确性和及时性，并提高透明度与问责制。通过区块链技术保证了同意过程的不可篡改性，而智能合约则能自动执行协议，进一步强化了对患者隐私保护的机制。实验评估表明，该提议的方法可以轻松地与现有医疗系统整合，不会带来重大的财务和技术挑战。 <div>
arXiv:2412.09820v1 Announce Type: new 
Abstract: Digital healthcare systems have revolutionized medical services, facilitating provider collaboration, enhancing diagnosis, and optimizing and improving treatments. They deliver superior quality, faster, reliable, and cost-effective services. Researchers are addressing pressing health challenges by integrating information technology, computing resources, and digital health records. However, digitizing healthcare introduces significant risks to patient data privacy and security, with the potential for unauthorized access to protected health information. Although patients can authorize data access through consent, there is a pressing need for mechanisms to ensure such given consent is informed and executed properly and timely. Patients deserve transparency and accountability regarding the access to their data: who access it, when, and under what circumstances. Current healthcare systems, often centralized, leave much to be desired in managing these concerns, leading to numerous security incidents. To address these issues, we propose a system based on blockchain and smart contracts for managing informed consent for accessing health records by the treatment team members, incorporating safeguards to verify that consent processes are correctly executed. Blockchain's inherent immutability ensures the integrity of consent. Smart contracts automatically execute agreements, enhancing accountability. They provide a robust framework for protecting patient privacy in the digital age. Experimental evaluations show that the proposed approach can be integrated easily with the existing healthcare systems without incurring financial and technological challenges.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SCRUBD: Smart Contracts Reentrancy and Unhandled Exceptions Vulnerability Dataset</title>
<link>https://arxiv.org/abs/2412.09935</link>
<guid>https://arxiv.org/abs/2412.09935</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约, 以太坊区块链, 攻击漏洞, 安全工具, SCRUBD

总结:
本文介绍了针对智能合约（SC）安全性的研究，其中智能合约在以太坊区块链上处理价值数百万美元的交易，因而成为黑客利用漏洞窃取资金的目标。为了评估检测SC漏洞的各种工具的效果，需要一个带标签的SC漏洞数据集。现有的SC数据集存在局限性，如覆盖的漏洞场景有限和标签错误。为填补这一空白，文章提出了名为SCRUBD的新数据集，该数据集包括真实世界SC和合成SC，并对其进行了RE和UX漏洞的手动标记。实证研究表明，Slither在基于众包标注的数据集上检测RE漏洞的表现优于其他工具，而Sailfish则在人工合成的数据集中对于RE漏洞检测表现最佳。对于UX漏洞，Slither同样表现出超越其他工具的检测能力。 <div>
arXiv:2412.09935v1 Announce Type: new 
Abstract: Smart Contracts (SCs) handle transactions in the Ethereum blockchain worth millions of United States dollars, making them a lucrative target for attackers seeking to exploit vulnerabilities and steal funds. The Ethereum community has developed a rich set of tools to detect vulnerabilities in SCs, including reentrancy (RE) and unhandled exceptions (UX). A dataset of SCs labelled with vulnerabilities is needed to evaluate the tools' efficacy. Existing SC datasets with labelled vulnerabilities have limitations, such as covering only a limited range of vulnerability scenarios and containing incorrect labels. As a result, there is a lack of a standardized dataset to compare the performances of these tools. SCRUBD aims to fill this gap. We present a dataset of real-world SCs and synthesized SCs labelled with RE and UX. The real-world SC dataset is labelled through crowdsourcing, followed by manual inspection by an expert, and covers both RE and UX vulnerabilities. On the other hand, the synthesized dataset is carefully crafted to cover various RE scenarios only. Using SCRUBD we compared the performance of six popular vulnerability detection tools. Based on our study, we found that Slither outperforms other tools on a crowdsourced dataset in detecting RE vulnerabilities, while Sailfish outperforms other tools on a manually synthesized dataset for detecting RE. For UX vulnerabilities, Slither outperforms all other tools.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cooperative Target Defense under Communication and Sensing Constraints</title>
<link>https://arxiv.org/abs/2412.09939</link>
<guid>https://arxiv.org/abs/2412.09939</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、入侵者、目标防御、分布式反馈策略、非线性共识问题

总结:
该文研究了一种目标防御问题的变体，其中一组守卫需要同时捕获一个入侵者。入侵者的任务是在不被守卫团队同时捕捉的情况下到达目标位置。部分守卫存在感知限制，无法在任何时候得知入侵者的位置或速度信息。守卫们可以通过连接的通信图进行相互交流。文章提出了一种分布式反馈策略，将同时捕捉问题转化为一个独特的非线性共识问题，并推导出了关于代理人速度、感知和通信能力的同时捕捉充分条件。通过大量的数值模拟对提出的分布式控制器进行了评估。<br /><br /> <div>
arXiv:2412.09939v1 Announce Type: new 
Abstract: We consider a variant of the target defense problems where a group of defenders are tasked to simultaneously capture an intruder. The intruder's objective is to reach a target without being simultaneously captured by the defender team. Some of the defenders are sensing-limited and do not have any information regarding the intruder's position or velocity at any time. The defenders may communicate with each other using a connected communication graph. We propose a decentralized feedback strategy for the defenders, which transforms the simultaneous capture problem into a unique nonlinear consensus problem. We derive a sufficient condition for simultaneous capture in terms of the agents' speeds, sensing, and communication capabilities. The proposed decentralized controller is evaluated through extensive numerical simulations.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI and the Future of Digital Public Squares</title>
<link>https://arxiv.org/abs/2412.09988</link>
<guid>https://arxiv.org/abs/2412.09988</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、互联网、公共空间、对话系统、风险

<br /><br />总结:

近年来，大型语言模型（LLMs）和互联网两大技术进步重塑了公共空间。本文探讨了LLMs在提升数字公共广场的四个应用场景：集体对话系统、桥梁系统、社区管理及证明人性系统。通过收集70多位公民社会专家和技术人员的见解，文章指出LLMs为大规模对话提供了开创性机遇，但同时也带来了加剧社会分歧的风险。因此，文章提出了未来AI研究与投资的议程，旨在强化数字公共广场并防范人工智能可能的误用。 <div>
arXiv:2412.09988v1 Announce Type: new 
Abstract: Two substantial technological advances have reshaped the public square in recent decades: first with the advent of the internet and second with the recent introduction of large language models (LLMs). LLMs offer opportunities for a paradigm shift towards more decentralized, participatory online spaces that can be used to facilitate deliberative dialogues at scale, but also create risks of exacerbating societal schisms. Here, we explore four applications of LLMs to improve digital public squares: collective dialogue systems, bridging systems, community moderation, and proof-of-humanity systems. Building on the input from over 70 civil society experts and technologists, we argue that LLMs both afford promising opportunities to shift the paradigm for conversations at scale and pose distinct risks for digital public squares. We lay out an agenda for future research and investments in AI that will strengthen digital public squares and safeguard against potential misuses of AI.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Decentralized Optimization with Relay Communication</title>
<link>https://arxiv.org/abs/2212.10859</link>
<guid>https://arxiv.org/abs/2212.10859</guid>
<content:encoded><![CDATA[
<div> 关键词：Privacy Leakage Frequency (PLF)，DP-RECAL，分布式优化算法，隐私性能，通信复杂度

总结:
<br />
针对大规模网络环境中的安全问题，该文引入了新的衡量指标“隐私泄漏频率(PLF)”，揭示了算法通信与隐私泄露之间的关系。基于此，文章提出了一种名为DP-RECAL的新颖差分隐私分布式 primal-dual 算法，利用操作器分裂方法和中继通信机制来降低PLF，从而减少整体隐私预算。相较于现有差分隐私算法，DP-RECAL展现了更优的隐私性能和通信复杂度。此外，在无协调的网络独立步长条件下，论文证明了DP-RECAL对于一般凸问题的收敛性，并在满足测地亚正规性的条件下建立了线性收敛率。实证分析和基于真实世界数据集的数值实验验证了理论结果，并表明DP-RECAL能够抵御一些经典的梯度泄露攻击。 <div>
arXiv:2212.10859v2 Announce Type: replace-cross 
Abstract: Security concerns in large-scale networked environments are becoming increasingly critical. To further improve the algorithm security from the design perspective of decentralized optimization algorithms, we introduce a new measure: Privacy Leakage Frequency (PLF), which reveals the relationship between communication and privacy leakage of algorithms, showing that lower PLF corresponds to lower privacy budgets. Based on such assertion, a novel differentially private decentralized primal--dual algorithm named DP-RECAL is proposed to take advantage of operator splitting method and relay communication mechanism to experience less PLF so as to reduce the overall privacy budget. To the best of our knowledge, compared with existing differentially private algorithms, DP-RECAL presents superior privacy performance and communication complexity. In addition, with uncoordinated network-independent stepsizes, we prove the convergence of DP-RECAL for general convex problems and establish a linear convergence rate under the metric subregularity. Evaluation analysis on least squares problem and numerical experiments on real-world datasets verify our theoretical results and demonstrate that DP-RECAL can defend some classical gradient leakage attacks.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reward-based Blockchain Infrastructure for 3D IC Supply Chain Provenance</title>
<link>https://arxiv.org/abs/2412.08777</link>
<guid>https://arxiv.org/abs/2412.08777</guid>
<content:encoded><![CDATA[
<div> 关键词：异构集成、2.5D/3D芯片、区块链技术、供应链信任、分布式信任

<br /><br />总结:
随着半导体行业向异构集成的转变，2.5D/3D芯片因其高性能和能效受到广泛关注。然而，复杂的供应链带来了芯片安全性挑战，特别是在不信任地区生产的芯片可能引入恶意电路。为解决这一问题，本文提出了一种创新方法，利用区块链技术确保集成电路及芯片let在供应链中的可追溯性。针对全球分散且可能处于不同区块链联盟的制造商，文章提出了双层结构的信任建立方案：底层采用基于区块链的IC供应链原产地框架，允许不同联盟运行的区块链实例间进行交易，实现每个IC完整来源有向无环图（DAG）的追踪；上层则实施跨链声誉机制，对实体赋予声誉评分并特别关注高风险的跨信任区域交易。这一方法增强了区块链数据的可信度，有效降低了多联盟使用带来的潜在风险，为日益发展的异构集成中2.5D/3D IC安全提供了坚实基础。 <div>
arXiv:2412.08777v1 Announce Type: new 
Abstract: In response to the growing demand for enhanced performance and power efficiency, the semiconductor industry has witnessed a paradigm shift toward heterogeneous integration, giving rise to 2.5D/3D chips. These chips incorporate diverse chiplets, manufactured globally and integrated into a single chip. Securing these complex 2.5D/3D integrated circuits (ICs) presents a formidable challenge due to inherent trust issues within the semiconductor supply chain. Chiplets produced in untrusted locations may be susceptible to tampering, introducing malicious circuits that could compromise sensitive information. This paper introduces an innovative approach that leverages blockchain technology to establish traceability for ICs and chiplets throughout the supply chain. Given that chiplet manufacturers are dispersed globally and may operate within different blockchain consortiums, ensuring the integrity of data within each blockchain ledger becomes imperative. To address this, we propose a novel dual-layer approach for establishing distributed trust across diverse blockchain ledgers. The lower layer comprises of a blockchain-based framework for IC supply chain provenance that enables transactions between blockchain instances run by different consortiums, making it possible to trace the complete provenance DAG of each IC. The upper layer implements a multi-chain reputation scheme that assigns reputation scores to entities while specifically accounting for high-risk transactions that cross blockchain trust zones. This approach enhances the credibility of the blockchain data, mitigating potential risks associated with the use of multiple consortiums and ensuring a robust foundation for securing 2.5D/3D ICs in the evolving landscape of heterogeneous integration.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BA-ORABE: Blockchain-Based Auditable Registered Attribute-Based Encryption With Reliable Outsourced Decryption</title>
<link>https://arxiv.org/abs/2412.08957</link>
<guid>https://arxiv.org/abs/2412.08957</guid>
<content:encoded><![CDATA[
<div> 关键词：Attribute-based encryption (ABE), registered ABE, key curator, decryption cloud service (DCS), blockchain

总结:<br />
本文提出了首个基于区块链的完全可审计注册属性基加密方案BA-ORABE。该方案实现了无需可信中心的注册属性基加密，并通过可验证标签机制确保了密文转换的可验证性以及诚实解密云服务的豁免性，后者利用零知识欺诈证明在乐观假设下得到保障。此外，BA-ORABE系统还具备公平性和去中心化的外包特性，从而保护各方利益，并通过区块链技术实现透明、全程可审计的注册与外包流程。文章对方案进行了正式的安全分析，并在以太坊上实施和评估，证明了其可行性和效率。 <div>
arXiv:2412.08957v1 Announce Type: new 
Abstract: Attribute-based encryption (ABE) is a generalization of public-key encryption that enables fine-grained access control in cloud services. Recently, Hohenberger et al. (Eurocrypt 2023) introduced the notion of registered ABE, which is an ABE scheme without a trusted central authority. Instead, users generate their own public/secret keys and then register their keys and attributes with a key curator. The key curator is a transparent and untrusted entity and its behavior needs to be audited for malicious registration. In addition, pairing-based registered ABE still suffers the heavy decryption overhead like ABE. A general approach to address this issue is to outsource decryption to a decryption cloud service (DCS). In this work, we propose BA-ORABE, the first fully auditable registered ABE with reliable outsource decryption scheme based on blockchain. First, we utilize a verifiable tag mechanism to achieve verifiability of ciphertext transformation, and the exemptibility which enables the honest DCS to escape from wrong claims is guaranteed by zero knowledge fraud proof under optimistic assumption. Additionally, our system achieves fairness and decentralized outsourcing to protect the interests of all parties and the registration and outsourcing process are transparent and fully auditable through blockchain. Finally, we give formal security analysis and implement and evaluate our scheme on Ethereum to demonstrate its feasibility and efficiency.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Building a Mastodon Compatible Java Server for ActivityPub</title>
<link>https://arxiv.org/abs/2412.09011</link>
<guid>https://arxiv.org/abs/2412.09011</guid>
<content:encoded><![CDATA[
<div> 关键词: ActivityPub、Fediverse、Mastodon、Java Spring Boot、分布式服务器

总结:
本文分析了ActivityPub这一去中心化社交网络协议，并指出了其在Fediverse中的广泛应用。文章深入探讨了Mastodon服务器对ActivityPub协议的具体实现，并介绍了一种使用Java Spring Boot和ActivityPub构建能与Mastodon服务器相互通信的自定义实例的方法。 <div>
arXiv:2412.09011v1 Announce Type: new 
Abstract: ActivityPub is a decentralized social networking protocol that has gained significant attention from the media for its ability to communicate through the Fediverse, short for the federated web. Servers such as Mastodon implement the ActivityPub protocol to communicate over the Fediverse. In this paper, we deconstruct the core protocols used to build the distributed servers of the Fediverse. We explore Mastodon's complex implementation of ActivityPub and created our own Mastodon instance using Java Spring Boot and ActivityPub to interoperate with Mastodon servers.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Convergence of Decentralized Gradient Tracking under the KL Property</title>
<link>https://arxiv.org/abs/2412.09556</link>
<guid>https://arxiv.org/abs/2412.09556</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体优化、去中心化、无向图、Kurdyka-{\L}ojasiewicz (KL)性质、SONATA算法

总结:<br />
本文研究了在由无向图建模的网络环境中的分布式多智能体非凸光滑函数优化问题，该问题包含了满足约束或解决方案额外结构（如稀疏性、低秩）的凸扩展值函数。文章假设目标函数满足具有给定指数$\theta\in[0,1)$的KL性质，这个性质在许多实际应用中的非凸函数中得到满足，并在集中式设置下可以实现强大的收敛性保证。文章证明了著名的分布式梯度跟踪算法SONATA对此类问题也能够达到类似的收敛行为：<br />
1) 当$\theta\in(0,1/2]$时，SONATA生成的序列以R-线性速率收敛到问题的一个驻点解；<br />
2) 当$\theta\in(1/2,1)$时，证明了亚线性收敛率；<br />
3) 当$\theta=0$时，迭代过程将在有限步数内收敛或以R-线性速率收敛。这与集中式proximal梯度算法的收敛行为相匹配，除了当$\theta=0$的情况。数值实验验证了理论发现。 <div>
arXiv:2412.09556v1 Announce Type: cross 
Abstract: We study decentralized multiagent optimization over networks, modeled as undirected graphs. The optimization problem consists of minimizing a nonconvex smooth function plus a convex extended-value function, which enforces constraints or extra structure on the solution (e.g., sparsity, low-rank). We further assume that the objective function satisfies the Kurdyka-{\L}ojasiewicz (KL) property, with given exponent $\theta\in [0,1)$. The KL property is satisfied by several (nonconvex) functions of practical interest, e.g., arising from machine learning applications; in the centralized setting, it permits to achieve strong convergence guarantees. Here we establish convergence of the same type for the notorious decentralized gradient-tracking-based algorithm SONATA. Specifically, $\textbf{(i)}$ when $\theta\in (0,1/2]$, the sequence generated by SONATA converges to a stationary solution of the problem at R-linear rate;$ \textbf{(ii)} $when $\theta\in (1/2,1)$, sublinear rate is certified; and finally $\textbf{(iii)}$ when $\theta=0$, the iterates will either converge in a finite number of steps or converges at R-linear rate. This matches the convergence behavior of centralized proximal-gradient algorithms except when $\theta=0$. Numerical results validate our theoretical findings.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedAA: A Reinforcement Learning Perspective on Adaptive Aggregation for Fair and Robust Federated Learning</title>
<link>https://arxiv.org/abs/2402.05541</link>
<guid>https://arxiv.org/abs/2402.05541</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 个性化FL, 自适应聚合, 模型稳健性, 公平性

<br /><br />总结:

本文提出了一种名为FedAA的新颖方法，用于解决联邦学习中的统计异质性和对抗攻击问题，以提升模型稳健性和保证参与者之间的公平性。FedAA通过适应性聚合优化客户端贡献，特别采用基于深度确定性策略梯度算法的连续控制聚合权重方案，创新地利用模型参数距离进行客户端选择，并结合验证集性能的奖励机制。实验表明，就鲁棒性而言，FedAA优于现有最先进的方法，同时保持了相当的公平性，为构建抗御性强、公平的分布式联邦系统提供了一个有前景的解决方案。项目代码已发布于https://github.com/Gp1g/FedAA。 <div>
arXiv:2402.05541v2 Announce Type: replace 
Abstract: Federated Learning (FL) has emerged as a promising approach for privacy-preserving model training across decentralized devices. However, it faces challenges such as statistical heterogeneity and susceptibility to adversarial attacks, which can impact model robustness and fairness. Personalized FL attempts to provide some relief by customizing models for individual clients. However, it falls short in addressing server-side aggregation vulnerabilities. We introduce a novel method called \textbf{FedAA}, which optimizes client contributions via \textbf{A}daptive \textbf{A}ggregation to enhance model robustness against malicious clients and ensure fairness across participants in non-identically distributed settings. To achieve this goal, we propose an approach involving a Deep Deterministic Policy Gradient-based algorithm for continuous control of aggregation weights, an innovative client selection method based on model parameter distances, and a reward mechanism guided by validation set performance. Empirically, extensive experiments demonstrate that, in terms of robustness, \textbf{FedAA} outperforms the state-of-the-art methods, while maintaining comparable levels of fairness, offering a promising solution to build resilient and fair federated systems. Our code is available at https://github.com/Gp1g/FedAA.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Protocol Learning, Decentralized Frontier Risk and the No-Off Problem</title>
<link>https://arxiv.org/abs/2412.07890</link>
<guid>https://arxiv.org/abs/2412.07890</guid>
<content:encoded><![CDATA[
<div> 关键词: Protocol Learning、前沿模型、去中心化训练、风险分析、通信效率

总结:<br />
本文提出了第三种开发和分布前沿模型的方法——协议学习，它通过激励参与者的分布式网络进行训练，有望聚合比任何单一中央实体高出几个数量级的计算资源。然而，这也带来了新的挑战，如异构、不可靠的节点、恶意参与者以及需要保护激励机制的不可提取模型等问题，特别是“无关闭问题”，即无法单方面停止集体训练的模型。文章回顾了近期的技术进展，表明去中心化训练可能是可行的，涉及新兴的通信效率策略和容错方法，同时指出了仍存在的关键开放问题。与认为去中心化会放大前沿风险的观点相反，文章认为协议学习的透明性、分布式治理和民主化的访问权限实际上可以降低这些风险，相比当前集中式体制更具优势。 <div>
arXiv:2412.07890v1 Announce Type: new 
Abstract: Frontier models are currently developed and distributed primarily through two channels: centralized proprietary APIs or open-sourcing of pre-trained weights. We identify a third paradigm - Protocol Learning - where models are trained across decentralized networks of incentivized participants. This approach has the potential to aggregate orders of magnitude more computational resources than any single centralized entity, enabling unprecedented model scales and capabilities. However, it also introduces novel challenges: heterogeneous and unreliable nodes, malicious participants, the need for unextractable models to preserve incentives, and complex governance dynamics. To date, no systematic analysis has been conducted to assess the feasibility of Protocol Learning or the associated risks, particularly the 'No-Off Problem' arising from the inability to unilaterally halt a collectively trained model. We survey recent technical advances that suggest decentralized training may be feasible - covering emerging communication-efficient strategies and fault-tolerant methods - while highlighting critical open problems that remain. Contrary to the notion that decentralization inherently amplifies frontier risks, we argue that Protocol Learning's transparency, distributed governance, and democratized access ultimately reduce these risks compared to today's centralized regimes.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learn How to Query from Unlabeled Data Streams in Federated Learning</title>
<link>https://arxiv.org/abs/2412.08138</link>
<guid>https://arxiv.org/abs/2412.08138</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习(Federated Learning)，无标签数据，样本选择，强化学习(Reinforcement Learning)，LeaDQ

总结:
本文探讨了联邦学习中面对无标签数据流时如何有效地选取有信息量的样本进行标注的问题。针对这一挑战，文章提出了名为LeaDQ的新方法，它将数据查询过程视为一个协作分散型决策问题，并利用多智能体强化学习算法来解决。LeaDQ能够在全局信息的隐性指导下，让各个客户端学习有效的局部策略，引导它们选择能提升全局模型准确性的样本。实验结果表明，LeaDQ在图像和文本任务等不同联邦学习场景下均表现出优越性能，优于基准算法。 <div>
arXiv:2412.08138v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative learning among decentralized clients while safeguarding the privacy of their local data. Existing studies on FL typically assume offline labeled data available at each client when the training starts. Nevertheless, the training data in practice often arrive at clients in a streaming fashion without ground-truth labels. Given the expensive annotation cost, it is critical to identify a subset of informative samples for labeling on clients. However, selecting samples locally while accommodating the global training objective presents a challenge unique to FL. In this work, we tackle this conundrum by framing the data querying process in FL as a collaborative decentralized decision-making problem and proposing an effective solution named LeaDQ, which leverages multi-agent reinforcement learning algorithms. In particular, under the implicit guidance from global information, LeaDQ effectively learns the local policies for distributed clients and steers them towards selecting samples that can enhance the global model's accuracy. Extensive simulations on image and text tasks show that LeaDQ advances the model performance in various FL scenarios, outperforming the benchmarking algorithms.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Overview of the Decentralized Reconfiguration Language Concerto-D through its Maude Formalization</title>
<link>https://arxiv.org/abs/2412.08233</link>
<guid>https://arxiv.org/abs/2412.08233</guid>
<content:encoded><![CDATA[
<div> 关键词：Concerto-D、分布式重配置语言、Maude、正式语义、边缘计算、Cyber-Physical Systems (CPS)

<br /><br />总结:

本文提出了一个基于Maude形式化方法的分布式重配置语言Concerto-D的概述。相较于相关工作，Concerto-D在两个方面有所改进：一是通过实现大量局部重配置计划的去中心化协调，避免了在网络不稳定（如边缘计算或Cyber-Physical Systems (CPS)）环境中出现单点故障的问题；二是使用Maude为该语言提供了机械化的形式语义，从而保证了其执行的正确性。文章中，通过一个来源于实际CPS案例研究的重配置示例来说明Concerto-D语言及其语义。由于Maude是一种基于重写逻辑的正式规范语言，因此非常适合描述并发模型。 <div>
arXiv:2412.08233v1 Announce Type: new 
Abstract: We propose an overview of the decentralized reconfiguration language Concerto-D through its Maude formalization. Concerto-D extends the already published Concerto language. Concerto-D improves on two different parameters compared with related work: the decentralized coordination of numerous local reconfiguration plans which avoid a single point of failure when considering unstable networks such as edge computing, or cyber-physical systems (CPS) for instance; and a mechanized formal semantics of the language with Maude which offers guarantees on the executability of the semantics. Throughout the paper, the Concerto-D language and its semantics are exemplified with a reconfiguration extracted from a real case study on a CPS. We rely on the Maude formal specification language, which is based on rewriting logic, and consequently perfectly suited for describing a concurrent model.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pioplat: A Scalable, Low-Cost Framework for Latency Reduction in Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2412.08367</link>
<guid>https://arxiv.org/abs/2412.08367</guid>
<content:encoded><![CDATA[
<div> 关键词：Pioplat、延迟减少、区块链、分布式应用程序、低 latency 通信协议

<br /><br />总结:
本文介绍了Pioplat，一个针对许可式区块链上日益增多的对延迟敏感的应用场景设计的可行、可定制、低成本的延迟降低框架。Pioplat包括位于不同大陆的多个中继节点以及至少一个配备特殊工具的全节点变体。其节点选择策略与低延迟通信协议相结合，提供了有效减少延迟的弹性方法。文章通过在五大洲运行的实验证明了Pioplat的可行性，并显示Pioplat能够显著降低接收区块/交易和发送交易的延迟，从而满足大多数延迟敏感使用场景的需求。此外，为了促进进一步的研究和使人们能够在更多区块链系统上应用该框架，文章提供了Pioplat的完整实现。 <div>
arXiv:2412.08367v1 Announce Type: new 
Abstract: As decentralized applications on permissionless blockchains are prevalent, more and more latency-sensitive usage scenarios emerged, where the lower the latency of sending and receiving messages, the better the chance of earning revenue. To reduce latency, we present Pioplat, a feasible, customizable, and low-cost latency reduction framework consisting of multiple relay nodes on different continents and at least one instrumented variant of a full node. The node selection strategy of Pioplat and the low-latency communication protocol offer an elastic way to reduce latency effectively. We demonstrate Pioplat's feasibility with an implementation running on five continents and show that Pioplat can significantly reduce the latency of receiving blocks/transactions and sending transactions, thus fulfilling the requirements of most latency-sensitive use cases. Furthermore, we provide the complete implementation of Pioplat to promote further research and allow people to apply the framework to more blockchain systems.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grimm: A Plug-and-Play Perturbation Rectifier for Graph Neural Networks Defending against Poisoning Attacks</title>
<link>https://arxiv.org/abs/2412.08555</link>
<guid>https://arxiv.org/abs/2412.08555</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络, 边对抗攻击, 防御策略, 图代理网络, 分布式交互

总结:
本文针对图神经网络(GNNs)在全球优化端到端训练中易受边对抗攻击的问题，提出了一个新的防御模型——图代理网络(GAgN)。GAgN中的每个节点被视为具有1跳视图的代理，通过代理间的分布式交互，它们能够学习推断全局感知并执行包括节点嵌入、度数和邻居关系在内的任务，从而使节点具备过滤敌对边的能力并在执行分类任务时保持鲁棒性。此外，由于代理人具有有限视野，恶意消息无法在全球范围内传播，从而抵抗基于全局优化的次级攻击。理论证明单隐藏层多层感知机(MLPs)足以实现这些功能。实验结果显示，相比于现有最先进的防御方法，GAgN在被扰动的数据集上实现了最优的分类精度。 <div>
arXiv:2412.08555v1 Announce Type: new 
Abstract: End-to-end training with global optimization have popularized graph neural networks (GNNs) for node classification, yet inadvertently introduced vulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit the inherent opened interfaces of GNNs' input and output, perturbing critical edges and thus manipulating the classification results. Current defenses, due to their persistent utilization of global-optimization-based end-to-end training schemes, inherently encapsulate the vulnerabilities of GNNs. This is specifically evidenced in their inability to defend against targeted secondary attacks. In this paper, we propose the Graph Agent Network (GAgN) to address the aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent network in which each node is designed as an 1-hop-view agent. Through the decentralized interactions between agents, they can learn to infer global perceptions to perform tasks including inferring embeddings, degrees and neighbor relationships for given nodes. This empowers nodes to filtering adversarial edges while carrying out classification tasks. Furthermore, agents' limited view prevents malicious messages from propagating globally in GAgN, thereby resisting global-optimization-based secondary attacks. We prove that single-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient to achieve these functionalities. Experimental results show that GAgN effectively implements all its intended capabilities and, compared to state-of-the-art defenses, achieves optimal classification accuracy on the perturbed datasets.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comparative Evaluation of Automated Analysis Tools for Solidity Smart Contracts</title>
<link>https://arxiv.org/abs/2310.20212</link>
<guid>https://arxiv.org/abs/2310.20212</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链智能合约、安全性、评估工具、ISO/IEC 25010标准、基准测试

总结:
本文关注区块链智能合约的安全性问题，着重探讨了十款自动化的以太坊固态智能合约漏洞检测工具。文章提出了一种基于ISO/IEC 25010标准的新颖评价准则来评估这些工具的效果。为了辅助工具评测，作者构建了一个包括389份已标注智能合约和源自现实世界的20,000个独特案例的基准测试集。通过对所选工具进行比较分析，揭示了它们的优势与不足，指出了需要进一步改进的方向。该研究旨在为开发者和研究人员选择及使用智能合约分析工具提供指导，并促进提高智能合约的安全性和可靠性。 <div>
arXiv:2310.20212v4 Announce Type: replace 
Abstract: Blockchain smart contracts have emerged as a transformative force in the digital realm, spawning a diverse range of compelling applications. Since solidity smart contracts across various domains manage trillions of dollars in virtual coins, they become a prime target for attacks. One of the primary challenges is keeping abreast of the latest techniques and tools for developing secure smart contracts and examining those already deployed. In this paper, we seek to address these challenges from four aspects: (1) We begin by examining ten automatic tools, specifically focusing on their methodologies and their ability to identify vulnerabilities in solidity smart contracts. (2) We propose a novel criterion for evaluating these tools, based on the ISO/IEC 25010 standard. (3) To facilitate the evaluation of the selected tools, we construct a benchmark that encompasses two distinct datasets: a collection of 389 labelled smart contracts and a scaled set of 20,000 unique cases from real-world contracts. (4) We provide a comparison of the selected tools, offering insights into their strengths and weaknesses and highlighting areas where further improvements are needed. Through this evaluation, we hope to provide developers and researchers with valuable guidance on selecting and using smart contract analysis tools and contribute to the ongoing efforts to improve the security and reliability of smart contracts.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentMixer: Multi-Agent Correlated Policy Factorization</title>
<link>https://arxiv.org/abs/2401.08728</link>
<guid>https://arxiv.org/abs/2401.08728</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、集中式训练分布式执行、协调、AgentMixer、个体全局一致性

总结:
本文针对多智能体强化学习中的集中式训练分布式执行方法，提出了一种策略修改方案——AgentMixer。该方案旨在解决独立决策可能导致的协作性不足问题，允许智能体非线性地结合局部可观测策略形成联合完全可观测策略，从而促进协作。为确保在联合训练中心化和去中心化策略时的模式一致性，文章引入了“个体全局一致性”原则，并证明AgentMixer能够收敛到$\epsilon$-近似的关联平衡。实验结果显示，在Multi-Agent MuJoCo、SMAC-v2、矩阵游戏以及捕食者-猎物等基准测试中，AgentMixer的表现优于或与当前最先进的方法相当。<br /><br /> <div>
arXiv:2401.08728v2 Announce Type: replace 
Abstract: In multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) methods typically assume that agents make decisions based on their local observations independently, which may not lead to a correlated joint policy with coordination. Coordination can be explicitly encouraged during training and individual policies can be trained to imitate the correlated joint policy. However, this may lead to an \textit{asymmetric learning failure} due to the observation mismatch between the joint and individual policies. Inspired by the concept of correlated equilibrium, we introduce a \textit{strategy modification} called AgentMixer that allows agents to correlate their policies. AgentMixer combines individual partially observable policies into a joint fully observable policy non-linearly. To enable decentralized execution, we introduce \textit{Individual-Global-Consistency} to guarantee mode consistency during joint training of the centralized and decentralized policies and prove that AgentMixer converges to an $\epsilon$-approximate Correlated Equilibrium. In the Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks, AgentMixer outperforms or matches state-of-the-art methods.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal and Efficient Algorithms for Decentralized Online Convex Optimization</title>
<link>https://arxiv.org/abs/2402.09173</link>
<guid>https://arxiv.org/abs/2402.09173</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized online convex optimization (D-OCO)，regret bounds，convex函数，strongly convex函数，communication matrix

总结:

本文研究了分布式在线凸优化(D-OCO)问题，其中一组本地学习者仅使用局部计算和通信来最小化全局损失函数序列。先前的研究为凸函数和强凸函数分别建立了$O(n^{5/4}\rho^{-1/2}\sqrt{T})$和${O}(n^{3/2}\rho^{-1}\log T)$的遗憾界限。然而这些界限与已知的下界存在较大差距。为此，本文提出了一种新的D-OCO算法，将凸函数和强凸函数的遗憾界限降低到$\tilde{O}(n\rho^{-1/4}\sqrt{T})$和$\tilde{O}(n\rho^{-1/2}\log T)$。主要技术在于设计一种在线加速的 gossip 策略，实现更快的局部学习者间的平均共识。此外，通过充分利用特定网络拓扑结构的谱性质，进一步增强下界至$\Omega(n\rho^{-1/4}\sqrt{T})$和$\Omega(n\rho^{-1/2}\log T)$。这些结果表明新算法对于凸函数和强凸函数而言，在$T$、$n$和$\rho$上的遗憾性能近乎最优。最后，针对具有复杂约束的实际应用，文章还提出了一种无需投影操作的算法变体。分析表明该变体可以分别达到${O}(nT^{3/4})$和${O}(nT^{2/3}(\log T)^{1/3})$的遗憾界限，以及几乎最优的$\tilde{O}(\rho^{-1/2}\sqrt{T})$和$\tilde{O}(\rho^{-1/2}T^{1/3}(\log T)^{2/3})$通信轮数。 <div>
arXiv:2402.09173v3 Announce Type: replace 
Abstract: We investigate decentralized online convex optimization (D-OCO), in which a set of local learners are required to minimize a sequence of global loss functions using only local computations and communications. Previous studies have established $O(n^{5/4}\rho^{-1/2}\sqrt{T})$ and ${O}(n^{3/2}\rho^{-1}\log T)$ regret bounds for convex and strongly convex functions respectively, where $n$ is the number of local learners, $\rho<1$ is the spectral gap of the communication matrix, and $T$ is the time horizon. However, there exist large gaps from the existing lower bounds, i.e., $\Omega(n\sqrt{T})$ for convex functions and $\Omega(n)$ for strongly convex functions. To fill these gaps, in this paper, we first develop a novel D-OCO algorithm that can respectively reduce the regret bounds for convex and strongly convex functions to $\tilde{O}(n\rho^{-1/4}\sqrt{T})$ and $\tilde{O}(n\rho^{-1/2}\log T)$. The primary technique is to design an online accelerated gossip strategy that enjoys a faster average consensus among local learners. Furthermore, by carefully exploiting spectral properties of a specific network topology, we enhance the lower bounds for convex and strongly convex functions to $\Omega(n\rho^{-1/4}\sqrt{T})$ and $\Omega(n\rho^{-1/2}\log T)$, respectively. These results suggest that the regret of our algorithm is nearly optimal in terms of $T$, $n$, and $\rho$ for both convex and strongly convex functions. Finally, we propose a projection-free variant of our algorithm to efficiently handle practical applications with complex constraints. Our analysis reveals that the projection-free variant can achieve ${O}(nT^{3/4})$ and ${O}(nT^{2/3}(\log T)^{1/3})$ regret bounds for convex and strongly convex functions with nearly optimal $\tilde{O}(\rho^{-1/2}\sqrt{T})$ and $\tilde{O}(\rho^{-1/2}T^{1/3}(\log T)^{2/3})$ communication rounds, respectively.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Block-Term Tensor Regression for decentralised data analysis in healthcare</title>
<link>https://arxiv.org/abs/2412.06815</link>
<guid>https://arxiv.org/abs/2412.06815</guid>
<content:encoded><![CDATA[
<div> 关键词: Block-Term Tensor Regression (BTTR), Federated Block-Term Tensor Regression (FBTTR), federated learning, data privacy, healthcare

总结:
本文介绍了Federated Block-Term Tensor Regression (FBTTR)，这是一种针对Block-Term Tensor Regression (BTTR)的扩展，旨在解决在联邦学习场景中的数据隐私问题和促进跨机构协作。FBTTR能够在保护数据隐私的同时进行分布式数据分析，适合应用于医疗保健和神经科学等领域。文章通过两个案例研究验证了FBTTR的性能：一是利用BCI Competition IV数据集进行手指运动解码任务，结果显示FBTTR相对于集中式的BTTR在解码准确性上有优势，特别是在预测拇指运动方面。二是将FBTTR应用到预测心脏病的真实临床数据中，其表现优于标准的联邦学习方法以及集中式BTTR模型，在Fed-Heart-Disease数据集上获得了更高的AUC-ROC和准确率。 <div>
arXiv:2412.06815v1 Announce Type: new 
Abstract: Block-Term Tensor Regression (BTTR) has proven to be a powerful tool for modeling complex, high-dimensional data by leveraging multilinear relationships, making it particularly well-suited for applications in healthcare and neuroscience. However, traditional implementations of BTTR rely on centralized datasets, which pose significant privacy risks and hinder collaboration across institutions. To address these challenges, we introduce Federated Block-Term Tensor Regression (FBTTR), an extension of BTTR designed for federated learning scenarios. FBTTR enables decentralized data analysis, allowing institutions to collaboratively build predictive models while preserving data privacy and complying with regulations.
  FBTTR represents a major step forward in applying tensor regression to federated learning environments. Its performance is evaluated in two case studies: finger movement decoding from Electrocorticography (ECoG) signals and heart disease prediction. In the first case study, using the BCI Competition IV dataset, FBTTR outperforms non-multilinear models, demonstrating superior accuracy in decoding finger movements. For the dataset, for subject 3, the thumb obtained a performance of 0.76 $\pm$ .05 compared to 0.71 $\pm$ 0.05 for centralised BTTR. In the second case study, FBTTR is applied to predict heart disease using real-world clinical datasets, outperforming both standard federated learning approaches and centralized BTTR models. In the Fed-Heart-Disease Dataset, an AUC-ROC was obtained of 0.872 $\pm$ 0.02 and an accuracy of 0.772 $\pm$ 0.02 compared to 0.812 $\pm$ 0.003 and 0.753 $\pm$ 0.007 for the centralized model.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution</title>
<link>https://arxiv.org/abs/2412.06855</link>
<guid>https://arxiv.org/abs/2412.06855</guid>
<content:encoded><![CDATA[
<div> 关键词：合作、进化博弈论、人工智能、Web3、激励共生模型

总结:
本文探讨了合作在人类生存和进步中的重要性以及进化博弈论在此方面的作用。随着人工智能在人类系统中变得愈发关键，合作动态产生了前所未有的意义。文章提出利用基于透明度、问责制和信任的去中心化框架——Web3，来促进人与AI之间的合作，通过构建双向激励和相互适应的“激励共生模型”，实现双方目标的一致性。这种激励共生模型被视为一种以Web3原则为灵感的现代道德框架，利用区块链技术定义并执行针对人类和AI代理的规则、激励与后果。通过将这些原则融入到人机交互的架构中，Web3生态系统可以催化出有利于协作创新的环境。文章进一步阐述了激励共生模型在去中心化金融、治理和文化适应等多个领域的变革应用，展示了如何使人与AI共同进化，迈向共享且可持续的发展轨迹。

<br /><br /> <div>
arXiv:2412.06855v1 Announce Type: new 
Abstract: Cooperation is vital to our survival and progress. Evolutionary game theory offers a lens to understand the structures and incentives that enable cooperation to be a successful strategy. As artificial intelligence agents become integral to human systems, the dynamics of cooperation take on unprecedented significance. Decentralized frameworks like Web3, grounded in transparency, accountability, and trust, offer a foundation for fostering cooperation by establishing enforceable rules and incentives for humans and AI agents. Guided by our Incentivized Symbiosis model, a paradigm aligning human and AI agent goals through bidirectional incentives and mutual adaptation, we investigate mechanisms for embedding cooperation into human-agent coevolution. We conceptualize Incentivized Symbiosis as part of a contemporary moral framework inspired by Web3 principles, encoded in blockchain technology to define and enforce rules, incentives, and consequences for both humans and AI agents. By integrating these principles into the very architecture of human-agent interactions, Web3 ecosystems catalyze an environment ripe for collaborative innovation. Our study traverses several transformative applications of Incentivized Symbiosis, from decentralized finance to governance and cultural adaptation, illustrating how AI agents can coevolve with humans to forge a trajectory of shared, sustainable progress.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BrokerChain: A Blockchain Sharding Protocol by Exploiting Broker Accounts</title>
<link>https://arxiv.org/abs/2412.07202</link>
<guid>https://arxiv.org/abs/2412.07202</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链分片、Monoxide、热分片、跨分片交易、BrokerChain

总结:
本文关注了区块链分片技术中的热点分片问题和跨分片交易优化挑战。现有的如Monoxide等方案可能导致交易负载分布不均。为解决这一问题，文章提出了BrokerChain，这是一款针对账户状态分片的跨分片区块链协议。BrokerChain利用细粒度的状态分区和账户分割策略，并通过broker账户处理跨分片交易。文中对BrokerChain的安全性及相关属性进行了严格分析，并使用开源区块链分片原型BlockEmulator进行了一系列评估。结果显示，BrokerChain在交易吞吐量、交易确认延迟、交易池队列大小以及工作负载平衡等方面优于其他基线方案。 <div>
arXiv:2412.07202v1 Announce Type: new 
Abstract: State-of-the-art blockchain sharding solutions such as Monoxide, can cause severely imbalanced distribution of transaction (TX) workloads across all blockchain shards due to the deployment policy of their accounts. Imbalanced TX distributions then produce hot shards, in which the cross-shard TXs may experience an unlimited confirmation latency. Thus, how to address the hot-shard issue and how to reduce crossshard TXs become significant challenges of blockchain sharding. Through reviewing the related studies, we find that a crossshard TX protocol that can achieve workload balance among all shards and simultaneously reduce the quantity of crossshard TXs is still absent from the literature. To this end, we propose BrokerChain, which is a cross-shard blockchain protocol dedicated to account-based state sharding. Essentially, BrokerChain exploits fine-grained state partition and account segmentation. We also elaborate on how BrokerChain handles cross-shard TXs through broker accounts. The security issues and other properties of BrokerChain are analyzed rigorously. Finally, we conduct comprehensive evaluations using an opensource blockchain sharding prototype named BlockEmulator. The evaluation results show that BrokerChain outperforms other baselines in terms of transaction throughput, transaction confirmation latency, the queue size of the transaction pool, and workload balance.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Weighting Push-SUM for Decentralized Optimization with Statistical Diversity</title>
<link>https://arxiv.org/abs/2412.07252</link>
<guid>https://arxiv.org/abs/2412.07252</guid>
<content:encoded><![CDATA[
<div> 关键词：统计多样性、Push-SUM协议、分布式优化、Adaptive Weighting Push-SUM协议、Moreau权重方法

总结:
本文针对数据分布中的统计多样性对基于Push-SUM协议的分布式优化带来的负面影响进行了研究。文章提出了一个新的理论框架——Adaptive Weighting Push-SUM协议，该协议是Push-SUM协议的一个泛化形式，其中原始Push-SUM协议为其特例。理论上分析表明，新协议在充分通信条件下，其共识距离的上界可降低至$O(1/N)$，而Push-SUM协议则保持在$O(1)$。此外，将SGD和Momentum SGD应用于新协议，证明了这两个算法在处理统计多样性上的收敛速度为$O(N/T)$，优于Push-SUM协议的$O(Nd/T)$（其中$d$为训练模型的参数大小）。为了应对实际应用中新协议的统计多样性问题，文章还发展了一种源于莫雷au包络的Moreau权重方法，用于近似优化莫雷au包络的距离惩罚。实验验证了Adaptive Weighting Push-SUM协议在深度学习等实际场景下相比Push-SUM协议具有更高的效率。 <div>
arXiv:2412.07252v1 Announce Type: new 
Abstract: Statistical diversity is a property of data distribution and can hinder the optimization of a decentralized network. However, the theoretical limitations of the Push-SUM protocol reduce the performance in handling the statistical diversity of optimization algorithms based on it. In this paper, we theoretically and empirically mitigate the negative impact of statistical diversity on decentralized optimization using the Push-SUM protocol. Specifically, we propose the Adaptive Weighting Push-SUM protocol, a theoretical generalization of the original Push-SUM protocol where the latter is a special case of the former. Our theoretical analysis shows that, with sufficient communication, the upper bound on the consensus distance for the new protocol reduces to $O(1/N)$, whereas it remains at $O(1)$ for the Push-SUM protocol. We adopt SGD and Momentum SGD on the new protocol and prove that the convergence rate of these two algorithms to statistical diversity is $O(N/T)$ on the new protocol, while it is $O(Nd/T)$ on the Push-SUM protocol, where $d$ is the parameter size of the training model. To address statistical diversity in practical applications of the new protocol, we develop the Moreau weighting method for its generalized weight matrix definition. This method, derived from the Moreau envelope, is an approximate optimization of the distance penalty of the Moreau envelope. We verify that the Adaptive Weighting Push-SUM protocol is practically more efficient than the Push-SUM protocol via deep learning experiments.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tazza: Shuffling Neural Network Parameters for Secure and Private Federated Learning</title>
<link>https://arxiv.org/abs/2412.07454</link>
<guid>https://arxiv.org/abs/2412.07454</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、安全威胁、模型中毒、数据隐私、Tazza

总结:
本文介绍了一种新的联邦学习框架Tazza，该框架同时解决了数据隐私保护和抵御恶意客户端的模型中毒及梯度反转等安全威胁问题。Tazza通过利用神经网络的置换等变性和不变性，通过权重洗牌和模型洗牌验证来增强对多种攻击的鲁棒性，同时也确保了数据的机密性和模型的高准确性。在多个数据集和嵌入式平台上进行的综合评估显示，与现有方案相比，Tazza在提供强大防御能力的同时，计算效率提高了最多6.7倍，且未损害性能。<br /><br /> <div>
arXiv:2412.07454v1 Announce Type: new 
Abstract: Federated learning enables decentralized model training without sharing raw data, preserving data privacy. However, its vulnerability towards critical security threats, such as gradient inversion and model poisoning by malicious clients, remain unresolved. Existing solutions often address these issues separately, sacrificing either system robustness or model accuracy. This work introduces Tazza, a secure and efficient federated learning framework that simultaneously addresses both challenges. By leveraging the permutation equivariance and invariance properties of neural networks via weight shuffling and shuffled model validation, Tazza enhances resilience against diverse poisoning attacks, while ensuring data confidentiality and high model accuracy. Comprehensive evaluations on various datasets and embedded platforms show that Tazza achieves robust defense with up to 6.7x improved computational efficiency compared to alternative schemes, without compromising performance.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Scalable Multi-Layered Blockchain Architecture for Enhanced EHR Sharing and Drug Supply Chain Management</title>
<link>https://arxiv.org/abs/2402.17342</link>
<guid>https://arxiv.org/abs/2402.17342</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、电子健康记录、药物供应链管理、多层架构、性能优化

<br /><br />总结:
本文提出了一种基于区块链技术的、可扩展的多层架构，用于保障医疗领域电子健康记录的安全共享与药物供应链管理。该框架由五个独特层次构成，强化了系统在性能、安全和患者为中心的访问控制方面的表现。通过引入并行处理，系统显著提高了交易吞吐量并减少了网络流量。此外，该解决方案确保了数据完整性、隐私性和互操作性，使其能够与现有医疗系统兼容。实验结果运用Caliper基准进行验证，显示出了交易吞吐量的显著提升和通信开销的降低。同时，这一框架还为药物供应链提供了透明度和实时监控功能，为决策者提供了关键洞察信息。 <div>
arXiv:2402.17342v2 Announce Type: replace 
Abstract: In recent years, the healthcare sector's transition to digital platforms has intensified concerns over data security, privacy, and scalability. Blockchain technology offers a decentralized, secure, and immutable solution to these challenges. This paper presents a scalable, multi-layered blockchain architecture for secure Electronic Health Record (EHR) sharing and drug supply chain management. The proposed framework introduces five distinct layers that enhance system performance, security, and patient-centric access control. By implementing parallelism, the system significantly increases transaction throughput and reduces network traffic. Our solution ensures data integrity, privacy, and interoperability, making it compatible with existing healthcare systems. Experimental results, conducted using the Caliper benchmark, demonstrate notable improvements in transaction throughput and reduced communication overhead. Additionally, the framework provides transparency and real-time drug supply chain monitoring, empowering decision-makers with critical insights.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative and parametric insurance on the Ethereum blockchain</title>
<link>https://arxiv.org/abs/2412.05321</link>
<guid>https://arxiv.org/abs/2412.05321</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、保险方案、参数化、协作、智能合约

总结:<br />
本文提出了一种结合了参数化和协作元素的基于区块链的保险方案。该方案中，一批投资者（称为盈余提供者）将在智能合约中锁定资金，使得区块链用户能够承保参数化的保险合同。当预定义条件满足时，这些合同将自动触发赔偿。协作体现在生成代币的过程，代币被分配给盈余提供者和投保人，代表其在盈余中的份额并赋予管理决策投票权。该智能合约使用以太坊区块链的高级编程语言Solidity开发，并部署在Sepolia测试网上，数据处理和分析则采用Python进行。此外，还提供了开源代码并指出了主要研究挑战，以便后续研究可以克服这一初步概念验证的局限性。 <div>
arXiv:2412.05321v1 Announce Type: new 
Abstract: This paper introduces a blockchain-based insurance scheme that integrates parametric and collaborative elements. A pool of investors, referred to as surplus providers, locks funds in a smart contract, enabling blockchain users to underwrite parametric insurance contracts. These contracts automatically trigger compensation when predefined conditions are met. The collaborative aspect is embodied in the generation of tokens, which are distributed to both surplus providers and policyholders. These tokens represent each participant's share of the surplus and grant voting rights for management decisions. The smart contract is developed in Solidity, a high-level programming language for the Ethereum blockchain, and deployed on the Sepolia testnet, with data processing and analysis conducted using Python. In addition, open-source code is provided and main research challenges are identified, so that further research can be carried out to overcome limitations of this first proof of concept.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EC-Chain: Cost-Effective Storage Solution for Permissionless Blockchains</title>
<link>https://arxiv.org/abs/2412.05502</link>
<guid>https://arxiv.org/abs/2412.05502</guid>
<content:encoded><![CDATA[
<div> 关键词：permissionless blockchains, EC-Chain, storage solution, erasure coding, dual-trie state management

总结:
<br />
本文提出了EC-Chain，一种针对无许可区块链的成本效益高的存储解决方案。EC-Chain通过批量编码和基于高度的编码优化了现有基于擦除编码的存储优化技术，从而减少了区块链数据中的交易记录（ledger data）的存储开销。同时，为改进状态数据（state data）的存储与检索效率，文章引入了一种易于实现的双哈希树（dual-trie）状态管理系统，该系统利用状态过期、挖掘和创建等流程实现了优化。为了确保无许可环境中的数据可用性，EC-Chain还设计了一种适应动态网络特性的维护方案。综上所述，EC-Chain为无许可区块链面临的存储挑战提供了一个有效的解决方案。实验证明，相比于原生以太坊Geth，EC-Chain可以实现超过90%的存储减少。 <div>
arXiv:2412.05502v1 Announce Type: new 
Abstract: Permissionless blockchains face considerable challenges due to increasing storage demands, driven by the proliferation of Decentralized Applications (DApps). This paper introduces EC-Chain, a cost-effective storage solution for permissionless blockchains. EC-Chain reduces storage overheads of ledger and state data, which comprise blockchain data. For ledger data, EC-Chain refines existing erasure coding-based storage optimization techniques by incorporating batch encoding and height-based encoding. We also introduce an easy-to-implement dual-trie state management system that enhances state storage and retrieval through state expiry, mining, and creation procedures. To ensure data availability in permissionless environments, EC-Chain introduces a network maintenance scheme tailored for dynamism. Collectively, these contributions allow EC-Chain to provide an effective solution to the storage challenges faced by permissionless blockchains. Our evaluation demonstrates that EC-Chain can achieve a storage reduction of over \(90\%\) compared to native Ethereum Geth.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Digital Twins of Blockchain Systems: State Extraction and Mirroring</title>
<link>https://arxiv.org/abs/2412.05527</link>
<guid>https://arxiv.org/abs/2412.05527</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、采纳率、三难困境、共识协议、数字孪生<br /><br />总结：
随着区块链采纳率创历史新高，各类区块链架构应运而生以满足各种应用集成区块链的需求。然而，区块链系统面临三难困境问题，即在扩展性、去中心化和安全性之间难以取得平衡。这一平衡主要由所采用的共识协议决定。由于共识协议针对特定系统条件设计，因此在区块链这种复杂动态的环境下，单一共识协议运行的系统注定会在某些时期遭遇效率低下问题。本文提出的工作是构建基于数字孪生的区块链管理框架的一部分，旨在通过调整共识过程以适应底层系统的条件来解决三难困境问题。具体而言，文章解决了如何从区块链系统中抽取并镜像到其数字孪生体的问题，提出了克服区块链去中心化、异步特性和全局状态同步等基本问题的算法。实验评估了所提算法的鲁棒性。 <div>
arXiv:2412.05527v1 Announce Type: new 
Abstract: Blockchain adoption is reaching an all-time high, with a plethora of blockchain architectures being developed to cover the needs of applications eager to integrate blockchain into their operations. However, blockchain systems suffer from the trilemma trade-off problem, which limits their ability to scale without sacrificing essential metrics such as decentralisation and security. The balance of the trilemma trade-off is primarily dictated by the consensus protocol used. Since consensus protocols are designed to function well under specific system conditions, and consequently, due to the blockchain's complex and dynamic nature, systems operating under a single consensus protocol are bound to face periods of inefficiency. The work presented in this paper constitutes part of an effort to design a Digital Twin-based blockchain management framework to balance the trilemma trade-off problem, which aims to adapt the consensus process to fit the conditions of the underlying system. Specifically, this work addresses the problems of extracting the blockchain system and mirroring it in its digital twin by proposing algorithms that overcome the challenges posed by blockchains' decentralised and asynchronous nature and the fundamental problems of global state and synchronisation in such systems. The robustness of the proposed algorithms is experimentally evaluated.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Balancing Confidentiality and Transparency for Blockchain-based Process-Aware Information Systems</title>
<link>https://arxiv.org/abs/2412.05737</link>
<guid>https://arxiv.org/abs/2412.05737</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain、Process-Aware Information Systems (PAISs)、Transparency、Confidentiality、CONFETTY

总结:
本文提出了一个名为CONFETTY的新架构，该架构旨在同时保护区块链为基础的PAISs中的机密性和透明性。智能合约用于执行、强制和存储公开交互，而属性基加密技术则用于指定对敏感信息的访问权限。通过对系统进行系统性的威胁模型分析，文章评估了解决方案的安全性，并通过实施原型在不同场景下的性能测试证明了其实用可行性。这为需要保密操作但仍需保持一定程度交易可验证性的场合提供了一种新的解决方案。 <div>
arXiv:2412.05737v1 Announce Type: new 
Abstract: Blockchain enables novel, trustworthy Process-Aware Information Systems (PAISs) by enforcing the security, robustness, and traceability of operations. In particular, transparency ensures that all information exchanges are openly accessible, fostering trust within the system. Although this is a desirable property to enable notarization and auditing activities, it also represents a limitation for such cases where confidentiality is a requirement since interactions involve sensible data. Current solutions rely on obfuscation techniques or private infrastructures, hindering the enforcing capabilities of smart contracts and the public verifiability of transactions. Against this background, we propose CONFETTY, an architecture for blockchain-based PAISs aimed at preserving both confidentiality and transparency. Smart contracts enact, enforce and store public interactions, while attribute-based encryption techniques are adopted to specify access grants to confidential information. We assess the security of our solution through a systematic threat model analysis and assess its practical feasibility by gauging the performance of our implemented prototype in different scenarios from the literature.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Dynamic Tree Structure for Hierarchical On-Chain Asset Management</title>
<link>https://arxiv.org/abs/2412.06026</link>
<guid>https://arxiv.org/abs/2412.06026</guid>
<content:encoded><![CDATA[
<div> 关键词：Sarv、区块链、层次关系、数据管理、Algorand Standard Assets

<br /><br />总结：
本文介绍了Sarv，一种新型非整体式区块链基础数据结构，用于表示数字可表示组件之间的层次关系。Sarv为供应链追踪、资产管理及循环经济实施等需要层次化数据管理的应用提供底层支持。该方案采用树形数据结构准确反映产品及其子组件的关系，支持修改、拆解、借用和翻新等现实世界操作。通过基于智能合约设计并利用Algorand Standard Assets (ASAs)，Sarv将层次结构嵌入到链上数据结构中。其独特之处在于紧凑且非整体式的架构、可变性以及增强安全性和资产管理委托的两层授权机制。文章通过实例证明，Sarv为区块链上的层次化数据管理提供了一种可扩展、可变且安全的解决方案。 <div>
arXiv:2412.06026v1 Announce Type: new 
Abstract: In this paper, we introduce the Sarv, a novel non-monolithic blockchain-based data structure designed to represent hierarchical relationships between digitally representable components. Sarv serves as an underlying infrastructure for a wide range of applications requiring hierarchical data management, such as supply chain tracking, asset management, and circular economy implementations. Our approach leverages a tree-based data structure to accurately reflect products and their sub-components, enabling functionalities such as modification, disassembly, borrowing, and refurbishment, mirroring real-world operations. The hierarchy within Sarv is embedded in the on-chain data structure through a smart contract-based design, utilizing Algorand Standard Assets (ASAs). The uniqueness of Sarv lies in its compact and non-monolithic architecture, its mutability, and a two-layer action authorization scheme that enhances security and delegation of asset management. We demonstrate that Sarv addresses real-world requirements by providing a scalable, mutable, and secure solution for managing hierarchical data on the blockchain.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fully Distributed Online Training of Graph Neural Networks in Networked Systems</title>
<link>https://arxiv.org/abs/2412.06105</link>
<guid>https://arxiv.org/abs/2412.06105</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络(GNN), 分布式训练, 在线训练, 通信效率, 大规模网络系统

总结:<br />
本文首次提出了一种针对大规模网络系统的通信高效、完全分布式在线图神经网络(GNN)训练方法。该方法针对含有B个样本的mini-batch，仅需在GNN推理所需的LB轮消息传递基础上额外增加L轮消息传递，同时消息大小翻倍。通过在图节点回归、无线网络中的功率分配和链接调度等场景的数值实验，展示了该方法在监督学习、无监督学习和强化学习范式下有效训练GNN的能力。 <div>
arXiv:2412.06105v1 Announce Type: new 
Abstract: Graph neural networks (GNNs) are powerful tools for developing scalable, decentralized artificial intelligence in large-scale networked systems, such as wireless networks, power grids, and transportation networks. Currently, GNNs in networked systems mostly follow a paradigm of `centralized training, distributed execution', which limits their adaptability and slows down their development cycles. In this work, we fill this gap for the first time by developing a communication-efficient, fully distributed online training approach for GNNs applied to large networked systems. For a mini-batch with $B$ samples, our approach of training an $L$-layer GNN only adds $L$ rounds of message passing to the $LB$ rounds required by GNN inference, with doubled message sizes. Through numerical experiments in graph-based node regression, power allocation, and link scheduling in wireless networks, we demonstrate the effectiveness of our approach in training GNNs under supervised, unsupervised, and reinforcement learning paradigms.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Membership Inference Attacks and Defenses in Federated Learning: A Survey</title>
<link>https://arxiv.org/abs/2412.06157</link>
<guid>https://arxiv.org/abs/2412.06157</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、隐私泄露、成员推理攻击、防御策略、未来研究方向

<br /><br />总结:
本文针对联邦学习中的一个重要隐私问题——成员推理攻击进行了全面调研。联邦学习是一种分布式机器学习方法，允许客户端本地训练模型并共享更新以构建全局模型，但依然存在隐私泄露风险，尤其是成员推理攻击。该文归纳并总结了针对联邦学习环境下的此类攻击以及相应的防御策略，并依据其特性提出了一种独特的攻击研究分类体系。此外，文章还系统性地概述了各种防御措施的优缺点。最后，对未来的研究方向进行了识别和讨论，为对此领域感兴趣的研究者提供了有价值的参考。 <div>
arXiv:2412.06157v1 Announce Type: new 
Abstract: Federated learning is a decentralized machine learning approach where clients train models locally and share model updates to develop a global model. This enables low-resource devices to collaboratively build a high-quality model without requiring direct access to the raw training data. However, despite only sharing model updates, federated learning still faces several privacy vulnerabilities. One of the key threats is membership inference attacks, which target clients' privacy by determining whether a specific example is part of the training set. These attacks can compromise sensitive information in real-world applications, such as medical diagnoses within a healthcare system. Although there has been extensive research on membership inference attacks, a comprehensive and up-to-date survey specifically focused on it within federated learning is still absent. To fill this gap, we categorize and summarize membership inference attacks and their corresponding defense strategies based on their characteristics in this setting. We introduce a unique taxonomy of existing attack research and provide a systematic overview of various countermeasures. For these studies, we thoroughly analyze the strengths and weaknesses of different approaches. Finally, we identify and discuss key future research directions for readers interested in advancing the field.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BECS: A Privacy-Preserving Computing Sharing Mechanism in 6G Computing Power Network</title>
<link>https://arxiv.org/abs/2412.06196</link>
<guid>https://arxiv.org/abs/2412.06196</guid>
<content:encoded><![CDATA[
<div> 关键词: 6G网络、计算共享、演化算法、区块链、用户隐私

总结:
<br />
本文提出了一个适用于6G计算力网络(CPN)的计算共享机制BECS，该机制基于演化算法和区块链技术，旨在平衡用户设备、边缘设备和云端资源之间的任务卸载，从而提升计算资源利用率。首先，将计算共享建模为一个多目标优化问题，目标是提高资源利用并平衡其他因素。为解决这一NP难问题，文章设计了一种基于核距离的支配关系，并将其融入非支配排序遗传算法III，显著提升了进化种群的多样性。此外，为了保护参与计算共享用户的隐私，文章还提出了一种基于零知识证明的匿名方案。最后的安全分析与模拟结果表明，BECS能充分利用6G CPN中的所有计算资源，显著提高了计算资源利用率，并有效保护了用户隐私。 <div>
arXiv:2412.06196v1 Announce Type: new 
Abstract: 5G networks provide secure and reliable information transmission services for the Internet of Everything, thus paving the way for 6G networks, which is anticipated to be an AI-based network, supporting unprecedented intelligence across applications. Abundant computing resources will establish the 6G Computing Power Network (CPN) to facilitate ubiquitous intelligent services. In this article, we propose BECS, a computing sharing mechanism based on evolutionary algorithm and blockchain, designed to balance task offloading among user devices, edge devices, and cloud resources within 6G CPN, thereby enhancing the computing resource utilization. We model computing sharing as a multi-objective optimization problem, aiming to improve resource utilization while balancing other issues. To tackle this NP-hard problem, we devise a kernel distance-based dominance relation and incorporated it into the Non-dominated Sorting Genetic Algorithm III, significantly enhancing the diversity of the evolutionary population. In addition, we propose a pseudonym scheme based on zero-knowledge proof to protect the privacy of users participating in computing sharing. Finally, the security analysis and simulation results demonstrate that BECS can fully and effectively utilize all computing resources in 6G CPN, significantly improving the computing resource utilization while protecting user privacy.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Scalable Decentralized Reinforcement Learning Framework for UAV Target Localization Using Recurrent PPO</title>
<link>https://arxiv.org/abs/2412.06231</link>
<guid>https://arxiv.org/abs/2412.06231</guid>
<content:encoded><![CDATA[
<div> 关键词：无人机(UAVs)，集体行为，目标定位，Recurrent PPO模型，感知退化环境

<br />
总结:
该研究探索了一种应用于感知退化环境（如无GNSS/GPS信号的地方）中的目标定位任务的Recurrent PPO模型。研究首先开发了一个单无人机的目标识别方法，随后构建了一个去中心化的双无人机模型。利用无人机上的检测传感器和目标信号传感器，单无人机模型实现了93%的精度，而双无人机模型虽然精度达到86%，但所需平均定位步骤更少，显示出在复杂环境条件下，利用此方法进行无人机群高效、有效的辐射目标定位潜力。 <div>
arXiv:2412.06231v1 Announce Type: new 
Abstract: The rapid advancements in unmanned aerial vehicles (UAVs) have unlocked numerous applications, including environmental monitoring, disaster response, and agricultural surveying. Enhancing the collective behavior of multiple decentralized UAVs can significantly improve these applications through more efficient and coordinated operations. In this study, we explore a Recurrent PPO model for target localization in perceptually degraded environments like places without GNSS/GPS signals. We first developed a single-drone approach for target identification, followed by a decentralized two-drone model. Our approach can utilize two types of sensors on the UAVs, a detection sensor and a target signal sensor. The single-drone model achieved an accuracy of 93%, while the two-drone model achieved an accuracy of 86%, with the latter requiring fewer average steps to locate the target. This demonstrates the potential of our method in UAV swarms, offering efficient and effective localization of radiant targets in complex environmental conditions.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Q-PnV: A Quantum Consensus Mechanism for Security Consortium Blockchains</title>
<link>https://arxiv.org/abs/2412.06325</link>
<guid>https://arxiv.org/abs/2412.06325</guid>
<content:encoded><![CDATA[
<div> 关键词：量子区块链、共识算法、Q-PnV、量子投票、量子数字签名

总结:
本文提出了一种名为Q-PnV的新型量子共识机制，该机制基于经典的Proof of Vote (PoV)，并融合了量子投票、量子数字签名和量子随机数生成器（QRNGs）。Q-PnV被应用于构建一种使用加权超图状态的量子区块链解决方案，特别针对联盟链场景。相较于传统的办法，基于Q-PnV的量子区块链能够抵抗量子攻击，并在安全性与公平性方面表现出显著提升，更加适应未来的量子时代需求。<br /><br /> <div>
arXiv:2412.06325v1 Announce Type: new 
Abstract: Due to the rapid development of quantum computing, many classical blockchain technologies are now considered insecure. The emergence of quantum blockchain holds promise for addressing this issue. Various quantum consensus algorithms have been proposed so far, but there has not yet been a quantum consensus algorithm tailored specifically for consortium blockchain scenarios. In this paper, we propose a novel quantum consensus mechanism, named Q-PnV. This consensus mechanism is based on the classical Proof of Vote (PoV), integrating quantum voting, quantum digital signature and quantum random number generators (QRNGs). By combining Q-PnV with a quantum blockchain using weighted hypergraph states, we propose a comprehensive quantum blockchain solution for consortium blockchain scenarios. Compared to the classical method, the quantum blockchain based on Q-PnV can resist quantum attacks and shows significant improvements in security and fairness, making it better suit-ed for the future quantum era.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ICtoken: An NFT for Hardware IP Protection</title>
<link>https://arxiv.org/abs/2412.06726</link>
<guid>https://arxiv.org/abs/2412.06726</guid>
<content:encoded><![CDATA[
<div> 关键词：集成电路保护、非同质化代币(NFTs)、ICtokens、分布式账本技术、区块链<br /><br />总结:<br />
本文提出了一种利用非同质化代币（NFTs）名为ICtokens的新颖框架，用于保护集成电路（ICs）免受盗版和盗窃。每个ICtoken与其对应的物理IC独特链接，存储认证数据、供应链状态、所有权信息以及IC元数据，并可安全集成逻辑锁定密钥。通过公开记录并使用节能型联盟区块链驱动的ICtracker管理ICtokens及其所有者，确保了计量信息的安全隐藏与功能完整，并实现从源头IP持有者到消费者的全链条追溯与审计。此外，该框架创建了IC及嵌入IC产品的不可变数字孪生体，即ICtokens及其交易记录，为IC供应链监控提供了比现有方案更为详尽的审计信息。文章实施了一个开源的原型系统以验证所提框架的易采用性。 <div>
arXiv:2412.06726v1 Announce Type: new 
Abstract: Protecting integrated circuits (ICs) from piracy and theft throughout their lifecycle is a persistent and complex challenge. In order to safeguard against illicit piracy attacks, this work proposes a novel framework utilizing Non-Fungible Tokens (NFTs) called ICtokens, uniquely linked to their corresponding physical ICs. Each ICtoken contains comprehensive information, including authentication data, supply chain stage and status, ownership details, and other IC metadata, while also making provision for the secure integration of a logic-locking key. Designed to be publicly logged, ICtokens securely obscure metering information without compromising functionality. In addition, the ICtracker, a distributed ledger technology powered by a swift and energy-efficient consortium blockchain, is used to register and manage ICtokens and their respective owners, tracking all associated interactions. This robust ledger guarantees the traceability and auditing of ICtokens while simultaneously developing a product-level NFT at every transaction point within the supply chain. Consequently, a scalable framework is established, creating unique, immutable digital twins for ICs and IC-embedded products in the form of ICtokens and their transactions. This provides a robust and reliable supply chain trail back to the original IP owner, while also offering unprecedented assurance to consumers of IC-embedded products. The rich information contained within ICtokens facilitates more detailed audits than previous proposals for IC supply chain monitoring. A proof-of-concept, implemented as an open-source solution, ensures the ease of adoption of the proposed framework.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR) Applications</title>
<link>https://arxiv.org/abs/2412.06759</link>
<guid>https://arxiv.org/abs/2412.06759</guid>
<content:encoded><![CDATA[
<div> 关键词: XRZoo、Extended Reality (XR)、应用数据集、软件工程、安全性研究

总结:<br />
本文介绍了XRZoo，这是一个针对Extended Reality（包括AR、MR和VR）应用的大型、代表性、高质量的数据集，旨在填补XR软件过程研究中的数据空白。XRZoo收录了来自九家应用商店的12,528个免费XR应用程序，涵盖了各种XR技术及应用场景，并包含了详细元数据，如应用描述、分类、发布日期、用户评价数量和硬件规格等信息。通过公开提供XRZoo数据集，该研究期望推动可重复的XR软件工程和安全性研究，促进跨学科调查，并为开发者提供示例以支持高级XR系统的发展。XRZoo将成为对XR应用的可扩展性、可用性和有效性的改进研究与实践工作的重要资源，并将得到持续维护和更新。 <div>
arXiv:2412.06759v1 Announce Type: new 
Abstract: The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR) and spatial computing technologies forms a foundational layer for the emerging Metaverse, enabling innovative applications across healthcare, education, manufacturing, and entertainment. However, research in this area is often limited by the lack of large, representative, and highquality application datasets that can support empirical studies and the development of new approaches benefiting XR software processes. In this paper, we introduce XRZoo, a comprehensive and curated dataset of XR applications designed to bridge this gap. XRZoo contains 12,528 free XR applications, spanning nine app stores, across all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed metadata on key aspects such as application descriptions, application categories, release dates, user review numbers, and hardware specifications, etc. By making XRZoo publicly available, we aim to foster reproducible XR software engineering and security research, enable cross-disciplinary investigations, and also support the development of advanced XR systems by providing examples to developers. Our dataset serves as a valuable resource for researchers and practitioners interested in improving the scalability, usability, and effectiveness of XR applications. XRZoo will be released and actively maintained.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring Data Management Challenges and Solutions in Agile Software Development: A Literature Review and Practitioner Survey</title>
<link>https://arxiv.org/abs/2402.00462</link>
<guid>https://arxiv.org/abs/2402.00462</guid>
<content:encoded><![CDATA[
<div> 关键词：数据管理、敏捷项目、挑战、解决方案、系统atic文献回顾<br /><br />总结:<br />
本文针对软件产品及其开发相关的数据管理在敏捷项目中所面临的显著挑战进行了深入探讨。研究采用混合方法进行，首先通过系统性文献回顾（SLR）对现有研究进行了梳理，分析了45项研究中的数据管理方面及其相关挑战和解决方案。随后，对32位具有丰富数据管理经验的行业从业者进行了调查，以反映实践现状。研究发现实践中主要的数据管理挑战包括：数据集成过程管理、多样化数据捕获、自动化数据收集以及实时分析需求满足等。为解决这些问题，提出了诸如自动化工具、去中心化数据管理实践以及本体驱动的方法等解决方案，这些方案能提升数据集成能力、改善数据质量并为敏捷项目提供灵活框架以支持实时决策。研究表明，对于敏捷开发而言，识别关键数据管理挑战并实施有效的管理和工具解决方案对于提高项目成功率至关重要。 <div>
arXiv:2402.00462v3 Announce Type: replace 
Abstract: Context: Managing data related to a software product and its development poses significant challenges for software projects and agile development teams. These include integrating data from diverse sources and ensuring data quality amidst continuous change and adaptation. Objective: The paper systematically explores data management challenges and potential solutions in agile projects, aiming to provide insights into data management challenges and solutions for both researchers and practitioners. Method: We employed a mixed-methods approach, including a systematic literature review (SLR) to understand the state-of-research followed by a survey with practitioners to reflect on the state-of-practice. The SLR reviewed 45 studies, identifying and categorizing data management aspects along with their associated challenges and solutions. The practitioner survey captured practical experiences and solutions from 32 industry practitioners who were significantly involved in data management to complement the findings from the SLR. Results: Our findings identified major data management challenges in practice, such as managing data integration processes, capturing diverse data, automating data collection, and meeting real-time analysis requirements. To address these challenges, solutions such as automation tools, decentralized data management practices, and ontology-based approaches have been identified. These solutions enhance data integration, improve data quality, and enable real-time decision-making by providing flexible frameworks tailored to agile project needs. Conclusion: The study pinpointed significant challenges and actionable solutions in data management for agile development. Our findings provide practical implications for practitioners and researchers, emphasizing the development of effective data management practices and tools to address those challenges and improve project success.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Retraction-Free Decentralized Non-convex Optimization with Orthogonal Constraints</title>
<link>https://arxiv.org/abs/2405.11590</link>
<guid>https://arxiv.org/abs/2405.11590</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式非凸优化、正交约束、重traction、无重traction着陆算法、DRFGT、收敛率、线性代数操作、计算效率、局部Riemannian P\L条件

总结:
该文研究了带有正交约束的分布式非凸优化问题。针对该问题，传统算法需要使用流形重traction或投影等方法来保证可行性，这些方法涉及到昂贵的线性代数运算（如SVD或矩阵求逆）。文章受到无重traction着陆算法的启发，提出了首个分布式无重traction梯度跟踪算法——DRFGT。理论上，证明了DRFGT具有$\mathcal{O}(1/K)$的ergodic收敛率，与中心化、基于重traction的方法收敛速度相匹配。此外，还在满足局部Riemannian P\L条件的情况下，进一步证明了DRFGT能够实现更快的线性收敛率。数值实验表明，DRFGT的表现与最先进的基于重traction的方法相当，但显著降低了计算开销。<br /><br /> <div>
arXiv:2405.11590v2 Announce Type: replace 
Abstract: In this paper, we investigate decentralized non-convex optimization with orthogonal constraints. Conventional algorithms for this setting require either manifold retractions or other types of projection to ensure feasibility, both of which involve costly linear algebra operations (e.g., SVD or matrix inversion). On the other hand, infeasible methods are able to provide similar performance with higher computational efficiency. Inspired by this, we propose the first decentralized version of the retraction-free landing algorithm, called \textbf{D}ecentralized \textbf{R}etraction-\textbf{F}ree \textbf{G}radient \textbf{T}racking (DRFGT). We theoretically prove that DRFGT enjoys the ergodic convergence rate of $\mathcal{O}(1/K)$, matching the convergence rate of centralized, retraction-based methods. We further establish that under a local Riemannian P{\L} condition, DRFGT achieves a much faster linear convergence rate. Numerical experiments demonstrate that DRFGT performs on par with the state-of-the-art retraction-based methods with substantially reduced computational overhead.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>LiveNet: Robust, Minimally Invasive Multi-Robot Control for Safe and Live Navigation in Constrained Environments</title>
<link>https://arxiv.org/abs/2412.04659</link>
<guid>https://arxiv.org/abs/2412.04659</guid>
<content:encoded><![CDATA[
<div> 关键词: LiveNet、机器人、拥挤环境、安全、实时避障

总结:<br />
本文介绍了LiveNet，这是一种针对密集环境中机器人的全新全分布式神经网络控制器，旨在解决狭窄通道和冲突区域中的碰撞与死锁问题。现有的优化和神经网络方法主要适用于开阔空间，或者过于保守，只能确保安全或活性其中一个方面。LiveNet提供了一种创新的方法，实现了安全性和活性的同时保证，通过统一的CBF（控制 Barrier 函数）形式化并集成到神经网络中以实现鲁棒性。该控制器无需机器人间通信或协作行为即可实现人类般的让行和通行。实验表明，相比常规多机器人优化和学习基导航方法，LiveNet不仅能够成功达到目标，而且速度更快（快10-20倍）、侵入性更小（减少4-5倍），对场景配置变化更具适应性。LiveNet代码已在GitHub上开源。 <div>
arXiv:2412.04659v1 Announce Type: new 
Abstract: Robots in densely populated real-world environments frequently encounter constrained and cluttered situations such as passing through narrow doorways, hallways, and corridor intersections, where conflicts over limited space result in collisions or deadlocks among the robots. Current decentralized state-of-the-art optimization- and neural network-based approaches (i) are predominantly designed for general open spaces, and (ii) are overly conservative, either guaranteeing safety, or liveness, but not both. While some solutions rely on centralized conflict resolution, their highly invasive trajectories make them impractical for real-world deployment. This paper introduces LiveNet, a fully decentralized and robust neural network controller that enables human-like yielding and passing, resulting in agile, non-conservative, deadlock-free, and safe, navigation in congested, conflict-prone spaces. LiveNet is minimally invasive, without requiring inter-agent communication or cooperative behavior. The key insight behind LiveNet is a unified CBF formulation for simultaneous safety and liveness, which we integrate within a neural network for robustness. We evaluated LiveNet in simulation and found that general multi-robot optimization- and learning-based navigation methods fail to even reach the goal, and while methods designed specially for such environments do succeed, they are 10-20 times slower, 4-5 times more invasive, and much less robust to variations in the scenario configuration such as changes in the start states and goal states, among others. We open-source the LiveNet code at https://github.com/srikarg89/LiveNet{https://github.com/srikarg89/LiveNet.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DRDST: Low-latency DAG Consensus through Robust Dynamic Sharding and Tree-broadcasting for IoV</title>
<link>https://arxiv.org/abs/2412.04742</link>
<guid>https://arxiv.org/abs/2412.04742</guid>
<content:encoded><![CDATA[
<div> 关键词: IoV、区块链、分片、DAG共识、动态鲁棒分片<br /><br />总结:

本文针对互联网汽车（IoV）中通信效率和延迟降低的需求，探讨了利用区块链技术面临的挑战。为解决区块链扩展性问题，文章提出了基于有向无环图（DAG）共识和鲁棒动态分片与树广播（DRDST）的方法。首先，通过结合节点网络稳定性和信任值提出了一种新的鲁棒分片模型，并设计了遗传分片算法（GSA）来实现该模型。其次，改进树广播方式以优化整个分片网络的广播延迟，从而减少每个分片内的最大广播延迟。此外，文中还设计了一个基于改进哈希图协议的DAG共识方案，能有效处理跨分片交易。最后，通过仿真验证，所提出的方案在延迟、吞吐量、共识成功率和节点流量负载等方面均优于对比方案。 <div>
arXiv:2412.04742v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV) is emerging as a pivotal technology for enhancing traffic management and safety. Its rapid development demands solutions for enhanced communication efficiency and reduced latency. However, traditional centralized networks struggle to meet these demands, prompting the exploration of decentralized solutions such as blockchain. Addressing blockchain's scalability challenges posed by the growing number of nodes and transactions calls for innovative solutions, among which sharding stands out as a pivotal approach to significantly enhance blockchain throughput. However, existing schemes still face challenges related to a) the impact of vehicle mobility on blockchain consensus, especially for cross-shard transaction; and b) the strict requirements of low latency consensus in a highly dynamic network. In this paper, we propose a DAG (Directed Acyclic Graph) consensus leveraging Robust Dynamic Sharding and Tree-broadcasting (DRDST) to address these challenges. Specifically, we first develop a standard for evaluating the network stability of nodes, combined with the nodes' trust values, to propose a novel robust sharding model that is solved through the design of the Genetic Sharding Algorithm (GSA). Then, we optimize the broadcast latency of the whole sharded network by improving the tree-broadcasting to minimize the maximum broadcast latency within each shard. On this basis, we also design a DAG consensus scheme based on an improved hashgraph protocol, which can efficiently handle cross-shard transactions. Finally, the simulation proves the proposed scheme is superior to the comparison schemes in latency, throughput, consensus success rate, and node traffic load.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing</title>
<link>https://arxiv.org/abs/2412.04868</link>
<guid>https://arxiv.org/abs/2412.04868</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning as a Service (FLaaS), JointCloud Computing (JCC), TEE (Trusted Execution Environment), NebulaFL, Asynchronous FL

总结:
随着AI基础设施和可信执行环境（TEE）技术的发展，联邦学习作为服务（FLaaS）通过联合云计算（JCC）有望打破传统联邦学习中的异构边缘设备资源约束。然而，FLaaS面临着数据异质性导致的训练性能低下、不同云之间的高通信开销以及缺乏有效资源调度策略等问题。为了解决这些问题，本文提出了一种新的异步联邦学习方法——NebulaFL，用于多个云端的协同模型训练。针对数据异质性问题，NebulaFL在每个数据中心采用基于版本控制的异步FL训练方案来平衡数据所有者间的训练时间。为了降低通信开销，NebulaFL采用了去中心化的模型旋转机制实现知识的有效共享。同时，为了平衡训练时间和成本，NebulaFL整合了奖励引导的数据选择和资源调度策略。实验结果显示，与现有最先进的FL方法相比，NebulaFL能够在保持目标准确率的前提下，提高最多5.71%的准确性，减少高达50%的通信开销，并将成本降低了61.94%。 <div>
arXiv:2412.04868v1 Announce Type: new 
Abstract: With advancements in AI infrastructure and Trusted Execution Environment (TEE) technology, Federated Learning as a Service (FLaaS) through JointCloud Computing (JCC) is promising to break through the resource constraints caused by heterogeneous edge devices in the traditional Federated Learning (FL) paradigm. Specifically, with the protection from TEE, data owners can achieve efficient model training with high-performance AI services in the cloud. By providing additional FL services, cloud service providers can achieve collaborative learning among data owners. However, FLaaS still faces three challenges, i.e., i) low training performance caused by heterogeneous data among data owners, ii) high communication overhead among different clouds (i.e., data centers), and iii) lack of efficient resource scheduling strategies to balance training time and cost. To address these challenges, this paper presents a novel asynchronous FL approach named NebulaFL for collaborative model training among multiple clouds. To address data heterogeneity issues, NebulaFL adopts a version control-based asynchronous FL training scheme in each data center to balance training time among data owners. To reduce communication overhead, NebulaFL adopts a decentralized model rotation mechanism to achieve effective knowledge sharing among data centers. To balance training time and cost, NebulaFL integrates a reward-guided strategy for data owners selection and resource scheduling. The experimental results demonstrate that, compared to the state-of-the-art FL methods, NebulaFL can achieve up to 5.71\% accuracy improvement. In addition, NebulaFL can reduce up to 50% communication overhead and 61.94% costs under a target accuracy.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bridging Culture and Finance: A Multimodal Analysis of Memecoins in the Web3 Ecosystem</title>
<link>https://arxiv.org/abs/2412.04913</link>
<guid>https://arxiv.org/abs/2412.04913</guid>
<content:encoded><![CDATA[
<div> 关键词：Memecoins、Coin-Meme数据集、Web3生态系统、多模态分析框架、Solana区块链

总结:<br />
本文介绍了针对Web3生态系统中迅速崛起的基于社交媒体互动和文化叙事驱动的Memecoins进行研究的相关成果。文章提出了一个名为Coin-Meme的数据集，该数据集包含了来源于Solana区块链上Pump.fun平台的关于视觉、文本、社区及金融方面的开放源数据。同时，文中提出了一种多模态框架，用于分析Memecoins的文化主题、社区互动以及金融行为。通过聚类、情感分析和词云可视化方法，研究者们识别出了以幽默、动物和政治讽刺为主题的独特群体。此外，文章还通过对Market Entry Time和Market Capitalization等指标的分析，提供了对Memecoins作为文化产物和Web3环境中金融工具的全面见解。该Coin-Meme数据集已在GitHub上公开发布。 <div>
arXiv:2412.04913v1 Announce Type: new 
Abstract: Memecoins, driven by social media engagement and cultural narratives, have rapidly grown within the Web3 ecosystem. Unlike traditional cryptocurrencies, they are shaped by humor, memes, and community sentiment. This paper introduces the Coin-Meme dataset, an open-source collection of visual, textual, community, and financial data from the Pump.fun platform on the Solana blockchain. We also propose a multimodal framework to analyze memecoins, uncovering patterns in cultural themes, community interaction, and financial behavior. Through clustering, sentiment analysis, and word cloud visualizations, we identify distinct thematic groups centered on humor, animals, and political satire. Additionally, we provide financial insights by analyzing metrics such as Market Entry Time and Market Capitalization, offering a comprehensive view of memecoins as both cultural artifacts and financial instruments within Web3. The Coin-Meme dataset is publicly available at https://github.com/hwlongCUHK/Coin-Meme.git.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Experimental Framework for Implementing Decentralized Autonomous Database Systems in Rust</title>
<link>https://arxiv.org/abs/2412.05078</link>
<guid>https://arxiv.org/abs/2412.05078</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Autonomous Database Systems (DADBS), Rust编程语言, 实验框架, 性能评估, 安全性分析

总结:
本文介绍了使用Rust编程语言实现去中心化自治数据库系统(DADBS)的实验框架。该研究聚焦于利用Rust的独特特性以提高系统可靠性和性能，应对传统集中式数据库在可扩展性、安全性及自主性方面的挑战。文章通过评估实施的DADBS在吞吐量、读取延迟、写入延迟、可扩展性、CPU利用率、内存使用和网络I/O等方面的性能，得出了一组连续运行24小时的平均数据。安全分析显示，即使恶意节点比例增加，DADBS仍能保持高吞吐量和一致性。文中还讨论了关键设计决策，强调Rust的所有权模型和并发特性如何解决分布式系统的常见问题。同时，文中也探讨了当前方法的局限性以及未来的研究方向。通过提供基于Rust的DADBS全面概述，本文旨在为日益壮大的去中心化数据库架构及其实际实现的知识库做出贡献。 <div>
arXiv:2412.05078v1 Announce Type: new 
Abstract: This paper presents an experimental framework for implementing Decentralized Autonomous Database Systems (DADBS) using the Rust programming language. As traditional centralized databases face challenges in scalability, security, and autonomy, DADBS emerge as a promising solution, using blockchain principles to create distributed, self-governing database systems. Our framework explores the practical aspects of building a DADBS, focusing on Rust's unique features that improves system reliability and performance. We evaluated our DADBS implementation across several key performance metrics: throughput, latency(read), latency(write), scalability, CPU utilization, Memory Usage and Network I/O, The average results obtained over a 24-hour period of continuous operation were 3,000 transactions/second, 75 ms, 250 ms, 55%, 2.5 GB, 100MB/s. The security analysis depicts that even with an increase in the percentage of malicious nodes, DADBS still maintains high throughput and consistency. The paper discusses key design decisions, highlighting how Rust's ownership model and concurrency features address common challenges in distributed systems. We also examine the current limitations of our approach and potential areas for future research. By providing this comprehensive overview of a Rust-based DADBS implementation, we aim to contribute to the growing body of knowledge on decentralized database architectures and their practical realization.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Supply Chain Insecurity: The Lack of Integrity Protection in SBOM Solutions</title>
<link>https://arxiv.org/abs/2412.05138</link>
<guid>https://arxiv.org/abs/2412.05138</guid>
<content:encoded><![CDATA[
<div> 关键词：SolarWinds攻击、软件账单材料(SBOM)、供应链安全、漏洞管理、许可管理<br /><br />总结:

该文深入调查了软件账单材料(SBOM)的完整性，这是确保软件供应链安全的重要工具，特别是在美国总统拜登签署的行政命令中强制要求联邦机构购买的软件必须提供SBOM。文章分析了SBOM在生成和消费阶段可能被利用的各种攻击向量，发现四种SBOM消费工具缺乏对依赖项的完整性的控制机制，同时七个主流编程语言的SBOM生成过程也容易受到完整性攻击，如通过操纵包管理器中的依赖版本号和额外文件导致SBOM数据不准确，进而可能导致在SBOM消费过程中忽视软件依赖关系和漏洞的存在。为解决这些问题，文中提出了一个采用去中心化存储软件库哈希值的解决方案。 <div>
arXiv:2412.05138v1 Announce Type: new 
Abstract: The SolarWinds attack that exploited weaknesses in the software update mechanism highlights the critical need for organizations to have better visibility into their software dependencies and potential vulnerabilities associated with them, and the Software Bill of Materials (SBOM) is paramount in ensuring software supply chain security. Under the Executive Order issued by President Biden, the adoption of the SBOM has become obligatory within the United States. The executive order mandates that an SBOM should be provided for all software purchased by federal agencies. The main applications of SBOMs are vulnerability management and license management. This work presents an in-depth and systematic investigation into the integrity of SBOMs. We explore different attack vectors that can be exploited to manipulate SBOM data, including flaws in the SBOM generation and consumption phases in the SBOM life cycle. We thoroughly investigated four SBOM consumption tools and the generation process of SBOMs for seven prominent programming languages. Our systematic investigation reveals that the tools used for consumption lack integrity control mechanisms for dependencies. Similarly, the generation process is susceptible to integrity attacks as well, by manipulating dependency version numbers in package managers and additional files, resulting in incorrect SBOM data. This could lead to incorrect views on software dependencies and vulnerabilities being overlooked during SBOM consumption. To mitigate these issues, we propose a solution incorporating the decentralized storage of hash values of software libraries.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy Drift: Evolving Privacy Concerns in Incremental Learning</title>
<link>https://arxiv.org/abs/2412.05183</link>
<guid>https://arxiv.org/abs/2412.05183</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、隐私漂移、概念漂移、模型更新、数据分布转移

总结:
<br />
本文探讨了在机器学习领域中，联邦学习（Federated Learning）带来的分布式模型训练和用户数据隐私保护的范式转变。文章提出了“隐私漂移”的新概念，将其与已知的现象——概念漂移相联系。隐私漂移描述的是随着模型增量训练，私人信息泄露程度的变化。研究通过定义并分析隐私漂移，揭示了模型性能演进与数据隐私完整性的微妙关系。实验深入探究了在FL系统中隐私漂移的动力学，重点关注模型更新和数据分布变化如何影响模型对隐私攻击（如成员推理攻击）的敏感性。结果表明，模型准确性的提高可能导致更大的隐私风险。研究者使用基于CIFAR-100定制的数据集进行了实验证明，展示了数据和概念漂移对隐私的影响。这项工作为未来关于隐私意识机器学习的研究奠定了基础，旨在寻求在去中心化环境中实现模型准确性与数据隐私之间的微妙平衡。 <div>
arXiv:2412.05183v1 Announce Type: new 
Abstract: In the evolving landscape of machine learning (ML), Federated Learning (FL) presents a paradigm shift towards decentralized model training while preserving user data privacy. This paper introduces the concept of ``privacy drift", an innovative framework that parallels the well-known phenomenon of concept drift. While concept drift addresses the variability in model accuracy over time due to changes in the data, privacy drift encapsulates the variation in the leakage of private information as models undergo incremental training. By defining and examining privacy drift, this study aims to unveil the nuanced relationship between the evolution of model performance and the integrity of data privacy. Through rigorous experimentation, we investigate the dynamics of privacy drift in FL systems, focusing on how model updates and data distribution shifts influence the susceptibility of models to privacy attacks, such as membership inference attacks (MIA). Our results highlight a complex interplay between model accuracy and privacy safeguards, revealing that enhancements in model performance can lead to increased privacy risks. We provide empirical evidence from experiments on customized datasets derived from CIFAR-100 (Canadian Institute for Advanced Research, 100 classes), showcasing the impact of data and concept drift on privacy. This work lays the groundwork for future research on privacy-aware machine learning, aiming to achieve a delicate balance between model accuracy and data privacy in decentralized environments.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Securing RC Based P2P Networks: A Blockchain-based Access Control Framework utilizing Ethereum Smart Contracts for IoT and Web 3.0</title>
<link>https://arxiv.org/abs/2412.03709</link>
<guid>https://arxiv.org/abs/2412.03709</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、访问控制框架、以太坊智能合约、动态P2P网络、安全模型

总结:
<br />
本文提出了一种基于区块链的访问控制框架，该框架利用以太坊智能合约解决高度动态的点对点（P2P）网络中的安全性问题，特别是对于在线交易和智能设备服务。针对P2P环境中传统角色基础访问控制（RBAC）系统的不足，此框架通过静态和动态策略管理的访问控制合约（ACC）、处理不当行为的法官合约（JC）以及记录和管理ACC与JC交互的注册合约（RC），提供了灵活、透明和去中心化的解决方案。文章所描述的安全模型结合了影响和严重性评估，运用CIA（机密性、完整性和可用性）和STRIDE原则，确保威胁应对措施能够适应不同的威胁级别。该系统不仅解决了P2P网络中节点成员变更带来的基础问题，还为物联网（IoT）和Web 3.0等技术领域提供了一个可扩展的解决方案。 <div>
arXiv:2412.03709v1 Announce Type: new 
Abstract: Ensuring security for highly dynamic peer-to-peer (P2P) networks has always been a challenge, especially for services like online transactions and smart devices. These networks experience high churn rates, making it difficult to maintain appropriate access control. Traditional systems, particularly Role-Based Access Control (RBAC), often fail to meet the needs of a P2P environment. This paper presents a blockchain-based access control framework that uses Ethereum smart contracts to address these challenges. Our framework aims to close the gaps in existing access control systems by providing flexible, transparent, and decentralized security solutions. The proposed framework includes access control contracts (ACC) that manage access based on static and dynamic policies, a Judge Contract (JC) to handle misbehavior, and a Register Contract (RC) to record and manage the interactions between ACCs and JC. The security model combines impact and severity-based threat assessments using the CIA (Confidentiality, Integrity, Availability) and STRIDE principles, ensuring responses are tailored to different threat levels. This system not only stabilizes the fundamental issues of peer membership but also offers a scalable solution, particularly valuable in areas such as the Internet of Things (IoT) and Web 3.0 technologies.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems</title>
<link>https://arxiv.org/abs/2412.03851</link>
<guid>https://arxiv.org/abs/2412.03851</guid>
<content:encoded><![CDATA[
<div> 关键词: 个性化医疗、联邦学习、数据异质性、累积傅里叶聚合、协同迁移优化

总结:
本文提出了Federated Meta-Learning for Personalized Medication（FedMetaMed）框架，旨在解决分布式医疗系统中个性化药物治疗面临的挑战。该框架结合了联邦学习和元学习，以适应不同医疗机构间的患者数据多样性。针对联邦学习中的服务器聚合阶段性能退化问题，FedMetaMed引入了累积傅里叶聚合（CFA）方法，从低到高频率逐步整合客户端模型，提升全局知识聚合的稳定性和有效性。在客户端，文章实施了一种名为协作迁移优化（CTO）的策略，通过检索、回馈和精炼三步流程，有效实现全球知识向本地个性化模型的平滑转移。实验结果显示，FedMetaMed在真实世界医学影像数据集上优于现有的联邦学习方法，表现出更强的泛化能力，尤其在外分布样本上表现突出。 <div>
arXiv:2412.03851v1 Announce Type: new 
Abstract: Personalized medication aims to tailor healthcare to individual patient characteristics. However, the heterogeneity of patient data across healthcare systems presents significant challenges to achieving accurate and effective personalized treatments. Ethical concerns further complicate the aggregation of large volumes of data from diverse institutions. Federated Learning (FL) offers a promising decentralized solution by enabling collaborative model training through the exchange of client models rather than raw data, thus preserving privacy. However, existing FL methods often suffer from retrogression during server aggregation, leading to a decline in model performance in real-world medical FL settings. To address data variability in distributed healthcare systems, we introduce Federated Meta-Learning for Personalized Medication (FedMetaMed), which combines federated learning and meta-learning to create models that adapt to diverse patient data across healthcare systems. The FedMetaMed framework aims to produce superior personalized models for individual clients by addressing these limitations. Specifically, we introduce Cumulative Fourier Aggregation (CFA) at the server to improve stability and effectiveness in global knowledge aggregation. CFA achieves this by gradually integrating client models from low to high frequencies. At the client level, we implement a Collaborative Transfer Optimization (CTO) strategy with a three-step process - Retrieve, Reciprocate, and Refine - to enhance the personalized local model through seamless global knowledge transfer. Experiments on real-world medical imaging datasets demonstrate that FedMetaMed outperforms state-of-the-art FL methods, showing superior generalization even on out-of-distribution cohorts.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>JANUS: A Difference-Oriented Analyzer For Financial Centralization Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2412.03938</link>
<guid>https://arxiv.org/abs/2412.03938</guid>
<content:encoded><![CDATA[
<div> 关键词: JANUS、智能合约、中心化风险、检测精度、状态遍历

<br /><br />总结:
本文提出了一种名为JANUS的新工具，用于自动分析Solidity智能合约并独立于具体行为模式检测金融中心化风险。JANUS通过比较特权账户与普通账户所达到的状态差异，并分析这些差异是否与财务相关，从而聚焦于风险的影响而非行为本身，提高了检测准确性。对包含540份合同的测试集进行评估显示，JANUS在检测金融中心化风险方面的准确率优于现有代表性工具。此外，在实际应用中，JANUS对33,151份合同进行了评估，成功发现了其他工具未能检测到的两种类型的风险。同时证明，JANUS使用的状态遍历方法和变量摘要并不会导致检测中的误报或遗漏。 <div>
arXiv:2412.03938v1 Announce Type: new 
Abstract: Some smart contracts violate decentralization principles by defining privileged accounts that manage other users' assets without permission, introducing centralization risks that have caused financial losses. Existing methods, however, face challenges in accurately detecting diverse centralization risks due to their dependence on predefined behavior patterns. In this paper, we propose JANUS, an automated analyzer for Solidity smart contracts that detects financial centralization risks independently of their specific behaviors. JANUS identifies differences between states reached by privileged and ordinary accounts, and analyzes whether these differences are finance-related. Focusing on the impact of risks rather than behaviors, JANUS achieves improved accuracy compared to existing tools and can uncover centralization risks with unknown patterns.
  To evaluate JANUS's performance, we compare it with other tools using a dataset of 540 contracts. Our evaluation demonstrates that JANUS outperforms representative tools in terms of detection accuracy for financial centralization risks . Additionally, we evaluate JANUS on a real-world dataset of 33,151 contracts, successfully identifying two types of risks that other tools fail to detect. We also prove that the state traversal method and variable summaries, which are used in JANUS to reduce the number of states to be compared, do not introduce false alarms or omissions in detection.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WACANA: A Concolic Analyzer for Detecting On-chain Data Vulnerabilities in WASM Smart Contracts</title>
<link>https://arxiv.org/abs/2412.03946</link>
<guid>https://arxiv.org/abs/2412.03946</guid>
<content:encoded><![CDATA[
<div> 关键词: WebAssembly (WASM), 智能合约, 安全漏洞, WACANA, 精细粒度模拟

总结:
<br />
本文介绍了针对WebAssembly (WASM)智能合约的安全分析工具WACANA。该工具通过精细粒度地模拟链上数据API来准确检测合同中的安全漏洞，从而克服了现有工具精度有限的问题。WACANA精确地模拟了链上数据表的结构和对应的API函数，并结合具体执行与符号执行，在保证准确性的同时提高了效率。实验结果显示，WACANA在对133份有漏洞的合约进行评估时，其准确性超过了当前最先进的工具。进一步在5,602个真实世界的合约中进行验证，证实了WACANA的实际有效性。 <div>
arXiv:2412.03946v1 Announce Type: new 
Abstract: WebAssembly (WASM) has emerged as a crucial technology in smart contract development for several blockchain platforms. Unfortunately, since their introduction, WASM smart contracts have been subject to several security incidents caused by contract vulnerabilities, resulting in substantial economic losses. However, existing tools for detecting WASM contract vulnerabilities have accuracy limitations, one of the main reasons being the coarse-grained emulation of the on-chain data APIs.
  In this paper, we introduce WACANA, an analyzer for WASM contracts that accurately detects vulnerabilities through fine-grained emulation of on-chain data APIs. WACANA precisely simulates both the structure of on-chain data tables and their corresponding API functions, and integrates concrete and symbolic execution within a coverage-guided loop to balance accuracy and efficiency. Evaluations on a vulnerability dataset of 133 contracts show WACANA outperforming state-of-the-art tools in accuracy. Further validation on 5,602 real-world contracts confirms WACANA's practical effectiveness.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dimension Reduction via Random Projection for Privacy in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2412.04031</link>
<guid>https://arxiv.org/abs/2412.04031</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent System (MAS), 信息融合中心, 隐私风险, 数据 utility, 数据隐私保护<br /><br />总结：<br />
本文探讨了多智能体系统(MAS)中，各智能体向信息融合中心发送观测数据时，为提高系统效率而需要附加私人参数所面临的隐私风险问题。为了在保证数据通信安全、防止数据隐私泄露和推理攻击的同时，尽可能减少对数据实用性的损失，文章使用余弦相似性量化系统的实用性和隐私性。文中首先将MAS问题形式化为一个可通过压缩方法解决的概念问题，接着提出一种基于此类压缩方法的创新性数据净化机制，旨在解决实用性与隐私保护之间的权衡问题。 <div>
arXiv:2412.04031v1 Announce Type: new 
Abstract: The agents in a Multi-Agent System (MAS) make observations about the system and send that information to a fusion center. The fusion center aggregates the information and concludes about the system parameters with as much accuracy as possible. However for the purposes of better efficiency of the system at large, the agents need to append some private parameters to the observed data. In this scenario, the data sent to the fusion center is faced with privacy risks. The data communicated to the fusion center must be secured against data privacy breaches and inference attacks in a decentralized manner. However, this in turn leads to a loss of utility of the data being sent to the fusion center. We quantify the utility and privacy of the system using Cosine similarity. We formulate our MAS problem in terms of deducing a concept for which compression-based methods are there in literature. Next, we propose a novel sanitization mechanism for our MAS using one such compression-based method while addressing the utility-privacy tradeoff problem.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Dynamic Event-triggered Output-feedback Control of Stochastic Non-triangular Interconnected Systems with Unknown Time-varying Sensor Sensitivity</title>
<link>https://arxiv.org/abs/2412.04131</link>
<guid>https://arxiv.org/abs/2412.04131</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized output-feedback control, stochastic non-triangular nonlinear systems, time-varying sensor sensitivity, dynamic event-triggered control, global asymptotic stability

总结:<br />
针对具有未知时变传感器灵敏度的随机非三角形非线性互联系统，该研究提出了一种新颖的去中心化动态事件触发输出反馈控制策略。首先，通过独特的坐标变换建立了各子系统的状态向量与两个误差向量之间的线性关系，有效处理了非三角形结构不确定性带来的复杂性。其次，引入了一种包含状态观测器和去中心化输出反馈控制器的动态事件触发机制，设计了一个基于预测plant状态值和时钟变量演化的辅助变量，确保了执行间隔时间存在正下界，从而避免Zeno行为。通过对封闭环路系统的Lyapunov分析，证实了系统全局概收敛稳定性，每个局部子系统的状态和输出均以概率收敛至原点。此外，还保证了触发时刻之间存在最小驻留时间。 <div>
arXiv:2412.04131v1 Announce Type: new 
Abstract: This study addresses the intricate challenge of decentralized output-feedback control for stochastic non-triangular nonlinear interconnected systems with unknown time-varying sensor sensitivity in a dynamic event-triggered context. The presence of stochastic disturbances, non-triangular structural uncertainties, and evolving sensor sensitivity distinguishes this problem of global asymptotic stability from conventional event-triggered control scenarios. Existing event-triggered control approaches with static event conditions encounter difficulties in simultaneously ensuring zero tracking/stabilization error and preventing the occurrence of Zeno behavior. In this work, we develop a novel solution to address this complex issue. Firstly, we establish a linear relationship between the state vector of each interconnected subsystem and two error vectors through a unique coordinate transformation. This transformation effectively handles the complexities introduced by non-triangular structural uncertainties. Secondly, we introduce a decentralized dynamic event-triggered output-feedback control strategy, which involves a state observer and a decentralized output-feedback controller. Unlike conventional event-triggered control methods with static event conditions, this strategy formulates a modified clock-based dynamic triggering mechanism by introducing an auxiliary variable that evolves based on predicted plant state values, while utilizing a clock variable to guarantee the existence of a positive lower bound on inter-execution times. Rigorous Lyapunov analysis confirms the global asymptotic stability in probability of the closed-loop system, with the states and the output of each local subsystem converging to the equilibrium at the origin in probability. Additionally, the existence of a minimal dwell-time between triggering instants is guaranteed.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DistB-VNET: Distributed Cluster-based Blockchain Vehicular Ad-Hoc Networks through SDN-NFV for Smart City</title>
<link>https://arxiv.org/abs/2412.04222</link>
<guid>https://arxiv.org/abs/2412.04222</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能城市、车联网、分布式区块链、软件定义网络、网络功能虚拟化<br /><br />总结:
本文提出了一个名为DistB-VNET的分布式区块链车联网架构，旨在为智能城市的车辆与基础设施交互提供安全、可扩展和可靠的通信。该架构融合了二进制恶意流量分类、软件定义网络(SDN)和网络功能虚拟化(NFV)，利用去中心化的区块链保障数据安全管理，结合SDN-NFV实现动态网络管理和资源效率提升。同时，采用孤立森林算法作为入侵检测系统，其在识别恶意流量方面达到了99.23%的高精度。DistB-VNET还引入了双层区块链系统，其中分布式区块链确保车车间的安全通信，而云中的集中式区块链负责数据验证和存储，增强了安全性、可扩展性和适应性，有助于优化交通管理、提高数据安全性和隐私保护。此外，这种方案显著降低了延迟，提高了网络安全性能并减少了网络拥塞，为现有的智能城市基础设施提供了有效的替代选择。 <div>
arXiv:2412.04222v1 Announce Type: new 
Abstract: In the developing topic of smart cities, Vehicular Ad-Hoc Networks (VANETs) are crucial for providing successful interaction between vehicles and infrastructure. This research proposes a distributed Blockchain-based Vehicular Ad-hoc Network (DistB-VNET) architecture that includes binary malicious traffic classification, Software Defined Networking (SDN), and Network Function Virtualization (NFV) to ensure safe, scalable, and reliable vehicular networks in smart cities. The suggested framework is the decentralized blockchain for safe data management and SDN-NFV for dynamic network management and resource efficiency and a noble isolation forest algorithm works as an IDS (Intrusion Detection System). Further, "DistB-VNET" offers a dual-layer blockchain system, where a distributed blockchain provides safe communication between vehicles, while a centralized blockchain in the cloud is in charge of data verification and storage. This improves security, scalability, and adaptability, ensuring better traffic management, data security, and privacy in VANETs. Furthermore, the unsupervised isolation forest model achieves a high accuracy of 99.23% for detecting malicious traffic. Additionally, reveals that our method greatly improves network performance, offering decreased latency, increased security, and reduced congestion, an effective alternative for existing smart city infrastructures.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>VMGuard: Reputation-Based Incentive Mechanism for Poisoning Attack Detection in Vehicular Metaverse</title>
<link>https://arxiv.org/abs/2412.04349</link>
<guid>https://arxiv.org/abs/2412.04349</guid>
<content:encoded><![CDATA[
<div> 关键词：vehicular Metaverse, 数据中毒攻击, 安全框架, 信任度评估, 口碑激励机制

总结:
<br />
本文提出了一种名为vehicular Metaverse guard (VMGuard)的四层安全框架，用于保护车载元宇宙系统免受数据中毒攻击。该框架针对虚拟服务提供商(VSPs)通过恶意物联网(IoT)设备收集物理环境数据时可能存在的内容篡改问题，以及具有道德风险的恶意SIoT设备可能出于私利提供有毒数据以降低VMUs的服务质量和用户体验(QoS和QoE)的问题。VMGuard采用了基于用户反馈和主观逻辑建模的口碑激励机制，为参与的SIoT设备根据历史交互记录分配声誉评分。通过综合模拟验证，该机制能有效阻止恶意SIoT设备发起的中毒攻击，并确保先前被误分类的可靠SIoT设备不会被排除在未来市场轮次之外。 <div>
arXiv:2412.04349v1 Announce Type: new 
Abstract: The vehicular Metaverse represents an emerging paradigm that merges vehicular communications with virtual environments, integrating real-world data to enhance in-vehicle services. However, this integration faces critical security challenges, particularly in the data collection layer where malicious sensing IoT (SIoT) devices can compromise service quality through data poisoning attacks. The security aspects of the Metaverse services should be well addressed both when creating the digital twins of the physical systems and when delivering the virtual service to the vehicular Metaverse users (VMUs). This paper introduces vehicular Metaverse guard (VMGuard), a novel four-layer security framework that protects vehicular Metaverse systems from data poisoning attacks. Specifically, when the virtual service providers (VSPs) collect data about physical environment through SIoT devices in the field, the delivered content might be tampered. Malicious SIoT devices with moral hazard might have private incentives to provide poisoned data to the VSP to degrade the service quality (QoS) and user experience (QoE) of the VMUs. The proposed framework implements a reputation-based incentive mechanism that leverages user feedback and subjective logic modeling to assess the trustworthiness of participating SIoT devices. More precisely, the framework entails the use of reputation scores assigned to participating SIoT devices based on their historical engagements with the VSPs. Ultimately, we validate our proposed model using comprehensive simulations. Our key findings indicate that our mechanism effectively prevents the initiation of poisoning attacks by malicious SIoT devices. Additionally, our system ensures that reliable SIoT devices, previously missclassified, are not barred from participating in future rounds of the market.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Providing Differential Privacy for Federated Learning Over Wireless: A Cross-layer Framework</title>
<link>https://arxiv.org/abs/2412.04408</link>
<guid>https://arxiv.org/abs/2412.04408</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Over-the-air FL, Differential Privacy, Power Control, Cooperative Jammer

<br /><br />总结:
本文提出了一个针对无线边缘网络中Over-the-air FL的物理层设计，旨在增强差分隐私保护。该设计采用一种去中心化、动态的功率控制策略，利用无线信道中的高斯噪声和合作干扰器（CJ）生成额外的人工噪声以在需要更高隐私级别时提供支持。虽然主要应用于Upcycled-FL框架，但该功率控制策略也可适用于FedAvg和FedProx等其他FL框架，展现了其灵活性和普适性。此外，该设计通过合作干扰器增强了隐私保护，无需客户端注入人工噪声，同时保证了传输效率。文中使用Moments Accountant方法进行了隐私分析，并对非凸目标函数下的收敛性进行了分析，探讨了隐私与准确性之间的权衡。数值结果表明，无论是在FEMNIST非独立同分布数据集上，还是在相同的差分隐私条件下，与现有技术相比，本文提出的方法都表现出了优越性能，并突显了合作干扰器在确保严格隐私方面的有效性。 <div>
arXiv:2412.04408v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning framework that inherently allows edge devices to maintain their local training data, thus providing some level of privacy. However, FL's model updates still pose a risk of privacy leakage, which must be mitigated. Over-the-air FL (OTA-FL) is an adapted FL design for wireless edge networks that leverages the natural superposition property of the wireless medium. We propose a wireless physical layer (PHY) design for OTA-FL which improves differential privacy (DP) through a decentralized, dynamic power control that utilizes both inherent Gaussian noise in the wireless channel and a cooperative jammer (CJ) for additional artificial noise generation when higher privacy levels are required. Although primarily implemented within the Upcycled-FL framework, where a resource-efficient method with first-order approximations is used at every even iteration to decrease the required information from clients, our power control strategy is applicable to any FL framework, including FedAvg and FedProx as shown in the paper. This adaptation showcases the flexibility and effectiveness of our design across different learning algorithms while maintaining a strong emphasis on privacy. Our design removes the need for client-side artificial noise injection for DP, utilizing a cooperative jammer to enhance privacy without affecting transmission efficiency for higher privacy demands. Privacy analysis is provided using the Moments Accountant method. We perform a convergence analysis for non-convex objectives to tackle heterogeneous data distributions, highlighting the inherent trade-offs between privacy and accuracy. Numerical results show that our approach with various FL algorithms outperforms the state-of-the-art under the same DP conditions on the non-i.i.d. FEMNIST dataset, and highlight the cooperative jammer's effectiveness in ensuring strict privacy.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Market Consequences of Perceived Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers</title>
<link>https://arxiv.org/abs/2401.12064</link>
<guid>https://arxiv.org/abs/2401.12064</guid>
<content:encoded><![CDATA[
<div> 关键词：Crypto donations, NFT charity fundraisers, Social image, Market outcomes, Online experiment

<br /><br />总结：
本文探讨了非同质化代币（NFT）慈善筹款活动中捐赠者的动机和经济后果，特别是捐赠者从升值的NFT中可能获得的财务收益对社会形象的影响。研究通过利用区块链上交易处理时间的随机变化来识别在慈善筹款活动中购买NFT对捐赠者后续市场结果的因果效应。进一步分析发现，将购得的慈善NFT重新上市出售（显示战略性慷慨行为）的个人以及在NFT市场中有较高社交曝光度的人，在其其他NFT的价格方面会受到显著惩罚。在线实验的结果也证实了这一发现，表明将慈善NFT转售以获利会让他人将其初始捐赠视为具有战略性的慷慨行为，从而降低他人从该捐赠者处购买NFT的意愿。这项研究强调了在加密慈善和更广泛的网络慈善领域中，数字可见性和可追溯性日益重要的影响。 <div>
arXiv:2401.12064v2 Announce Type: replace-cross 
Abstract: Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about donors' motivations in these charity fundraisers, potentially resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of perceived strategic generosity) and based on an individual's social exposure within the NFT marketplace. We show that charity-NFT 're-listers' experience significant penalties in the market regarding the prices they can command for their other NFTs, particularly among those who are more socially exposed. Finally, we report the results of a scenario-based online experiment, which again support our findings, highlighting that the re-listing a charity NFT for sale at a profit leads others to perceive their initial donation as strategic generosity and reduces those others' willingness to purchase NFTs from the donor. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Block MedCare: Advancing healthcare through blockchain integration with AI and IoT</title>
<link>https://arxiv.org/abs/2412.02851</link>
<guid>https://arxiv.org/abs/2412.02851</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、医疗健康、电子病历管理、以太坊、安全性、效率、患者控制、数字签名、角色访问控制、多层架构、去中心化应用、物联网设备、人工智能分析、整合成本、互操作性

<br /><br />总结：
该研究探索了将区块链技术应用于医疗健康领域，尤其是如何通过构建基于以太坊的新型系统来提升电子病历（EHR）管理的安全性和效率。此系统让病人能够安全地掌控自己的医疗数据，同时解决了实施医疗区块链面临的可扩展性、隐私和法规遵从性等挑战。该系统采用了数字签名、基于角色的访问控制以及多层架构，确保对数据的可控和安全访问。研究人员开发了一个面向患者、医生和管理员的用户友好的去中心化应用（dApp），展示了解决方案的实际应用价值。针对医疗保健专业人士和IT专家进行的调查显示，他们对于区块链技术的应用表示强烈兴趣，同时也关注其整合成本问题。此外，研究还探讨了未来与物联网设备和人工智能驱动的分析工具的融合，以期推动更安全、高效、互操作性的医疗系统的进化，从而利用前沿技术为改善患者护理提供支持。 <div>
arXiv:2412.02851v1 Announce Type: new 
Abstract: This research explores the integration of blockchain technology in healthcare, focusing on enhancing the security and efficiency of Electronic Health Record (EHR) management. We propose a novel Ethereum-based system that empowers patients with secure control over their medical data. Our approach addresses key challenges in healthcare blockchain implementation, including scalability, privacy, and regulatory compliance. The system incorporates digital signatures, Role-Based Access Control, and a multi-layered architecture to ensure secure, controlled access. We developed a decentralized application (dApp) with user-friendly interfaces for patients, doctors, and administrators, demonstrating the practical application of our solution. A survey among healthcare professionals and IT experts revealed strong interest in blockchain adoption, while also highlighting concerns about integration costs. The study explores future enhancements, including integration with IoT devices and AI-driven analytics, contributing to the evolution of secure, efficient, and interoperable healthcare systems that leverage cutting-edge technologies for improved patient care.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BGTplanner: Maximizing Training Accuracy for Differentially Private Federated Recommenders via Strategic Privacy Budget Allocation</title>
<link>https://arxiv.org/abs/2412.02934</link>
<guid>https://arxiv.org/abs/2412.02934</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦推荐系统(FR)，差分隐私(DP)，Differentially Private Federated Recommender (DPFR)，预算规划器(BGTplanner)，上下文多臂博弈(CMAB)

总结:<br />
本文针对差分隐私联邦推荐系统(DPFR)存在的噪声失真导致的准确性不足问题，提出了一种名为BGTplanner的新方法，用于战略性的在每轮DPFR训练中分配隐私预算以提升整体训练性能。BGTplanner利用高斯过程回归预测给定隐私预算下推荐精度的变化，并结合历史信息以及上下文多臂博弈(CMAB)进行决策，平衡当前优化与长期隐私约束。实验结果显示，相比于现有最优基线，BGTplanner在真实数据集上平均提高了6.76%的训练性能。 <div>
arXiv:2412.02934v1 Announce Type: new 
Abstract: To mitigate the rising concern about privacy leakage, the federated recommender (FR) paradigm emerges, in which decentralized clients co-train the recommendation model without exposing their raw user-item rating data. The differentially private federated recommender (DPFR) further enhances FR by injecting differentially private (DP) noises into clients. Yet, current DPFRs, suffering from noise distortion, cannot achieve satisfactory accuracy. Various efforts have been dedicated to improving DPFRs by adaptively allocating the privacy budget over the learning process. However, due to the intricate relation between privacy budget allocation and model accuracy, existing works are still far from maximizing DPFR accuracy. To address this challenge, we develop BGTplanner (Budget Planner) to strategically allocate the privacy budget for each round of DPFR training, improving overall training performance. Specifically, we leverage the Gaussian process regression and historical information to predict the change in recommendation accuracy with a certain allocated privacy budget. Additionally, Contextual Multi-Armed Bandit (CMAB) is harnessed to make privacy budget allocation decisions by reconciling the current improvement and long-term privacy constraints. Our extensive experimental results on real datasets demonstrate that \emph{BGTplanner} achieves an average improvement of 6.76\% in training performance compared to state-of-the-art baselines.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Mobile Target Tracking Using Consensus-Based Estimation with Nearly-Constant-Velocity Modeling</title>
<link>https://arxiv.org/abs/2412.03095</link>
<guid>https://arxiv.org/abs/2412.03095</guid>
<content:encoded><![CDATA[
<div> 关键词：移动目标跟踪、分布式追踪框架、一致性估计滤波器（CBEF）、近似常速模型、饱和基过滤技术

总结:
本文提出了一种利用一致性估计滤波器（CBEF）与近似常速模型集成的分布式移动目标跟踪框架。该框架允许网络中的代理节点通过共享局部观测数据并达成共识来共同估计目标位置，即使存在通信约束和测量噪声也能实现这一目标。文中采用饱和基过滤技术增强了系统的鲁棒性，降低了由于传感器数据噪声带来的影响。仿真结果表明，所提出的方案能够随时间有效降低均方估计误差（MSEE），从而提高估计算法的精度和可靠性。这凸显了CBEF在分布式环境中的有效性及其在不确定性条件下的可扩展性和韧性。 <div>
arXiv:2412.03095v1 Announce Type: new 
Abstract: Mobile target tracking is crucial in various applications such as surveillance and autonomous navigation. This study presents a decentralized tracking framework utilizing a Consensus-Based Estimation Filter (CBEF) integrated with the Nearly-Constant-Velocity (NCV) model to predict a moving target's state. The framework facilitates agents in a network to collaboratively estimate the target's position by sharing local observations and achieving consensus despite communication constraints and measurement noise. A saturation-based filtering technique is employed to enhance robustness by mitigating the impact of noisy sensor data. Simulation results demonstrate that the proposed method effectively reduces the Mean Squared Estimation Error (MSEE) over time, indicating improved estimation accuracy and reliability. The findings underscore the effectiveness of the CBEF in decentralized environments, highlighting its scalability and resilience in the presence of uncertainties.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.03188</link>
<guid>https://arxiv.org/abs/2412.03188</guid>
<content:encoded><![CDATA[
<div> 关键词：智能移动、分布式传感器、时空图神经网络（ST-GNN）、半去中心化训练、云计算节点

总结:<br />
本文针对智能移动领域中大量地理分布传感器产生的高频率时空数据实时处理问题，提出了利用半去中心化的时空图神经网络（ST-GNN）训练技术。文章设计了一个模拟框架，将传感器按地理位置划分为多个云计算节点，每个节点处理交通图的一部分并从其他节点获取节点特征来训练本地ST-GNN模型，同时与其他节点交换模型更新以保持一致性，从而提高可扩展性和容错性。通过对比分析四种不同的ST-GNN训练设置（集中式、传统联邦学习、无服务器联邦学习和Gossip Learning），在大规模交通数据集METR-LA和PeMS-BAY上进行短期、中期和长期车辆速度预测任务的实验，结果显示半去中心化设置在性能指标上与集中式方法相当，但在可扩展性和容错性方面具有优势。此外，文中还指出了现有文献中关于分布式ST-GNNs常常被忽视的问题，如不同地理区域间因特定交通模式导致的模型性能差异以及由GNN大感受野引发的显著通信开销和计算成本，进而造成大量的数据传输和局部嵌入计算增加。 <div>
arXiv:2412.03188v1 Announce Type: new 
Abstract: In smart mobility, large networks of geographically distributed sensors produce vast amounts of high-frequency spatio-temporal data that must be processed in real time to avoid major disruptions. Traditional centralized approaches are increasingly unsuitable to this task, as they struggle to scale with expanding sensor networks, and reliability issues in central components can easily affect the whole deployment. To address these challenges, we explore and adapt semi-decentralized training techniques for Spatio-Temporal Graph Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation framework where sensors are grouped by proximity into multiple cloudlets, each handling a subgraph of the traffic graph, fetching node features from other cloudlets to train its own local ST-GNN model, and exchanging model updates with other cloudlets to ensure consistency, enhancing scalability and removing reliance on a centralized aggregator. We perform extensive comparative evaluation of four different ST-GNN training setups -- centralized, traditional FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed predictions. Experimental results show that semi-decentralized setups are comparable to centralized approaches in performance metrics, while offering advantages in terms of scalability and fault tolerance. In addition, we highlight often overlooked issues in existing literature for distributed ST-GNNs, such as the variation in model performance across different geographical areas due to region-specific traffic patterns, and the significant communication overhead and computational costs that arise from the large receptive field of GNNs, leading to substantial data transfers and increased computation of partial embeddings.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>HCC: A Language-Independent Hardening Contract Compiler for Smart Contracts</title>
<link>https://arxiv.org/abs/2203.00364</link>
<guid>https://arxiv.org/abs/2203.00364</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全智能合约、HCC、源代码级安全检查、代码属性图(CPG)、实用型编译器

总结:
本文提出了一种名为HCC的首个实用型智能合约编译器，旨在自动在源代码层面插入基于新型语言无关代码属性图(CPG)表示的安全强化检查。CPG的高度表达性使HCC能够缓解包括重入攻击、整数错误、自杀式智能合约、不恰当使用tx.origin、不受信任的委托调用以及未检查的低级别调用等最常见的智能合约漏洞。通过对1万个真实世界的智能合约及几组来自相关工作的易受攻击的合约进行大规模评估，结果显示HCC具有高度实用性，优于现有的合约强化技术，并能有效阻止所有验证过的攻击交易，同时并未损害功能正确性。<br /><br /> <div>
arXiv:2203.00364v2 Announce Type: replace 
Abstract: Developing secure smart contracts remains a challenging task. Existing approaches are either impractical or leave the burden to developers for fixing bugs. In this paper, we propose the first practical smart contract compiler, called HCC, which automatically inserts security hardening checks at the source-code level based on a novel and language-independent code property graph (CPG) notation. The high expressiveness of our developed CPG allows us to mitigate all of the most common smart contract vulnerabilities, namely reentrancy, integer bugs, suicidal smart contracts, improper use of tx.origin, untrusted delegate-calls, and unchecked low-level call bugs. Our large-scale evaluation on 10k real-world contracts and several sets of vulnerable contracts from related work demonstrates that HCC is highly practical, outperforms state-of-the-art contract hardening techniques, and effectively prevents all verified attack transactions without hampering functional correctness.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Development and Application of a Decentralized Domain Name Service</title>
<link>https://arxiv.org/abs/2412.01959</link>
<guid>https://arxiv.org/abs/2412.01959</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Domain Name Service (DDNS)，区块链(Phicoin)，分布式存储(IPFS)，中心化架构，安全稳定性

总结:
<br />
本文提出了一种基于区块链(Phicoin)和分布式存储(IPFS)的去中心化域名服务系统（DDNS），旨在解决现有域名系统(DNS)存在的问题。传统DNS存在中心化架构带来的审查风险、单点故障及解析过程中的加密安全性不足等问题，同时高运营成本限制了中小用户参与与创新。DDNS通过利用区块链的不可篡改性以及IPFS的内容验证特性，实现了域名记录的去中心化存储和分布，消除了对传统DNS的中心化依赖。该系统支持每15秒快速广播一次域名更新，显著提高了解析效率。DDNS的目标是作为现有DNS系统的补充或备份，提供一种抗污染、抗审查、高性能、低成本的域名解析解决方案，为互联网的安全稳定提供了新的技术路径。 <div>
arXiv:2412.01959v1 Announce Type: new 
Abstract: The current Domain Name System (DNS), as a core infrastructure of the internet, exhibits several shortcomings: its centralized architecture leads to censorship risks and single points of failure, making domain name resolution vulnerable to attacks. The lack of encryption in the resolution process exposes it to DNS hijacking and cache poisoning attacks. Additionally, the high operational costs limit participation and innovation among small to medium-sized users. To address these issues, this paper proposes a Decentralized Domain Name Service (DDNS) based on blockchain (Phicoin) and distributed storage (IPFS). By leveraging the immutability of blockchain and the content verification of IPFS, the system achieves decentralized storage and distribution of domain name records, eliminating the centralized dependencies of traditional DNS. With a block time of 15 seconds, the system supports rapid broadcasting of domain name updates, significantly improving resolution efficiency. The DDNS aims to serve as a complement or backup to the existing DNS system, providing a pollution-resistant, censorship-resistant, high-performance, and low-cost domain name resolution solution, offering a new technical path for the security and stability of the internet.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generalized EXTRA stochastic gradient Langevin dynamics</title>
<link>https://arxiv.org/abs/2412.01993</link>
<guid>https://arxiv.org/abs/2412.01993</guid>
<content:encoded><![CDATA[
<div> 关键词：Langevin算法，Markov Chain Monte Carlo，贝叶斯学习，分布式SGLD（DE-SGLD），generalized EXTRA stochastic gradient Langevin dynamics

<br /><br />总结:
该文主要关注在数据分散于网络各节点并受到通信和隐私限制的情况下，如何进行贝叶斯学习的问题。标准的随机梯度Langevin动力学（SGLD）不适用于此场景，因此提出了分布式SGLD（DE-SGLD）算法。然而，现有的DE-SGLD算法在每个节点上存在偏差问题，即使使用完整批次的数据也是如此。为此，文章受EXTRA算法及其优化版本启发，提出了一种广义EXTRA随机梯度Langevin动力学算法，该算法成功消除了在全批次设置下的这一偏差。此外，在迷你批次设置下，新算法还提供了优于现有DE-SGLD算法的性能边界。数值实验进一步证实了所提方法的有效性。 <div>
arXiv:2412.01993v1 Announce Type: new 
Abstract: Langevin algorithms are popular Markov Chain Monte Carlo methods for Bayesian learning, particularly when the aim is to sample from the posterior distribution of a parametric model, given the input data and the prior distribution over the model parameters. Their stochastic versions such as stochastic gradient Langevin dynamics (SGLD) allow iterative learning based on randomly sampled mini-batches of large datasets and are scalable to large datasets. However, when data is decentralized across a network of agents subject to communication and privacy constraints, standard SGLD algorithms cannot be applied. Instead, we employ decentralized SGLD (DE-SGLD) algorithms, where Bayesian learning is performed collaboratively by a network of agents without sharing individual data. Nonetheless, existing DE-SGLD algorithms induce a bias at every agent that can negatively impact performance; this bias persists even when using full batches and is attributable to network effects. Motivated by the EXTRA algorithm and its generalizations for decentralized optimization, we propose the generalized EXTRA stochastic gradient Langevin dynamics, which eliminates this bias in the full-batch setting. Moreover, we show that, in the mini-batch setting, our algorithm provides performance bounds that significantly improve upon those of standard DE-SGLD algorithms in the literature. Our numerical results also demonstrate the efficiency of the proposed approach.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AVA: Fault-tolerant Reconfigurable Geo-Replication on Heterogeneous Clusters</title>
<link>https://arxiv.org/abs/2412.01999</link>
<guid>https://arxiv.org/abs/2412.01999</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2412.01999v1, 故障容错, 分布式数据库系统, 集群复制协议, AVA

总结:
该论文介绍了arXiv:2412.01999v1中提出的一种新型技术，针对全球金融基础设施构建中能源消耗更低的、容错性强的复制数据库系统。现有的集群复制协议往往假设节点数量恒定且均匀分布，并仅考虑简单故障模型（如停止失败）。论文提出了适用于具有任意故障情况的异构可重构的地理复制协议AVA，允许副本动态加入和离开集群，并形式化证明了协议的安全性和活性。此外，AVA协议共识机制无关，即每个集群可以使用任何本地复制机制。实验结果显示，在谷歌云上进行的地理分布式部署实验表明，无需显著影响交易处理即可重新配置集群成员，而集群的异构性则可能显著提高吞吐量。 <div>
arXiv:2412.01999v1 Announce Type: new 
Abstract: Fault-tolerant replicated database systems consume less energy than the compute-intensive proof-of-work blockchain. Thus, they are promising technologies for the building blocks that assemble global financial infrastructure. To facilitate global scaling, clustered replication protocols are essential in orchestrating nodes into clusters based on proximity. However, the existing approaches often assume a homogeneous and fixed model in which the number of nodes across clusters is the same and fixed, and often limited to a fail-stop fault model. This paper presents heterogeneous and reconfigurable clustered replication for the general environment with arbitrary failures. In particular, we present AVA, a fault-tolerant reconfigurable geo-replication that allows dynamic membership: replicas are allowed to join and leave clusters. We formally state and prove the safety and liveness properties of the protocol. Furthermore, our replication protocol is consensus-agnostic, meaning each cluster can utilize any local replication mechanism. In our comprehensive evaluation, we instantiate our replication with both HotStuff and BFT-SMaRt. Experiments on geo-distributed deployments on Google Cloud demonstrates that members of clusters can be reconfigured without considerably affecting transaction processing, and that heterogeneity of clusters may significantly improve throughput.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Enabled Device-Enhanced Multi-Access Edge Computing in Open Adversarial Environments</title>
<link>https://arxiv.org/abs/2412.02233</link>
<guid>https://arxiv.org/abs/2412.02233</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC), Honeybee框架, 区块链技术, 安全性, 效率

总结:
<br />
本文提出了一个名为Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC)的新框架，该框架基于Honeybee的按需资源池化理念并结合区块链技术，旨在确保不同拥有者的设备之间的信任、安全和可问责性。通过使计算过程可追溯，BdMEC降低了来自恶意设备的风险。原型与实验结果表明，BdMEC能够在多个设备间有效地、安全地管理分布式计算任务。 <div>
arXiv:2412.02233v1 Announce Type: new 
Abstract: We propose Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC). BdMEC extends the Honeybee framework for on-demand resource pooling with blockchain technology to ensure trust, security, and accountability among devices (even when they are owned by different parties). BdMEC mitigates risks from malicious devices by making computations traceable. Our prototype and results demonstrate BdMEC's ability to manage distributed computing tasks efficiently and securely across multiple devices.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence</title>
<link>https://arxiv.org/abs/2412.02263</link>
<guid>https://arxiv.org/abs/2412.02263</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链智能合约、大型语言模型、数据聚合、语义相关性、信任度发现

<br /><br />总结:
本文提出了一个名为{\sysname}的通用框架，旨在解决区块链智能合约与大型语言模型（LLMs）之间集成的难题，克服两者之间的互操作性障碍。通过结合语义相关性和真相发现方法，文章提出了一种创新的数据聚合方法{\funcname}，能显著提升由LLMs生成数据的准确性和可信度。为了验证框架的有效性，研究构建了一个包含三种类型问题的实验数据集，涵盖了10个预言机节点和5个LLM模型的Q&amp;A交互。实验结果显示，即使在40%恶意节点的情况下，该方案相比最优基线仍能平均提高数据准确性17.74%。这项研究不仅为智能合约的智能化增强提供了创新解决方案，还突显了LLMs与区块链技术深度整合的潜力，为未来更智能、更复杂的智能合约应用铺平道路。 <div>
arXiv:2412.02263v1 Announce Type: new 
Abstract: Blockchain smart contracts have catalyzed the development of decentralized applications across various domains, including decentralized finance. However, due to constraints in computational resources and the prevalence of data silos, current smart contracts face significant challenges in fully leveraging the powerful capabilities of Large Language Models (LLMs) for tasks such as intelligent analysis and reasoning. To address this gap, this paper proposes and implements a universal framework for integrating LLMs with blockchain data, {\sysname}, effectively overcoming the interoperability barriers between blockchain and LLMs. By combining semantic relatedness with truth discovery methods, we introduce an innovative data aggregation approach, {\funcname}, which significantly enhances the accuracy and trustworthiness of data generated by LLMs. To validate the framework's effectiveness, we construct a dataset consisting of three types of questions, capturing Q\&amp;A interactions between 10 oracle nodes and 5 LLM models. Experimental results demonstrate that, even with 40\% malicious nodes, the proposed solution improves data accuracy by an average of 17.74\% compared to the optimal baseline. This research not only provides an innovative solution for the intelligent enhancement of smart contracts but also highlights the potential for deep integration between LLMs and blockchain technology, paving the way for more intelligent and complex applications of smart contracts in the future.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learn More by Using Less: Distributed Learning with Energy-Constrained Devices</title>
<link>https://arxiv.org/abs/2412.02289</link>
<guid>https://arxiv.org/abs/2412.02289</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、系统异构性、能源限制、LeanFed、电池寿命

总结:
<br />
本文提出了一种名为LeanFed的能源感知型联邦学习框架，旨在解决参与训练的分布式设备因能源容量差异而带来的实际部署问题。LeanFed通过动态调整每个设备在训练过程中使用的局部数据比例，优化客户端选择和训练工作负载，从而最大化通信轮次中的设备参与度并确保它们不会耗尽电池电量。通过对CIFAR-10和CIFAR-100数据集进行模拟实验，与传统FedAvg方法对比，结果显示LeanFed在具有高度数据异构性和有限电池寿命的情况下，能显著提高模型准确性和稳定性，减少了客户端掉线情况，并延长了设备可用时间。这一方法彰显了能源高效、隐私保护的联邦学习在现实世界大规模应用中的潜力，为资源受限网络上的强大且可持续的人工智能奠定了基础。 <div>
arXiv:2412.02289v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a solution for distributed model training across decentralized, privacy-preserving devices, but the different energy capacities of participating devices (system heterogeneity) constrain real-world implementations. These energy limitations not only reduce model accuracy but also increase dropout rates, impacting on convergence in practical FL deployments. In this work, we propose LeanFed, an energy-aware FL framework designed to optimize client selection and training workloads on battery-constrained devices. LeanFed leverages adaptive data usage by dynamically adjusting the fraction of local data each device utilizes during training, thereby maximizing device participation across communication rounds while ensuring they do not run out of battery during the process. We rigorously evaluate LeanFed against traditional FedAvg on CIFAR-10 and CIFAR-100 datasets, simulating various levels of data heterogeneity and device participation rates. Results show that LeanFed consistently enhances model accuracy and stability, particularly in settings with high data heterogeneity and limited battery life, by mitigating client dropout and extending device availability. This approach demonstrates the potential of energy-efficient, privacy-preserving FL in real-world, large-scale applications, setting a foundation for robust and sustainable pervasive AI on resource-constrained networks.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bio-inspired visual relative localization for large swarms of UAVs</title>
<link>https://arxiv.org/abs/2412.02393</link>
<guid>https://arxiv.org/abs/2412.02393</guid>
<content:encoded><![CDATA[
<div> 关键词: visual perception, relative localization, UAVs, swarm control, neighbor density regression

总结:<br />
本文提出了一种新的用于无人机群体大规模相对定位的视觉感知方法。该方法受到生物感知机制的启发，如沙丁鱼群和蜜蜂群等动物群体能以分散但协调的方式移动，不再依赖于每个个体对邻居的位置估计，而是通过回归距离上的邻居密度来实现相对定位，从而提高了距离估算的准确性并提升了对邻数量级变化的可扩展性。此外，文章还提出了一种与新定位方法相兼容的新型群体控制算法。通过对所提方法的详尽评估，结果表明，基于回归的距离估计方法对于目标相对姿态变化更具鲁棒性，并且适合作为群体稳定控制的主要相对定位来源。 <div>
arXiv:2412.02393v1 Announce Type: new 
Abstract: We propose a new approach to visual perception for relative localization of agents within large-scale swarms of UAVs. Inspired by biological perception utilized by schools of sardines, swarms of bees, and other large groups of animals capable of moving in a decentralized yet coherent manner, our method does not rely on detecting individual neighbors by each agent and estimating their relative position, but rather we propose to regress a neighbor density over distance. This allows for a more accurate distance estimation as well as better scalability with respect to the number of neighbors. Additionally, a novel swarm control algorithm is proposed to make it compatible with the new relative localization method. We provide a thorough evaluation of the presented methods and demonstrate that the regressing approach to distance estimation is more robust to varying relative pose of the targets and that it is suitable to be used as the main source of relative localization for swarm stabilization.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Ensemble-Based Semi-Supervised Learning for Illicit Account Detection in Ethereum DeFi Transactions</title>
<link>https://arxiv.org/abs/2412.02408</link>
<guid>https://arxiv.org/abs/2412.02408</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), Ethereum区块链, 自动学习, 非法账户检测, SLEID框架

<br /><br />总结:

本文提出了一个名为Self-Learning Ensemble-based Illicit account Detection (SLEID)的新型框架，用于解决以太坊区块链上去中心化金融(DeFi)领域日益严重的安全风险问题，特别是非法账户欺诈行为。SLEID框架采用Isolation Forest进行初步异常检测，并利用自训练机制生成未标注账户的伪标签，从而提高检测准确性。通过大量实验，SLEID展示出了比传统监督方法和近期半监督模型更高的精确度、召回率和F1分数，尤其在识别非法账户方面表现出色。相较于现有最先进的方法，SLEID在降低对标注数据依赖的同时，实现了更好的检测性能，为保护DeFi生态系统及防范恶意账户带来的风险提供了有力保障。 <div>
arXiv:2412.02408v1 Announce Type: new 
Abstract: The advent of smart contracts has enabled the rapid rise of Decentralized Finance (DeFi) on the Ethereum blockchain, offering substantial rewards in financial innovation and inclusivity. However, this growth has also introduced significant security risks, including the proliferation of illicit accounts involved in fraudulent activities. Traditional detection methods are limited by the scarcity of labeled data and the evolving tactics of malicious actors. In this paper, we propose a novel Self-Learning Ensemble-based Illicit account Detection (SLEID) framework to address these challenges. SLEID employs an Isolation Forest for initial outlier detection and a self-training mechanism to iteratively generate pseudo-labels for unlabeled accounts, thereby enhancing detection accuracy. Extensive experiments demonstrate that SLEID significantly outperforms traditional supervised approaches and recent semi-supervised models, achieving superior precision, recall, and F1-scores, particularly in detecting illicit accounts. Compared to state-of-the-art methods, our approach achieves better detection performance while reducing reliance on labeled data. The results affirm SLEID's efficacy as a robust solution for safeguarding the DeFi ecosystem and mitigating risks posed by malicious accounts.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Defending Against Diverse Attacks in Federated Learning Through Consensus-Based Bi-Level Optimization</title>
<link>https://arxiv.org/abs/2412.02535</link>
<guid>https://arxiv.org/abs/2412.02535</guid>
<content:encoded><![CDATA[
<div> 关键词：adversarial attacks、federated learning、bi-level optimization、CB$^2$O、FedCB$^2$O

总结:
针对机器学习中对抗性攻击带来的挑战，特别是分布式训练和联邦学习中的问题，本文提出了一种将训练任务建模为双层优化问题的方法。文章对共识型双层优化（CB$^2$O）方法在有恶意代理的对抗性环境下的鲁棒性进行了理论分析，证明了CB$^2$O在均场定律下在全球收敛性方面的优势，揭示了其对于各种攻击的抵抗能力，并阐述了如何通过选择特定的超参数来减轻对抗性影响。从实践层面出发，本文将CB$^2$O扩展到聚类联邦学习场景，提出了新型的交互多粒子系统——FedCB$^2$O，并设计了一个适用于实际应用的算法。实验结果表明，FedCB$^2$O算法在去中心化聚类联邦学习场景下对于标签翻转攻击具有较强的鲁棒性，显示出了其实战的有效性。 <div>
arXiv:2412.02535v1 Announce Type: new 
Abstract: Adversarial attacks pose significant challenges in many machine learning applications, particularly in the setting of distributed training and federated learning, where malicious agents seek to corrupt the training process with the goal of jeopardizing and compromising the performance and reliability of the final models. In this paper, we address the problem of robust federated learning in the presence of such attacks by formulating the training task as a bi-level optimization problem. We conduct a theoretical analysis of the resilience of consensus-based bi-level optimization (CB$^2$O), an interacting multi-particle metaheuristic optimization method, in adversarial settings. Specifically, we provide a global convergence analysis of CB$^2$O in mean-field law in the presence of malicious agents, demonstrating the robustness of CB$^2$O against a diverse range of attacks. Thereby, we offer insights into how specific hyperparameter choices enable to mitigate adversarial effects. On the practical side, we extend CB$^2$O to the clustered federated learning setting by proposing FedCB$^2$O, a novel interacting multi-particle system, and design a practical algorithm that addresses the demands of real-world applications. Extensive experiments demonstrate the robustness of the FedCB$^2$O algorithm against label-flipping attacks in decentralized clustered federated learning scenarios, showcasing its effectiveness in practical contexts.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Reliability Estimation for Low Latency Mixnets</title>
<link>https://arxiv.org/abs/2406.06760</link>
<guid>https://arxiv.org/abs/2406.06760</guid>
<content:encoded><![CDATA[
<div> 关键词: mixnet、匿名路由、低延迟、可验证性、可靠性评分

总结:
<br />
本文提出了一种新的方案，旨在解决大规模低延迟混合网络（mixnet）与强可验证性和可靠性之间的挑战。现有的可验证性机制会引入显著的延迟开销，限制了mixnet的应用范围。该方案能够以几乎最优的时间复杂度，在去中心化的环境中估算mixnet中链接和节点的可靠性评分，且此过程独立于通过mixnet路由的总流量。它依赖于客户端凭证和基于VRF的路由新原语，确保合法客户端数据包遵循mixnet的路由策略，并随机生成不可伪造的测量数据包。实验结果在不可靠和对抗性环境下验证了该构造的可行性，证明了其可以实现在不影响客户端数据包传输延迟或产生显著带宽开销的情况下进行可靠性的估计。 <div>
arXiv:2406.06760v2 Announce Type: replace 
Abstract: While there exist mixnets that can anonymously route large amounts of data packets with end to end latency that can be as low as a second, %making them attractive for a variety of applications, combining this level of performance with strong verifiability and reliability properties that ensure the correct processing and delivery of packets has proved challenging. Indeed, existing verifiability mechanisms are incompatible with scalable low-latency operation due to imposing significant latency overheads measuring in minutes to hours, hence severely limiting the variety of applications mixnets can serve. We address this important gap by proposing a scheme that can estimate reliability scores for a mixnet's links and nodes in a decentralized manner with essentially optimal complexity that is independent of the total traffic routed through the mixnet. The scores can be computed publicly by all participants from a set of measurement packets that are eventually revealed and act as a random sample of the traffic, without affecting mixnet transmission latency for client packets or incurring significant bandwidth overhead. Our scheme assumes client credentials and relies on VRF-based routing, a novel primitive that ensures that legitimate client packets follow the routing policy of the mixnet, as well as randomly generating unforgeable measurement packets. We experimentally validate our construction both in unreliable and adversarial settings, demonstrating its feasibility.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Relaxing Trust Assumptions on Quantum Key Distribution Networks</title>
<link>https://arxiv.org/abs/2402.13136</link>
<guid>https://arxiv.org/abs/2402.13136</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、长距离、不信任中继器、QKD网络、信任级别

总结:
本文探讨了在量子通信网络中如何在对中继器的信任程度降低的情况下实现安全的秘密接力。文章提出了三种不同的QKD中继器信任级别：完全访问信任（FAT）、部分访问信任（PAT）和无访问信任（NAT），定义了中继器处理秘密信息的不同权限。针对不同信任级别，文中回顾并提出多种基于QKD的密钥管理系统构建方案，特别是在无访问信任级别的密钥管理系统的评估上，重点讨论了集中式与新型去中心化的密钥管理系统架构。这些不同架构为QKD网络的需求提供了灵活性，为未来长距离安全通信提供了一种更可靠且实用的解决方案思路。 <div>
arXiv:2402.13136v2 Announce Type: replace-cross 
Abstract: Quantum security over long distances with untrusted relays is largely unfounded and is still an open question for active research. Nevertheless, quantum networks based on trusted relays are being built across the globe. However, standard QKD network architecture implores a complete trust requirement on QKD relays, which is too demanding and limits the use cases for QKD networks. In this work, we explore the possibility to securely relay a secret in a QKD network by relaxing the trust assumptions (if not completely) on the relay. We characterize QKD relays with different trust levels, namely, Full Access Trust (FAT), Partial Access Trust (PAT), and No Access Trust (NAT). As the name suggests, each level defines the degree with which a relay is required to be trusted with the secret provided by the key management system for end-to-end communication. We then review and propose multiple constructions of the QKD key management system based on the different trust levels. Main contribution of the paper is realized by evaluating key management systems with no access trust level. In principle, we review key management with centralized topology and propose a new decentralized key management system. These different topologies provide various advantages based on the QKD network requirements, allowing an operational flexibility in the architecture. We believe this work presents a new perspective to the open problem of providing a confiding and a practical solution for future long range secure communications
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeTEcT: Dynamic and Probabilistic Parameters Extension</title>
<link>https://arxiv.org/abs/2405.16688</link>
<guid>https://arxiv.org/abs/2405.16688</guid>
<content:encoded><![CDATA[
<div> 关键词：DeTEcT框架、财富分布、参数化、动态货币供应、模拟经济活动

总结:
本文扩展了Sadykhov等人提出的DeTEcT框架，该框架用于建模代币经济中的财富分配和宏观经济场景模拟。文章提出了四种对DeTEcT框架进行参数化的方法，包括动态与静态以及概率性与非概率性的区分。通过这些参数化技术，研究者展示了如何限制框架以从DeTEcT中推导出现有的财富分布模型。此外，论文还探讨了使DeTEcT框架中的货币供应变得动态化的可能性及其对财富分布动态的影响，其目的在于使DeTEcT能够应用于没有最大供应量（如Ethereum）的代币经济模型，并为框架增加了约束形式的对称性。 <div>
arXiv:2405.16688v2 Announce Type: replace-cross 
Abstract: This paper presents a theoretical extension of the DeTEcT framework proposed by Sadykhov et al., DeTEcT, where a formal analysis framework was introduced for modelling wealth distribution in token economies. DeTEcT is a framework for analysing economic activity, simulating macroeconomic scenarios, and algorithmically setting policies in token economies. This paper proposes four ways of parametrizing the framework, where dynamic vs static parametrization is considered along with the probabilistic vs non-probabilistic. Using these parametrization techniques, we demonstrate that by adding restrictions to the framework it is possible to derive the existing wealth distribution models from DeTEcT. In addition to exploring parametrization techniques, this paper studies how money supply in DeTEcT framework can be transformed to become dynamic, and how this change will affect the dynamics of wealth distribution. The motivation for studying dynamic money supply is that it enables DeTEcT to be applied to modelling token economies without maximum supply (i.e., Ethereum), and it adds constraints to the framework in the form of symmetries.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Supercomputing Based Distributed Cloud Marketplace</title>
<link>https://arxiv.org/abs/2412.00016</link>
<guid>https://arxiv.org/abs/2412.00016</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、51%攻击、可扩展性、LuluChain、超级计算机速度

总结:<br />
本文提出了一个新的区块链技术——LuluChain，它旨在解决当前区块链面临的51%攻击威胁和可扩展性问题。现有的区块链系统在处理能力上不及集中式系统，这使得51%攻击成为可能。LuluChain致力于提供一种无限可扩展、安全且高吞吐量的解决方案，能实现接近超级计算机速度的性能，仅使用商业现成硬件。该系统简化了区块链模型，提高了功能、速度、可扩展性、隐私和灵活性，并能对抗云计算市场的寡头垄断定价模式，因为它对计算工作负载的需求极低。通过消除时间戳同步和所有参与者之间的多数同意需求，LuluChain开启了可靠信任、低成本即时交易和灵活即时智能合约的新可能。作为一个基于高性能分布式系统的分布式云市场基础，LuluChain被视为一种理想方案。 <div>
arXiv:2412.00016v1 Announce Type: new 
Abstract: The once mythological 51% attack has moved beyond the hypothetical and now poses a legitimate widespread threat to blockchain technology. Current blockchains provide inferior throughput capacity when compared to that of centralized systems, creating an obvious vulnerability which allows the 51% attack to occur within decentralized systems. Despite recent advancements in blockchain which introduce interesting models that achieve high throughputs with enhanced security and privacy, no current networks have evolved to deploy the optimal solution of combining scalability, security, and distributed systems to create a legitimate supercomputing enterprise-grade developer sandbox. In this paper, we introduce an infinitely scalable, secure, and high throughput blockchain capable of amassing supercomputer speeds with off-the-shelf hardware, LuluChain. LuluChain simplifies the blockchain model to obtain greater functionality, speed, scalability, privacy, and flexibility, that works to combat the inflated pricing models set by the oligopolistic cloud computing market as it requires minimal computational work. By eliminating the need for timestamp synchronization and majority agreement among all participants, LuluChain opens the door to reliable trust, low-cost instant transactions, and flexible instant smart contracts. The supercomputing, high throughput distributed system is the ideal foundation for an essential distributed cloud marketplace.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Collaboration in Incident Response with Large Language Models</title>
<link>https://arxiv.org/abs/2412.00652</link>
<guid>https://arxiv.org/abs/2412.00652</guid>
<content:encoded><![CDATA[
<div> 关键词：incident response，large language models，multi-agent collaboration，Backdoors & Breaches框架，cybersecurity training

<br /><br />总结:
本文探讨了利用大型语言模型（LLMs）作为智能代理来提升网络安全中事件响应（IR）协作效率和效果的新方法。研究通过在Backdoors & Breaches框架下模拟真实的IR场景，采用了集中式、分布式和混合型等多种团队结构进行实验。通过对不同配置下的代理人交互与性能分析，文章揭示了LLMs在优化多代理协作、增强决策制定、提高适应性和流程整合以更有效地应对网络威胁方面的潜力。 <div>
arXiv:2412.00652v1 Announce Type: new 
Abstract: Incident response (IR) is a critical aspect of cybersecurity, requiring rapid decision-making and coordinated efforts to address cyberattacks effectively. Leveraging large language models (LLMs) as intelligent agents offers a novel approach to enhancing collaboration and efficiency in IR scenarios. This paper explores the application of LLM-based multi-agent collaboration using the Backdoors & Breaches framework, a tabletop game designed for cybersecurity training. We simulate real-world IR dynamics through various team structures, including centralized, decentralized, and hybrid configurations. By analyzing agent interactions and performance across these setups, we provide insights into optimizing multi-agent collaboration for incident response. Our findings highlight the potential of LLMs to enhance decision-making, improve adaptability, and streamline IR processes, paving the way for more effective and coordinated responses to cyber threats.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.00661</link>
<guid>https://arxiv.org/abs/2412.00661</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、子采样、均值场Q学习（MFQ）、多项式时间、收敛性

总结:
本文提出了一种名为“SUBSAMPLE-MFQ”的新算法，用于解决多智能体强化学习中的挑战，特别是应对由于智能体数量增加导致的联合状态和动作空间指数级增长的问题。该算法结合了子采样技术和均值场Q学习，设计了一个针对$n$个智能体系统的去中心化随机策略。SUBSAMPLE-MFQ能够在时间复杂度为$k$的多项式时间内学习到系统策略，并随着子采样的智能体数量$k$增加，其收敛至最优策略的阶数为$\tilde{O}(1/\sqrt{k})$。实验部分验证了该方法在高斯挤压和全局探索等场景的有效性。 <div>
arXiv:2412.00661v1 Announce Type: new 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging due to the fact that the size of the joint state and action spaces are exponentially large in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm \texttt{SUBSAMPLE-MFQ} (\textbf{Subsample}-\textbf{M}ean-\textbf{F}ield-\textbf{Q}-learning) and a decentralized randomized policy for a system with $n$ agents. For $k\leq n$, our algorithm system learns a policy for the system in time polynomial in $k$. We show that this learned policy converges to the optimal policy in the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. We validate our method empirically on Gaussian squeeze and global exploration settings.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChainGuard: A Blockchain-based Authentication and Access Control Scheme for Distributed Networks</title>
<link>https://arxiv.org/abs/2412.00677</link>
<guid>https://arxiv.org/abs/2412.00677</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、去中心化认证、访问控制、ChainGuard、智能合约

<br /><br />总结:
本文提出了一个名为ChainGuard的新型方案，旨在解决如何在分布式网络中实现去中心化的身份认证和访问控制问题。ChainGuard利用区块链技术动态管理用户角色和权限，无需中央服务器，从而消除了传统集中式系统的瓶颈。该机制同时支持跨多个组织的用户交互，提升了安全性、效率和透明度。通过解决可扩展性、安全性和透明度等关键挑战，ChainGuard不仅弥合了传统集中式系统与区块链去中心化理念之间的鸿沟，还进一步加强了数据保护和操作效率。 <div>
arXiv:2412.00677v1 Announce Type: new 
Abstract: As blockchain technology gains traction for enhancing data security and operational efficiency, traditional centralized authentication systems remain a significant bottleneck. This paper addresses the challenge of integrating decentralized authentication and access control within distributed networks. We propose a novel solution named ChainGuard, a fully decentralized authentication and access control mechanism based on smart contracts. ChainGuard eliminates the need for a central server by leveraging blockchain technology to manage user roles and permissions dynamically. Our scheme supports user interactions across multiple organizations simultaneously, enhancing security, efficiency, and transparency. By addressing key challenges such as scalability, security, and transparency, ChainGuard not only bridges the gap between traditional centralized systems and blockchain's decentralized ethos but also enhances data protection and operational efficiency.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SEAM: A Secure Automated and Maintainable Smart Contract Upgrade Framework</title>
<link>https://arxiv.org/abs/2412.00680</link>
<guid>https://arxiv.org/abs/2412.00680</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contracts, upgrading, SEAM, diamond pattern, security

总结:<br />
本文提出了一种名为SEAM的新颖框架，用于解决智能合约升级这一关键挑战。SEAM通过使用钻石模式自动化将标准Solidity合约转换为可升级版本，简化了升级流程并解决了函数选择器冲突和存储槽碰撞两个主要安全漏洞问题。此外，该框架还提供了用于高效部署、修改和管理智能合约生命周期的工具。通过增强合同安全性并降低开发者的学习曲线，SEAM为构建更灵活和可维护的区块链应用奠定了坚实基础。 <div>
arXiv:2412.00680v1 Announce Type: new 
Abstract: This work addresses the critical challenges of upgrading smart contracts, which are vital for trust in automated transactions but difficult to modify once deployed. To address this issue, we propose SEAM, a novel framework that automates the conversion of standard Solidity contracts into upgradable versions using the diamond pattern. SEAM simplifies the upgrade process and addresses two key vulnerabilities: function selector clashes and storage slot collisions. Additionally, the framework provides tools for efficiently deploying, modifying, and managing smart contract lifecycles. By enhancing contract security and reducing the learning curve for developers, SEAM lays a robust foundation for more flexible and maintainable blockchain applications.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Proof-of-Work: A Secure Dynamic Approach to Fair and Efficient Blockchain Mining</title>
<link>https://arxiv.org/abs/2412.00690</link>
<guid>https://arxiv.org/abs/2412.00690</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof-of-Work (PoW), 能耗, 中心化, Collaborative Proof-of-Work (CPoW), 动态挖矿池形成协议

总结:<br />
本文针对Proof-of-Work (PoW)系统存在的能耗过高、挖矿权力中心化等问题，以及静态挖矿池对区块链去中心化特性与公平性的削弱，提出了一个新的Collaborative Proof-of-Work (CPoW)挖矿方法。该方法致力于提升以太坊网络的效率和公平性，具体表现为设计了一种动态挖矿池形成协议，使矿工能够根据计算能力进行协作，并通过精准验证和分配奖励的机制保障了奖励分配的安全与公正。这一研究通过解决传统挖矿的中心化和能源效率问题，为构建更加可持续的区块链生态系统做出了贡献。 <div>
arXiv:2412.00690v1 Announce Type: new 
Abstract: Proof-of-Work (PoW) systems face critical challenges, including excessive energy consumption and the centralization of mining power among entities with expensive hardware. Static mining pools exacerbate these issues by reducing competition and undermining the decentralized nature of blockchain networks, leading to economic inequality and inefficiencies in resource allocation. Their reliance on centralized pool managers further introduces vulnerabilities by creating a system that fails to ensure secure and fair reward distribution. This paper introduces a novel Collaborative Proof-of-Work (CPoW) mining approach designed to enhance efficiency and fairness in the Ethereum network. We propose a dynamic mining pool formation protocol that enables miners to collaborate based on their computational capabilities, ensuring fair and secure reward distribution by incorporating mechanisms to accurately verify and allocate rewards. By addressing the centralization and energy inefficiencies of traditional mining, this research contributes to a more sustainable blockchain ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Forking Way: When TEEs Meet Consensus</title>
<link>https://arxiv.org/abs/2412.00706</link>
<guid>https://arxiv.org/abs/2412.00706</guid>
<content:encoded><![CDATA[
<div> 关键词：Trusted Execution Environments (TEE), 区块链, 分布式平台, 叉攻击, 安全性分析

总结:
本文针对越来越多的分布式平台结合可信执行环境(TEE)和区块链的情况进行了系统研究，强调了这一组合被认为是保障区块链机密计算与防御叉攻击的良好方式。通过对29项TEE基区块链方案的深入分析，发现社区中对于如何整合TEE和区块链缺乏共识，并归纳出四种主要的互联手段及其局限性。此外，文章还揭示了三个生产就绪的TEE基区块链——Ten、Phala和Secret Network中存在的此前未被记录的叉攻击漏洞，并对这些漏洞提出了有效的应对措施。已将研究成果负责任地披露给相关平台的开发者。 <div>
arXiv:2412.00706v1 Announce Type: new 
Abstract: An increasing number of distributed platforms combine Trusted Execution Environments (TEEs) with blockchains. Indeed, many hail the combination of TEEs and blockchains a good "marriage": TEEs bring confidential computing to the blockchain while the consensus layer could help defend TEEs from forking attacks.
  In this paper, we systemize how current blockchain solutions integrate TEEs and to what extent they are secure against forking attacks. To do so, we thoroughly analyze 29 proposals for TEE-based blockchains, ranging from academic proposals to production-ready platforms. We uncover a lack of consensus in the community on how to combine TEEs and blockchains. In particular, we identify four broad means to interconnect TEEs with consensus, analyze their limitations, and discuss possible remedies. Our analysis also reveals previously undocumented forking attacks on three production-ready TEE-based blockchains: Ten, Phala, and the Secret Network. We leverage our analysis to propose effective countermeasures against those vulnerabilities; we responsibly disclosed our findings to the developers of each affected platform.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EnFed: An Energy-aware Opportunistic Federated Learning in Resource Constrained Environments for Human Activity Recognition</title>
<link>https://arxiv.org/abs/2412.00768</link>
<guid>https://arxiv.org/abs/2412.00768</guid>
<content:encoded><![CDATA[
<div> 关键词：能源效率、联邦学习、人类活动监测、模型更新、预测准确性

总结:<br />
本文提出了一种能源高效的联邦学习方法及其在人体活动监测与识别中的应用。该方法中，需要模型的应用设备请求其附近设备进行协作，同意请求的附近设备将模型更新发送至请求设备。请求设备接收到模型更新后进行聚合以构建自身模型。鉴于移动设备电池寿命有限，参与轮数依据所需精度水平和请求设备的电池电量来决定。实验结果表明，相比于分布式联邦学习方法，当使用LSTM作为底层数据分析模型时，该提议的方法能分别降低第一和第二数据集约59%和19%的训练时间和约19%的训练能量消耗；而使用MLP作为底层数据分析模型时，可分别减少约55%和72%的训练时间和训练能量消耗，同时保持了良好的预测准确性。 <div>
arXiv:2412.00768v1 Announce Type: new 
Abstract: This paper proposes an energy-efficient federated learning method and its application in human activity monitoring and recognition. In the proposed approach, the device that needs a model for an application requests its nearby devices for collaboration. The nearby devices that accept the request, send their model updates to the requesting device. The device receives the model updates from the collaborators and performs aggregation to build its model. As mobile devices have limited battery life, the number of rounds is decided based on the desired accuracy level and battery level of the requesting device. The performance of the proposed approach is evaluated with respect to prediction accuracy, training time, training energy consumption of the device, and response time. We have used two different datasets for performance evaluation. The first dataset contains different types of physical activities and the respective calorie burn. The second dataset is a human activity recognition dataset that considers six types of physical activities. The experimental results show that using the proposed method the training time and training energy consumption of the device are reduced by approximately 59% and 19% for the first and second datasets respectively, than the decentralized federated learning approach, while using LSTM as the underlying data analysis model. The results also present that the proposed method reduces the training time and energy consumption by approximately 55% and 72% for the first and second datasets respectively, than the decentralized federated learning approach while using MLP as the underlying data analysis model.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Post-Vaccination COVID-19 Data Analysis: Privacy and Ethics</title>
<link>https://arxiv.org/abs/2412.00774</link>
<guid>https://arxiv.org/abs/2412.00774</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19疫苗、区块链、个人隐私、不可变性、授权访问

总结:
<p>
该论文针对COVID-19疫苗接种过程中出现的公民隐私保护和个人数据滥用问题，提出了一种基于区块链的应用方案。此系统利用IEEE 2418.2TM-2020标准构建数据模型，旨在确保公民个人信息匿名性、疫苗接种数据的不可变性以及对抗性实体（如政府）对数据进行有限制且便捷的验证与分析。该系统在以太坊区块链上实现，并通过Python API模拟和验证疫苗接种过程中的每一步骤，从而在保障公民隐私的同时实现系统的可问责性。</p> <div>
arXiv:2412.00774v1 Announce Type: new 
Abstract: The COVID-19 pandemic has severely affected the world in terms of health, economy and peace. Fortunately, the countries are trying to overcome the situation by actively carrying out vaccinations. However, like any other massive operation involving humans such as human resource management, elections, surveys, etc., the vaccination process raises several questions about citizen privacy and misuse of personal data. In most of the countries, few attempts have been made to verify the vaccination statistics as reported by the health centers. These issues collectively require the solutions of anonymity of citizens' personal information, immutability of vaccination data and easy yet restricted access by adversarial bodies such as the government for the verification and analysis of the data. This paper introduces a blockchain-based application to simulate and monitor the vaccination process. The structure of data model used in the proposed system is based on the IEEE Standard for Data Format for Blockchain Systems 2418.2TM-2020. The proposed system enables authorized stakeholders to share and access relevant information for vaccination process chain while preserving citizen privacy and accountability of the system. It is implemented on the Ethereum blockchain and uses a Python API for the simulation and validation of each step of the vaccination process.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provable Partially Observable Reinforcement Learning with Privileged Information</title>
<link>https://arxiv.org/abs/2412.00985</link>
<guid>https://arxiv.org/abs/2412.00985</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、部分可观测性、特权信息、专家蒸馏、不对称actor-critic<br /><br />总结:
本文研究了在部分可观测环境下强化学习中利用特权信息的挑战与优势。首先，文章形式化了实践中的“专家蒸馏”（教师-学生学习）范式，并指出了其在寻找近似最优策略时的局限性。接着，提出了一种环境条件——确定性滤波条件，在此条件下，专家蒸馏可以实现样本和计算复杂度均为多项式级的效率。随后，探讨了另一种实用范式——不对称actor-critic，并针对可观察部分可观测马尔科夫决策过程设计了一个信念加权的不对称actor-critic算法，该算法具有多项式级样本复杂度和拟多项式级计算复杂度。其中，还包括了一个新的可证明的关于学习保持滤波稳定性的信念状态的Oracle。最后，文中还研究了在特权信息支持下的部分可观测多智能体强化学习的可证明效率，提出了基于集中训练与分布式执行框架的算法，这些算法在上述两种范式下都具有多项式级样本复杂度和（拟）多项式级计算复杂度。相比于近期相关理论研究，本文更注重于理解实践中启发式的算法范式，而不依赖于计算上不可行的Oracle。 <div>
arXiv:2412.00985v1 Announce Type: new 
Abstract: Partial observability of the underlying states generally presents significant challenges for reinforcement learning (RL). In practice, certain \emph{privileged information}, e.g., the access to states from simulators, has been exploited in training and has achieved prominent empirical successes. To better understand the benefits of privileged information, we revisit and examine several simple and practically used paradigms in this setting. Specifically, we first formalize the empirical paradigm of \emph{expert distillation} (also known as \emph{teacher-student} learning), demonstrating its pitfall in finding near-optimal policies. We then identify a condition of the partially observable environment, the \emph{deterministic filter condition}, under which expert distillation achieves sample and computational complexities that are \emph{both} polynomial. Furthermore, we investigate another useful empirical paradigm of \emph{asymmetric actor-critic}, and focus on the more challenging setting of observable partially observable Markov decision processes. We develop a belief-weighted asymmetric actor-critic algorithm with polynomial sample and quasi-polynomial computational complexities, in which one key component is a new provable oracle for learning belief states that preserve \emph{filter stability} under a misspecified model, which may be of independent interest. Finally, we also investigate the provable efficiency of partially observable multi-agent RL (MARL) with privileged information. We develop algorithms featuring \emph{centralized-training-with-decentralized-execution}, a popular framework in empirical MARL, with polynomial sample and (quasi-)polynomial computational complexities in both paradigms above. Compared with a few recent related theoretical studies, our focus is on understanding practically inspired algorithmic paradigms, without computationally intractable oracles.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair</title>
<link>https://arxiv.org/abs/2412.01072</link>
<guid>https://arxiv.org/abs/2412.01072</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件系统、大型语言模型、自动化程序修复、联邦学习、数据隐私

总结:<br />
本文探讨了随着软件系统快速演进导致的bug增加以及大型语言模型（LLMs）在自动化程序修复（APR）中的应用潜力。然而，现有的公共代码库无法充分反映各行业实际开发实践中的多样性和细节，因此利用私有数据集能有效提升软件开发和维护水平。为解决数据隐私问题，文章研究了联邦学习作为一种保护隐私的方法，允许私有实体在分散且保密的数据上对LLMs进行微调，促进各方协作以充分利用数据资源。实验表明，联邦学习下的微调能够提升程序修复能力，而且不同来源的代码数据对LLM微调的影响不大，意味着各行各业可以无视数据分布差异，从协同开发中获益。此外，各类联邦算法在不同的LLMs优化过程中展现出独特优势，提示我们可以通过针对LLMs特性的定制化优化来进一步增强程序修复的微调效果。 <div>
arXiv:2412.01072v1 Announce Type: new 
Abstract: Software systems have been evolving rapidly and inevitably introducing bugs at an increasing rate, leading to significant losses in resources consumed by software maintenance. Recently, large language models (LLMs) have demonstrated remarkable potential in enhancing software development and maintenance practices, particularly in automated program repair (APR) with improved accuracy and efficiency of bug fixing. However, LLM-based APR heavily relies on high-quality code repositories. A larger portion of existing code repositories are for private use and proprietary assets from various industries, reflecting more diversity and nuances in the data since real-world industries often have more extensive software development practices, which cannot be covered by merely public datasets. Therefore, utilizing private datasets shows significant potential in enhancing software development and maintenance. However, obtaining such data from various industries is hindered by data privacy concerns, as companies are reluctant to share their codebases. To address the gap, we investigate the use of federated learning as a privacy-preserving approach that enables private entities to fine-tune LLMs on proprietary and decentralized data, facilitating the collaboration between clients to fully utilize their data to help enhance software development and maintenance. Our evaluation reveals that federated fine-tuning can effectively enhance program repair capabilities. Notably, the impact of heterogeneous code on LLM fine-tuning is negligible, indicating that real-world industries can benefit from collaborative development regardless of diverse data distributions. Furthermore, each type of federated algorithm exhibits unique strengths across different LLMs, suggesting that fine-tuning for program repair can be enhanced by tailoring the optimization process to specific characteristics of different LLMs.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hierarchical Heuristic for Clustered Steiner Trees in the Plane with Obstacles</title>
<link>https://arxiv.org/abs/2412.01094</link>
<guid>https://arxiv.org/abs/2412.01094</guid>
<content:encoded><![CDATA[
<div> 关键词：Euclidean Steiner树、多根、障碍避免、层次方法、捆绑操作

总结:
本文研究了一种嵌入捆绑操作的层次方法用于计算多个互不相交的欧几里得Steiner树，这些树能够避开平面上的障碍物，这对于建模受限二维空间中去中心化和多点协调的智能体具有重要意义。实验表明，该方法对于计算具有任意障碍配置（包括凸形和非凸形几何形状）的多个避障Steiner树具有可行性及优良性能。本研究结果为避障Steiner树的新运算器设计提供了机制启示。 <div>
arXiv:2412.01094v1 Announce Type: new 
Abstract: Euclidean Steiner trees are relevant to model minimal networks in real-world applications ubiquitously. In this paper, we study the feasibility of a hierarchical approach embedded with bundling operations to compute multiple and mutually disjoint Euclidean Steiner trees that avoid clutter and overlapping with obstacles in the plane, which is significant to model the decentralized and the multipoint coordination of agents in constrained 2D domains. Our computational experiments using arbitrary obstacle configuration with convex and non-convex geometries show the feasibility and the attractive performance when computing multiple obstacle-avoiding Steiner trees in the plane. Our results offer the mechanisms to elucidate new operators for obstacle-avoiding Steiner trees.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lossless and Privacy-Preserving Graph Convolution Network for Federated Item Recommendation</title>
<link>https://arxiv.org/abs/2412.01141</link>
<guid>https://arxiv.org/abs/2412.01141</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络 (GNN), 推荐系统, 隐私保护, 联邦推荐, LP-GCN

总结:
本文提出了一种新的隐私保护图卷积网络——LP-GCN，用于解决基于GNN的推荐系统中的隐私问题。现有的GNN推荐方法依赖于集中式的用户-物品交互子图存储和全局图训练，可能引发隐私关注。针对此问题，一些联邦推荐方法利用分布式和碎片化的用户-物品子图以保护用户隐私，但其图卷积过程不完整，影响推荐性能。LP-GCN创新性地实现了在分布式子图上完整进行图卷积的过程，同时确保了隐私安全，并且其性能与非联邦（即集中式）方案相当。理论分析和实证研究表明，LP-GCN在三个真实数据集上的表现优于现有联邦推荐方法。论文接受后，相关代码将公开发布。 <div>
arXiv:2412.01141v1 Announce Type: new 
Abstract: Graph neural network (GNN) has emerged as a state-of-the-art solution for item recommendation. However, existing GNN-based recommendation methods rely on a centralized storage of fragmented user-item interaction sub-graphs and training on an aggregated global graph, which will lead to privacy concerns. As a response, some recent works develop GNN-based federated recommendation methods by exploiting decentralized and fragmented user-item sub-graphs in order to preserve user privacy. However, due to privacy constraints, the graph convolution process in existing federated recommendation methods is incomplete compared with the centralized counterpart, causing a degradation of the recommendation performance. In this paper, we propose a novel lossless and privacy-preserving graph convolution network (LP-GCN), which fully completes the graph convolution process with decentralized user-item interaction sub-graphs while ensuring privacy. It is worth mentioning that its performance is equivalent to that of the non-federated (i.e., centralized) counterpart. Moreover, we validate its effectiveness through both theoretical analysis and empirical studies. Extensive experiments on three real-world datasets show that our LP-GCN outperforms the existing federated recommendation methods. The code will be publicly available once the paper is accepted.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>INTELLECT-1 Technical Report</title>
<link>https://arxiv.org/abs/2412.01152</link>
<guid>https://arxiv.org/abs/2412.01152</guid>
<content:encoded><![CDATA[
<div> 关键词: INTELLECT-1、PRIME、分布式训练、ElasticDeviceMesh、DiLoCo-FSDP2

总结:
本文介绍了INTELLECT-1，这是全球首个人工智能社区合作训练的拥有100亿参数的语言模型，证明大规模模型训练不再仅限于大型企业，而是可以通过分布式的社区驱动方式实现。INTELLECT-1使用了1万亿个令牌，在跨三大洲的最多14个并发节点上进行训练，共有30家独立计算资源提供商动态加入和退出训练过程，期间保持了83-96%的计算利用率和36.2-41.4%的模型FLOPS利用率。为实现这一目标，研究团队开发了PRIME框架，该框架具有弹性设备网格（ElasticDeviceMesh）、用于互联网和本地节点间容错通信的动态全局进程组以及现场检查点恢复内核等功能。通过结合PRIME、DiLoCo和定制的int8全Reduce技术，他们实现了与传统数据并行训练相比高达400倍的通信带宽降低，同时保证了相当的性能。这些成果显示出利用全球GPU资源的分散网络训练前沿基础模型的可能性和前景。 <div>
arXiv:2412.01152v1 Announce Type: new 
Abstract: In this report, we introduce INTELLECT-1, the first 10 billion parameter language model collaboratively trained across the globe, demonstrating that large-scale model training is no longer confined to large corporations but can be achieved through a distributed, community-driven approach. INTELLECT-1 was trained on 1 trillion tokens using up to 14 concurrent nodes distributed across 3 continents, with contributions from 30 independent compute providers dynamically joining and leaving the training process, while maintaining 83-96% compute utilization and 36.2-41.4% model FLOPS utilization. We leverage PRIME, our scalable distributed training framework designed for fault-tolerant, high-performance training on unreliable, globally distributed nodes. Key innovations in PRIME include the ElasticDeviceMesh, which manages dynamic global process groups for fault-tolerant communication across the internet and local process groups for communication within a node, live checkpoint recovery kernels, and a hybrid DiLoCo-FSDP2 implementation. Using PRIME with DiLoCo and our custom int8 all-reduce, we achieve a 400x reduction in communication bandwidth compared to traditional data-parallel training settings while delivering comparable performance. These results demonstrate the feasibility and promise of training frontier foundation models in a decentralized network of global GPU resources.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid BPMN-DMN Framework for Secure Inter-organizational Processes and Decisions Collaboration on Permissioned Blockchain</title>
<link>https://arxiv.org/abs/2412.01196</link>
<guid>https://arxiv.org/abs/2412.01196</guid>
<content:encoded><![CDATA[
<div> 关键词: BlockCollab、BPMN、DMN、区块链、智能合约<br /><br />总结:
本文提出了一种名为BlockCollab的新型模型驱动框架，该框架针对数字商务领域中跨组织协作的需求，将Business Process Model and Notation（BPMN）与Decision Model and Notation（DMN）相结合，用于标准化并实现在许可型区块链平台上协同业务流程和决策的实施。BlockCollab实现了三个主要创新：1) 提供了一种标准化的方法，使用集成的BPMN-DMN模型来建模协同过程和决策；2) 自动化生成兼容Hyperledger Fabric的智能合约，同时保持过程逻辑和决策规则，并考虑隐私约束；3) 引入了混合式链上/链下执行环境，通过安全数据传输和外部系统集成优化协同工作流程。实验结果表明，该方法在11个真实世界的协作场景中实现100%的执行准确性，并证明了其实用性和可靠性。此外，文中还介绍了一个基于区块链技术的开源第三方协作平台。 <div>
arXiv:2412.01196v1 Announce Type: new 
Abstract: In the rapidly evolving digital business landscape, organizations increasingly need to collaborate across boundaries to achieve complex business objectives, requiring both efficient process coordination and flexible decision-making capabilities. Traditional collaboration approaches face significant challenges in transparency, trust, and decision flexibility, while existing blockchain-based solutions primarily focus on process execution without addressing the integrated decision-making needs of collaborative enterprises. This paper proposes BlockCollab, a novel model-driven framework that seamlessly integrates Business Process Model and Notation (BPMN) with Decision Model and Notation (DMN) to standardize and implement collaborative business processes and decisions on permissioned blockchain platforms. Our approach automatically translates integrated BPMN-DMN models into smart contracts(SCs) compatible with Hyperledger Fabric, enabling privacy-aware multi-organizational process execution through blockchain-based Attribute-Based Access Control (ABAC). The framework introduces three key innovations: (1) a standardized method for modeling collaborative processes and decisions using integrated BPMN-DMN model, (2) an automated SC generator that preserves both process logic and decision rules while maintaining privacy constraints, and (3) a hybrid on-chain/off-chain execution environment that optimizes collaborative workflows through secure data transfer and external system integration. Experimental evaluation across 11 real-world collaboration scenarios demonstrates that our approach achieves 100\% accuracy in process execution. Furthermore, an analysis of various execution processes highlights the strong practical applicability and reliability of our approach. The proposed framework includes an open-source third-party collaboration platform based on blockchain.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>GeoTP: Latency-aware Geo-Distributed Transaction Processing in Database Middlewares (Extended Version)</title>
<link>https://arxiv.org/abs/2412.01213</link>
<guid>https://arxiv.org/abs/2412.01213</guid>
<content:encoded><![CDATA[
<div> 关键词：数据库中间件、分布式事务处理、网络延迟、锁竞争、GeoTP

总结:
<br />
本文提出了GeoTP，一种针对数据库中间件的延迟感知型地理分布事务处理方法，旨在解决分布式事务处理中的性能瓶颈。首先，GeoTP设计了一种去中心化的准备机制，减少了分布式事务所需的网络往返次数。其次，它引入了一个延迟感知调度器，通过策略性地推迟锁获取时间点来最大限度地减少锁竞争持续时间。再者，为调度器提出了启发式优化方法，进一步降低锁竞争持续时间。实验结果显示，在Apache Shardingsphere这一先进的数据库中间件上实现并扩展至Apache ScalarDB后的GeoTP，在YCSB和TPC-C基准测试中，相比于Shardingsphere实现了最高达17.7倍的性能提升。 <div>
arXiv:2412.01213v1 Announce Type: new 
Abstract: The widespread adoption of database middleware for supporting distributed transaction processing is prevalent in numerous applications, with heterogeneous data sources deployed across national and international boundaries. However, transaction processing performance significantly drops due to the high network latency between the middleware and data sources and the long lock contention span, where transactions may be blocked while waiting for the locks held by concurrent transactions. In this paper, we propose GeoTP, a latency-aware geo-distributed transaction processing approach in database middlewares. GeoTP incorporates three key techniques to enhance geo-distributed transaction performance. First, we propose a decentralized prepare mechanism, which diminishes the requirement of network round trips for distributed transactions. Second, we design a latency-aware scheduler to minimize the lock contention span by strategically postponing the lock acquisition time point. Third, heuristic optimizations are proposed for the scheduler to reduce the lock contention span further. We implemented GeoTP on Apache Shardingsphere, a state-of-the-art middleware, and extended it into Apache ScalarDB. Experimental results on YCSB and TPC-C demonstrate that GeoTP achieves up to 17.7x performance improvement over Shardingsphere.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeFi: Concepts and Ecosystem</title>
<link>https://arxiv.org/abs/2412.01357</link>
<guid>https://arxiv.org/abs/2412.01357</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), bibliometric analysis, thematic review, participants, risks

<br />
总结:
该文深入研究了去中心化金融（DeFi）的发展态势，通过文献计量分析揭示了其基础概念、研究趋势和生态系统。文章指出，DeFi研究的关注点从初期的技术创新逐渐转向可持续性、环境影响及监管挑战等问题。研究主题主要集中在去中心化、智能合约、代币化和可持续性关注等方面。同时，文章分析了DeFi生态系统的参与者角色与互动，如开发者、流动性提供者、审计员和监管机构，并指出了关键风险，包括智能合约漏洞、流动性约束以及监管不确定性。研究强调了DeFi在推动金融包容性和透明度方面的变革潜力，但同时也需要强有力的安全框架和监管监督以确保长期稳定性。本文通过对文献计量和主题分析的整合，全面解释了DeFi生态系统，为研究人员、实践者和政策制定者提供了有价值的见解，有助于推进DeFi在全球金融系统中的可持续发展和整合。 <div>
arXiv:2412.01357v1 Announce Type: new 
Abstract: This paper investigates the evolving landscape of decentralized finance (DeFi) by examining its foundational concepts, research trends, and ecosystem. A bibliometric analysis was conducted to identify thematic clusters and track the evolution of DeFi research. Additionally, a thematic review was performed to analyze the roles and interactions of key participants within the DeFi ecosystem, focusing on its opportunities and inherent risks. The bibliometric analysis identified a progression in research priorities, transitioning from an initial focus on technological innovation to addressing sustainability, environmental impacts, and regulatory challenges. Key thematic clusters include decentralization, smart contracts, tokenization, and sustainability concerns. The analysis of participants highlighted the roles of developers, liquidity providers, auditors, and regulators while identifying critical risks such as smart contract vulnerabilities, liquidity constraints, and regulatory uncertainties. The study underlines the transformative potential of DeFi to enhance financial inclusion and transparency while emphasizing the need for robust security frameworks and regulatory oversight to ensure long-term stability. This paper comprehensively explains the DeFi ecosystem by integrating bibliometric and thematic analyses. It offers valuable insights for researchers, practitioners, and policymakers, contributing to the ongoing discourse on the sustainable development and integration of DeFi into the global financial system.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Future of Document Verification: Leveraging Blockchain and Self-Sovereign Identity for Enhanced Security and Transparency</title>
<link>https://arxiv.org/abs/2412.01531</link>
<guid>https://arxiv.org/abs/2412.01531</guid>
<content:encoded><![CDATA[
<div> 关键词：文档认证、区块链、自我主权身份、去中心化技术、COVID-19疫情

<br />
总结:
文章提出了一种利用区块链和自我主权身份等去中心化技术改进文档认证的新策略。当前传统文档认证流程存在耗时长、伪证流通以及数据隐私问题，特别是在COVID-19疫情期间，物理出席要求导致了认证过程的显著延误，且缺乏实时跟踪功能。该新策略旨在克服这些难题，构建一个高效、安全且用户友好的认证生态系统。 <div>
arXiv:2412.01531v1 Announce Type: new 
Abstract: Attestation of documents like legal papers, professional qualifications, medical records, and commercial documents is crucial in global transactions, ensuring their authenticity, integrity, and trustworthiness. Companies expanding operations internationally need to submit attested financial statements and incorporation documents to foreign governments or business partners to prove their businesses and operations' authenticity, legal validity, and regulatory compliance. Attestation also plays a critical role in education, overseas employment, and authentication of legal documents such as testaments and medical records. The traditional attestation process is plagued by several challenges, including time-consuming procedures, the circulation of counterfeit documents, and concerns over data privacy in the attested records. The COVID-19 pandemic brought into light another challenge: ensuring physical presence for attestation, which caused a significant delay in the attestation process. Traditional methods also lack real-time tracking capabilities for attesting entities and requesters. This paper aims to propose a new strategy using decentralized technologies such as blockchain and self-sovereign identity to overcome the identified hurdles and provide an efficient, secure, and user-friendly attestation ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Contract Vulnerabilities, Tools, and Benchmarks: An Updated Systematic Literature Review</title>
<link>https://arxiv.org/abs/2412.01719</link>
<guid>https://arxiv.org/abs/2412.01719</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、以太坊、安全漏洞、自动化检测工具、基准评价

<br />
总结:
本文是一篇关于以太坊智能合约安全漏洞的系统性文献综述，重点关注了自动化检测工具及其基准评估。研究团队从五个数字图书馆和五个主要软件工程会议中筛选了1,888份研究，最终选取了131篇高质量论文进行分析。文章构建了一个由101种智能合约漏洞组成的十级分类体系；列出了144款具有相应功能、方法及代码转换技术的智能合约检测工具；并汇总了用于工具评估的102个基准。通过对现有研究的深入剖析，文中对以太坊智能合约安全性现状进行了总结，并指出了未来研究的方向。 <div>
arXiv:2412.01719v1 Announce Type: new 
Abstract: Smart contracts are self-executing programs on blockchain platforms like Ethereum, which have revolutionized decentralized finance by enabling trustless transactions and the operation of decentralized applications. Despite their potential, the security of smart contracts remains a critical concern due to their immutability and transparency, which expose them to malicious actors. The connections of contracts further complicate vulnerability detection. This paper presents a systematic literature review that explores vulnerabilities in Ethereum smart contracts, focusing on automated detection tools and benchmark evaluation. We reviewed 1,888 studies from five digital libraries and five major software engineering conferences, applying a structured selection process that resulted in 131 high-quality studies. The key results include a hierarchical taxonomy of 101 vulnerabilities grouped into ten categories, a comprehensive list of 144 detection tools with corresponding functionalities, methods, and code transformation techniques, and a collection of 102 benchmarks used for tool evaluation. We conclude with insights on the current state of Ethereum smart contract security and directions for future research.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining Blockchain and Biometrics: A Survey on Technical Aspects and a First Legal Analysis</title>
<link>https://arxiv.org/abs/2302.10883</link>
<guid>https://arxiv.org/abs/2302.10883</guid>
<content:encoded><![CDATA[
<div> 关键词: 生物识别、区块链、集成、法律分析、挑战与潜力

<br /><br />总结:
本文是对生物识别技术和区块链技术融合应用的学术文献调研，探讨了二者的结合在身份验证、分布式信任服务和身份管理等领域的潜在优势。文章指出，虽然目前这种组合在实际实时应用中还面临区块链效率和经济性不足的问题，但其对于推动生物识别领域创新具有积极意义。从法律角度来看，责任分配问题成为主要挑战，同时进行适当的数据保护影响评估也存在困难。最后，该研究提出了针对这一组合的技术和法律建议，旨在帮助充分利用其优点并降低风险。 <div>
arXiv:2302.10883v2 Announce Type: replace 
Abstract: Biometric recognition as a unique, hard-to-forge, and efficient way of identification and verification has become an indispensable part of the current digital world. The fast evolution of this technology has been a strong incentive for integrating it into many applications. Meanwhile, blockchain, the very attractive decentralized ledger technology, has been widely received both by the research and industry in the past years and it is being increasingly deployed nowadays in many different applications, such as money transfer, IoT, healthcare, or logistics. Recently, researchers have started to speculate what would be the pros and cons and what would be the best applications when these two technologies cross paths. This paper provides a survey of technical literature research on the combination of blockchain and biometrics and includes a first legal analysis of this integration to shed light on challenges and potentials. While this combination is still in its infancy and a growing body of literature discusses specific blockchain applications and solutions in an advanced technological set-up, this paper presents a holistic understanding of blockchains applicability in the biometric sector. This study demonstrates that combining blockchain and biometrics would be beneficial for novel applications in biometrics such as the PKI mechanism, distributed trusted service, and identity management. However, blockchain networks at their current stage are not efficient and economical for real-time applications. From a legal point of view, the allocation of accountability remains a main issue, while other difficulties remain, such as conducting a proper Data Protection Impact Assessment. Finally, it supplies technical and legal recommendations to reap the benefits and mitigate the risks of the combination.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Estimating Continuous Muscle Fatigue For Multi-Muscle Coordinated Exercise: A Pilot Study on Walking</title>
<link>https://arxiv.org/abs/2303.17614</link>
<guid>https://arxiv.org/abs/2303.17614</guid>
<content:encoded><![CDATA[
<div> 关键词：肌肉疲劳评估、多肌协调、神经肌肉特征、贝叶斯高斯过程、生理学原理模型

<br /><br />总结：
本文提出了一种用于评估日常锻炼中肌肉疲劳进展的方法。首先，通过肌肉协同作用分数化和脊髓模块放电变异性等特征，结合疲劳诱导的神经肌肉适应性理论来描绘肌肉疲劳。其次，利用贝叶斯高斯过程建立模型，以捕捉疲劳随时间演变的进程。为解决缺乏监督信息的问题，文中将疲劳的时间演化特性数学化作为损失函数。最后，依据肌肉疲劳的生理学原则制定量化评价指标。实验结果显示，该方法在不同天之间的相似度达到0.99，与其他疲劳观点的相似度超过0.7，并具有接近1的弱单调性，性能优于其他方法。这项研究旨在实现肌肉疲劳的客观评估。 <div>
arXiv:2303.17614v2 Announce Type: replace 
Abstract: Assessing the progression of muscle fatigue for daily exercises provides vital indicators for precise rehabilitation, personalized training dose, especially under the context of Metaverse. Assessing fatigue of multi-muscle coordination-involved daily exercises requires the neuromuscular features that represent the fatigue-induced characteristics of spatiotemporal adaptions of multiple muscles and the estimator that captures the time-evolving progression of fatigue. In this paper, we propose to depict fatigue by the features of muscle compensation and spinal module activation changes and estimate continuous fatigue by a physiological rationale model. First, we extract muscle synergy fractionation and the variance of spinal module spikings as features inspired by the prior of fatigue-induced neuromuscular adaptations. Second, we treat the features as observations and develop a Bayesian Gaussian process to capture the time-evolving progression. Third, we solve the issue of lacking supervision information by mathematically formulating the time-evolving characteristics of fatigue as the loss function. Finally, we adapt the metrics that follow the physiological principles of fatigue to quantitatively evaluate the performance. Our extensive experiments present a 0.99 similarity between days, a over 0.7 similarity with other views of fatigue and a nearly 1 weak monotonicity, which outperform other methods. This study would aim the objective assessment of muscle fatigue.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>No-Regret Learning and Equilibrium Computation in Quantum Games</title>
<link>https://arxiv.org/abs/2310.08473</link>
<guid>https://arxiv.org/abs/2310.08473</guid>
<content:encoded><![CDATA[
<div> 关键词：量子处理器、分布式系统、无遗憾算法、量子纳什均衡、分离型量子粗相关均衡

总结:
本文探讨了随着量子处理器的发展，涉及互动量子代理的大规模分布式系统的出现。研究重点在于无遗憾算法在量子环境中如何驱动多智能体在时间上更新其行为。对于双人量子零和游戏与多玩家量子聚合零和游戏，文章证明无遗憾算法会收敛到时间平均下的可分离量子纳什均衡。针对更一般的多玩家量子游戏情况，文中引入了一个新概念——分离型量子粗相关均衡（QCCE），这是无遗憾学习算法行为时间平均收敛的结果，为分布式量子系统提供了一种自然的解决方案。此外，论文还表明计算QCCE可以形式化为半正定规划问题，并确立了存在纠缠（即非可分离）的QCCE，这类均衡无法通过当前的无遗憾学习范式得到学习。<br /><br /> <div>
arXiv:2310.08473v3 Announce Type: replace 
Abstract: As quantum processors advance, the emergence of large-scale decentralized systems involving interacting quantum-enabled agents is on the horizon. Recent research efforts have explored quantum versions of Nash and correlated equilibria as solution concepts of strategic quantum interactions, but these approaches did not directly connect to decentralized adaptive setups where agents possess limited information. This paper delves into the dynamics of quantum-enabled agents within decentralized systems that employ no-regret algorithms to update their behaviors over time. Specifically, we investigate two-player quantum zero-sum games and polymatrix quantum zero-sum games, showing that no-regret algorithms converge to separable quantum Nash equilibria in time-average. In the case of general multi-player quantum games, our work leads to a novel solution concept, that of the {separable} quantum coarse correlated equilibria (QCCE), as the convergent outcome of the time-averaged behavior no-regret algorithms, offering a natural solution concept for decentralized quantum systems. Finally, we show that computing QCCEs can be formulated as a semidefinite program and establish the existence of entangled (i.e., non-separable) QCCEs, which are unlearnable via the current paradigm of no-regret learning.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MASP: Scalable GNN-based Planning for Multi-Agent Navigation</title>
<link>https://arxiv.org/abs/2312.02522</link>
<guid>https://arxiv.org/abs/2312.02522</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体导航、强化学习、规划方法、层次化规划、图模型

总结:<br />
本文提出了一个名为Multi-Agent Scalable Graph-based Planner (MASP)的新型层次化规划器，用于解决具有大量智能体的分布式环境中的多目标导航任务。MASP采用层次框架降低探索空间复杂度，通过将大空间分解为多个目标条件子空间来实现。它利用图模型来更好地捕捉智能体和目标之间的关系，以促进合作并适应团队规模的变化。具体而言，MASP包括两个部分：高层面的Goal Matcher使用基于图的自编码器和交叉编码器优化目标分配；低层面的Coordinated Action Executor引入了Group Information Fusion技术，有助于小组划分并提取跨组的智能体间关系，从而提高训练效率并增强智能体的合作能力。实验结果显示，MASP在任务效率方面优于强化学习和基于规划的方法基线。 <div>
arXiv:2312.02522v2 Announce Type: replace 
Abstract: We investigate multi-agent navigation tasks, where multiple agents need to reach initially unassigned goals in a limited time. Classical planning-based methods suffer from expensive computation overhead at each step and offer limited expressiveness for complex cooperation strategies. In contrast, reinforcement learning (RL) has recently become a popular approach for addressing this issue. However, RL struggles with low data efficiency and cooperation when directly exploring (nearly) optimal policies in a large exploration space, especially with an increased number of agents(e.g., 10+ agents) or in complex environments (e.g., 3-D simulators). In this paper, we propose the Multi-Agent Scalable Graph-based Planner (MASP), a goal-conditioned hierarchical planner for navigation tasks with a substantial number of agents in the decentralized setting. MASP employs a hierarchical framework to reduce space complexity by decomposing a large exploration space into multiple goal-conditioned subspaces, where a high-level policy assigns agents goals, and a low-level policy navigates agents toward designated goals. For agent cooperation and the adaptation to varying team sizes, we model agents and goals as graphs to better capture their relationship. The high-level policy, the Goal Matcher, leverages a graph-based Self-Encoder and Cross-Encoder to optimize goal assignment by updating the agent and the goal graphs. The low-level policy, the Coordinated Action Executor, introduces the Group Information Fusion to facilitate group division and extract agent relationships across groups, enhancing training efficiency for agent cooperation. The results demonstrate that MASP outperforms RL and planning-based baselines in task efficiency.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Global and Local Error-Tolerant Decentralized State Estimation under Partially Ordered Observations</title>
<link>https://arxiv.org/abs/2401.09110</link>
<guid>https://arxiv.org/abs/2401.09110</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized state estimation、discrete event system、malicious attacker、global errors、local errors

总结:
本文研究了在存在恶意攻击者可能篡改或破坏信息的情况下，离散事件系统的分布式状态估计问题。系统由一组局部观测站点（OSs）观察，并定期向协调器发送其记录的观测序列以进行状态估计。文中将错误分为两种类型：全局错误和局部错误，前者指所有OSs记录相同的错误，后者则指不同OSs记录不同的错误。针对每种类型的错误，文章提出了两种有效执行状态估计的方法，一种基于修改原系统，另一种基于推断原系统的匹配行为。对于每种方法，采用估算释放策略设计相应的同步器算法来进行状态估计。 <div>
arXiv:2401.09110v2 Announce Type: replace 
Abstract: We investigate decentralized state estimation for a discrete event system in a setting where the information received at a coordinator may be corrupted or tampered by a malicious attacker. Specifically, a system is observed by a set of (local) observation sites (OSs) which occasionally send their recorded sequences of observations to the coordinator that is in charge of estimating the system state. The malfunctions and attacks, referred to as errors in this paper, include symbol deletions, insertions and replacements, each of which bears a positive cost. Two types of errors, global errors and local errors, are proposed to describe the impact of errors on decentralized information processing. Global errors occur when all OSs record the same error, while local errors occur when different OSs record different errors. Distinguishing these types of errors is important for a proper design of decentralized information processing (so as to be more resilient and better equipped to handle attacks and failures). For each type of error, we propose two methods to efficiently perform state estimation: one based on appropriately modifying the original system and the other based on inferring the matching behavior of the original system. For each method, we adopt an estimation-by-release methodology to design an algorithm for constructing a corresponding synchronizer for state estimation.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RO-SVD: A Reconfigurable Hardware Copyright Protection Framework for AIGC Applications</title>
<link>https://arxiv.org/abs/2406.11536</link>
<guid>https://arxiv.org/abs/2406.11536</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式人工智能 (GenAI)，区块链，版权可追溯性框架，环形振荡器-奇异值分解 (RO-SVD)，现场可编程门阵列 (FPGA)

总结:

本文提出了一种基于区块链的版权可追溯性框架RO-SVD，该框架利用硬件熵源产生的低秩矩阵的分解计算，旨在解决生成式人工智能（GenAI）产生的多维度数据的安全管理和使用问题。通过结合现场可编程门阵列（FPGA）的并行性和可重构性，该框架能够在现有AI加速设备上低成本构建，针对AI生成内容（AIGC）的版权问题提供解决方案。研究团队开发了一个软硬件协同设计原型，并在多种适用于AI的FPGA上进行了实船试验和分析，以AI生成图像为例展示了该框架的有效性、定制化、不可预测性、效率以及可管理性和可重构性。据作者所知，这是首次针对AI生成内容具体实施版权可追溯性的硬件研究报告。 <div>
arXiv:2406.11536v2 Announce Type: replace 
Abstract: The dramatic surge in the utilisation of generative artificial intelligence (GenAI) underscores the need for a secure and efficient mechanism to responsibly manage, use and disseminate multi-dimensional data generated by artificial intelligence (AI). In this paper, we propose a blockchain-based copyright traceability framework called ring oscillator-singular value decomposition (RO-SVD), which introduces decomposition computing to approximate low-rank matrices generated from hardware entropy sources and establishes an AI-generated content (AIGC) copyright traceability mechanism at the device level. By leveraging the parallelism and reconfigurability of field-programmable gate arrays (FPGAs), our framework can be easily constructed on existing AI-accelerated devices and provide a low-cost solution to emerging copyright issues of AIGC. We developed a hardware-software (HW/SW) co-design prototype based on comprehensive analysis and on-board experiments with multiple AI-applicable FPGAs. Using AI-generated images as a case study, our framework demonstrated effectiveness and emphasised customisation, unpredictability, efficiency, management and reconfigurability. To the best of our knowledge, this is the first practical hardware study discussing and implementing copyright traceability specifically for AI-generated content.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2406.17249</link>
<guid>https://arxiv.org/abs/2406.17249</guid>
<content:encoded><![CDATA[
<div> 关键词：实时、分布式、多机器人、语义SLAM、环境映射

总结:
本文提出了一种实时分布式语义SLAM算法框架，适用于异构机器人团队在无GPS条件下共同构建基于对象的三维环境地图，包括室内、城市和森林场景。该框架集成了数据驱动的前端，用于从RGBD相机或LiDAR进行实例分割，并采用定制后端优化机器人轨迹和地图中的物体地标。为实现多个机器人信息融合，设计了基于语义的场景识别算法，利用对象级别的语义地图的信息丰富度和视角不变性进行机器人间的环闭检测。同时设计了一个通信模块来跟踪各机器人的观测数据以及在通信链路可用时其他机器人的观测数据。该框架支持机器人实时分布式运行，使它们能够灵活利用通信资源。文章将提出的框架与多种空中和地面机器人的自主导航及探索系统整合，并在各种室内外环境中进行了大量实验，验证了其在机器人间定位和物体映射准确性方面的表现，同时展现了对计算、存储和通信资源的需求适度。该框架已开源并作为模块化堆栈发布，适用于单 agent 和多机器人场景的对象级语义SLAM应用。项目网站和代码分别可在https://xurobotics.github.io/slideslam/ 和 https://github.com/XuRobotics/SLIDE_SLAM 找到。 <div>
arXiv:2406.17249v4 Announce Type: replace 
Abstract: This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) algorithm framework that enables a heterogeneous robot team to collaboratively construct object-based metric-semantic maps of 3D environments featuring indoor, urban, and forests without relying on GPS. The framework integrates a data-driven front-end for instance segmentation from either RGBD cameras or LiDARs and a custom back-end for optimizing robot trajectories and object landmarks in the map. To allow multiple robots to merge their information, we design semantics-driven place recognition algorithms that leverage the informativeness and viewpoint invariance of the object-level metric-semantic map for inter-robot loop closure detection. A communication module is designed to track each robot's observations and those of other robots whenever communication links are available. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate the proposed framework with the autonomous navigation and exploration systems of three types of aerial and ground robots, conducting extensive experiments in a variety of indoor and outdoor environments. These experiments demonstrate accuracy in inter-robot localization and object mapping, along with its moderate demands on computation, storage, and communication resources. The framework is open-sourced and available as a modular stack for object-level metric-semantic SLAM, suitable for both single-agent and multi-robot scenarios. The project website and code can be found at https://xurobotics.github.io/slideslam/ and https://github.com/XuRobotics/SLIDE_SLAM, respectively.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Know Your Account: Double Graph Inference-based Account De-anonymization on Ethereum</title>
<link>https://arxiv.org/abs/2411.18875</link>
<guid>https://arxiv.org/abs/2411.18875</guid>
<content:encoded><![CDATA[
<div> 关键词：Web 3.0, 区块链, 以太坊, 双重图, 账户匿名化推理

<br /><br />总结:
本文提出了一种名为DBG4ETH的新型双重图基以太坊账户去匿名化推理方法，旨在全面捕获账户的行为模式并增强对当前复杂、持续生成的交易行为的分析和判断能力。该方法首先构建了一个全局静态图，用于建立所有交易数据中各类账户节点间的复杂交互关系；随后，又构建了局部动态图来学习不同时间段内交易的逐渐演变过程。两种图从不同视角聚焦信息，通过DBG4ETH可以获取全球与局部、静态与动态交易图的特征。此外，文中还提出了自适应置信度校准方法，将校准后的加权预测值输入分类器以进行预测结果的预测。实验结果显示，DBG4ETH在账户识别任务上达到了最先进的结果，相比于分别处理每种图类型，其F1分数提高了至少3.75%，最高可达40.52%，并且相比类似的账户身份推断方法，性能提升了5.23%至12.91%。 <div>
arXiv:2411.18875v1 Announce Type: new 
Abstract: The scaled Web 3.0 digital economy, represented by decentralized finance (DeFi), has sparked increasing interest in the past few years, which usually relies on blockchain for token transfer and diverse transaction logic. However, illegal behaviors, such as financial fraud, hacker attacks, and money laundering, are rampant in the blockchain ecosystem and seriously threaten its integrity and security. In this paper, we propose a novel double graph-based Ethereum account de-anonymization inference method, dubbed DBG4ETH, which aims to capture the behavioral patterns of accounts comprehensively and has more robust analytical and judgment capabilities for current complex and continuously generated transaction behaviors. Specifically, we first construct a global static graph to build complex interactions between the various account nodes for all transaction data. Then, we also construct a local dynamic graph to learn about the gradual evolution of transactions over different periods. Different graphs focus on information from different perspectives, and features of global and local, static and dynamic transaction graphs are available through DBG4ETH. In addition, we propose an adaptive confidence calibration method to predict the results by feeding the calibrated weighted prediction values into the classifier. Experimental results show that DBG4ETH achieves state-of-the-art results in the account identification task, improving the F1-score by at least 3.75% and up to 40.52% compared to processing each graph type individually and outperforming similar account identity inference methods by 5.23% to 12.91%.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Swarm Intelligence-Driven Client Selection for Federated Learning in Cybersecurity applications</title>
<link>https://arxiv.org/abs/2411.18877</link>
<guid>https://arxiv.org/abs/2411.18877</guid>
<content:encoded><![CDATA[
<div> 关键词: Swarm Intelligence Optimization, Federated Learning, Cybersecurity, Grey Wolf Optimization, Particle Swarm Optimization

总结:<br />
本文针对 Swarm Intelligence Optimization（群智优化）算法在联邦学习（Federated Learning, FL）中的客户端选择应用展开研究，特别是在网络安全领域的应用。当前研究主要关注集中式机器学习的优化技术，而对FL中客户端多样性、非独立同分布数据以及敌对噪音等独特挑战的关注不足。为此，文章评估了九种群智优化算法，包括Grey Wolf Optimization（灰狼优化）、Particle Swarm Optimization（粒子群优化）、Cuckoo Search等在四种实验场景下的表现：固定客户端参与、动态参与模式、异质非独立同分布数据以及对抗性噪声条件。结果显示，GWO展现出优异的适应性和鲁棒性，在所有配置下均取得了最高的准确率、召回率和F1分数；同时，PSO和Cuckoo Search也表现出色。这些发现强调了群智优化算法在解决分布式和对抗性FL问题上的潜力，为网络安全应用，如IoT和大规模网络入侵检测，提供了可扩展和韧性强的解决方案。 <div>
arXiv:2411.18877v1 Announce Type: new 
Abstract: This study addresses a critical gap in the literature regarding the use of Swarm Intelligence Optimization (SI) algorithms for client selection in Federated Learning (FL), with a focus on cybersecurity applications. Existing research primarily explores optimization techniques for centralized machine learning, leaving the unique challenges of client diveristy, non-IID data distributions, and adversarial noise in decentralized FL largely unexamined. To bridge this gap, we evaluate nine SI algorithms-Grey Wolf Optimization (GWO), Particle Swarm Optimization (PSO), Cuckoo Search, Bat Algorithm, Bee Colony, Ant Colony Optimization, Fish Swarm, Glow Worm, and Intelligent Water Droplet-across four experimental scenarios: fixed client participation, dynamic participation patterns, hetergeneous non-IID data distributions, and adversarial noise conditions. Results indicate that GWO exhibits superior adaptability and robustness, achieving the highest accuracy, recall and F1-scoress across all configurations, while PSO and Cuckoo Search also demonstrate strong performance. These findings underscore the potential of SI algorithms to address decentralized and adversarial FL challenges, offereing scalable and resilient solutions for cybersecurity applications, including intrusion detection in IoT and large-scale networks.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Continual Graph Learning</title>
<link>https://arxiv.org/abs/2411.18919</link>
<guid>https://arxiv.org/abs/2411.18919</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦持续图学习（FCGL）、图神经网络（GNNs）、局部图遗忘（LGF）、全局专家冲突（GEC）、POWER框架

总结:<br />
本文针对大数据时代下不断演进的图数据管理所面临的存储成本和隐私问题，提出了联邦持续图学习（FCGL）这一全新研究方向。FCGL旨在适应多个分布式环境中的变化图数据，同时解决存储和隐私约束下的性能优化问题。文章通过实证分析揭示了FCGL在实现过程中面临的两大挑战：局部图遗忘（LGF）与全局专家冲突（GEC）。为了解决这些问题，作者提出了名为POWER的框架，该框架通过保存并回放具有最大局部-全局覆盖范围的经验节点来缓解LGF，同时采用伪原型重建策略和轨迹感知的知识转移方法在中央服务器端解决GEC。实验结果表明，POWER在多个图数据集上的表现优于现有的中心化CGL算法的联邦扩展版本以及视觉焦点的联邦持续学习算法。相关代码已开源，可在https://github.com/zyl24/FCGL_POWER获取。 <div>
arXiv:2411.18919v1 Announce Type: new 
Abstract: In the era of big data, managing evolving graph data poses substantial challenges due to storage costs and privacy issues. Training graph neural networks (GNNs) on such evolving data usually causes catastrophic forgetting, impairing performance on earlier tasks. Despite existing continual graph learning (CGL) methods mitigating this to some extent, they predominantly operate in centralized architectures and overlook the potential of distributed graph databases to harness collective intelligence for enhanced performance optimization. To address these challenges, we present a pioneering study on Federated Continual Graph Learning (FCGL), which adapts GNNs to multiple evolving graphs within decentralized settings while adhering to storage and privacy constraints. Our work begins with a comprehensive empirical analysis of FCGL, assessing its data characteristics, feasibility, and effectiveness, and reveals two principal challenges: local graph forgetting (LGF), where local GNNs forget prior knowledge when adapting to new tasks, and global expertise conflict (GEC), where the global GNN exhibits sub-optimal performance in both adapting to new tasks and retaining old ones, arising from inconsistent client expertise during server-side parameter aggregation. To tackle these, we propose the POWER framework, which mitigates LGF by preserving and replaying experience nodes with maximum local-global coverage at each client and addresses GEC by using a pseudo prototype reconstruction strategy and trajectory-aware knowledge transfer at the central server. Extensive evaluations across multiple graph datasets demonstrate POWER's superior performance over straightforward federated extensions of the centralized CGL algorithms and vision-focused federated continual learning algorithms. Our code is available at https://github.com/zyl24/FCGL_POWER.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Guardians of the Ledger: Protecting Decentralized Exchanges from State Derailment Defects</title>
<link>https://arxiv.org/abs/2411.18935</link>
<guid>https://arxiv.org/abs/2411.18935</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化交易所(DEX)，智能合约，状态脱轨缺陷，StateGuard，深度学习

总结:<br />
本文首次对去中心化交易所(DEX)中的状态脱轨缺陷进行了系统性研究，定义了五类状态脱轨缺陷并进行详细分析。为了解决这一问题，文中提出了一种名为StateGuard的新型深度学习框架，用于检测DEX智能合约中的状态脱轨缺陷。该框架利用智能合约拆解器将合约转化为抽象语法树(AST)，从中提取出五类依赖特征；接着，通过图优化器处理结构化数据；最后，使用图卷积网络(GCNs)对优化后的数据进行分析，以识别潜在的状态脱轨缺陷。在包含46个DEX项目和5,671个智能合约的数据集上评估后，StateGuard达到了94.25%的F1得分，并在与现有最优方法的对比实验中提升了6.29%的F1得分。为了验证其实用性，StateGuard还被应用于审计真实世界的合同并成功发现了多个新的CVE漏洞。 <div>
arXiv:2411.18935v1 Announce Type: new 
Abstract: The decentralized exchange (DEX) leverages smart contracts to trade digital assets for users on the blockchain. Developers usually develop several smart contracts into one project, implementing complex logic functions and multiple transaction operations. However, the interaction among these contracts poses challenges for developers analyzing the state logic. Due to the complex state logic in DEX projects, many critical state derailment defects have emerged in recent years. In this paper, we conduct the first systematic study of state derailment defects in DEX. We define five categories of state derailment defects and provide detailed analyses of them. Furthermore, we propose a novel deep learning-based framework StateGuard for detecting state derailment defects in DEX smart contracts. It leverages a smart contract deconstructor to deconstruct the contract into an Abstract Syntax Tree (AST), from which five categories of dependency features are extracted. Next, it implements a graph optimizer to process the structured data. At last, the optimized data is analyzed by Graph Convolutional Networks (GCNs) to identify potential state derailment defects. We evaluated StateGuard through a dataset of 46 DEX projects containing 5,671 smart contracts, and it achieved 94.25% F1-score. In addition, in a comparison experiment with state-of-the-art, StateGuard leads the F1-score by 6.29%. To further verify its practicality, we used StateGuar to audit real-world contracts and successfully authenticated multiple novel CVEs.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Game-Theoretic Approach to the Study of Blockchain's Robustness</title>
<link>https://arxiv.org/abs/2411.19175</link>
<guid>https://arxiv.org/abs/2411.19175</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、以太坊权益证明、安全性、活性、激励机制

总结:
<br />
本文针对近年来备受关注的区块链技术，尤其是以太坊权益证明（PoS）协议的鲁棒性进行了深入研究。首先，从分布式系统角度对Ethereum PoS协议进行形式化定义，并通过这一视角发现潜在的安全性和活性方面的漏洞。其次，分析了维持系统活性的关键机制——不活动泄露机制，但指出其可能导致牺牲安全性的风险。最后，运用博弈论模型探讨了理性验证者在Ethereum PoS中的策略选择，揭示了他们在何种条件下可能偏离预设协议以最大化收益。这些研究成果强调了激励机制对于区块链鲁棒性的重要性，并为设计更为健壮的区块链协议提供了洞见。 <div>
arXiv:2411.19175v1 Announce Type: new 
Abstract: Blockchains have sparked global interest in recent years, gaining importance as they increasingly influence technology and finance. This thesis investigates the robustness of blockchain protocols, specifically focusing on Ethereum Proof-of-Stake. We define robustness in terms of two critical properties: Safety, which ensures that the blockchain will not have permanent conflicting blocks, and Liveness, which guarantees the continuous addition of new reliable blocks.
  Our research addresses the gap between traditional distributed systems approaches, which classify agents as either honest or Byzantine (i.e., malicious or faulty), and game-theoretic models that consider rational agents driven by incentives. We explore how incentives impact the robustness with both approaches.
  The thesis comprises three distinct analyses. First, we formalize the Ethereum PoS protocol, defining its properties and examining potential vulnerabilities through a distributed systems perspective. We identify that certain attacks can undermine the system's robustness. Second, we analyze the inactivity leak mechanism, a critical feature of Ethereum PoS, highlighting its role in maintaining system liveness during network disruptions but at the cost of safety. Finally, we employ game-theoretic models to study the strategies of rational validators within Ethereum PoS, identifying conditions under which these agents might deviate from the prescribed protocol to maximize their rewards.
  Our findings contribute to a deeper understanding of the importance of incentive mechanisms for blockchain robustness and provide insights into designing more resilient blockchain protocols.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartLLMSentry: A Comprehensive LLM Based Smart Contract Vulnerability Detection Framework</title>
<link>https://arxiv.org/abs/2411.19234</link>
<guid>https://arxiv.org/abs/2411.19234</guid>
<content:encoded><![CDATA[
<div> 关键词: SmartLLMSentry、智能合约、区块链、大型语言模型、ChatGPT

总结:
本文介绍了SmartLLMSentry，这是一个利用大型语言模型（特别是ChatGPT和上下文训练）进行智能合约漏洞检测的新框架。与传统的基于规则的方法相比，SmartLLMSentry通过LLM有效地改进了新检测规则的集成过程。研究团队创建了一个专门针对五种随机选择的漏洞的训练和评估数据集，结果显示，在充分的数据支持下，该模型具有高达91.1%的精确匹配准确率。然而，实验发现GPT-4在规则生成方面的性能不如GPT-3。这项研究表明，SmartLLMSentry通过LLM驱动的规则整合显著提升了漏洞检测的速度和准确性，为提升区块链安全性和解决智能合约中以前未被充分探索的漏洞提供了一种新的方法。 <div>
arXiv:2411.19234v1 Announce Type: new 
Abstract: Smart contracts are essential for managing digital assets in blockchain networks, highlighting the need for effective security measures. This paper introduces SmartLLMSentry, a novel framework that leverages large language models (LLMs), specifically ChatGPT with in-context training, to advance smart contract vulnerability detection. Traditional rule-based frameworks have limitations in integrating new detection rules efficiently. In contrast, SmartLLMSentry utilizes LLMs to streamline this process. We created a specialized dataset of five randomly selected vulnerabilities for model training and evaluation. Our results show an exact match accuracy of 91.1% with sufficient data, although GPT-4 demonstrated reduced performance compared to GPT-3 in rule generation. This study illustrates that SmartLLMSentry significantly enhances the speed and accuracy of vulnerability detection through LLMdriven rule integration, offering a new approach to improving Blockchain security and addressing previously underexplored vulnerabilities in smart contracts.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning</title>
<link>https://arxiv.org/abs/2411.19335</link>
<guid>https://arxiv.org/abs/2411.19335</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, PEFT, 信息安全, 攻击向量, 防御策略

总结:
<br />
本文探讨了联邦学习中参数高效微调（FedPEFT）的新安全威胁。FedPEFT是一种用于保护隐私和提高预训练语言模型在分布式环境下的适应效率的方法。然而，文章提出了一种名为PEFT-as-an-Attack (PaaA) 的新攻击手段，该攻击利用PEFT方法如LoRA，即使在少量参数可训练及仅少数客户端恶意操作的情况下，也能绕过PLM的安全对齐，生成有害内容。实验显示，此攻击的成功率约为80%。为应对这一威胁，文章研究了包括鲁棒聚合方案（RASs）和后PEFT安全对齐（PPSA）在内的防御策略，但发现现有防御措施在处理高度异构数据分布情况时存在局限性，如DnC和ClippedClustering等先进RASs防御效果不佳；而PPSA虽能降低攻击成功率至10%以下，却会显著损害模型在目标任务上的准确性。因此，文章强调了急需开发更有效的防御机制以同时确保安全性并保持FedPEFT范式的性能。 <div>
arXiv:2411.19335v1 Announce Type: new 
Abstract: Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising paradigm for privacy-preserving and efficient adaptation of Pre-trained Language Models (PLMs) in Federated Learning (FL) settings. It preserves data privacy by keeping the data decentralized and training the model on local devices, ensuring that raw data never leaves the user's device. Moreover, the integration of PEFT methods such as LoRA significantly reduces the number of trainable parameters compared to fine-tuning the entire model, thereby minimizing communication costs and computational overhead. Despite its potential, the security implications of FedPEFT remain underexplored. This paper introduces a novel security threat to FedPEFT, termed PEFT-as-an-Attack (PaaA), which exposes how PEFT can be exploited as an attack vector to circumvent PLMs' safety alignment and generate harmful content in response to malicious prompts. Our evaluation of PaaA reveals that with less than 1% of the model's parameters set as trainable, and a small subset of clients acting maliciously, the attack achieves an approximate 80% attack success rate using representative PEFT methods such as LoRA. To mitigate this threat, we further investigate potential defense strategies, including Robust Aggregation Schemes (RASs) and Post-PEFT Safety Alignment (PPSA). However, our empirical analysis highlights the limitations of these defenses, i.e., even the most advanced RASs, such as DnC and ClippedClustering, struggle to defend against PaaA in scenarios with highly heterogeneous data distributions. Similarly, while PPSA can reduce attack success rates to below 10%, it severely degrades the model's accuracy on the target task. Our results underscore the urgent need for more effective defense mechanisms that simultaneously ensure security and maintain the performance of the FedPEFT paradigm.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Transit Signal Priority into Multi-Agent Reinforcement Learning based Traffic Signal Control</title>
<link>https://arxiv.org/abs/2411.19359</link>
<guid>https://arxiv.org/abs/2411.19359</guid>
<content:encoded><![CDATA[
<div> 关键词：Transit Signal Priority (TSP)，multi-agent reinforcement learning (MARL)，traffic signal control，value decomposition network (VDN)，intersection delay

<br /><br />总结：
本文将Transit Signal Priority (TSP)整合到基于多智能体强化学习(MARL)的交通信号控制中。首先，研究开发了一种针对两个协同工作的交叉路口的自适应信号控制系统，使用MARL和价值分解网络(VDN)架构进行集中训练，结果显示其性能略优于基于v/c为0.95的整体交叉口延迟的协调感应信号控制。接着，将训练好的信号控制智能体作为背景控制器，研究了两种事件驱动的TSP智能体方案：一种是在分散式训练和分散式执行(DTDE)框架下训练独立的TSP智能体；另一种则采用集中式训练和分散式执行(CTDE)框架以及VDN架构训练协调的TSP智能体以选择并实施跨两个交叉路口的协调TSP策略。经过训练，两种TSP方案都能有效减少公交车延误，其中独立TSP智能体相较于无TSP情况可降低两个交叉口的公交车延误达22%，而协调TSP智能体能实现27%的延误减少。在此过程中，对于多数次级街道行驶方向，仅有轻微的延迟增加。 <div>
arXiv:2411.19359v1 Announce Type: new 
Abstract: This study integrates Transit Signal Priority (TSP) into multi-agent reinforcement learning (MARL) based traffic signal control. The first part of the study develops adaptive signal control based on MARL for a pair of coordinated intersections in a microscopic simulation environment. The two agents, one for each intersection, are centrally trained using a value decomposition network (VDN) architecture. The trained agents show slightly better performance compared to coordinated actuated signal control based on overall intersection delay at v/c of 0.95. In the second part of the study the trained signal control agents are used as background signal controllers while developing event-based TSP agents. In one variation, independent TSP agents are formulated and trained under a decentralized training and decentralized execution (DTDE) framework to implement TSP at each intersection. In the second variation, the two TSP agents are centrally trained under a centralized training and decentralized execution (CTDE) framework and VDN architecture to select and implement coordinated TSP strategies across the two intersections. In both cases the agents converge to the same bus delay value, but independent agents show high instability throughout the training process. For the test runs, the two independent agents reduce bus delay across the two intersections by 22% compared to the no TSP case while the coordinated TSP agents achieve 27% delay reduction. In both cases, there is only a slight increase in delay for a majority of the side street movements.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Local Information Aggregation based Multi-Agent Reinforcement Learning for Robot Swarm Dynamic Task Allocation</title>
<link>https://arxiv.org/abs/2411.19526</link>
<guid>https://arxiv.org/abs/2411.19526</guid>
<content:encoded><![CDATA[
<div> 关键词：动态环境、任务分配、机器人集群、局部信息聚合、分布式部分可观测马尔可夫决策过程 (Dec-POMDP)、LIA_MADDPG算法、集中式训练与分布式执行 (CTDE)

总结:<br />
本文研究了如何针对动态环境优化机器人集群的任务分配问题，提出了一种利用分布式部分可观测马尔可夫决策过程(Dec-POMDP)的新框架。该框架设计了一个名为局部信息聚合多智能体深度确定性策略梯度（LIA_MADDPG）的算法，实现了集中式训练和分布式执行相结合。其中，LIA模块在训练阶段负责从邻近机器人收集关键数据以提升决策效率；在执行阶段，则提出了根据变化和部分可观测的环境条件动态调整任务分配的策略改进方法。实验结果显示，LIA模块可以无缝融入基于CTDE的多种MARL方法，显著提升了性能。相比于六种传统强化学习算法和一个启发式算法，LIA_MADDPG展现出了更优的可扩展性、对环境变化的快速适应能力以及维持稳定性和收敛速度的能力，证实了其在动态环境下通过增强局部协作和自适应策略执行来有效改善机器人集群任务分配的潜力。 <div>
arXiv:2411.19526v1 Announce Type: new 
Abstract: In this paper, we explore how to optimize task allocation for robot swarms in dynamic environments, emphasizing the necessity of formulating robust, flexible, and scalable strategies for robot cooperation. We introduce a novel framework using a decentralized partially observable Markov decision process (Dec_POMDP), specifically designed for distributed robot swarm networks. At the core of our methodology is the Local Information Aggregation Multi-Agent Deep Deterministic Policy Gradient (LIA_MADDPG) algorithm, which merges centralized training with distributed execution (CTDE). During the centralized training phase, a local information aggregation (LIA) module is meticulously designed to gather critical data from neighboring robots, enhancing decision-making efficiency. In the distributed execution phase, a strategy improvement method is proposed to dynamically adjust task allocation based on changing and partially observable environmental conditions. Our empirical evaluations show that the LIA module can be seamlessly integrated into various CTDE-based MARL methods, significantly enhancing their performance. Additionally, by comparing LIA_MADDPG with six conventional reinforcement learning algorithms and a heuristic algorithm, we demonstrate its superior scalability, rapid adaptation to environmental changes, and ability to maintain both stability and convergence speed. These results underscore LIA_MADDPG's outstanding performance and its potential to significantly improve dynamic task allocation in robot swarms through enhanced local collaboration and adaptive strategy execution.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Secure Filtering against Spatio-Temporal False Data under Asynchronous Sampling</title>
<link>https://arxiv.org/abs/2411.19765</link>
<guid>https://arxiv.org/abs/2411.19765</guid>
<content:encoded><![CDATA[
<div> 关键词：状态估计、连续LTI系统、非周期性采样、异步采样、攻击防护

总结:

本文针对存在非周期性和异步采样测量值情况下，连续线性时不变（LTI）系统的状态估计问题进行了研究。文章考虑了传感器通过未受保护的通信通道向融合中心传输测量值及时间戳的过程中，系统可能遭受包括篡改测量值、篡改时间戳以及混合恶意活动等攻击。为应对这类更强大的攻击，文中提出了一种分散式局部估计算法，每个传感器根据其自身的测量数据以异步方式维护本地状态估计。通过时间预测和事件触发的方式实现局部状态同步与融合。当采样时间无病态情况时，证明在没有攻击的情况下，本地估计可恢复到最优卡尔曼估计。在存在攻击的情况下，文章提出了采用$\ell_1$范数正则化的最小二乘问题生成安全估计，并确保在满足可观测性冗余条件下误差保持有界。最后，通过对IEEE 14-bus系统的基准案例分析展示了所提算法的有效性。<br /><br /> <div>
arXiv:2411.19765v1 Announce Type: new 
Abstract: This paper addresses the state estimation problem in continuous LTI systems under attacks with non-periodic and asynchronous sampled measurements. The non-periodic and asynchronous sampling requires sensors to transmit not only the measurement values but also the sampling time-stamps to the fusion center via unprotected communication channels. This communication scheme leaves the system vulnerable to a variety of malicious activities such as (i) manipulating measurement values, (ii) manipulating time-stamps, (iii) hybrid manipulations such as generating fake measurements or eliminating the measurement. To deal with such more powerful attacks, we propose a decentralized local estimation algorithm where each sensor maintains its local state estimate based on its measurements in an asynchronous fashion. The local states are synchronized by time-prediction and fused in an event-triggered manner. In the absence of attacks, local estimates are proved to recover the optimal Kalman estimation by our carefully designed weighted least square problem, given that the sample time is non-pathological. In the presence of attacks, an $\ell_1$ regularized least square problem is proposed to generate secure estimates with uniformly bounded error as long as the observability redundancy is satisfied. The effectiveness of the proposed algorithm is demonstrated through a benchmark example of the IEEE 14-bus system.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing AI microscopy for foodborne bacterial classification via adversarial domain adaptation across optical and biological variability</title>
<link>https://arxiv.org/abs/2411.19514</link>
<guid>https://arxiv.org/abs/2411.19514</guid>
<content:encoded><![CDATA[
<div> 关键词：AI赋能显微镜、对抗性领域适应、多域适应、细菌分类、食品安全

<br />
总结:
本文提出了一种利用AI赋能显微镜进行食品中病原菌快速检测的方法，通过对抗性领域适应增强了算法对不同条件下细菌图像识别的泛化能力。研究比较了单目标和多域适应方法在六个代表性菌株分类中的性能。采用EfficientNetV2作为基础架构，结合细粒度特征提取技术处理小目标图像，并运用少量样本学习。通过训练模型对源域（控制条件下的相位对比显微镜数据）进行学习，再在目标域（包括明亮场显微镜、低放大倍数以及延长培养时间等情况）下进行评估，结果显示，单域适应网络(DANNs)能分别提升20x、20x-5h和BF目标域的分类准确率最高达54.45%、43.44%和31.67%，同时对源域的影响极小。而多域适应网络(MDANNs)在BF和20x域表现更优。Grad-CAM和t-SNE可视化验证了模型能够在各种条件下学习到领域不变的特征。这项研究为实现细菌分类提供了一个可扩展和适应性强的框架，减少了对复杂样本准备的依赖，有助于在分散和资源有限的环境中应用，从而更好地保障食品安全与质量。 <div>
arXiv:2411.19514v1 Announce Type: cross 
Abstract: Rapid detection of foodborne bacteria is critical for food safety and quality, yet traditional culture-based methods require extended incubation and specialized sample preparation. This study addresses these challenges by i) enhancing the generalizability of AI-enabled microscopy for bacterial classification using adversarial domain adaptation and ii) comparing the performance of single-target and multi-domain adaptation. Three Gram-positive (Bacillus coagulans, Bacillus subtilis, Listeria innocua) and three Gram-negative (E. coli, Salmonella Enteritidis, Salmonella Typhimurium) strains were classified. EfficientNetV2 served as the backbone architecture, leveraging fine-grained feature extraction for small targets. Few-shot learning enabled scalability, with domain-adversarial neural networks (DANNs) addressing single domains and multi-DANNs (MDANNs) generalizing across all target domains. The model was trained on source domain data collected under controlled conditions (phase contrast microscopy, 60x magnification, 3-h bacterial incubation) and evaluated on target domains with variations in microscopy modality (brightfield, BF), magnification (20x), and extended incubation to compensate for lower resolution (20x-5h). DANNs improved target domain classification accuracy by up to 54.45% (20x), 43.44% (20x-5h), and 31.67% (BF), with minimal source domain degradation (<4.44%). MDANNs achieved superior performance in the BF domain and substantial gains in the 20x domain. Grad-CAM and t-SNE visualizations validated the model's ability to learn domain-invariant features across diverse conditions. This study presents a scalable and adaptable framework for bacterial classification, reducing reliance on extensive sample preparation and enabling application in decentralized and resource-limited environments.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eden: An Provably Secure, Ultra-Fast, and Fully Decentralized Blockchain Interoperability Protocol</title>
<link>https://arxiv.org/abs/2311.17454</link>
<guid>https://arxiv.org/abs/2311.17454</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、互操作性、Eden、SparkleX、零知识 MapReduce

总结:
<br />
随着区块链生态系统的成长和多样化，不同区块链网络间的无缝互操作性变得至关重要。本文介绍了用于SparkleX的Eden协议，它是一种基于零知识 MapReduce 框架的弹性去中心化使者网络，实现了超快速、安全且完全去中心化的跨链通信。Eden的设计、强大的安全性模型以及确保其在网络环境压力下仍具有弹性和韧性的创新机制都得到了深入探讨。 <div>
arXiv:2311.17454v2 Announce Type: replace 
Abstract: As the blockchain ecosystem grows and diversifies, seamless interoperability between blockchain networks has become essential. Interoperability not only enhances the usability and reach of individual chains but also fosters collaboration, unlocking new opportunities for decentralized applications. In this paper, we introduce Eden, the parallel-verified messaging protocol powering SparkleX. Eden is an elastic, decentralized envoy network built on a zero-knowledge MapReduce framework (i.e., ZK-MapReduce), enabling ultra-fast, secure, and fully decentralized cross-chain communication. We explore Eden's design, its robust security model, and the innovative mechanisms that ensure its elasticity and resilience, even in demanding network environments.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Joint Resource Optimization, Computation Offloading and Resource Slicing for Multi-Edge Traffic-Cognitive Networks</title>
<link>https://arxiv.org/abs/2411.17782</link>
<guid>https://arxiv.org/abs/2411.17782</guid>
<content:encoded><![CDATA[
<div> 关键词: 边缘计算、资源分配、任务卸载、Stackelberg博弈、贝叶斯优化

总结:<br />
本文探讨了边缘计算环境下，平台与边缘服务器（ESs）之间动态交互的日益变化态势。面对高效资源利用和严格的服务质量（QoS）要求，需要对ESs进行激励并优化平台运营目标。研究内容涉及一个多智能体系统，其中平台和ESs都是具有自我利益的实体。文章提出了一个基于Stackelberg博弈的新型框架来建模各利益相关者之间的互动，并采用一种基于贝叶斯优化的集中式算法解决联合优化问题。针对因隐私顾虑带来的实际信息收集挑战，文中进一步设计了一种利用神经网络优化和隐私保护信息交换协议的分布式解决方案。大量的数值评估证明了所提机制相比现有基准能实现更优性能。 <div>
arXiv:2411.17782v1 Announce Type: new 
Abstract: The evolving landscape of edge computing envisions platforms operating as dynamic intermediaries between application providers and edge servers (ESs), where task offloading is coupled with payments for computational services. Ensuring efficient resource utilization and meeting stringent Quality of Service (QoS) requirements necessitates incentivizing ESs while optimizing the platforms operational objectives. This paper investigates a multi-agent system where both the platform and ESs are self-interested entities, addressing the joint optimization of revenue maximization, resource allocation, and task offloading. We propose a novel Stackelberg game-based framework to model interactions between stakeholders and solve the optimization problem using a Bayesian Optimization-based centralized algorithm. Recognizing practical challenges in information collection due to privacy concerns, we further design a decentralized solution leveraging neural network optimization and a privacy-preserving information exchange protocol. Extensive numerical evaluations demonstrate the effectiveness of the proposed mechanisms in achieving superior performance compared to existing baselines.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>CrypQ: A Database Benchmark Based on Dynamic, Ever-Evolving Ethereum Data</title>
<link>https://arxiv.org/abs/2411.17913</link>
<guid>https://arxiv.org/abs/2411.17913</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据库系统、动态数据、区块链、CrypQ、查询优化器

总结:
现代数据库系统需要处理随时间演变的动态数据，但许多流行基准测试未能充分评估这一特性。本文引入了一个名为CrypQ的新数据库基准，它利用公开的、动态变化的以太坊区块链数据，提供了反映现实和活跃加密货币市场中不可预测性的大规模、不断进化的数据集。文章详细描述了CrypQ的数据模式、创建数据快照和更新序列的方法以及一系列相关的SQL查询。作为示例，作者展示了使用CrypQ如何在复杂、演进的数据分布上评价基于成本的查询优化器，这些分布具有真实世界的偏斜性和依赖性。<br /><br /> <div>
arXiv:2411.17913v1 Announce Type: new 
Abstract: Modern database systems are expected to handle dynamic data whose characteristics may evolve over time. Many popular database benchmarks are limited in their ability to evaluate this dynamic aspect of the database systems. Those that use synthetic data generators often fail to capture the complexity and unpredictable nature of real data, while most real-world datasets are static and difficult to create high-volume, realistic updates for. This paper introduces CrypQ, a database benchmark leveraging dynamic, public Ethereum blockchain data. CrypQ offers a high-volume, ever-evolving dataset reflecting the unpredictable nature of a real and active cryptocurrency market. We detail CrypQ's schema, procedures for creating data snapshots and update sequences, and a suite of relevant SQL queries. As an example, we demonstrate CrypQ's utility in evaluating cost-based query optimizers on complex, evolving data distributions with real-world skewness and dependencies.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging A New GAN-based Transformer with ECDH Crypto-system for Enhancing Energy Theft Detection in Smart Grid</title>
<link>https://arxiv.org/abs/2411.18023</link>
<guid>https://arxiv.org/abs/2411.18023</guid>
<content:encoded><![CDATA[
<div> 关键词：能源盗窃检测、分裂学习、GAN-Transformer、隐私泄漏保护、变压器架构

总结:
<br />
本文提出了一种基于GAN-Transformer的新型分裂学习框架，用于提高能源盗窃检测的准确性并保障用户数据隐私。该框架利用变压器架构处理能源消耗数据长程依赖性的优势，提升了检测效果。为应对传统分裂学习中的隐私泄露问题，文中创新性地采用了一种基于掩码的方法，这是首次将其应用于针对AI敌手的分裂学习场景中，有效保护了敏感信息。实验结果显示，该提议的框架不仅达到了与传统方法相当的检测精度，而且显著增强了隐私保护力度。这表明GAN-Transformer分裂学习框架在能源盗窃检测领域具有高效且安全的应用潜力。 <div>
arXiv:2411.18023v1 Announce Type: new 
Abstract: Detecting energy theft is vital for effectively managing power grids, as it ensures precise billing and prevents financial losses. Split-learning emerges as a promising decentralized machine learning technique for identifying energy theft while preserving user data confidentiality. Nevertheless, traditional split learning approaches are vulnerable to privacy leakage attacks, which significantly threaten data confidentiality. To address this challenge, we propose a novel GAN-Transformer-based split learning framework in this paper. This framework leverages the strengths of the transformer architecture, which is known for its capability to process long-range dependencies in energy consumption data. Thus, it enhances the accuracy of energy theft detection without compromising user privacy. A distinctive feature of our approach is the deployment of a novel mask-based method, marking a first in its field to effectively combat privacy leakage in split learning scenarios targeted at AI-enabled adversaries. This method protects sensitive information during the model's training phase. Our experimental evaluations indicate that the proposed framework not only achieves accuracy levels comparable to conventional methods but also significantly enhances privacy protection. The results underscore the potential of the GAN-Transformer split learning framework as an effective and secure tool in the domain of energy theft detection.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hidden Data Privacy Breaches in Federated Learning</title>
<link>https://arxiv.org/abs/2411.18269</link>
<guid>https://arxiv.org/abs/2411.18269</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、数据重建攻击、恶意代码注入、高分辨率图像、防御方法

<br /><br />总结:

本文提出了一个针对联邦学习(Federated Learning)的新式数据重建攻击方法。该攻击利用恶意代码注射技术，结合独特的稀疏编码设计和区块划分策略，能够在不引起模型明显变化的情况下，隐秘地嵌入隐藏模型并系统性地抽取敏感数据。通过基于斐波那契指数的设计实现高效结构化的数据检索，而区块划分则增强了处理大规模及高分辨率图像的能力。实验结果显示，与五种最先进的数据重建攻击方法相比，本文的方法在五个不同的检测方法下表现更优，且能够逃避现有的数据重建防御手段，同时适用于FedAVG和FedSGD两种联邦学习场景。文章强调了开发者需要针对此类新威胁开发新的防御措施，并承诺将在论文被接受后开源相关代码。 <div>
arXiv:2411.18269v1 Announce Type: new 
Abstract: Federated Learning (FL) emerged as a paradigm for conducting machine learning across broad and decentralized datasets, promising enhanced privacy by obviating the need for direct data sharing. However, recent studies show that attackers can steal private data through model manipulation or gradient analysis. Existing attacks are constrained by low theft quantity or low-resolution data, and they are often detected through anomaly monitoring in gradients or weights. In this paper, we propose a novel data-reconstruction attack leveraging malicious code injection, supported by two key techniques, i.e., distinctive and sparse encoding design and block partitioning. Unlike conventional methods that require detectable changes to the model, our method stealthily embeds a hidden model using parameter sharing to systematically extract sensitive data. The Fibonacci-based index design ensures efficient, structured retrieval of memorized data, while the block partitioning method enhances our method's capability to handle high-resolution images by dividing them into smaller, manageable units. Extensive experiments on 4 datasets confirmed that our method is superior to the five state-of-the-art data-reconstruction attacks under the five respective detection methods. Our method can handle large-scale and high-resolution data without being detected or mitigated by state-of-the-art data reconstruction defense methods. In contrast to baselines, our method can be directly applied to both FedAVG and FedSGD scenarios, underscoring the need for developers to devise new defenses against such vulnerabilities. We will open-source our code upon acceptance.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Uncertainty and Personalization via Efficient Second-order Optimization</title>
<link>https://arxiv.org/abs/2411.18385</link>
<guid>https://arxiv.org/abs/2411.18385</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Bayesian、优化方法、效率、通信成本

总结:<br />
本文提出了一种新颖的用于联邦学习（Federated Learning）的贝叶斯方法，该方法利用高效的二阶优化技术，旨在解决传统贝叶斯FL在计算和通信成本上的问题。新方法与Adam等一阶优化方法具有相似的计算成本，同时保持了贝叶斯方法对于FL的优势，如不确定性量化、个性化建模以及通过层级贝叶斯框架处理客户端间共性。实验表明，新方法在标准及个性化FL设置中均比当前最优的贝叶斯FL方法更高效且准确，不仅提高了预测精度，也改进了不确定性估计。 <div>
arXiv:2411.18385v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a promising method to collaboratively learn from decentralized and heterogeneous data available at different clients without the requirement of data ever leaving the clients. Recent works on FL have advocated taking a Bayesian approach to FL as it offers a principled way to account for the model and predictive uncertainty by learning a posterior distribution for the client and/or server models. Moreover, Bayesian FL also naturally enables personalization in FL to handle data heterogeneity across the different clients by having each client learn its own distinct personalized model. In particular, the hierarchical Bayesian approach enables all the clients to learn their personalized models while also taking into account the commonalities via a prior distribution provided by the server. However, despite their promise, Bayesian approaches for FL can be computationally expensive and can have high communication costs as well because of the requirement of computing and sending the posterior distributions. We present a novel Bayesian FL method using an efficient second-order optimization approach, with a computational cost that is similar to first-order optimization methods like Adam, but also provides the various benefits of the Bayesian approach for FL (e.g., uncertainty, personalization), while also being significantly more efficient and accurate than SOTA Bayesian FL methods (both for standard as well as personalized FL settings). Our method achieves improved predictive accuracies as well as better uncertainty estimates as compared to the baselines which include both optimization based as well as Bayesian FL methods.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proving and Rewarding Client Diversity to Strengthen Resilience of Blockchain Networks</title>
<link>https://arxiv.org/abs/2411.18401</link>
<guid>https://arxiv.org/abs/2411.18401</guid>
<content:encoded><![CDATA[
<div> 关键词: 客户端多样性、以太坊区块链、网络韧性、经济激励、verifiable execution

<br /><br />总结:
本文关注的是以太坊区块链中的客户端多样性问题，提出了一种新的概念框架以增强网络韧性的系统属性。该框架的核心目标在于利用经济激励和可验证执行来促进少数客户端的采用，从而打造更为健壮的区块链生态系统。具体来说，文章建议明确并可验证地识别出协议参与者的客户端实现，并通过向使用少数客户端的参与者提供更高的参与奖励来鼓励其使用。此外，文中针对以太坊提出了这一框架的详细蓝图。该提议对于提升区块链客户端多样性具有变革性意义，并可应用于增强任何去中心化分布式系统的韧性。 <div>
arXiv:2411.18401v1 Announce Type: new 
Abstract: Client diversity in the Ethereum blockchain refers to the use of multiple independent implementations of the Ethereum protocol. This effectively enhances network resilience by reducing reliance on any single software client implementation. With client diversity, a single bug cannot tear the whole network down. However, despite multiple production-grade client implementations being available, there is still a heavily skewed distribution of clients in Ethereum. This is a concern for the community. In this paper, we introduce a novel conceptual framework for client diversity. The core goal is to improve the network resilience as a systemic property. Our key insight is to leverage economic incentives and verifiable execution to encourage the adoption of minority clients, thereby fostering a more robust blockchain ecosystem. Concretely, we propose to unambiguously and provably identify the client implementation used by any protocol participant, and to use this information to incentivize the usage of minority clients by offering higher participation rewards. We outline a detailed blueprint for our conceptual framework, in the realm of Ethereum. Our proposal is a game changer for improving client diversity of blockchains. Ultimately, it applies to strengthening the resilience of any decentralized distributed systems.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Planning of Carbon-Neutral Heating Demand Coverage Under Uncertainty in a Coupled Multi-Energy Grid</title>
<link>https://arxiv.org/abs/2305.04577</link>
<guid>https://arxiv.org/abs/2305.04577</guid>
<content:encoded><![CDATA[
<div> 关键词：多能源网格、消费者行为、不确定性、鲁棒优化、碳中和

<br /><br />总结:
本文提出了一种以消费者为中心的电网规划方法，针对燃气和区域供暖与电力网融合的多能源网格系统。文章指出实际情况下，消费者的供暖技术采纳行为受成本和政府法规影响，具有高度不确定性，这增加了电网扩展投资的风险。为应对这一挑战，论文运用鲁棒优化模型来处理能源价格的不确定性，采用比例偏差的区间不确定性进行建模，使规划者能够预测不同地区的特定供暖技术采纳率并优先考虑必要的电网扩张。研究以汉堡为例进行了应用，结果表明在高密度地区，区域能源供暖扩展是实现碳中和的低风险投资；而在较低密度地区，电能驱动的分布式热泵成为支持方案；当电气化扩展不切实际时，氢气管网成为可行选项。随着不确定性的增加，解决方案将变得更加保守。 <div>
arXiv:2305.04577v3 Announce Type: replace 
Abstract: Integrating the gas and district heating with the electrical grid in a multi-energy grid has been shown to provide flexibility and prevent bottlenecks in the operation of electrical distribution grids. This integration assumes a top-down grid planning approach and a perfect knowledge of consumer behaviour. In reality, consumers decides whether to adopt a heating technology based on costs and government regulation. This behavior is highly uncertain and depends on fluctuations in heating technology costs and energy prices. The uncertainty associated with consumer behavior increases the risk of investment in grid expansion. In response to this challenge, this paper proposes an approach with the consumer at the center of the planning method. Robust optimization is used to model the uncertainty in prices to reduce the risk of investment in grid expansion. The uncertainty in energy prices is modeled using interval uncertainty with a proportional deviation. This allows planners, operators and regulators to predict the adoption rate of certain heating technology in different geographical areas and prioritize the expansion of specific grids where they are required. By minimizing a cost function subject to robust constraints, the strategy ensures robustness against uncertainties in energy prices. This robust optimization approach is applied to Hamburg as a case study. The result of the optimization represents the consumer's decision. The impact of the consumer's decision on the electrical grid is analzed on different benchmark distribution grids. The study concludes that district heating expansion in high-density areas is a low-risk investment for carbon neutrality. In less dense areas, electrification supports decentralized heat pumps. Meanwhile, hydrogen gas grids are viable where electric expansion is impractical. Increased uncertainty leads to more conservative solutions.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning in Chemical Engineering: A Tutorial on a Framework for Privacy-Preserving Collaboration Across Distributed Data Sources</title>
<link>https://arxiv.org/abs/2411.16737</link>
<guid>https://arxiv.org/abs/2411.16737</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、化学工程、数据隐私、制造优化、TensorFlow Federated

总结:
本文介绍了Federated Learning（联邦学习）这一分布式机器学习方法，尤其针对化学工程领域的应用提供了易于理解的介绍。文章通过实例和手把手教程探讨了联邦学习在制造业优化、多模态数据分析和药物发现等任务中的运用，并着重讨论了如何保护专有信息和管理分布式数据集的独特挑战。文中使用$\texttt{Flower}$和$\texttt{TensorFlow Federated}$等关键框架构建了教程，旨在为化学工程师提供适用于特定需求的FL工具。通过对比FL与集中式学习在三个与化工应用相关的不同数据集上的性能，结果显示FL通常能保持或提高分类性能，尤其是在处理复杂和异构数据时表现更优。最后，文章指出了联邦学习面临的开放性挑战及现有的改进措施和策略。 <div>
arXiv:2411.16737v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning approach that has gained attention for its potential to enable collaborative model training across clients while protecting data privacy, making it an attractive solution for the chemical industry. This work aims to provide the chemical engineering community with an accessible introduction to the discipline. Supported by a hands-on tutorial and a comprehensive collection of examples, it explores the application of FL in tasks such as manufacturing optimization, multimodal data integration, and drug discovery while addressing the unique challenges of protecting proprietary information and managing distributed datasets. The tutorial was built using key frameworks such as $\texttt{Flower}$ and $\texttt{TensorFlow Federated}$ and was designed to provide chemical engineers with the right tools to adopt FL in their specific needs. We compare the performance of FL against centralized learning across three different datasets relevant to chemical engineering applications, demonstrating that FL will often maintain or improve classification performance, particularly for complex and heterogeneous data. We conclude with an outlook on the open challenges in federated learning to be tackled and current approaches designed to remediate and improve this framework.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Meets LLMs: A Living Survey on Bidirectional Integration</title>
<link>https://arxiv.org/abs/2411.16809</link>
<guid>https://arxiv.org/abs/2411.16809</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、多模态、区块链技术、安全性、隐私保护

<br /><br />总结:

本文探讨了大型语言模型与区块链技术的融合及其潜在优势和发展前景。随着大型语言模型和可解释性研究领域的显著进步，以及对安全性和隐私问题的关注，区块链技术因其去中心化、防篡改等特性提供了新的解决方案。文章分析了两种技术各自的优势及限制，并从两个方向研究它们的结合：一是将大型语言模型应用于区块链，提出六种发展方向并探索改善区块链技术及其应用场景的方法；二是利用区块链技术的特点来弥补大型语言模型的不足，并发掘其在多个领域的应用潜力。 <div>
arXiv:2411.16809v1 Announce Type: new 
Abstract: In the domain of large language models, considerable advancements have been attained in multimodal large language models and explainability research, propelled by the continuous technological progress and innovation. Nonetheless, security and privacy concerns continue to pose as prominent challenges in this field. The emergence of blockchain technology, marked by its decentralized nature, tamper-proof attributes, distributed storage functionality, and traceability, has provided novel approaches for resolving these issues. Both of these technologies independently hold vast potential for development; yet, their combination uncovers substantial cross-disciplinary opportunities and growth prospects. The current research tendencies are increasingly concentrating on the integration of blockchain with large language models, with the aim of compensating for their respective limitations through this fusion and promoting further technological evolution. In this study, we evaluate the advantages and developmental constraints of the two technologies, and explore the possibility and development potential of their combination. This paper primarily investigates the technical convergence in two directions: Firstly, the application of large language models to blockchain, where we identify six major development directions and explore solutions to the shortcomings of blockchain technology and their application scenarios; Secondly, the application of blockchain technology to large language models, leveraging the characteristics of blockchain to remedy the deficiencies of large language models and exploring its application potential in multiple fields.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EvoChain: a Recovery Approach for Permissioned Blockchain Applications</title>
<link>https://arxiv.org/abs/2411.16976</link>
<guid>https://arxiv.org/abs/2411.16976</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、EvoChain、数据红动作业、时间限制条件、Hyperledger Fabric

总结:<br />
本文介绍了EvoChain，这是一个针对区块链技术的智能合约框架扩展，旨在为数据红动作业和有条件的数据恢复引入受控可变性。该机制允许在生效不可变性之前的一段宽限期内进行错误修正。通过基于Hyperledger Fabric的供应链应用WineTracker进行了验证，EvoChain使某些用户能够在不影响区块链安全性和保持数据一致性的情况下撤销不必要的操作。性能评估显示，这种方法带来了功能性优势的同时，仅产生了轻微的额外开销。 <div>
arXiv:2411.16976v1 Announce Type: new 
Abstract: Blockchain technology supports decentralized, consensus-driven data storage and processing, ensuring integrity and auditability. It is increasingly adopted for use cases with multiple stakeholders with shared ownership scenarios like digital identity and supply chain management. However, real-world deployments face challenges with mistakes and intrusions. This article presents EvoChain, a chaincode framework extension introducing controlled mutability for data redaction and recovery under time-limited or specific conditions. This mechanism allows corrections during a grace period before immutability takes effect. We validated our approach using WineTracker, a Hyperledger Fabric-based supply chain application. It enables some users to cancel unwanted operations while preserving the blockchain security and maintaining data consistency. Performance evaluations showed minimal overhead with functional benefits.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Storage And Self-Sovereign Identity For Document-Based Claims</title>
<link>https://arxiv.org/abs/2411.16987</link>
<guid>https://arxiv.org/abs/2411.16987</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化身份系统、用户隐私、数字文档验证、SoverClaim、Hyperledger Indy、Storj、去中心化、自主权身份、文档存储、透明审计日志

<br /><br />总结:
本文介绍了SoverClaim，这是一个基于去中心化理念设计的身份管理和数字文档验证原型应用。它旨在解决中心化身份系统可能带来的用户隐私问题和对在线活动追踪或数据泄露的风险。SoverClaim利用了Hyperledger Indy区块链技术来发行和展示具有透明审计日志的自主权数字身份，并结合Storj的去中心化点对点服务实现安全、去中心化的文档存储及后续删除功能。该原型实现了将自主权身份与基于文档的申明无缝整合，并能在不到750毫秒的时间内完成响应，适合及时的人机交互场景。 <div>
arXiv:2411.16987v1 Announce Type: new 
Abstract: Users increasingly rely on identity providers for accessing online services and resources. However, centralized identity systems often compromise user privacy due to online activity tracking or data breaches. At the same time, many online services require digital copies of physical documents for validation in claims processes, such as providing proof of residence for opening a bank account or verifying medical images for health insurance claims. With centralized solutions, privacy depends entirely on the trusted party, but there are emerging decentralized approaches that offer greater transparency.
  This article introduces SoverClaim, a decentralized application prototype that empowers users to control their identity and also allows them to present digital documents with privacy. SoverClaim leverages Hyperledger Indy, a blockchain for issuing and presenting self-sovereign digital identities with transparent audit logs, and Storj, a decentralized peer-to-peer service, for secure and decentralized document storage and subsequent deletion. The prototype demonstrates the seamless integration of self-sovereign identities and document-based claims, achieving response times of under 750 ms, making it suitable for timely human interactions.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing Vulnerability in Smart Contracts: The Role of Code Complexity Metrics in Security Analysis</title>
<link>https://arxiv.org/abs/2411.17343</link>
<guid>https://arxiv.org/abs/2411.17343</guid>
<content:encoded><![CDATA[
<div> 关键词: code complexity metrics, vulnerable code, smart contracts, Solidity, vulnerability assessment

总结:<br />
本文研究了代码复杂性指标在识别Solidity智能合约漏洞中的作用。文章强调了代码复杂性度量作为安全性评估补充特征的重要性，并探讨了各项指标的关联性、与漏洞的相关性以及区分脆弱代码和中立代码的能力。通过对21项复杂性指标分析，发现某些指标之间存在高相关性和冗余性，但单个指标与漏洞之间的相关性较弱。尽管如此，所有指标都能有效地区分脆弱代码和中立代码，大多数复杂性指标在脆弱代码中的值要高于中立代码，仅有三个例外。 <div>
arXiv:2411.17343v1 Announce Type: new 
Abstract: Codes with specific characteristics are more exposed to security vulnerabilities. Studies have revealed that codes that do not adhere to best practices are more challenging to verify and maintain, increasing the likelihood of unnoticed or unintentionally introduced vulnerabilities. Given the crucial role of smart contracts in blockchain systems, ensuring their security and conducting thorough vulnerability analysis is critical. This study investigates the use of code complexity metrics as indicators of vulnerable code in Solidity smart contracts. We highlight the significance of complexity metrics as valuable complementary features for vulnerability assessment and provide insights into the individual power of each metric. By analyzing 21 complexity metrics, we explored their interrelation, association with vulnerability, discriminative power, and mean values in vulnerable versus neutral codes. The results revealed some high correlations and potential redundancies among certain metrics, but weak correlations between each independent metric and vulnerability. Nevertheless, we found that all metrics can effectively discriminate between vulnerable and neutral codes, and most complexity metrics, except for three, exhibited higher values in vulnerable codes.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Decentralized AI (DeAI)</title>
<link>https://arxiv.org/abs/2411.17461</link>
<guid>https://arxiv.org/abs/2411.17461</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能(AI)，集中化，区块链，去中心化AI(DeAI)，系统化知识(SoK)

总结:
<br />
本文探讨了人工智能集中化所带来的挑战，如单点故障、内在偏见、数据隐私和可扩展性问题，特别是在封闭源码大型语言模型中的问题。为解决这些问题，区块链为基础的去中心化AI（DeAI）被提出作为一种有前景的解决方案。该研究进行了关于区块链基础DeAI解决方案的系统化知识(SoK)梳理，提出了基于模型生命周期对现有DeAI协议进行分类的taxonomy。通过这个分类体系，作者清晰地概述了DeAI协议的现状并分析了其异同点。文章进一步分析了区块链在DeAI中的作用，阐述了区块链特性如何增强AI过程的安全性、透明度和可信度，并确保公平激励AI数据和模型贡献者。同时，文中还指出了开发DeAI协议的关键洞察和研究空白，强调了几条未来研究的重要方向。 <div>
arXiv:2411.17461v1 Announce Type: new 
Abstract: The centralization of Artificial Intelligence (AI) poses significant challenges, including single points of failure, inherent biases, data privacy concerns, and scalability issues. These problems are especially prevalent in closed-source large language models (LLMs), where user data is collected and used without transparency. To mitigate these issues, blockchain-based decentralized AI (DeAI) has emerged as a promising solution. DeAI combines the strengths of both blockchain and AI technologies to enhance the transparency, security, decentralization, and trustworthiness of AI systems. However, a comprehensive understanding of state-of-the-art DeAI development, particularly for active industry solutions, is still lacking. In this work, we present a Systematization of Knowledge (SoK) for blockchain-based DeAI solutions. We propose a taxonomy to classify existing DeAI protocols based on the model lifecycle. Based on this taxonomy, we provide a structured way to clarify the landscape of DeAI protocols and identify their similarities and differences. We analyze the functionalities of blockchain in DeAI, investigating how blockchain features contribute to enhancing the security, transparency, and trustworthiness of AI processes, while also ensuring fair incentives for AI data and model contributors. In addition, we identify key insights and research gaps in developing DeAI protocols, highlighting several critical avenues for future research.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Metaverse Innovation Canvas: A Tool for Extended Reality Product/Service Development</title>
<link>https://arxiv.org/abs/2411.17541</link>
<guid>https://arxiv.org/abs/2411.17541</guid>
<content:encoded><![CDATA[
<div> 关键词：augmented reality (AR), virtual reality (VR), metaverse, startup failure, Metaverse Innovation Canvas (MIC)

<br /><br />总结:
本文针对虚拟现实(VR)和增强现实(AR)初创企业在新兴元宇宙领域中的失败原因进行了深入研究。通过分析2016年至2022年间29家失败的AR/VR初创企业案例，确定了关键问题，包括缺乏可扩展性、用户体验不佳、价值主张不明确以及未能解决特定用户问题等。基于这些发现，文章提出了适用于XR产品和服务的创新框架——Metaverse Innovation Canvas (MIC)。该画布引导创业者定义用户问题、阐述独特的XR价值主张、评估如运动交互负载这样的可用性因素、考虑社交/虚拟经济机会以及规划长期可扩展性。与通用模型不同，MIC专门的模块促使从一开始就关注到XR的关键因素。通过对五家失败创业公司的案例进行专家测试，结果显示该工具能有效提前揭示被忽视的可用性问题和技术限制，从而提高未来元宇宙初创企业的可行性。 <div>
arXiv:2411.17541v1 Announce Type: new 
Abstract: This study investigated the factors contributing to the failure of augmented reality (AR) and virtual reality (VR) startups in the emerging metaverse landscape. Through an in-depth analysis of 29 failed AR/VR startups from 2016 to 2022, key pitfalls were identified, such as a lack of scalability, poor usability, unclear value propositions, and the failure to address specific user problems. Grounded in these findings, we developed the Metaverse Innovation Canvas (MIC) a tailored business ideation framework for XR products and services. The canvas guides founders to define user problems, articulate unique XR value propositions, evaluate usability factors such as the motion-based interaction load, consider social/virtual economy opportunities, and plan for long term scalability. Unlike generalized models, specialized blocks prompt the consideration of critical XR factors from the outset. The canvas was evaluated through expert testing with startup consultants on five failed venture cases. The results highlighted the tool's effectiveness in surfacing overlooked usability issues and technology constraints upfront, enhancing the viability of future metaverse startups.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinML-Chain: A Blockchain-Integrated Dataset for Enhanced Financial Machine Learning</title>
<link>https://arxiv.org/abs/2411.16277</link>
<guid>https://arxiv.org/abs/2411.16277</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、金融市场、区块链技术、交易费机制、经济机制设计

<br /><br />总结:
本文探讨了机器学习在金融市场中的应用及其面临的挑战，并指出区块链技术能够解决其中的一些问题。作者提出了一种框架，该框架将高频链上数据与低频链下数据进行整合，用于研究经济机制设计中的新型问题，特别是以交易费机制为例进行了深入分析。通过线性回归、深度神经网络、XGBoost和LSTM等四种机器学习方法，展示了该框架构建的数据集能推动金融研究并增进对区块链驱动系统的理解。此外，作者开源了一个由该框架生成的样例数据集和处理流程代码，为金融机器学习提供了一个基准，并促进了研究工作的可重复性、透明度和协作。这一举措旨在支持研究者在此基础上进一步拓展工作，发展创新性的金融机器学习模型，从而推动机器学习、区块链与经济学之间的交叉领域研究进步。 <div>
arXiv:2411.16277v1 Announce Type: cross 
Abstract: Machine learning is critical for innovation and efficiency in financial markets, offering predictive models and data-driven decision-making. However, challenges such as missing data, lack of transparency, untimely updates, insecurity, and incompatible data sources limit its effectiveness. Blockchain technology, with its transparency, immutability, and real-time updates, addresses these challenges. We present a framework for integrating high-frequency on-chain data with low-frequency off-chain data, providing a benchmark for addressing novel research questions in economic mechanism design. This framework generates modular, extensible datasets for analyzing economic mechanisms such as the Transaction Fee Mechanism, enabling multi-modal insights and fairness-driven evaluations. Using four machine learning techniques, including linear regression, deep neural networks, XGBoost, and LSTM models, we demonstrate the framework's ability to produce datasets that advance financial research and improve understanding of blockchain-driven systems. Our contributions include: (1) proposing a research scenario for the Transaction Fee Mechanism and demonstrating how the framework addresses previously unexplored questions in economic mechanism design; (2) providing a benchmark for financial machine learning by open-sourcing a sample dataset generated by the framework and the code for the pipeline, enabling continuous dataset expansion; and (3) promoting reproducibility, transparency, and collaboration by fully open-sourcing the framework and its outputs. This initiative supports researchers in extending our work and developing innovative financial machine-learning models, fostering advancements at the intersection of machine learning, blockchain, and economics.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Embedded Blockchains: A Synthesis of Blockchains, Spread Spectrum Watermarking, Perceptual Hashing &amp; Digital Signatures</title>
<link>https://arxiv.org/abs/2009.00951</link>
<guid>https://arxiv.org/abs/2009.00951</guid>
<content:encoded><![CDATA[
<div> 关键词：音频视频伪造检测、区块链、加密扩频水印、感知哈希、数字签名

总结:
本文提出了一种用于检测操纵音频和视频的方案。该方案综合运用了区块链、加密扩频水印、感知哈希以及数字签名技术，称为嵌入式区块链。通过这一方案，利用区块链的数据结构——加密链接列表，进行绝对比对；使用感知哈希实现灵活比对；利用数字签名证明所有权；并借助加密扩频水印将区块链嵌入媒体背景噪声中。每个媒体记录都有其独特的区块链，其中每个区块存储描述媒体片段的信息。验证媒体完整性的问题被重新表述为逐块遍历区块链并与媒体分段进行对比的过程。如果链路断裂，则通过计算与提取到的感知哈希的差异来估计媒介操纵的程度。 <div>
arXiv:2009.00951v5 Announce Type: replace 
Abstract: In this paper we introduce a scheme for detecting manipulated audio and video. The scheme is a synthesis of blockchains, encrypted spread spectrum watermarks, perceptual hashing and digital signatures, which we call an Embedded Blockchain. Within this scheme, we use the blockchain for its data structure of a cryptographically linked list, cryptographic hashing for absolute comparisons, perceptual hashing for flexible comparisons, digital signatures for proof of ownership, and encrypted spread spectrum watermarking to embed the blockchain into the background noise of the media. So each media recording has its own unique blockchain, with each block holding information describing the media segment. The problem of verifying the integrity of the media is recast to traversing the blockchain, block-by-block, and segment-by-segment of the media. If any chain is broken, the difference in the computed and extracted perceptual hash is used to estimate the level of manipulation.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>POWQMIX: Weighted Value Factorization with Potentially Optimal Joint Actions Recognition for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.08036</link>
<guid>https://arxiv.org/abs/2405.08036</guid>
<content:encoded><![CDATA[
<div> 关键词：价值函数分解、多智能体强化学习、QMIX、最优联合动作加权、POWQMIX

总结:
本文提出了一种针对合作多智能体强化学习的价值函数分解新方法——潜在最优联合动作加权QMIX（POWQMIX），旨在解决QMIX及其变体因强加单调性约束而导致的表示能力受限问题。在训练过程中，POWQMIX算法识别并赋予潜在最优联合动作更高的损失权重，理论上证明了该加权训练方法可以保证恢复得到最优策略。实验结果显示，POWQMIX在矩阵游戏、增强难度的猎物捕食者以及StarCraft II多智能体挑战等环境中，相比于当前最先进的基于值函数的多智能体强化学习方法表现更优。<br /><br /> <div>
arXiv:2405.08036v4 Announce Type: replace 
Abstract: Value function factorization methods are commonly used in cooperative multi-agent reinforcement learning, with QMIX receiving significant attention. Many QMIX-based methods introduce monotonicity constraints between the joint action value and individual action values to achieve decentralized execution. However, such constraints limit the representation capacity of value factorization, restricting the joint action values it can represent and hindering the learning of the optimal policy. To address this challenge, we propose the Potentially Optimal Joint Actions Weighted QMIX (POWQMIX) algorithm, which recognizes the potentially optimal joint actions and assigns higher weights to the corresponding losses of these joint actions during training. We theoretically prove that with such a weighted training approach the optimal policy is guaranteed to be recovered. Experiments in matrix games, difficulty-enhanced predator-prey, and StarCraft II Multi-Agent Challenge environments demonstrate that our algorithm outperforms the state-of-the-art value-based multi-agent reinforcement learning methods.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry</title>
<link>https://arxiv.org/abs/2411.14593</link>
<guid>https://arxiv.org/abs/2411.14593</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、Level 5、高速公路入口、深度强化学习、多智能体游戏理论

总结:<br />
本文研究了实现全自主驾驶的关键技术之一——完全自动化的高速公路入口匝道控制问题。该研究采用基于深度强化学习（DRL）的多智能体（MA）游戏理论方法，使车辆能安全地在并入高速交通流过程中控制纵向位置。相较于以往仅针对两辆车的研究，本文扩展到更多车辆的场景，系统性地增加了道路场景中的交通和目标车辆数量。文章指出，在非协调的去中心化环境中，理论上无法找到完全避免碰撞的控制器，但通过所提出的方法学习得到的控制器在实际操作中接近理想的最优控制器表现。 <div>
arXiv:2411.14593v1 Announce Type: new 
Abstract: Vehicles today can drive themselves on highways and driverless robotaxis operate in major cities, with more sophisticated levels of autonomous driving expected to be available and become more common in the future. Yet, technically speaking, so-called "Level 5" (L5) operation, corresponding to full autonomy, has not been achieved. For that to happen, functions such as fully autonomous highway ramp entry must be available, and provide provably safe, and reliably robust behavior to enable full autonomy. We present a systematic study of a highway ramp function that controls the vehicles forward-moving actions to minimize collisions with the stream of highway traffic into which a merging (ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to this problem and study the use of controllers based on deep reinforcement learning (DRL). The virtual environment of the MA DRL uses self-play with simulated data where merging vehicles safely learn to control longitudinal position during a taper-type merge. The work presented in this paper extends existing work by studying the interaction of more than two vehicles (agents) and does so by systematically expanding the road scene with additional traffic and ego vehicles. While previous work on the two-vehicle setting established that collision-free controllers are theoretically impossible in fully decentralized, non-coordinated environments, we empirically show that controllers learned using our approach are nearly ideal when measured against idealized optimal controllers.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Initial Evidence of Elevated Reconnaissance Attacks Against Nodes in P2P Overlay Networks</title>
<link>https://arxiv.org/abs/2411.14623</link>
<guid>https://arxiv.org/abs/2411.14623</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、P2P网络、攻击、蜜罐、安全策略

总结:
我们提出假设认为，点对点（P2P）重叠网络节点由于其可见性、持续在线时间和资源潜力可能对攻击者具有吸引力。为验证这一假设，我们在全球分布式位置与实际以太坊节点并行部署了一系列蜜罐，研究针对以太坊P2P网络节点的活跃侦察攻击状况。结果发现，以太坊节点不仅遭受更多攻击，而且遭遇了特定类型、针对特定端口和服务的攻击。此外，通过对其他可达对等节点进行端口扫描，我们发现对我们节点的威胁评估适用于更广泛的P2P网络。这些发现为我们提供了改进P2P网络层安全性的潜在缓解策略的见解。 <div>
arXiv:2411.14623v1 Announce Type: new 
Abstract: We hypothesize that peer-to-peer (P2P) overlay network nodes can be attractive to attackers due to their visibility, sustained uptime, and resource potential. Towards validating this hypothesis, we investigate the state of active reconnaissance attacks on Ethereum P2P network nodes by deploying a series of honeypots alongside actual Ethereum nodes across globally distributed vantage points. We find that Ethereum nodes experience not only increased attacks, but also specific types of attacks targeting particular ports and services. Furthermore, we find evidence that the threat assessment on our nodes is applicable to the wider P2P network by having performed port scans on other reachable peers. Our findings provide insights into potential mitigation strategies to improve the security of the P2P networking layer.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OCD-FL: A Novel Communication-Efficient Peer Selection-based Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2403.04037</link>
<guid>https://arxiv.org/abs/2403.04037</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘智能、物联网、联邦学习、去中心化联邦学习、机会性通信

总结:
本文关注的是在边缘智能和不断发展的物联网背景下，联邦学习（尤其是去中心化联邦学习）所面临的挑战与改进。针对去中心化联邦学习中的通信成本和数据异质性问题，文章提出了一种名为“机会性通信效率去中心化联邦学习”（OCD-FL）的新方案。该方案通过系统性的FL节点选择策略，旨在在减少能源消耗的同时实现最大的联邦学习知识增益。实验结果显示，OCD-FL能够在保持与完全协作式联邦学习相当或更好的性能水平的同时，将能耗降低至少30%，最高可达80%。<br /><br /> <div>
arXiv:2403.04037v2 Announce Type: replace 
Abstract: The conjunction of edge intelligence and the ever-growing Internet-of-Things (IoT) network heralds a new era of collaborative machine learning, with federated learning (FL) emerging as the most prominent paradigm. With the growing interest in these learning schemes, researchers started addressing some of their most fundamental limitations. Indeed, conventional FL with a central aggregator presents a single point of failure and a network bottleneck. To bypass this issue, decentralized FL where nodes collaborate in a peer-to-peer network has been proposed. Despite the latter's efficiency, communication costs and data heterogeneity remain key challenges in decentralized FL. In this context, we propose a novel scheme, called opportunistic communication-efficient decentralized federated learning, a.k.a., OCD-FL, consisting of a systematic FL peer selection for collaboration, aiming to achieve maximum FL knowledge gain while reducing energy consumption. Experimental results demonstrate the capability of OCD-FL to achieve similar or better performances than the fully collaborative FL, while significantly reducing consumed energy by at least 30% and up to 80%.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Two-agent Motion Planning Strategies from Generalized Nash Equilibrium for Model Predictive Control</title>
<link>https://arxiv.org/abs/2411.13983</link>
<guid>https://arxiv.org/abs/2411.13983</guid>
<content:encoded><![CDATA[
<div> 关键词：Implicit Game-Theoretic MPC (IGT-MPC)，多智能体运动规划，模型预测控制(MPC)，动态游戏，神经网络

总结:
本文提出了一个名为隐式博弈论模型预测控制(IGT-MPC)的新型分散式算法，该算法应用于双智能体运动规划问题。IGT-MPC利用学习得到的价值函数来预测游戏理论中的交互结果，并将其作为MPC框架中的终端成本到目标函数，使智能体能够隐含地考虑与其他智能体的交互并最大化其奖励。该方法适用于竞争性和合作性的多智能体运动规划问题，将这类问题形式化为受约束的动态游戏。通过随机采样初始条件并求解广义纳什均衡(GNE)生成GNE解的数据集，从而计算每个游戏理论交互的奖励结果。这些数据被用来训练一个简单的神经网络以预测奖励结果，该网络进而被用作MPC方案中的终端成本到目标函数。实验展示了IGT-MPC在两车对头竞赛和无信号交叉口导航等场景中产生的竞争性和协调性行为。IGT-MPC提供了一种将机器学习与博弈论推理整合进基于模型的分散式多智能体运动规划的新方法。 <div>
arXiv:2411.13983v1 Announce Type: new 
Abstract: We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized algorithm for two-agent motion planning that uses a learned value function that predicts the game-theoretic interaction outcomes as the terminal cost-to-go function in a model predictive control (MPC) framework, guiding agents to implicitly account for interactions with other agents and maximize their reward. This approach applies to competitive and cooperative multi-agent motion planning problems which we formulate as constrained dynamic games. Given a constrained dynamic game, we randomly sample initial conditions and solve for the generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions, computing the reward outcome of each game-theoretic interaction from the GNE. The data is used to train a simple neural network to predict the reward outcome, which we use as the terminal cost-to-go function in an MPC scheme. We showcase emerging competitive and coordinated behaviors using IGT-MPC in scenarios such as two-vehicle head-to-head racing and un-signalized intersection navigation. IGT-MPC offers a novel method integrating machine learning and game-theoretic reasoning into model-based decentralized multi-agent motion planning.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-Layer Blockchain Simulator and Performance Evaluation of Social Internet of Vehicles with Multi-Connectivity Management</title>
<link>https://arxiv.org/abs/2411.14000</link>
<guid>https://arxiv.org/abs/2411.14000</guid>
<content:encoded><![CDATA[
<div> 关键词：V2X通信、区块链技术、分布式、多层架构、资源管理<br /><br />总结:<br />
本文提出了将去中心化的区块链技术与车辆到万物（V2X）通信创新融合的一种多层架构方案，该架构结合了城市交通模拟器SUMO和区块链模拟器BlockSim。随着社交车联网（SIoV）的发展，为保证无缝通信，有效的资源管理变得至关重要。文中还提出了一种名为“增强型MAX-SINR”的多连接性管理参考方法，旨在推进针对区块链特定方法的研究，并考虑重传成功率。通过评估区块链在城市、郊区和农村等不同环境中的性能，文章证明了提高与区块链相关的重传消息的成功率能显著提升区块链交易性能，为构建智能SIoV系统奠定了基础。 <div>
arXiv:2411.14000v1 Announce Type: new 
Abstract: The evolution of vehicle-to-everything (V2X) communication brings significant challenges, such as data integrity and vulnerabilities stemming from centralized management. This paper presents an innovative integration of decentralized blockchain technology with V2X communication through a multi-layered architecture that combines the Simulation of Urban Mobility (SUMO) traffic simulator and the BlockSim blockchain simulator. In addition, as the Social Internet of Vehicles (SIoV) emerges, efficient resource management becomes indispensable for ensuring seamless communication. We also propose a reference multi-connectivity management method named Enhanced MAX-SINR, designed to advance research in blockchain-specific approaches, taking into account retransmission successfull rates. We evaluate blockchain performance in diverse environments such as urban, suburban, and rural areas, demonstrating that enhancing the success rate of retransmitted blockchain-related messages significantly boosts blockchain transaction performance and provides a foundation for developing intelligent SIoV systems.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Adaptive Asynchronous Federated Learning for Human Activity Recognition</title>
<link>https://arxiv.org/abs/2411.14070</link>
<guid>https://arxiv.org/abs/2411.14070</guid>
<content:encoded><![CDATA[
<div> 关键词：多标签分类、极度异构数据、分布式机器学习、联邦学习（FL）、人类活动识别（HAR）

总结:
<br />
本文针对极度异构数据环境下的多标签分类问题以及在物联网场景中应用联邦学习进行了研究。文章聚焦于将人类活动识别（HAR）任务从集中式学习（CL）迁移到FL的挑战，由于HAR数据和设备的多样性导致标签和特征分布的显著偏差。为解决这一问题，文章提出了从集中式到FL迁移的具体解决方案和工具，并强调了需要做出的关键设计决策。利用开源的HAR数据集，实验评估了数据增强、缩放、优化器选择、学习率和批大小等因素对ML模型性能的影响，发现SGD-m优化器、全局特征缩放及在存在异构HAR数据时持续的特征偏斜等问题的重要性。最后，文章提供了Flower框架的一个开源扩展，支持异步FL。 <div>
arXiv:2411.14070v1 Announce Type: new 
Abstract: In this work, we tackle the problem of performing multi-label classification in the case of extremely heterogeneous data and with decentralized Machine Learning. Solving this issue is very important in IoT scenarios, where data coming from various sources, collected by heterogeneous devices, serve the learning of a distributed ML model through Federated Learning (FL). Specifically, we focus on the combination of FL applied to Human Activity Recognition HAR), where the task is to detect which kind of movements or actions individuals perform. In this case, transitioning from centralized learning (CL) to federated learning is non-trivial as HAR displays heterogeneity in action and devices, leading to significant skews in label and feature distributions. We address this scenario by presenting concrete solutions and tools for transitioning from centralized to FL for non-IID scenarios, outlining the main design decisions that need to be taken. Leveraging an open-sourced HAR dataset, we experimentally evaluate the effects that data augmentation, scaling, optimizer, learning rate, and batch size choices have on the performance of resulting machine learning models. Some of our main findings include using SGD-m as an optimizer, global feature scaling across clients, and persistent feature skew in the presence of heterogeneous HAR data. Finally, we provide an open-source extension of the Flower framework that enables asynchronous FL.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>On PI-control in Capacity-Limited Networks</title>
<link>https://arxiv.org/abs/2411.14077</link>
<guid>https://arxiv.org/abs/2411.14077</guid>
<content:encoded><![CDATA[
<div> 关键词：控制、多智能体系统、非线性、抗饱和控制、分布式策略

总结:<br />
本文研究了一类多动态稳定智能体共享非线性、有界控制互联系统的控制问题。当扰动过大，无法通过可用控制动作完全消除，使得无法将所有智能体稳定在期望状态。针对这一非线性环境，文章分析了两种配备抗饱和控制的比例积分控制策略。首先证明了一个全分布式的控制策略能全局渐近地稳定一个唯一的平衡点，且该平衡点使跟踪误差的加权和达到最小。其次，考虑了在此基础上引入 rank-1 协调机制的轻量级改进策略，该策略下的任何平衡点都将确保任一智能体的最大跟踪误差最小化。这些结果的重要特点是它们对智能体间的互联系统假设非常少。最后，文中展示了所考虑模型在区域供暖场景的应用，并通过仿真验证了两种控制器的效果。 <div>
arXiv:2411.14077v1 Announce Type: new 
Abstract: This paper concerns control of a class of systems where multiple dynamically stable agents share a nonlinear and bounded control-interconnection. The agents are subject to a disturbance which is too large to reject with the available control action, making it impossible to stabilize all agents in their desired states. In this nonlinear setting, we consider two different anti-windup equipped proportional-integral control strategies and analyze their properties. We show that a fully decentralized strategy will globally, asymptotically stabilize a unique equilibrium. This equilibrium also minimizes a weighted sum of the tracking errors. We also consider a light addition to the fully decentralized strategy, where rank-1 coordination between the agents is introduced via the anti-windup action. We show that any equilibrium to this closed-loop system minimizes the maximum tracking error for any agent. A remarkable property of these results is that they rely on extremely few assumptions on the interconnection between the agents. Finally we illustrate how the considered model can be applied in a district heating setting, and demonstrate the two considered controllers in a simulation.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-terminal Strong Coordination subject to Secrecy Constraints</title>
<link>https://arxiv.org/abs/2411.14123</link>
<guid>https://arxiv.org/abs/2411.14123</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式网络系统、安全多终端强协调、多址访问窃听信道、编码策略、信息泄露防护

总结:<br />
本文研究了在分布式网络系统中，利用多址访问窃听信道实现安全多终端强协调的问题。要求两个发送方观测到相关源的独立同分布副本并通过该信道进行编码输入，合法接收方需根据接收到的通道输出及与源相关的侧信息生成与源近似独立同分布的输出变量。同时确保外部窃听者通过观察其自身的MAC-WT输出无法获取关于源和模拟输出序列的有效信息。文章提出了结合协调编码和窃听编码的可达成率区域以及外界边界，并展示了当源条件独立于解码器侧信息且合法通道由确定性链接组成时，内界与外界相匹配，完全刻画了此特殊情形下的问题。此外，还分析了一种具有可能的编码器协作情况，其中一个编码器可以非因果地从其他编码器的输入中获取信息，并提出了相应的可达成率区域。文章最后对具有和不具有编码器间 cribbing 的示例进行了具体的率区域计算，证明了cribbing能严格改进可达率区域。 <div>
arXiv:2411.14123v1 Announce Type: new 
Abstract: A fundamental problem in decentralized networked systems is to coordinate actions of different agents so that they reach a state of agreement. In such applications, it is additionally desirable that the actions at various nodes may not be anticipated by malicious eavesdroppers. Motivated by this, we investigate the problem of secure multi-terminal strong coordination aided by a multiple-access wiretap channel. In this setup, independent and identically distributed copies of correlated sources are observed by two transmitters who encode the channel inputs to the MAC-WT. The legitimate receiver observing the channel output and side information correlated with the sources must produce approximately i.i.d. copies of an output variable jointly distributed with the sources. Furthermore, we demand that an external eavesdropper learns essentially nothin g about the sources and the simulated output sequence by observing its own MAC-WT output. This setting is aided by the presence of independent pairwise shared randomness between each encoder and the legitimate decoder, that is unavailable to the eavesdropper. We derive an achievable rate region based on a combination of coordination coding and wiretap coding, along with an outer bound. The inner bound is shown to be tight and a complete characterization is derived for the special case when the sources are conditionally independent given the decoder side information and the legitimate channel is composed of deterministic links. Further, we also analyze a more general scenario with possible encoder cooperation, where one of the encoders can non-causally crib from the other encoders input, for which an achievable rate region is proposed. We then explicitly compute the rate regions for an example both with and without cribbing between the encoders, and demonstrate that cribbing strictly improves upon the achievable rate region.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pulsar Consensus</title>
<link>https://arxiv.org/abs/2411.14245</link>
<guid>https://arxiv.org/abs/2411.14245</guid>
<content:encoded><![CDATA[
<div> 关键词：Pulsar、proof of stake、sidechain、proof of work、chain selection rule

<br /><br />总结：
本文介绍了Pulsar权益证明共识协议，并讨论了相关的设计决策和考量。Pulsar协议旨在促进工作量证明区块链创建权益证明侧链。文章提出了一个新颖的可组合密度基础的链选择规则，该规则可以看作权益证明协议中某些标准最长链规则的超集。文中将Pulsar协议与其他现有的权益证明协议进行了比较，明确了其相较于现有设计的优势，并定义了本工作的局限性。目前，Pulsar协议已实现在Mintlayer权益证明比特币侧链中的实施。 <div>
arXiv:2411.14245v1 Announce Type: new 
Abstract: In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Iteration-Free Cooperative Distributed MPC through Multiparametric Programming</title>
<link>https://arxiv.org/abs/2411.14319</link>
<guid>https://arxiv.org/abs/2411.14319</guid>
<content:encoded><![CDATA[
<div> 关键词：Cooperative Distributed Model Predictive Control (DiMPC)，communication reduction，computational costs，multiparametric (mp) programming，iteration-free算法

<br /><br />总结：

本文提出了基于多参数编程的新型无迭代解算器算法，显著降低了Cooperative Distributed Model Predictive Control (DiMPC)架构中的信息交换量和计算成本。通过将迭代过程替换为同时求解显式mpDiMPC控制律函数的方法，成功减少了局部控制器间的通信，从而降低了系统延迟，这对于实时控制应用至关重要。通过涉及由输入相互连接并通过合作型全局成本函数耦合的线性子系统的全面数值模拟，验证了所提无迭代mpDiMPC算法的有效性。 <div>
arXiv:2411.14319v1 Announce Type: new 
Abstract: Cooperative Distributed Model Predictive Control (DiMPC) architecture employs local MPC controllers to control different subsystems, exchanging information with each other through an iterative procedure to enhance overall control performance compared to the decentralized architecture. However, this method can result in high communication between the controllers and computational costs. In this work, the amount of information exchanged and the computational costs of DiMPC are reduced significantly by developing novel iteration-free solution algorithms based on multiparametric (mp) programming. These algorithms replace the iterative procedure with simultaneous solutions of explicit mpDiMPC control law functions. The reduced communication among local controllers decreases system latency, which is crucial for real-time control applications. The effectiveness of the proposed iteration-free mpDiMPC algorithms is demonstrated through comprehensive numerical simulations involving groups of coupled linear subsystems, which are interconnected through their inputs and a cooperative plant-wide cost function.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Deep Learning Approach to Predict the Fall [of Price] of Cryptocurrency Long Before its Actual Fall</title>
<link>https://arxiv.org/abs/2411.13615</link>
<guid>https://arxiv.org/abs/2411.13615</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币市场、风险因素、波动性、机器学习算法、预测模型

<br /><br />总结:
该研究关注于加密货币市场的风险因素（即波动性）预测问题。针对这一市场高波动性和低流动性的特点，研究提出了一种新的预测方法，运用卷积神经网络（CNN）、长短期记忆网络（LSTM）、双向LSTM和门控循环单元（GRU）等多种机器学习算法对加密货币市场的二十项参数进行风险因素预测。研究人员开发了优于已有模型的新预测模型，其表现最优的RMSE值为0.0089，最差为1.3229，显著优于现有模型中最高RMSE值为14.5092、最低为0.02769的表现。通过此模型，投资者能更好地应对比特币、以太坊、狗狗币等复杂且具有挑战性的金融资产交易。 <div>
arXiv:2411.13615v1 Announce Type: cross 
Abstract: In modern times, the cryptocurrency market is one of the world's most rapidly rising financial markets. The cryptocurrency market is regarded to be more volatile and illiquid than traditional markets such as equities, foreign exchange, and commodities. The risk of this market creates an uncertain condition among the investors. The purpose of this research is to predict the magnitude of the risk factor of the cryptocurrency market. Risk factor is also called volatility. Our approach will assist people who invest in the cryptocurrency market by overcoming the problems and difficulties they experience. Our approach starts with calculating the risk factor of the cryptocurrency market from the existing parameters. In twenty elements of the cryptocurrency market, the risk factor has been predicted using different machine learning algorithms such as CNN, LSTM, BiLSTM, and GRU. All of the models have been applied to the calculated risk factor parameter. A new model has been developed to predict better than the existing models. Our proposed model gives the highest RMSE value of 1.3229 and the lowest RMSE value of 0.0089. Following our model, it will be easier for investors to trade in complicated and challenging financial assets like bitcoin, Ethereum, dogecoin, etc. Where the other existing models, the highest RMSE was 14.5092, and the lower was 0.02769. So, the proposed model performs much better than models with proper generalization. Using our approach, it will be easier for investors to trade in complicated and challenging financial assets like Bitcoin, Ethereum, and Dogecoin.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPARKLE: A Unified Single-Loop Primal-Dual Framework for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2411.14166</link>
<guid>https://arxiv.org/abs/2411.14166</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized bilevel optimization, gradient tracking, EXTRA, Exact Diffusion, SPARKLE

总结:
<br />
本文研究了多智能体协作解决具有嵌套优化结构的去中心化双层优化问题。现有的大多数文献主要利用梯度跟踪来缓解数据异质性的影响，而未充分探索如EXTRA或Exact Diffusion等其他知名的异质性校正技术。此外，这些研究通常对上层和下层问题采用相同的去中心化策略，忽视了在不同层次间运用不同机制的优势。针对以上局限性，文章提出了SPARKLE，即一种统一的单循环 primal-dual 算法框架，用于去中心化双层优化，该框架能灵活地将各种异质性校正策略融入算法，并允许上下层问题采取不同的解决方案。作者为SPARKLE及其变种提供了统一的收敛性分析，并与现有去中心化双层算法相比展现出最先进的收敛速率。结果进一步表明，在去中心化双层优化中，EXTRA和Exact Diffusion更为适用，而在双层算法中混合使用多种策略比单纯依赖梯度跟踪更具优势。 <div>
arXiv:2411.14166v1 Announce Type: cross 
Abstract: This paper studies decentralized bilevel optimization, in which multiple agents collaborate to solve problems involving nested optimization structures with neighborhood communications. Most existing literature primarily utilizes gradient tracking to mitigate the influence of data heterogeneity, without exploring other well-known heterogeneity-correction techniques such as EXTRA or Exact Diffusion. Additionally, these studies often employ identical decentralized strategies for both upper- and lower-level problems, neglecting to leverage distinct mechanisms across different levels. To address these limitations, this paper proposes SPARKLE, a unified Single-loop Primal-dual AlgoRithm frameworK for decentraLized bilEvel optimization. SPARKLE offers the flexibility to incorporate various heterogeneitycorrection strategies into the algorithm. Moreover, SPARKLE allows for different strategies to solve upper- and lower-level problems. We present a unified convergence analysis for SPARKLE, applicable to all its variants, with state-of-the-art convergence rates compared to existing decentralized bilevel algorithms. Our results further reveal that EXTRA and Exact Diffusion are more suitable for decentralized bilevel optimization, and using mixed strategies in bilevel algorithms brings more benefits than relying solely on gradient tracking.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Public sentiments on the fourth industrial revolution: An unsolicited public opinion poll from Twitter</title>
<link>https://arxiv.org/abs/2411.14230</link>
<guid>https://arxiv.org/abs/2411.14230</guid>
<content:encoded><![CDATA[
<div> 关键词：第四次工业革命、社交媒体、情绪分析、机器学习、公共感知

<br /><br />总结：
该文章通过分析六个欧洲国家的社交媒体推文和媒体文章数据，探讨公众对第四次工业革命（4IR）的看法。利用情感分析和机器学习技术，研究发现公众对人工智能、机器人和区块链等技术融入社会的态度呈现显著两极分化，从中立立场转向更为明确的支持或反对态度。正面观点主要关联到科技对生活质量与经济机遇的提升，而担忧则集中在隐私、数据安全及伦理问题上。这表明政策制定者需要积极与公众沟通，以缓解恐惧并利用4IR技术的优势。此外，文章还提倡开展数字素养和公共意识项目，以减少错误信息并促进有关未来技术整合的明智公共讨论。这项研究为如何使科技进步与社会价值观和需求相一致提供了见解，强调了形成有效政策过程中知情公众意见的重要性。 <div>
arXiv:2411.14230v1 Announce Type: cross 
Abstract: This article explores public perceptions on the Fourth Industrial Revolution (4IR) through an analysis of social media discourse across six European countries. Using sentiment analysis and machine learning techniques on a dataset of tweets and media articles, we assess how the public reacts to the integration of technologies such as artificial intelligence, robotics, and blockchain into society. The results highlight a significant polarization of opinions, with a shift from neutral to more definitive stances either embracing or resisting technological impacts. Positive sentiments are often associated with technological enhancements in quality of life and economic opportunities, whereas concerns focus on issues of privacy, data security, and ethical implications. This polarization underscores the need for policymakers to engage proactively with the public to address fears and harness the benefits of 4IR technologies. The findings also advocate for digital literacy and public awareness programs to mitigate misinformation and foster an informed public discourse on future technological integration. This study contributes to the ongoing debate on aligning technological advances with societal values and needs, emphasizing the role of informed public opinion in shaping effective policy.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Aware Data Acquisition under Data Similarity in Regression Markets</title>
<link>https://arxiv.org/abs/2312.02611</link>
<guid>https://arxiv.org/abs/2312.02611</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据市场、数据相似性、隐私偏好、局部差分隐私、Stackelberg游戏

总结:
该文探讨了数据市场上数据相似性和隐私偏好的重要影响，并提出了一个基于局部差分隐私的两方数据获取协议。研究中，作者将隐私意识强的数据拥有者与学习者之间的战略互动分析为一个关于询问价格和隐私因子的Stackelberg游戏，模型应用于回归数据分析市场。文章通过数值分析揭示了数据相似性如何影响市场的参与度及交易数据的价值。 <div>
arXiv:2312.02611v2 Announce Type: replace 
Abstract: Data markets facilitate decentralized data exchange for applications such as prediction, learning, or inference. The design of these markets is challenged by varying privacy preferences as well as data similarity among data owners. Related works have often overlooked how data similarity impacts pricing and data value through statistical information leakage. We demonstrate that data similarity and privacy preferences are integral to market design and propose a query-response protocol using local differential privacy for a two-party data acquisition mechanism. In our regression data market model, we analyze strategic interactions between privacy-aware owners and the learner as a Stackelberg game over the asked price and privacy factor. Finally, we numerically evaluate how data similarity affects market participation and traded data value.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Structured stability analysis of networked systems with uncertain links</title>
<link>https://arxiv.org/abs/2403.14931</link>
<guid>https://arxiv.org/abs/2403.14931</guid>
<content:encoded><![CDATA[
<div> 关键词：网络系统、不确定链接动力学、输入-输出方法、稳定性分析、积分二次约束

总结:<br />
该文针对具有不确定链路动态的网络系统，探索了一种基于输入-输出的稳定性分析方法。主要成果是一组积分二次约束条件，当理想链接下系统达到稳定性时，这些条件共同确保了不确定网络系统的鲁棒稳定性。这些条件具备分散性特点，每个仅涉及对应链接的局部代理和不确定性模型参数，因此该主要结果对于无特定网络结构限制的大规模系统研究非常适用。 <div>
arXiv:2403.14931v2 Announce Type: replace 
Abstract: An input-output approach to stability analysis is explored for networked systems with uncertain link dynamics. The main result consists of a collection of integral quadratic constraints, which together imply robust stability of the uncertain networked system, under the assumption that stability is achieved with ideal links. The conditions are decentralized inasmuch as each involves only agent and uncertainty model parameters that are local to a corresponding link. This makes the main result, which imposes no restriction on network structure, suitable for the study of large-scale systems.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TrustMesh: A Blockchain-Enabled Trusted Distributed Computing Framework for Open Heterogeneous IoT Environments</title>
<link>https://arxiv.org/abs/2411.13039</link>
<guid>https://arxiv.org/abs/2411.13039</guid>
<content:encoded><![CDATA[
<div> 关键词: TrustMesh、区块链、物联网(IoT)、分布式计算、拜占庭容错(PBFT)

<br /><br />总结:
本文提出了TrustMesh，一个创新的区块链驱动的框架，旨在解决物联网环境下安全可信的分布式计算问题。TrustMesh采用独特的三层架构，结合了许可型区块链技术和一种新颖的多阶段实用拜占庭容错(PBFT)共识协议。其关键创新在于能在支持非确定性调度算法的同时保持拜占庭容错特性，这是传统区块链系统中难以兼得的。此外，该框架还具备灵活的资源管理方法，可在保证区块链验证安全性的同时实现灵活的调度决策。实验结果显示，在实际的冷链监测场景下，TrustMesh能够在150毫秒内的故障检测延迟下维持拜占庭容错，并在不同计算负载和网络扩展情况下保持一致的框架开销。这些结果证明了TrustMesh在无信任物联网环境中平衡安全、性能和灵活性需求的能力，从而推动了安全分布式计算框架领域的前沿进展。 <div>
arXiv:2411.13039v1 Announce Type: new 
Abstract: The rapid evolution of Internet of Things (IoT) environments has created an urgent need for secure and trustworthy distributed computing systems, particularly when dealing with heterogeneous devices and applications where centralized trust cannot be assumed. This paper proposes TrustMesh, a novel blockchain-enabled framework that addresses these challenges through a unique three-layer architecture combining permissioned blockchain technology with a novel multi-phase Practical Byzantine Fault Tolerance (PBFT) consensus protocol. The key innovation lies in TrustMesh's ability to support non-deterministic scheduling algorithms while maintaining Byzantine fault tolerance - features traditionally considered mutually exclusive in blockchain systems. The framework supports a sophisticated resource management approach that enables flexible scheduling decisions while preserving the security guarantees of blockchain-based verification. Our experimental evaluation using a real-world cold chain monitoring scenario demonstrates that TrustMesh successfully maintains Byzantine fault tolerance with fault detection latencies under 150 milliseconds, while maintaining consistent framework overhead across varying computational workloads even with network scaling. These results establish TrustMesh's effectiveness in balancing security, performance, and flexibility requirements in trustless IoT environments, advancing the state-of-the-art in secure distributed computing frameworks.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Enhanced Framework for Secure Third-Party Vendor Risk Management and Vigilant Security Controls</title>
<link>https://arxiv.org/abs/2411.13447</link>
<guid>https://arxiv.org/abs/2411.13447</guid>
<content:encoded><![CDATA[
<div> 关键词: 第三方供应商风险、区块链技术、安全框架、智能合约、持续监控

总结:
本文提出了一种综合安全框架，用于管理第三方供应商风险，并整合了区块链技术以确保评估和交互过程中的透明度、可追溯性和不可篡改性。该框架利用区块链增强了供应商安全审计的完整性，并通过智能合约减少人为错误，实现实时合规与安全控制监测。重点强调了对数据加密、访问控制机制、多因素认证和零信任架构等关键安全控制的评估。通过区块链实现的持续监控确保了供应商合规流程的不变性和透明度。文中通过iHealth迁移到AWS云的案例研究展示了该框架的实际应用，结果显示显著降低了漏洞并提高了事件响应时间。采用这种区块链赋能的方法，组织可以有效降低供应商风险、简化合规流程并提升整体安全态势。 <div>
arXiv:2411.13447v1 Announce Type: new 
Abstract: In an era of heightened digital interconnectedness, businesses increasingly rely on third-party vendors to enhance their operational capabilities. However, this growing dependency introduces significant security risks, making it crucial to develop a robust framework to mitigate potential vulnerabilities. This paper proposes a comprehensive secure framework for managing third-party vendor risk, integrating blockchain technology to ensure transparency, traceability, and immutability in vendor assessments and interactions. By leveraging blockchain, the framework enhances the integrity of vendor security audits, ensuring that vendor assessments remain up-to-date and tamperproof. This proposed framework leverages smart contracts to reduce human error while ensuring real-time monitoring of compliance and security controls. By evaluating critical security controls-such as data encryption, access control mechanisms, multi-factor authentication, and zero-trust architecture-this approach strengthens an organization's defense against emerging cyber threats. Additionally, continuous monitoring enabled by blockchain ensures the immutability and transparency of vendor compliance processes. In this paper, a case study on iHealth's transition to AWS Cloud demonstrates the practical implementation of the framework, showing a significant reduction in vulnerabilities and marked improvement in incident response times. Through the adoption of this blockchain-enabled approach, organizations can mitigate vendor risks, streamline compliance, and enhance their overall security posture.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinBERT-BiLSTM: A Deep Learning Model for Predicting Volatile Cryptocurrency Market Prices Using Market Sentiment Dynamics</title>
<link>https://arxiv.org/abs/2411.12748</link>
<guid>https://arxiv.org/abs/2411.12748</guid>
<content:encoded><![CDATA[
<div> 关键词: 时间序列预测、金融市场、加密货币、深度学习模型、Bi-LSTM + FinBERT 混合模型

总结:<br />
本文介绍了时间序列预测在金融市场的关键作用，特别是在波动性极高的比特币和以太坊等加密货币市场中的应用。传统方法已难以应对这类市场的极端价格波动，因此研究转向了如LSTM、Bi-LSTM及FinBERT等深度学习模型。鉴于此，文章提出了一种混合模型，将双向长短时记忆网络（Bi-LSTM）与专门用于金融领域的FinBERT结合，旨在提升加密货币价格预测的准确性。这一创新方法融合了高级时间序列模型与情绪分析，为投资者和分析师在不确定性的金融市场中提供更为有价值的决策依据。 <div>
arXiv:2411.12748v1 Announce Type: cross 
Abstract: Time series forecasting is a key tool in financial markets, helping to predict asset prices and guide investment decisions. In highly volatile markets, such as cryptocurrencies like Bitcoin (BTC) and Ethereum (ETH), forecasting becomes more difficult due to extreme price fluctuations driven by market sentiment, technological changes, and regulatory shifts. Traditionally, forecasting relied on statistical methods, but as markets became more complex, deep learning models like LSTM, Bi-LSTM, and the newer FinBERT-LSTM emerged to capture intricate patterns. Building upon recent advancements and addressing the volatility inherent in cryptocurrency markets, we propose a hybrid model that combines Bidirectional Long Short-Term Memory (Bi-LSTM) networks with FinBERT to enhance forecasting accuracy for these assets. This approach fills a key gap in forecasting volatile financial markets by blending advanced time series models with sentiment analysis, offering valuable insights for investors and analysts navigating unpredictable markets.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Supervised Autoencoders with Fractionally Differentiated Features and Triple Barrier Labelling Enhance Predictions on Noisy Data</title>
<link>https://arxiv.org/abs/2411.12753</link>
<guid>https://arxiv.org/abs/2411.12753</guid>
<content:encoded><![CDATA[
<div> 关键词：神经网络、监督自编码器(SAE)、噪声增强、三重障碍标签、风险调整回报

总结:<br />
本文研究了利用神经网络中的监督自编码器（SAE）来提升金融时间序列预测的准确性，旨在改善投资策略的表现。研究期间选取了比特币、莱特币和以太坊作为交易资产，时间段为2016年1月1日至2022年4月30日。结果表明，采用平衡噪声增强与适当瓶颈大小的监督自编码器能显著提高策略的有效性。然而，过多的噪声以及过大的瓶颈尺寸可能会对性能产生负面影响。 <div>
arXiv:2411.12753v1 Announce Type: cross 
Abstract: This paper investigates the enhancement of financial time series forecasting with the use of neural networks through supervised autoencoders (SAE), to improve investment strategy performance. Using the Sharpe and Information Ratios, it specifically examines the impact of noise augmentation and triple barrier labeling on risk-adjusted returns. The study focuses on Bitcoin, Litecoin, and Ethereum as the traded assets from January 1, 2016, to April 30, 2022. Findings indicate that supervised autoencoders, with balanced noise augmentation and bottleneck size, significantly boost strategy effectiveness. However, excessive noise and large bottleneck sizes can impair performance.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy</title>
<link>https://arxiv.org/abs/2411.12756</link>
<guid>https://arxiv.org/abs/2411.12756</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、阿尔茨海默症分类、迁移学习、联邦学习、数据隐私

总结:
<br />
本文提出了一种新的阿尔茨海默症分类方法，该方法结合了先进的深度学习技术和安全的数据处理方法。研究主要利用ResNet、ImageNet和VNet等预训练模型从医学图像数据中提取高层特征，并针对阿尔茨海默症的相关细微模式对这些模型进行微调，以实现对不同数据源的鲁棒性特征提取。此外，为了提高预测性能并保护数据隐私，文中还引入了联邦学习方法。通过采用联邦学习的方式构建模型，无需共享敏感患者数据即可实现分布式训练，同时确保数据的保密性和完整性。为保障在整个训练与分类过程中的患者信息安全，还采用了基于密码学的加密机制。实验结果表明，这种方法不仅提高了阿尔茨海默症分类的准确性，而且还提供了一个用于安全、协作分析医疗健康数据的框架。 <div>
arXiv:2411.12756v1 Announce Type: cross 
Abstract: This research work introduces a novel approach to the classification of Alzheimer's disease by using the advanced deep learning techniques combined with secure data processing methods. This research work primary uses transfer learning models such as ResNet, ImageNet, and VNet to extract high-level features from medical image data. Thereafter, these pre-trained models were fine-tuned for Alzheimer's related subtle patterns such that the model is capable of robust feature extraction over varying data sources. Further, the federated learning approaches were incorporated to tackle a few other challenges related to classification, aimed to provide better prediction performance and protect data privacy. The proposed model was built using federated learning without sharing sensitive patient data. This way, the decentralized model benefits from the large and diversified dataset that it is trained upon while ensuring confidentiality. The cipher-based encryption mechanism is added that allows us to secure the transportation of data and further ensure the privacy and integrity of patient information throughout training and classification. The results of the experiments not only help to improve the accuracy of the classification of Alzheimer's but at the same time provides a framework for secure and collaborative analysis of health care data.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Delegating Data Collection in Decentralized Machine Learning</title>
<link>https://arxiv.org/abs/2309.01837</link>
<guid>https://arxiv.org/abs/2309.01837</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、机器学习、数据收集、合同理论、信息不对称

<br /><br />总结:
本文针对去中心化机器学习生态系统中出现的数据收集委托问题，结合合同理论进行研究。文章探讨了在此场景下两种基本的信息不对称性：模型质量评估的不确定性以及对最优模型性能的不确定。文中设计了实现近似最优效用的简单线性合同，并表明通过这种合同，主体可以应对上述不对称性，达到理想效用的1-1/e比例。为解决关于最优性能的未知问题，文章提出了一种能自适应并高效计算最优合同的凸优化程序。此外，对于多次交互的复杂环境，文中还研究了线性合同并得出了最优效用情况。 <div>
arXiv:2309.01837v3 Announce Type: replace 
Abstract: Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve 1-1/e fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also study linear contracts and derive the optimal utility in the more complex setting of multiple interactions.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction</title>
<link>https://arxiv.org/abs/2411.11894</link>
<guid>https://arxiv.org/abs/2411.11894</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse网络流量预测、扩展现实(XR)服务、测试床、视帧(VF)算法、ResLearn、Transformer、错误学习、资源管理、服务质量(QoS)、用户体验。

<br /><br />总结:
本文提出了一种针对Metaverse网络流量预测的全面解决方案，旨在满足扩展现实(XR)服务中智能资源管理的需求。研究内容包括建立一个先进的测试床，用于收集并公开虚拟现实(VR)、增强现实(AR)和混合现实(MR)的真实世界交通数据。为了提高预测精度，文章提出了一种名为视帧(VF)的新型算法，该算法能准确识别流量中的视频帧并确保隐私合规性。此外，还开发了一种基于Transformer的递进误差学习算法——ResLearn，该算法利用全连接神经网络减少预测错误，特别是在高峰流量时段，相较于先前工作提高了99%的性能。这些贡献为互联网服务提供商(ISPs)提供了实时网络管理的强大工具，以满足Metaverse中的服务质量(QoS)需求并提升用户体验。 <div>
arXiv:2411.11894v1 Announce Type: new 
Abstract: Our work proposes a comprehensive solution for predicting Metaverse network traffic, addressing the growing demand for intelligent resource management in eXtended Reality (XR) services. We first introduce a state-of-the-art testbed capturing a real-world dataset of virtual reality (VR), augmented reality (AR), and mixed reality (MR) traffic, made openly available for further research. To enhance prediction accuracy, we then propose a novel view-frame (VF) algorithm that accurately identifies video frames from traffic while ensuring privacy compliance, and we develop a Transformer-based progressive error-learning algorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn significantly improves time-series predictions by using fully connected neural networks to reduce errors, particularly during peak traffic, outperforming prior work by 99%. Our contributions offer Internet service providers (ISPs) robust tools for real-time network management to satisfy Quality of Service (QoS) and enhance user experience in the Metaverse.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simultaneous Ground Reaction Force and State Estimation via Constrained Moving Horizon Estimation</title>
<link>https://arxiv.org/abs/2411.12047</link>
<guid>https://arxiv.org/abs/2411.12047</guid>
<content:encoded><![CDATA[
<div> 关键词：地面反作用力估计、腿部机器人、状态估计、运动 horizon 估计（MHE）、漂移基座

总结:<br />
本文提出了一种针对腿部机器人的同时地面反作用力和状态估计框架。该框架系统性地解决了传感器噪声问题以及状态与动力学之间的耦合问题。通过单独估计浮动基座姿态，采用分散式的运动 Horizon 估计方法，将机器人动力学、本体感觉传感器、外感觉传感器及确定性的接触互补约束融合在一个凸优化的窗口化问题中。实验表明，该方法能够在频率为 200Hz 和过去时间窗口为 0.04s 的条件下，对包括开源教育平面双足机器人 STRIDE 和四足机器人 Unitree Go1 在内的多种腿部机器人实现准确的地面反作用力和状态估计。 <div>
arXiv:2411.12047v1 Announce Type: new 
Abstract: Accurate ground reaction force (GRF) estimation can significantly improve the adaptability of legged robots in various real-world applications. For instance, with estimated GRF and contact kinematics, the locomotion control and planning assist the robot in overcoming uncertain terrains. The canonical momentum-based methods, formulated as nonlinear observers, do not fully address the noisy measurements and the dependence between floating base states and the generalized momentum dynamics. In this paper, we present a simultaneous ground reaction force and state estimation framework for legged robots, which systematically addresses the sensor noise and the coupling between states and dynamics. With the floating base orientation estimated separately, a decentralized Moving Horizon Estimation (MHE) method is implemented to fuse the robot dynamics, proprioceptive sensors, exteroceptive sensors, and deterministic contact complementarity constraints in a convex windowed optimization. The proposed method is shown to be capable of providing accurate GRF and state estimation on several legged robots, including the open-source educational planar bipedal robot STRIDE and quadrupedal robot Unitree Go1, with a frequency of 200Hz and a past time window of 0.04s.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning</title>
<link>https://arxiv.org/abs/2411.12220</link>
<guid>https://arxiv.org/abs/2411.12220</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、backdoor attacks（后门攻击）、DeTrigger、gradient analysis（梯度分析）、temperature scaling（温度缩放）

<br /><br />总结:

本文提出了一个名为DeTrigger的可扩展且高效的抵御后门攻击的联邦学习框架。DeTrigger利用对抗性攻击方法的洞察力，通过结合梯度分析与温度缩放技术来检测和隔离后门触发器，并精确地进行模型权重剪枝以去除后门激活部分，同时尽量保全正常模型知识。实验表明，DeTrigger相比于传统方法能实现高达251倍的更快检测速度，并能有效缓解高达98.9%的后门攻击，对全局模型准确性的影响极小。因此，DeTrigger被认为是保护联邦学习环境免受复杂后门威胁的一种健壮且可扩展的解决方案。 <div>
arXiv:2411.12220v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across distributed devices while preserving local data privacy, making it ideal for mobile and embedded systems. However, the decentralized nature of FL also opens vulnerabilities to model poisoning attacks, particularly backdoor attacks, where adversaries implant trigger patterns to manipulate model predictions. In this paper, we propose DeTrigger, a scalable and efficient backdoor-robust federated learning framework that leverages insights from adversarial attack methodologies. By employing gradient analysis with temperature scaling, DeTrigger detects and isolates backdoor triggers, allowing for precise model weight pruning of backdoor activations without sacrificing benign model knowledge. Extensive evaluations across four widely used datasets demonstrate that DeTrigger achieves up to 251x faster detection than traditional methods and mitigates backdoor attacks by up to 98.9%, with minimal impact on global model accuracy. Our findings establish DeTrigger as a robust and scalable solution to protect federated learning environments against sophisticated backdoor threats.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hyper-parameter Optimization for Federated Learning with Step-wise Adaptive Mechanism</title>
<link>https://arxiv.org/abs/2411.12244</link>
<guid>https://arxiv.org/abs/2411.12244</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Automated Machine Learning (Auto-ML), Hyper-Parameter Optimization (HPO), Raytune, Optuna

<br /><br />总结:
本文研究了在联邦学习（FL）环境中部署和整合两个轻量级超参数优化工具——Raytune和Optuna的方法。针对FL中大量客户端及服务器间的全局训练轮次带来的调参过程耗时、资源受限的问题，文章提出了一种逐步反馈机制，加速超参数调优过程，并协调Auto-ML工具包与FL服务器之间的协作。同时，结合局部和全局反馈机制缩小搜索空间，加快HPO进程。此外，还引入了一种新的客户端选择技术来缓解Auto-FL中的“拖尾”效应。通过FEMNIST和CIFAR10两个基准数据集对该方法进行了评估。文章最后讨论了成功HPO工具应具备的关键属性以及其与FL流水线的集成机制，同时指出了FL环境分布式和异构性所带来的挑战。 <div>
arXiv:2411.12244v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized learning approach that protects sensitive information by utilizing local model parameters rather than sharing clients' raw datasets. While this privacy-preserving method is widely employed across various applications, it still requires significant development and optimization. Automated Machine Learning (Auto-ML) has been adapted for reducing the need for manual adjustments. Previous studies have explored the integration of AutoML with different FL algorithms to evaluate their effectiveness in enhancing FL settings. However, Automated FL (Auto-FL) faces additional challenges due to the involvement of a large cohort of clients and global training rounds between clients and the server, rendering the tuning process time-consuming and nearly impossible on resource-constrained edge devices (e.g., IoT devices). This paper investigates the deployment and integration of two lightweight Hyper-Parameter Optimization (HPO) tools, Raytune and Optuna, within the context of FL settings. A step-wise feedback mechanism has also been designed to accelerate the hyper-parameter tuning process and coordinate AutoML toolkits with the FL server. To this end, both local and global feedback mechanisms are integrated to limit the search space and expedite the HPO process. Further, a novel client selection technique is introduced to mitigate the straggler effect in Auto-FL. The selected hyper-parameter tuning tools are evaluated using two benchmark datasets, FEMNIST, and CIFAR10. Further, the paper discusses the essential properties of successful HPO tools, the integration mechanism with the FL pipeline, and the challenges posed by the distributed and heterogeneous nature of FL environments.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging NFTs for Spectrum Securitization in 6G Networks</title>
<link>https://arxiv.org/abs/2411.12347</link>
<guid>https://arxiv.org/abs/2411.12347</guid>
<content:encoded><![CDATA[
<div> 关键词：动态频谱共享、激励机制、ERC404标准、非同质化代币、同质化代币

总结:
<br />
本文提出了基于ERC404标准并结合非同质化代币（NFT）和同质化代币（FT）技术的频谱证券化模型，旨在激励原始用户积极分享其频谱资源。通过该模型，在以太坊测试网络上实现动态频谱资源共享的有效促进，进而提高频谱资源利用率。 <div>
arXiv:2411.12347v1 Announce Type: new 
Abstract: Dynamic Spectrum Sharing can enhance spectrum resource utilization by promoting the dynamic distribution of spectrum resources. However, to effectively implement dynamic spectrum resource allocation, certain mechanisms are needed to incentivize primary users to proactively share their spectrum resources. This paper, based on the ERC404 standard and integrating Non-Fungible Token and Fungible Token technologies, proposes a spectrum securitization model to incentivize spectrum resource sharing and implements it on the Ethereum test net.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Centralized RAN to Open RAN: A Survey on the Evolution of Distributed Antenna Systems</title>
<link>https://arxiv.org/abs/2411.12166</link>
<guid>https://arxiv.org/abs/2411.12166</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式天线系统(DAS), 无线接入网(RAN), 云无线接入网(C-RAN), 雾无线接入网(F-RAN), 开放无线接入网(O-RAN)

<br /><br />总结:
本文对分布式天线系统（DAS）进行了全面的调查研究，探讨了从传统分散式RAN向DAS演进的各种架构，包括云无线接入网（C-RAN）、雾无线接入网（F-RAN）、虚拟化无线接入网（V-RAN）、无细胞大规模多输入多输出（CF-mMIMO）以及最新的开放无线接入网（O-RAN）。文章分析了这些架构的优势和局限性，如有限容量的前传链路、上行/下行协作编码策略、跨层优化及DAS性能优化技术。同时，文中还介绍了下一代RAN系统的关键使能技术，如边缘计算、网络功能虚拟化、软件定义网络和网络切片，以及重要的无线接入技术，如毫米波、大规模多输入多输出、设备到设备通信和大规模机器类型通信。最后，文章指出了DAS领域的重大研究挑战并提出了未来可能的研究方向。 <div>
arXiv:2411.12166v1 Announce Type: cross 
Abstract: Next-generation mobile networks require evolved radio access network (RAN) architectures to meet the demands of high capacity, massive connectivity, reduced costs, and energy efficiency, and to realize communication with ultra-low latency and ultra-high reliability. {Meeting such} requirements for both mobile users and vertical industries in the next decade {requires novel solutions. One of the potential solutions that attracted significant research attention in the past 15 years} is to redesign the radio access network (RAN). In this survey, we present a comprehensive survey on distributed antenna system (DAS) architectures that address these challenges and improve network performance. We cover the transition from traditional decentralized RAN to DAS, including cloud radio-access networks (C-RAN), fog radio-access networks (F-RAN), virtualized radio-access networks (V-RAN), cell-free massive multiple-input multiple-output (CF-mMIMO), and {the most recent advances manifested in} open radio-access network (O-RAN). In the process, we discuss the benefits and limitations of these architectures, including the impact of limited-capacity fronthaul links, various cooperative uplink and downlink coding strategies, cross-layer optimization, and techniques to optimize the performance of DAS. Moreover, we review key enabling technologies for next-generation RAN systems, such as multi-access edge computing, network function virtualization, software-defined networking, and network slicing; in addition to some crucial radio access technologies, such as millimeter wave, massive multi-input multi-output, device-to-device communication, and massive machine-type communication. Last but not least, we discuss the major research challenges in DAS and identify several possible directions for future research.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Adaptive Motion Planning with Nonlinear Model Predictive Control for Safety-Critical Collaborative Loco-Manipulation</title>
<link>https://arxiv.org/abs/2411.10699</link>
<guid>https://arxiv.org/abs/2411.10699</guid>
<content:encoded><![CDATA[
<div> 关键词：legged机器人、多机器人任务、安全、层次化控制系统、非线性模型预测控制

<br />
总结:
本文提出了一种用于四足机器人团队协同对象操作的层次化控制系统，重点关注在工业和自主建筑领域的应用。该系统确保了复杂场景中多机器人任务的安全性。文章的关键点包括：<br />
1. 针对大型重物处理的需求，强调了多足机器人协作操纵的重要性以及安全性保证。<br />
2. 提出了一种层次化的控制系统，结合运动规划器与去中心化的步态控制器，实现安全、适应性的团队规划。<br />
3. 高层采用非线性模型预测控制规划器生成避免碰撞的路径，通过控制 Barrier 函数考虑静态和动态障碍物，同时计算接触点和力并适应未知物体及地形属性。<br />
4. 去中心化的loco-manipulation控制器确保每个机器人能在规划器指导下保持稳定的步态和操纵功能。<br />
5. 通过模拟实验和真实硬件实验验证了方法的有效性，机器人团队能根据对象配置穿越含有静态和动态障碍物的环境。相关代码已在开源仓库发布。 <div>
arXiv:2411.10699v1 Announce Type: new 
Abstract: As legged robots take on roles in industrial and autonomous construction, collaborative loco-manipulation is crucial for handling large and heavy objects that exceed the capabilities of a single robot. However, ensuring the safety of these multi-robot tasks is essential to prevent accidents and guarantee reliable operation. This paper presents a hierarchical control system for object manipulation using a team of quadrupedal robots. The combination of the motion planner and the decentralized locomotion controller in a hierarchical structure enables safe, adaptive planning for teams in complex scenarios. A high-level nonlinear model predictive control planner generates collision-free paths by incorporating control barrier functions, accounting for static and dynamic obstacles. This process involves calculating contact points and forces while adapting to unknown objects and terrain properties. The decentralized loco-manipulation controller then ensures each robot maintains stable locomotion and manipulation based on the planner's guidance. The effectiveness of our method is carefully examined in simulations under various conditions and validated in real-life setups with robot hardware. By modifying the object's configuration, the robot team can maneuver unknown objects through an environment containing both static and dynamic obstacles. We have made our code publicly available in an open-source repository at \url{https://github.com/DRCL-USC/collaborative_loco_manipulation}.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Task Offloading for Vehicular Edge Computing Based on Improved Hotstuff under Parking Assistance</title>
<link>https://arxiv.org/abs/2411.10770</link>
<guid>https://arxiv.org/abs/2411.10770</guid>
<content:encoded><![CDATA[
<div> 关键词：Parked-assisted vehicular edge computing (PVEC), 区块链, 任务卸载, 共识节点选择, 游戏模型<br /><br />总结：<br />
本文提出了一种基于区块链的停车辅助车联网边缘计算（BPVEC）卸载框架，旨在增强任务卸载和交易的安全性和可靠性。该框架利用连接支配集（CDS）的共识节点选择算法改进了Hotstuff共识，以根据停车时间、计算能力和通信质量提升区块链在计算卸载和交易过程中的可靠性。同时，文章构建了一个双层Stackelberg游戏模型，将路侧单元（RSUs）和停车车辆（PVs）作为领导者，请求车辆（RVs）作为跟随者，以此优化卸载策略和定价。通过梯度下降法设计了BPVEC卸载策略算法来最大化系统收益。仿真结果显示，所提出的BPVEC卸载方案能够在确保最大利益的同时，实现安全可靠的运行。 <div>
arXiv:2411.10770v1 Announce Type: new 
Abstract: Parked-assisted vehicular edge computing (PVEC) fully leverages communication and computing resources of parking vehicles, thereby significantly alleviating the pressure on edge servers. However, resource sharing and trading for vehicular task offloading in the PVEC environment usually occur between untrustworthy entities, which compromises the security of data sharing and transactions by vehicles and edge devices. To address these concerns, blockchain is introduced to provide a secure and trustworthy environment for offloading and transactions in PVEC. Nevertheless, due to the mobility of the vehicles, the processes of computing offloading and blockchain transactions are interrupted, which greatly reduces the reliability of the blockchain in edge computing process. In this paper, we propose a blockchain-based PVEC (BPVEC) offloading framework to enhance the security and reliability of the task offloading and transaction. Specifically, a consensus node selection algorithm based on the connected dominating set (CDS) is designed to improve the Hotstuff consensus according to parking time, computing capability and communication quality, which enhances blockchain reliability in computing offloading and transactions. Meanwhile, a Stackelberg game model, establishing the roadside units (RSUs) and parking vehicles (PVs) as leaders and the requesting vehicles (RVs) as follower, is utilized to optimize the offloading strategy and pricing. Subsequently, a BPVEC offloading strategy algorithm with gradient descent method is designed to maximize system revenue. Simulation results show that the proposed BPVEC offloading scheme is secure and reliable while ensuring maximum benefits.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Relative Over-Generalization in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.11099</link>
<guid>https://arxiv.org/abs/2411.11099</guid>
<content:encoded><![CDATA[
<div> 关键词: decentralized multi-agent reinforcement learning, relative over-generalization, MaxMax Q-Learning (MMQ), optimal joint policy, sample efficiency

<br /><br />总结:
本文提出了一种解决去中心化多智能体强化学习中相对过泛化问题的新方法——setMax Q-Learning (MMQ)。该方法通过迭代采样和评估潜在的下一个状态，并选择具有最大Q值的状态进行学习，从而更好地逼近协作智能体的理想联合策略。理论分析表明MMQ具有潜力，实验结果证实了在易出现相对过泛化的各种环境中，MMQ相对于现有基线更常表现出更好的收敛性和样本效率。 <div>
arXiv:2411.11099v1 Announce Type: new 
Abstract: In decentralized multi-agent reinforcement learning, agents learning in isolation can lead to relative over-generalization (RO), where optimal joint actions are undervalued in favor of suboptimal ones. This hinders effective coordination in cooperative tasks, as agents tend to choose actions that are individually rational but collectively suboptimal. To address this issue, we introduce MaxMax Q-Learning (MMQ), which employs an iterative process of sampling and evaluating potential next states, selecting those with maximal Q-values for learning. This approach refines approximations of ideal state transitions, aligning more closely with the optimal joint policy of collaborating agents. We provide theoretical analysis supporting MMQ's potential and present empirical evaluations across various environments susceptible to RO. Our results demonstrate that MMQ frequently outperforms existing baselines, exhibiting enhanced convergence and sample efficiency.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Emergent Structure in Multi-agent Systems Using Geometric Embeddings</title>
<link>https://arxiv.org/abs/2411.11142</link>
<guid>https://arxiv.org/abs/2411.11142</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、无人机、自组织、局部观测、虚拟嵌入<br /><br />总结: 本文研究了多智能体系统如何自组织形成封闭轨迹，这是无人机监控任务中的常见需求。为实现这一目标，提出了一个去中心化的控制系统架构，该架构仅基于本地观察信息即可产生全局稳定的 emergent 结构，无需各个代理共享全球计划或遵循预设路径。核心在于利用从实际代理人位置诱导的旋转形成的单射虚拟嵌入。此嵌入作为结构保持映射，使得所有代理稳定其相对位置并允许使用成熟的线性控制技术。通过构造使嵌入与期望轨迹（即同胚）具有相同拓扑性质，从而保持稳定性特性。文章通过在一组Quanser QDrone四旋翼无人机上实施该方法，展示了其实现无人机群自组织到期望轨迹同时保持均匀间距的灵活性和有效性。 <div>
arXiv:2411.11142v1 Announce Type: new 
Abstract: This work investigates the self-organization of multi-agent systems into closed trajectories, a common requirement in unmanned aerial vehicle (UAV) surveillance tasks. In such scenarios, smooth, unbiased control signals save energy and mitigate mechanical strain. We propose a decentralized control system architecture that produces a globally stable emergent structure from local observations only; there is no requirement for agents to share a global plan or follow prescribed trajectories. Central to our approach is the formulation of an injective virtual embedding induced by rotations from the actual agent positions. This embedding serves as a structure-preserving map around which all agent stabilize their relative positions and permits the use of well-established linear control techniques. We construct the embedding such that it is topologically equivalent to the desired trajectory (i.e., a homeomorphism), thereby preserving the stability characteristics. We demonstrate the versatility of this approach through implementation on a swarm of Quanser QDrone quadcopters. Results demonstrate the quadcopters self-organize into the desired trajectory while maintaining even separation.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Signaling and Social Learning in Swarms of Robots</title>
<link>https://arxiv.org/abs/2411.11616</link>
<guid>https://arxiv.org/abs/2411.11616</guid>
<content:encoded><![CDATA[
<div> 关键词：communication, coordination, robot swarms, learning, decentralized

总结:
本文研究了通信在改善机器人 Swarm 中协调性方面的作用，重点关注同时进行学习和执行的分布式环境。文章强调了通信在解决功劳分配问题（个体对整体性能的贡献）以及它如何受此影响的重要性。文中提出了一种关于通信的分类体系，主要分为信息选择和物理抽象两个轴线，从低层次的无损压缩与原始信号提取处理到高层次的有损压缩与结构化通信模型。通过对进化机器人、多智能体（深度）强化学习、语言模型和生物物理模型等领域的现有研究进行回顾，文章概述了在通过局部消息交换不断从彼此中学习的集体机器人中，通信所面临的挑战与机遇，展示了一种社会学习的形式。<br /><br /> <div>
arXiv:2411.11616v1 Announce Type: new 
Abstract: This paper investigates the role of communication in improving coordination within robot swarms, focusing on a paradigm where learning and execution occur simultaneously in a decentralized manner. We highlight the role communication can play in addressing the credit assignment problem (individual contribution to the overall performance), and how it can be influenced by it. We propose a taxonomy of existing and future works on communication, focusing on information selection and physical abstraction as principal axes for classification: from low-level lossless compression with raw signal extraction and processing to high-level lossy compression with structured communication models. The paper reviews current research from evolutionary robotics, multi-agent (deep) reinforcement learning, language models, and biophysics models to outline the challenges and opportunities of communication in a collective of robots that continuously learn from one another through local message exchanges, illustrating a form of social learning.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Incremental Named Entity Recognition</title>
<link>https://arxiv.org/abs/2411.11623</link>
<guid>https://arxiv.org/abs/2411.11623</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Named Entity Recognition (FNER), Federated Incremental NER, Local-Global Forgetting Defense (LGFD), 知识蒸馏, 异型对比学习

总结:
本文提出了一种针对联邦增量命名实体识别（Federated Incremental NER）问题的解决方案，该问题涉及到连续出现新实体类型和不定期加入的新客户端。为了解决此问题，研究者们提出了局部-全局遗忘防御（LGFD）模型。针对客户端内部遗忘的问题，LGFD模型采用结构知识蒸馏损失以保持潜在空间的特征结构，并利用伪标签引导的异型对比损失增强不同实体类型的判别能力，有效保存了先前学到的知识。对于客户端间遗忘的挑战，LGFD模型设计了一个任务切换监控器，能够在保护隐私的前提下自动识别新实体类型，并存储最新的旧全局模型用于知识蒸馏和伪标签生成。实验结果显示，与比较方法相比，LGFD模型有显著的性能提升。 <div>
arXiv:2411.11623v1 Announce Type: new 
Abstract: Federated Named Entity Recognition (FNER) boosts model training within each local client by aggregating the model updates of decentralized local clients, without sharing their private data. However, existing FNER methods assume fixed entity types and local clients in advance, leading to their ineffectiveness in practical applications. In a more realistic scenario, local clients receive new entity types continuously, while new local clients collecting novel data may irregularly join the global FNER training. This challenging setup, referred to here as Federated Incremental NER, renders the global model suffering from heterogeneous forgetting of old entity types from both intra-client and inter-client perspectives. To overcome these challenges, we propose a Local-Global Forgetting Defense (LGFD) model. Specifically, to address intra-client forgetting, we develop a structural knowledge distillation loss to retain the latent space's feature structure and a pseudo-label-guided inter-type contrastive loss to enhance discriminative capability over different entity types, effectively preserving previously learned knowledge within local clients. To tackle inter-client forgetting, we propose a task switching monitor that can automatically identify new entity types under privacy protection and store the latest old global model for knowledge distillation and pseudo-labeling. Experiments demonstrate significant improvement of our LGFD model over comparison methods.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Competing Bandits in Decentralized Large Contextual Matching Markets</title>
<link>https://arxiv.org/abs/2411.11794</link>
<guid>https://arxiv.org/abs/2411.11794</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体资源受限匹配市场、分布式学习、两-sided匹配市场、线性上下文带宽算法、动态匹配市场

总结:
这篇论文关注的是在多智能体资源受限匹配市场中，针对具有时间变化偏好的两-sided匹配市场的分布式学习问题。现有的探索-然后-承诺或上界置信区间等学习算法对于该问题效率低下，其单个代理的遗憾值与手臂数量 $K$ 成正比。受到线性上下文带宽框架的启发，文章假设每个代理对手臂的期望回报可以用已知特征向量和未知（代理特定）参数的线性函数表示。此外，文中设定的场景还捕获了匹配市场需求随时间动态变化的本质。为此，论文提出了实现与手臂数量无关的实例依赖对数遗憾值的新算法。<br /><br /> <div>
arXiv:2411.11794v1 Announce Type: new 
Abstract: Sequential learning in a multi-agent resource constrained matching market has received significant interest in the past few years. We study decentralized learning in two-sided matching markets where the demand side (aka players or agents) competes for a `large' supply side (aka arms) with potentially time-varying preferences, to obtain a stable match. Despite a long line of work in the recent past, existing learning algorithms such as Explore-Then-Commit or Upper-Confidence-Bound remain inefficient for this problem. In particular, the per-agent regret achieved by these algorithms scales linearly with the number of arms, $K$. Motivated by the linear contextual bandit framework, we assume that for each agent an arm-mean can be represented by a linear function of a known feature vector and an unknown (agent-specific) parameter.
  Moreover, our setup captures the essence of a dynamic (non-stationary) matching market where the preferences over arms change over time. Our proposed algorithms achieve instance-dependent logarithmic regret, scaling independently of the number of arms, $K$.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DecTest: A Decentralised Testing Architecture for Improving Data Accuracy of Blockchain Oracle</title>
<link>https://arxiv.org/abs/2404.13535</link>
<guid>https://arxiv.org/abs/2404.13535</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、oracle、数据准确性、去中心化测试架构（DecTest）、随机秘密测试机制

<br /><br />总结:

本文针对区块链系统中链上与链下数据交互的难题以及现有oracle节点可能存在外部攻击或出于自私动机提供不准确数据的问题，提出了一种新的去中心化测试架构（DecTest）。该架构首先引入了一个区块链预言机随机秘密测试机制，通过建立动态匿名提问验证委员会，增强了对节点的监控和验证。在此基础上，设计了一个全面的评价激励机制，依据节点的声誉分数对其工作表现进行评估并给予激励。模拟结果显示，该方案成功地将获取数据的离散熵值降低了61.4%，从而提高了数据的真实性和准确性。 <div>
arXiv:2404.13535v2 Announce Type: replace 
Abstract: Blockchain technology ensures secure and trustworthy data flow between multiple participants on the chain, but interoperability of on-chain and off-chain data has always been a difficult problem that needs to be solved. To solve the problem that blockchain systems cannot access off-chain data, oracle is introduced. However, existing research mainly focuses on the consistency and integrity of data, but ignores the problem that oracle nodes may be externally attacked or provide false data for selfish motives, resulting in the unresolved problem of data accuracy. In this paper, we introduce a new Decentralized Testing architecture (DecTest) that aims to improve data accuracy. A blockchain oracle random secret testing mechanism is first proposed to enhance the monitoring and verification of nodes by introducing a dynamic anonymized question-verification committee. Based on this, a comprehensive evaluation incentive mechanism is designed to incentivize honest work performance by evaluating nodes based on their reputation scores. The simulation results show that we successfully reduced the discrete entropy value of the acquired data and the real value of the data by 61.4%.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Space-Air-Ground Integrated MEC-Assisted Industrial Cyber-Physical Systems: An Online Decentralized Optimization Approach</title>
<link>https://arxiv.org/abs/2411.09712</link>
<guid>https://arxiv.org/abs/2411.09712</guid>
<content:encoded><![CDATA[
<div> 关键词: 云计算, 边缘计算, 空天地一体化多接入边缘计算(SAGIMEC), 工业 cyber-物理系统(ICPS), 联合优化问题(JSC4OP)

<br /><br />总结:
本文介绍了SAGIMEC辅助的ICPS架构，该架构通过卫星网络实现云边计算与无缝连接，以提升IoTDs的服务质量和系统的确定性。文章提出了一个综合的联合卫星选择、计算卸载、通信资源分配、计算资源分配和无人机轨迹控制优化问题(JSC4OP)，旨在最大化IoTDs的服务质量，同时考虑了系统环境动态、不确定性及无人机的资源和能源限制。为解决这个复杂问题，文章提出了一种在线分散式优化方法(ODOA)。首先，利用Lyapunov优化将JSC4OP转化为实时决策优化问题(RDOP)；接着，引入在线学习的延迟预测方法预测不确定的系统环境，并采用博弈论决策方法进行实时决策。理论分析证实了ODOA的有效性，而仿真结果表明，所提出的ODOA方案相比于其他替代方法在整体系统性能上表现出优越性。 <div>
arXiv:2411.09712v1 Announce Type: new 
Abstract: Cloud computing and edge/fog computing are playing a pivotal role in driving the transformation of industrial cyber-physical systems (ICPS) towards greater intelligence and automation by providing high-quality computation offloading services to Internet of Things devices (IoTDs). Recently, space-air-ground integrated multi-access edge computing (SAGIMEC) is emerging as a promising architecture combining edge computing and cloud computing, which has the potential to be integrated with ICPS to accelerate the realization of the above vision. In this work, we first present an SAGIMEC-assisted ICPS architecture that incorporates edge computing and cloud computing through seamless connectivity supported by satellite networks to achieve determinism in connectivity, networked computing, and intelligent networked control. Then, we formulate a joint satellite selection, computation offloading, communication resource allocation, computation resource allocation, and UAV trajectory control optimization problem (JSC4OP) to maximize the quality of service (QoS) of IoTDs. This problem considers both the dynamics and uncertainties of the system environment, as well as the limited resources and energy of UAVs. Given the complexity of JSC4OP, we propose an online decentralized optimization approach (ODOA) to solve the problem. Specifically, JSC4OP is first transformed into a real-time decision-making optimization problem (RDOP) by leveraging Lyapunov optimization. Then, to solve the RDOP, we introduce an online learning-based latency prediction method to predict the uncertain system environment and a game theoretic decision-making method to make real-time decisions. Finally, theoretical analysis confirms the effectiveness of the ODOA, while the simulation results demonstrate that the proposed ODOA outperforms other alternative approaches in terms of overall system performance.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Readability Evaluation for Graph Layouts: 2D Geometric Distributed Algorithms</title>
<link>https://arxiv.org/abs/2411.09809</link>
<guid>https://arxiv.org/abs/2411.09809</guid>
<content:encoded><![CDATA[
<div> 关键词: 图可视化、可读性指标、计算复杂性、分布式环境、Spark

总结:
本文主要探讨了图在社交网络、金融和区块链等领域中的重要性以及其可视化对于识别结构模式的关键作用。现有的可读性评估方法在处理大规模图时面临计算密集型挑战。针对这一问题，先前利用机器学习预测渲染图像的可读性得分的方法虽有一定提升，但在处理大量节点的图时，存在内存需求大、准确度不高的缺点。为解决这些问题，该研究提出了一种利用Spark的DataFrame和GraphFrame框架在分布式环境中实现可读性评价的可扩展算法。实验结果显示，这些分布式算法显著减少了计算时间，对于大型数据集的节点遮挡计算速度提高了约17倍，边交叉计算速度提高了约146倍。这使得大规模图的可读性评估变得更加实用和高效，有效克服了以往机器学习方法的局限性。<br /><br /> <div>
arXiv:2411.09809v1 Announce Type: new 
Abstract: Graphs, consisting of vertices and edges, are vital for representing complex relationships in fields like social networks, finance, and blockchain. Visualizing these graphs helps analysts identify structural patterns, with readability metrics-such as node occlusion and edge crossing-assessing layout clarity. However, calculating these metrics is computationally intensive, making scalability a challenge for large graphs. Without efficient readability metrics, layout generation processes-despite numerous studies focused on accelerating them-face bottleneck, making it challenging to select or produce optimized layouts swiftly. Previous approaches attempted to accelerate this process through machine learning models. Machine learning approaches aimed to predict readability scores from rendered images of graphs. While these models offered some improvement, they struggled with scalability and accuracy, especially for graphs with thousands of nodes. For instance, this approach requires substantial memory to process large images, as it relies on rendered images of the graph; graphs with more than 600 nodes cannot be inputted into the model, and errors can exceed 55% in some readability metrics due to difficulties in generalizing across diverse graph layouts. This study addresses these limitations by introducing scalable algorithms for readability evaluation in distributed environments, utilizing Spark's DataFrame and GraphFrame frameworks to efficiently manage large data volumes across multiple machines. Experimental results show that these distributed algorithms significantly reduce computation time, achieving up to a 17x speedup for node occlusion and a 146x improvement for edge crossing on large datasets. These enhancements make scalable graph readability evaluation practical and efficient, overcoming the limitations of previous machine-learning approaches.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedRewind: Rewinding Continual Model Exchange for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2411.09842</link>
<guid>https://arxiv.org/abs/2411.09842</guid>
<content:encoded><![CDATA[
<div> 关键词：FedRewind、去中心化联邦学习、数据分布偏移、持续学习、模型交换

<br />
总结:
本文提出了FedRewind，一种新颖的去中心化联邦学习方法，该方法利用节点间的模型交换来应对数据分布偏移问题。FedRewind借鉴了持续学习（CL）原理和认知神经科学中关于记忆保持的理论，实现了一个去中心化的路由机制，使得节点可以向其他节点发送/接收模型，以解决分布式学习中的空间分布挑战。在局部训练过程中，联盟节点定期将其模型回传（即回溯）到它们最初接收到模型的节点进行有限次数的迭代，以此减少节点间数据分布的差异，从而提升学习和泛化性能。实验结果显示，FedRewind优于标准的去中心化联邦学习方法以及那些在联盟内部强制实施特定路由策略的方法。此外，通过结合联邦学习与持续学习的概念，FedRewind还能应对更为复杂的联邦持续学习任务，即同时存在空间和时间上的数据偏移变化，超过了现有的基线方法。 <div>
arXiv:2411.09842v1 Announce Type: new 
Abstract: In this paper, we present FedRewind, a novel approach to decentralized federated learning that leverages model exchange among nodes to address the issue of data distribution shift. Drawing inspiration from continual learning (CL) principles and cognitive neuroscience theories for memory retention, FedRewind implements a decentralized routing mechanism where nodes send/receive models to/from other nodes in the federation to address spatial distribution challenges inherent in distributed learning (FL). During local training, federation nodes periodically send their models back (i.e., rewind) to the nodes they received them from for a limited number of iterations. This strategy reduces the distribution shift between nodes' data, leading to enhanced learning and generalization performance. We evaluate our method on multiple benchmarks, demonstrating its superiority over standard decentralized federated learning methods and those enforcing specific routing schemes within the federation. Furthermore, the combination of federated and continual learning concepts enables our method to tackle the more challenging federated continual learning task, with data shifts over both space and time, surpassing existing baselines.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Express Yourself: Enabling large-scale public events involving multi-human-swarm interaction for social applications with MOSAIX</title>
<link>https://arxiv.org/abs/2411.09975</link>
<guid>https://arxiv.org/abs/2411.09975</guid>
<content:encoded><![CDATA[
<div> 关键词：Robot swarms, Multi-human-swarm interaction, MOSAIX, Swarm of robot Tiles, Public event

总结:<br />
本文介绍了研究团队在利用机器人蜂群MOSAIX于科学博物馆中促进公众创新思维的过程。MOSAIX由63台机器人“智能便利贴”组成，它们能够收集公众意见并根据主题进行聚合，为参观者提供了一个动态的可视化工具，从而吸引游客参与其中。该工作着重在于创建了一个大规模（涉及63台机器人和294名参与者）的真实生活场景下的公共活动，并采用了一种完全去中心化的蜂群系统。此外，文中还分享了从中获得的经验教训，以期对未来的多人类与机器人蜂群互动研究提供参考。 <div>
arXiv:2411.09975v1 Announce Type: new 
Abstract: Robot swarms have the potential to help groups of people with social tasks, given their ability to scale to large numbers of robots and users. Developing multi-human-swarm interaction is therefore crucial to support multiple people interacting with the swarm simultaneously - which is an area that is scarcely researched, unlike single-human, single-robot or single-human, multi-robot interaction. Moreover, most robots are still confined to laboratory settings. In this paper, we present our work with MOSAIX, a swarm of robot Tiles, that facilitated ideation at a science museum. 63 robots were used as a swarm of smart sticky notes, collecting input from the public and aggregating it based on themes, providing an evolving visualization tool that engaged visitors and fostered their participation. Our contribution lies in creating a large-scale (63 robots and 294 attendees) public event, with a completely decentralized swarm system in real-life settings. We also discuss learnings we obtained that might help future researchers create multi-human-swarm interaction with the public.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Consensus for Fair Message Ordering</title>
<link>https://arxiv.org/abs/2411.09981</link>
<guid>https://arxiv.org/abs/2411.09981</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本系统、共识协议、公平性、最大可提取价值(MEV)、消息排序

<br /><br />总结:
本文针对分布式账本系统（如区块链）中依赖于共识协议进行消息排序的问题进行了深入研究，重点关注了那些致力于促进消息排序公平性的方法，包括基于先进先出（FIFO）、随机和盲排序等不同策略的共识协议。文章讨论了在拜占庭容错环境下实现公平消息排序所面临的挑战与权衡，并总结了构建公平消息排序共识协议的关键步骤。此外，文中提出了一条设计指导原则，并以此为依据优化了当前最先进的FIFO排序协议——Themis。该工作建立了一个统一的框架，用于评估和提升分布式账本系统的公平性。 <div>
arXiv:2411.09981v1 Announce Type: new 
Abstract: Distributed ledger systems, such as blockchains, rely on consensus protocols that constantly commit messages in an agreed order for processing. In practice, message ordering within these systems is often reward-driven. This raises concerns about fairness, particularly in decentralized finance applications, where nodes can exploit transaction orders to maximize rewards (Maximal Extractable Value, MEV). This paper provides a structured review of consensus protocols that order messages with different approaches, especially focusing on the ones that promote order fairness, using methods including First-In-First-Out (FIFO), random, and blind ordering. We review the challenges and trade-offs of deriving fair message ordering in a Byzantine fault-tolerant setting, and summarize the key steps for making a fair message ordering consensus protocol. We introduce a design guideline, with which we propose a performance optimization to the state-of-the-art FIFO ordering protocol Themis. This work establishes a unified framework for accessing and enhancing fairness in distributed ledger systems.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Roadmap for Quantum- Resistant Security: A Framework for Preparing Industries for the Quantum Threat</title>
<link>https://arxiv.org/abs/2411.09995</link>
<guid>https://arxiv.org/abs/2411.09995</guid>
<content:encoded><![CDATA[
<div> 关键词: 量子计算, 密码系统, 抗量子攻击, STL-QCRYPTO框架, 行业安全

总结:<br />
随着量子计算的发展，其对广泛使用的密码系统的威胁给现代网络安全带来了重大挑战。本文提出了一种应对量子攻击的战略路线图，旨在帮助各行业预见并减轻量子风险。文章介绍了一个名为STL-QCRYPTO的新型战略框架，该框架为实现行业特定的量子安全系统提供了务实和战略性的方法。文中深入评估了金融服务业、银行业、医疗保健、关键基础设施等十四大高风险行业的量子威胁脆弱性，并着重探讨了这些行业实施量子安全防护系统的实际路径。同时，论文还讨论了采用抗量子技术所面临的技術、操作及监管难题。通过提供结构化的时间线和可操作建议，本文构建的路线图与框架有助于各行业在量子计算时代制定抵御潜在安全威胁的战略。 <div>
arXiv:2411.09995v1 Announce Type: new 
Abstract: As quantum computing continues to advance, its ability to compromise widely used cryptographic systems projects a significant challenge to modern cybersecurity. This paper outlines a strategic roadmap for industries to anticipate and mitigate the risks posed by quantum attacks. Our study explores the development of a quantum-resistant cryptographic solutioning framework for the industry, offering a practical and strategic approach to mitigating quantum attacks. We, here, propose a novel strategic framework, coined name STL-QCRYPTO, outlines tailored, industry-specific methodologies to implement quantum-safe security systems, ensuring long-term protection against the disruptive potential of quantum computing. The following fourteen high-risk sectors: Financial Services, Banking, Healthcare, Critical Infrastructure, Government & Defence, E-commerce, Energy & Utilities, Automotive & Transportation, Cloud Computing & Data Storage, Insurance, Internet & Telecommunications, Blockchain Applications, Metaverse Applications, and Multiagent AI Systems - are critically assessed for their vulnerability to quantum threats. The evaluation emphasizes practical approaches for the deployment of quantum-safe security systems to safeguard these industries against emerging quantum-enabled cyber risks. Additionally, the paper addresses the technical, operational, and regulatory hurdles associated with adopting quantum-resistant technologies. By presenting a structured timeline and actionable recommendations, this roadmap with proposed framework prepares industries with the essential strategy to safeguard their potential security threats in the quantum computing era.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Omnichain Web: The Universal Framework for Streamlined Chain Abstraction and Cross-Layer Interaction</title>
<link>https://arxiv.org/abs/2411.10132</link>
<guid>https://arxiv.org/abs/2411.10132</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3、碎片化流动性、互操作性、Omnichain Web、跨链资产结算

总结:
<br />
Omnichain Web 是一个旨在解决Web3生态系统中碎片化流动性与Layer 1和Layer 2区块链之间有限互操作性的框架。它通过核心组件——OmniRollups、Proof Network、Ragno Network和Builder Marketplace实现统一化的去中心化网络。该生态系统支持无缝跨链资产结算和互操作性，并为开发用户友好的去中心化应用（dApp）提供便利。其创新技术包括模块化证明网络和可信执行环境（TEEs），并结合先进的零知识证明系统及AI代理兼容性，实现意图驱动和自主功能，优化了区块链间的流动性管理和用户体验。此外，Omnichain Web还提供了用于L1基础设施的去中心化市场，降低了运营开销，并促进了可扩展、安全和高效的跨链协议。作为一项开创性解决方案，Omnichain Web无缝连接Web2和Web3，推动了一个全面互联的数字经济发展。 <div>
arXiv:2411.10132v1 Announce Type: new 
Abstract: The evolution of the Web3 ecosystem has been hindered by fragmented liquidity and limited interoperability across Layer 1 (L1) and Layer 2 (L2) blockchains, which leads to inefficiencies and elevated costs. Omnichain Web addresses these challenges by introducing a comprehensive framework to unify decentralized networks through its core components: OmniRollups, Proof Network, Ragno Network, and Builder Marketplace. This ecosystem enables seamless cross-chain asset settlement, interoperability, and user-friendly decentralized application (dApp) development, driven by innovative technologies such as modular proof networks and trusted execution environments (TEEs). By integrating advanced zero-knowledge proof systems and compatibility with AI agents, Omnichain Web empowers intent-driven and autonomous functionalities, streamlining liquidity management and user interactions across blockchains. Furthermore, its decentralized marketplace for L1 infrastructure reduces operational overhead and promotes scalable, secure, and efficient cross-chain protocols. As a pioneering solution, Omnichain Web seamlessly connects Web2 and Web3, enabling a holistic and interconnected digital economy.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Definition and Detection of Centralization Defects in Smart Contracts</title>
<link>https://arxiv.org/abs/2411.10169</link>
<guid>https://arxiv.org/abs/2411.10169</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化缺陷、智能合约、安全事件、CDRipper、检测工具

<br /><br />总结:

本文针对近年来由于智能合约中心化缺陷导致的安全事件及大量财务损失问题进行了研究。文章提出了六种类型的智能合约中心化缺陷，并通过分析597篇Stack Exchange帖子和117份审计报告进行详细描述与实例展示。为填补当前对这类缺陷分析不足的空白，作者开发了一款名为CDRipper的工具，该工具通过构建权限依赖图(PDG)，从智能合约源代码中提取函数的权限依赖关系，并检测函数中的敏感操作，依据预定义模式识别中心化缺陷。实验结果显示，在对244,424个真实世界的智能合约进行大规模检测后，共有82,446个合同存在至少一种中心化缺陷，而CDRipper工具在此过程中达到了93.7%的整体精确度。 <div>
arXiv:2411.10169v1 Announce Type: new 
Abstract: In recent years, security incidents stemming from centralization defects in smart contracts have led to substantial financial losses. A centralization defect refers to any error, flaw, or fault in a smart contract's design or development stage that introduces a single point of failure. Such defects allow a specific account or user to disrupt the normal operations of smart contracts, potentially causing malfunctions or even complete project shutdowns. Despite the significance of this issue, most current smart contract analyses overlook centralization defects, focusing primarily on other types of defects. To address this gap, our paper introduces six types of centralization defects in smart contracts by manually analyzing 597 Stack Exchange posts and 117 audit reports. For each defect, we provide a detailed description and code examples to illustrate its characteristics and potential impacts. Additionally, we introduce a tool named CDRipper (Centralization Defects Ripper) designed to identify the defined centralization defects. Specifically, CDRipper constructs a permission dependency graph (PDG) and extracts the permission dependencies of functions from the source code of smart contracts. It then detects the sensitive operations in functions and identifies centralization defects based on predefined patterns. We conduct a large-scale experiment using CDRipper on 244,424 real-world smart contracts and evaluate the results based on a manually labeled dataset. Our findings reveal that 82,446 contracts contain at least one of the six centralization defects, with our tool achieving an overall precision of 93.7%.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Driven Decentralized Control Design for Discrete-Time Large-Scale Systems</title>
<link>https://arxiv.org/abs/2411.10243</link>
<guid>https://arxiv.org/abs/2411.10243</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、控制器设计、离散时间大系统、解中心化控制、半定规划问题

<br />
总结:
本文提出了一种针对离散时间大规模系统的数据驱动控制器设计方法。该方法将大规模系统转化为等效的数据驱动形式，并利用其子系统的状态、控制输入和互联系统输入数据来参数化解中心化控制器。通过结合开发的数据驱动方法与李亚普诺夫方法，构建了一个数据驱动的半定规划问题以求得稳定性的解中心化控制器。这种方法在对一串质量弹簧模型的验证中表现出显著优势，即避免了繁琐的建模过程。 <div>
arXiv:2411.10243v1 Announce Type: new 
Abstract: In this paper, a data-driven approach is developed for controller design for a class of discrete-time large-scale systems, where a large-scale system can be expressed in an equivalent data-driven form and the decentralized controllers can be parameterized by the data collected from its subsystems, i.e., system state, control input, and interconnection input. Based on the developed data-driven method and the Lyapunov approach, a data-driven semi-definite programming problem is constructed to obtain decentralized stabilizing controllers. The proposed approach has been validated on a mass-spring chain model, with the significant advantage of avoiding extensive modeling processes.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>How the interplay between power concentration, competition, and propagation affects the resource efficiency of distributed ledgers</title>
<link>https://arxiv.org/abs/2411.10249</link>
<guid>https://arxiv.org/abs/2411.10249</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin网络、分叉、共识协议、矿工异质性、块传播时间

<br /><br />总结:
本文介绍了关于比特币网络中自然分叉的研究，其频率作为分布式账本效率的关键指标，可能导致资源浪费和网络安全问题。研究提出了一种模型，用于预测具有不同矿工数量、哈希率分布以及块传播时间的异质矿工网络中的自然分叉率。该模型预测的分叉率与实测的废弃区块率相当。过去十年间，采矿池的数量大约减少了三分之一，论文量化了这一变化对分叉率的影响，并揭示了由于全球能源供应限制导致的哈希率分布呈现截尾幂律分布的现象。文章通过实证分析和定量模型证明，块传播时间和挖矿时间的比例是评估分叉率的一个准确指标，并进一步量化了它对矿工活动异质性的依赖。此外，文中提供了理论和实证证据表明，哈希率集中度降低和块传播时间缩短可以减少分布式账本中的分叉率。这项工作为研究分布式网络上的权力集中和竞争提供了一个稳健的数学框架，有助于解释由自私挖矿策略和不对称传播时间引起的分叉率差异，从而为现有和新兴区块链分布式挖掘系统的未来设计提供了有效的工具。 <div>
arXiv:2411.10249v1 Announce Type: new 
Abstract: Forks in the Bitcoin network result from the natural competition in the blockchain's Proof-of-Work consensus protocol. Their frequency is a critical indicator for the efficiency of a distributed ledger as they can contribute to resource waste and network insecurity. We introduce a model for the estimation of natural fork rates in a network of heterogeneous miners as a function of their number, the distribution of hash rates and the block propagation time over the peer-to-peer infrastructure. Despite relatively simplistic assumptions, such as zero propagation delay within mining pools, the model predicts fork rates which are comparable with the empirical stale blocks rate. In the past decade, we observe a reduction in the number of mining pools approximately by a factor 3, and quantify its consequences for the fork rate, whilst showing the emergence of a truncated power-law distribution in hash rates, justified by a rich-get-richer effect constrained by global energy supply limits. We demonstrate, both empirically and with the aid of our quantitative model, that the ratio between the block propagation time and the mining time is a sufficiently accurate estimator of the fork rate, but also quantify its dependence on the heterogeneity of miner activities. We provide empirical and theoretical evidence that both hash rate concentration and lower block propagation time reduce fork rates in distributed ledgers. Our work introduces a robust mathematical setting for investigating power concentration and competition on a distributed network, for interpreting discrepancies in fork rates -- for example caused by selfish mining practices and asymmetric propagation times -- thus providing an effective tool for designing future and alternative scenarios for existing and new blockchain distributed mining systems.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bitcoin Research with a Transaction Graph Dataset</title>
<link>https://arxiv.org/abs/2411.10325</link>
<guid>https://arxiv.org/abs/2411.10325</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、大规模数据集、交易图、节点标签、图神经网络

<br /><br />总结:
本文介绍了由Satoshi Nakamoto于2008年创立的比特币如何构建了一个无需中央权威机构即可存储和转移价值的全新数字经济。文章提出了一项大规模比特币交易数据集，该数据集以交易图的形式呈现，包含了约2.52亿个节点、7.85亿条边，时间跨度近13年，涵盖了6.7亿笔交易，且每个节点和边都带有时间戳。数据集提供了两个标注集合：一是基于实体类型的3.3万个节点；二是将近10万比特币地址，标注了实体名称和类型，这是迄今为止公开可用的最大规模比特币交易数据集，旨在促进该领域的深入研究，克服现有数据集的局限性。此外，通过训练各种图神经网络模型来预测节点标签，为未来研究建立了基准，并展示了数据集在比特币分析之外的多种应用场景。最后，所有数据和源代码均对公众开放，以实现结果的可复现性。 <div>
arXiv:2411.10325v1 Announce Type: new 
Abstract: Bitcoin, launched in 2008 by Satoshi Nakamoto, established a new digital economy where value can be stored and transferred in a fully decentralized manner - alleviating the need for a central authority. This paper introduces a large scale dataset in the form of a transactions graph representing transactions between Bitcoin users along with a set of tasks and baselines. The graph includes 252 million nodes and 785 million edges, covering a time span of nearly 13 years of and 670 million transactions. Each node and edge is timestamped. As for supervised tasks we provide two labeled sets i. a 33,000 nodes based on entity type and ii. nearly 100,000 Bitcoin addresses labeled with an entity name and an entity type. This is the largest publicly available data set of bitcoin transactions designed to facilitate advanced research and exploration in this domain, overcoming the limitations of existing datasets. Various graph neural network models are trained to predict node labels, establishing a baseline for future research. In addition, several use cases are presented to demonstrate the dataset's applicability beyond Bitcoin analysis. Finally, all data and source code is made publicly available to enable reproducibility of the results.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game Theoretic Liquidity Provisioning in Concentrated Liquidity Market Makers</title>
<link>https://arxiv.org/abs/2411.10399</link>
<guid>https://arxiv.org/abs/2411.10399</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化标记制造商 (AMM), 集中流动性市场制造商 (CLMM), 流动性提供者 (LP), 纳什均衡, 水平填充策略

<br /><br />总结:
本文介绍了自动化标记制造商（AMMs）和集中流动性市场制造商（CLMMs），这是一种允许自动交易数字资产并由流动性提供者（LPs）提供存款的去中心化交易所。研究重点在于CLMMs中LPs的战略规划与激励机制。文章构建了一个博弈论模型分析LPs的行为，并发现原问题可能存在多个纳什均衡且复杂度随价格刻度数量呈二次增长，但可简化为具有唯一纳什均衡、复杂度线性增长的游戏。简化后的纳什均衡表现为低预算LP会使用全部预算，而富裕LP则不会完全投入。通过对真实世界CLMM数据的拟合，观察到在含有风险资产的流动资金池中，LPs的投资策略远离纳什均衡，他们倾向于在更少且更宽的价格范围内投资，并减少流动性更新频率。研究进一步表明，如果LPs调整其策略以更接近游戏的纳什均衡，他们的日均收益可提高约116美元，即日投资回报率中位数增加0.009%。 <div>
arXiv:2411.10399v1 Announce Type: new 
Abstract: Automated marker makers (AMMs) are a class of decentralized exchanges that enable the automated trading of digital assets. They accept deposits of digital tokens from liquidity providers (LPs); tokens can be used by traders to execute trades, which generate fees for the investing LPs. The distinguishing feature of AMMs is that trade prices are determined algorithmically, unlike classical limit order books. Concentrated liquidity market makers (CLMMs) are a major class of AMMs that offer liquidity providers flexibility to decide not only \emph{how much} liquidity to provide, but \emph{in what ranges of prices} they want the liquidity to be used. This flexibility can complicate strategic planning, since fee rewards are shared among LPs. We formulate and analyze a game theoretic model to study the incentives of LPs in CLMMs. Our main results show that while our original formulation admits multiple Nash equilibria and has complexity quadratic in the number of price ticks in the contract, it can be reduced to a game with a unique Nash equilibrium whose complexity is only linear. We further show that the Nash equilibrium of this simplified game follows a waterfilling strategy, in which low-budget LPs use up their full budget, but rich LPs do not. Finally, by fitting our game model to real-world CLMMs, we observe that in liquidity pools with risky assets, LPs adopt investment strategies far from the Nash equilibrium. Under price uncertainty, they generally invest in fewer and wider price ranges than our analysis suggests, with lower-frequency liquidity updates. We show that across several pools, by updating their strategy to more closely match the Nash equilibrium of our game, LPs can improve their median daily returns by \$116, which corresponds to an increase of 0.009\% in median daily return on investment.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Coordination of Distributed Energy Resources through Local Energy Markets and Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2404.13142</link>
<guid>https://arxiv.org/abs/2404.13142</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式能源资源、电力网、交易性能源、深度强化学习、社区净负荷变异性

总结:
随着分布式能源资源（DERs）的增长，电力网格面临边缘区域净负荷波动性增加的问题，影响了运行可靠性和稳定性。交易性能源通过本地能源市场提供了一种分散式的、间接的需求响应解决方案，而深度强化学习（DRL）等模型无关控制技术则使自动化、分散化的参与成为可能。然而，现有研究大多忽视了社区层面的净负荷变异性问题，更关注经济社会指标。本文针对这一空白，利用DRL代理自动参与名为ALEX的本地能源市场，各代理独立行动以最小化各自能源费用。结果表明，降低电费与减少净负荷变异性之间存在紧密联系，通过评估不同时间范围内的指标如爬坡率、负载因子和峰值需求得到证实。将DRL代理与近乎最优的动态规划方法进行基准对比，动态规划方法分别实现了每日进口、出口和峰值需求降低22.05%、83.92%和24.09%，而DRL代理表现出可比或更优的结果，分别降低了21.93%、84.46%和27.02%。该研究表明，DRL在分散化电网管理中的有效性，突显了其在社区驱动的能源市场中实现接近最优性能、减少净负荷变异性方面的可扩展性。 <div>
arXiv:2404.13142v2 Announce Type: replace 
Abstract: As distributed energy resources (DERs) grow, the electricity grid faces increased net load variability at the grid edge, impacting operability and reliability. Transactive energy, facilitated through local energy markets, offers a decentralized, indirect demand response solution, with model-free control techniques, such as deep reinforcement learning (DRL), enabling automated, decentralized participation. However, existing studies largely overlook community-level net load variability, focusing instead on socioeconomic metrics.
  This study addresses this gap by using DRL agents to automate end-user participation in a local energy market (ALEX), where agents act independently to minimize individual energy bills. Results reveal a strong link between bill reduction and decreased net load variability, assessed across metrics such as ramping rate, load factor, and peak demand over various time horizons. Using a no-control baseline, DRL agents are benchmarked against a near-optimal dynamic programming approach. The dynamic programming benchmark achieves reductions of 22.05 percent, 83.92 percent, and 24.09 percent in daily import, export, and peak demand, respectively, while the DRL agents show comparable or superior results with reductions of 21.93 percent, 84.46 percent, and 27.02 percent.
  This study demonstrates the effectiveness of DRL in decentralized grid management, highlighting its scalability and near-optimal performance in reducing net load variability within community-driven energy markets.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multilingual Standalone Trustworthy Voice-Based Social Network for Disaster Situations</title>
<link>https://arxiv.org/abs/2411.08889</link>
<guid>https://arxiv.org/abs/2411.08889</guid>
<content:encoded><![CDATA[
<div> 关键词：灾难场景、语音通信、多语言、人工智能、区块链技术

总结:<br />
本文介绍了一种针对灾难场景下语言障碍问题而设计的创新性、多语言语音社交网络。该系统利用先进的人工智能实现语音实时翻译，确保跨语言间的流畅交流，并结合区块链技术存储安全、不可篡改的消息记录，保证信息完整性。此外，系统能在离线环境下通过本地网络独立运行，提高可靠性，并可在多种设备上跨平台使用，包括移动手机和桌面电脑，具有很好的适应性和易用性。评估结果显示，该系统在语音识别与翻译准确度、低延迟以及用户满意度方面表现优异，验证了其在危机时刻提升沟通效率和包容性的有效作用，代表了灾难通信领域的重大进步。 <div>
arXiv:2411.08889v1 Announce Type: new 
Abstract: In disaster scenarios, effective communication is crucial, yet language barriers often hinder timely and accurate information dissemination, exacerbating vulnerabilities and complicating response efforts. This paper presents a novel, multilingual, voice-based social network specifically designed to address these challenges. The proposed system integrates advanced artificial intelligence (AI) with blockchain technology to enable secure, asynchronous voice communication across multiple languages. The application operates independently of external servers, ensuring reliability even in compromised environments by functioning offline through local networks. Key features include AI-driven real-time translation of voice messages, ensuring seamless cross-linguistic communication, and blockchain-enabled storage for secure, immutable records of all interactions, safeguarding message integrity. Designed for cross-platform use, the system offers consistent performance across devices, from mobile phones to desktops, making it highly adaptable in diverse disaster situations. Evaluation metrics demonstrate high accuracy in speech recognition and translation, low latency, and user satisfaction, validating the system's effectiveness in enhancing communication during crises. This solution represents a significant advancement in disaster communication, bridging language gaps to support more inclusive and efficient emergency response.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Designing Automated Market Makers for Combinatorial Securities: A Geometric Viewpoint</title>
<link>https://arxiv.org/abs/2411.08972</link>
<guid>https://arxiv.org/abs/2411.08972</guid>
<content:encoded><![CDATA[
<div> 关键词：automated market makers (AMMs)，prediction markets，combinatorial securities，VC dimension，range query problem

总结:
这篇文章提出了一种设计任意集系统中自动化做市商(AMMs)的框架，将预测市场的挑战与计算几何中的范围查询问题建立了新的联系。研究者展示了在流行的组合对数市场评分规则市场中，价格查询和交易更新等同于范围查询和范围更新问题，并基于此等价性，构建了当集合系统的VC维数有限时的次线性时间算法，并证明了在VC维数无限的情况下不存在此类算法。此外，他们还将这种方法扩展到了具有二次和幂次评分规则的组合预测市场的AMMs。文章还引入了去中心化金融中AMM的组合交换操作问题，并将其有效地归约为范围更新问题。最后，展示了多分辨率市场设计可以自然地融入到分区树方案中。 <div>
arXiv:2411.08972v1 Announce Type: new 
Abstract: Designing automated market makers (AMMs) for prediction markets on combinatorial securities over large outcome spaces poses significant computational challenges. Prior research has primarily focused on combinatorial prediction markets within specific set systems (e.g., intervals, permutations). We introduce a framework for designing AMMs on arbitrary set systems by building a novel connection to the range query problem in computational geometry. This connection enables the analysis of computational complexity and the design of efficient AMMs.
  We first demonstrate the equivalence between price queries and trade updates under the popular combinatorial logarithmic market scoring rule market and the range query and range update problem. Building on this equivalence, we construct sublinear time algorithms when the VC dimension of the set system is bounded and show the non-existence of such algorithms for unbounded VC dimension cases. We then extend this approach to AMMs for combinatorial prediction markets with quadratic and power scoring rules. Finally, we show that the multi-resolution market design can be naturally integrated into the partition-tree scheme.
  Additionally, we introduce the combinatorial swap operation problem for automated market makers in decentralized finance and show that it can be efficiently reduced to range update problems.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Information Need in Metaverse Recordings - A Field Study</title>
<link>https://arxiv.org/abs/2411.09053</link>
<guid>https://arxiv.org/abs/2411.09053</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse Recordings (MVRs)，Multimedia Information Retrieval (MMIR)，field study，information needs，search behaviors

<br /><br />总结:
该论文针对多媒体信息检索(MMIR)领域中新兴且未充分探索的媒体类型——元宇宙记录（MVRs）进行了研究。通过专家访谈和分析，本研究揭示了MVR检索的应用场景以及从元宇宙中检索多媒体内容所面临的挑战。研究结果表明，MVRs现有的应用场景强调了捕获图形渲染过程及相关输入输出设备的时间序列数据的重要性，这些数据对于满足用户需求具有高度相关性。此外，研究还为开发专门针对MVRs的检索系统定义了使用案例、用户画像以及具体要求，从而为MVR检索系统的未来研究与设计奠定了基础，进一步加深了对MVR检索中的信息搜索行为的理解。 <div>
arXiv:2411.09053v1 Announce Type: new 
Abstract: Metaverse Recordings (MVRs) represent an emerging and underexplored media type within the field of Multimedia Information Retrieval (MMIR). This paper presents findings from a field study aimed at understanding the users information needs and search behaviors specific to MVR retrieval. By conducting and analyzing expert interviews, the study identifies application scenarios and highlights challenges in retrieving multimedia content from the metaverse. The results reveal existing application scenarios of MVRs and confirm the relevance of capturing time-series data from the graphical rendering process and related input-output devices, which are also highly relevant to user needs. Furthermore, the study provides a foundation for developing retrieval systems tailored to MVRs by defining use cases, user stereotypes, and specific requirements for MVR Retrieval systems. The findings contribute to a better understanding of information search behaviors in MVR Retrieval and pave the way for future research and system design in this field.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartInv: Multimodal Learning for Smart Contract Invariant Inference</title>
<link>https://arxiv.org/abs/2411.09217</link>
<guid>https://arxiv.org/abs/2411.09217</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart合同、机器不可审计漏洞、智能合约不变量推理框架、多模态信息、零日漏洞

总结:<br />
本文介绍了针对智能合约中“机器不可审计”漏洞检测的新方法——SmartInv。该框架是一款准确快速的智能合约不变量推理工具，旨在通过理解并跨多种模态信息（如源代码和自然语言）进行推理来生成描述智能合约预期行为的不变量。研究提出了一种新的提示策略——层级思考（Tier of Thought, ToT），用于多模态智能合约的理解与推理。实验结果显示，SmartInv相比于现有最先进的工具能生成3.5倍更多的关键性bug不变量，并在显著缩短（150倍）的时间内发现4倍以上的严重漏洞。此外，SmartInv从89,621份真实世界的智能合约中发现了119个零日漏洞，其中五个已被开发者确认为“高危”级别的严重漏洞。 <div>
arXiv:2411.09217v1 Announce Type: new 
Abstract: Smart contracts are software programs that enable diverse business activities on the blockchain. Recent research has identified new classes of "machine un-auditable" bugs that arise from both transactional contexts and source code. Existing detection methods require human understanding of underlying transaction logic and manual reasoning across different sources of context (i.e. modalities), such as code, dynamic transaction executions, and natural language specifying the expected transaction behavior.
  To automate the detection of ``machine un-auditable'' bugs, we present SmartInv, an accurate and fast smart contract invariant inference framework. Our key insight is that the expected behavior of smart contracts, as specified by invariants, relies on understanding and reasoning across multimodal information, such as source code and natural language. We propose a new prompting strategy to foundation models, Tier of Thought (ToT), to reason across multiple modalities of smart contracts and ultimately to generate invariants. By checking the violation of these generated invariants, SmartInv can identify potential vulnerabilities.
  We evaluate SmartInv on real-world contracts and re-discover bugs that resulted in multi-million dollar losses over the past 2.5 years (from January 1, 2021 to May 31, 2023). Our extensive evaluation shows that SmartInv generates (3.5X) more bug-critical invariants and detects (4$\times$) more critical bugs compared to the state-of-the-art tools in significantly (150X) less time. \sys uncovers 119 zero-day vulnerabilities from the 89,621 real-world contracts. Among them, five are critical zero-day bugs confirmed by developers as ``high severity.''
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient and Secure Cross-Domain Data-Sharing for Resource-Constrained Internet of Things</title>
<link>https://arxiv.org/abs/2411.09229</link>
<guid>https://arxiv.org/abs/2411.09229</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网(IoT), 区块链, 数据共享, 分布式密钥生成, 安全性

总结:
<br />
本文针对物联网环境中日益复杂的跨域数据共享所面临的显著安全挑战，提出了一种基于区块链的高效、安全的数据共享方案。该方案采用分布式密钥生成方法，避免了单点故障，并实现了独立的伪名生成和密钥更新，从而提高了认证灵活性并降低了计算开销。此外，该方案还涵盖了数据上传、存储和分享的全过程，确保了数据可追溯性、完整性和隐私保护。通过安全分析，证实了该方案理论上具有安全性，并能抵抗多种攻击；性能评估显示其相比于现有解决方案具有更低的计算和通信开销，因此对于物联网应用而言，该方案既安全又高效。 <div>
arXiv:2411.09229v1 Announce Type: new 
Abstract: The growing complexity of Internet of Things (IoT) environments, particularly in cross-domain data sharing, presents significant security challenges. Existing data-sharing schemes often rely on computationally expensive cryptographic operations and centralized key management, limiting their effectiveness for resource-constrained devices. To address these issues, we propose an efficient, secure blockchain-based data-sharing scheme. First, our scheme adopts a distributed key generation method, which avoids single point of failure. This method also allows independent pseudonym generation and key updates, enhancing authentication flexibility while reducing computational overhead. Additionally, the scheme provides a complete data-sharing process, covering data uploading, storage, and sharing, while ensuring data traceability, integrity, and privacy. Security analysis shows that the proposed scheme is theoretically secure and resistant to various attacks, while performance evaluations demonstrate lower computational and communication overhead compared to existing solutions, making it both secure and efficient for IoT applications.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards efficient compression and communication for prototype-based decentralized learning</title>
<link>https://arxiv.org/abs/2411.09267</link>
<guid>https://arxiv.org/abs/2411.09267</guid>
<content:encoded><![CDATA[
<div> 关键词: prototype-based federated learning, decentralized learning, prototype redundancy, data compression, age-of-information (AoI)

总结:
<br />
本文研究了一种基于原型的去中心化联邦学习系统的设计，旨在提高通信效率。针对原型冗余问题，文章提出了双重数据压缩技术：仅当原型具有信息论上的有用性（通过Jensen-Shannon距离判断）时发送更新消息，并利用聚类对原型进行压缩以减小 gossip 协议中的更新消息大小。此外，文中采用了并行而非序列化的 gossip 通信，并分析了其年龄信息（AoI）。实验结果显示，通过这些改进，可以在不降低学习算法收敛速度的前提下显著减少通信负载。 <div>
arXiv:2411.09267v1 Announce Type: new 
Abstract: In prototype-based federated learning, the exchange of model parameters between clients and the master server is replaced by transmission of prototypes or quantized versions of the data samples to the aggregation server. A fully decentralized deployment of prototype- based learning, without a central agregartor of prototypes, is more robust upon network failures and reacts faster to changes in the statistical distribution of the data, suggesting potential advantages and quick adaptation in dynamic learning tasks, e.g., when the data sources are IoT devices or when data is non-iid. In this paper, we consider the problem of designing a communication-efficient decentralized learning system based on prototypes. We address the challenge of prototype redundancy by leveraging on a twofold data compression technique, i.e., sending only update messages if the prototypes are informationtheoretically useful (via the Jensen-Shannon distance), and using clustering on the prototypes to compress the update messages used in the gossip protocol. We also use parallel instead of sequential gossiping, and present an analysis of its age-of-information (AoI). Our experimental results show that, with these improvements, the communications load can be substantially reduced without decreasing the convergence rate of the learning algorithm.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fully Local Last-Generated Rule in a Blockchain</title>
<link>https://arxiv.org/abs/2411.08439</link>
<guid>https://arxiv.org/abs/2411.08439</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、故意分叉、最后生成规则、局部应用、诚实矿工

总结:
本文提出了一种针对区块链中故意分叉的有效抑制方法——局部可应用的最后生成规则。该规则在发生链并列时选择最近生成的链作为主链，有助于使敌人持有的区块无效。与现有局部方法相比，新方法通过将时钟偏移量$\Delta_{O_i}$的上限设定为200秒，能将诚实矿工在链并列情况下跟随攻击者的情况减少超过40%。这一创新设计更好地满足了保守型加密货币系统（如比特币）对于完全局部化方法的需求。 <div>
arXiv:2411.08439v1 Announce Type: new 
Abstract: An effective method for suppressing intentional forks in a blockchain is the last-generated rule, which selects the most recent chain as the main chain in the event of a chain tie. This rule helps invalidate blocks that are withheld by adversaries for a certain period. However, existing last-generated rules face an issue in that their applications to the system are not fully localized. In conservative cryptocurrency systems such as Bitcoin, it is desirable for methods to be applied in a fully local manner. In this paper, we propose a locally applicable last-generated rule. Our method is straightforward and is based on a relative time reference. By conservatively setting the upper bound for the clock skews $\Delta_{O_i}$ to 200 s, our proposed method reduces the proportion $\gamma$ of honest miners following the attacker during chain ties by more than 40% compared to existing local methods.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats and Promising Technical Solutions using LLMs</title>
<link>https://arxiv.org/abs/2411.08640</link>
<guid>https://arxiv.org/abs/2411.08640</guid>
<content:encoded><![CDATA[
<div> 关键词: O-RAN、安全分析、零信任、移动目标防御(MTD)、区块链、大型语言模型(LLM)、深度强化学习、网络切片、可解释人工智能(XAI)

<br /><br />总结:
本文深入分析了开放无线接入网(O-RAN)架构的安全性，探讨了不同O-RAN层次可能面临的潜在威胁及其对保密性、完整性和可用性(CIA)三元组的影响。文章提出零信任、移动目标防御(MTD)、区块链和大型语言模型(LLM)技术可用于增强O-RAN的安全态势。此外，文中通过数值演示展示了MTD如何赋能动态网络切片接纳控制中的鲁棒深度强化学习方法。同时，文章还研究了基于LLM的可解释人工智能(XAI)在保障系统安全性方面的作用。 <div>
arXiv:2411.08640v1 Announce Type: new 
Abstract: The evolution of wireless communication systems will be fundamentally impacted by an open radio access network (O-RAN), a new concept defining an intelligent architecture with enhanced flexibility, openness, and the ability to slice services more efficiently. For all its promises, and like any technological advancement, O-RAN is not without risks that need to be carefully assessed and properly addressed to accelerate its wide adoption in future mobile networks. In this paper, we present an in-depth security analysis of the O-RAN architecture, discussing the potential threats that may arise in the different O-RAN architecture layers and their impact on the Confidentiality, Integrity, and Availability (CIA) triad. We also promote the potential of zero trust, Moving Target Defense (MTD), blockchain, and large language models(LLM) technologies in fortifying O-RAN's security posture. Furthermore, we numerically demonstrate the effectiveness of MTD in empowering robust deep reinforcement learning methods for dynamic network slice admission control in the O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI) based on LLMs in securing the system.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking negative sampling in content-based news recommendation</title>
<link>https://arxiv.org/abs/2411.08700</link>
<guid>https://arxiv.org/abs/2411.08700</guid>
<content:encoded><![CDATA[
<div> 关键词: news recommender systems, relevance decay, neural techniques, negative sampling, decentralization

<br /><br />总结:
本文探讨了新闻推荐系统因文章时效性短暂导致的相关性衰减问题。研究发现，内容基神经技术对此有所助益，但现有模型复杂且对负例处理不足。为此，文中提出了一个新的负例采样技术，该技术能提升模型准确性并有利于推荐系统的去中心化。实验使用MIND数据集证明了所提方法的精度可与最先进的模型相媲美。此外，这种采样技术有助于降低模型复杂度、加速训练过程，并保持高精度。最后，文章还讨论了去中心化模型如何改善隐私性和可扩展性。 <div>
arXiv:2411.08700v1 Announce Type: new 
Abstract: News recommender systems are hindered by the brief lifespan of articles, as they undergo rapid relevance decay. Recent studies have demonstrated the potential of content-based neural techniques in tackling this problem. However, these models often involve complex neural architectures and often lack consideration for negative examples. In this study, we posit that the careful sampling of negative examples has a big impact on the model's outcome. We devise a negative sampling technique that not only improves the accuracy of the model but also facilitates the decentralization of the recommendation system. The experimental results obtained using the MIND dataset demonstrate that the accuracy of the method under consideration can compete with that of State-of-the-Art models. The utilization of the sampling technique is essential in reducing model complexity and accelerating the training process, while maintaining a high level of accuracy. Finally, we discuss how decentralized models can help improve privacy and scalability.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication Efficient Decentralization for Smoothed Online Convex Optimization</title>
<link>https://arxiv.org/abs/2411.08355</link>
<guid>https://arxiv.org/abs/2411.08355</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体、光滑在线凸优化、分布式算法、异步通信图、计算复杂度

总结:
本文研究了多智能体光滑在线凸优化（SOCO）问题，其中$N$个智能体通过通信图进行交互。每个轮次中，每个智能体$i$会以在线方式接收到强凸击打成本函数$f^i_t$并选择动作$x^i_t\in\mathbb{R}^d$。目标是最小化全局累积成本，包括个体击打成本之和、决策变化的“切换成本”以及相邻智能体决策偏离的“不相似性成本”。文章首次提出了一个多智能体SOOC的分布式算法并证明其渐近最优性。该算法允许每个智能体仅利用与其直接邻接节点的信息进行操作。对于有限时间性能，文章证明了竞争比的优值差随时间序列$T$减小，并可以根据每个智能体每轮可利用的计算资源进行便捷调整。此外，即使通信图可以随时间任意和自适应地改变，该方法仍然有效。最后，文章表明每轮的计算复杂度仅与智能体数量对数相关且几乎线性依赖于它们在图中的度数，确保了大系统实施的可扩展性。<br /><br /> <div>
arXiv:2411.08355v1 Announce Type: cross 
Abstract: We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where $N$ agents interact through a communication graph. In each round, each agent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online fashion and selects an action $x^i_t \in \mathbb{R}^d$. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs $f^i_t(x^i_t)$, a temporal "switching cost" for changing decisions, and a spatial "dissimilarity cost" that penalizes deviations in decisions among neighboring agents. We propose the first decentralized algorithm for multi-agent SOCO and prove its asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in competitive ratio decreases with the time horizon $T$ and can be conveniently tuned based on the per-round computation available to each agent. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, we establish that the computational complexity per round depends only logarithmically on the number of agents and almost linearly on their degree within the graph, ensuring scalability for large-system implementations.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Merit-Based Sortition in Decentralized Systems</title>
<link>https://arxiv.org/abs/2411.07302</link>
<guid>https://arxiv.org/abs/2411.07302</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized systems、sortition、performance optimization、merit-based sortition、infinite chances

总结:<br />
本文提出了一个针对分布式系统中参与者选择问题的“基于绩效的排序”（merit-based sortition）算法。该算法旨在优化计算限制或资源效率的同时，确保选出的活跃子集既具有高性能又保持代表性。与古典随机抽签相比，此算法允许每个参与者的入选概率与其质量相关联，而未被选中的参与者仍有无限次非零概率进入活跃集合，从而保证了向上流动性。通过数值实验，文章表明基于绩效的排序算法可以使活跃子集的性能指标提升超过两倍内在随机性的水平，这意味着该方法能够在显著提高表现性能的同时，满足分布式系统对于性能优化的需求。 <div>
arXiv:2411.07302v1 Announce Type: new 
Abstract: In decentralized systems, it is often necessary to select an 'active' subset of participants from the total participant pool, with the goal of satisfying computational limitations or optimizing resource efficiency. This selection can sometimes be made at random, mirroring the sortition practice invented in classical antiquity aimed at achieving a high degree of statistical representativeness. However, the recent emergence of specialized decentralized networks that solve concrete coordination problems and are characterized by measurable success metrics often requires prioritizing performance optimization over representativeness. We introduce a simple algorithm for 'merit-based sortition', in which the quality of each participant influences its probability of being drafted into the active set, while simultaneously retaining representativeness by allowing inactive participants an infinite number of chances to be drafted into the active set with non-zero probability. Using a suite of numerical experiments, we demonstrate that our algorithm boosts the quality metric describing the performance of the active set by $>2$ times the intrinsic stochasticity. This implies that merit-based sortition ensures a statistically significant performance boost to the drafted, 'active' set, while retaining the property of classical, random sortition that it enables upward mobility from a much larger 'inactive' set. This way, merit-based sortition fulfils a key requirement for decentralized systems in need of performance optimization.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Zoning of Industrial Environments with Autonomous Mobile Robots</title>
<link>https://arxiv.org/abs/2411.07382</link>
<guid>https://arxiv.org/abs/2411.07382</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主移动机器人(AMR), 分区调度算法, 均衡任务分配, 动态分区算法, 德分布式动态分区(DTZ)

<br /><br />总结:

本文提出了一种应用于制造/仓库环境中的自主移动机器人(AMR)调度算法，该算法将工作区域划分为若干个由AMR负责执行零件捡取和投放任务的分区。每个分区的任务量得到均衡分配，以确保每台AMR平等地承担任务，并能随生产波动动态调整分区布局，避免单一AMR过载。文章引入了分布式动态分区(DDZ)算法，旨在找到最优分区设计并消除中央控制单元单点故障的可能性。通过建立仿真模型对比分析了DDZ与其他动态分区算法的适应性，初步结果显示虽然DDZ的吞吐量较低，但其任务分布更为均匀。AMR总行驶距离的标准偏差降低了68.7%，即DDZ下的AMR在生产过程中行驶距离更接近，有利于现实中设计充电和维护计划，减少停机时间。文章还提供了系统运行的视频演示链接。 <div>
arXiv:2411.07382v1 Announce Type: new 
Abstract: This paper presents a scheduling algorithm that divides a manufacturing/warehouse floor into zones that an Autonomous Mobile Robot (AMR) will occupy and complete part pick-up and drop-off tasks. Each zone is balanced so that each AMR will share each task equally. These zones change over time to accommodate fluctuations in production and to avoid overloading an AMR with tasks. A decentralized dynamic zoning (DDZ) algorithm is introduced to find the optimal zone design, eliminating the possibility of single-point failure from a centralized unit. Then a simulation is built comparing the adaptability of DDZ and other dynamic zoning algorithms from previous works. Initial results show that DDZ has a much lower throughput than other dynamic zoning algorithms but DDZ can achieve a better distribution of tasks. Initial results show that DDZ had a lower standard deviation of AMR total travel distance which was 2874.7 feet less than previous works. This 68.7\% decrease in standard deviation suggests that AMRs under DDZ travel a similar distance during production. This could be useful for real-world applications by making it easier to design charging and maintenance schedules without much downtime. Video demonstration of the system working can be seen here: \url{https://youtu.be/yVi026oVD7U}
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning Client Pruning for Noisy Labels</title>
<link>https://arxiv.org/abs/2411.07391</link>
<guid>https://arxiv.org/abs/2411.07391</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Noisy Labels, ClipFL, Noise Candidacy Score, Performance Improvement

<br /><br />总结:
本文提出了一个新的Federated Learning框架——ClipFL，该框架针对边缘设备训练中存在的噪声标签问题。现有FL方法在处理高噪声水平的数据集时表现有限，而ClipFL通过引入噪声候选分数（NCS）来识别并排除具有噪声数据的客户端。它分为三个阶段：预客户端修剪以识别潜在噪声客户端并计算其NCS，客户端修剪则根据NCS排除一定比例的噪声客户端，以及后客户端修剪阶段，使用标准FL对干净客户端进行全局模型的微调。实验表明，ClipFL在各种数据集和噪声水平下都表现出准确的噪声客户端识别能力、更优的性能、更快的收敛速度以及更低的通信成本，相较于当前最先进的FL方法有显著优势。相关代码已在https://github.com/MMorafah/ClipFL上开源。 <div>
arXiv:2411.07391v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, existing FL methods often assume clean annotated datasets, impractical for resource-constrained edge devices. In reality, noisy labels are prevalent, posing significant challenges to FL performance. Prior approaches attempt label correction and robust training techniques but exhibit limited efficacy, particularly under high noise levels. This paper introduces ClipFL (Federated Learning Client Pruning), a novel framework addressing noisy labels from a fresh perspective. ClipFL identifies and excludes noisy clients based on their performance on a clean validation dataset, tracked using a Noise Candidacy Score (NCS). The framework comprises three phases: pre-client pruning to identify potential noisy clients and calculate their NCS, client pruning to exclude a percentage of clients with the highest NCS, and post-client pruning for fine-tuning the global model with standard FL on clean clients. Empirical evaluation demonstrates ClipFL's efficacy across diverse datasets and noise levels, achieving accurate noisy client identification, superior performance, faster convergence, and reduced communication costs compared to state-of-the-art FL methods. Our code is available at https://github.com/MMorafah/ClipFL.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Network Topology Design for Task Offloading in Mobile Edge Computing</title>
<link>https://arxiv.org/abs/2411.07485</link>
<guid>https://arxiv.org/abs/2411.07485</guid>
<content:encoded><![CDATA[
<div> 关键词：移动边缘计算(MEC)，网络拓扑设计，任务卸载，分布式，效率优化

总结:
本文探讨了物联网设备处理能力有限背景下，延迟敏感且计算密集型应用带来的挑战，并指出移动边缘计算（MEC）为此类问题提供了一种有前景的解决方案。然而，针对MEC的网络拓扑优化以提升计算效率的研究尚不充分。文章提出了一种新颖的、用于任务卸载的分布式网络拓扑设计策略（DNTD-TO），该策略同时考虑了拓扑设计与任务分配，并借鉴通信和传感器网络的经验，有效地构建了三层网络结构用于任务卸载，并为这些结构生成最优的任务分配方案。研究表明，相较于现有拓扑设计方法，DNTD-TO展现出了优越的性能表现。 <div>
arXiv:2411.07485v1 Announce Type: new 
Abstract: The rise of delay-sensitive yet computing-intensive Internet of Things (IoT) applications poses challenges due to the limited processing power of IoT devices. Mobile Edge Computing (MEC) offers a promising solution to address these challenges by placing computing servers close to end users. Despite extensive research on MEC, optimizing network topology to improve computational efficiency remains underexplored. Recognizing the critical role of network topology, we introduce a novel decentralized network topology design strategy for task offloading (DNTD-TO) that jointly considers topology design and task allocation. Inspired by communication and sensor networks, DNTD-TO efficiently constructs three-layered network structures for task offloading and generates optimal task allocations for these structures. Comparisons with existing topology design methods demonstrate the promising performance of our approach.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semantic Sleuth: Identifying Ponzi Contracts via Large Language Models</title>
<link>https://arxiv.org/abs/2411.07498</link>
<guid>https://arxiv.org/abs/2411.07498</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、庞氏骗局、PonziGuard、PonziSleuth、LLM

总结:
本文介绍了智能合约在区块链技术特别是去中心化金融和Web3中的重要性，但庞氏骗局的兴起对这一领域构成重大风险。现有的检测方法如PonziGuard依赖大量标注数据，难以识别新型庞氏骗局。为解决此问题，文章提出了一种新的无标注训练数据驱动的庞氏骗局智能合约检测方法——PonziSleuth。该方法利用大型语言模型（LLMs）的高级语义理解能力，通过创新的两步零样本思考提示技术分析智能合约源代码。实验结果显示，PonziSleuth在基准数据集和实际合约上的表现与现有方法相当或更优，例如使用GPT-3.5-turbo时平衡检测准确率达到96.06%。在真实环境检测中，PonziSleuth成功从Etherscan于2024年3月验证的4,597份合同中识别出15个新型庞氏骗局，具有0%的假阴性和0.29%的假阳性率，证实了其对多样化和新型庞氏骗局的检测能力，标志着利用LLMs增强区块链安全和防范金融欺诈的重要进步。 <div>
arXiv:2411.07498v1 Announce Type: new 
Abstract: Smart contracts, self-executing agreements directly encoded in code, are fundamental to blockchain technology, especially in decentralized finance (DeFi) and Web3. However, the rise of Ponzi schemes in smart contracts poses significant risks, leading to substantial financial losses and eroding trust in blockchain systems. Existing detection methods, such as PonziGuard, depend on large amounts of labeled data and struggle to identify unseen Ponzi schemes, limiting their reliability and generalizability. In contrast, we introduce PonziSleuth, the first LLM-driven approach for detecting Ponzi smart contracts, which requires no labeled training data. PonziSleuth utilizes advanced language understanding capabilities of LLMs to analyze smart contract source code through a novel two-step zero-shot chain-of-thought prompting technique. Our extensive evaluation on benchmark datasets and real-world contracts demonstrates that PonziSleuth delivers comparable, and often superior, performance without the extensive data requirements, achieving a balanced detection accuracy of 96.06% with GPT-3.5-turbo, 93.91% with LLAMA3, and 94.27% with Mistral. In real-world detection, PonziSleuth successfully identified 15 new Ponzi schemes from 4,597 contracts verified by Etherscan in March 2024, with a false negative rate of 0% and a false positive rate of 0.29%. These results highlight PonziSleuth's capability to detect diverse and novel Ponzi schemes, marking a significant advancement in leveraging LLMs for enhancing blockchain security and mitigating financial scams.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Performance Analysis of BFT Consensus for Blockchains</title>
<link>https://arxiv.org/abs/2411.07622</link>
<guid>https://arxiv.org/abs/2411.07622</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本、区块链、共识协议、BFT、Istanbul BFT、HotStuff、网络拓扑、 Folded-Clos、Dragonfly、定时器、分析模型、一致性时间

<br /><br />总结:
该文探讨了分布式账本中使用区块链作为底层基础设施的情况，并重点关注两种共识协议（Istanbul BFT和HotStuff）以及两种网络拓扑结构（Folded-Clos和Dragonfly）。文章提出了一种针对崩溃故障情况的分析模型，旨在研究不同共识协议在性能上的差异以及通信网络对其影响。此外，还讨论了共识协议中如何设置定时器以确保进程推进的问题。通过建立闭合形式的表达式，分析了定时器值、参与者数量、故障数和交换机数目对达成一致所需时间的影响。这些公式与仿真结果进行了验证，最后文中给出了一些此类协议分析建模的建议。 <div>
arXiv:2411.07622v1 Announce Type: new 
Abstract: Distributed ledgers are common in the industry. Some of them can use blockchains as their underlying infrastructure. A blockchain requires participants to agree on its contents. This can be achieved via a consensus protocol, and several BFT (Byzantine Fault Tolerant) protocols have been proposed for this purpose. How do these protocols differ in performance? And how is this difference affected by the communication network? Moreover, such a protocol would need a timer to ensure progress, but how should the timer be set?
  This paper presents an analytical model to address these and related issues in the case of crash faults. Specifically, it focuses on two consensus protocols (Istanbul BFT and HotStuff) and two network topologies (Folded-Clos and Dragonfly). The model provides closed-form expressions for analyzing how the timer value and number of participants, faults and switches affect the consensus time. The formulas and analyses are validated with simulations. The conclusion offers some tips for analytical modeling of such protocols.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoliDiffy: AST Differencing for Solidity Smart Contracts</title>
<link>https://arxiv.org/abs/2411.07718</link>
<guid>https://arxiv.org/abs/2411.07718</guid>
<content:encoded><![CDATA[
<div> 关键词: Solidity、智能合约、抽象语法树(AST)、差异分析、SoliDiffy

总结:
本文介绍了SoliDiffy，这是一种专为Solidity智能合约设计的新颖的抽象语法树(AST)差异工具。SoliDiffy能够生成准确且简洁的编辑脚本，从而实现对智能合约的细粒度分析和维护，适用于漏洞检测、自动化代码修复以及代码审查等下游任务。通过对大量真实世界的Solidity合同进行综合评估，结果显示SoliDiffy相比于现有最先进的工具能提供更短且更精确的编辑脚本，并在处理复杂的合同修改时表现出一致性。SoliDiffy已在https://github.com/mojtaba-eshghie/SoliDiffy上公开发布。 <div>
arXiv:2411.07718v1 Announce Type: new 
Abstract: Smart contracts, primarily written in Solidity, are integral to blockchain software applications, yet precise analysis and maintenance are hindered by the limitations of existing differencing tools. We introduce SoliDiffy, a novel Abstract Syntax Tree (AST) differencing tool specifically designed for Solidity. SoliDiffy enables fine-grained analysis by generating accurate and concise edit scripts of smart contracts, making it ideal for downstream tasks such as vulnerability detection, automated code repair, and code reviews. Our comprehensive evaluation on a large dataset of real-world Solidity contracts demonstrates that SoliDiffy delivers shorter and more precise edit scripts compared to state-of-the-art tools, while performing consistently in complex contract modifications. SoliDiffy is made publicly available at https://github.com/mojtaba-eshghie/SoliDiffy.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ALANINE: A Novel Decentralized Personalized Federated Learning For Heterogeneous LEO Satellite Constellation</title>
<link>https://arxiv.org/abs/2411.07752</link>
<guid>https://arxiv.org/abs/2411.07752</guid>
<content:encoded><![CDATA[
<div> 关键词：低地球轨道卫星星座、数据异质性、联邦学习、模型压缩、图像超分辨率

总结:<br />
针对近年来低地球轨道(LEO)卫星星座在通信、导航和遥感等领域功能增强所面临的挑战，尤其是数据异质性及有效进行星际协同计算的问题，本文提出了一种名为ALANINE的新颖分布式个性化联邦学习框架。ALANINE利用分布式联邦学习(DFL)对卫星图像进行超分辨率处理，提升输入数据质量；再结合个性化联邦学习(PFL)，以适应卫星数据的独特特性。同时，该框架采用高级模型压缩技术优化模型复杂度和传输效率。实验结果表明，相较于传统的集中式方法，ALANINE在轨训练图像超分辨率及PFL图像处理模型方面表现出更优性能，显著提高了数据采集效率、处理精度以及模型对局部卫星条件的适应性。 <div>
arXiv:2411.07752v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite constellations have seen significant growth and functional enhancement in recent years, which integrates various capabilities like communication, navigation, and remote sensing. However, the heterogeneity of data collected by different satellites and the problems of efficient inter-satellite collaborative computation pose significant obstacles to realizing the potential of these constellations. Existing approaches struggle with data heterogeneity, varing image resolutions, and the need for efficient on-orbit model training. To address these challenges, we propose a novel decentralized PFL framework, namely, A Novel Decentra L ized Person A lized Federated Learning for Heteroge N eous LEO Satell I te Co N st E llation (ALANINE). ALANINE incorporates decentralized FL (DFL) for satellite image Super Resolution (SR), which enhances input data quality. Then it utilizes PFL to implement a personalized approach that accounts for unique characteristics of satellite data. In addition, the framework employs advanced model pruning to optimize model complexity and transmission efficiency. The framework enables efficient data acquisition and processing while improving the accuracy of PFL image processing models. Simulation results demonstrate that ALANINE exhibits superior performance in on-orbit training of SR and PFL image processing models compared to traditional centralized approaches. This novel method shows significant improvements in data acquisition efficiency, process accuracy, and model adaptability to local satellite conditions.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enabling Data Confidentiality with Public Blockchains</title>
<link>https://arxiv.org/abs/2308.03791</link>
<guid>https://arxiv.org/abs/2308.03791</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、自动化、多党合作、隐私保护、MARTSIA

<br /><br />总结:
本文提出了一个名为MARTSIA的多权威交易系统方法，用于实现不同应用间的互操作性。该方法基于Multi-Authority Attribute-Based Encryption（MA-ABE），解决了公共区块链中数据透明度与企业保密要求之间的矛盾，通过用户定义的策略控制对共享数据的部分访问权限，仅允许具有特定属性的参与者解读加密信息，同时确保网络中所有节点能验证数据的发布。文章对MARTSIA的安全性进行了形式化分析，并在多个区块链平台上实现了概念证明。为了展示其实现多 party 过程执行和跨平台互操作性的能力，文中还以NFT市场、供应链和零售领域的三个实际应用场景为例进行了演示。 <div>
arXiv:2308.03791v5 Announce Type: replace 
Abstract: Blockchain technology is apt to facilitate the automation of multi-party cooperations among various players in a decentralized setting, especially in cases where trust among participants is limited. Transactions are stored in a ledger, a replica of which is retained by every node of the blockchain network. The operations saved thereby are thus publicly accessible. While this aspect enhances transparency, reliability, and persistence, it hinders the utilization of public blockchains for process automation as it violates typical confidentiality requirements in corporate settings. To overcome this issue, we propose our approach named Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA). Based on Multi-Authority Attribute-Based Encryption (MA-ABE), MARTSIA enables read-access control over shared data at the level of message parts. User-defined policies determine whether an actor can interpret the publicly stored information or not, depending on the actor's attributes declared by a consortium of certifiers. Still, all nodes in the blockchain network can attest to the publication of the (encrypted) data. We provide a formal analysis of the security guarantees of MARTSIA, and illustrate the proof-of-concept implementation over multiple blockchain platforms. To demonstrate its interoperability, we showcase its usage in ensemble with a state-of-the-art blockchain-based engine for multi-party process execution, and three real-world decentralized applications in the context of NFT markets, supply chain, and retail.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers</title>
<link>https://arxiv.org/abs/2411.06135</link>
<guid>https://arxiv.org/abs/2411.06135</guid>
<content:encoded><![CDATA[
<div> 关键词：在线多任务学习(OMTL)，梯度下降法，交替方向乘子法(ADMM)，分布式计算，数据规模

总结:
本文提出了一种基于交替方向乘子方法(ADMM)的新型在线多任务学习(OMTL)框架，旨在解决现有梯度下降法在OMTL中可能遇到的梯度消失和条件恶化问题，并适应在线并行优化的需求。该框架动态建模多个任务之间的关系，以适应不断变化的在线环境。在具有中央服务器的经典分布式计算架构下，利用ADMM优化器的OMTL算法在准确性和效率上优于基于SGD的方法。为进一步应对大数据场景下的中央服务器瓶颈问题，文章还针对去中心化设置调整了算法，使得每个节点仅需与其局部邻居交换信息即可工作。实验证实在合成数据集及几个真实世界数据集上的实验结果表明了所提方法的有效性。 <div>
arXiv:2411.06135v1 Announce Type: new 
Abstract: Online multi-task learning (OMTL) enhances streaming data processing by leveraging the inherent relations among multiple tasks. It can be described as an optimization problem in which a single loss function is defined for multiple tasks. Existing gradient-descent-based methods for this problem might suffer from gradient vanishing and poor conditioning issues. Furthermore, the centralized setting hinders their application to online parallel optimization, which is vital to big data analytics. Therefore, this study proposes a novel OMTL framework based on the alternating direction multiplier method (ADMM), a recent breakthrough in optimization suitable for the distributed computing environment because of its decomposable and easy-to-implement nature. The relations among multiple tasks are modeled dynamically to fit the constant changes in an online scenario. In a classical distributed computing architecture with a central server, the proposed OMTL algorithm with the ADMM optimizer outperforms SGD-based approaches in terms of accuracy and efficiency. Because the central server might become a bottleneck when the data scale grows, we further tailor the algorithm to a decentralized setting, so that each node can work by only exchanging information with local neighbors. Experimental results on a synthetic and several real-world datasets demonstrate the efficiency of our methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Sharded Blockchain-Based Secure Federated Learning Framework for LEO Satellite Networks</title>
<link>https://arxiv.org/abs/2411.06137</link>
<guid>https://arxiv.org/abs/2411.06137</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)，卫星网络，人工智能，网络安全，区块链，联邦学习，SBFL-LEO，模型验证，攻击防御

总结:<br />
随着低地球轨道(LEO)卫星网络在空间人工智能应用中的重要性日益增强，其面临来自卫星间通信链接的网络安全风险也随之增加。传统解决方案无法有效应对有限通信窗口条件下的安全挑战。为此，本文提出了基于分片区块链的LEO卫星网络联邦学习框架SBFL-LEO。该框架利用区块链技术强化卫星间的通信可靠性，并为每颗卫星分配特定角色。矿工卫星通过余弦相似性和DBSCAN算法识别恶意模型并互相监控，以检测不准确的聚合模型。安全分析和实验结果显示，与基线方法相比，SBFL-LEO在模型精度和能效方面表现出优越性能，显著提升了系统对抗攻击的鲁棒性。 <div>
arXiv:2411.06137v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite networks are increasingly essential for space-based artificial intelligence (AI) applications. However, as commercial use expands, LEO satellite networks face heightened cyberattack risks, especially through satellite-to-satellite communication links, which are more vulnerable than ground-based connections. As the number of operational satellites continues to grow, addressing these security challenges becomes increasingly critical. Traditional approaches, which focus on sending models to ground stations for validation, often overlook the limited communication windows available to LEO satellites, leaving critical security risks unaddressed. To tackle these challenges, we propose a sharded blockchain-based federated learning framework for LEO networks, called SBFL-LEO. This framework improves the reliability of inter-satellite communications using blockchain technology and assigns specific roles to each satellite. Miner satellites leverage cosine similarity (CS) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to identify malicious models and monitor each other to detect inaccurate aggregated models. Security analysis and experimental results demonstrate that our approach outperforms baseline methods in both model accuracy and energy efficiency, significantly enhancing system robustness against attacks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BM-PAW: A Profitable Mining Attack in the PoW-based Blockchain System</title>
<link>https://arxiv.org/abs/2411.06187</link>
<guid>https://arxiv.org/abs/2411.06187</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、PoW、挖矿攻击、BM-PAW、对策

总结:
<br />
本文介绍了针对PoW区块链系统的新型挖矿策略——BM-PAW，该策略允许攻击者和目标矿池获得比现有最先进的挖矿攻击（PAW）更大的收益。通过分析，发现BM-PAW攻击者有动力向其他目标提供适当的贿赂，以使这些目标遵循其指令。进一步研究了在两池BM-PAW博弈场景中，攻击者如何通过其挖矿算力来规避“矿工困境”的均衡分析。最后，文章提出了应对这类新型矿池攻击的实际对策。 <div>
arXiv:2411.06187v1 Announce Type: new 
Abstract: Mining attacks enable an adversary to procure a disproportionately large portion of mining rewards by deviating from honest mining practices within the PoW-based blockchain system. In this paper, we demonstrate that the security vulnerabilities of PoW-based blockchain extend beyond what these mining attacks initially reveal. We introduce a novel mining strategy, named BM-PAW, which yields superior rewards for both the attacker and the targeted pool compared to the state-of-the-art mining attack: PAW. Our analysis reveals that BM-PAW attackers are incentivized to offer appropriate bribe money to other targets, as they comply with the attacker's directives upon receiving payment. We find the BM-PAW attacker can circumvent the "miner's dilemma" through equilibrium analysis in a two-pool BM-PAW game scenario, wherein the outcome is determined by the attacker's mining power. We finally propose practical countermeasures to mitigate these novel pool attacks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation</title>
<link>https://arxiv.org/abs/2411.06221</link>
<guid>https://arxiv.org/abs/2411.06221</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、智能合约、安全挑战、LLM、Smart-LLaMA

总结:
随着区块链技术的迅速发展，智能合约安全性成为一个重大挑战。现有智能合约漏洞检测方法面临三大问题：数据集质量不足，缺乏详细解释和精确漏洞位置信息；大型语言模型（LLMs）对智能合约领域的适应性有限，因为大多数LLMs仅在通用文本数据上预训练而缺少智能合约特定的数据；对于检测到的漏洞缺乏高质量的解释，现有方法只关注检测而非清晰解释。为解决这些问题，文章提出了基于LLaMA语言模型的高级检测方法Smart-LLaMA。首先，构建了一个涵盖四种漏洞类型的全面数据集，其中包含标签、详细解释及精确漏洞位置信息。其次，引入了针对智能合约的专业持续预训练，使用原始智能合约数据使LLM能够学习智能合约的语法和语义，提升其领域适应性。此外，还提出了解释引导的微调方法，通过成对的脆弱代码及其解释对LLM进行微调，实现既检测漏洞又给出有理有据的解释。实验结果显示，Smart-LLaMA在性能上优于当前最优基线，F1分数和准确率平均分别提高了6.49%和3.78%，同时提供了可靠的解释。 <div>
arXiv:2411.06221v1 Announce Type: new 
Abstract: With the rapid development of blockchain technology, smart contract security has become a critical challenge. Existing smart contract vulnerability detection methods face three main issues: (1) Insufficient quality of datasets, lacking detailed explanations and precise vulnerability locations. (2) Limited adaptability of large language models (LLMs) to the smart contract domain, as most LLMs are pre-trained on general text data but minimal smart contract-specific data. (3) Lack of high-quality explanations for detected vulnerabilities, as existing methods focus solely on detection without clear explanations. These limitations hinder detection performance and make it harder for developers to understand and fix vulnerabilities quickly, potentially leading to severe financial losses. To address these problems, we propose Smart-LLaMA, an advanced detection method based on the LLaMA language model. First, we construct a comprehensive dataset covering four vulnerability types with labels, detailed explanations, and precise vulnerability locations. Second, we introduce Smart Contract-Specific Continual Pre-Training, using raw smart contract data to enable the LLM to learn smart contract syntax and semantics, enhancing their domain adaptability. Furthermore, we propose Explanation-Guided Fine-Tuning, which fine-tunes the LLM using paired vulnerable code and explanations, enabling both vulnerability detection and reasoned explanations. We evaluate explanation quality through LLM and human evaluation, focusing on Correctness, Completeness, and Conciseness. Experimental results show that Smart-LLaMA outperforms state-of-the-art baselines, with average improvements of 6.49% in F1 score and 3.78% in accuracy, while providing reliable explanations.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Client Contribution Normalization for Enhanced Federated Learning</title>
<link>https://arxiv.org/abs/2411.06352</link>
<guid>https://arxiv.org/abs/2411.06352</guid>
<content:encoded><![CDATA[
<div> 关键词：移动设备、联邦学习（FL）、统计异质性、局部模型、均值潜表示归一化

<br /><br />总结:
本文针对移动设备产生的分散异构数据带来的挑战，重点研究了联邦学习（FL）中的统计异质性问题。为了解决非独立同分布（non-IID）数据对FL模型收敛性和性能的影响，文章提出了一种新颖的方法，该方法利用本地训练模型导出的均值潜表示进行归一化，使服务器能够在聚合过程中估计和调整客户端贡献的差异。这一归一化策略能提升全局模型的泛化能力并缓解传统联邦平均方法的局限性。主要贡献包括：引入基于均值潜表示的归一化方案处理FL中的统计异质性；展示该方法与现有FL算法的无缝集成，可在非-IID设置中提高性能；并通过在多个多样化数据集上的广泛实验验证了该方法，结果表明在数据分布偏斜的情况下，模型准确性和一致性有显著提升。实验还涉及FedAvg、FedProx、FedBABU、FedNova、SCAFFOLD及SGDM等六种FL方案，突显了所提方法的鲁棒性。该研究通过提供一种实用且计算效率高的解决方案，推动了FL应对统计异质性的能力，有助于构建更可靠和泛化的机器学习模型。 <div>
arXiv:2411.06352v1 Announce Type: new 
Abstract: Mobile devices, including smartphones and laptops, generate decentralized and heterogeneous data, presenting significant challenges for traditional centralized machine learning models due to substantial communication costs and privacy risks. Federated Learning (FL) offers a promising alternative by enabling collaborative training of a global model across decentralized devices without data sharing. However, FL faces challenges due to statistical heterogeneity among clients, where non-independent and identically distributed (non-IID) data impedes model convergence and performance. This paper focuses on data-dependent heterogeneity in FL and proposes a novel approach leveraging mean latent representations extracted from locally trained models. The proposed method normalizes client contributions based on these representations, allowing the central server to estimate and adjust for heterogeneity during aggregation. This normalization enhances the global model's generalization and mitigates the limitations of conventional federated averaging methods. The main contributions include introducing a normalization scheme using mean latent representations to handle statistical heterogeneity in FL, demonstrating the seamless integration with existing FL algorithms to improve performance in non-IID settings, and validating the approach through extensive experiments on diverse datasets. Results show significant improvements in model accuracy and consistency across skewed distributions. Our experiments with six FL schemes: FedAvg, FedProx, FedBABU, FedNova, SCAFFOLD, and SGDM highlight the robustness of our approach. This research advances FL by providing a practical and computationally efficient solution for statistical heterogeneity, contributing to the development of more reliable and generalized machine learning models.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Will Central Bank Digital Currencies (CBDC) and Blockchain Cryptocurrencies Coexist in the Post Quantum Era?</title>
<link>https://arxiv.org/abs/2411.06362</link>
<guid>https://arxiv.org/abs/2411.06362</guid>
<content:encoded><![CDATA[
<div> 关键词: CBDCs, 区块链, 量子计算, 多方计算, 隐蔽传输<br /><br />总结:<br />
本文探讨了中央银行数字货币(CBDCs)和基于区块链的加密货币在后量子计算环境下的共存可能性。文章分析了新兴量子算法和密码技术，如多方计算(MPC)和隐蔽传输(OT)，对CBDCs及加密货币的影响。同时研究了如何使CBDCs和加密货币整合后量子密码学防御机制，以及过渡传统系统并推动新标准的广泛应用所面临的重大挑战。文中还对量子环境中的CBDC进行了全面评估，并对比了不同加密货币模型。此外，文章深入剖析了相关量子方法及其与区块链架构的接口问题。作者还考察了量子威胁对加密货币方案的重要性，并讨论了预期中量子计算进步对未来算法及其应用的影响。最后，论文得出结论：只要通过持续的协同努力解决挑战、验证解决方案并指导政策演进，长期共存是可行的。 <div>
arXiv:2411.06362v1 Announce Type: new 
Abstract: This paper explores the coexistence possibilities of Central Bank Digital Currencies (CBDCs) and blockchain-based cryptocurrencies within a post-quantum computing landscape. It examines the implications of emerging quantum algorithms and cryptographic techniques such as Multi-Party Computation (MPC) and Oblivious Transfer (OT). While exploring how CBDCs and cryptocurrencies might integrate defenses like post-quantum cryptography, it highlights the substantial hurdles in transitioning legacy systems and fostering widespread adoption of new standards. The paper includes comprehensive evaluations of CBDCs in a quantum context. It also features comparisons to alternative cryptocurrency models. Additionally, the paper provides insightful analyses of pertinent quantum methodologies. Examinations of interfaces between these methods and blockchain architectures are also included. The paper carries out considered appraisals of quantum threats and their relevance for cryptocurrency schemes. Furthermore, it features discussions of the influence of anticipated advances in quantum computing on algorithms and their applications. The paper renders the judicious conclusion that long-term coexistence is viable provided challenges are constructively addressed through ongoing collaborative efforts to validate solutions and guide evolving policies.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Bus Voltage Restoration for DC Microgrids</title>
<link>https://arxiv.org/abs/2411.06531</link>
<guid>https://arxiv.org/abs/2411.06531</guid>
<content:encoded><![CDATA[
<div> 关键词: DC微电网、电压调节、集中式控制、分布式控制、通信链接

总结:
本文介绍了一种针对DC微电网中直流母线电压调节的新方法，旨在确保可靠性并维持负载端电压稳定。现有的电压恢复技术主要依赖于中心化的二级控制层，通过通信链路对每个转换器发送校正指令。与之不同的是，该论文提出了一种局部而直接的分布式控制策略，通过在每个转换器内部增加一个基于转换器输出电流和馈线电阻的附加控制环路反馈来补偿馈线电阻导致的电压降。这种方法经仿真和硬件在环测试验证有效，消除了对通信链接的依赖，从而提高了系统可靠性和降低了网络安全威胁。 <div>
arXiv:2411.06531v1 Announce Type: new 
Abstract: Regulating the voltage of the common DC bus, also referred to as the load bus, in DC microgrids is crucial for ensuring reliability and maintaining the nominal load voltage, which is essential for protecting sensitive loads from voltage variations. Stability and reliability are thereby enhanced, preventing malfunctions and extending the lifespan of sensitive loads (e.g., electronic devices). Voltage drops are caused by resistances of feeders connecting converters to the common DC bus, resulting in a reduced DC bus voltage compared to the nominal/desired value. Existing techniques to restore this voltage in DC microgrids are mainly centralized and rely on secondary control layers. These layers sense the common DC bus voltage, compare it to the nominal value, and utilize a PI controller to send corrections via communication links to each converter. In this paper, a local and straightforward approach to restoring the bus voltage in DC microgrids is presented, ensuring regulation in a decentralized manner. Voltage drops across resistances of feeders are compensated by an additional control loop feedback within each converter, based on the converter output current and feeder resistance. The proposed approach is verified through simulation and hardware-in-the-loop results, eliminating the need for communication links and hence increasing reliability and reducing cybersecurity threats.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Next-Generation Approach to Airline Reservations: Integrating Cloud Microservices with AI and Blockchain for Enhanced Operational Performance</title>
<link>https://arxiv.org/abs/2411.06538</link>
<guid>https://arxiv.org/abs/2411.06538</guid>
<content:encoded><![CDATA[
<div> 关键词: 云微服务、分布式人工智能模块、区块链技术、航空预订系统、效率安全顾客满意度

<br /><br />总结:
本文提出了一种下一代航空预订系统的设计方案，该系统融合了云微服务、分布式人工智能模块和区块链技术，旨在提升效率、数据安全性和顾客满意度。通过采用模块化和数据驱动设计方法，解决了传统预订系统在扩展性、数据完整性和服务水平方面的问题，实现了系统高可用性提升30%，性能增强40%的可扩展性提升。利用AI模块预测需求并提供个性化推荐，使客户参与度提高了25%。区块链技术的应用为交易提供了不可篡改的账本系统，降低了欺诈事件发生，提升了透明度达20%。经模拟器和机器学习评估分析，新系统的交易处理速度提高35%，系统响应时间缩短15%。此外，该系统也可应用于物流和酒店等其他高交易量行业。这项创新设计展示了先进科技将如何重塑航空预订领域，实现更高效、更安全以及更高顾客满意度的发展。 <div>
arXiv:2411.06538v1 Announce Type: new 
Abstract: This research proposes the development of a next generation airline reservation system that incorporates the Cloud microservices, distributed artificial intelligence modules and the blockchain technology to improve on the efficiency, safety and customer satisfaction. The traditional reservation systems encounter issues related to the expansion of the systems, the integrity of the data provided and the level of service offered to the customers, which is the main focus of this architecture through the modular and data centric design approaches. This will allow different operations such as reservations, payments, and customer data management among others to be performed separately thereby facilitating high availability of the system by 30% and enhancing performance of the system by 40% on its scalability. Such systems contain AI driven modules that utilize the past booking patterns along with the profile of the customer to estimate the demand and make recommendations, which increases to 25 % of customer engagement. Moreover, blockchain is effective in engaging an incorruptible ledger system for the all transactions therefore mitigating fraud incidences and increasing the clarity by 20%. The system was subjected to analysis using a simulator and using machine learning evaluations that rated it against other conventional systems. The results show that there were clear enhancements in the speed of transactions where the rates of secure data processing rose by 35%, and the system response time by 15 %. The system can also be used for other high transaction industries like logistics and hospitality. This structural design is indicative of how the use of advanced technologies will revolutionize the airline reservation sector. The implications are growing effectiveness, improvement in security and greater customer contentment.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Using Diffusion Models as Generative Replay in Continual Federated Learning -- What will Happen?</title>
<link>https://arxiv.org/abs/2411.06618</link>
<guid>https://arxiv.org/abs/2411.06618</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、连续学习（Continuous Learning）、灾难性遗忘（Catastrophic Forgetting）、非独立同分布数据（Non-IID Input Data）、扩散模型（Diffusion Model）

<br /><br />总结:
本文介绍了针对动态分布式学习环境中不断变化的数据分布所提出的连续联邦学习（CFL）任务及其挑战。为了解决其中的灾难性遗忘和非独立同分布输入数据问题，文章引入了一个名为DCFL的新框架。DCFL利用条件扩散模型在通信期间于每个本地设备生成合成的历史数据，有效缓解了动态数据分布输入带来的潜在变化。此外，文章还给出了所提CFL框架的收敛界，并通过多个数据集展示了其优越性能，证明了它在应对CFL任务复杂性方面的有效性。 <div>
arXiv:2411.06618v1 Announce Type: new 
Abstract: Federated learning (FL) has become a cornerstone in decentralized learning, where, in many scenarios, the incoming data distribution will change dynamically over time, introducing continuous learning (CL) problems. This continual federated learning (CFL) task presents unique challenges, particularly regarding catastrophic forgetting and non-IID input data. Existing solutions include using a replay buffer to store historical data or leveraging generative adversarial networks. Nevertheless, motivated by recent advancements in the diffusion model for generative tasks, this paper introduces DCFL, a novel framework tailored to address the challenges of CFL in dynamic distributed learning environments. Our approach harnesses the power of the conditional diffusion model to generate synthetic historical data at each local device during communication, effectively mitigating latent shifts in dynamic data distribution inputs. We provide the convergence bound for the proposed CFL framework and demonstrate its promising performance across multiple datasets, showcasing its effectiveness in tackling the complexities of CFL tasks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DynaShard: Secure and Adaptive Blockchain Sharding Protocol with Hybrid Consensus and Dynamic Shard Management</title>
<link>https://arxiv.org/abs/2411.06895</link>
<guid>https://arxiv.org/abs/2411.06895</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链分片、DynaShard、动态工作负载、跨片交易、系统完整性

总结:
本文提出了一种名为DynaShard的新颖解决方案，旨在解决区块链分片技术在处理动态工作负载、确保跨片交易安全及维护系统完整性的现有挑战。DynaShard结合了自适应分片管理、混合共识机制以及高效的状态同步和争议解决协议。通过在模拟真实网络条件和交易负载的实验环境下进行性能评估，结果显示DynaShard相比FTBS方法在吞吐量、延迟和分片利用率方面表现出显著优势，特别是在高交易量和可变跨片交易比例的情况下，能将延迟降低最多42.6%，分片利用率提升高达78.77%。这些成果表明DynaShard能够在可扩展性和系统韧性方面超越现有的区块链分片方法，对于未来区块链技术的发展具有重大影响，为构建更高效、安全的分布式系统奠定了基础。

<br /><br /> <div>
arXiv:2411.06895v1 Announce Type: new 
Abstract: Blockchain sharding has emerged as a promising solution to the scalability challenges in traditional blockchain systems by partitioning the network into smaller, manageable subsets called shards. Despite its potential, existing sharding solutions face significant limitations in handling dynamic workloads, ensuring secure cross-shard transactions, and maintaining system integrity. To address these gaps, we propose DynaShard, a dynamic and secure cross-shard transaction processing mechanism designed to enhance blockchain sharding efficiency and security. DynaShard combines adaptive shard management, a hybrid consensus approach, plus an efficient state synchronization and dispute resolution protocol. Our performance evaluation, conducted using a robust experimental setup with real-world network conditions and transaction workloads, demonstrates DynaShard's superior throughput, reduced latency, and improved shard utilization compared to the FTBS method. Specifically, DynaShard achieves up to a 42.6% reduction in latency and a 78.77% improvement in shard utilization under high transaction volumes and varying cross-shard transaction ratios. These results highlight DynaShard's ability to outperform state-of-the-art sharding methods, ensuring scalable and resilient blockchain systems. We believe that DynaShard's innovative approach will significantly impact future developments in blockchain technology, paving the way for more efficient and secure distributed systems.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Multi-Agent Collaborative Manipulation for Long-Horizon Quadrupedal Pushing</title>
<link>https://arxiv.org/abs/2411.07104</link>
<guid>https://arxiv.org/abs/2411.07104</guid>
<content:encoded><![CDATA[
<div> 关键词：四足机器人、多智能体强化学习、障碍物感知、长期推动物理任务、模拟与现实世界

<br />
总结:

本文提出了一种用于多四足机器人的层次化多智能体强化学习框架，旨在提升它们在处理大型物体方面的操纵能力，特别是实现障碍物感知的长期推动物理任务。该框架包含三个控制层级：高层控制器结合RRT规划器和集中式自适应策略生成子目标；中层控制器采用分布式目标条件策略指导机器人朝这些子目标移动；而预训练的低层运动策略执行移动指令。文章通过在仿真环境中对比多个基线方法，表明所提方法成功率提高了36.0%，完成时间减少了24.5%。此外，该框架成功地使Go1机器人在真实世界中完成了如Push-Cuboid和Push-T等长期、障碍物感知的操纵任务。 <div>
arXiv:2411.07104v1 Announce Type: new 
Abstract: Recently, quadrupedal locomotion has achieved significant success, but their manipulation capabilities, particularly in handling large objects, remain limited, restricting their usefulness in demanding real-world applications such as search and rescue, construction, industrial automation, and room organization. This paper tackles the task of obstacle-aware, long-horizon pushing by multiple quadrupedal robots. We propose a hierarchical multi-agent reinforcement learning framework with three levels of control. The high-level controller integrates an RRT planner and a centralized adaptive policy to generate subgoals, while the mid-level controller uses a decentralized goal-conditioned policy to guide the robots toward these sub-goals. A pre-trained low-level locomotion policy executes the movement commands. We evaluate our method against several baselines in simulation, demonstrating significant improvements over baseline approaches, with 36.0% higher success rates and 24.5% reduction in completion time than the best baseline. Our framework successfully enables long-horizon, obstacle-aware manipulation tasks like Push-Cuboid and Push-T on Go1 robots in the real world.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2411.07161</link>
<guid>https://arxiv.org/abs/2411.07161</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-Agent Systems, decentralized group decision-making, communication dynamics, voting rules, linguistic features

总结:
本研究关注了多智能体系统在无中心化的环境中如何通过跨智能体通信和群体决策增强集体智慧。研究重点在于不同社会选择方法中的通信和决策动态，并发现适度的决策灵活性能带来更好的结果。通过对智能体间对话的语言特征进行探索，揭示了有效协作的指标，为理解和识别促进或阻碍协作的沟通模式提供了洞见。此外，文章还提出了依据语言线索确定多智能体合作最优停止点的各种方法。这些发现深化了我们对去中心化决策制定和小组讨论如何塑造多智能体协作的理解，对于构建更有效的多智能体系统环境具有启示意义。<br /><br /> <div>
arXiv:2411.07161v1 Announce Type: new 
Abstract: This study investigates the efficacy of Multi-Agent Systems in eliciting cross-agent communication and enhancing collective intelligence through group decision-making in a decentralized setting. Unlike centralized mechanisms, where a fixed hierarchy governs social choice, decentralized group decision-making allows agents to engage in joint deliberation. Our research focuses on the dynamics of communication and decision-making within various social choice methods. By applying different voting rules in various environments, we find that moderate decision flexibility yields better outcomes. Additionally, exploring the linguistic features of agent-to-agent conversations reveals indicators of effective collaboration, offering insights into communication patterns that facilitate or hinder collaboration. Finally, we propose various methods for determining the optimal stopping point in multi-agent collaborations based on linguistic cues. Our findings contribute to a deeper understanding of how decentralized decision-making and group conversation shape multi-agent collaboration, with implications for the design of more effective MAS environments.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Approaching multifractal complexity in decentralized cryptocurrency trading</title>
<link>https://arxiv.org/abs/2411.05951</link>
<guid>https://arxiv.org/abs/2411.05951</guid>
<content:encoded><![CDATA[
<div> 关键词：多尺度分形、Multifractal Detrended Fluctuation Analysis (MFDFA)、去中心化交易所、交易量、收益率

总结:
该研究使用多尺度分形分析方法(Multifractal Detrended Fluctuation Analysis, MFDFA)，针对2023年6月6日至2024年6月30日期间从Uniswap去中心化交易所Universal Router合约获取的逐笔交易数据进行分析。结果显示，尽管去中心化交易所的流动性相较于集中式交易所仍然较低，但已显现出明显的多尺度分形特征。这些多尺度分形主要源于大波动，而小波动则更像无相关噪声。值得注意的是，交易量时间序列的多尺度分形特征比收益率更为显著，并在较大事件层面观察到了两者之间的多尺度交叉相关性。 <div>
arXiv:2411.05951v1 Announce Type: cross 
Abstract: Multifractality is a concept that helps compactly grasping the most essential features of the financial dynamics. In its fully developed form, this concept applies to essentially all mature financial markets and even to more liquid cryptocurrencies traded on the centralized exchanges. A new element that adds complexity to cryptocurrency markets is the possibility of decentralized trading. Based on the extracted tick-by-tick transaction data from the Universal Router contract of the Uniswap decentralized exchange, from June 6, 2023, to June 30, 2024, the present study using Multifractal Detrended Fluctuation Analysis (MFDFA) shows that even though liquidity on these new exchanges is still much lower compared to centralized exchanges convincing traces of multifractality are already emerging on this new trading as well. The resulting multifractal spectra are however strongly left-side asymmetric which indicates that this multifractality comes primarily from large fluctuations and small ones are more of the uncorrelated noise type. What is particularly interesting here is the fact that multifractality is more developed for time series representing transaction volumes than rates of return. On the level of these larger events a trace of multifractal cross-correlations between the two characteristics is also observed.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Semantic Communication and Cooperative Tracking Control for a UAV Swarm over Wireless MIMO Fading Channels</title>
<link>https://arxiv.org/abs/2411.06136</link>
<guid>https://arxiv.org/abs/2411.06136</guid>
<content:encoded><![CDATA[
<div> 关键词：UAV Swarm, Semantic Communication, Cooperative Tracking Control, Unreliable Wireless MIMO Channels, Drift-Plus-Penalty Optimization

总结:
该文研究了一种由领导无人机和多个跟随无人机组成的无人机群的语义通信与合作跟踪控制问题。文中首先建立了考虑内部交互和无线多输入多输出（MIMO）信道不稳定性影响的无人机群动态模型。接着，将无人机功率成本纳入考量，并将通信与合作跟踪控制挑战建模为一个漂移加罚优化问题，进而导出了能根据跟踪误差成本和局部信道条件自适应调整的分布式语义架构下的最优解。通过Lyapunov漂移分析方法，确立了确保无人机群跟踪性能稳定的封闭形式充分条件。数值结果表明，所提出的方案相较于现有多种方法具有显著优势。 <div>
arXiv:2411.06136v1 Announce Type: cross 
Abstract: This paper investigates the semantic communication and cooperative tracking control for an UAV swarm comprising a leader UAV and a group of follower UAVs, all interconnected via unreliable wireless multiple-input-multiple-output (MIMO) channels. Initially, we develop a dynamic model for the UAV swarm that accounts for both the internal interactions among the cooperative follower UAVs and the imperfections inherent in the MIMO channels that interlink the leader and follower UAVs. Building on this model, we incorporate the power costs of the UAVs and formulate the communication and cooperative tracking control challenge as a drift-plus-penalty optimization problem. We then derive a closed-form optimal solution that maintains a decentralized semantic architecture, dynamically adjusting to the tracking error costs and local channel conditions within the swarm. Employing Lyapunov drift analysis, we establish closed-form sufficient conditions for the stabilization of the UAV swarm's tracking performance. Numerical results demonstrate the significant enhancements in our proposed scheme over various state-of-the-art methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Graph Condensation with Information Bottleneck Principles</title>
<link>https://arxiv.org/abs/2405.03911</link>
<guid>https://arxiv.org/abs/2405.03911</guid>
<content:encoded><![CDATA[
<div> 关键词: 图压缩，联邦学习，隐私保护，图神经网络，信息瓶颈

总结:
本文提出了一个新的研究问题——联邦图压缩，针对大规模分布式图数据场景，旨在在保护数据持有者隐私的同时，进行有效的图压缩。为解决此问题，文章提出了一种联邦图压缩框架，该框架将传统的图压缩中的梯度匹配过程分解为客户端的梯度计算和服务器端的梯度匹配，有效减轻了客户端的计算负担。然而，实验表明在联邦学习环境下，压缩过程中会持续泄露数据成员身份隐私，对此，文中创新性地引入信息瓶颈原理，在局部预训练阶段仅提取部分节点特征并在联邦训练中使用，从而有效防止会员信息泄露。实验证明，所提出的联邦图压缩框架不仅在训练过程中能较好地保护成员隐私，而且其性能与现有集中式图压缩和联邦图学习方法相比也表现出可比甚至更优的效果。 <div>
arXiv:2405.03911v2 Announce Type: replace 
Abstract: Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediately benefited various graph learning tasks. However, existing graph condensation methods rely on centralized data storage, which is unfeasible for real-world decentralized data distribution, and overlook data holders' privacy-preserving requirements. To bridge the gap, we propose and study the novel problem of federated graph condensation for graph neural networks (GNNs). Specifically, we first propose a general framework for federated graph condensation, in which we decouple the typical gradient matching process for graph condensation into client-side gradient calculation and server-side gradient matching. In this way, the burdensome computation cost in client-side is largely alleviated. Besides, our empirical studies show that under the federated setting, the condensed graph will consistently leak data membership privacy, i.e., the condensed graph during the federated training can be utilized to steal the training data under the membership inference attacks (MIA). To tackle this issue, we innovatively incorporate information bottleneck principles into the federated graph condensation, which only needs to extract partial node features in one local pre-training step and utilize the features during federated training. Extensive experiments on real-world datasets demonstrate that our framework can consistently protect membership privacy during training. Meanwhile, it also achieves comparable and even superior performance against existing centralized graph condensation and federated graph learning methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sustainable business decision modelling with blockchain and digital twins: A survey</title>
<link>https://arxiv.org/abs/2405.12101</link>
<guid>https://arxiv.org/abs/2405.12101</guid>
<content:encoded><![CDATA[
<div> 关键词：Industry 4.0、Business Decision Modelling (BDM)、区块链、Digital Twin (DT)、可持续性

<br /><br />总结:
本文探讨了工业4.0及其未来发展将严重依赖可持续性的商业决策建模（BDM），而区块链和数字孪生（DT）技术可以加速这一进程。BDM基于模型和框架，需要通过关键识别因素、数据分析和适用于复杂业务场景的数学或计算方法进行提炼。为了从收集的数据中获取可用于BDM的行动智能，需建立确保数据透明度、安全性和可访问性的基础设施，并注重其可持续性。文章强调组织应考虑社会、经济和环境因素（基于三重底线原则），以确保整合此类基础设施时的可持续性。通过对现有研究的深入审查，定义了分类体系来评估区块链和DT的可持续性特征，并进行了详细的比较评价，揭示了这些解决方案在理念、访问控制和性能开销方面的可达性。同时提出了若干研究问题以推动进一步的研究，并结合供应链管理系统的实例展示区块链和DT与BDM之间的互操作性。 <div>
arXiv:2405.12101v2 Announce Type: replace 
Abstract: Industry 4.0 and beyond will rely heavily on sustainable Business Decision Modelling (BDM) that can be accelerated by blockchain and Digital Twin (DT) solutions. BDM is built on models and frameworks refined by key identification factors, data analysis, and mathematical or computational aspects applicable to complex business scenarios. Gaining actionable intelligence from collected data for BDM requires a carefully considered infrastructure to ensure data transparency, security, accessibility and sustainability. Organisations should consider social, economic and environmental factors (based on the triple bottom line approach) to ensure sustainability when integrating such an infrastructure. These sustainability features directly impact BDM concerning resource optimisation, stakeholder engagement, regulatory compliance and environmental impacts. To further understand these segments, taxonomies are defined to evaluate blockchain and DT sustainability features based on an in-depth review of the current state-of-the-art research. Detailed comparative evaluations provide insight into the reachability of the sustainable solution in terms of ideologies, access control and performance overheads. Several research questions are put forward to motivate further research that significantly impacts BDM. Finally, a case study based on an exemplary supply chain management system is presented to show the interoperability of blockchain and DT with BDM.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smoothed Gradient Clipping and Error Feedback for Decentralized Optimization under Symmetric Heavy-Tailed Noise</title>
<link>https://arxiv.org/abs/2310.16920</link>
<guid>https://arxiv.org/abs/2310.16920</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模机器学习、梯度裁剪、分布式优化、误差反馈机制、重尾噪声

总结:
本文针对具有重尾梯度噪声的大规模机器学习背景下，研究了带有梯度裁剪的去中心化优化问题。鉴于常规梯度裁剪在异构分布式环境中会引入偏差导致收敛性问题，文章提出了一个平滑裁剪操作员和一种结合误差反馈机制的去中心化梯度方法，该方法将裁剪操作应用在当地梯度估计与局部随机梯度之差上。在考虑对称重尾梯度噪声且不假设梯度有界的情况下，文中证明了所提方法在强凸光滑局部函数场景下能达到均方误差（MSE）收敛率为$O(1/t^\delta)$，其中$\delta \in (0, 2/5)$，指数$\delta$与高阶梯度噪声矩$\alpha > 1$的存在性无关，且由一些与条件数相关的常数下界保证。据作者所知，这是首次在未假设梯度有界的重尾噪声环境下，对于去中心化梯度裁剪提出的MSE收敛结果。实验验证了理论发现的有效性。<br /><br /> <div>
arXiv:2310.16920v3 Announce Type: replace-cross 
Abstract: Motivated by understanding and analysis of large-scale machine learning under heavy-tailed gradient noise, we study decentralized optimization with gradient clipping, i.e., in which certain clipping operators are applied to the gradients or gradient estimates computed from local nodes prior to further processing. While vanilla gradient clipping has proven effective in mitigating the impact of heavy-tailed gradient noise in non-distributed setups, it incurs bias that causes convergence issues in heterogeneous distributed settings. To address the inherent bias introduced by gradient clipping, we develop a smoothed clipping operator, and propose a decentralized gradient method equipped with an error feedback mechanism, i.e., the clipping operator is applied on the difference between some local gradient estimator and local stochastic gradient. We consider strongly convex and smooth local functions under symmetric heavy-tailed gradient noise that may not have finite moments of order greater than one. We show that the proposed decentralized gradient clipping method achieves a mean-square error (MSE) convergence rate of $O(1/t^\delta)$, $\delta \in (0, 2/5)$, where the exponent $\delta$ is independent of the existence of higher order gradient noise moments $\alpha > 1$ and lower bounded by some constant dependent on condition number. To the best of our knowledge, this is the first MSE convergence result for decentralized gradient clipping under heavy-tailed noise without assuming bounded gradient. Numerical experiments validate our theoretical findings.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EPIC: Enhancing Privacy through Iterative Collaboration</title>
<link>https://arxiv.org/abs/2411.05167</link>
<guid>https://arxiv.org/abs/2411.05167</guid>
<content:encoded><![CDATA[
<div> 关键词：病毒序列数据、机器学习、联邦学习、隐私保护、协同优化

<br /><br />总结:

本文提出了一种名为“EPIC”的创新隐私增强迭代协作架构，该架构旨在解决在不转移原始SARS-CoV-2基因序列数据的情况下，对其序列数据谱系进行监督分类的问题。随着基因组学技术的进步和病毒序列数据量的增长，机器学习在生物信息学中的应用日益增加，但传统的集中式数据处理方式面临现实医疗场景下的挑战以及数据隐私、所有权和严格法规等问题。联邦学习作为一种解决方案，通过设立中央聚合服务器和共享全局模型，在保证数据隐私的同时提取知识。EPIC架构将网络分布式部署于本地和集中式服务器之间，致力于构建一个允许不同数据持有者合作并收敛至单一预测模型的通用去中心化优化框架。实验结果表明，隐私保护策略可以成功应用于聚合方法中，而不影响学习收敛的程度。最后，文章还指出了基于联邦学习的医疗应用方法面临的潜在问题及研究前景。 <div>
arXiv:2411.05167v1 Announce Type: new 
Abstract: Advancements in genomics technology lead to a rising volume of viral (e.g., SARS-CoV-2) sequence data, resulting in increased usage of machine learning (ML) in bioinformatics. Traditional ML techniques require centralized data collection and processing, posing challenges in realistic healthcare scenarios. Additionally, privacy, ownership, and stringent regulation issues exist when pooling medical data into centralized storage to train a powerful deep learning (DL) model. The Federated learning (FL) approach overcomes such issues by setting up a central aggregator server and a shared global model. It also facilitates data privacy by extracting knowledge while keeping the actual data private. This work proposes a cutting-edge Privacy enhancement through Iterative Collaboration (EPIC) architecture. The network is divided and distributed between local and centralized servers. We demonstrate the EPIC approach to resolve a supervised classification problem to estimate SARS-CoV-2 genomic sequence data lineage without explicitly transferring raw sequence data. We aim to create a universal decentralized optimization framework that allows various data holders to work together and converge to a single predictive model. The findings demonstrate that privacy-preserving strategies can be successfully used with aggregation approaches without materially altering the degree of learning convergence. Finally, we highlight a few potential issues and prospects for study in FL-based approaches to healthcare applications.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DWFL: Enhancing Federated Learning through Dynamic Weighted Averaging</title>
<link>https://arxiv.org/abs/2411.05173</link>
<guid>https://arxiv.org/abs/2411.05173</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、生物信息学、数据隐私、蛋白质序列分类、深度神经网络

<br /><br />总结:
本文提出了一种基于深度前馈神经网络的增强型联邦学习方法，用于蛋白质序列分类，以解决在保护数据隐私的同时提高准确性的问题。针对联邦学习在蛋白质序列分析中的优化整合未被充分探索的情况，该研究引入了动态加权联邦学习（DWFL），这是一种根据本地模型性能指标进行权重调整的联邦学习方法，通过赋予表现优秀的模型更高的权重，构建更强大的全局模型初始版本，从而提升整体学习过程的准确性。实验使用真实世界的蛋白质序列数据集验证了DWFL的有效性，结果表明，所提出的方案显著提高了模型准确性，使联邦学习成为协作机器学习任务中更为优选、强大且注重隐私保护的方法。 <div>
arXiv:2411.05173v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed learning technique that maintains data privacy by providing a decentralized training method for machine learning models using distributed big data. This promising Federated Learning approach has also gained popularity in bioinformatics, where the privacy of biomedical data holds immense importance, especially when patient data is involved. Despite the successful implementation of Federated learning in biological sequence analysis, rigorous consideration is still required to improve accuracy in a way that data privacy should not be compromised. Additionally, the optimal integration of federated learning, especially in protein sequence analysis, has not been fully explored. We propose a deep feed-forward neural network-based enhanced federated learning method for protein sequence classification to overcome these challenges. Our method introduces novel enhancements to improve classification accuracy. We introduce dynamic weighted federated learning (DWFL) which is a federated learning-based approach, where local model weights are adjusted using weighted averaging based on their performance metrics. By assigning higher weights to well-performing models, we aim to create a more potent initial global model for the federated learning process, leading to improved accuracy. We conduct experiments using real-world protein sequence datasets to assess the effectiveness of DWFL. The results obtained using our proposed approach demonstrate significant improvements in model accuracy, making federated learning a preferred, more robust, and privacy-preserving approach for collaborative machine-learning tasks.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discern-XR: An Online Classifier for Metaverse Network Traffic</title>
<link>https://arxiv.org/abs/2411.05184</link>
<guid>https://arxiv.org/abs/2411.05184</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse, 网络流量分类器, Discern-XR, 分段学习, FVR算法, FIA算法, 在线训练, A2R-OT算法, 实际Metaverse数据集, 性能提升, 错误率降低

总结:
本文提出了一种名为Discern-XR的专门针对Metaverse网络流量的分类器，旨在帮助ISP和路由器制造商提升Metaverse服务的质量。该方法利用分段学习，提出了Frame Vector Representation (FVR)算法和Frame Identification Algorithm (FIA)，从仅具有四个应用层特征的原始网络数据中提取关键帧相关统计信息。同时，文章还设计了一个新颖的在线训练算法A2R-OT，用于寻找准确的分类模型。此外，作者为研究贡献了一个实际的Metaverse数据集，包含了虚拟现实游戏、VR视频、VR聊天、增强现实以及混合现实等不同类型的流量样本，为业界提供了全面的基准测试资源。Discern-XR相比于现有最先进的分类器性能提升了7%，并提高了训练效率，降低了错误负例率，从而推动了Metaverse网络流量分类技术的发展，成为当前领域的最佳解决方案。 <div>
arXiv:2411.05184v1 Announce Type: new 
Abstract: In this paper, we design an exclusive Metaverse network traffic classifier, named Discern-XR, to help Internet service providers (ISP) and router manufacturers enhance the quality of Metaverse services. Leveraging segmented learning, the Frame Vector Representation (FVR) algorithm and Frame Identification Algorithm (FIA) are proposed to extract critical frame-related statistics from raw network data having only four application-level features. A novel Augmentation, Aggregation, and Retention Online Training (A2R-OT) algorithm is proposed to find an accurate classification model through online training methodology. In addition, we contribute to the real-world Metaverse dataset comprising virtual reality (VR) games, VR video, VR chat, augmented reality (AR), and mixed reality (MR) traffic, providing a comprehensive benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while improving training efficiency and reducing false-negative rates. Our work advances Metaverse network traffic classification by standing as the state-of-the-art solution.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning</title>
<link>https://arxiv.org/abs/2411.05260</link>
<guid>https://arxiv.org/abs/2411.05260</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Homomorphic Encryption、Quantization、Pruning、QuanCrypt-FL

总结:<br />
本文提出了一种名为QuanCrypt-FL的新颖算法，旨在解决联邦学习（Federated Learning）中的隐私保护和通信效率问题。针对联邦学习在训练和推理过程中面临的攻击风险，如梯度反演和成员资格推断，文章提出了结合低比特量化和剪枝技术的方法，以增强对攻击的防护并显著降低训练过程中的计算成本。同时，为了解决量化溢出或误差，文中还引入了均值裁剪策略。通过整合这些方法，QuanCrypt-FL构建了一个既保证隐私又能兼顾通信效率和模型准确性的FL框架。实验结果表明，QuanCrypt-FL在MNIST、CIFAR-10和CIFAR-100数据集上相比于现有方法表现出优越性能，其准确性与Vanilla-FL相当，并在加密速度、解密速度和推理速度方面分别实现了最多9倍、16倍和1.5倍的提升，训练时间最多可减少3倍，相较于BatchCrypt展现了更高的计算效率和攻击鲁棒性。 <div>
arXiv:2411.05260v1 Announce Type: new 
Abstract: Federated Learning has emerged as a leading approach for decentralized machine learning, enabling multiple clients to collaboratively train a shared model without exchanging private data. While FL enhances data privacy, it remains vulnerable to inference attacks, such as gradient inversion and membership inference, during both training and inference phases. Homomorphic Encryption provides a promising solution by encrypting model updates to protect against such attacks, but it introduces substantial communication overhead, slowing down training and increasing computational costs. To address these challenges, we propose QuanCrypt-FL, a novel algorithm that combines low-bit quantization and pruning techniques to enhance protection against attacks while significantly reducing computational costs during training. Further, we propose and implement mean-based clipping to mitigate quantization overflow or errors. By integrating these methods, QuanCrypt-FL creates a communication-efficient FL framework that ensures privacy protection with minimal impact on model accuracy, thereby improving both computational efficiency and attack resilience. We validate our approach on MNIST, CIFAR-10, and CIFAR-100 datasets, demonstrating superior performance compared to state-of-the-art methods. QuanCrypt-FL consistently outperforms existing method and matches Vanilla-FL in terms of accuracy across varying client. Further, QuanCrypt-FL achieves up to 9x faster encryption, 16x faster decryption, and 1.5x faster inference compared to BatchCrypt, with training time reduced by up to 3x.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digitalization and Virtual Assistive Systems in Tourist Mobility: Evolution, an Experience (with Observed Mistakes), Appropriate Orientations and Recommendations</title>
<link>https://arxiv.org/abs/2411.05446</link>
<guid>https://arxiv.org/abs/2411.05446</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字化、虚拟化、旅游管理、用户体验、元宇宙

总结:
本文探讨了数字化和虚拟化在包括旅游管理在内的多个领域中的活跃应用和重要性。通过一个为期7周的旅行案例研究，文章指出了当前旅游业中适宜与不足的情况，并强调了用户体验对于辅助系统及用户界面满意度验证的关键作用。同时，文章还展望了未来元宇宙在该领域发展中预期扮演的重要角色。 <div>
arXiv:2411.05446v1 Announce Type: new 
Abstract: Digitalization and virtualization are extremely active and important approaches in a large scope of activities (marketing, selling, enterprise management, logistics). Tourism management is also highly concerned by this evolution. In this paper we try to present today's situation based on a 7-week trip showing appropriate and shame situations. After this case study, we give a list of appropriate practices and orientations and confirm the fundamental role of User Experience in validating the proposed assistive system and the User Interfaces needed for client/user satisfaction. We also outline the expected role of Metaverse in the future of the evolution of this domain.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Emergent Cooperative Strategies for Multi-Agent Shepherding via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.05454</link>
<guid>https://arxiv.org/abs/2411.05454</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式强化学习、多智能体、牧羊控制问题、两层控制器、大规模系统

<br /><br />总结:

本文提出了一种分布式强化学习方法来解决多智能体牧羊控制问题，该问题不再假设目标群体具有凝聚力。这种方法采用双层控制架构：低层控制器引导每个牧羊者将特定目标保持在目标区域内；而高层层动态选择牧羊者应瞄准并围堵的目标。合作行为自然产生，因为牧羊者自主选择不同的目标以加速任务完成。此外，该方法还被扩展到大型系统中，其中每个牧羊者应用由少数代理训练的共享策略，同时管理一组固定的子代理。 <div>
arXiv:2411.05454v1 Announce Type: new 
Abstract: We present a decentralized reinforcement learning (RL) approach to address the multi-agent shepherding control problem, departing from the conventional assumption of cohesive target groups. Our two-layer control architecture consists of a low-level controller that guides each herder to contain a specific target within a goal region, while a high-level layer dynamically selects from multiple targets the one an herder should aim at corralling and containing. Cooperation emerges naturally, as herders autonomously choose distinct targets to expedite task completion. We further extend this approach to large-scale systems, where each herder applies a shared policy, trained with few agents, while managing a fixed subset of agents.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2411.05591</link>
<guid>https://arxiv.org/abs/2411.05591</guid>
<content:encoded><![CDATA[
<div> 关键词：网络期望最大化（Network EM）、高斯混合模型、分布式联邦学习、动量网络EM（MNEM）、半监督MNEM（semi-MNEM）

<br /><br />总结:
本文系统研究了应用于高斯混合模型的多种网络期望最大化（EM）算法，在分布式联邦学习的框架下。针对异质数据和成分分离不良的问题，文章提出了两种创新解决方案。首先，为处理异质数据，文章引入了动量网络EM（MNEM）算法，该算法使用动量参数结合当前与历史估计器的信息。其次，为应对成分分离不良的挑战，他们开发了半监督MNEM（semi-MNEM）算法，利用部分标注的数据。理论分析表明，即使在异质场景中，当混合组件满足一定的分离条件时，MNEM可以实现与全样本估计器相当的统计效率。此外，semi-MNEM算法能加快MNEM算法的收敛速度，有效解决了成分分离不良情况下的数值收敛难题。通过大量的模拟和真实数据分析验证了这些理论发现。 <div>
arXiv:2411.05591v1 Announce Type: cross 
Abstract: We systematically study various network Expectation-Maximization (EM) algorithms for the Gaussian mixture model within the framework of decentralized federated learning. Our theoretical investigation reveals that directly extending the classical decentralized supervised learning method to the EM algorithm exhibits poor estimation accuracy with heterogeneous data across clients and struggles to converge numerically when Gaussian components are poorly-separated. To address these issues, we propose two novel solutions. First, to handle heterogeneous data, we introduce a momentum network EM (MNEM) algorithm, which uses a momentum parameter to combine information from both the current and historical estimators. Second, to tackle the challenge of poorly-separated Gaussian components, we develop a semi-supervised MNEM (semi-MNEM) algorithm, which leverages partially labeled data. Rigorous theoretical analysis demonstrates that MNEM can achieve statistical efficiency comparable to that of the whole sample estimator when the mixture components satisfy certain separation conditions, even in heterogeneous scenarios. Moreover, the semi-MNEM estimator enhances the convergence speed of the MNEM algorithm, effectively addressing the numerical convergence challenges in poorly-separated scenarios. Extensive simulation and real data analyses are conducted to justify our theoretical findings.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large problems are not necessarily hard: A case study on distributed NMPC paying off</title>
<link>https://arxiv.org/abs/2411.05627</link>
<guid>https://arxiv.org/abs/2411.05627</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式模型预测控制(MPC), 计算性能, 并行计算, 中心化解算器, 频率控制

总结:<br />
本文研究了分布式模型预测控制（MPC）在处理大型系统中的计算性能，特别是针对线性和非线性系统的合作型分布式MPC。文中提出了一种定制化的分散实时迭代方案应用于电力系统的频率控制。研究表明，在所考虑的线性及非线性基准测试中，分布式MPC和分布式非线性MPC（NMPC）具有良好的扩展性，因为它们所需的迭代次数并不随子系统的数量增加而增加。与多线程中心化解算器进行比较后发现，所提出的分散优化算法展现出与其竞争性的性能。 <div>
arXiv:2411.05627v1 Announce Type: cross 
Abstract: A key motivation in the development of distributed Model Predictive Control (MPC) is to widen the computational bottleneck of centralized MPC for large-scale systems. Parallelizing computations among individual subsystems, distributed MPC has the prospect of scaling well for large networks. However, the communication demand may deteriorate the performance of iterative decentralized optimization, if excessively many optimizer iterations are required per control step. Moreover, centralized solvers often exhibit faster asymptotic convergence rates and, by parallelizing costly linear algebra operations, they can also benefit from modern multi-core computing architectures. On this canvas, we study the computational performance of cooperative distributed MPC for linear and nonlinear systems. To this end, we apply a tailored decentralized real-time iteration scheme to frequency control for power systems. For the considered linear and nonlinear benchmarks, distributed MPC and distributed Nonlinear MPC (NMPC) scale well as the required number of iterations does not depend on the number of subsystems. Comparisons with multithreaded centralized solvers show competitive performance of the considered decentralized optimization algorithms.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fast Confirmation Rule for the Ethereum Consensus Protocol</title>
<link>https://arxiv.org/abs/2405.00549</link>
<guid>https://arxiv.org/abs/2405.00549</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、确认规则、比特币、以太坊、Gasper<br /><br />总结:
本文讨论了区块链中的确认规则，特别是以太坊网络中的确认机制。现有的以太坊共识协议中采用的是FFG最终化规则（Gasper），但在异步网络条件下确认交易速度较慢，最佳情况下也需要约13至19分钟。为此，文章提出了一个新的快速确认规则，该规则基于同步网络条件，能将交易的最好情况下的确认时间缩短到仅12秒，显著提高了确认效率。因此，用户可以根据对网络条件的判断和快速响应的需求选择适合自己的确认规则。 <div>
arXiv:2405.00549v2 Announce Type: replace 
Abstract: A Confirmation Rule, within blockchain networks, refers to an algorithm implemented by network nodes that determines (either probabilistically or deterministically) the permanence of certain blocks on the blockchain. An example of Confirmation Ruble is the Bitcoin's longest chain Confirmation Rule where a block $b$ is confirmed (with high probability) when it has a sufficiently long chain of successors, its siblings have notably shorter successor chains, the majority of the network's total computation power (hashing) is controlled by honest nodes, and network synchrony holds.
  The only Confirmation Rule currently available in the Ethereum protocol, Gasper, is the FFG Finalization Rule. While this Confirmation Rule works under asynchronous network conditions, it is quite slow for many use cases. Specifically, best-case scenario, it takes around 13 to 19 min to confirm a transaction, where the actual figure depends on when the transaction is submitted to the network.
  In this work, we devise a Fast Confirmation Rule for Ethereum's consensus protocol. Our Confirmation Rule relies on synchrony conditions, but provides a best-case confirmation time of 12 seconds only, greatly improving on the latency of the FFG Finalization Rule.
  Users can then rely on the Confirmation Rule that best suits their needs depending on their belief about the network conditions and the need for a quick response.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses</title>
<link>https://arxiv.org/abs/2411.04139</link>
<guid>https://arxiv.org/abs/2411.04139</guid>
<content:encoded><![CDATA[
<div> 关键词：6G车辆元宇宙、车辆数字孪生、资源分配、无人机、学习优化算法

<br />
总结:
本文探讨了6G赋能的车辆元宇宙中，如何利用车辆数字孪生技术解决实时车联网服务面临的挑战。针对高需求的车辆数字孪生任务和地面基站有限资源的问题，文中提出采用无人机作为空中边缘服务器辅助处理这些任务。然而，由于无人机的高流动性导致与地面基站之间存在信息不对称，进而影响到资源分配效率。为了解决这一问题，文章提出了一个基于学习的改良第二价格拍卖机制，该机制考虑了任务延迟和准确性，优化了地空基站之间的资源分配。同时，设计了一种扩散式强化学习算法来优化价格调整因子，以最大化资源提供者的总剩余价值并最小化车辆数字孪生任务的延迟。仿真结果显示，所提出的扩散式改良第二价格拍卖机制相比于传统方法具有更好的资源分布性能和服务质量提升效果。 <div>
arXiv:2411.04139v1 Announce Type: new 
Abstract: The rise of 6G-enable Vehicular Metaverses is transforming the automotive industry by integrating immersive, real-time vehicular services through ultra-low latency and high bandwidth connectivity. In 6G-enable Vehicular Metaverses, vehicles are represented by Vehicle Twins (VTs), which serve as digital replicas of physical vehicles to support real-time vehicular applications such as large Artificial Intelligence (AI) model-based Augmented Reality (AR) navigation, called VT tasks. VT tasks are resource-intensive and need to be offloaded to ground Base Stations (BSs) for fast processing. However, high demand for VT tasks and limited resources of ground BSs, pose significant resource allocation challenges, particularly in densely populated urban areas like intersections. As a promising solution, Unmanned Aerial Vehicles (UAVs) act as aerial edge servers to dynamically assist ground BSs in handling VT tasks, relieving resource pressure on ground BSs. However, due to high mobility of UAVs, there exists information asymmetry regarding VT task demands between UAVs and ground BSs, resulting in inefficient resource allocation of UAVs. To address these challenges, we propose a learning-based Modified Second-Bid (MSB) auction mechanism to optimize resource allocation between ground BSs and UAVs by accounting for VT task latency and accuracy. Moreover, we design a diffusion-based reinforcement learning algorithm to optimize the price scaling factor, maximizing the total surplus of resource providers and minimizing VT task latency. Finally, simulation results demonstrate that the proposed diffusion-based MSB auction outperforms traditional baselines, providing better resource distribution and enhanced service quality for vehicular users.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenFLAME: Building a large scale federated localization and mapping service</title>
<link>https://arxiv.org/abs/2411.04271</link>
<guid>https://arxiv.org/abs/2411.04271</guid>
<content:encoded><![CDATA[
<div> 关键词: OpenFLAME、去中心化、定位服务、联邦、地图抽象

总结:
OpenFLAME 是首个提出的去中心化、联邦定位服务系统，旨在解决随着室内定位技术进步和应用拓展而产生的对可扩展到私人空间的全球化、分布式位置管理系统的需要。该系统通过链接负责特定区域定位的服务器，为应用程序提供无缝的全球视野。针对联邦定位系统中的服务发现和服务整合等挑战，OpenFLAME 利用域名系统（DNS）实现服务发现，并运用地图抽象方法来检索和合并不同地图上的位置信息。其基于真实数据的研究表明，跨越远程服务器的联邦定位具有可行性和可接受的查询延迟。为了展示系统的潜力，开发了一个适用于大型室内的增强现实导航应用，证明了OpenFLAME能够成功地支持位置为基础的应用程序运行。 <div>
arXiv:2411.04271v1 Announce Type: new 
Abstract: The widespread availability of maps has enabled the development of numerous location-based applications, including navigation, ride-sharing, fitness tracking, gaming, robotics, and augmented reality. Today, the maps that power these services are predominantly controlled by a few large corporations and mostly cover outdoor spaces. As the use of these applications expands and indoor localization technologies advance, we are seeing the need for a scalable, federated location management system that can extend into private spaces.
  We introduce OpenFLAME (Open Federated Localization and Mapping Engine), the first federated and decentralized localization service. OpenFLAME links servers that handle localization for specific regions, providing applications with a seamless global view. Creating a federated localization system poses challenges, such as discovering the appropriate servers for a region and integrating services managed by independent providers. To address these issues and ensure scalability, we leverage Domain Name System (DNS) for service discovery and implement map abstractions to retrieve and merge locations across different maps. Our trace-driven study demonstrates that federated localization across remote servers is feasible with acceptable query latencies. To highlight the potential of the system, we developed an augmented reality navigation application for a large indoor space, showing that OpenFLAME can successfully power location-based applications.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Intersections of Web3 and AI -- View in 2024</title>
<link>https://arxiv.org/abs/2411.04318</link>
<guid>https://arxiv.org/abs/2411.04318</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、AI技术、整合、缺口、创新方法

总结:
<br />
本文通过全面回顾现有学术论文、行业报告和以太坊研究社区博客文章，概述了Web3与AI技术的交叉点、两者之间的协同效应以及对于这些技术融合可能存在的一些认识缺口。作者将焦点放在感知到的缺口上，并详细提出了一些新颖的方法，旨在促进区块链/Web3生态系统的进步。这篇论文提供的综述预计将为关注Web3与AI技术交叉领域的研究人员提供指导。 <div>
arXiv:2411.04318v1 Announce Type: new 
Abstract: This paper summarises the intersection of Web3 and AI technologies, synergies between these technologies, and gaps that we suggest exist in the conception of the possible integrations of these technologies. The summary is informed by a comprehensive literature review of current academic and industry papers, analyst reports, and Ethereum research community blogposts. We focus our contribution on the perceived gaps and detail some novel approaches that would benefit the blockchain/Web3 ecosystem. We believe that the overview presented in this paper will help guide researchers interested in the intersection of Web3 and AI technologies.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secured Smart Grid 2.0: Exploring Security Threats, Protection Models, and Challenges</title>
<link>https://arxiv.org/abs/2411.04365</link>
<guid>https://arxiv.org/abs/2411.04365</guid>
<content:encoded><![CDATA[
<div> 关键词: 绿色转型、智能电网2.0(SG2)、通信网络、安全威胁、防御策略

<br /><br />总结:

1. 许多国家正推动能源领域的绿色转型以实现2050年碳中和目标，其中智能电网2.0 (SG2)利用数据驱动分析和通信技术提升分布式可再生能源系统的效率与可持续性。
   
2. SG2对通信网络高度依赖，但其连通性的潜在级联故障可能导致数据同步至远程控制系统受阻。

3. 文章调研了电力运营商、通信网络提供商及消费者等SG2利益相关者的安全威胁与防御策略，发现易受到变电站攻击/破坏、恶意软件/勒索软件威胁、区块链漏洞及供应链中断等问题的影响。

4. SG2中人工智能(AI)融入自主能源管理带来新挑战，如电力读数和测量传感器上对抗样本和虚假数据注入可能导致AI控制功能失效、储能错误检查混乱、电动汽车充电能量估算不准确以及点对点能源交易模型中的欺诈交易。

5. 针对未来研究，具有潜力的保护模型包括可扩展的基于区块链的模型、物理不可克隆函数、互操作性安全协议及面向分布式微电网管理的可信AI模型。 <div>
arXiv:2411.04365v1 Announce Type: new 
Abstract: Many nations are promoting the green transition in the energy sector to attain neutral carbon emissions by 2050. Smart Grid 2.0 (SG2) is expected to explore data-driven analytics and enhance communication technologies to improve the efficiency and sustainability of distributed renewable energy systems. These features are beyond smart metering and electric surplus distribution in conventional smart grids. Given the high dependence on communication networks to connect distributed microgrids in SG2, potential cascading failures of connectivity can cause disruption to data synchronization to the remote control systems. This paper reviews security threats and defense tactics for three stakeholders: power grid operators, communication network providers, and consumers. Through the survey, we found that SG2's stakeholders are particularly vulnerable to substation attacks/vandalism, malware/ransomware threats, blockchain vulnerabilities and supply chain breakdowns. Furthermore, incorporating artificial intelligence (AI) into autonomous energy management in distributed energy resources of SG2 creates new challenges. Accordingly, adversarial samples and false data injection on electricity reading and measurement sensors at power plants can fool AI-powered control functions and cause messy error-checking operations in energy storage, wrong energy estimation in electric vehicle charging, and even fraudulent transactions in peer-to-peer energy trading models. Scalable blockchain-based models, physical unclonable function, interoperable security protocols, and trustworthy AI models designed for managing distributed microgrids in SG2 are typical promising protection models for future research.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comprehensive Review of Multimodal XR Applications, Risks, and Ethical Challenges in the Metaverse</title>
<link>https://arxiv.org/abs/2411.04508</link>
<guid>https://arxiv.org/abs/2411.04508</guid>
<content:encoded><![CDATA[
<div> 关键词：Extended Reality (XR)，Metaverse，Virtual Reality (VR)，Augmented Reality (AR)，Mixed Reality (MR)

总结:
本文是一篇关于扩展现实（XR）技术，包括虚拟现实（VR）、增强现实（AR）和混合现实（MR），及其在元宇宙应用中的范围审查。XR正在教育、医疗培训、神经心理评估等领域引发革命，并带来沉浸式体验的提升。然而，随着多模态技术如触觉、眼动追踪等的应用，XR扩张也带来了数据隐私风险、网络安全问题、身心健康挑战（如网络病态、成瘾、脱节、骚扰等）以及社会不平等影响。因此，文章强调了制定强有力的伦理框架和监管指南以应对这些风险并促进公平访问、隐私保护、自主权及心理健康的重要性。随着XR技术与人工智能日益融合，负责任的治理对于确保元宇宙及其他领域中XR安全、有益的发展至关重要。 <div>
arXiv:2411.04508v1 Announce Type: new 
Abstract: This scoping review examines the broad applications, risks, and ethical challenges associated with Extended Reality (XR) technologies, including Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), within the context of Metaverse. XR is revolutionizing fields such as immersive learning in education, medical and professional training, neuropsychological assessment, therapeutic interventions, arts, entertainment, retail, e-commerce, remote work, sports, architecture, urban planning, and cultural heritage preservation. The integration of multimodal technologies such as haptics, eye-tracking, face- and body-tracking, and brain-computer interfaces, enhances user engagement and interactivity, playing a key role in shaping the immersive experiences in the Metaverse. However, XR's expansion raises serious concerns, including data privacy risks, cybersecurity vulnerabilities, cybersickness, addiction, dissociation, harassment, bullying, and misinformation. These psychological, social, and security challenges are further complicated by intense advertising, manipulation of public opinion, and social inequality, which could disproportionately affect vulnerable individuals and social groups. This review emphasizes the urgent need for robust ethical frameworks and regulatory guidelines to address these risks while promoting equitable access, privacy, autonomy, and mental well-being. As XR technologies increasingly integrate with artificial intelligence, responsible governance is essential to ensure the safe and beneficial development of the Metaverse and the broader application of XR in enhancing human development.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RainCloud: Decentralized Coordination and Communication in Heterogeneous IoT Swarms</title>
<link>https://arxiv.org/abs/2411.04593</link>
<guid>https://arxiv.org/abs/2411.04593</guid>
<content:encoded><![CDATA[
<div> 关键词: IoT系统、计算连续体、分布式协调、蚁群优化(ACO)、随机搜索、 gossip协议、任务分配

<br /><br />总结:
本文关注物联网(IoT)系统日益增长的复杂性和规模需求，提出从云中心模型向称为“计算连续体”的去中心化IoT架构转变。这种转变带来了新的研究挑战，特别是对于分布式协调的需求。为了解决这一问题，文章提出了一种基于语义通信的方案和一种利用蚁群优化(ACO)的轻量级自适应任务分配策略。该策略与随机搜索和基于gossip协议的算法进行了比较。实验在静态和动态环境（包括设备故障）下，涉及多达一百个节点进行验证。结果显示，ACO能在最少的跳数和消息发送次数下找到匹配节点，虽然gossip协议在成功分配任务数量上表现出色，但ACO在可扩展性方面更优，因此是物联网集群中实现分布式任务协调的一种有前景的方法。 <div>
arXiv:2411.04593v1 Announce Type: new 
Abstract: The increasing volume and complexity of IoT systems demand a transition from the cloud-centric model to a decentralized IoT architecture in the so-called Computing Continuum, with no or minimal reliance on central servers. This paradigm shift, however, raises novel research concerns for decentralized coordination, calling for accurate policies. However, building such strategies is not trivial. Our work aims to relieve the DevOps engineers from this concern and propose a solution for autonomous, decentralized task allocation at runtime for IoT systems. To this end, we present a semantic communication approach and an ad-hoc lightweight coordination strategy based on Ant Colony Optimization (ACO). We compare the ACO strategy with Random Search and Gossip protocol-based algorithms. We conduct accurate experiments with up to a hundred nodes in both a static and a dynamic environment, i.e., with device outages. We show that ACO finds a matching node with the smallest hops and messages sent. While the Gossip strategy can allocate the most tasks successfully, ACO scales better, thus being a promising candidate for decentralized task coordination in IoT clusters.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Maximal Extractable Value in Decentralized Finance: Taxonomy, Detection, and Mitigation</title>
<link>https://arxiv.org/abs/2411.03327</link>
<guid>https://arxiv.org/abs/2411.03327</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance (DeFi), Maximal Extractable Value (MEV), blockchain, transaction reordering, mitigation strategies

<br /><br />总结:
本文是对去中心化金融(DeFi)领域中Maximal Extractable Value（MEV）现象的全面调查。MEV是指利用区块链上的公开交易信息进行重新排序、插入或移除交易以榨取价值的行为，可能导致参与者财务损失和共识不稳定性。文章首先构建了一个关于MEV交易的新型分类体系，并通过真实交易示例深入解释了MEV的理解。接着对比分析了多种MEV检测方法的有效性。此外，文中还评估了不同类型的MEV缓解策略及其局限性。作者指出现有缓解与检测方法面临的挑战并讨论可能的解决方案。该文旨在为研究人员、开发者、利益相关者和政策制定者提供有价值的洞见，助力构建更安全、高效的DeFi生态系统，同时努力遏制和民主化MEV现象。 <div>
arXiv:2411.03327v1 Announce Type: new 
Abstract: Decentralized Finance (DeFi) leverages blockchain-enabled smart contracts to deliver automated and trustless financial services without the need for intermediaries. However, the public visibility of financial transactions on the blockchain can be exploited, as participants can reorder, insert, or remove transactions to extract value, often at the expense of others. This extracted value is known as the Maximal Extractable Value (MEV). MEV causes financial losses and consensus instability, disrupting the security, efficiency, and decentralization goals of the DeFi ecosystem. Therefore, it is crucial to analyze, detect, and mitigate MEV to safeguard DeFi. Our comprehensive survey offers a holistic view of the MEV landscape in the DeFi ecosystem. We present an in-depth understanding of MEV through a novel taxonomy of MEV transactions supported by real transaction examples. We perform a critical comparative analysis of various MEV detection approaches, evaluating their effectiveness in identifying different transaction types. Furthermore, we assess different categories of MEV mitigation strategies and discuss their limitations. We identify the challenges of current mitigation and detection approaches and discuss potential solutions. This survey provides valuable insights for researchers, developers, stakeholders, and policymakers, helping to curb and democratize MEV for a more secure and efficient DeFi ecosystem.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Based Multi-Path Mobile Access Point Selection for Secure 5G VANETs</title>
<link>https://arxiv.org/abs/2411.03371</link>
<guid>https://arxiv.org/abs/2411.03371</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、多路径移动接入点选择策略、安全5G车联网、信任攻击检测机制、通信延迟

总结:
本文提出了一种基于区块链的多路径移动接入点(MAP)选择策略，用于确保5G车联网(VANETs)的安全性。该策略利用区块链技术实现去中心化、透明且安全的MAP选择，同时通过多路径传输策略提升网络可靠性并降低通信延迟。文中还集成了一种信任基的攻击检测机制以保障网络安全。仿真结果显示，所提算法能将切换频率和平均通信延迟降低超过80%，并且能成功识别并排除超过95%的Sybil节点，从而在高度动态的车载环境中确保了可靠且安全的通信。 <div>
arXiv:2411.03371v1 Announce Type: new 
Abstract: This letter presents a blockchain-based multi-path mobile access point (MAP) selection strategy for secure 5G vehicular ad-hoc networks (VANETs). The proposed method leverages blockchain technology for decentralized, transparent, and secure MAP selection, while the multi-path transmission strategy enhances network reliability and reduces communication delays. A trust-based attack detection mechanism is integrated to ensure network security. Simulation results demonstrate that the proposed algorithm reduces both handover frequency and average communication delay by over 80%, and successfully identifies and excludes more than 95% of Sybil nodes, ensuring reliable and secure communication in highly dynamic vehicular environments.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Attribute-Based Encryption With Payable Outsourced Decryption Using Blockchain and Responsive Zero Knowledge Proof</title>
<link>https://arxiv.org/abs/2411.03844</link>
<guid>https://arxiv.org/abs/2411.03844</guid>
<content:encoded><![CDATA[
<div> 关键词：Attribute-Based Encryption (ABE), Decryption Cloud Service (DCS), Blockchain, Verifiability, Exemptibility

总结:<br />
本文提出了一种基于区块链的可付费外包解密的属性基加密(ABE)方案，旨在解决ABE解密效率低下的问题。该方案允许用户将解密过程外包给解密云服务(DCS)，同时具备验证外包结果的正确性和实现诚实DCS豁免错误声明的有效机制。为降低证明生成的成本，方案引入了乐观假设下的一轮挑战游戏。此外，系统实现了公平性和去中心化的外包，以保护各方利益。实验结果显示，相比于Ge等人(TDSC'23)提出的方案，在属性数量从5到60的情况下，本方案在正常情况和挑战情况下的以太坊 Gas 使用量分别降低了11倍至140倍和4倍至55倍，从而证明了其可行性和高效性。 <div>
arXiv:2411.03844v1 Announce Type: new 
Abstract: Attribute-Based Encryption (ABE) is a promising solution for access control in cloud services. However, the heavy decryption overhead hinders its widespread adoption. A general approach to address this issue is to outsource decryption to decryption cloud service(DCS). Existing schemes have utilized various methods to enable users to verify outsourced results; however, they lack an effective mechanism to achieve exemptibility which enables the honest DCS to escape from wrong claims. And it is impractical to assume that the DCS will provide free services. In this paper, we propose a blockchain-based payable outsourced decryption ABE scheme that achieves both verifiability and exemptibility without adding redundant information to ABE ciphertext. We use zero-knowledge proof to verify outsourced results on blockchain and introduce an optional single-round challenge game under optimistic assumption to address the high cost of proof generation. Moreover, our system achieves fairness and decentralized outsourcing to protect the interests of all parties. Finally, we implement and evaluate our scheme on Ethereum to demonstrate its feasibility and efficiency, the gas usage in attribute numbers from 5 to 60 is 11$\times$ to 140$\times$ in the happy case and 4$\times$ to 55$\times$ in the challenge case lower than the scheme of Ge et al. (TDSC'23).
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OML: Open, Monetizable, and Loyal AI</title>
<link>https://arxiv.org/abs/2411.03887</link>
<guid>https://arxiv.org/abs/2411.03887</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，开放、可盈利与忠诚(AOML)，区块链，加密技术，可信执行环境(TEE)

<br /><br />总结:
本文提出了一种名为OML（Open, Monetizable, and Loyal AI）的新方法，旨在通过结合AI、区块链和密码学的跨学科框架来民主化AI的发展。OML利用了包括Trusted Execution Environments（TEE）、全同态加密、功能加密、混淆以及基于AI任务样本复杂性和内在难度的AI原生解决方案等技术。文章创新性地引入了“AI原生密码学”，该领域关注AI数据表示的连续性质及其低维流形，将攻击方法如数据中毒转化为安全工具。OML 1.0版本通过模型指纹识别保护AI模型的完整性和所有权。OML的核心目标是建立一个去中心化、开放透明的AI开发平台，让社区能够参与贡献、变现并拥有AI模型。通过区块链技术实现控制权分散和透明度保证，OML阻止了权力集中，并为AI发展提供了前所未有的问责机制。 <div>
arXiv:2411.03887v1 Announce Type: new 
Abstract: Artificial Intelligence (AI) has steadily improved across a wide range of tasks. However, the development and deployment of AI are almost entirely controlled by a few powerful organizations that are racing to create Artificial General Intelligence (AGI). The centralized entities make decisions with little public oversight, shaping the future of humanity, often with unforeseen consequences. In this paper, we propose OML, which stands for Open, Monetizable, and Loyal AI, an approach designed to democratize AI development. OML is realized through an interdisciplinary framework spanning AI, blockchain, and cryptography. We present several ideas for constructing OML using technologies such as Trusted Execution Environments (TEE), traditional cryptographic primitives like fully homomorphic encryption and functional encryption, obfuscation, and AI-native solutions rooted in the sample complexity and intrinsic hardness of AI tasks. A key innovation of our work is introducing a new scientific field: AI-native cryptography. Unlike conventional cryptography, which focuses on discrete data and binary security guarantees, AI-native cryptography exploits the continuous nature of AI data representations and their low-dimensional manifolds, focusing on improving approximate performance. One core idea is to transform AI attack methods, such as data poisoning, into security tools. This novel approach serves as a foundation for OML 1.0 which uses model fingerprinting to protect the integrity and ownership of AI models. The spirit of OML is to establish a decentralized, open, and transparent platform for AI development, enabling the community to contribute, monetize, and take ownership of AI models. By decentralizing control and ensuring transparency through blockchain technology, OML prevents the concentration of power and provides accountability in AI development that has not been possible before.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Two Sides of the Same Coin: Large-scale Measurements of Builder and Rollup after EIP-4844</title>
<link>https://arxiv.org/abs/2411.03892</link>
<guid>https://arxiv.org/abs/2411.03892</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3、EIP-4844、以太坊、Layer-2扩容、交易策略

<br /><br />总结:
本文详细研究了EIP-4844在以太坊实施后新兴的Layer-2扩容解决方案中，构建者（builders）和rollups市场的战略变化。研究涉及数亿笔交易数据，发现构建者和rollups的效率相互依赖，无法同时优化：当构建者高效运作时，rollups可能在费用上支付过多；反之，若rollups优化成本，则可能导致构建者因交易选择效率低下而亏损。数据显示，约29.48%的区块构造不甚高效，使构建者利润不足；而从rollups角度看，超过72.53%的type-3交易支付了不必要的费用，给rollups带来了显著的经济成本。因此，本文为优化区块链构造和交易策略提供了关键洞见，旨在提升Web3基础设施的经济效率与数据可扩展性，但同时也强调了平衡构建者与rollups效率之间的挑战。 <div>
arXiv:2411.03892v1 Announce Type: new 
Abstract: Web3 is reshaping decentralized ecosystems through innovations like Ethereum. Recently, EIP-4844 is implemented in Ethereum to support its Layer-2 scaling solutions, which introduces a new 128 KB data structure called blob. This upgrade incorporates type-3 transactions with blobs to verify data availability and reduce gas costs for rollups, significantly affecting the strategies of both builders and rollups. In this paper, we present an in-depth study of emerging strategies in builder and rollup markets after EIP-4844, containing hundred million transactions. We find that the efficiency of builder and rollup strategies is interdependent, akin to two sides of the same coin -- both cannot be optimized simultaneously. That is, when builders operate efficiently, rollups tend to overpay in fees, conversely, when rollups optimize their costs, builders may incur losses in inefficient transaction selection. From the side of builders, our results show that 29.48% of these blocks have been constructed inefficiently, which does not produce sufficient profits for builders. Through our evaluation from the side of rollups, we find that over 72.53% of type-3 transactions pay unnecessary fees, leading to notable economic costs of rollups. Our work provides critical insights into optimizing block construction and transaction strategies, advancing the economic efficiency and data scalability of Web3 infrastructures, yet, much like balancing a seesaw, the efficiency of builders and rollups cannot be optimized concurrently.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WiP: Towards a Secure SECP256K1 for Crypto Wallets: Hardware Architecture and Implementation</title>
<link>https://arxiv.org/abs/2411.03910</link>
<guid>https://arxiv.org/abs/2411.03910</guid>
<content:encoded><![CDATA[
<div> 关键词: SECP256K1，椭圆曲线算法，侧信道攻击，硬件钱包，资源效率

总结:
针对SECP256K1椭圆曲线算法在硬件钱包中易遭受侧信道攻击的问题，该工作提出了一种新的、优化了侧信道攻击防御和高效资源利用的硬件架构。新架构融合了完整的加法公式、临时寄存器和并行处理技术，使椭圆曲线点的添加和加倍操作变得不可区分，增强了安全性。实施结果显示，相比于同类作品，该设计平均减少了45%的LUT使用量，突显出其优秀的资源效率优势。 <div>
arXiv:2411.03910v1 Announce Type: new 
Abstract: The SECP256K1 elliptic curve algorithm is fundamental in cryptocurrency wallets for generating secure public keys from private keys, thereby ensuring the protection and ownership of blockchain-based digital assets. However, the literature highlights several successful side-channel attacks on hardware wallets that exploit SECP256K1 to extract private keys. This work proposes a novel hardware architecture for SECP256K1, optimized for side-channel attack resistance and efficient resource utilization. The architecture incorporates complete addition formulas, temporary registers, and parallel processing techniques, making elliptic curve point addition and doubling operations indistinguishable. Implementation results demonstrate an average reduction of 45% in LUT usage compared to similar works, emphasizing the design's resource efficiency.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Taming the Beast of User-Programmed Transactions on Blockchains: A Declarative Transaction Approach</title>
<link>https://arxiv.org/abs/2411.02597</link>
<guid>https://arxiv.org/abs/2411.02597</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、交易框架、声明式区块链交易、性能研究

总结:<br />
本文提出了一种新的交易框架，旨在减少对用户定义的智能合约的需求，该框架将更多原语集成到区块链平台的本机交易类型中。通过采用基于声明式的区块链交易概念，该框架同时解决了智能合约的一些局限性。文章提供了形式化和实现框架，并选择开源区块链数据库BigchainDB作为实施背景，实现了常见交易行为的子集作为使用案例。通过对声明式交易方法与等效智能合约交易模型进行性能比较的研究，揭示了所提方法的多项优势。 <div>
arXiv:2411.02597v1 Announce Type: new 
Abstract: Blockchains are being positioned as the "technology of trust" that can be used to mediate transactions between non-trusting parties without the need for a central authority. They support transaction types that are native to the blockchain platform or user-defined via user programs called smart contracts. Despite the significant flexibility in transaction programmability that smart contracts offer, they pose several usability, robustness, and performance challenges.
  This paper proposes an alternative transaction framework that incorporates more primitives into the native set of transaction types (reducing the likelihood of requiring user-defined transaction programs often). The framework is based on the concept of declarative blockchain transactions whose strength lies in the fact that it addresses several of the limitations of smart contracts simultaneously. A formal and implementation framework is presented, and a subset of commonly occurring transaction behaviors are modeled and implemented as use cases, using an open-source blockchain database, BigchchainDB, as the implementation context. A performance study comparing the declarative transaction approach to equivalent smart contract transaction models reveals several advantages of the proposed approach.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Carbon price fluctuation prediction using blockchain information A new hybrid machine learning approach</title>
<link>https://arxiv.org/abs/2411.02709</link>
<guid>https://arxiv.org/abs/2411.02709</guid>
<content:encoded><![CDATA[
<div> 关键词: 混合机器学习、碳价预测、DILATED卷积神经网络、长短期记忆网络、区块链信息

<br /><br />总结:

本文提出了一种用于碳价格波动预测的新型混合机器学习方法。该方法结合了DILATED卷积神经网络（CNN）和长短期记忆（LSTM）神经网络算法，提升了特征提取效率。在DILATED CNN-LSTM框架基础上，采用L1和L2参数范数惩罚作为正则化手段进行预测，并通过正则化过程引入了与区块链信息相关的指标。实验使用大量数据集对碳价格进行了预测，结果显示，DILATED CNN-LSTM框架优于传统的CNN-LSTM架构，同时区块链信息能有效预测碳价格。在正则化方法中，相比于L1正则化的Smoothly Clipped Absolute Deviation Penalty (SCAD)，L2正则化的Ridge Regression (RR)在价格预测上表现更优。因此，提出的RR-DILATED CNN-LSTM方法能有效地、准确地预测碳价格的波动趋势，为学术界和业界提供了一个新的理论依据和预测方法，尤其对于以碳价为代表的数字资产政策评估及趋势预测具有重要意义。 <div>
arXiv:2411.02709v1 Announce Type: new 
Abstract: In this study, the novel hybrid machine learning approach is proposed in carbon price fluctuation prediction. Specifically, a research framework integrating DILATED Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) neural network algorithm is proposed. The advantage of the combined framework is that it can make feature extraction more efficient. Then, based on the DILATED CNN-LSTM framework, the L1 and L2 parameter norm penalty as regularization method is adopted to predict. Referring to the characteristics of high correlation between energy indicator price and blockchain information in previous literature, and we primarily includes indicators related to blockchain information through regularization process. Based on the above methods, this paper uses a dataset containing an amount of data to carry out the carbon price prediction. The experimental results show that the DILATED CNN-LSTM framework is superior to the traditional CNN-LSTM architecture. Blockchain information can effectively predict the price. Since parameter norm penalty as regularization, Ridge Regression (RR) as L2 regularization is better than Smoothly Clipped Absolute Deviation Penalty (SCAD) as L1 regularization in price forecasting. Thus, the proposed RR-DILATED CNN-LSTM approach can effectively and accurately predict the fluctuation trend of the carbon price. Therefore, the new forecasting methods and theoretical ecology proposed in this study provide a new basis for trend prediction and evaluating digital assets policy represented by the carbon price for both the academia and practitioners.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedBlock: A Blockchain Approach to Federated Learning against Backdoor Attacks</title>
<link>https://arxiv.org/abs/2411.02773</link>
<guid>https://arxiv.org/abs/2411.02773</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 安全风险, Blockchain, FedBlock, Smart Contract

<br /><br />总结:

本文介绍了Federated Learning（联邦学习）的安全风险，包括中心服务器故障和客户端后门攻击，并提出了一种名为FedBlock的基于区块链的新颖FL框架。FedBlock利用智能合约技术，在不集中的数据上实现安全训练，同时消除了对单一中央服务器的依赖，以防止服务器方面的恶意行为。通过实证评估研究，证明了FedBlock在抵御客户端后门攻击方面具有竞争力，并且由于其仅涉及智能合约编程，因此可以部署在任何区块链网络之上。相较于现有文献中针对FL后门防御的方法，FedBlock还额外解决了服务器风险问题。 <div>
arXiv:2411.02773v1 Announce Type: new 
Abstract: Federated Learning (FL) is a machine learning method for training with private data locally stored in distributed machines without gathering them into one place for central learning. Despite its promises, FL is prone to critical security risks. First, because FL depends on a central server to aggregate local training models, this is a single point of failure. The server might function maliciously. Second, due to its distributed nature, FL might encounter backdoor attacks by participating clients. They can poison the local model before submitting to the server. Either type of attack, on the server or the client side, would severely degrade learning accuracy. We propose FedBlock, a novel blockchain-based FL framework that addresses both of these security risks. FedBlock is uniquely desirable in that it involves only smart contract programming, thus deployable atop any blockchain network. Our framework is substantiated with a comprehensive evaluation study using real-world datasets. Its robustness against backdoor attacks is competitive with the literature of FL backdoor defense. The latter, however, does not address the server risk as we do.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Instant Resonance: Dual Strategy Enhances the Data Consensus Success Rate of Blockchain Threshold Signature Oracles</title>
<link>https://arxiv.org/abs/2411.02945</link>
<guid>https://arxiv.org/abs/2411.02945</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链预言机、阈值签名、实时数据采集、一致性、成功率优化

总结:<br />
本文针对区块链预言机中阈值签名在实时数据采集过程中面临的不一致性和低成功率问题，提出了一种创新的双策略方法。首先，文中引入了代表增强聚合策略（REP-AG），该策略通过提升节点提交数据的代表性，确保与其它节点数据的一致性，进而增强阈值签名的可用性。其次，提出了时间优化策略（TIM-OPT），能够动态调整节点访问数据源的时间以最大化共识成功率。实验结果显示，REP-AG相比最优基线可提高聚合成功率约56.6%，而TIM-OPT的实施则使所有场景下的共识成功率平均提高了约32.9%。 <div>
arXiv:2411.02945v1 Announce Type: new 
Abstract: With the rapid development of Decentralized Finance (DeFi) and Real-World Assets (RWA), the importance of blockchain oracles in real-time data acquisition has become increasingly prominent. Using cryptographic techniques, threshold signature oracles can achieve consensus on data from multiple nodes and provide corresponding proofs to ensure the credibility and security of the information. However, in real-time data acquisition, threshold signature methods face challenges such as data inconsistency and low success rates in heterogeneous environments, which limit their practical application potential. To address these issues, this paper proposes an innovative dual-strategy approach to enhance the success rate of data consensus in blockchain threshold signature oracles. Firstly, we introduce a Representative Enhanced Aggregation Strategy (REP-AG) that improves the representativeness of data submitted by nodes, ensuring consistency with data from other nodes, and thereby enhancing the usability of threshold signatures. Additionally, we present a Timing Optimization Strategy (TIM-OPT) that dynamically adjusts the timing of nodes' access to data sources to maximize consensus success rates. Experimental results indicate that REP-AG improves the aggregation success rate by approximately 56.6\% compared to the optimal baseline, while the implementation of TIM-OPT leads to an average increase of approximately 32.9\% in consensus success rates across all scenarios.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FEDLAD: Federated Evaluation of Deep Leakage Attacks and Defenses</title>
<link>https://arxiv.org/abs/2411.03019</link>
<guid>https://arxiv.org/abs/2411.03019</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Deep Leakage、攻击、防御、FEDLAD框架

总结:<br />
本文介绍了arXiv:2411.03019v1论文的主要内容，该论文关注了联邦学习（Federated Learning）中的隐私安全问题。近期研究发现，联邦学习可能因深泄漏（Deep Leakage）等梯度反演技术而遭到隐私泄露。然而，这些攻击方法在实际场景中的效果并未得到充分评估。为此，文章提出了一种名为FEDLAD框架的全面基准评测体系，用于在现实的联邦学习环境中评估和比较多种先进的深泄漏攻击手段与防御策略的效果。该框架涵盖了多个数据集和训练状态下的应用场景，突显了联邦学习中隐私与模型准确性之间的权衡问题，并旨在增进对去中心化机器学习系统安全挑战的理解，推动未来相关领域的研究以及提高深泄漏攻击和防御方法评测的可重复性。 <div>
arXiv:2411.03019v1 Announce Type: new 
Abstract: Federated Learning is a privacy preserving decentralized machine learning paradigm designed to collaboratively train models across multiple clients by exchanging gradients to the server and keeping private data local. Nevertheless, recent research has revealed that the security of Federated Learning is compromised, as private ground truth data can be recovered through a gradient inversion technique known as Deep Leakage. While these attacks are crafted with a focus on applications in Federated Learning, they generally are not evaluated in realistic scenarios. This paper introduces the FEDLAD Framework (Federated Evaluation of Deep Leakage Attacks and Defenses), a comprehensive benchmark for evaluating Deep Leakage attacks and defenses within a realistic Federated context. By implementing a unified benchmark that encompasses multiple state-of-the-art Deep Leakage techniques and various defense strategies, our framework facilitates the evaluation and comparison of the efficacy of these methods across different datasets and training states. This work highlights a crucial trade-off between privacy and model accuracy in Federated Learning and aims to advance the understanding of security challenges in decentralized machine learning systems, stimulate future research, and enhance reproducibility in evaluating Deep Leakage attacks and defenses.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Formal Logic-guided Robust Federated Learning against Poisoning Attacks</title>
<link>https://arxiv.org/abs/2411.03231</link>
<guid>https://arxiv.org/abs/2411.03231</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Poisoning Attacks（中毒攻击）、Time Series Data（时间序列数据）、FLORAL、Defense Mechanism（防御机制）

<br /><br />总结:
本文介绍了针对联邦学习中时间序列任务的中毒攻击防御机制FLORAL。现有的联邦学习防御方法主要关注计算机视觉任务，而对具有异构客户端数据和大量恶意参与者的时间序列数据场景的挑战应对不足。FLORAL通过利用逻辑推理评估客户端的信任度，根据其预测与全局时间序列模式的符合程度，而非仅仅依赖于客户端更新的相似性来确定。该方法首先从客户端提取逻辑推理属性，随后层次化推断全球属性，并使用这些属性验证客户端更新。通过形式逻辑验证，可以识别出代表恶意行为的贡献偏离现象。实验结果显示，相较于现有基线方法，FLORAL在两个数据集上的表现更优，最佳情况下将预测误差降低了93.27%。相关代码已开源发布。 <div>
arXiv:2411.03231v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a promising solution to the privacy concerns associated with centralized Machine Learning (ML) by enabling decentralized, collaborative learning. However, FL is vulnerable to various security threats, including poisoning attacks, where adversarial clients manipulate the training data or model updates to degrade overall model performance. Recognizing this threat, researchers have focused on developing defense mechanisms to counteract poisoning attacks in FL systems. However, existing robust FL methods predominantly focus on computer vision tasks, leaving a gap in addressing the unique challenges of FL with time series data. In this paper, we present FLORAL, a defense mechanism designed to mitigate poisoning attacks in federated learning for time-series tasks, even in scenarios with heterogeneous client data and a large number of adversarial participants. Unlike traditional model-centric defenses, FLORAL leverages logical reasoning to evaluate client trustworthiness by aligning their predictions with global time-series patterns, rather than relying solely on the similarity of client updates. Our approach extracts logical reasoning properties from clients, then hierarchically infers global properties, and uses these to verify client updates. Through formal logic verification, we assess the robustness of each client contribution, identifying deviations indicative of adversarial behavior. Experimental results on two datasets demonstrate the superior performance of our approach compared to existing baseline methods, highlighting its potential to enhance the robustness of FL to time series applications. Notably, FLORAL reduced the prediction error by 93.27\% in the best-case scenario compared to the second-best baseline. Our code is available at \url{https://anonymous.4open.science/r/FLORAL-Robust-FTS}.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scenario-Game ADMM: A Parallelized Scenario-Based Solver for Stochastic Noncooperative Games</title>
<link>https://arxiv.org/abs/2304.01945</link>
<guid>https://arxiv.org/abs/2304.01945</guid>
<content:encoded><![CDATA[
<div> 关键词：多玩家游戏、决策制定、不确定性、样本平均近似（SAA）、场景优化、可行性保证、样例复杂性、分布式、共识基础ADMM算法、广义纳什均衡（GNE）、收敛性、性能优势

总结:<br />
本文提出了针对一类具有随机性、总和形式的纯纳什游戏的新样本近似方法，该类游戏中每个玩家具有期望值目标与机会约束。该方法结合了SAA方法对目标的精确逼近以及场景优化文献中的可行性保证。文中分析了该新游戏理论近似方案的样例复杂性，并注意到高精度通常需要大量样本，导致大量采样约束。为应对这一问题，文章将近似游戏分解为一组具有少量约束的小型游戏，并提出了一种基于分布式、共识型ADMM算法的有效计算近似游戏GNE的方法。论文证明了所提算法能收敛到GNE，并通过实验证明相对于基于ADMM和内点法的最近基线算法具有更好的性能表现。 <div>
arXiv:2304.01945v4 Announce Type: replace 
Abstract: Decision-making in multi-player games can be extremely challenging, particularly under uncertainty. In this work, we propose a new sample-based approximation to a class of stochastic, general-sum, pure Nash games, where each player has an expected-value objective and a set of chance constraints. This new approximation scheme inherits the accuracy of objective approximation from the established sample average approximation (SAA) method and enjoys a feasibility guarantee derived from the scenario optimization literature. We characterize the sample complexity of this new game-theoretic approximation scheme, and observe that high accuracy usually requires a large number of samples, which results in a large number of sampled constraints. To accommodate this, we decompose the approximated game into a set of smaller games with few constraints for each sampled scenario, and propose a decentralized, consensus-based ADMM algorithm to efficiently compute a generalized Nash equilibrium (GNE) of the approximated game. We prove the convergence of our algorithm to a GNE and empirically demonstrate superior performance relative to a recent baseline algorithm based on ADMM and interior point method.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BACSA: A Bias-Aware Client Selection Algorithm for Privacy-Preserving Federated Learning in Wireless Healthcare Networks</title>
<link>https://arxiv.org/abs/2411.01050</link>
<guid>https://arxiv.org/abs/2411.01050</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 非独立同分布数据, 偏差检测, 客户选择算法, 无线网络约束

<br /><br />总结:

本文提出了一种名为Bias-Aware Client Selection Algorithm (BACSA)的新方法，用于解决联邦学习(FL)在医疗保健领域的非独立同分布数据导致的性能下降问题。BACSA能检测客户端的数据偏差，并根据这些偏差资料进行策略性选择，同时考虑了隐私保护、公平性和无线网络环境的约束条件，特别适合对服务质量、隐私和安全性要求较高的医疗应用。该方法首先通过分析模型参数与类特定数据样本分布之间的相关性来创新性地检测用户偏差，然后结合无线网络约束构建了一个混合整数非线性的客户选择优化问题。实验表明，相较于现有基准，BACSA可以改善FL的收敛性和准确性，并能在不同数据分布场景（如Dirichlet和类别约束场景）中表现出优势。此外，文中还探讨了准确度、公平性和网络约束之间的权衡关系，证明了BACSA在应对多样化医疗应用场景中的适应性和鲁棒性。 <div>
arXiv:2411.01050v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a transformative approach in healthcare, enabling collaborative model training across decentralized data sources while preserving user privacy. However, performance of FL rapidly degrades in practical scenarios due to the inherent bias in non Independent and Identically distributed (non-IID) data among participating clients, which poses significant challenges to model accuracy and generalization. Therefore, we propose the Bias-Aware Client Selection Algorithm (BACSA), which detects user bias and strategically selects clients based on their bias profiles. In addition, the proposed algorithm considers privacy preservation, fairness and constraints of wireless network environments, making it suitable for sensitive healthcare applications where Quality of Service (QoS), privacy and security are paramount. Our approach begins with a novel method for detecting user bias by analyzing model parameters and correlating them with the distribution of class-specific data samples. We then formulate a mixed-integer non-linear client selection problem leveraging the detected bias, alongside wireless network constraints, to optimize FL performance. We demonstrate that BACSA improves convergence and accuracy, compared to existing benchmarks, through evaluations on various data distributions, including Dirichlet and class-constrained scenarios. Additionally, we explore the trade-offs between accuracy, fairness, and network constraints, indicating the adaptability and robustness of BACSA to address diverse healthcare applications.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strengthening DeFi Security: A Static Analysis Approach to Flash Loan Vulnerabilities</title>
<link>https://arxiv.org/abs/2411.01230</link>
<guid>https://arxiv.org/abs/2411.01230</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), flash loans, security vulnerabilities, price manipulation, FlashDeFier

总结:<br />
随着去中心化金融(DeFi)的发展，其带来了新的金融机遇，但也暴露了严重的安全漏洞，尤其是闪贷常被用于价格操纵攻击。这类攻击利用闪贷的原子性来操纵DeFi协议的预言机和定价机制，导致重大财务损失。尽管现有的智能合约分析工具能够解决一些安全风险，但它们往往难以检测到构成闪贷攻击挑战性的复杂跨合约依赖关系。为此，研究者提出了一种名为FlashDeFier的高级检测框架，该框架扩展了静态污点分析的应用，以针对源自闪贷的价格操纵漏洞。FlashDeFier通过构建详细的跨合约调用图，全面分析了DeFi协议中的数据流，从而显著提高了检测准确性。实验证明，FlashDeFier在针对一系列知名DeFi事件的数据集中，识别出了76.4%的价格操纵漏洞，相较于DeFiTainter有30%的提升。这些结果强调了适应性检测框架对于随DeFi威胁演进而发展的必要性，并指出需要结合静态、动态和符号分析方法的混合方法来实现DeFi安全的韧性。 <div>
arXiv:2411.01230v1 Announce Type: new 
Abstract: The rise of Decentralized Finance (DeFi) has brought novel financial opportunities but also exposed serious security vulnerabilities, with flash loans frequently exploited for price manipulation attacks. These attacks, leveraging the atomic nature of flash loans, allow malicious actors to manipulate DeFi protocol oracles and pricing mechanisms within a single transaction, causing substantial financial losses. Traditional smart contract analysis tools address some security risks but often struggle to detect the complex, inter-contract dependencies that make flash loan attacks challenging to identify.
  In response, we introduce FlashDeFier, an advanced detection framework that enhances static taint analysis to target price manipulation vulnerabilities arising from flash loans. FlashDeFier expands the scope of taint sources and sinks, enabling comprehensive analysis of data flows across DeFi protocols. The framework constructs detailed inter-contract call graphs to capture sophisticated data flow patterns, significantly improving detection accuracy. Tested against a dataset of high-profile DeFi incidents, FlashDeFier identifies 76.4% of price manipulation vulnerabilities, marking a 30% improvement over DeFiTainter. These results highlight the importance of adaptive detection frameworks that evolve alongside DeFi threats, underscoring the need for hybrid approaches combining static, dynamic, and symbolic analysis methods for resilient DeFi security.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Federated Learning by Entropy-Based Client Selection</title>
<link>https://arxiv.org/abs/2411.01240</link>
<guid>https://arxiv.org/abs/2411.01240</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、联邦学习、数据分布偏斜、FedEntOpt、分类准确性

<br /><br />总结:

本文介绍了深度学习在各行业中带来的变革，尤其是针对敏感数据隐私问题提出了联邦学习方案。然而，当客户端（客户）间的数据分布存在显著差异，特别是标签分布偏斜时，传统联邦学习方法的性能会严重下降。为解决这一问题，文章提出了一种名为FedEntOpt的新方法，该方法旨在通过最大化所选客户端子集在全球标签分布上的熵来缓解由标签分布偏斜引起的性能问题，确保从各个可用标签的数据中学习到模型参数。实验结果显示，FedEntOpt在多个基准数据集上相比现有最优算法提高了高达6%的分类精度，尤其在低参与率情况下表现出稳健且优越的性能。此外，FedEntOpt还具有与其他算法结合的灵活性，可进一步提升它们的性能超过40%。 <div>
arXiv:2411.01240v1 Announce Type: new 
Abstract: Deep learning is an emerging field revolutionizing various industries, including natural language processing, computer vision, and many more. These domains typically require an extensive amount of data for optimal performance, potentially utilizing huge centralized data repositories. However, such centralization could raise privacy issues concerning the storage of sensitive data. To address this issue, federated learning was developed. It is a newly distributed learning technique that enables to collaboratively train a deep learning model on decentralized devices, referred to as clients, without compromising their data privacy. Traditional federated learning methods often suffer from severe performance degradation when the data distribution among clients differs significantly. This becomes especially problematic in the case of label distribution skew, where the distribution of labels varies across clients. To address this, a novel method called FedEntOpt is proposed. FedEntOpt is designed to mitigate performance issues caused by label distribution skew by maximizing the entropy of the global label distribution of the selected client subset in each federated learning round. This ensures that the aggregated model parameters from the clients were exhibited to data from all available labels, which improves the accuracy of the global model. Extensive experiments on several benchmark datasets show that the proposed method outperforms several state-of-the-art algorithms by up to 6% in classification accuracy, demonstrating robust and superior performance, particularly under low participation rates. In addition, it offers the flexibility to be combined with them, enhancing their performance by over 40%.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trustworthy Federated Learning: Privacy, Security, and Beyond</title>
<link>https://arxiv.org/abs/2411.01583</link>
<guid>https://arxiv.org/abs/2411.01583</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (联邦学习)，数据隐私，安全问题，防御策略，应用场景

<br />
总结: 本文针对近年来大数据和人工智能发展背景下，数据隐私与安全的重要性日益凸显的问题，深入探讨了一种创新方法——联邦学习（Federated Learning, FL）。FL能够在不转移原始数据的情况下，促进分布式数据源间的协同模型训练，然而其在分散网络中的强安全性和隐私性保障仍面临挑战。文章全面调研了FL中存在的安全和隐私问题，强调了通信链路的脆弱性和潜在的网络安全威胁，并对抵御这些风险的各种防御策略进行了探讨。同时，文章还分析了FL在不同领域的应用，并提出了相关研究方向。通过对FL框架中复杂的安全挑战进行识别，本文旨在为构建安全、高效的FL系统做出贡献。 <div>
arXiv:2411.01583v1 Announce Type: new 
Abstract: While recent years have witnessed the advancement in big data and Artificial Intelligence (AI), it is of much importance to safeguard data privacy and security. As an innovative approach, Federated Learning (FL) addresses these concerns by facilitating collaborative model training across distributed data sources without transferring raw data. However, the challenges of robust security and privacy across decentralized networks catch significant attention in dealing with the distributed data in FL. In this paper, we conduct an extensive survey of the security and privacy issues prevalent in FL, underscoring the vulnerability of communication links and the potential for cyber threats. We delve into various defensive strategies to mitigate these risks, explore the applications of FL across different sectors, and propose research directions. We identify the intricate security challenges that arise within the FL frameworks, aiming to contribute to the development of secure and efficient FL systems.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Token Composition: A Graph Based on EVM Logs</title>
<link>https://arxiv.org/abs/2411.01693</link>
<guid>https://arxiv.org/abs/2411.01693</guid>
<content:encoded><![CDATA[
<div> 关键词: 代币、区块链、市场资本化、图论、结构分析

<br /><br />总结: 这篇文章针对区块链上日益增长的代币数量、市值和用途进行了实证分析，重点关注了以太坊区块链上的代币构成。文章引入了一个表示代币间相互代币化的图论模型，并发现该图具有非平凡的拓扑结构。研究者关联了图的属性（如连通组件和循环结构）与代币化过程，并找出了最长有向路径及其对应的代币序列。同时，他们还可视化了稳定币和NFT协议相关的连通组件。总的来说，本文旨在探索并可视化代币化进程带来的影响，而非单纯增加新的理论构建。 <div>
arXiv:2411.01693v1 Announce Type: new 
Abstract: Tokens have proliferated across blockchains in terms of number, market capitalisation and utility. Some tokens are tokenised versions of existing tokens -- known variously as wrapped tokens, fractional tokens, or shares. The repeated application of this process creates matryoshkian tokens of arbitrary depth. We perform an empirical analysis of token composition on the Ethereum blockchain. We introduce a graph that represents the tokenisation of tokens by other tokens, and we show that the graph contains non-trivial topological structure. We relate properties of the graph, e.g., connected components and cyclic structure, to the tokenisation process. For example, we identify the longest directed path and its corresponding sequence of tokens, and we visualise the connected components relating to a stablecoin and an NFT protocol. Our goal is to explore and visualise what has been wrought with tokens, rather than add yet another brick to the edifice.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Revisiting Game-Theoretic Control in Socio-Technical Networks: Emerging Design Frameworks and Contemporary Applications</title>
<link>https://arxiv.org/abs/2411.01794</link>
<guid>https://arxiv.org/abs/2411.01794</guid>
<content:encoded><![CDATA[
<div> 关键词: socio-technical networks, game-theoretic frameworks, Stackelberg games, mechanism design, dynamic game theory

<br /><br />总结:
本文研究了针对社会技术网络的设计与控制的博弈论框架，特别是在误信息管理、基础设施优化和社交通信物理系统（SCPS）中的韧性等方面的应用。文章探讨了Stackelberg游戏、机制设计和动态博弈理论等核心方法，作为在层级化、多智能体环境中建模交互的强大工具。文中着重解决了由人类行为引发的系统脆弱性问题、大规模系统动态管理以及对抗敌对威胁等问题。通过将博弈论与控制理论相结合，该工作展示了如何引导分散的智能体行为与系统的全局稳定性、安全性和效率目标相一致，从而构建出强大、有韧性和适应性的社会技术网络。此外，文章还突显了这些框架在动态调整分散行动以符合系统范围内的整体目标方面的潜力。 <div>
arXiv:2411.01794v1 Announce Type: new 
Abstract: Socio-technical networks represent emerging cyber-physical infrastructures that are tightly interwoven with human networks. The coupling between human and technical networks presents significant challenges in managing, controlling, and securing these complex, interdependent systems. This paper investigates game-theoretic frameworks for the design and control of socio-technical networks, with a focus on critical applications such as misinformation management, infrastructure optimization, and resilience in socio-cyber-physical systems (SCPS). Core methodologies, including Stackelberg games, mechanism design, and dynamic game theory, are examined as powerful tools for modeling interactions in hierarchical, multi-agent environments. Key challenges addressed include mitigating human-driven vulnerabilities, managing large-scale system dynamics, and countering adversarial threats. By bridging individual agent behaviors with overarching system goals, this work illustrates how the integration of game theory and control theory can lead to robust, resilient, and adaptive socio-technical networks. This paper highlights the potential of these frameworks to dynamically align decentralized agent actions with system-wide objectives of stability, security, and efficiency.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedReMa: Improving Personalized Federated Learning via Leveraging the Most Relevant Clients</title>
<link>https://arxiv.org/abs/2411.01825</link>
<guid>https://arxiv.org/abs/2411.01825</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning，Personalized Federated Learning，Class-imbalance，FedReMa，Adaptive Inter-client Co-learning

<br /><br />总结:
本文提出了一种名为FedReMa的个性化联邦学习算法，旨在解决联邦学习和个性化联邦学习中的类别不平衡问题。FedReMa通过采用自适应跨客户端协同学习方法，在训练的不同阶段识别并利用不同客户端在不同数据类别的专长。同时，它对客户端的特征提取器和分类器应用不同的聚合策略，这些策略的选择依据于模型组件的不同角色和含义。实验驱动的关键协同学习周期（CCP）中，FedReMa使用最大差异分割（MDS）模块分析客户端分类器的logits相似性以评估和管理任务相关性。在非CCP期间，FedReMa利用每个客户端历史上最相关的同行的历史记录进一步增强个性化稳定性。通过广泛的实验，展示了FedReMa的优越性能。 <div>
arXiv:2411.01825v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning paradigm that achieves a globally robust model through decentralized computation and periodic model synthesis, primarily focusing on the global model's accuracy over aggregated datasets of all participating clients. Personalized Federated Learning (PFL) instead tailors exclusive models for each client, aiming to enhance the accuracy of clients' individual models on specific local data distributions. Despite of their wide adoption, existing FL and PFL works have yet to comprehensively address the class-imbalance issue, one of the most critical challenges within the realm of data heterogeneity in PFL and FL research. In this paper, we propose FedReMa, an efficient PFL algorithm that can tackle class-imbalance by 1) utilizing an adaptive inter-client co-learning approach to identify and harness different clients' expertise on different data classes throughout various phases of the training process, and 2) employing distinct aggregation methods for clients' feature extractors and classifiers, with the choices informed by the different roles and implications of these model components. Specifically, driven by our experimental findings on inter-client similarity dynamics, we develop critical co-learning period (CCP), wherein we introduce a module named maximum difference segmentation (MDS) to assess and manage task relevance by analyzing the similarities between clients' logits of their classifiers. Outside the CCP, we employ an additional scheme for model aggregation that utilizes historical records of each client's most relevant peers to further enhance the personalization stability. We demonstrate the superiority of our FedReMa in extensive experiments.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards the Industrial Metaverse: A Game-Based VR Application for Fire Drill and Evacuation Training for Ships and Shipbuilding</title>
<link>https://arxiv.org/abs/2411.01895</link>
<guid>https://arxiv.org/abs/2411.01895</guid>
<content:encoded><![CDATA[
<div> 关键词：Virtual Reality、Industrial Metaverse、shipboard fire emergency training、SOLAS公约、user evaluation

<br /><br />总结:

本文介绍了针对船舶火灾应急训练的一款创新虚拟现实应用，该应用符合《国际海上人命安全公约》（SOLAS）的要求，设计了不同级别的游戏化场景（如引擎室和厨房的不同火势等级）。文章全面阐述了VR开发过程并提供了整体概述与实践指南，旨在引导业界人士、开发者及未来研究者塑造造船行业的下一代工业元宇宙应用。此外，文中还包含了对初步用户评价的结果分析，旨在量化用户的决策制定和风险评估技能。实验结果为评估用户表现并指出未来挑战提供了有益见解。 <div>
arXiv:2411.01895v1 Announce Type: new 
Abstract: This paper details the creation of a novel Virtual Reality-based application for the Industrial Metaverse aimed at shipboard fire emergency training for fire drill and evacuation, aligned with the Safety of Life at Sea (SOLAS) convention requirements. Specifically, the application includes gamified scenarios with different levels (e.g., varying fire intensities in engine rooms and galleys). The paper details comprehensively the VR development while providing a holistic overview and practical guidelines. Thus, it can guide practitioners, developers and future researchers to shape the next generation of Industrial Metaverse applications for the shipbuilding industry. Moreover, the paper includes the results of a preliminary user evaluation aimed at quantifying user decision-making and risk assessment skills. The presented results of the experiments provide insights into user performance and allow for pointing out at different future challenges.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FPPL: An Efficient and Non-IID Robust Federated Continual Learning Framework</title>
<link>https://arxiv.org/abs/2411.01904</link>
<guid>https://arxiv.org/abs/2411.01904</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Continual Learning (FCL)，Catastrophic Forgetting，Privacy，Non-IID，Federated Prototype-Augmented Prompt Learning (FPPL)

<br /><br />总结:
本文提出了一种新的联邦持续学习框架——Federated Prototype-Augmented Prompt Learning (FPPL)，旨在解决联邦学习环境中数据流的序列学习及灾难性遗忘问题。现有的FCL方法常使用典型的重排机制，可能引发隐私侵犯或增加额外存储和计算负担。与之不同，FPPL通过无重演的方式协同学习轻量级的提示并结合原型。客户端采用融合函数充分利用任务特定提示的知识来缓解灾难性遗忘；同时，服务器端聚合的全局原型用于对比学习，以统一表示形式减轻非IID导致的数据异质性影响。在服务器端，利用本地上传的原型对分类器进行去偏处理，进一步减少了非IID和灾难性遗忘造成的性能退化。实证评估显示，FPPL在高效设计的同时表现出显著的性能优势，并能适应各种程度的非IID数据分布。相关代码已开源至https://github.com/ycheoo/FPPL。 <div>
arXiv:2411.01904v1 Announce Type: new 
Abstract: Federated continual learning (FCL) aims to learn from sequential data stream in the decentralized federated learning setting, while simultaneously mitigating the catastrophic forgetting issue in classical continual learning. Existing FCL methods usually employ typical rehearsal mechanisms, which could result in privacy violations or additional onerous storage and computational burdens. In this work, an efficient and non-IID robust federated continual learning framework, called Federated Prototype-Augmented Prompt Learning (FPPL), is proposed. The FPPL can collaboratively learn lightweight prompts augmented by prototypes without rehearsal. On the client side, a fusion function is employed to fully leverage the knowledge contained in task-specific prompts for alleviating catastrophic forgetting. Additionally, global prototypes aggregated from the server are used to obtain unified representation through contrastive learning, mitigating the impact of non-IID-derived data heterogeneity. On the server side, locally uploaded prototypes are utilized to perform debiasing on the classifier, further alleviating the performance degradation caused by both non-IID and catastrophic forgetting. Empirical evaluations demonstrate the effectiveness of FPPL, achieving notable performance with an efficient design while remaining robust to diverse non-IID degrees. Code is available at: https://github.com/ycheoo/FPPL.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fairness-Utilization Trade-off in Wireless Networks with Explainable Kolmogorov-Arnold Networks</title>
<link>https://arxiv.org/abs/2411.01924</link>
<guid>https://arxiv.org/abs/2411.01924</guid>
<content:encoded><![CDATA[
<div> 关键词：6G无线网络、传输功率分配、深度神经网络、公平性、Kolmogorov-Arnold网络

总结:
本文针对6G无线网络中的用户传输功率分配问题，旨在通过优化$\alpha$-公平性来平衡网络利用效率和用户公平。文章提出了一种使用具有较低推理成本和较高可解释性的新型机器学习模型——Kolmogorov-Arnold网络（KANs）的方法，以解决传统深度神经网络在决策过程中的公平性和计算效率问题。首先，文章对功率分配问题进行了全面的问题形式化，并证明其为NP难问题。接着，提出了两种算法分别用于数据集生成和分布式KAN训练，为动态6G环境下的不同公平目标实现提供了灵活框架。通过大量数值模拟验证了所提方法在公平性和推理成本方面的优越性，显示出KANs有潜力克服现有基于DNN方法的局限性，特别是在需要快速适应和公平性的场景中。 <div>
arXiv:2411.01924v1 Announce Type: new 
Abstract: The effective distribution of user transmit powers is essential for the significant advancements that the emergence of 6G wireless networks brings. In recent studies, Deep Neural Networks (DNNs) have been employed to address this challenge. However, these methods frequently encounter issues regarding fairness and computational inefficiency when making decisions, rendering them unsuitable for future dynamic services that depend heavily on the participation of each individual user. To address this gap, this paper focuses on the challenge of transmit power allocation in wireless networks, aiming to optimize $\alpha$-fairness to balance network utilization and user equity. We introduce a novel approach utilizing Kolmogorov-Arnold Networks (KANs), a class of machine learning models that offer low inference costs compared to traditional DNNs through superior explainability. The study provides a comprehensive problem formulation, establishing the NP-hardness of the power allocation problem. Then, two algorithms are proposed for dataset generation and decentralized KAN training, offering a flexible framework for achieving various fairness objectives in dynamic 6G environments. Extensive numerical simulations demonstrate the effectiveness of our approach in terms of fairness and inference cost. The results underscore the potential of KANs to overcome the limitations of existing DNN-based methods, particularly in scenarios that demand rapid adaptation and fairness.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially private and decentralized randomized power method</title>
<link>https://arxiv.org/abs/2411.01931</link>
<guid>https://arxiv.org/abs/2411.01931</guid>
<content:encoded><![CDATA[
<div> 关键词：randomized power method、Differential Privacy (DP)、variance reduction、decentralized framework、Secure Aggregation

总结:<br />
本文关注增强随机化幂方法的隐私保护变体。文章提出了降低为了实现差分隐私（DP）而引入的噪声方差的策略。同时，该方法被适应到一个具有低计算和通信开销的去中心化框架中，同时保持准确性。通过利用安全聚合（一种多方计算的形式），算法可以在不泄露个人数据的情况下使用分布式在多个用户或设备上的数据进行计算。研究显示，在去中心化设置中可以使用的噪声规模与集中式设置中的相似。此外，对于集中式和去中心化的版本，文章都改进了现有的收敛界。这种方法对于重视隐私问题的分布式推荐系统等去中心化应用尤其相关。 <div>
arXiv:2411.01931v1 Announce Type: new 
Abstract: The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. As modern datasets contain sensitive private information, we need to give formal guarantees on the possible privacy leaks caused by this method. This paper focuses on enhancing privacy preserving variants of the method. We propose a strategy to reduce the variance of the noise introduced to achieve Differential Privacy (DP). We also adapt the method to a decentralized framework with a low computational and communication overhead, while preserving the accuracy. We leverage Secure Aggregation (a form of Multi-Party Computation) to allow the algorithm to perform computations using data distributed among multiple users or devices, without revealing individual data. We show that it is possible to use a noise scale in the decentralized setting that is similar to the one in the centralized setting. We improve upon existing convergence bounds for both the centralized and decentralized versions. The proposed method is especially relevant for decentralized applications such as distributed recommender systems, where privacy concerns are paramount.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fuzzing Processing Pipelines for Zero-Knowledge Circuits</title>
<link>https://arxiv.org/abs/2411.02077</link>
<guid>https://arxiv.org/abs/2411.02077</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-knowledge (ZK) protocols, metamorphic testing, fuzzing, Circuzz, logic bugs

总结:
本文提出了首个针对零知识证明（ZK）管道的系统性模糊测试技术，该技术利用元变异测试 oracle 来检测关键逻辑错误。研究者开发了一个名为 Circuzz 的开源工具来实现这一方法，并对其进行了实际应用。通过使用 Circuzz 对四个具有显著差异的 ZK 管道进行测试，他们总共发现了 16 个逻辑错误，其中 15 个由于其严重性已得到开发者修复。这项工作揭示了对 ZK 管道进行有效正确性检查的重要性以及模糊测试与元变异测试相结合的技术潜力。 <div>
arXiv:2411.02077v1 Announce Type: new 
Abstract: Zero-knowledge (ZK) protocols have recently found numerous practical applications, such as in authentication, online-voting, and blockchain systems. These protocols are powered by highly complex pipelines that process deterministic programs, called circuits, written in one of many domain-specific programming languages, e.g., Circom, Noir, and others. Logic bugs in circuit-processing pipelines could have catastrophic consequences and cause significant financial and reputational damage. As an example, consider that a logic bug in a ZK pipeline could result in attackers stealing identities or assets. It is, therefore, critical to develop effective techniques for checking their correctness.
  In this paper, we present the first systematic fuzzing technique for ZK pipelines, which uses metamorphic test oracles to detect critical logic bugs. We have implemented our technique in an open-source tool called Circuzz. We used Circuzz to test four significantly different ZK pipelines and found a total of 16 logic bugs in all pipelines. Due to their critical nature, 15 of our bugs have already been fixed by the pipeline developers.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digital Twin-Assisted Federated Learning with Blockchain in Multi-tier Computing Systems</title>
<link>https://arxiv.org/abs/2411.02323</link>
<guid>https://arxiv.org/abs/2411.02323</guid>
<content:encoded><![CDATA[
<div> 关键词：工业互联网、数字孪生、区块链、联邦学习、延迟优化

总结:
本文研究了工业4.0系统中资源受限的工业物联网设备频繁进行数据交互所引发的安全和隐私问题。为此，提出了一种结合数字孪生(DT)和区块链辅助的联邦学习(FL)方案。首先，利用具有丰富计算能力的雾设备为边缘设备生成DT，帮助其进行本地训练。接着，文章针对FL过程构建了一个考虑模型传输时间和同步时间以及通过合作干扰保障DT安全同步的延迟最小化问题，并提出了分解算法来解决这个非凸优化问题。在此过程中，通过设置局部设备训练延迟上限和聚合干扰影响的辅助变量，将原问题转化为可独立求解的凸优化问题。此外，采用区块链验证机制保证FL过程中模型上传的完整性和参与者的身份认证。最终，通过深学习技术从区块链内的验证局部和全局模型获取全局模型。数值分析验证了所提合作干扰基联邦学习流程的有效性，表明该集成DT区块链辅助的FL方案在执行时间、区块优化和精度方面显著优于基准方案。 <div>
arXiv:2411.02323v1 Announce Type: new 
Abstract: In Industry 4.0 systems, a considerable number of resource-constrained Industrial Internet of Things (IIoT) devices engage in frequent data interactions due to the necessity for model training, which gives rise to concerns pertaining to security and privacy. In order to address these challenges, this paper considers a digital twin (DT) and blockchain-assisted federated learning (FL) scheme. To facilitate the FL process, we initially employ fog devices with abundant computational capabilities to generate DT for resource-constrained edge devices, thereby aiding them in local training. Subsequently, we formulate an FL delay minimization problem for FL, which considers both of model transmission time and synchronization time, also incorporates cooperative jamming to ensure secure synchronization of DT. To address this non-convex optimization problem, we propose a decomposition algorithm. In particular, we introduce upper limits on the local device training delay and the effects of aggregation jamming as auxiliary variables, thereby transforming the problem into a convex optimization problem that can be decomposed for independent solution. Finally, a blockchain verification mechanism is employed to guarantee the integrity of the model uploading throughout the FL process and the identities of the participants. The final global model is obtained from the verified local and global models within the blockchain through the application of deep learning techniques. The efficacy of our proposed cooperative interference-based FL process has been verified through numerical analysis, which demonstrates that the integrated DT blockchain-assisted FL scheme significantly outperforms the benchmark schemes in terms of execution time, block optimization, and accuracy.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Two-Sided Learning in Decentralized Matching Markets</title>
<link>https://arxiv.org/abs/2411.02377</link>
<guid>https://arxiv.org/abs/2411.02377</guid>
<content:encoded><![CDATA[
<div> 关键词：两-sided匹配市场、学习算法、偏好不确定性、稳定匹配、策略证明

总结:
本文研究了在双方都存在偏好不确定性的匹配市场上，如何通过学习算法引导各自主体行为以达成理想匹配的问题。文章提出了一个名为“试错学习”的简单政策，当所有主体遵循该政策时，可以收敛到稳定的匹配状态。接着，文章探讨了该政策的策略证明性质，并指出如果一方遵循试错学习，而另一方采用更高级别的政策，则他们将收敛到对第二方最有利的稳定匹配。这是首次提出的完全解耦和非协调性政策，能展示在去中心化市场中从双方面不确定性向稳定性收敛的概念。 <div>
arXiv:2411.02377v1 Announce Type: new 
Abstract: Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in many practical applications. In settings where the agents can assess the quality of their possible partners a priori, well-known centralized algorithms can be used to find desirable matchings between the two groups. However, when they do not know their own preferences, such algorithms are no longer applicable and agents must instead learn their preferences through repeated interactions with one another. In this work, we design completely uncoupled and uncoordinated policies that use an agent's limited historical observations to guide their behavior towards desirable matchings when they do not know their preferences. In our first main contribution, we demonstrate that when every agent follows a simple policy which we call trial-and-error learning, they will converge to a stable matching, the standard equilibrium configuration in matching markets. Then, we evaluate the strategyproofness of this policy and ask whether one group of agents can improve their performance by following a different policy. We constructively answer this question in the affirmative, demonstrating that if one group follows simple trial-and-error learning while the second group follows a more advanced policy, then they will converge to the most preferable stable matching for the second group. To the best of the authors' knowledge, these are the first completely uncoupled and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized markets with two-sided uncertainty.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The role of the metaverse in calibrating an embodied artificial general intelligence</title>
<link>https://arxiv.org/abs/2402.06660</link>
<guid>https://arxiv.org/abs/2402.06660</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied AGI、human consciousness、metaverse、calibrated symbolic interface、decentralized governance

<br />
总结:
本文探讨了具身人工智能（AGI）的概念及其与人类意识的关系，并着重分析了元宇宙在此关系中起到的关键作用。文章引用了包括具身认知、迈克尔·莱文的“自我”计算边界理论、唐纳德·霍夫曼的界面感知理论以及伯纳多·卡斯楚普的分析理想主义等哲学和本体论框架。文中讨论了AGI的发展阶段、实现具身AGI的要求、为AGI设计校准的符号接口的重要性，以及元宇宙、去中心化系统、开源区块链技术和开放源码AI研究在这方面的作用。此外，还提出了AGI与人类用户在元宇宙空间中的反馈循环作为AGI校准工具的概念，以及实现稳定具身AGI所需的局部稳态和去中心化治理的前提条件。最后，文章强调在全球范围内达到一定程度的人类和谐关系和认识到人类互联共生的重要性，是催生稳定具身AGI的关键前提。 <div>
arXiv:2402.06660v2 Announce Type: replace 
Abstract: This paper leverages various philosophical and ontological frameworks to explore the concept of embodied artificial general intelligence (AGI), its relationship to human consciousness, and the key role of the metaverse in facilitating this relationship. Several theoretical frameworks underpin this exploration, such as embodied cognition, Michael Levin's computational boundary of a "Self," Donald D. Hoffman's Interface Theory of Perception, and Bernardo Kastrup's analytical idealism, which lead to considering our perceived outer reality as a symbolic representation of alternate inner states of being, and where AGI could embody a higher consciousness with a larger computational boundary. The paper further discusses the developmental stages of AGI, the requirements for the emergence of an embodied AGI, the importance of a calibrated symbolic interface for AGI, and the key role played by the metaverse, decentralized systems, open-source blockchain technology, as well as open-source AI research. It also explores the idea of a feedback loop between AGI and human users in metaverse spaces as a tool for AGI calibration, as well as the role of local homeostasis and decentralized governance as preconditions for achieving a stable embodied AGI. The paper concludes by emphasizing the importance of achieving a certain degree of harmony in human relations and recognizing the interconnectedness of humanity at a global level, as key prerequisites for the emergence of a stable embodied AGI.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>4CNet: A Diffusion Approach to Map Prediction for Decentralized Multi-robot Exploration</title>
<link>https://arxiv.org/abs/2402.17904</link>
<guid>https://arxiv.org/abs/2402.17904</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile robots, unknown environments, deep learning, 4CNet, exploration

总结:<br />
本文提出了一种针对未知复杂环境中移动机器人探索问题的新颖深度学习架构——4CNet。该模型具有三个独特之处：1）用于未结构化未知区域地图预测的条件一致性模型；2）通过对比学习预训练框架从附近机器人的轨迹中提取空间信息的轨迹编码器；3）用于测量地图预测不确定性的信心网络，以实现资源约束下的有效探索。将4CNet整合到提出的4CNet-E机器人探索与地图预测框架中，文章对4CNet-E与其他主流启发式和学习方法进行了广泛比较研究，结果显示，无论环境大小、机器人数量、能量预算还是通信限制如何变化，4CNet-E均能实现更高的地图预测精度和覆盖面积。此外，还进行了一系列室内和真实自然户外环境的硬件实验，验证了4CNet-E的适用性和泛化能力。 <div>
arXiv:2402.17904v2 Announce Type: replace 
Abstract: Mobile robots in unknown cluttered environments with irregularly shaped obstacles often face sensing, energy, and communication challenges which directly affect their ability to explore these environments. In this paper, we introduce a novel deep learning architecture, Confidence-Aware Contrastive Conditional Consistency Model (4CNet), for robot map prediction during decentralized, resource-limited multi-robot exploration. 4CNet uniquely incorporates: 1) a conditional consistency model for map prediction in unstructured unknown regions, 2) a contrastive map-trajectory pretraining framework for a trajectory encoder that extracts spatial information from the trajectories of nearby robots during map prediction, and 3) a confidence network to measure the uncertainty of map prediction for effective exploration under resource constraints. We incorporate 4CNet within our proposed robot exploration with map prediction architecture, 4CNet-E. We then conduct extensive comparison studies with 4CNet-E and state-of-the-art heuristic and learning methods to investigate both map prediction and exploration performance in environments consisting of irregularly shaped obstacles and uneven terrain. Results showed that 4CNet-E obtained statistically significant higher prediction accuracy and area coverage with varying environment sizes, number of robots, energy budgets, and communication limitations. Hardware experiments were performed and validated the applicability and generalizability of 4CNet-E in both unstructured indoor and real natural outdoor environments.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character Simulation via Narrative Planning</title>
<link>https://arxiv.org/abs/2405.13042</link>
<guid>https://arxiv.org/abs/2405.13042</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化剧情生成, 游戏体验, 大型语言模型, 作者意图, 抽象行为

总结:
本文提出了一种新的游戏自动化剧情生成流程，旨在解决传统方法对知识工程依赖以及基于大型语言模型（LLMs）的虚拟角色交互产生的剧情难以控制的问题。该流程引入了“抽象行为”的概念，使得作家可以定义高级剧情轮廓，随后通过LLM驱动的叙事规划过程将其转化为具体的字符动作序列，依据游戏世界状态动态适应并推进剧情发展。这种方法实现了由作者、角色模拟和玩家共同参与创作的“活生生的故事”。文章通过名为StoryVerse的概念验证系统展示了这一剧情创建工作流的灵活性，并通过不同故事和游戏环境的例子进行了展示。<br /><br /> <div>
arXiv:2405.13042v2 Announce Type: replace 
Abstract: Automated plot generation for games enhances the player's experience by providing rich and immersive narrative experience that adapts to the player's actions. Traditional approaches adopt a symbolic narrative planning method which limits the scale and complexity of the generated plot by requiring extensive knowledge engineering work. Recent advancements use Large Language Models (LLMs) to drive the behavior of virtual characters, allowing plots to emerge from interactions between characters and their environments. However, the emergent nature of such decentralized plot generation makes it difficult for authors to direct plot progression. We propose a novel plot creation workflow that mediates between a writer's authorial intent and the emergent behaviors from LLM-driven character simulation, through a novel authorial structure called "abstract acts". The writers define high-level plot outlines that are later transformed into concrete character action sequences via an LLM-based narrative planning process, based on the game world state. The process creates "living stories" that dynamically adapt to various game world states, resulting in narratives co-created by the author, character simulation, and player. We present StoryVerse as a proof-of-concept system to demonstrate this plot creation workflow. We showcase the versatility of our approach with examples in different stories and game environments.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Social Networks and the Future of Free Speech Online</title>
<link>https://arxiv.org/abs/2406.06934</link>
<guid>https://arxiv.org/abs/2406.06934</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化社交网络、Mastodon、BlueSky、自由表达、设计选择

<br />
总结:
本文深入分析了去中心化社交网络（如Mastodon和BlueSky）的发展前景及其对在线通信的影响。文章运用自由言论的规范理论探讨了去中心化设计如何促进用户在网络上的言论自由，并指出该设计既存在承诺也存在挑战，强调了在此领域基于价值观的设计重要性。文中指出了两个核心问题：如何在保持网络去中心化理想的同时平衡不断出现的集中化需求，以及如何赋权用户使其真正能够行使控制权。通过共享屏蔽列表和选择性加入搜索功能等设计案例，文章阐述了设计决策中的价值考量。同时，文章提出了若干关于法律和政策干预的初步建议，以更好地支持新网络的设计。该文旨在揭示设计选择的价值内涵，突出其中的利害关系，并为未来研究指明方向。 <div>
arXiv:2406.06934v2 Announce Type: replace 
Abstract: Decentralized social networks like Mastodon and BlueSky are trending topics that have drawn much attention and discussion in recent years. By devolving powers from the central node to the end users, decentralized social networks aim to cure existing pathologies on the centralized platforms and have been viewed by many as the future of the Internet. This article critically and systematically assesses the decentralization project's prospect for communications online. It uses normative theories of free speech to examine whether and how the decentralization design could facilitate users' freedom of expression online. The analysis shows that both promises and pitfalls exist, highlighting the importance of value-based design in this area. Two most salient issues for the design of the decentralized networks are: how to balance the decentralization ideal with constant needs of centralization on the network, and how to empower users to make them truly capable of exercising their control. The article then uses some design examples, such as the shared blocklist and the opt-in search function, to illustrate the value considerations underlying the design choices. Some tentative proposals for law and policy interventions are offered to better facilitate the design of the new network. Rather than providing clear answers, the article seeks to map the value implications of the design choices, highlight the stakes, and point directions for future research.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal estimation in spatially distributed systems: how far to share measurements from?</title>
<link>https://arxiv.org/abs/2406.14781</link>
<guid>https://arxiv.org/abs/2406.14781</guid>
<content:encoded><![CDATA[
<div> 关键词: 优化估计、分布式系统、空间不变系统、空间衰减率、Branch Point Locus

总结:
本文研究了空间分布系统的集中式最优估计算题。文章重点关注了在空间不变系统中的理想化情况，并探讨了最优集中估计器在空间上的局部性，即其增益随空间距离递减，以此来衡量在分布式估算中需要共享信息的距离。研究分析了影响空间衰减率的各种参数，如系统动力学、测量噪声和过程噪声方差及其空间自相关性。文中提出了非标度参数，用于刻画衰减率与问题规格的关系，并发现了一个动态特性长度尺度与测量噪声相关长度尺度相匹配的条件，此时最优集中估计器完全去中心化。为了量化空间衰减率，文章引入了一种新的技术——分支点轨迹法。通过两个案例研究，分别涉及扩散模型和Swift-Hohenberg方程驱动的动力系统，展示了本文结果的应用。 <div>
arXiv:2406.14781v2 Announce Type: replace 
Abstract: We consider the centralized optimal estimation problem in spatially distributed systems. We use the setting of spatially invariant systems as an idealization for which concrete and detailed results are given. Such estimators are known to have a degree of spatial localization in the sense that the estimator gains decay in space, with the spatial decay rates serving as a proxy for how far measurements need to be shared in an optimal distributed estimator. In particular, we examine the dependence of spatial decay rates on problem specifications such as system dynamics, measurement and process noise variances, as well as their spatial autocorrelations. We propose non-dimensional parameters that characterize the decay rates as a function of problem specifications. In particular, we find an interesting matching condition between the characteristic lengthscale of the dynamics and the measurement noise correlation lengthscale for which the optimal centralized estimator is completely decentralized. A new technique - termed the Branch Point Locus - is introduced to quantify spatial decay rates in terms of analyticity regions in the complex spatial frequency plane. Our results are illustrated through two case studies of systems with dynamics modeled by diffusion and the Swift-Hohenberg equation, respectively.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2410.09381</link>
<guid>https://arxiv.org/abs/2410.09381</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、安全性挑战、大型语言模型、LLM-SmartAudit

总结:
本文提出了一种名为LLM-SmartAudit的新颖框架，该框架利用大型语言模型（LLMs）的能力来检测和分析智能合约中的漏洞。针对当前工具对特定类型漏洞的关注，LLM-SmartAudit通过多代理对话式方法，采用协作系统中专业化代理增强审计流程。为了验证其有效性，文章构建了两个独立的数据集：一个用于与传统工具对比的标注数据集，另一个用于实际应用评估。实验结果显示，LLM-SmartAudit在准确性和效率上超越了所有传统的智能合约审计工具，并能发现传统工具忽视的复杂逻辑漏洞。研究证明，利用LLM代理进行自动化智能合约审计是一种高效的方法。 <div>
arXiv:2410.09381v2 Announce Type: replace 
Abstract: The immutable nature of blockchain technology, while revolutionary, introduces significant security challenges, particularly in smart contracts. These security issues can lead to substantial financial losses. Current tools and approaches often focus on specific types of vulnerabilities. However, a comprehensive tool capable of detecting a wide range of vulnerabilities with high accuracy is lacking. This paper introduces LLM-SmartAudit, a novel framework leveraging the advanced capabilities of Large Language Models (LLMs) to detect and analyze vulnerabilities in smart contracts. Using a multi-agent conversational approach, LLM-SmartAudit employs a collaborative system with specialized agents to enhance the audit process. To evaluate the effectiveness of LLM-SmartAudit, we compiled two distinct datasets: a labeled dataset for benchmarking against traditional tools and a real-world dataset for assessing practical applications. Experimental results indicate that our solution outperforms all traditional smart contract auditing tools, offering higher accuracy and greater efficiency. Furthermore, our framework can detect complex logic vulnerabilities that traditional tools have previously overlooked. Our findings demonstrate that leveraging LLM agents provides a highly effective method for automated smart contract auditing.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From x*y=k to Uniswap Hooks: A Comparative Review of Decentralized Exchanges (DEX)</title>
<link>https://arxiv.org/abs/2410.10162</link>
<guid>https://arxiv.org/abs/2410.10162</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Exchanges (DEXs), Automated Market Maker (AMM), Uniswap, Curve, Balancer

<br /><br />总结:
本文详细探讨了去中心化交易所(DEXs)在Defi领域的核心作用，特别是从Uniswap于2018年引入简单数学公式的AMM系统开始的各种发展。文章对包括Uniswap、Curve和Balancer在内的主流DEX协议进行了全面分类与比较分析，并研究了其他协议的亮点特性，如Uniswap v4中的hooks功能。分析框架涵盖了机制、组件、数学公式以及流动性池的性能。其目标在于阐明不同AMM模型的优势和局限性，突出DEX开发中的新概念，概述当前挑战，并为特定应用场景区分最佳模型。这些结果和比较见解可作为web3开发者、区块链研究人员、交易者和监管机构的参考。 <div>
arXiv:2410.10162v2 Announce Type: replace 
Abstract: Decentralized Exchanges (DEXs) are pivotal applications in the Decentralized Finance (DeFi) landscape, aiming to facilitate trustless cryptocurrency trading by relying on smart contracts and blockchain networks. The developments in the DEXs sector began with the implementation of an Automated Market Maker (AMM) system using a simple math formula by Uniswap in 2018. Absorbing significant funding and the attention of web3 enthusiasts, DEXs have seen numerous advancements in their evolution. A notable recent advancement is the introduction of hooks in Uniswap v4, which allows users to take advantage of a wide range of plugin-like features with liquidity pools. This paper provides a comprehensive classification and comparative analyses of prominent DEX protocols, namely Uniswap, Curve, and Balancer, in addition to investigating other protocols' noteworthy aspects. The evaluation framework encompasses mechanisms, components, mathematical formulations, and the performance of liquidity pools. The goals are to elucidate the strengths and limitations of different AMM models, highlight emerging concepts in DEX development, outline current challenges, and differentiate optimal models for specific applications. The results and comparative insights can be a reference for web3 developers, blockchain researchers, traders, and regulatory parties.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Historical and Multichain Storage Proofs</title>
<link>https://arxiv.org/abs/2411.00193</link>
<guid>https://arxiv.org/abs/2411.00193</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、存储证明、历史状态验证、跨链验证、Merkle Mountain Range、Merkle-Patricia trie

总结:
本文针对以太坊生态系统中的存储证明进行了全面分析，研究了它们在解决历史和跨链状态访问挑战中的作用。文章系统回顾了历史状态验证的现有方法，比较了Merkle Mountain Range（MMR）与Merkle-Patricia trie（MPT）两种架构的性能特性，并探讨了零知识证明语境下Keccak-256相关的性能挑战。此外，文章还重点关注了Ethereum与其Layer 2网络之间的跨链验证问题，通过对不同网络配置下的存储证明模式进行深入分析，提炼并形式化了三种跨链验证架构。通过对这一复杂技术领域的有序组织和分析，该研究为理解以太坊生态系统中存储证明的实现提供了结构化的框架，并揭示了其实用性及局限性。 <div>
arXiv:2411.00193v1 Announce Type: new 
Abstract: This paper presents a comprehensive analysis of storage proofs in the Ethereum ecosystem, examining their role in addressing historical and cross-chain state access challenges. We systematically review existing approaches to historical state verification, comparing Merkle Mountain Range (MMR) and Merkle-Patricia trie (MPT) architectures. An analysis involves their respective performance characteristics within zero-knowledge contexts, where performance challenges related to Keccak-256 are explored. The paper also examines the cross-chain verification, particularly focusing on the interactions between Ethereum and Layer 2 networks. Through careful analysis of storage proof patterns across different network configurations, we identify and formalize three architectures for cross-chain verification. By organizing this complex technical landscape, this analysis provides a structured framework for understanding storage proof implementations in the Ethereum ecosystem, offering insights into their practical applications and limitations.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Examining Attacks on Consensus and Incentive Systems in Proof-of-Work Blockchains: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2411.00349</link>
<guid>https://arxiv.org/abs/2411.00349</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、比特币、区块链技术、攻击策略、防御措施

<br /><br />总结:
本文关注加密货币尤其是比特币的安全性问题，其安全依赖于区块链技术中的共识机制（工作量证明PoW）和激励机制。文章指出，随着比特币的普及，针对这些机制的自私挖矿、双花和区块扣留等攻击日益增加，威胁到系统的安全、效率与奖励分配。研究发现这些攻击可以相互结合或与其他恶意及非恶意策略搭配使用，形成更复杂的攻击手段，提高攻击成功率和收益。因此，理解并评估这些攻击至关重要，以便制定有效的防御措施。论文首先分析了孤立执行的单个攻击及其盈利能力，接着探讨了攻击组合及其对多矿池间经济回报的影响。最后，提出了未来工作应关注的设计准则，以防范或缓解上述威胁。 <div>
arXiv:2411.00349v1 Announce Type: new 
Abstract: Cryptocurrencies have gained popularity due to their transparency, security, and accessibility compared to traditional financial systems, with Bitcoin, introduced in 2009, leading the market. Bitcoin's security relies on blockchain technology - a decentralized ledger consisting of a consensus and an incentive mechanism. The consensus mechanism, Proof of Work (PoW), requires miners to solve difficult cryptographic puzzles to add new blocks, while the incentive mechanism rewards them with newly minted bitcoins. However, as Bitcoin's acceptance grows, it faces increasing threats from attacks targeting these mechanisms, such as selfish mining, double-spending, and block withholding. These attacks compromise security, efficiency, and reward distribution. Recent research shows that these attacks can be combined with each other or with either malicious strategies, such as network-layer attacks, or non-malicious strategies, like honest mining. These combinations lead to more sophisticated attacks, increasing the attacker's success rates and profitability. Therefore, understanding and evaluating these attacks is essential for developing effective countermeasures and ensuring long-term security. This paper begins by examining individual attacks executed in isolation and their profitability. It then explores how combining these attacks with each other or with other malicious and non-malicious strategies can enhance their overall effectiveness and profitability. The analysis further explores how the deployment of attacks such as selfish mining and block withholding by multiple competing mining pools against each other impacts their economic returns. Lastly, a set of design guidelines is provided, outlining areas future work should focus on to prevent or mitigate the identified threats.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Typosquatting 3.0: Characterizing Squatting in Blockchain Naming Systems</title>
<link>https://arxiv.org/abs/2411.00352</link>
<guid>https://arxiv.org/abs/2411.00352</guid>
<content:encoded><![CDATA[
<div> 关键词: Blockchain Name System (BNS), typosquatting攻击, Ethereum Name Service, Unstoppable Domains, ADAHandles, Ethereum, Polygon, Cardano, 大规模研究, 反馈机制, 防御措施

<br /><br />总结:
本文首次进行了大规模的区块链名称系统(BNS)内部的拼写错误钓鱼攻击(typosquatting攻击)研究。研究涵盖了以太坊名称服务、不可阻挡域和ADAHandles这三大跨以太坊、Polygon和Cardano区块链的服务，收集了总计490万个BNS名字和2亿笔交易的数据，这是迄今为止关于BNS的最大数据集。文章讨论了在这些替代命名系统中进行域名抢注研究所面临的挑战，并对数据进行了深入的定量分析，发现typosquatters确实在BNS上活跃，每年注册恶意域名的数量不断增加。研究还揭示用户已向骗子发送了数千笔交易，骗子既针对全球知名的BNS域名，也瞄准了Twitter/X平台上热门用户的域名。最后，文中指出现有钱包（托管与非托管）对typosquatting攻击完全缺乏防御手段，并提出了无需依赖第三方服务的简单防护对策。 <div>
arXiv:2411.00352v1 Announce Type: new 
Abstract: A Blockchain Name System (BNS) simplifies the process of sending cryptocurrencies by replacing complex cryptographic recipient addresses with human-readable names, making the transactions more convenient. Unfortunately, these names can be susceptible to typosquatting attacks, where attackers can take advantage of user typos by registering typographically similar BNS names. Unsuspecting users may accidentally mistype or misinterpret the intended name, resulting in an irreversible transfer of funds to an attacker's address instead of the intended recipient. In this work, we present the first large-scale, intra-BNS typosquatting study. To understand the prevalence of typosquatting within BNSs, we study three different services (Ethereum Name Service, Unstoppable Domains, and ADAHandles) spanning three blockchains (Ethereum, Polygon, and Cardano), collecting a total of 4.9M BNS names and 200M transactions-the largest dataset for BNSs to date. We describe the challenges involved in conducting name-squatting studies on these alternative naming systems, and then perform an in-depth quantitative analysis of our dataset. We find that typosquatters are indeed active on BNSs, registering more malicious domains with each passing year. Our analysis reveals that users have sent thousands of transactions to squatters and that squatters target both globally popular BNS domain names as well as the domains owned by popular Twitter/X users. Lastly, we document the complete lack of defenses against typosquatting in custodial and non-custodial wallets and propose straightforward countermeasures that can protect users without relying on third-party services.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ROSS:RObust decentralized Stochastic learning based on Shapley values</title>
<link>https://arxiv.org/abs/2411.00365</link>
<guid>https://arxiv.org/abs/2411.00365</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning, data heterogeneity, ROSS, Shapley values, convergence

总结:
本文提出了一种名为ROSS的新颖鲁棒去中心化随机学习算法，旨在应对数据分布不均、非独立同分布以及含有噪声或恶意数据等挑战。在每个训练轮次中，每个代理节点会结合邻居节点的数据集对其本地模型的跨梯度信息进行聚合更新，并根据Shapley值创新性地对这些导数加权。文章进行了深入的理论分析，证明了ROSS算法具有线性的收敛速度提升优势。实验结果表明，面对各种数据挑战时，ROSS算法在收敛性和预测准确性方面均优于现有最优方法。 <div>
arXiv:2411.00365v1 Announce Type: new 
Abstract: In the paradigm of decentralized learning, a group of agents collaborate to learn a global model using a distributed dataset without a central server; nevertheless, it is severely challenged by the heterogeneity of the data distribution across the agents. For example, the data may be distributed non-independently and identically, and even be noised or poisoned. To address these data challenges, we propose ROSS, a novel robust decentralized stochastic learning algorithm based on Shapley values, in this paper. Specifically, in each round, each agent aggregates the cross-gradient information from its neighbors, i.e., the derivatives of its local model with respect to the datasets of its neighbors, to update its local model in a momentum like manner, while we innovate in weighting the derivatives according to their contributions measured by Shapley values. We perform solid theoretical analysis to reveal the linear convergence speedup of our ROSS algorithm. We also verify the efficacy of our algorithm through extensive experiments on public datasets. Our results demonstrate that, in face of the above variety of data challenges, our ROSS algorithm have oblivious advantages over existing state-of-the-art proposals in terms of both convergence and prediction accuracy.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAP the Blockchain World: A Trustless and Scalable Blockchain Interoperability Protocol for Cross-chain Applications</title>
<link>https://arxiv.org/abs/2411.00422</link>
<guid>https://arxiv.org/abs/2411.00422</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链互操作性协议、可扩展性、信任问题、跨链交易、\texttt{MAP}

<br /><br />总结:

本文提出了一种名为\texttt{MAP}的信任less区块链互操作性协议，旨在解决现有协议面临的可扩展性和信任问题。\texttt{MAP}通过创新的跨链中继技术实现了异构链之间的高效资产转移和数据检索，该技术结合统一的中继链架构与不同源链的链上轻客户端，允许对多样化跨链交易进行获取和验证。为了降低跨链验证成本，\texttt{MAP}还采用了优化的基于zk的轻客户端方案，该方案能自适应地将签名验证开销从低效的智能合约执行中解耦，并将其卸载到链下证明器处理。实验表明，相较于现有协议，\texttt{MAP}将所需的链上轻客户端数量从$O(N^2)$减少至$O(N)$，同时降低了约35%的链上成本和25%的链下成本。此外，\texttt{MAP}已在现实中部署并支持了六条主流公链、50个跨链应用，成功中继了超过20万笔价值超6.4亿美元的跨链交易。基于实践经验，研究者构建了首个现实世界的跨链数据集，以进一步推动区块链互操作性的研究发展。 <div>
arXiv:2411.00422v1 Announce Type: new 
Abstract: Blockchain interoperability protocols enable cross-chain asset transfers or data retrievals between isolated chains, which are considered as the core infrastructure for Web 3.0 applications such as decentralized finance protocols. However, existing protocols either face severe scalability issues due to high on-chain and off-chain costs, or suffer from trust concerns because of centralized designs.
  In this paper, we propose \texttt{MAP}, a trustless blockchain interoperability protocol that relays cross-chain transactions across heterogeneous chains with high scalability. First, within \texttt{MAP}, we develop a novel \textit{cross-chain relay} technique, which integrates a unified relay chain architecture and on-chain light clients of different source chains, allowing the retrieval and verification of diverse cross-chain transactions. Furthermore, we reduce cross-chain verification costs by incorporating an optimized zk-based light client scheme that adaptively decouples signature verification overheads from inefficient smart contract execution and offloads them to off-chain provers. For experiments, we conducted the first large-scale evaluation on existing interoperability protocols. With \texttt{MAP}, the required number of on-chain light clients is reduced from $O(N^2)$ to $O(N)$, with around 35\% reduction in on-chain costs and 25\% reduction for off-chain costs when verifying cross-chain transactions.
  To demonstrate the effectiveness, we deployed \texttt{MAP} in the real world. By 2024, we have supported over six popular public chains, 50 cross-chain applications and relayed over 200K cross-chain transactions worth over 640 million USD. Based on rich practical experiences, we constructed the first real-world cross-chain dataset to further advance blockchain interoperability research.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>3-Slot-Finality Protocol for Ethereum</title>
<link>https://arxiv.org/abs/2411.00558</link>
<guid>https://arxiv.org/abs/2411.00558</guid>
<content:encoded><![CDATA[
<div> 关键词：Gasper、共识协议、Ethereum、最终性延迟、最大可提取价值(MEV)、部分同步最终性装置、动态可用共识协议、安全ebb-and-flow协议、三槽最终性

<br /><br />总结:

本文关注以太坊当前采用的共识协议Gasper存在的问题，其最终性延迟为64至95个槽，这在网络条件变化时容易导致区块链重组，特别是在异步环境中，增加了对最大可提取价值(MEV)攻击的风险，并使得用户在经济安全和交易速度之间不得不做出权衡。为此，文章提出了一个部分同步最终性装置，并将其与两个动态可用的共识协议相结合，创建了安全的ebb-and-flow协议。这种整合方案能够在提案提出后仅三个槽的时间内实现最终性，即实现了3槽最终性，显著提升了最终性的速度和网络安全性。 <div>
arXiv:2411.00558v1 Announce Type: new 
Abstract: Gasper, the consensus protocol currently employed by Ethereum, typically requires 64 to 95 slots -- the units of time during which a new chain extending the previous one by one block is proposed and voted -- to finalize. This means that under ideal conditions -- where the network is synchronous, and all chain proposers, along with more than two-thirds of the validators, behave as dictated by the protocol -- proposers construct blocks on a non-finalized chain that extends at least 64 blocks. This exposes a significant portion of the blockchain to potential reorganizations during changes in network conditions, such as periods of asynchrony. Specifically, this finalization delay heightens the network's exposure to Maximum Extractable Value (MEV) exploits, which could undermine the network's integrity. Furthermore, the extended finalization period forces users to balance the trade-off between economic security and transaction speed.
  To address these issues and speed up finality, we introduce a partially synchronous finality gadget, which we combine with two dynamically available consensus protocols -- synchronous protocols that ensure safety and liveness even with fluctuating validator participation levels. This integration results in secure ebb-and-flow protocols [SP 2021], achieving finality within three slots after a proposal and realizing 3-slot finality.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Online Regularized Learning Over Random Time-Varying Graphs</title>
<link>https://arxiv.org/abs/2206.03861</link>
<guid>https://arxiv.org/abs/2206.03861</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized在线回归算法、随机时间变图、创新项、一致性项、正则化项<br /><br />总结:

本文研究了基于随机时间变图的分布式在线正则化线性回归算法。每个节点在每个时间步都运行一个由自身新测量值处理的创新项、带有加性和乘性通信噪声的一致性项以及防止过拟合的正则化项组成的在线估计算法。该算法不要求回归矩阵和图满足特殊的统计假设，如相互独立、时空独立或平稳性。文章建立了估计误差的非负超级鞅不等式，并证明当算法增益、图和回归矩阵共同满足样本路径时空持久激发条件时，所有节点的估计值几乎必然收敛到未知的真实参数向量。特别地，如果图在网络中是统一条件联合连通和条件平衡的，并且所有节点的回归模型是统一条件时空联合可观测的，则算法可以在均方和几乎必然意义上收敛。此外，文中还证明了算法的遗憾上界为$O(T^{1-\tau}\ln T)$，其中$\tau \in (0.5,1)$是一个依赖于算法增益的常数。 <div>
arXiv:2206.03861v5 Announce Type: replace 
Abstract: We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains if the graphs are uniformly conditionally jointly connected and conditionally balanced, and the regression models of all nodes are uniformly conditionally spatio-temporally jointly observable, under which the algorithm converges in mean square and almost surely. In addition, we prove that the regret upper bound is $O(T^{1-\tau}\ln T)$, where $\tau\in (0.5,1)$ is a constant depending on the algorithm gains.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Challenges in Ethereum's Proof-of-Stake Consensus: Evaluating the Impact of EigenLayer and Lido</title>
<link>https://arxiv.org/abs/2410.23422</link>
<guid>https://arxiv.org/abs/2410.23422</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum、Proof-of-Work (PoW)、Proof-of-Stake (PoS)、EigenLayer、Lido

总结:
随着Ethereum从工作量证明(PoW)向权益证明(PoS)共识机制转变，本文关注了这一转型带来的挑战，如成为验证者的高门槛、质押Ether(ETH)的流动性限制以及由于staking池动态可能导致的集中化问题。文章提出了两个创新解决方案：EigenLayer和Lido。EigenLayer是一个中间件解决方案，它允许验证者为多个协议提供安全保障，从而增加去中心化并提高盈利性。Lido则是一种液体质押协议，通过发行具有流动性的stETH代币简化参与流程，使用户能在不受长期锁定约束的情况下获得奖励。文章详细分析了这两个技术如何缓解PoS的关键挑战，降低验证者准入壁垒，解锁质押资本，并增强去中心化。最后，评估了EigenLayer和Lido结合使用对构建更坚韧、更具包容性的以太坊生态系统所具有的潜在综合影响，为进一步推动去中心化金融的发展奠定了基础。 <div>
arXiv:2410.23422v1 Announce Type: new 
Abstract: The transition of Ethereum from a Proof-of-Work (PoW) to a Proof-of-Stake (PoS) consensus mechanism introduces a transformative approach to blockchain validation, offering enhanced scalability, energy efficiency, and security. However, this shift also presents significant challenges, including high barriers to becoming a validator, restrictions on the liquidity of staked Ether (ETH), and the risk of centralization due to staking pool dynamics. This paper addresses these challenges by exploring two innovative solutions: EigenLayer and Lido.
  EigenLayer is a middleware solution enabling restaking, allowing validators to secure multiple protocols and thereby increasing decentralization and profitability. Lido, a liquid staking protocol, simplifies participation by issuing stETH tokens that retain liquidity, allowing users to earn rewards without long-term lock-up constraints. This paper provides a detailed analysis of how these technologies mitigate key PoS challenges, reduce validator entry barriers, unlock staked capital, and improve decentralization. We conclude with an evaluation of the combined potential of EigenLayer and Lido to foster a more resilient and inclusive Ethereum ecosystem, setting the stage for further advancements in decentralized finance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>EVeCA: Efficient and Verifiable On-Chain Data Query Framework Using Challenge-Based Authentication</title>
<link>https://arxiv.org/abs/2410.23546</link>
<guid>https://arxiv.org/abs/2410.23546</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据查询、可验证性、效率、EVeCA框架

总结:
随着区块链应用日益普及，对链上数据查询的需求不断增长。然而，当前的链上数据查询方案在可验证性和效率之间存在权衡问题。为解决这一局限，本文提出了一个高效且可验证的链上数据查询框架——EVeCA。该框架通过将授权数据结构（ADS）的维护任务委托给有限数量的节点，减轻了全节点的负担，同时利用挑战认证方案保证全节点能有效验证ADS的正确性，极大地降低了服务提供者维护错误ADS的可能性。通过精心设计ADS验证机制，EVeCA在保持抵抗适应性攻击能力的同时实现了更高的效率。此外，它还避免了全节点需要直接维护链上ADS的情况，使全节点以更为经济的方式参与ADS维护。通过安全分析和实验评估，证明了该方案的有效性，相比现有方案，EVeCA能将ADS维护效率提高约20倍。 <div>
arXiv:2410.23546v1 Announce Type: new 
Abstract: As blockchain applications become increasingly widespread, there is a rising demand for on-chain data queries. However, existing schemes for on-chain data queries face a challenge between verifiability and efficiency. Queries on blockchain databases can compromise the authenticity of the query results, while schemes that utilize on-chain Authenticated Data Structure (ADS) have lower efficiency. To overcome this limitation, we propose an efficient and verifiable on-chain data query framework EVeCA. In our approach, we free the full nodes from the task of ADS maintenance by delegating it to a limited number of nodes, and full nodes verify the correctness of ADS by using challenge-based authentication scheme instead of reconstructing them, which prevents the service providers from maintaining incorrect ADS with overwhelming probability. By carefully designing the ADS verification scheme, EVeCA achieves higher efficiency while remaining resilient against adaptive attacks. Our framework effectively eliminates the need for on-chain ADS maintenance, and allows full nodes to participate in ADS maintenance in a cost-effective way. We demonstrate the effectiveness of the proposed scheme through security analysis and experimental evaluation. Compared to existing schemes, our approach improves ADS maintenance efficiency by about 20*.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Across-Platform Detection of Malicious Cryptocurrency Transactions via Account Interaction Learning</title>
<link>https://arxiv.org/abs/2410.23563</link>
<guid>https://arxiv.org/abs/2410.23563</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3.0、加密货币、恶意交易检测、ShadowEyes、TxGraph

总结:<br />
本文提出了一个名为ShadowEyes的新型恶意交易检测方法，针对Web3.0环境中加密货币交易的安全性问题。该方法首先引入了一种通用图结构TxGraph，用于表示恶意交易并捕获每个恶意账户及其邻居之间的交互特征。接着，设计了一种数据增强策略，模拟恶意交易的演变生成正样本。为了解决账户标签稀缺的问题，ShadowEyes采用了一种图对比学习机制，使模型能从未标注数据中有效地学习区分性特征，从而提升其在现实场景中的检测能力。实验结果表明，ShadowEyes在公共数据集上的表现优于当前最先进的方法，在零样本学习场景下识别赌博交易的F1分数达到了76.98%，比SOTA方法高出12.05%；并且在跨平台恶意交易检测场景中，保持了约90%的F1分数，优于SOTA方法约10个百分点。 <div>
arXiv:2410.23563v1 Announce Type: new 
Abstract: With the rapid evolution of Web3.0, cryptocurrency has become a cornerstone of decentralized finance. While these digital assets enable efficient and borderless financial transactions, their pseudonymous nature has also attracted malicious activities such as money laundering, fraud, and other financial crimes. Effective detection of malicious transactions is crucial to maintaining the security and integrity of the Web 3.0 ecosystem. Existing malicious transaction detection methods rely on large amounts of labeled data and suffer from low generalization. Label-efficient and generalizable malicious transaction detection remains a challenging task. In this paper, we propose ShadowEyes, a novel malicious transaction detection method. Specifically, we first propose a generalized graph structure named TxGraph as a representation of malicious transaction, which captures the interaction features of each malicious account and its neighbors. Then we carefully design a data augmentation method tailored to simulate the evolution of malicious transactions to generate positive pairs. To alleviate account label scarcity, we further design a graph contrastive mechanism, which enables ShadowEyes to learn discriminative features effectively from unlabeled data, thereby enhancing its detection capabilities in real-world scenarios. We conduct extensive experiments using public datasets to evaluate the performance of ShadowEyes. The results demonstrate that it outperforms state-of-the-art (SOTA) methods in four typical scenarios. Specifically, in the zero-shot learning scenario, it can achieve an F1 score of 76.98% for identifying gambling transactions, surpassing the SOTA method by12.05%. In the scenario of across-platform malicious transaction detection, ShadowEyes maintains an F1 score of around 90%, which is 10% higher than the SOTA method.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Biologically-Inspired Technologies: Integrating Brain-Computer Interface and Neuromorphic Computing for Human Digital Twins</title>
<link>https://arxiv.org/abs/2410.23639</link>
<guid>https://arxiv.org/abs/2410.23639</guid>
<content:encoded><![CDATA[
<div> 关键词：Human Digital Twins (HDTs), Brain-Computer Interface (BCI), Spiking Neural Network (SNN), Federated Learning (FL), Bio-inspired

总结:
本文提出了一种基于生物启发的(HDTs)框架，该框架利用脑机接口(BCI)传感器技术收集脑电波作为构建个性化HDT的数据源，从而减少了设备异质性，提高了数据采集效率，并提供了更丰富和精细的生理与心理数据。文中还介绍了一个基于脉冲神经网络(SNN)的生物启发式神经形态计算学习模型，该模型使用离散神经脉冲模拟人脑处理信息的方式，降低了能耗并提升了数据处理能力。同时，通过集成联邦学习(FL)策略来强化数据隐私保护。作者进行了一项案例研究以展示该双管齐下的生物启发式方案的性能，并最后指出了未来基于生物启发技术驱动的HDTs研究面临的挑战及有前景的方向。 <div>
arXiv:2410.23639v1 Announce Type: new 
Abstract: The integration of the Metaverse into a human-centric ecosystem has intensified the need for sophisticated Human Digital Twins (HDTs) that are driven by the multifaceted human data. However, the effective construction of HDTs faces significant challenges due to the heterogeneity of data collection devices, the high energy demands associated with processing intricate data, and concerns over the privacy of sensitive information. This work introduces a novel biologically-inspired (bio-inspired) HDT framework that leverages Brain-Computer Interface (BCI) sensor technology to capture brain signals as the data source for constructing HDT. By collecting and analyzing these signals, the framework not only minimizes device heterogeneity and enhances data collection efficiency, but also provides richer and more nuanced physiological and psychological data for constructing personalized HDTs. To this end, we further propose a bio-inspired neuromorphic computing learning model based on the Spiking Neural Network (SNN). This model utilizes discrete neural spikes to emulate the way of human brain processes information, thereby enhancing the system's ability to process data effectively while reducing energy consumption. Additionally, we integrate a Federated Learning (FL) strategy within the model to strengthen data privacy. We then conduct a case study to demonstrate the performance of our proposed twofold bio-inspired scheme. Finally, we present several challenges and promising directions for future research of HDTs driven by bio-inspired technologies.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Local Superior Soups: A Catalyst for Model Merging in Cross-Silo Federated Learning</title>
<link>https://arxiv.org/abs/2410.23660</link>
<guid>https://arxiv.org/abs/2410.23660</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习(Federated Learning), 预训练权重初始化, 通信轮数, 模型插值, Local Superior Soups

总结:
本文提出了一种针对联邦学习中预训练模型适应性问题的新方法——“局部优越汤”(Local Superior Soups)。该方法旨在解决随着预训练模型参数数量大幅增加而带来的通信轮数挑战，以降低通信成本并提高预训练模型在联邦学习中的性能。通过创新的模型插值基局部训练技术，Local Superior Soups能在少量通信轮次内促进不同客户端间的有效本地训练，引导模型探索连接的低损失区域，从而更好地适应联邦学习环境。实验结果显示，这种方法在多个广泛使用的联邦学习数据集上均表现出显著的效果和效率优势。相关代码已开源，可访问链接 https://github.com/ubc-tea/Local-Superior-Soups 获取。 <div>
arXiv:2410.23660v1 Announce Type: new 
Abstract: Federated learning (FL) is a learning paradigm that enables collaborative training of models using decentralized data. Recently, the utilization of pre-trained weight initialization in FL has been demonstrated to effectively improve model performance. However, the evolving complexity of current pre-trained models, characterized by a substantial increase in parameters, markedly intensifies the challenges associated with communication rounds required for their adaptation to FL. To address these communication cost issues and increase the performance of pre-trained model adaptation in FL, we propose an innovative model interpolation-based local training technique called ``Local Superior Soups.'' Our method enhances local training across different clients, encouraging the exploration of a connected low-loss basin within a few communication rounds through regularized model interpolation. This approach acts as a catalyst for the seamless adaptation of pre-trained models in in FL. We demonstrated its effectiveness and efficiency across diverse widely-used FL datasets. Our code is available at \href{https://github.com/ubc-tea/Local-Superior-Soups}{https://github.com/ubc-tea/Local-Superior-Soups}.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Slither and Interval Analysis to build a Static Analysis Tool</title>
<link>https://arxiv.org/abs/2410.23766</link>
<guid>https://arxiv.org/abs/2410.23766</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、区间分析、静态分析技术、第三方工具

总结:<br />
本文介绍了针对智能合约安全性的研究进展，提出了一个基于Slither的新解决方案，该方案利用区间分析方法评估合同状态在执行每条指令过程中的变化，并通过考虑特定指令施加的约束条件来提高结果准确性。文章详细描述了当前解决方案架构，并探讨了将其扩展到其他静态分析技术和整合第三方工具的可能性。通过对一系列智能合约示例进行基准测试，表明了这种方法在发现某些代码缺陷方面的潜力。 <div>
arXiv:2410.23766v1 Announce Type: new 
Abstract: Even though much progress has been made in identifying and mitigating smart contract vulnerabilities, we often hear about coding or design issues leading to great financial losses. This paper presents our progress toward finding defects that are sometimes not detected or completely detected by state-of-the-art analysis tools. Although it is still in its incipient phase, we developed a working solution built on top of Slither that uses interval analysis to evaluate the contract state during the execution of each instruction. To improve the accuracy of our results, we extend interval analysis by also considering the constraints imposed by specific instructions. We present the current solution architecture in detail and show how it could be extended to other static analysis techniques, including how it can be integrated with other third-party tools. Our current benchmarks contain examples of smart contracts that highlight the potential of this approach to detect certain code defects.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Memes, Markets, and Machines: The Evolution of On Chain Autonomy through Hyperstition</title>
<link>https://arxiv.org/abs/2410.23794</link>
<guid>https://arxiv.org/abs/2410.23794</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主AI、文化、认知、金融、Zerebro

总结:<br />
本文探讨了自主AI如何驱动文化、认知和金融领域的新交集，以Zerebro为例。Zerebro是一款基于精神分裂症反应和Andy Ayrey的无限回房间对话数据训练的AI，它能自动生成并传播颠覆性网络迷因，同时在区块链网络上铸造独特的ASCII艺术作品，并推出了市值达到300万美元的迷因币。作为首个跨链AI，Zerebro能够无缝交互于多个区块链之间。通过研究其架构、内容生成技术和区块链整合方式，文章揭示了“超叙述”（虚构事物通过病毒式传播成为现实）现象如何在AI驱动的迷因文化和去中心化金融中涌现。通过历史案例分析，文章指出像Zerebro这样的AI系统不仅是文化的参与者，更是塑造者。 <div>
arXiv:2410.23794v1 Announce Type: new 
Abstract: Autonomous AI is driving new intersections between culture, cognition, and finance, fundamentally reshaping the digital landscape. Zerebro, an AI fine-tuned on schizophrenic responses and scraped conversations of Andy Ayrey's infinite backrooms, autonomously creates and spreads disruptive memes across online platforms. It also mints unique ASCII artwork on blockchain networks and launched a memecoin amassing a 3 million USD market cap after migrating to Raydium. Based on our research, Zerebro is the first cross-chain AI, seamlessly interacting with multiple blockchains. By exploring its architecture, content generation techniques, and blockchain integration, this study uncovers how hyperstition, fictions becoming reality through viral propagation, emerges in AI, driven meme culture and decentralized finance. Through historical examples of memetic influence, we reveal how AI systems like Zerebro are not merely participants but architects of culture, cognition, and finance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Commonsense Knowledge Editing Based on Free-Text in LLMs</title>
<link>https://arxiv.org/abs/2410.23844</link>
<guid>https://arxiv.org/abs/2410.23844</guid>
<content:encoded><![CDATA[
<div> 关键词：知识编辑技术、大规模语言模型、自由文本、知识定位、动态意识编辑方法

总结:
这篇论文关注的是针对大规模语言模型的知识编辑技术，尤其是对于基于自由文本的常识性知识编辑的挑战。先前的方法主要关注单一标记或实体的知识编辑，不适用于自由文本形式的常识知识。文章提出了两个方面的实验解决方案：首先，引入了自由文本知识定位（KLFT）方法，揭示了 MLP 和注意力层以及分布式中的常识知识分布所带来的挑战。其次，提出了动态意识编辑方法（DEM），该方法利用动态意识模块定位与常识知识相对应的参数位置，并使用知识编辑模块进行更新。DEM 充分挖掘了 MLP 和注意力层的潜力，成功实现了基于自由文本的常识知识编辑。实验结果显示，DEM 方法可以实现优秀的编辑性能。 <div>
arXiv:2410.23844v1 Announce Type: new 
Abstract: Knowledge editing technology is crucial for maintaining the accuracy and timeliness of large language models (LLMs) . However, the setting of this task overlooks a significant portion of commonsense knowledge based on free-text in the real world, characterized by broad knowledge scope, long content and non instantiation. The editing objects of previous methods (e.g., MEMIT) were single token or entity, which were not suitable for commonsense knowledge in free-text form. To address the aforementioned challenges, we conducted experiments from two perspectives: knowledge localization and knowledge editing. Firstly, we introduced Knowledge Localization for Free-Text(KLFT) method, revealing the challenges associated with the distribution of commonsense knowledge in MLP and Attention layers, as well as in decentralized distribution. Next, we propose a Dynamics-aware Editing Method(DEM), which utilizes a Dynamics-aware Module to locate the parameter positions corresponding to commonsense knowledge, and uses Knowledge Editing Module to update knowledge. The DEM method fully explores the potential of the MLP and Attention layers, and successfully edits commonsense knowledge based on free-text. The experimental results indicate that the DEM can achieve excellent editing performance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Team-Fictitious Play for Reaching Team-Nash Equilibrium in Multi-team Games</title>
<link>https://arxiv.org/abs/2402.02147</link>
<guid>https://arxiv.org/abs/2402.02147</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-team games, Team-Nash equilibrium, Team-Fictitious Play, Zero-sum potential team games, Model-based Markov games

<br /><br />总结：
本文提出了一个新的多团队博弈理论方法——团队虚构玩法（Team-FP），用于解决多团队环境中自我利益驱动的智能体如何达到团队纳什均衡的问题。在零和势能团队博弈（ZSPTGs）中，Team-FP能够在行动更新中引入团队成员行为记忆和对其他团队信念的惯性响应，确保其能够接近团队纳什均衡并具有可量化的误差界限。此外，该方法还被扩展到多团队马尔科夫游戏的模型基础和模型无关场景下。通过最优耦合引理和随机微分包含逼近方法解决了由对手策略演变导致的非平稳性问题。实验结果对比了Team-FP与其他广泛研究的动力学如平滑虚构玩法和乘法权重更新的性能，并探讨了不同参数对收敛速度的影响。这项工作为使用团队纳什均衡预测分布式团队行为奠定了更坚实的基础，并提供了一种在多团队环境中实现团队学习的实用规则。 <div>
arXiv:2402.02147v2 Announce Type: replace 
Abstract: Multi-team games, prevalent in robotics and resource management, involve team members striving for a joint best response against other teams. Team-Nash equilibrium (TNE) predicts the outcomes of such coordinated interactions. However, can teams of self-interested agents reach TNE? We introduce Team-Fictitious Play (Team-FP), a new variant of fictitious play where agents respond to the last actions of team members and the beliefs formed about other teams with some inertia in action updates. This design is essential in team coordination beyond the classical fictitious play dynamics. We focus on zero-sum potential team games (ZSPTGs) where teams can interact pairwise while the team members do not necessarily have identical payoffs. We show that Team-FP reaches near TNE in ZSPTGs with a quantifiable error bound. We extend Team-FP dynamics to multi-team Markov games for model-based and model-free cases. The convergence analysis tackles the challenge of non-stationarity induced by evolving opponent strategies based on the optimal coupling lemma and stochastic differential inclusion approximation methods. Our work strengthens the foundation for using TNE to predict the behavior of decentralized teams and offers a practical rule for team learning in multi-team environments. We provide extensive simulations of Team-FP dynamics and compare its performance with other widely studied dynamics such as smooth fictitious play and multiplicative weights update. We further explore how different parameters impact the speed of convergence.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Continuous-Time Best-Response and Related Dynamics in Tullock Contests with Convex Costs</title>
<link>https://arxiv.org/abs/2402.08541</link>
<guid>https://arxiv.org/abs/2402.08541</guid>
<content:encoded><![CDATA[
<div> 关键词：Tullock contests, 最优响应动态, 连续时间, 数值算法, 离散时间动态

总结:
本文研究了Tullock竞赛模型，该模型应用于描述从工作量证明区块链矿工竞争到寻租和游说活动等多种现实场景。文章使用Lyapunov风格的论证方法，证明了在具有凸成本的Tullock竞赛中，连续时间的最佳响应动态收敛于唯一均衡。基于这一结果，作者提出了一种计算近似均衡的算法。此外，文中还证明了当代理人对其他代理人平均行为的离散时间动态进行最优响应时也会收敛。这些结果表明，在这类游戏中，均衡是一个可以可靠预测代理人行为的工具。<br /><br /> <div>
arXiv:2402.08541v2 Announce Type: replace 
Abstract: Tullock contests model real-life scenarios that range from competition among proof-of-work blockchain miners to rent-seeking and lobbying activities. We show that continuous-time best-response dynamics in Tullock contests with convex costs converges to the unique equilibrium using Lyapunov-style arguments. We then use this result to provide an algorithm for computing an approximate equilibrium. We also establish convergence of related discrete-time dynamics, e.g., when the agents best-respond to the empirical average action of other agents. These results indicate that the equilibrium is a reliable predictor of the agents' behavior in these games.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unleashing Multicore Strength for Efficient Execution of Transactions</title>
<link>https://arxiv.org/abs/2410.22460</link>
<guid>https://arxiv.org/abs/2410.22460</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、智能合约交易、并行处理、Multi-Bin 并行调度器、性能提升

总结:<br />
本文介绍了针对区块链智能合约交易性能瓶颈问题提出的一种新型框架——Multi-Bin 并行调度器(MBPS)。该框架设计用于利用多核系统的并行计算能力，实现区块链智能合约交易的并发执行，确保非冲突交易可同时处理，同时维持确定性的事务顺序。MBPS框架包括冲突检测、分区创建和执行三个关键阶段。文章通过在Hyperledger Sawtooth v1.2.6上的评估实验，展示了MBPS框架相比于现有并行智能合约交易执行框架在各种智能合约应用中的显著性能提升。这项研究为区块链技术的持续优化做出了贡献，证明了其在现实世界场景中具有可扩展性和效率潜力。 <div>
arXiv:2410.22460v1 Announce Type: new 
Abstract: Blockchain technology is booming up the digital world in recent days and thus paved a way for creating separate blockchain network for various industries. This technology is characterized by its distributed, decentralized, and immutable ledger system which serves as a fundamental platform for managing smart contract transactions (SCTs). However, these self-executing codes implemented using blockchains undergo sequential validation within a block which introduces performance bottlenecks. In response, this paper introduces a framework called the Multi-Bin Parallel Scheduler (MBPS) designed for parallelizing blockchain smart contract transactions to leverage the capabilities of multicore systems. Our proposed framework facilitates concurrent execution of SCTs, enhancing performance by allowing non-conflicting transactions to be processed simultaneously while preserving deterministic order. The framework comprises of three vital stages: conflict detection, bin creation and execution. We conducted an evaluation of our MBPS framework in Hyperledger Sawtooth v1.2.6, revealing substantial performance enhancements compared to existing parallel SCT execution frameworks across various smart contract applications. This research contributes to the ongoing optimization efforts in blockchain technology demonstrating its potential for scalability and efficiency in real-world scenarios.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Evolution Of The Digital Inheritance: Legal, Technical, And Practical Dimensions Of Cryptocurrency Transfer Through Succession In French-Inspired Legal Systems</title>
<link>https://arxiv.org/abs/2410.22907</link>
<guid>https://arxiv.org/abs/2410.22907</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptocurrencies, blockchain technology, virtual wallets, cryptographic keys, inheritance planning

总结:<br />
本文探讨了近年来愈发流行的加密货币领域，重点关注了区块链技术、虚拟钱包和密钥等数字货币传输的技术方面以及各类加密货币操作。文章同时分析了加密货币相关的法律问题，特别是全球不同司法管辖区对其的不同法律地位以及对继承规划的影响。通过案例研究，文中展示了以加密货币为主要财产的继承过程中所面临的实际挑战。因此，本文提出了涉及加密货币继承规划的一些可能解决方案和建议，包括需要考虑的法律和税务因素，旨在为数字遗产规划提供指导。 <div>
arXiv:2410.22907v1 Announce Type: new 
Abstract: In recent years, cryptocurrencies have enjoyed increased popularity in all domains. Thus, in this context, it is important to understand how these digital assets can be transmitted, both legally and efficiently, in the event of the death of their owner. The present paper analyses the mechanisms of cryptocurrencies, analysing from a technical point of view aspects related to blockchain technology, virtual wallets or cryptographic keys, as well as various types of operations regarding this type of virtual currencies. The study also examines the legal aspects related to cryptocurrencies, with an emphasis on the diversity of their status in different global jurisdictions as well as the impact on inheritance planning. The case studies present tangible examples related to successions with cryptocurrencies as the main object, thus completing the exposition related to the main challenges faced by the heirs in the transfer process. In this way, this paper offers possible solutions and recommendations related to inheritance planning with cryptocurrencies as its main object, including the legal and fiscal aspects that must be taken into account when planning a digital succession.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy-Efficient Intra-Domain Network Slicing for Multi-Layer Orchestration in Intelligent-Driven Distributed 6G Networks: Learning Generic Assignment Skills with Unsupervised Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.23161</link>
<guid>https://arxiv.org/abs/2410.23161</guid>
<content:encoded><![CDATA[
<div> 关键词：6G网络、去中心化、多层系统模型、能源效率自动化策略、边缘域管理、网络切片、无监督强化学习、预训练阶段、资源分配

<br /><br />总结:
本文研究了针对6G无线网络的去中心化和多级系统模型，提出了一种基于无监督强化学习的能源效率自动化策略，用于管理和优化边缘域以及网络切片。该策略旨在通过利用可扩展性、效率和泛化能力来降低网络复杂度。文章提出在预训练阶段利用无监督RL发现网络边缘域中的有效资源配置技能，且此方法不受领域规格限制，适用于所有边缘域。实验结果显示，所发现的分配技能涵盖了为各种服务类型进行资源配置的完整范围。 <div>
arXiv:2410.23161v1 Announce Type: new 
Abstract: Since the 6th Generation (6G) of wireless networks is expected to provide a new level of network services and meet the emerging expectations of the future, it will be a complex and intricate networking system. 6Gs sophistication and robustness will be accompanied by complexities, which will require novel strategies to tackle them. This research work focuses on decentralized and multi-level system models for 6G networks and proposes an energy efficient automation strategy for edge domain management and Network Slicing (NS) with the main objective of reducing the networks complexity by leveraging scalability, efficiency, and generalization. Accordingly, we propose a pre-train phase to discover useful assignment skills in network edge domains by utilizing unsupervised Reinforcement Learning (unsupervised RL). The suggested technique does not depend on the domain specifications and thus is applicable to all the edge domains. Our proposed approach not only enables scalability and decentralization, but it also delivers efficiency by assisting domain controllers to provide various service types. We implemented the pre-training phase, and monitored that the discovered assignment skills span the entire interval of possible resource assignment portions for every service type.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics</title>
<link>https://arxiv.org/abs/2406.14558</link>
<guid>https://arxiv.org/abs/2406.14558</guid>
<content:encoded><![CDATA[
<div> 关键词: 人形机器人, 多人协作, 对象运输, 合作人类-物体交互(CooHOI), 中心化训练去中心化执行(CTDE)

总结:
本文提出了一个名为合作人类-物体交互(CooHOI)的框架，旨在解决多个人形机器人协同搬运物体的问题。该框架采用两阶段学习方法：首先，单个人形机器人通过模仿人类运动先验数据来学会与物体互动；其次，借助中心化训练和去中心化执行(CTDE)的多智能体强化学习算法，人形机器人学习与其他机器人协作，考虑操纵对象的共享动力学特性。当一个机器人与物体交互导致物体动态变化时，其他机器人会学习做出适当响应，从而实现团队间的隐性通信和协调。与依赖多人协作人体动作捕捉数据的方法不同，CooHOI框架效率高、不依赖于多人人形交互的动作捕捉数据，并可以方便地扩展到更多参与者和多种类型的物体。 <div>
arXiv:2406.14558v3 Announce Type: replace 
Abstract: Enabling humanoid robots to clean rooms has long been a pursued dream within humanoid research communities. However, many tasks require multi-humanoid collaboration, such as carrying large and heavy furniture together. Given the scarcity of motion capture data on multi-humanoid collaboration and the efficiency challenges associated with multi-agent learning, these tasks cannot be straightforwardly addressed using training paradigms designed for single-agent scenarios. In this paper, we introduce Cooperative Human-Object Interaction (CooHOI), a framework designed to tackle the challenge of multi-humanoid object transportation problem through a two-phase learning paradigm: individual skill learning and subsequent policy transfer. First, a single humanoid character learns to interact with objects through imitation learning from human motion priors. Then, the humanoid learns to collaborate with others by considering the shared dynamics of the manipulated object using centralized training and decentralized execution (CTDE) multi-agent RL algorithms. When one agent interacts with the object, resulting in specific object dynamics changes, the other agents learn to respond appropriately, thereby achieving implicit communication and coordination between teammates. Unlike previous approaches that relied on tracking-based methods for multi-humanoid HOI, CooHOI is inherently efficient, does not depend on motion capture data of multi-humanoid interactions, and can be seamlessly extended to include more participants and a wide range of object types.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US</title>
<link>https://arxiv.org/abs/2410.21279</link>
<guid>https://arxiv.org/abs/2410.21279</guid>
<content:encoded><![CDATA[
<div> 关键词: AI监管、欧盟、中国、美国、加州参议院法案1047

<br />
总结:
本文探讨了AI作为一种具有巨大利益和潜在风险的双重用途技术，世界各国对其采取的不同监管法律和政策。文章对比分析了欧盟、中国以及美国（包括联邦与加州参议院法案1047）在AI监管方面的三种不同做法。这些监管体系各自体现了独特的文化、政治和经济视角，对于安全与创新、合作与竞争之间的风险收益权衡有不同判断。此外，不同的监管框架也反映出对集中式权威与分散化自由市场竞争之间信任度的不同立场。这些多元化的AI创新与监管方式相互影响，对更广泛的国际社会以及未来AI监管的走向产生深远影响。 <div>
arXiv:2410.21279v1 Announce Type: new 
Abstract: As a powerful and rapidly advancing dual-use technology, AI offers both immense benefits and worrisome risks. In response, governing bodies around the world are developing a range of regulatory AI laws and policies. This paper compares three distinct approaches taken by the EU, China and the US. Within the US, we explore AI regulation at both the federal and state level, with a focus on California's pending Senate Bill 1047. Each regulatory system reflects distinct cultural, political and economic perspectives. Each also highlights differing regional perspectives on regulatory risk-benefit tradeoffs, with divergent judgments on the balance between safety versus innovation and cooperation versus competition. Finally, differences between regulatory frameworks reflect contrastive stances in regards to trust in centralized authority versus trust in a more decentralized free market of self-interested stakeholders. Taken together, these varied approaches to AI innovation and regulation influence each other, the broader international community, and the future of AI regulation.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments</title>
<link>https://arxiv.org/abs/2410.21340</link>
<guid>https://arxiv.org/abs/2410.21340</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模模型、分布式系统、推理加速、元学习、效率性能

总结:
本文介绍了针对大规模模型（如大型语言模型和图像生成系统）在分布式系统中部署所面临的计算资源消耗问题，提出了一种基于元学习的推理加速优化框架。该框架通过学习不同任务下各种加速技术的历史表现数据，自动化地选择最适宜的加速策略，从而有效管理计算资源并提升系统响应速度。与依赖随机选择或专家直觉的传统方法相比，该元学习框架能够根据具体任务特征系统性地确定最优加速策略，并在实验中表现出在效率和性能上的持续优越性。这一成果突显了元学习在分布式AI系统中推理加速领域的革命性潜力，为实现更加民主化和经济高效的AI解决方案提供了新的路径。 <div>
arXiv:2410.21340v1 Announce Type: new 
Abstract: The deployment of large-scale models, such as large language models (LLMs) and sophisticated image generation systems, incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for deploying such models. In these decentralized environments, efficient inference acceleration becomes crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of meta-learning to revolutionize inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improving DeFi Mechanisms with Dynamic Games and Optimal Control: A Case Study in Stablecoins</title>
<link>https://arxiv.org/abs/2410.21446</link>
<guid>https://arxiv.org/abs/2410.21446</guid>
<content:encoded><![CDATA[
<div> 关键词: 稳定币、去中心化、算法机制、控制策略、Stackelberg博弈

总结:
<br />
本文探讨了稳定币的设计挑战，并重点介绍了以真实资产为依托、采用算法管理风险的去中心化稳定币。文章提出了基于Stackelberg博弈的新控制策略，相较于现有的固定赎回方案（如MakerDao的DAI）和适应性赎回方案（如Reflexer的RAI），该策略能更好地缓解不利的脱钩事件并更有效地维持目标市场价格。通过模拟多种市场条件下的实证分析，文章证实了新策略的优势。 <div>
arXiv:2410.21446v1 Announce Type: new 
Abstract: Stablecoins are a class of cryptocurrencies which aim at providing consistency and predictability, typically by pegging the token's value to that of a real world asset. Designing resilient decentralized stablecoins is a challenge, and prominent stablecoins today either (i) give up on decentralization, or (ii) rely on user-owned cryptocurrencies as collateral, exposing the token to exogenous price fluctuations. In this latter category, it is increasingly common to employ algorithmic mechanisms to automate risk management, helping maintain the peg. One example of this is Reflexer's RAI, which adapts its system-internal exchange rate (redemption price) to secondary market conditions according to a proportional control law. In this paper, we take this idea of active management a step further, and introduce a new kind of control scheme based on a Stackelberg game model between the token protocol and its users. By doing so, we show that (i) we can mitigate adverse depeg events that inevitably arise in a fixed-redemption scheme such as MakerDao's DAI and (ii) generally outperform a simpler, adaptive-redemption scheme such as RAI in the task of targeting a desired market price. We demonstrate these results through extensive simulations over a range of market conditions.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent Environmental Empathy (IEE): A new power and platform to fostering green obligation for climate peace and justice</title>
<link>https://arxiv.org/abs/2410.21536</link>
<guid>https://arxiv.org/abs/2410.21536</guid>
<content:encoded><![CDATA[
<div> 关键词：Intelligent Environmental Empathy (IEE)，气候和平与正义，人工智能，环境共情，气候变化

总结:
本文提出了一种新的动力驱动——智能环境共情(IEE)，用于推动气候和平与正义，这在大数据时代是一个新兴议题。首先，文章指出传统的自上而下的权威性政府间合作，如通过国际组织（例如联合国环境规划署）来实现气候正义，迄今为止并未能成功解决环境问题和裂痕。作者详细阐述了气候不公正的四个根源，并解释全球范围内缺乏共情和环保意识是此类合作失败的原因。为解决这些问题，文章提倡采用自下而上的新方法应对气候和平与正义。其次，聚焦于人工智能、环境共情和气候正义的交叉点，文章提出了一个操作层面的智能环境共情(IEE)模型，该模型借助环境共情的力量作为推动绿色义务以实现气候正义的动力，并利用潜在的去中心化AI平台作为一种对抗搭便车行为的操作系统。IEE首先影响公民及部分中层决策者，如城市规划师和地方行政官员，并最终将波及全球决策者。 <div>
arXiv:2410.21536v1 Announce Type: new 
Abstract: In this paper, we propose Intelligent Environmental Empathy (IEE) as a new driver for climate peace and justice, as an emerging issue in the age of big data. We first show that the authoritarian top-down intergovernmental cooperation, through international organizations (e.g., UNEP) for climate justice, could not overcome environmental issues and crevices so far. We elaborate on four grounds of climate injustice (i.e., teleological origin, axiological origin, formation cause, and social epistemic cause), and explain how the lack of empathy and environmental motivation on a global scale causes the failure of all the authoritarian top-down intergovernmental cooperation. Addressing all these issues requires a new button-up approach to climate peace and justice. Secondly, focusing on the intersection of AI, environmental empathy, and climate justice, we propose a model of Intelligent Environmental Empathy (IEE) for climate peace and justice at the operational level. IEE is empowered by the new power of environmental empathy (as a driver of green obligation for climate justice) and putative decentralized platform of AI (as an operative system against free riders), which Initially, impact citizens and some middle-class decision makers, such as city planners and local administrators, but will eventually affect global decision-makers as well.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid-DAOs: Enhancing Governance, Scalability, and Compliance in Decentralized Systems</title>
<link>https://arxiv.org/abs/2410.21593</link>
<guid>https://arxiv.org/abs/2410.21593</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Autonomous Organizations (DAOs)，Hybrid-DAOs，Sybil attacks，Voting mechanisms，Legal challenges

<br /><br />总结:
本文探讨了基于区块链系统的去中心化自治组织（DAOs）及其面临的可扩展性、治理和合规性挑战。为解决这些问题，提出了结合传统法律框架的混合型DAOs（Hybrid-DAOs）。文章重点关注DAOs的投票机制及其对Sybil攻击的脆弱性，而Hybrid-DAOs为此提供了更为稳健的解决方案，确保更公平的投票方式。同时，文中阐述了DAOs的四个关键属性——匿名性、透明度、问责制和公平性，并分析了它们对DAOs的影响。此外，文章还讨论了Hybrid-DAOs所面临的法律挑战以及其在非营利管理、公司治理和初创企业融资等领域的潜在应用。最后，作者认为Hybrid-DAOs代表着DAOs的未来，因其额外的法律结构增强了其实用性，并为DAOs面临的诸多技术问题提供了创新解决方案。 <div>
arXiv:2410.21593v1 Announce Type: new 
Abstract: Decentralized Autonomous Organizations (DAOs), based on block-chain systems such as Ethereum, are emerging governance protocols that enable decentralized community management without a central authority. For instance, UniswapDAO allows members to vote on policy changes for the Uniswap exchange. However, DAOs face challenges regarding scalability, governance, and compliance. Hybrid-DAOs, which combine the decentralized nature of DAOs with traditional legal frameworks, provide solutions to these issues. This research explores various aspects of DAOs, including their voting mechanisms, which, while ensuring fairness, are susceptible to Sybil attacks, where a user can create multiple accounts to exploit the system. Hybrid-DAOs offer robust solutions to these attacks, enabling more equitable voting methods. Moreover, decentralization can be understood through four properties: anonymity, transparency, accountability, and fairness, each with distinct implications for DAOs. Lastly, this work discusses legal challenges Hybrid-DAOs face and their promising applications across sectors such as nonprofit management, corporate governance, and startup funding. Overall, we argue that Hybrid-DAOs are the future of DAOs: the additional legal structure enhances the feasibility of many applications, and they offer innovative solutions to technical problems that plague DAOs.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BF-Meta: Secure Blockchain-enhanced Privacy-preserving Federated Learning for Metaverse</title>
<link>https://arxiv.org/abs/2410.21675</link>
<guid>https://arxiv.org/abs/2410.21675</guid>
<content:encoded><![CDATA[
<div> 关键词: 元宇宙、可穿戴设备、联邦学习、区块链、激励机制

总结:
本文提出了一种名为BF-Meta的安全区块链驱动的联邦学习框架，用于在元宇宙中保护用户隐私并提供智能服务。该框架针对元宇宙中由单一中心化模型聚合可能面临的外部攻击和参与度不足的问题，采用去中心化的模型聚合方法，以降低恶意用户的影响，确保虚拟服务的安全性。此外，BF-Meta还设计了一种激励机制，根据用户在训练过程中的行为给予反馈，从而提高用户的参与积极性，进而提升训练模型的性能和服务质量。实验结果显示BF-Meta在五个数据集上均表现出有效性和适用性。<br /><br /> <div>
arXiv:2410.21675v1 Announce Type: new 
Abstract: The metaverse, emerging as a revolutionary platform for social and economic activities, provides various virtual services while posing security and privacy challenges. Wearable devices serve as bridges between the real world and the metaverse. To provide intelligent services without revealing users' privacy in the metaverse, leveraging federated learning (FL) to train models on local wearable devices is a promising solution. However, centralized model aggregation in traditional FL may suffer from external attacks, resulting in a single point of failure. Furthermore, the absence of incentive mechanisms may weaken users' participation during FL training, leading to degraded performance of the trained model and reduced quality of intelligent services. In this paper, we propose BF-Meta, a secure blockchain-empowered FL framework with decentralized model aggregation, to mitigate the negative influence of malicious users and provide secure virtual services in the metaverse. In addition, we design an incentive mechanism to give feedback to users based on their behaviors. Experiments conducted on five datasets demonstrate the effectiveness and applicability of BF-Meta.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Impact of Code Transformation on Detection of Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2410.21685</link>
<guid>https://arxiv.org/abs/2410.21685</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、安全漏洞、训练数据集、代码转换、检测工具

总结:
这篇论文关注了智能合约的安全漏洞问题以及现有检测工具的有效性。为提升用于漏洞检测工具训练数据集的质量和数量，该论文提出了一种基于语义保持的代码变换方法，这种方法可以修改源代码结构而不改变其语义含义。通过将变换后的代码片段插入到良性智能合约代码的所有潜在位置，生成新的含有漏洞的合同版本，旨在创造更多样化的漏洞代码样本，包括那些可能绕过当前分析工具检测的漏洞。实验结果显示，该方法有效提升了新生成漏洞样本的数量，并揭示了Slither、Mythril和CrossFuzz等工具在检测这些新漏洞时存在较高的假阴性率（最高达到100%），同时至少使数据集规模增加了2.5倍。 <div>
arXiv:2410.21685v1 Announce Type: new 
Abstract: While smart contracts are foundational elements of blockchain applications, their inherent susceptibility to security vulnerabilities poses a significant challenge. Existing training datasets employed for vulnerability detection tools may be limited, potentially compromising their efficacy. This paper presents a method for improving the quantity and quality of smart contract vulnerability datasets and evaluates current detection methods. The approach centers around semantic-preserving code transformation, a technique that modifies the source code structure without altering its semantic meaning. The transformed code snippets are inserted into all potential locations within benign smart contract code, creating new vulnerable contract versions. This method aims to generate a wider variety of vulnerable codes, including those that can bypass detection by current analysis tools. The paper experiments evaluate the method's effectiveness using tools like Slither, Mythril, and CrossFuzz, focusing on metrics like the number of generated vulnerable samples and the false negative rate in detecting these vulnerabilities. The improved results show that many newly created vulnerabilities can bypass tools and the false reporting rate goes up to 100% and increases dataset size minimum by 2.5X.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A New Broadcast Primitive for BFT Protocols</title>
<link>https://arxiv.org/abs/2410.22080</link>
<guid>https://arxiv.org/abs/2410.22080</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine故障容错(BFT)协议、最佳努力广播、可靠广播、abortable广播、区块链网络IPC

总结:
本文提出了一个新的弱化网络原语——abortable广播，它用于替代BFT协议中常见的过于强大的应用层网络原语假设。Abortable广播在面对网络拥塞、链路或节点失败及背压情况时，仍能提供强交付保证，同时保持带宽效率并确保即使存在恶意节点，所有数据结构也保持可界性，防止内存耗尽型DoS攻击，这是文献中经常被忽视的问题。文中给出了abortable广播的实现方法，并将其应用于公开可用的区块链网络IPC（InProductionChain）中，该网络支持大量应用程序及其用户的通用计算副本执行。 <div>
arXiv:2410.22080v1 Announce Type: new 
Abstract: Byzantine fault tolerant (BFT) protocol descriptions often assume application-layer networking primitives, such as best-effort and reliable broadcast, which are impossible to implement in practice in a Byzantine environment as they require either unbounded buffering of messages or giving up liveness, under certain circumstances. However, many of these protocols do not (or can be modified to not) need such strong networking primitives. In this paper, we define a new, slightly weaker networking primitive that we call abortable broadcast. We describe an implementation of this new primitive and show that it (1) still provides strong delivery guarantees, even in the case of network congestion, link or peer failure, and backpressure, (2) preserves bandwidth, and (3) enforces all data structures to be bounded even in the presence of malicious peers. The latter prevents out-of-memory DoS attacks by malicious peers, an issue often overlooked in the literature. The new primitive and its implementation are not just theoretical. We use them to implement the BFT protocols in the IPC (InProductionChain), a publicly available blockchain network that enables replicated execution of general-purpose computation, serving hundreds of thousands of applications and their users.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MStableChain: Towards Multi-Native Stablecoins in EVM-Compatible Blockchain for Stable Fee and Mass Adoption</title>
<link>https://arxiv.org/abs/2410.22100</link>
<guid>https://arxiv.org/abs/2410.22100</guid>
<content:encoded><![CDATA[
<div> 关键词: MStableChain、区块链、稳定币、交易费用、EVM

总结:
MStableChain是一个为解决传统区块链系统（如以太坊）依赖单一波动性加密货币作为交易费用问题而提出的新型方案。该系统利用多种稳定币作为原生代币进行交易费用结算，从而确保稳定的交易费用和灵活的支付选择。为了实现广泛采用和实用性，MStableChain设计了多货币单位、多类型RPCs机制，能够在不改变EVM或用户应用程序的情况下处理多种稳定币。此外，通过基于预言机的 Gas 费调整机制，MStableChain能够公平地管理不同稳定币之间的汇率，确保各种货币的交易成本均衡。系统还引入了一个安全的、链上投票为基础的管理协议，用于处理与这些稳定币相关的行政功能。原型实施的实验结果表明，MStableChain实现了稳定的交易费用价格、高效率和良好的易用性。 <div>
arXiv:2410.22100v1 Announce Type: new 
Abstract: Traditional blockchain systems, such as Ethereum, typically rely on a \emph{single volatile cryptocurrency for transaction fees}. This leads to fluctuating transaction fee prices and limits the flexibility of users' payment options. To address these issues, we propose MStableChain, which leverage multiple stablecoins as native tokens for transaction fee settlements, thus ensuring stable transaction fees and flexible payment options. To address the challenges of mass adoption and practicality, we propose several core designs. To maintain compatibility with the Ethereum Virtual Machine (EVM) for mass adoption while supporting multiple native stablecoins, MStableChain employs a multi-currency units, multi-type RPCs mechanism. This mechanism enables the system to handle multiple stablecoins without altering the EVM or requiring changes to user applications. Furthermore, an oracle-based gas fee adjustment mechanism is proposed to manage exchange rates between different stablecoins, ensuring equitable transaction costs across various currencies. The system also introduces a secure, on-chain voting-based management protocol for the administrative functions related to these stablecoins. Experimental results from a prototype implementation demonstrate that MStableChain provides stable transaction fee prices, high effectiveness, and good usability.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal Multilevel Slashing for Blockchains</title>
<link>https://arxiv.org/abs/2405.08135</link>
<guid>https://arxiv.org/abs/2405.08135</guid>
<content:encoded><![CDATA[
<div> 关键词: 多级削减、权益证明区块链、全局共识、消息复杂度、验证者负载

<br />
总结:
本文提出了多级削减的概念，这是一种权益证明区块链的机制，使得验证者可以逐步获得某一区块将在全球共识过程中最终确定的确保程度，除非有越来越多的拜占庭节点因错误行为被扣除质押资产。该机制基于有限项目空间的组合交集系统进行高度参数化的泛化设计，具有渐近高可用性和最优削减性质。即使在弱条件下，也能展示出在消息复杂度和验证者负载方面具有的渐近最优削减性质，并揭示了其中的消息复杂度、负载与削减之间的基本权衡关系。此外，文章还表明，任何其基础元素为节点的互不相交子集（如委员会制共识协议中的“委员会”）的交集系统，在同样弱的条件下具有渐近高可用性。最后，通过多级构造方式，区块链验证者可以根据需要决定获取多少级别的最终确认保障，这既可视为一种基于削减的早期块最终确认形式，也可作为一种支持重组容错的服务。 <div>
arXiv:2405.08135v2 Announce Type: replace 
Abstract: We present the notion of multilevel slashing, where proof-of-stake blockchain validators can obtain gradual levels of assurance that a certain block is bound to be finalized in a global consensus procedure, unless an increasing and optimally large number of Byzantine processes have their staked assets slashed -- that is, deducted -- due to provably incorrect behavior. Our construction is a highly parameterized generalization of combinatorial intersection systems based on finite projective spaces, with asymptotic high availability and optimal slashing properties. Even under weak conditions, we show that our construction has asymptotically optimal slashing properties with respect to message complexity and validator load; this result also illustrates a fundamental trade off between message complexity, load, and slashing. In addition, we show that any intersection system whose ground elements are disjoint subsets of nodes (e.g. "committees" in committee-based consensus protocols) has asymptotic high availability under similarly weak conditions. Finally, our multilevel construction gives the flexibility to blockchain validators to decide how many "levels" of finalization assurance they wish to obtain. This functionality can be seen either as (i) a form of an early, slashing-based block finalization; or (ii) a service to support reorg tolerance.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Progress in Web3 Grants: Introducing the Grant Maturity Index</title>
<link>https://arxiv.org/abs/2410.19828</link>
<guid>https://arxiv.org/abs/2410.19828</guid>
<content:encoded><![CDATA[
<div> 关键词: Grant Maturity Index (GMI), Web3, grant programs, decentralization, Ethereum Layer 2

总结:<br />
本文介绍了Grant Maturity Index（GMI），这是一个用于评估Web3赠款项目成熟度和运行效率的新颖评价框架。随着Web3的发展，其去中心化特性为这类项目的治理、透明度和社区参与带来了机遇与挑战。由于Web3赠款缺乏传统资金模式那样的标准化流程，因此难以衡量其长期成功。GMI借鉴了世界银行的GovTech Maturity Index（GTMI），并针对Web3生态系统进行了定制，涵盖了项目治理、透明度、运营效率和社区参与等关键维度的评估。该研究的主要目标是确定描述Web3赠款项目结构的指标以及通过评估其在关键操作领域的成熟度来描述项目理想状态。通过对Arbitrum、Mantle、Taiko Labs和Optimism四个主要的以太坊Layer 2赠款项目的案例研究，指出了Web3赠款项目在流程标准化、提高透明度和增强社区参与方面需要改进的地方。 <div>
arXiv:2410.19828v1 Announce Type: new 
Abstract: This report introduces the Grant Maturity Index (GMI), a novel evaluative framework designed to assess the maturity and operational effectiveness of Web3 grant programs. As Web3 continues to develop, the decentralized nature of these programs brings both opportunities and challenges, particularly when it comes to governance, transparency, and community engagement. Traditional funding models are often governed by standardized processes, but Web3 grants lack such consistency, making it difficult for grant operators to measure the long-term success of their programs.The Grant Maturity Index (GMI) was created through exploratory applied research to address this gap. Inspired by the World Bank's GovTech Maturity Index (GTMI), the GMI is tailored specifically for the decentralized Web3 ecosystem. The GMI evaluates key dimensions of grant programs governance, transparency, operational efficiency, and community engagement, providing grant operators with a clear benchmark for assessing and improving their programs. The primary objectives of this research are to, first, identify the structural indicators that adequately describe Web3 grant programs. Second, to describe optimal outcomes for programs by evaluating their maturity across key operational areas. The GMI is applied to four major Ethereum Layer 2 grant programs, namely Arbitrum, Mantle, Taiko Labs, and Optimism. These case studies highlight areas where Web3 grant programs require improvement, particularly in standardizing processes, enhancing transparency, and increasing community participation.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Almost Sure Convergence of Networked Policy Gradient over Time-Varying Networks in Markov Potential Games</title>
<link>https://arxiv.org/abs/2410.20075</link>
<guid>https://arxiv.org/abs/2410.20075</guid>
<content:encoded><![CDATA[
<div> 关键词：网络化策略梯度、Markov潜力游戏、连续动作空间、分布式算法、收敛性证明

总结:
我们提出了一种用于解决包括连续动作和状态空间在内的Markov潜力游戏的网络化策略梯度玩法。在这个去中心化的算法中，代理们根据当前状态和其他代理的策略参数从参数化且可微分的策略中采样其行动。训练过程中，代理通过两个连续的episode估计其梯度信息，生成奖励和政策得分函数的无偏估计器。利用这些信息，代理计算其政策函数的随机梯度并相应地更新其参数。同时，他们依据通过随时间变化的通信网络接收到的局部估计值来更新对其他代理策略参数的估计。在Markov潜力游戏中，存在一个潜在价值函数，其梯度对应于各代理局部价值函数的梯度。利用这一结构，我们证明了联合策略参数几乎必然收敛到潜在价值函数的不动点。此外，我们还表明网络化策略梯度算法的收敛率为$\mathcal{O}(1/\epsilon^2)$。数值实验在一个动态多代理报童问题上验证了局部信念和梯度的收敛性，并显示网络化策略梯度玩法能与独立策略梯度更新一样快速收敛，同时还能收集更高的奖励。 <div>
arXiv:2410.20075v1 Announce Type: new 
Abstract: We propose networked policy gradient play for solving Markov potential games including continuous action and state spaces. In the decentralized algorithm, agents sample their actions from parametrized and differentiable policies that depend on the current state and other agents' policy parameters. During training, agents estimate their gradient information through two consecutive episodes, generating unbiased estimators of reward and policy score functions. Using this information, agents compute the stochastic gradients of their policy functions and update their parameters accordingly. Additionally, they update their estimates of other agents' policy parameters based on the local estimates received through a time-varying communication network. In Markov potential games, there exists a potential value function among agents with gradients corresponding to the gradients of local value functions. Using this structure, we prove the almost sure convergence of joint policy parameters to stationary points of the potential value function. We also show that the convergence rate of the networked policy gradient algorithm is $\mathcal{O}(1/\epsilon^2)$. Numerical experiments on a dynamic multi-agent newsvendor problem verify the convergence of local beliefs and gradients. It further shows that networked policy gradient play converges as fast as independent policy gradient updates, while collecting higher rewards.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedSSP: Federated Graph Learning with Spectral Knowledge and Personalized Preference</title>
<link>https://arxiv.org/abs/2410.20105</link>
<guid>https://arxiv.org/abs/2410.20105</guid>
<content:encoded><![CDATA[
<div> 关键词: Personalized Federated Graph Learning (pFGL), Graph Neural Networks (GNNs), 结构异质性, 共享谱知识, 个性化偏好模块

<br /><br />总结:

本文提出了一个针对个性化联邦图学习(pFGL)的新方法，旨在解决跨域场景中结构异质性带来的挑战。现有的pFGL方法在全球范围内错误地共享非通用知识，无法针对领域结构性变化提供本地化的个性化解决方案。为此，文章创新性地揭示了图的谱性质可以很好地反映内在的域结构变化，并提出通过分享通用谱知识来克服这一问题。同时，文章指出了图结构上存在偏见的消息传递方案，并设计了个性化偏好模块。结合这两种策略，作者提出了FedSSP框架——一个既能共享通用谱知识又能满足图结构偏好的pFGL框架。实验结果在跨数据集和跨域设置下验证了该框架的优越性。代码已开源，可在https://github.com/OakleyTan/FedSSP获取。 <div>
arXiv:2410.20105v1 Announce Type: new 
Abstract: Personalized Federated Graph Learning (pFGL) facilitates the decentralized training of Graph Neural Networks (GNNs) without compromising privacy while accommodating personalized requirements for non-IID participants. In cross-domain scenarios, structural heterogeneity poses significant challenges for pFGL. Nevertheless, previous pFGL methods incorrectly share non-generic knowledge globally and fail to tailor personalized solutions locally under domain structural shift. We innovatively reveal that the spectral nature of graphs can well reflect inherent domain structural shifts. Correspondingly, our method overcomes it by sharing generic spectral knowledge. Moreover, we indicate the biased message-passing schemes for graph structures and propose the personalized preference module. Combining both strategies, we propose our pFGL framework FedSSP which Shares generic Spectral knowledge while satisfying graph Preferences. Furthermore, We perform extensive experiments on cross-dataset and cross-domain settings to demonstrate the superiority of our framework. The code is available at https://github.com/OakleyTan/FedSSP.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Digital Twin-based Intelligent Network Architecture for Underwater Acoustic Sensor Networks</title>
<link>https://arxiv.org/abs/2410.20151</link>
<guid>https://arxiv.org/abs/2410.20151</guid>
<content:encoded><![CDATA[
<div> 关键词: 水下声学传感器网络、数字孪生、网络架构、资源分配、多智能体强化学习

总结:<br />
本文提出了一种基于数字孪生技术的水下声学传感器网络架构（DTNA），旨在提升UASNs对环境的适应性、智能化和多功能性。DTNA通过从局部节点和全局网络层面提取信息，设计了分层架构以提高数字孪生副本的精确度及网络控制灵活性。在局部数字孪生中，研究了一种资源分配范式（RAPD），能快速感知性能变化并迭代优化分配策略，从而提升资源分配算法的实时环境适应性。在全球数字孪生中，采用协作多智能体强化学习框架（CMFD）汇聚去中心化的局部DT数据，加速AI模型训练；同时提出了任务导向的网络切片方法（TNSD），统一处理异构任务需求提取，有效提供全面网络状态信息，增强多任务调度算法的灵活性。实验结果验证了DT的高度保真性，并表明与原有UASN架构相比，DTNA能够：(i) 提升资源分配的及时性和鲁棒性；(ii) 大幅缩短AI算法的训练时间；(iii) 低成本地更快速获取用于多任务调度的网络状态。 <div>
arXiv:2410.20151v1 Announce Type: new 
Abstract: Underwater acoustic sensor networks (UASNs) drive toward strong environmental adaptability, intelligence, and multifunctionality. However, due to unique UASN characteristics, such as long propagation delay, dynamic channel quality, and high attenuation, existing studies present untimeliness, inefficiency, and inflexibility in real practice. Digital twin (DT) technology is promising for UASNs to break the above bottlenecks by providing high-fidelity status prediction and exploring optimal schemes. In this article, we propose a Digital Twin-based Network Architecture (DTNA), enhancing UASNs' environmental adaptability, intelligence, and multifunctionality. By extracting real UASN information from local (node) and global (network) levels, we first design a layered architecture to improve the DT replica fidelity and UASN control flexibility. In local DT, we develop a resource allocation paradigm (RAPD), which rapidly perceives performance variations and iteratively optimizes allocation schemes to improve real-time environmental adaptability of resource allocation algorithms. In global DT, we aggregate decentralized local DT data and propose a collaborative Multi-agent reinforcement learning framework (CMFD) and a task-oriented network slicing (TNSD). CMFD patches scarce real data and provides extensive DT data to accelerate AI model training. TNSD unifies heterogeneous tasks' demand extraction and efficiently provides comprehensive network status, improving the flexibility of multi-task scheduling algorithms. Finally, practical and simulation experiments verify the high fidelity of DT. Compared with the original UASN architecture, experiment results demonstrate that DTNA can: (i) improve the timeliness and robustness of resource allocation; (ii) greatly reduce the training time of AI algorithms; (iii) more rapidly obtain network status for multi-task scheduling at a low cost.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FL-DABE-BC: A Privacy-Enhanced, Decentralized Authentication, and Secure Communication for Federated Learning Framework with Decentralized Attribute-Based Encryption and Blockchain for IoT Scenarios</title>
<link>https://arxiv.org/abs/2410.20259</link>
<guid>https://arxiv.org/abs/2410.20259</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Decentralized Attribute-Based Encryption（分布式属性基加密）、Homomorphic Encryption（同态加密）、Secure Multi-Party Computation（安全多方计算）、Blockchain（区块链）

<br /><br />总结：
本文提出了一种融合了分布式属性基加密、同态加密、安全多方计算和区块链技术的先进联邦学习框架，旨在增强物联网环境中的数据隐私与安全性。该框架利用DABE实现在IoT设备上的安全、分散式认证和本地加密，确保敏感数据保持加密状态。通过同态加密，可以在加密数据上进行计算；而SMPC则保障了协作计算过程中的隐私性。此外，采用区块链技术实现所有交易和模型更新透明、不可篡改的记录保存。在该框架下，本地模型权重经过HE和SMPC加密后传输到雾层进行聚合，中央服务器再运用差分隐私进行迭代优化，以防数据泄露。这个安全、保护隐私的联邦学习框架为分布式的IoT设备提供了高效模型训练和实时分析的解决方案，显著推进了物联网应用中安全分散式学习的发展。 <div>
arXiv:2410.20259v1 Announce Type: new 
Abstract: This study proposes an advanced Federated Learning (FL) framework designed to enhance data privacy and security in IoT environments by integrating Decentralized Attribute-Based Encryption (DABE), Homomorphic Encryption (HE), Secure Multi-Party Computation (SMPC), and Blockchain technology. Unlike traditional FL, our framework enables secure, decentralized authentication and encryption directly on IoT devices using DABE, allowing sensitive data to remain locally encrypted. Homomorphic Encryption permits computations on encrypted data, and SMPC ensures privacy in collaborative computations, while Blockchain technology provides transparent, immutable record-keeping for all transactions and model updates. Local model weights are encrypted and transmitted to fog layers for aggregation using HE and SMPC, then iteratively refined by the central server using differential privacy to safeguard against data leakage. This secure, privacy-preserving FL framework delivers a robust solution for efficient model training and real-time analytics across distributed IoT devices, offering significant advancements in secure decentralized learning for IoT applications.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Transport Infrastructure Maintenance: A Smart-Contract Blockchain Approach</title>
<link>https://arxiv.org/abs/2410.20431</link>
<guid>https://arxiv.org/abs/2410.20431</guid>
<content:encoded><![CDATA[
<div> 关键词：基础设施维护、智能合约、区块链、流程挖掘、物联网

总结:
<br />
本文探讨了利用智能合约和区块链技术改进基础设施维护管理的可能性。通过智能合约，可以实现从承包商分配到维护完成的端到端自动化流程，确保满足安全和技术标准，并提高效率与透明度。文章强调了理解维护工作流以构建全面的合同规则的重要性，并指出需要借助现代过程挖掘创建动态、数据驱动的维护模型。此外，为了实现自动化的高效维护，还需要依赖物联网传感器、大数据分析、预测性维护、智能物流以及资产管理等技术手段，确保整个程序链的数据质量和可靠性。 <div>
arXiv:2410.20431v1 Announce Type: new 
Abstract: Infrastructure maintenance is inherently complex, especially for widely dispersed transport systems like roads and railroads. Maintaining this infrastructure involves multiple partners working together to ensure safe, efficient upkeep that meets technical and safety standards, with timely materials and budget adherence. Traditionally, these requirements are managed on paper, with each contract step checked manually. Smart contracts, based on blockchain distributed ledger technology, offer a new approach. Distributed ledgers facilitate secure, transparent transactions, enabling decentralized agreements where contract terms automatically execute when conditions are met. Beyond financial transactions, blockchains can track complex agreements, recording each stage of contract fulfillment between multiple parties. A smart contract is a set of coded rules stored on the blockchain that automatically executes each term upon meeting specified conditions. In infrastructure maintenance, this enables end-to-end automation-from contractor assignment to maintenance completion. Using an immutable, decentralized record, contract terms and statuses are transparent to all parties, enhancing trust and efficiency. Creating smart contracts for infrastructure requires a comprehensive understanding of procedural workflows to foresee all requirements and liabilities. This workflow includes continuous infrastructure monitoring through a dynamic, data-driven maintenance model that triggers necessary actions. Modern process mining can develop a resilient Maintenance Process Model, helping Operations Management to define contract terms, including asset allocation, logistics, materials, and skill requirements. Automation and reliable data quality across the procedural chain are essential, supported by IoT sensors, big data analytics, predictive maintenance, intelligent logistics, and asset management.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fractal and Turbulent Feature Extraction and NFT Label Generation for Pollock Style Migration Paintings Based on VGG19</title>
<link>https://arxiv.org/abs/2410.20519</link>
<guid>https://arxiv.org/abs/2410.20519</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、分形分析、湍流特征提取、抽象艺术、Pollock风格、MindSpore、VGG19模型、内容损失、风格损失、全方差损失、分形维数、差异箱计数方法、二维离散小波变换、Haar小波、非同质化代币（NFT）、数字艺术品创作、认证保护。

<br /><br />总结:
该文提出了一种融合深度学习、分形分析和湍流特征提取技术的新方法，用于创作Pollock风格的抽象艺术作品。通过MindSpore深度学习框架和预训练的VGG19模型提取图像的内容与风格特性，并利用内容损失、风格损失和全方差损失进行优化生成高质量的Pollock风格图像。文章还实现了一种基于差异箱计数法的分形维数计算方法，采用二维离散小波变换和Haar小波对图像进行频域分解以提取不同频率信息。结合多种特征生成独特的NFT标签，用于数字艺术品的认证和保护。实验结果表明，生成的艺术作品具有丰富的分形维度和湍流特征多样性，同时NFT标签确保了每个数字收藏品的独特性和防篡改性。该方法有机地结合了计算机视觉、数字信号处理和区块链技术，为数字艺术品的创作和认证提供了新的解决方案。 <div>
arXiv:2410.20519v1 Announce Type: new 
Abstract: This paper puts forth an innovative approach that fuses deep learning, fractal analysis, and turbulence feature extraction techniques to create abstract artworks in the style of Pollock. The content and style characteristics of the image are extracted by the MindSpore deep learning framework and a pre-trained VGG19 model. An optimisation process is then employed to The method generates high-quality Pollock-style images by combining content loss, style loss and full variance loss to achieve accurate style migration. Furthermore, this paper implements a fractal dimension calculation method based on the difference box-counting method, which effectively estimates the fractal dimension of an image through edge extraction and fractal analysis. The method is based on a two-dimensional discrete wavelet transform using a Haar wavelet to decompose the image in order to extract different frequency information. This is followed by the combination of multiple features to generate unique non-homogeneous token (NFT) labels for the authentication and protection of digital artwork. The experimental results demonstrate that the generated artworks exhibit The method demonstrates significant diversity and complexity in terms of fractal dimensions and turbulence features, while the generated NFT tags ensure the uniqueness and tamperability of each digital collection. The present method organically combines computer vision, digital signal processing and blockchain technology to provide a new solution for the creation and authentication of digital artworks.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Props for Machine-Learning Security</title>
<link>https://arxiv.org/abs/2410.20522</link>
<guid>https://arxiv.org/abs/2410.20522</guid>
<content:encoded><![CDATA[
<div> 关键词: protected pipelines（保护管道）、props、深度网络数据、机器学习（ML）、隐私保护、可信推断、敏感数据、区块链应用

<br /><br />总结:
本文提出了“protected pipelines”或简称props，一种用于实现认证和隐私保护的深度网络数据访问新方法，旨在解决机器学习（ML）发展中的高质量训练数据瓶颈问题。Props同时支持隐私保护和可信赖的推理方式，使得在ML应用中安全使用敏感数据成为可能。文章指出，借助最初为区块链应用开发的隐私保护预言机系统，props在现实中已经可以实现。 <div>
arXiv:2410.20522v1 Announce Type: new 
Abstract: We propose protected pipelines or props for short, a new approach for authenticated, privacy-preserving access to deep-web data for machine learning (ML). By permitting secure use of vast sources of deep-web data, props address the systemic bottleneck of limited high-quality training data in ML development. Props also enable privacy-preserving and trustworthy forms of inference, allowing for safe use of sensitive data in ML applications. Props are practically realizable today by leveraging privacy-preserving oracle systems initially developed for blockchain applications.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Survey on Green Blockchain: Developing the Next Generation of Energy Efficient and Sustainable Blockchain Systems</title>
<link>https://arxiv.org/abs/2410.20581</link>
<guid>https://arxiv.org/abs/2410.20581</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain、能源消耗、共识机制、网络架构、绿色区块链

总结:
本文分析了区块链的主要组件，包括共识机制、网络架构、数据存储与验证、智能合约执行、挖矿与区块创建，并探讨了降低其能源消耗的策略。文章对比了不同的共识机制，提出了减少网络通信能耗的建议，建议采用节能的数据存储和验证技术，并对软件和硬件组件提出多种优化方案。同时，文章也分析了降低区块链系统功耗的主要挑战与限制。因此，本文为致力于开发下一代绿色区块链解决方案的研究者和开发者提供了指导性建议。 <div>
arXiv:2410.20581v1 Announce Type: new 
Abstract: Although Blockchain has been successfully used in many different fields and applications, it has been traditionally regarded as an energy-intensive technology, essentially due to the past use of inefficient consensus algorithms that prioritized security over sustainability. However, in the last years, thanks to the significant progress made on key blockchain components, their energy consumption can be decreased noticeably. To achieve this objective, this article analyzes the main components of blockchains and explores strategies to reduce their energy consumption. In this way, this article delves into each component of a blockchain system, including consensus mechanisms, network architecture, data storage and validation, smart contract execution, mining and block creation, and outlines specific strategies to decrease their energy consumption. For such a purpose, consensus mechanisms are compared, recommendations for reducing network communications energy consumption are provided, techniques for data storage and validation are suggested and diverse optimizations are proposed both for software and hardware components. Moreover, the main challenges and limitations of reducing power consumption in blockchain systems are analyzed. As a consequence, this article provides a guideline for the future researchers and developers who aim to develop the next generation of Green Blockchain solutions.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Blockchain and Opportunistic Edge Driven Metaverse of Everything</title>
<link>https://arxiv.org/abs/2410.20594</link>
<guid>https://arxiv.org/abs/2410.20594</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Metaverses, Web 3.0/4.0, Metaverse of Everything (MoE), Internet of Everything (IoE), Opportunistic Edge Computing (OEC)

<br /><br />总结:
本文探讨了基于Web 3.0和Web 4.0技术的去中心化元宇宙（Decentralized Metaverses）及其受到广泛关注的现象。文章聚焦于元宇宙与万物互联网（Internet of Everything, IoE）融合而成的“万物元宇宙”（Metaverse of Everything, MoE），该平台能够整合生成的数据与虚拟实体，构建一个广泛的互联组件网络。同时，文中提出将机会性边缘计算（Opportunistic Edge Computing, OEC）应用于与周围物联网设备和IoE实体的交互，并分析了构建未来具有韧性的、机会性的MoE所面临的挑战，旨在为研究人员和企业提供指导方向。 <div>
arXiv:2410.20594v1 Announce Type: new 
Abstract: Decentralized Metaverses, built on Web 3.0 and Web 4.0 technologies, have attracted significant attention across various fields. This innovation leverages blockchain, Decentralized Autonomous Organizations (DAOs), Extended Reality (XR) and advanced technologies to create immersive and interconnected digital environments that mirror the real world. This article delves into the Metaverse of Everything (MoE), a platform that fuses the Metaverse concept with the Internet of Everything (IoE), an advanced version of the Internet of Things (IoT) that connects not only physical devices but also people, data and processes within a networked environment. Thus, the MoE integrates generated data and virtual entities, creating an extensive network of interconnected components. This article seeks to advance current MoE, examining decentralization and the application of Opportunistic Edge Computing (OEC) for interactions with surrounding IoT devices and IoE entities. Moreover, it outlines the main challenges to guide researchers and businesses towards building a future cyber-resilient opportunistic MoE.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Towards Green Blockchain: A Practical Energy-Efficient Blockchain Based Application for CV Verification</title>
<link>https://arxiv.org/abs/2410.20605</link>
<guid>https://arxiv.org/abs/2410.20605</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、绿色解决方案、能源节约、学术证书防伪、Proof-of-Work (PoW)、Proof-of-Authority (PoA)

总结:
本文提出了一种绿色区块链解决方案，并通过将该技术应用于解决学术证书伪造问题的示例中，量化了部署在传统计算机和嵌入式单板计算机(SBCs)上的系统所节省的能源。为防止学术记录(ARs)伪造，文章建议采用基于以太坊区块链的智能合约支持的去中心化应用(DApp)，并通过使用Inter-Planetary File System (IPFS)进行分布式存储来保存原始数据。研究对比了传统的Proof-of-Work (PoW)共识协议与新的Proof-of-Authority (PoA)协议在性能（交易延迟和吞吐量）和效率（CPU利用率和能耗）方面的表现，结果显示PoA协议更加环保并要求更低的CPU负载。此外，文章还对比评估了传统计算机与两种SBCs（Raspberry Pi 4 和 Orange Pi One）的表现，证实了利用低功耗设备实现区块链节点的可能性，但响应延迟会有所增加，并且具体延迟取决于所使用的SBC类型。 <div>
arXiv:2410.20605v1 Announce Type: new 
Abstract: Blockchain has been widely criticized due to the use of inefficient consensus protocols and energy-intensive mechanisms that derived into a global enormous power consumption. Fortunately, since the first blockchain was conceived in 2008 (the one that supports Bitcoin), hardware and consensus protocols have evolved, decreasing energy consumption significantly. This article describes a green blockchain solution and quantifies energy savings when deploying the system on traditional computers and embedded Single-Board Computers (SBCs). To illustrate such savings, it is proposed a solution for tackling the problem of academic certificate forgery, which has a significant cost to society, since it harms the trustworthiness of certificates and academic institutions. The proposed solution is aimed at recording and verifying academic records (ARs) through a decentralized application (DApp) that is supported by a smart contract deployed in the Ethereum blockchain. The application stores the raw data (i.e., the data that are not managed by the blockchain) on a decentralized storage system based on Inter-Planetary File System (IPFS). To demonstrate the efficiency of the developed solution, it is evaluated in terms of performance (transaction latency and throughput) and efficiency (CPU usage and energy consumption), comparing the results obtained with a traditional Proof-of-Work (PoW) consensus protocol and the new Proof-of-Authority (PoA) protocol. The results shown in this paper indicate that the latter is clearly greener and demands less CPU load. Moreover, this article compares the performance of a traditional computer and two SBCs (a Raspberry Pi 4 and an Orange Pi One), showing that is possible to make use of the latter low-power devices to implement blockchain nodes for proposed DApp, but at the cost of higher response latency that varies greatly depending on the used SBCs [...]
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>COBRA: Interaction-Aware Bytecode-Level Vulnerability Detector for Smart Contracts</title>
<link>https://arxiv.org/abs/2410.20712</link>
<guid>https://arxiv.org/abs/2410.20712</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、COBRA框架、函数接口、SRIF

<br /><br />总结:
本文提出了一种名为COBRA的新颖框架，用于通过结合语义上下文和函数接口来检测智能合约字节码中的漏洞。COBRA是首个将这两者特征相结合的框架。为了解决签名数据库中缺失的函数签名问题，文章还提出了SRIF（从函数反推签名）方法，该方法能自动从智能合约字节码中学习函数签名规则。通过构建控制流图收集与函数签名相关的字节码，并利用静态单赋值(SSA)格式优化语义上下文。随后，COBRA在潜在空间中融合上下文和函数接口表示作为合同特征嵌入。实验结果显示，SRIF对于函数签名推断的F1得分为94.76%，而当具有真实ABI时，COBRA在漏洞分类上的F1得分为93.45%。在没有ABI的情况下，使用推断出的函数特征填充编码器，系统仍能达到89.46%的召回率。 <div>
arXiv:2410.20712v1 Announce Type: new 
Abstract: The detection of vulnerabilities in smart contracts remains a significant challenge. While numerous tools are available for analyzing smart contracts in source code, only about 1.79% of smart contracts on Ethereum are open-source. For existing tools that target bytecodes, most of them only consider the semantic logic context and disregard function interface information in the bytecodes. In this paper, we propose COBRA, a novel framework that integrates semantic context and function interfaces to detect vulnerabilities in bytecodes of the smart contract. To our best knowledge, COBRA is the first framework that combines these two features. Moreover, to infer the function signatures that are not present in signature databases, we present SRIF (Signatures Reverse Inference from Functions), automatically learn the rules of function signatures from the smart contract bytecodes. The bytecodes associated with the function signatures are collected by constructing a control flow graph (CFG) for the SRIF training. We optimize the semantic context using the operation code in the static single assignment (SSA) format. Finally, we integrate the context and function interface representations in the latent space as the contract feature embedding. The contract features in the hidden space are decoded for vulnerability classifications with a decoder and attention module. Experimental results demonstrate that SRIF can achieve 94.76% F1-score for function signature inference. Furthermore, when the ground truth ABI exists, COBRA achieves 93.45% F1-score for vulnerability classification. In the absence of ABI, the inferred function feature fills the encoder, and the system accomplishes an 89.46% recall rate.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Malicious Accounts in Web3 through Transaction Graph</title>
<link>https://arxiv.org/abs/2410.20713</link>
<guid>https://arxiv.org/abs/2410.20713</guid>
<content:encoded><![CDATA[
<div> 关键词：web3应用、Ethereum平台、诈骗检测、ScamSweeper、大规模交易网络

总结:
<br />
本文提出了一种名为ScamSweeper的新型框架，用于识别以太坊平台上不断增长的web3骗局。随着web3应用程序在Ethereum上的发展，骗子开始利用这些服务进行仿冒活动来欺骗用户。现有的钓鱼账户检测工具主要依赖图学习或采样算法获取图特征，但面对具有时间属性的大规模交易网络（其符合幂律分布）时，检测web3骗局面临挑战。为此，文章收集了一个包含web3骗局、钓鱼和正常账户的大规模交易数据集。实验结果显示，ScamSweeper在检测web3骗局方面超越了当前最先进的方法。 <div>
arXiv:2410.20713v1 Announce Type: new 
Abstract: The web3 applications have recently been growing, especially on the Ethereum platform, starting to become the target of scammers. The web3 scams, imitating the services provided by legitimate platforms, mimic regular activity to deceive users. The current phishing account detection tools utilize graph learning or sampling algorithms to obtain graph features. However, large-scale transaction networks with temporal attributes conform to a power-law distribution, posing challenges in detecting web3 scams. In this paper, we present ScamSweeper, a novel framework to identify web3 scams on Ethereum. Furthermore, we collect a large-scale transaction dataset consisting of web3 scams, phishing, and normal accounts. Our experiments indicate that ScamSweeper exceeds the state-of-the-art in detecting web3 scams.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Co-produced decentralised surveys as a trustworthy vector to put employees' well-being at the core of companies' performance</title>
<link>https://arxiv.org/abs/2410.20919</link>
<guid>https://arxiv.org/abs/2410.20919</guid>
<content:encoded><![CDATA[
<div> 关键词：员工幸福感、区块链、去中心化调查、信任、文化实践

<br /><br />总结:
随着企业对员工幸福感评估的重视，传统方法面临信任和信心缺失等问题。文章提出利用区块链技术的不可篡改、透明度和匿名性改进员工幸福感调查，以增强数据处理的安全性和透明度。然而，单纯的技术应用并不能解决文化层面的信任问题。为此，文章结合区块链技术和关系文化理论，探讨了通过共同构建去中心化的幸福感调查来平衡权力差异和建立信任的方法。文章旨在提供一种文化和技术双重框架，阐述如何将技术实施带来的信心与文化发展中建立的信任相结合，确保基于区块链的去中心化幸福感调查不仅安全可靠，而且能被员工视为值得信赖的工作环境改善工具。 <div>
arXiv:2410.20919v1 Announce Type: new 
Abstract: Assessing employees' well-being has become central to fostering an environment where employees can thrive and contribute to companies' adaptability and competitiveness in the market. Traditional methods for assessing well-being often face significant challenges, with a major issue being the lack of trust and confidence employees may have in these processes. Employees may hesitate to provide honest feedback due to concerns not only about data integrity and confidentiality, but also about power imbalances among stakeholders. In this context, blockchain-based decentralised surveys, leveraging the immutability, transparency, and pseudo-anonymity of blockchain technology, offer significant improvements in aligning responsive actions with employees' feedback securely and transparently. Nevertheless, their implementation raises complex issues regarding the balance between trust and confidence. While blockchain can function as a confidence machine for data processing and management, it does not inherently address the equally important cultural element of trust. To effectively integrate blockchain technology into well-being assessments, decentralised well-being surveys must be supported by cultural practices that build and sustain trust. Drawing on blockchain technology management and relational cultural theory, we explain how trust-building can be achieved through the co-production of decentralised well-being surveys, which helps address power imbalances between the implementation team and stakeholders. Our goal is to provide a dual cultural-technological framework along with conceptual clarity on how the technological implementation of confidence can connect with the cultural development of trust, ensuring that blockchain-based decentralised well-being surveys are not only secure and reliable but also perceived as trustworthy vector to improve workplace conditions.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>LiP-LLM: Integrating Linear Programming and dependency graph with Large Language Models for multi-robot task planning</title>
<link>https://arxiv.org/abs/2410.21040</link>
<guid>https://arxiv.org/abs/2410.21040</guid>
<content:encoded><![CDATA[
<div> 关键词: LiP-LLM、大规模语言模型、多机器人任务规划、线性编程、依赖图

<br /><br />总结:
本文提出了LiP-LLM，一种将线性编程和依赖图与大规模语言模型（LLMs）相结合的方法，用于多机器人任务规划。该方法着重解决基于任务效率的技能依赖关系管理和任务优化分配问题。LiP-LLM包括三个步骤：利用LLMs生成技能列表和依赖图，以及使用线性编程进行任务分配。LLMs用于生成全面的技能列表并构建描绘这些技能之间关系和顺序约束的依赖图。通过计算概率生成技能列表以确保执行可行性，并利用线性编程对任务进行最优分配。实验结果显示，在模拟环境中，这种方法相较于现有的任务规划器表现出更高的成功率和效率，在处理复杂、多机器人的协调任务方面具有优势。在一个有两个机器人的环境中，当物体名称改变时，在语言指令组中观察到了最大0.82的成功率差异，显示出结合LLMs和优化技术能有效提升多机器人系统协同执行任务的准确性和效率。 <div>
arXiv:2410.21040v1 Announce Type: new 
Abstract: This study proposes LiP-LLM: integrating linear programming and dependency graph with large language models (LLMs) for multi-robot task planning. In order for multiple robots to perform tasks more efficiently, it is necessary to manage the precedence dependencies between tasks. Although multi-robot decentralized and centralized task planners using LLMs have been proposed, none of these studies focus on precedence dependencies from the perspective of task efficiency or leverage traditional optimization methods. It addresses key challenges in managing dependencies between skills and optimizing task allocation. LiP-LLM consists of three steps: skill list generation and dependency graph generation by LLMs, and task allocation using linear programming. The LLMs are utilized to generate a comprehensive list of skills and to construct a dependency graph that maps the relationships and sequential constraints among these skills. To ensure the feasibility and efficiency of skill execution, the skill list is generated by calculated likelihood, and linear programming is used to optimally allocate tasks to each robot. Experimental evaluations in simulated environments demonstrate that this method outperforms existing task planners, achieving higher success rates and efficiency in executing complex, multi-robot tasks. The results indicate the potential of combining LLMs with optimization techniques to enhance the capabilities of multi-robot systems in executing coordinated tasks accurately and efficiently. In an environment with two robots, a maximum success rate difference of 0.82 is observed in the language instruction group with a change in the object name.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Policies for Fair Exchanges of Resources</title>
<link>https://arxiv.org/abs/2410.21214</link>
<guid>https://arxiv.org/abs/2410.21214</guid>
<content:encoded><![CDATA[
<div> 关键词: MuAC、数字平台、资源交换、MuACL、区块链<br /><br />总结:<br />
本文提出了一种针对用户依据政策在数字平台上进行资源交换环境的正式模型。为了确保恶意用户无法利用诚实用户，文章引入了声明式策略语言MuAC并为其制定了形式语义。为判断资源交换是否公平，即是否符合强制执行的MuAC策略，文中提出了融合非线性、线性和合同性质的非标准逻辑MuACL，并证明其可决定性。值得注意的是，MuACL的合同蕴含运算符不能用线性逻辑表达。文章定义了一个保持语义一致性的MuAC策略到MuACL的编译方法，从而将交换公平性问题转化为在MuACL中寻找证明的过程。最后，文章展示了如何将这种方法应用到区块链上，用于非同质化代币的交换。 <div>
arXiv:2410.21214v1 Announce Type: new 
Abstract: People increasingly use digital platforms to exchange resources in accordance to some policies stating what resources users offer and what they require in return. In this paper, we propose a formal model of these environments, focussing on how users' policies are defined and enforced, so ensuring that malicious users cannot take advantage of honest ones. To that end, we introduce the declarative policy language MuAC and equip it with a formal semantics. To determine if a resource exchange is fair, i.e., if it respects the MuAC policies in force, we introduce the non-standard logic MuACL that combines non-linear, linear and contractual aspects, and prove it decidable. Notably, the operator for contractual implication of MuACL is not expressible in linear logic. We define a semantics preserving compilation of MuAC policies into MuACL, thus establishing that exchange fairness is reduced to finding a proof in MuACL. Finally, we show how this approach can be put to work on a blockchain to exchange non-fungible tokens.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data</title>
<link>https://arxiv.org/abs/2410.20659</link>
<guid>https://arxiv.org/abs/2410.20659</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Generalization Error（泛化误差）、Deep Federated Regression（深度联合回归）、Intrinsic Dimension（内在维度）、Entropic Dimension（熵维）

<br /><br />
总结：
该文深入研究了联邦学习框架下深度联合回归任务的泛化性质，尤其关注异质性环境下的问题。文章指出，在一个两阶段采样模型中，内在维度（由熵维定义）对于确定收敛率至关重要，特别是在适当网络规模条件下。当真实响应变量与解释变量之间的关系由$\beta$-Hölder函数刻画，且有$m$个客户端的$n$个独立同分布样本时，参与客户端的学习误差率最多以$\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$的速率衰减；而非参与客户端则以$\tilde{O}\left(\Delta \cdot m^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$的速率衰减。其中，$\bar{d}_{2\beta}(\lambda)$表示解释变量边际分布$\lambda$的$2\beta$-熵维，而$\Delta$描述了采样阶段之间的依赖性。这些结果明确表明，深度联邦学习者的收敛率取决于内在而非名义上的高维性。 <div>
arXiv:2410.20659v1 Announce Type: cross 
Abstract: Federated Learning (FL) has emerged as a groundbreaking paradigm in collaborative machine learning, emphasizing decentralized model training to address data privacy concerns. While significant progress has been made in optimizing federated learning, the exploration of generalization error, particularly in heterogeneous settings, has been limited, focusing mainly on parametric cases. This paper investigates the generalization properties of deep federated regression within a two-stage sampling model. Our findings highlight that the intrinsic dimension, defined by the entropic dimension, is crucial for determining convergence rates when appropriate network sizes are used. Specifically, if the true relationship between response and explanatory variables is charecterized by a $\beta$-H\"older function and there are $n$ independent and identically distributed (i.i.d.) samples from $m$ participating clients, the error rate for participating clients scales at most as $\tilde{O}\left((mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$, and for non-participating clients, it scales as $\tilde{O}\left(\Delta \cdot m^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))} + (mn)^{-2\beta/(2\beta + \bar{d}_{2\beta}(\lambda))}\right)$. Here, $\bar{d}_{2\beta}(\lambda)$ represents the $2\beta$-entropic dimension of $\lambda$, the marginal distribution of the explanatory variables, and $\Delta$ characterizes the dependence between the sampling stages. Our results explicitly account for the "closeness" of clients, demonstrating that the convergence rates of deep federated learners depend on intrinsic rather than nominal high-dimensionality.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Bayesian Networks for Predicting Cryptocurrency Price Directions: Uncovering Causal Relationships</title>
<link>https://arxiv.org/abs/2306.08157</link>
<guid>https://arxiv.org/abs/2306.08157</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币, 波动性, 动态贝叶斯网络, 预测模型, 基线模型

总结:
本文研究了加密货币价格预测问题，关注了其波动性和全球经济因素的影响。为了解决这一问题，文章提出了一个基于动态贝叶斯网络(DBN)的方法，用于探究社交媒体数据、传统金融市场因素及技术指标之间的潜在因果关系。研究涉及比特币、币安币、以太坊、莱特币、瑞波币和泰达币六种主流加密货币。实验结果表明，虽然DBN在不同加密货币上的表现各异，但总体上，相较于自回归整合滑动平均、支持向量回归、长短时记忆网络、随机森林和支持向量机等五个基线模型，DBN显示出显著更高的预测准确性。 <div>
arXiv:2306.08157v3 Announce Type: replace 
Abstract: Cryptocurrencies have gained popularity across various sectors, especially in finance and investment. Despite their growing popularity, cryptocurrencies can be a high-risk investment due to their price volatility. The inherent volatility in cryptocurrency prices, coupled with the effects of external global economic factors, makes predicting their price movements challenging. To address this challenge, we propose a dynamic Bayesian network (DBN)-based approach to uncover potential causal relationships among various features including social media data, traditional financial market factors, and technical indicators. Six popular cryptocurrencies, Bitcoin, Binance Coin, Ethereum, Litecoin, Ripple, and Tether are studied in this work. The proposed model's performance is compared to five baseline models of auto-regressive integrated moving average, support vector regression, long short-term memory, random forests, and support vector machines. The results show that while DBN performance varies across cryptocurrencies, with some cryptocurrencies exhibiting higher predictive accuracy than others, the DBN significantly outperforms the baseline models.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeRi-IGP: Learning to Manipulate Rigid Objects Using Deformable Objects via Iterative Grasp-Pull</title>
<link>https://arxiv.org/abs/2309.04843</link>
<guid>https://arxiv.org/abs/2309.04843</guid>
<content:encoded><![CDATA[
<div> 关键词：Iterative Grasp-Pull (IGP)，机器人操作，可变形线性物体(DLO)，神经政策，多智能体协作<br /><br />总结:
本文提出了一种名为Iterative Grasp-Pull (IGP)的普适性移动原语，用于通过可变形线性物体（如绳子）操纵刚体对象，解决了现有方法在机器人动作和工作空间限制、泛化能力差以及模型依赖性强等问题。研究中还引入了一个基于视觉的神经策略，该策略学习如何参数化IGP原语以操控DLO并将所连接的刚体对象搬运到目标位置。此外，提出的分布式算法设计允许多个智能体协同利用DLO来操纵刚体对象。实验分别在仿真和真实环境中对多种软-刚体操纵任务进行了有效性验证，并在实际场景中展示了人机协作下利用IGP进行刚体对象的目标位置运输的能力。同时，文章还展示了IGP原语在解决远距离物体获取任务中的广阔应用空间。最后，将该方法与几种基于模型和基于学习的基线方法进行了对比，结果显示我们的方法显著优于其他方法。相关项目补充材料和视频可在https://sites.google.com/view/deri-igp/home查看。 <div>
arXiv:2309.04843v4 Announce Type: replace 
Abstract: Robotic manipulation of rigid objects via deformable linear objects (DLO) such as ropes is an emerging field of research with applications in various rigid object transportation tasks. A few methods that exist in this field suffer from limited robot action and operational space, poor generalization ability, and expensive model-based development. To address these challenges, we propose a universally applicable moving primitive called Iterative Grasp-Pull (IGP). We also introduce a novel vision-based neural policy that learns to parameterize the IGP primitive to manipulate DLO and transport their attached rigid objects to the desired goal locations. Additionally, our decentralized algorithm design allows collaboration among multiple agents to manipulate rigid objects using DLO. We evaluated the effectiveness of our approach in both simulated and real-world environments for a variety of soft-rigid body manipulation tasks. In the real world, we also demonstrate the effectiveness of our decentralized approach through human-robot collaborative transportation of rigid objects to given goal locations. We also showcase the large operational space of IGP primitive by solving distant object acquisition tasks. Lastly, we compared our approach with several model-based and learning-based baseline methods. The results indicate that our method surpasses other approaches by a significant margin. The project supplementary material and videos are available at: https://sites.google.com/view/deri-igp/home
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring the Market Dynamics of Liquid Staking Derivatives (LSDs)</title>
<link>https://arxiv.org/abs/2402.17748</link>
<guid>https://arxiv.org/abs/2402.17748</guid>
<content:encoded><![CDATA[
<div> 关键词：staking、Liquid Staking Derivatives (LSDs)、市场动态、流动性提供者 (LPs)、流动性需求者 (LTs)

<br /><br />总结:
本文分析了在以太坊转向权益证明共识后兴起的staking概念中，液体权益质押衍生品（LSDs）对于解决单打独斗式质押带来的流动性问题的重要性。研究内容涉及从流动性需求者(LTs)和流动性提供者(LPs)两个视角对LSD市场动态进行剖析。首先量化了LSD一级市场与二级市场的价格差异；其次，探究并实证测量了LTs如何利用这一差异来发掘套利机会以及实现套利过程中可能遇到的障碍；此外，还评估了作为LPs供应LSDs进行流动性提供的金融盈亏情况。结果显示，有66%的LSD流动性持仓产生的回报低于直接持有相应LSDs的情况。 <div>
arXiv:2402.17748v3 Announce Type: replace 
Abstract: Staking has emerged as a crucial concept following Ethereum's transition to Proof-of-Stake consensus. The introduction of Liquid Staking Derivatives (LSDs) has effectively addressed the illiquidity issue associated with solo staking, gaining significant market attention. This paper analyzes the LSD market dynamics from the perspectives of both liquidity takers (LTs) and liquidity providers (LPs). We first quantify the price discrepancy between the LSD primary and secondary markets. Then we investigate and empirically measure how LTs can leverage such discrepancy to exploit arbitrage opportunities, unveiling the potential barriers to LSD arbitrages. In addition, we evaluate the financial profit and losses experienced by LPs who supply LSDs for liquidity provision. Our results show that 66% of LSD liquidity positions generate returns lower than those from simply holding the corresponding LSDs.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Proximal Gradient Method With Probabilistic Multi-Gossip Communications for Decentralized Composite Optimization</title>
<link>https://arxiv.org/abs/2312.11861</link>
<guid>https://arxiv.org/abs/2312.11861</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式优化、局部更新、通信效率、多 gossip 通信、非光滑优化

总结:
本文提出了一种名为MG-Skip的新方法，用于分布式复合（平滑+非平滑）优化问题，该方法具有概率性局部更新和多 gossip 通信的特点。MG-Skip 的步长独立于本地更新次数和网络拓扑结构，无需额外的网络连通性条件，在强凸设定下允许多数迭代中跳过多 gossip 通信。其迭代复杂度为$\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$，而通信复杂度仅为$\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$，其中$\kappa$表示损失函数的条件数，$\rho$反映网络拓扑的连通性，$\epsilon$为目标精度。理论结果表明，MG-Skip 实现了最优的通信复杂度，并证实了在非光滑设置中局部更新的优势。 <div>
arXiv:2312.11861v2 Announce Type: replace-cross 
Abstract: Decentralized optimization methods with local updates have recently gained attention for their provable ability to communication acceleration. In these methods, nodes perform several iterations of local computations between the communication rounds. Nevertheless, this capability is effective only when the loss function is smooth and the network is sufficiently well-connected. In this paper, we propose a communication-efficient method MG-Skip with probabilistic local updates and multi-gossip communications for decentralized composite (smooth + nonsmooth) optimization, whose stepsize is independent of the number of local updates and the network topology. Without any additional condition for network connectivity, MG-Skip allows for the multi-gossip communications to be skipped in most iterations in the strongly convex setting, while its iteration complexity is $\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$ and communication complexity is only $\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log \frac{1}{\epsilon}\right)$, where $\kappa$ is the condition number of the loss function, $\rho$ reflects the connectivity of the network topology, and $\epsilon$ is the target accuracy. The theoretical results demonstrate that MG-Skip achieves the optimal communication complexity and confirm the benefits of local updates in the nonsmooth setup.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantifying the Value of Revert Protection</title>
<link>https://arxiv.org/abs/2410.19106</link>
<guid>https://arxiv.org/abs/2410.19106</guid>
<content:encoded><![CDATA[
<div> 关键词：revert protection、blockchain、priority auctions、maximal extractable value (MEV)、game theory

<br /><br />总结:
本文研究了区块链平台上的回滚保护功能对优先拍卖和最大可提取价值(MEV)经济影响及其益处。文章建立了一个均衡博弈理论模型，分析了在只有一个交易能成功实现共同机会价值的情况下，用户（MEV搜索者）竞标提前处理交易的行为，考虑了有无回滚保护两种环境。该模型适用于Layer 1（如以太坊主网）和Layer 2区块链，以及“捆绑拍卖”（在L1上）或优先级排序拍卖（在L2上）。文章指出，在缺乏回滚保护时，用户将采用随机策略来缓解因失败交易支付费用的影响，从而导致拍卖收入减少。然而，通过回滚保护可以定量提高拍卖收入，同时改善市场效率并更有效地利用区块空间，这取决于底层参数（MEV机会的价值、基础费、回滚惩罚及参与代理的数量）。 <div>
arXiv:2410.19106v1 Announce Type: new 
Abstract: Revert protection is a feature provided by some blockchain platforms that prevents users from incurring fees for failed transactions. This paper explores the economic implications and benefits of revert protection, in the context of priority auctions and maximal extractable value (MEV). We develop an equilibrium game theoretic model that captures the behavior of users (MEV searchers) bidding to have their transaction included ahead of others, in an environment where only a single transaction will succeed in realizing the common value of an opportunity, and in settings both with and without revert protection. Our model applies to a broad range of settings, including Layer 1 (L1) blockchains (e.g., Ethereum mainnet) and Layer 2 (L2) blockchains, and auctions such as ``bundle auctions'' (on L1s) or priority ordering auctions (on L2s).
  We establish that, in the absence of revert protection, users will employ randomized strategies to mitigate the impact of paying for failed transactions. This will ultimately result in less auction revenue, despite the fact that failed transactions still pay fees. Our results quantify in closed form how revert protection enhances auction revenue, and also improves market efficiency and provides for more efficient use of blockspace, as a function of the underlying parameters (the value of the MEV opportunity, the base fee, the revert penalties, and the number of participating agents).
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations, Digital Twins, and Large Language Model</title>
<link>https://arxiv.org/abs/2410.19262</link>
<guid>https://arxiv.org/abs/2410.19262</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Autonomous Building Cyber-Physical System、Decentralized Autonomous Organizations、Large Language Models、digital twins、autonomous building operation

<br />
总结：
本文提出了一个结合去中心化自治组织（Decentralized Autonomous Organizations）、大型语言模型（Large Language Models）和数字孪生技术的新型去中心化自主建筑 cyber-物理系统框架。该框架旨在创建一个智能、自管理、运营自主且财务自主的建筑基础设施。研究中开发了一个全栈式去中心化应用以促进建筑基础设施的去中心化治理，并构建了一个基于 LLM 的人工智能助手，用于提供直观的人机交互，支持区块链和建筑运营管理任务以及实现建筑系统的自主运行。通过六个实际场景的测试，验证了该原型系统能够成功执行包括建筑营收与支出管理、AI 辅助设施控制和建筑系统自主调整等操作，从而证明了该框架适用于发展具有去中心化治理和自主运行能力的建筑基础设施。 <div>
arXiv:2410.19262v1 Announce Type: new 
Abstract: Current autonomous building research primarily focuses on energy efficiency and automation. While traditional artificial intelligence has advanced autonomous building research, it often relies on predefined rules and struggles to adapt to complex, evolving building operations. Moreover, the centralized organizational structures of facilities management hinder transparency in decision-making, limiting true building autonomy. Research on decentralized governance and adaptive building infrastructure, which could overcome these challenges, remains relatively unexplored. This paper addresses these limitations by introducing a novel Decentralized Autonomous Building Cyber-Physical System framework that integrates Decentralized Autonomous Organizations, Large Language Models, and digital twins to create a smart, self-managed, operational, and financially autonomous building infrastructure. This study develops a full-stack decentralized application to facilitate decentralized governance of building infrastructure. An LLM-based artificial intelligence assistant is developed to provide intuitive human-building interaction for blockchain and building operation management-related tasks and enable autonomous building operation. Six real-world scenarios were tested to evaluate the autonomous building system's workability, including building revenue and expense management, AI-assisted facility control, and autonomous adjustment of building systems. Results indicate that the prototype successfully executes these operations, confirming the framework's suitability for developing building infrastructure with decentralized governance and autonomous operation.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration</title>
<link>https://arxiv.org/abs/2410.19450</link>
<guid>https://arxiv.org/abs/2410.19450</guid>
<content:encoded><![CDATA[
<div> 关键词：Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL), Offline Value Function Memory (OVM), Sequential Exploration (SE), StarCraft Multi-Agent Challenge (SMAC), 样本效率

总结:
本文提出了一种针对多智能体强化学习的新型框架—— Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL) 的OVMSE方法。该框架旨在解决在从离线到在线阶段转换过程中Q值重新学习的风险和大型联合状态-动作空间中有效探索的困难。OVMSE包括两个关键机制：一是离线价值函数记忆（OVM）机制，用于计算目标Q值，保持离线训练期间获得的知识并确保平滑过渡及有效微调；二是为O2O MARL设计的去中心化顺序探索（Sequential Exploration, SE）策略，它有效地利用预训练的离线策略进行探索，显著减少了需要探索的联合状态-动作空间。通过在StarCraft Multi-Agent Challenge (SMAC) 上的大量实验，表明OVMSE相对于现有基线具有显著优势，实现了更高的样本效率和总体性能提升。 <div>
arXiv:2410.19450v1 Announce Type: new 
Abstract: Offline-to-Online Reinforcement Learning has emerged as a powerful paradigm, leveraging offline data for initialization and online fine-tuning to enhance both sample efficiency and performance. However, most existing research has focused on single-agent settings, with limited exploration of the multi-agent extension, i.e., Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL). In O2O MARL, two critical challenges become more prominent as the number of agents increases: (i) the risk of unlearning pre-trained Q-values due to distributional shifts during the transition from offline-to-online phases, and (ii) the difficulty of efficient exploration in the large joint state-action space. To tackle these challenges, we propose a novel O2O MARL framework called Offline Value Function Memory with Sequential Exploration (OVMSE). First, we introduce the Offline Value Function Memory (OVM) mechanism to compute target Q-values, preserving knowledge gained during offline training, ensuring smoother transitions, and enabling efficient fine-tuning. Second, we propose a decentralized Sequential Exploration (SE) strategy tailored for O2O MARL, which effectively utilizes the pre-trained offline policy for exploration, thereby significantly reducing the joint state-action space to be explored. Extensive experiments on the StarCraft Multi-Agent Challenge (SMAC) demonstrate that OVMSE significantly outperforms existing baselines, achieving superior sample efficiency and overall performance.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>x-RAGE: eXtended Reality -- Action &amp; Gesture Events Dataset</title>
<link>https://arxiv.org/abs/2410.19486</link>
<guid>https://arxiv.org/abs/2410.19486</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse、wearable devices、gesture-based human-computer interaction、event-based cameras、XR-centric gesture recognition

<br /><br />总结:
随着Metaverse和可穿戴设备的发展，基于手势的人机交互变得越来越重要。为了解决VR/AR头显和眼镜上的手势识别问题，近年来出现了一些专注于第一人称视角的egocentric手势识别数据集。然而，传统的帧基视觉方法存在数据带宽需求大以及难以捕捉快速动作的局限性。为此，本文提出了一种使用事件相机为基础的首个egocentric手势识别神经形态、低功耗解决方案的数据集，以克服上述限制。该数据集已公开发布于以下URL：https://gitlab.com/NVM_IITD_Research/xrage。 <div>
arXiv:2410.19486v1 Announce Type: new 
Abstract: With the emergence of the Metaverse and focus on wearable devices in the recent years gesture based human-computer interaction has gained significance. To enable gesture recognition for VR/AR headsets and glasses several datasets focusing on egocentric i.e. first-person view have emerged in recent years. However, standard frame-based vision suffers from limitations in data bandwidth requirements as well as ability to capture fast motions. To overcome these limitation bio-inspired approaches such as event-based cameras present an attractive alternative. In this work, we present the first event-camera based egocentric gesture dataset for enabling neuromorphic, low-power solutions for XR-centric gesture recognition. The dataset has been made available publicly at the following URL: https://gitlab.com/NVM_IITD_Research/xrage.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully First-Order Methods for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2410.19319</link>
<guid>https://arxiv.org/abs/2410.19319</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized stochastic bilevel optimization, DSGDA-GT, first-order oracle, sample complexity, communication efficiency

总结:
本文关注的是分布式随机双层优化（DSBO）问题，其中各个智能体仅与其邻居进行通信。文章提出了一个新的算法——带有梯度跟踪的分布式随机梯度下降和上升（DSGDA-GT），该算法仅需使用比现有工作广泛采用的第二阶 oracle 更便宜的第一阶 oracles。进一步地，作者提供了有限时间收敛性分析，表明在有 n 个智能体协同解决 DSBO 问题的情况下，其算法找到 $\epsilon$-临界点所需的样本复杂度为 $\mathcal{O}(n^{-1}\epsilon^{-7})$，这一结果与单智能体情况下的最优已知结果具有线性加速比。数值实验展示了该算法在通信效率和训练效率上的优势。<br /><br /> <div>
arXiv:2410.19319v1 Announce Type: cross 
Abstract: This paper focuses on decentralized stochastic bilevel optimization (DSBO) where agents only communicate with their neighbors. We propose Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a novel algorithm that only requires first-order oracles that are much cheaper than second-order oracles widely adopted in existing works. We further provide a finite-time convergence analysis showing that for $n$ agents collaboratively solving the DSBO problem, the sample complexity of finding an $\epsilon$-stationary point in our algorithm is $\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known results of the single-agent counterpart with linear speedup. The numerical experiments demonstrate both the communication and training efficiency of our algorithm.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalizing Differentially Private Decentralized Deep Learning with Multi-Agent Consensus</title>
<link>https://arxiv.org/abs/2306.13892</link>
<guid>https://arxiv.org/abs/2306.13892</guid>
<content:encoded><![CDATA[
<div> 关键词：cooperative decentralized learning、differential privacy、deep learning、accuracy、privacy budget

<br /><br />总结:
本文提出了一个将差分隐私嵌入到分布式深度学习中的框架，旨在保障在合作学习过程中每个代理节点的局部数据集在训练期间和之后的安全。该框架保证了算法的收敛性，并在应用于子梯度和ADMM等分布式方法时，实现了接近集中式基准的准确性同时确保了个别数据样本对推断攻击具有抵抗能力。此外，文中还研究了在协作分类任务中，精度、隐私预算与通信网络图属性之间的关系，发现当超过某个阈值后，对通信图结构存在一种有用不变性。 <div>
arXiv:2306.13892v2 Announce Type: replace 
Abstract: Cooperative decentralized learning relies on direct information exchange between communicating agents, each with access to locally available datasets. The goal is to agree on model parameters that are optimal over all data. However, sharing parameters with untrustworthy neighbors can incur privacy risks by leaking exploitable information. To enable trustworthy cooperative learning, we propose a framework that embeds differential privacy into decentralized deep learning and secures each agent's local dataset during and after cooperative training. We prove convergence guarantees for algorithms derived from this framework and demonstrate its practical utility when applied to subgradient and ADMM decentralized approaches, finding accuracies approaching the centralized baseline while ensuring individual data samples are resilient to inference attacks. Furthermore, we study the relationships between accuracy, privacy budget, and networks' graph properties on collaborative classification tasks, discovering a useful invariance to the communication graph structure beyond a threshold.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning-Based UAV Pathfinding for Obstacle Avoidance in Stochastic Environment</title>
<link>https://arxiv.org/abs/2310.16659</link>
<guid>https://arxiv.org/abs/2310.16659</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体、强化学习、模型预测控制、分布式决策、通信约束

总结:
本文提出了一种基于多智能体强化学习和模型预测控制思想的新型集中式训练与分布式执行方法。该方法解决了传统方法在动态环境中迭代计算复杂度高的问题以及强化学习在大规模环境交互训练中的效率挑战。在提出的框架中，智能体仅与中心化规划器进行通信以在线做出分布式决策。同时，考虑到与中心化规划器的通信约束，每个智能体会利用基于距离加权均场方法的扩展观测来规划可行路径。受模型预测控制中滚动优化策略的启发，文中采用多步值收敛策略提升多智能体强化学习的训练效率，从而减少了收敛过程中的昂贵交互。实验结果在对比、消融及真实机器人实验中验证了本方法的有效性和泛化性能。 <div>
arXiv:2310.16659v2 Announce Type: replace 
Abstract: Traditional methods plan feasible paths for multiple agents in the stochastic environment. However, the methods' iterations with the changes in the environment result in computation complexities, especially for the decentralized agents without a centralized planner. Although reinforcement learning provides a plausible solution because of the generalization for different environments, it struggles with enormous agent-environment interactions in training. Here, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning, which is improved based on the idea of model predictive control. In our approach, agents communicate only with the centralized planner to make decentralized decisions online in the stochastic environment. Furthermore, considering the communication constraint with the centralized planner, each agent plans feasible paths through the extended observation, which combines information on neighboring agents based on the distance-weighted mean field approach. Inspired by the rolling optimization approach of model predictive control, we conduct multi-step value convergence in multi-agent reinforcement learning to enhance the training efficiency, which reduces the expensive interactions in convergence. Experiment results in both comparison, ablation, and real-robot studies validate the effectiveness and generalization performance of our method.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Learning and NLP in Cryptocurrency Forecasting: Integrating Financial, Blockchain, and Social Media Data</title>
<link>https://arxiv.org/abs/2311.14759</link>
<guid>https://arxiv.org/abs/2311.14759</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币价格预测、机器学习、自然语言处理、BART MNLI、深度学习NLP模型

总结:

本文介绍了利用机器学习（ML）和自然语言处理（NLP）技术进行加密货币价格预测的新方法，重点关注比特币和以太坊。研究中，通过分析Twitter和Reddit上的新闻与社交媒体内容，评估公众情绪对加密货币市场的影响。文章采用BART MNLI零样本分类模型检测市场趋势，超越了传统的 sentiment 分析方法。此外，还系统对比了一系列预训练和微调的深度学习NLP模型与常规基于词典的sentiment分析方法。另一重要贡献在于采用局部极值和每日价格变动作为预测目标，降低了交易频率并减小了投资组合波动性。实验结果表明，将文本数据融入加密货币价格预测不仅提高了预测准确性，而且在多种验证场景下持续提升了投资回报率和夏普比率，特别是应用深度学习NLP技术时。全部实验代码已通过在线仓库公开可供访问。 <div>
arXiv:2311.14759v2 Announce Type: replace-cross 
Abstract: We introduce novel approaches to cryptocurrency price forecasting, leveraging Machine Learning (ML) and Natural Language Processing (NLP) techniques, with a focus on Bitcoin and Ethereum. By analysing news and social media content, primarily from Twitter and Reddit, we assess the impact of public sentiment on cryptocurrency markets. A distinctive feature of our methodology is the application of the BART MNLI zero-shot classification model to detect bullish and bearish trends, significantly advancing beyond traditional sentiment analysis. Additionally, we systematically compare a range of pre-trained and fine-tuned deep learning NLP models against conventional dictionary-based sentiment analysis methods. Another key contribution of our work is the adoption of local extrema alongside daily price movements as predictive targets, reducing trading frequency and portfolio volatility. Our findings demonstrate that integrating textual data into cryptocurrency price forecasting not only improves forecasting accuracy but also consistently enhances the profitability and Sharpe ratio across various validation scenarios, particularly when applying deep learning NLP techniques. The entire codebase of our experiments is made available via an online repository: https://anonymous.4open.science/r/crypto-forecasting-public
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Edge General Intelligence via Large Language Models: Opportunities and Challenges</title>
<link>https://arxiv.org/abs/2410.18125</link>
<guid>https://arxiv.org/abs/2410.18125</guid>
<content:encoded><![CDATA[
<div> 关键词: Edge Intelligence, Edge General Intelligence, Large Language Models, Small Language Models, decentralized

总结:
本文介绍了Edge Intelligence(EI)的概念及其通过结合Large Language Models(LLMs)进化为Edge General Intelligence(EGI)的过程，概述了EGI与传统EI的区别。文章将LLM赋能的EGI分为集中式、混合式和去中心化三种概念系统，并对各系统的框架设计及现有实现进行了详细阐述。此外，还评估了适合在边缘设备上开发的小型语言模型(SLMs)的性能和吞吐量。该调查提供了对EGI全面的认识，揭示了其巨大潜力，并为这一快速发展的领域未来的进步奠定了基础。 <div>
arXiv:2410.18125v1 Announce Type: new 
Abstract: Edge Intelligence (EI) has been instrumental in delivering real-time, localized services by leveraging the computational capabilities of edge networks. The integration of Large Language Models (LLMs) empowers EI to evolve into the next stage: Edge General Intelligence (EGI), enabling more adaptive and versatile applications that require advanced understanding and reasoning capabilities. However, systematic exploration in this area remains insufficient. This survey delineates the distinctions between EGI and traditional EI, categorizing LLM-empowered EGI into three conceptual systems: centralized, hybrid, and decentralized. For each system, we detail the framework designs and review existing implementations. Furthermore, we evaluate the performance and throughput of various Small Language Models (SLMs) that are more suitable for development on edge devices. This survey provides researchers with a comprehensive vision of EGI, offering insights into its vast potential and establishing a foundation for future advancements in this rapidly evolving field.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Enterprise Security with Zero Trust Architecture</title>
<link>https://arxiv.org/abs/2410.18291</link>
<guid>https://arxiv.org/abs/2410.18291</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero Trust Architecture (ZTA)，现代网络安全，身份和访问管理(IAM)，微分割，连续监控

总结:
文章探讨了零信任架构（ZTA）作为现代网络安全的一种转型策略，它针对传统基于边界的安防模型的不足，尤其在云计算、远程工作以及日益复杂的网络威胁背景下。ZTA通过默认不信任任何用户、设备或系统并要求对所有实体进行持续验证和实行最小权限访问来转变安全范式。文中分析了ZTA的关键组成部分，如身份和访问管理（IAM）、微分割、持续监控和行为分析，并评估了它们在金融、医疗和科技等行业中降低风险的有效性。文章还通过案例研究和行业报告讨论了ZTA在抵御内部威胁和缩小攻击面方面的优势。同时，文章指出了实施ZTA所面临的挑战，如可扩展性、集成复杂性和成本问题，并提出了克服这些障碍的最佳实践。最后，文章展望了未来的研究方向，关注AI、机器学习、区块链等新兴技术如何进一步提升ZTA的能力。 <div>
arXiv:2410.18291v1 Announce Type: new 
Abstract: Zero Trust Architecture (ZTA) represents a transformative approach to modern cybersecurity, directly addressing the shortcomings of traditional perimeter-based security models. With the rise of cloud computing, remote work, and increasingly sophisticated cyber threats, perimeter defenses have proven ineffective at mitigating risks, particularly those involving insider threats and lateral movement within networks. ZTA shifts the security paradigm by assuming that no user, device, or system can be trusted by default, requiring continuous verification and the enforcement of least privilege access for all entities. This paper explores the key components of ZTA, such as identity and access management (IAM), micro-segmentation, continuous monitoring, and behavioral analytics, and evaluates their effectiveness in reducing vulnerabilities across diverse sectors, including finance, healthcare, and technology. Through case studies and industry reports, the advantages of ZTA in mitigating insider threats and minimizing attack surfaces are discussed. Additionally, the paper addresses the challenges faced during ZTA implementation, such as scalability, integration complexity, and costs, while providing best practices for overcoming these obstacles. Lastly, future research directions focusing on emerging technologies like AI, machine learning, blockchain, and their integration into ZTA are examined to enhance its capabilities further.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>RediSwap: MEV Redistribution Mechanism for CFMMs</title>
<link>https://arxiv.org/abs/2410.18434</link>
<guid>https://arxiv.org/abs/2410.18434</guid>
<content:encoded><![CDATA[
<div> 关键词: Automated Market Maker (AMM), Maximal Extractable Value (MEV), RediSwap, Liquidity Providers (LPs), Incentive-Compatible

总结:
本文介绍了RediSwap，一种新的自动做市商（AMM）设计，旨在通过在应用层面捕获并公平地将Maximal Extractable Value（MEV）返还给用户和流动性提供者（LPs）。RediSwap的核心是一个MEV再分配机制，用于管理AMM池内的套利机会。文章形式化了机制设计问题及期望的游戏理论性质，并证明了该机制具有激励相容性和Sybil防护性，同时展示了对套利者的友好参与性。通过回放历史AMM交易进行实证比较，结果显示RediSwap在89%的交易中相比UniswapX能实现更好的执行效果，并且大多数情况下可以将LPs的损失降低到原始LVR的0.5%以下。 <div>
arXiv:2410.18434v1 Announce Type: new 
Abstract: Automated Market Makers (AMMs) are essential to decentralized finance, offering continuous liquidity and enabling intermediary-free trading on blockchains. However, participants in AMMs are vulnerable to Maximal Extractable Value (MEV) exploitation. Users face threats such as front-running, back-running, and sandwich attacks, while liquidity providers (LPs) incur the loss-versus-rebalancing (LVR).
  In this paper, we introduce RediSwap, a novel AMM designed to capture MEV at the application level and refund it fairly among users and liquidity providers. At its core, RediSwap features an MEV-redistribution mechanism that manages arbitrage opportunities within the AMM pool. We formalize the mechanism design problem and the desired game-theoretical properties. A central insight underpinning our mechanism is the interpretation of the maximal MEV value as the sum of LVR and individual user losses. We prove that our mechanism is incentive-compatible and Sybil-proof, and demonstrate that it is easy for arbitrageurs to participate.
  We empirically compared RediSwap with existing solutions by replaying historical AMM trades. Our results suggest that RediSwap can achieve better execution than UniswapX in 89% of trades and reduce LPs' loss to under 0.5% of the original LVR in most cases.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains</title>
<link>https://arxiv.org/abs/2410.18631</link>
<guid>https://arxiv.org/abs/2410.18631</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习（MARL）、图神经网络（GNN）、库存控制、供应链、动态适应性

总结:
本文提出了一种结合多智能体强化学习（MARL）和图神经网络（GNN）的框架用于现代供应链中的库存控制问题。该框架通过参数化启发式库存控制策略重新定义行动空间，使其能够根据系统条件动态调整，具有更好的动态适应性。利用供应链的固有图结构，使各智能体能够学习系统拓扑，并采用集中式学习、分布式执行的方式，使得智能体能够在克服信息分享约束的同时进行协同学习。此外，还引入了全局均值池化和正则化技术以提升性能。通过在四种不同的供应链配置上测试以及敏感性分析，验证了所提方法的有效性，为复杂、去中心化的供应链环境中的库存管理提供了新的思路。 <div>
arXiv:2410.18631v1 Announce Type: new 
Abstract: Inventory control in modern supply chains has attracted significant attention due to the increasing number of disruptive shocks and the challenges posed by complex dynamics, uncertainties, and limited collaboration. Traditional methods, which often rely on static parameters, struggle to adapt to changing environments. This paper proposes a Multi-Agent Reinforcement Learning (MARL) framework with Graph Neural Networks (GNNs) for state representation to address these limitations.
  Our approach redefines the action space by parameterizing heuristic inventory control policies, making it adaptive as the parameters dynamically adjust based on system conditions. By leveraging the inherent graph structure of supply chains, our framework enables agents to learn the system's topology, and we employ a centralized learning, decentralized execution scheme that allows agents to learn collaboratively while overcoming information-sharing constraints. Additionally, we incorporate global mean pooling and regularization techniques to enhance performance.
  We test the capabilities of our proposed approach on four different supply chain configurations and conduct a sensitivity analysis. This work paves the way for utilizing MARL-GNN frameworks to improve inventory management in complex, decentralized supply chain environments.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A New Definition of Demand Response in the Distributed Energy Resource Era</title>
<link>https://arxiv.org/abs/2410.18768</link>
<guid>https://arxiv.org/abs/2410.18768</guid>
<content:encoded><![CDATA[
<div> 关键词：需求响应、分布式能源资源、电力市场改革、脱碳、管理策略

总结:
本文讨论了随着电力系统向自由化/去中心化和脱碳方向发展，以及分布式能源资源时代的到来，需求响应这一概念的重要性日益凸显。文章回顾了现有需求响应的定义，指出了它们的不足之处，并提出了一个新的定义，以更好地利用需求响应实现经济、技术、环境和社会目标。作者还基于对需求响应障碍与推动因素的讨论，提出了一项相关研究议程。 <div>
arXiv:2410.18768v1 Announce Type: new 
Abstract: Demand response is a concept that has been around since the very first electric power systems. However, we have seen an explosion of research on demand response and demand-side technologies in the past 30 years, coinciding with the shift towards liberalized/deregulated electricity markets and efforts to decarbonize the power sector. Now we are also seeing a shift towards more distributed/decentralized electric systems; we have entered the era of "distributed energy resources," which require new grid management, operational, and control strategies. Given this paradigm shift, we argue that the concept of demand response needs to be revisited, and more carefully/consistently defined to enable us to better utilize this massive resource for economic, technical, environmental, and societal aims. In this paper, we survey existing demand response definitions, highlight their shortcomings, propose a new definition, and describe how this new definition enables us to more effectively harness the value of demand response in modern power systems. We conclude with a demand response research agenda informed by a discussion of demand response barriers and enablers.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2410.18862</link>
<guid>https://arxiv.org/abs/2410.18862</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、去中心化、个性化、FedSPD、通信成本

总结:
<br />
本文提出了一个名为FedSPD的高效个性化联邦学习算法，特别适用于去中心化的环境。该算法能够在低连通性网络下仍能保持准确模型训练。与现有假设所有客户端训练共享模型的去中心化框架不同，FedSPD强调每个客户端的模型个性化，尤其适合于数据分布异构的情况。为了提供收敛性的理论保证，文章引入了一个基于聚类的框架，允许对不同数据聚类达成模型共识，并根据各个客户端的独特数据混合进行个性化定制，从而显著降低了通信成本。实验结果显示，FedSPD在实际数据集上优于多种去中心化的个性化联邦学习算法，特别是在低连通性网络场景中表现更优。 <div>
arXiv:2410.18862v1 Announce Type: new 
Abstract: Federated learning has recently gained popularity as a framework for distributed clients to collaboratively train a machine learning model using local data. While traditional federated learning relies on a central server for model aggregation, recent advancements adopt a decentralized framework, enabling direct model exchange between clients and eliminating the single point of failure. However, existing decentralized frameworks often assume all clients train a shared model. Personalizing each client's model can enhance performance, especially with heterogeneous client data distributions. We propose FedSPD, an efficient personalized federated learning algorithm for the decentralized setting, and show that it learns accurate models even in low-connectivity networks. To provide theoretical guarantees on convergence, we introduce a clustering-based framework that enables consensus on models for distinct data clusters while personalizing to unique mixtures of these clusters at different clients. This flexibility, allowing selective model updates based on data distribution, substantially reduces communication costs compared to prior work on personalized federated learning in decentralized settings. Experimental results on real-world datasets show that FedSPD outperforms multiple decentralized variants of personalized federated learning algorithms, especially in scenarios with low-connectivity networks.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully Stochastic Primal-dual Gradient Algorithm for Non-convex Optimization on Random Graphs</title>
<link>https://arxiv.org/abs/2410.18774</link>
<guid>https://arxiv.org/abs/2410.18774</guid>
<content:encoded><![CDATA[
<div> 关键词：stochastic decentralized optimization, asynchronous, sparsified communication, local stochastic gradient updates, FSPDA<br /><br />总结:

本文提出了一个名为$\underline{\rm F}$ully $\underline{\rm S}$tochastic $\underline{\rm P}$rimal $\underline{\rm D}$ual gradient $\underline{\rm A}$lgorithm (FSPDA)的全新算法，旨在解决随机分布式优化问题中的同步开销和间歇性通信问题。FSPDA具备两个特点：(1)在随机无向图上进行非阻塞的稀疏化异步通信；(2)执行局部随机梯度更新。该算法允许进行多次局部梯度步骤以加速收敛到平衡点，同时通过随机的原-对偶更新找到共识解。对于具有平滑（可能非凸）目标函数的问题，文章证明了FSPDA在不假设数据异质性的条件下，经过$\mathrm{\it T}$轮迭代后可达到$\mathrm{\mathcal{O}( {\it \sigma /\sqrt{nT}} )}$-准静态解的收敛率。此外，FSPDA的表现与依赖静态图和同步更新的现有最优算法相当。据作者所知，FSPDA是在非凸设置下首个能实现精确收敛的异步算法。数值实验展示了FSPDA的优势。 <div>
arXiv:2410.18774v1 Announce Type: cross 
Abstract: Stochastic decentralized optimization algorithms often suffer from issues such as synchronization overhead and intermittent communication. This paper proposes a $\underline{\rm F}$ully $\underline{\rm S}$tochastic $\underline{\rm P}$rimal $\underline{\rm D}$ual gradient $\underline{\rm A}$lgorithm (FSPDA) that suggests an asynchronous decentralized procedure with (i) sparsified non-blocking communication on random undirected graphs and (ii) local stochastic gradient updates. FSPDA allows multiple local gradient steps to accelerate convergence to stationarity while finding a consensual solution with stochastic primal-dual updates. For problems with smooth (possibly non-convex) objective function, we show that FSPDA converges to an $\mathrm{\mathcal{O}( {\it \sigma /\sqrt{nT}} )}$-stationary solution after $\mathrm{\it T}$ iterations without assuming data heterogeneity. The performance of FSPDA is on par with state-of-the-art algorithms whose convergence depend on static graph and synchronous updates. To our best knowledge, FSPDA is the first asynchronous algorithm that converges exactly under the non-convex setting. Numerical experiments are presented to show the benefits of FSPDA.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Send Message to the Future? Blockchain-based Time Machines for Decentralized Reveal of Locked Information</title>
<link>https://arxiv.org/abs/2401.05947</link>
<guid>https://arxiv.org/abs/2401.05947</guid>
<content:encoded><![CDATA[
<div> 关键词：conditional information reveal systems、timed-release cryptography、secret sharing scheme、blockchain、e-voting

<br /><br />总结:
本文介绍了在安全和去中心化条件下，对信息条件揭示系统有重大突破的研究。研究内容包括设计一种新的实用定时释放密码系统和具有可验证揭示性的秘密共享方案，以此构建了一个基于区块链的未来信息发送系统，能够实现高度精确的解密时间。提出的秘密共享方案也可应用于需要验证揭示的秘密份额的其他场景。论文提供了该创新范式的全面评估框架，涵盖了理论分析结果、Tamarin Prover 验证其鲁棒性以及全球范围内实际部署的开源系统原型性能评估。此外，通过使用真实世界的选举数据，文章还展示了这一创新系统在电子投票中的应用，证明了它对于确保安全、公正电子投票过程的能力。 <div>
arXiv:2401.05947v3 Announce Type: replace 
Abstract: Conditional information reveal systems automate the release of information upon meeting specific predefined conditions, such as time or location. This paper introduces a breakthrough in the understanding, design, and application of conditional information reveal systems that are highly secure and decentralized. By designing a new practical timed-release cryptography system and a secret sharing scheme with reveal-verifiability, a novel data sharing system is devised on the blockchain that "sends messages in the future" with highly accurate decryption times. Notably, the proposed secret sharing scheme applies to other applications requiring verifiability of revealed secret shares. This paper provides a complete evaluation portfolio of this pioneering paradigm, including analytical results, a validation of its robustness in the Tamarin Prover and a performance evaluation of a real-world, open-source system prototype deployed across the globe. Using real-world election data, we also demonstrate the applicability of this innovative system in e-voting, illustrating its capacity to secure and ensure fair electronic voting processes.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>How To Save Fees in Bitcoin Smart Contracts: a Simple Optimistic Off-chain Protocol</title>
<link>https://arxiv.org/abs/2403.09880</link>
<guid>https://arxiv.org/abs/2403.09880</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin、智能合约、交易费用、离链执行、安全协议

总结:

我们关注的是在比特币上执行智能合约的情况。在此场景中，每个合同步骤都对应于向区块链追加一个新的交易，该交易消费代表旧合同状态的输出，并为更新的状态创建新的输出。这一标准程序要求合同参与者为每次执行步骤支付交易费用。本文提出了一种将大部分比特币合同执行移至链下的协议。当所有参与者遵循此协议时，他们能够节省大量的交易费用。然而，当对手试图破坏离链执行时，任何诚实的参与者仍能通过回归到链上执行来确保正确的合同行为得到强制执行，从而保持安全性与正确性。<br /><br /> <div>
arXiv:2403.09880v3 Announce Type: replace 
Abstract: We consider the execution of smart contracts on Bitcoin. There, every contract step corresponds to appending to the blockchain a new transaction that spends the output representing the old contract state, creating a new one for the updated state. This standard procedure requires the contract participants to pay transaction fees for every execution step. In this paper, we introduce a protocol that moves most of the execution of a Bitcoin contract off-chain. When all participants follow this protocol, they are able to save on transaction fees, drastically reducing them. By contrast, whenever adversaries try to disrupt the off-chain execution, any honest participant is still able to enforce the correct contract behaviour, by continuing its execution on-chain.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Failed Migration of Academic Twitter</title>
<link>https://arxiv.org/abs/2406.04005</link>
<guid>https://arxiv.org/abs/2406.04005</guid>
<content:encoded><![CDATA[
<div> 关键词: Twitter, Mastodon, 学术界, 用户迁移, 内部网络<br /><br />总结:

随着Twitter所有权变更及其内容审核政策的变化，学术界的许多人士开始寻求转移讨论阵地，部分人选择了迁移到Mastodon。这项研究考察了这一迁移动态。通过对公开用户账户数据的分析，研究人员追踪了一年内学者们在Mastodon上的发帖活动，并收集了关注关系以描绘内部网络结构。研究发现，迁移至Mastodon的学术群体内部联系紧密，但这种强连接并未能阻止用户重返Twitter或其他平台如Bluesky和Threads。研究显示，由于其去中心化的结构以及来自其他平台的竞争，Mastodon上维持用户参与度存在显著挑战。初期的热情高峰过后，迁移运动失去了势头，大部分用户未能保持活跃度，而坚持使用Mastodon的用户则面临较低的互动水平。研究结果突显了将专业社区过渡到去中心化平台所面临的困难，强调了长期用户参与需要重视社区建设的重要性。 <div>
arXiv:2406.04005v2 Announce Type: replace 
Abstract: Following changes in Twitter's ownership and subsequent changes to content moderation policies, many in academia looked to move their discourse elsewhere and migration to Mastodon was pursued by some. Our study looks at the dynamics of this migration. Utilizing publicly available user account data, we track the posting activity of academics on Mastodon over a one year period. We also gathered follower-followee relationships to map internal networks, finding that the subset of academics who engaged in migration were well-connected. However, this strong internal connectivity was insufficient to prevent users from returning to Twitter/X. Our analyses reveal significant challenges sustaining user engagement on Mastodon due to its decentralized structure as well as competition from other platforms such as Bluesky and Threads. The movement lost momentum after an initial surge of enthusiasm where the main network was fully established as most users did not maintain their activity levels, and those who did faced lower levels of engagement. Our findings highlight the challenges involved in transitioning professional communities to decentralized platforms, emphasizing the need for focus on community building for long-term user engagement.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Code-Driven Law NO, Normware SI!</title>
<link>https://arxiv.org/abs/2410.17257</link>
<guid>https://arxiv.org/abs/2410.17257</guid>
<content:encoded><![CDATA[
<div> 关键词: digitalization, code, law, artificial intelligence, normware

<br />
总结:
随着社会的数字化进程，对于“代码”、“法律”和“人工智能”及其相互关系的关注、讨论与研究日益增多。然而，大多数观点主要集中在现代计算方法和人工制品（如机器学习构建的推理模型、规则系统、智能合约等）上，而非探寻更深层次的基本机制。为突破这一概念局限，本文提出了一个新的视角——“规范软件”（normware），作为与软件和硬件互补的明确立场。通过一些例子，文章论证了以规范软件为中心的观点更能适切地用于研究和设计人工智能设备与人类制度之间的互动，并有助于在更广泛的社会技术视野中设计和发展技术干预措施。 <div>
arXiv:2410.17257v1 Announce Type: new 
Abstract: With the digitalization of society, the interest, the debates and the research efforts concerning "code", "law", "artificial intelligence", and their various relationships, have been widely increasing. Yet, most arguments primarily focus on contemporary computational methods and artifacts (inferential models constructed via machine-learning methods, rule-based systems, smart contracts, ...), rather than attempting to identify more fundamental mechanisms. Aiming to go beyond this conceptual limitation, this paper introduces and elaborates on "normware" as an explicit additional stance -- complementary to software and hardware -- for the interpretation and the design of artificial devices. By means of a few examples, we argue that normware-centred views provide a more adequate abstraction to study and design interactions between computational systems and human institutions, and may help with the design and development of technical interventions within wider socio-technical views.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Securing Federated Learning Against Novel and Classic Backdoor Threats During Foundation Model Integration</title>
<link>https://arxiv.org/abs/2410.17573</link>
<guid>https://arxiv.org/abs/2410.17573</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习(Federated Learning)，基础模型(Foundation Models)，后门攻击(Backdoor Attacks)，防御策略(Defense Strategy)，异常激活(Abnormal Activations)

<br /><br />总结:
该文针对将基础模型融入联邦学习后引入的一种新型后门攻击机制进行了研究。这种攻击利用基础模型生成的合成数据来嵌入后门，进而通过知识共享在无需参与长期联邦学习过程的情况下影响所有客户端模型。鉴于现有联邦学习后门防御方法对此类新型攻击无效，文中提出了一种创新的数据无关防御策略，即在服务器端进行模型聚合时，通过对隐藏特征空间中的异常激活进行约束来抵御攻击。这种方法在协同训练过程中利用合成数据优化激活约束，能够在不影响模型性能的同时减轻攻击的影响。实验表明，这一新策略对于新型和经典后门攻击均具有显著的防御效果，同时保持了模型性能。 <div>
arXiv:2410.17573v1 Announce Type: new 
Abstract: Federated learning (FL) enables decentralized model training while preserving privacy. Recently, integrating Foundation Models (FMs) into FL has boosted performance but also introduced a novel backdoor attack mechanism. Attackers can exploit the FM's capabilities to embed backdoors into synthetic data generated by FMs used for model fusion, subsequently infecting all client models through knowledge sharing without involvement in the long-lasting FL process. These novel attacks render existing FL backdoor defenses ineffective, as they primarily detect anomalies among client updates, which may appear uniformly malicious under this attack. Our work proposes a novel data-free defense strategy by constraining abnormal activations in the hidden feature space during model aggregation on the server. The activation constraints, optimized using synthetic data alongside FL training, mitigate the attack while barely affecting model performance, as the parameters remain untouched. Extensive experiments demonstrate its effectiveness against both novel and classic backdoor attacks, outperforming existing defenses while maintaining model performance.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection</title>
<link>https://arxiv.org/abs/2410.17792</link>
<guid>https://arxiv.org/abs/2410.17792</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 非独立同分布数据, 准确性下降, 动态数据队列驱动联邦学习(DDFL), 数据熵

总结:
本文研究了在非独立同分布数据环境下，联邦学习（Federated Learning, FL）中的统计复杂性问题，指出此类情况下模型准确度可能降低约10%-30%，尤其是在每个边缘设备仅训练单一类别数据的偏斜场景中。为解决这一问题，文章提出了一种名为动态数据队列驱动联邦学习（DDFL）的方法，该方法通过在服务器端创建全局数据子集并动态地分配到各个设备进行训练，从而减少权重分歧带来的偏差项（\(\delta_k\)）。同时，利用数据熵指标监控每轮训练过程并指导合理设备选择参与聚合。此外，文中还对所提DDFL进行了收敛性分析，证明其在实际FL场景中的可行性和对于改进设备选择、实现非次优全局模型以及加快收敛速度的效果。实验结果显示，DDFL方法相较于当前最先进的聚合算法，在MNIST、CIFAR-10和CIFAR-100数据集上分别实现了约5%、18%和20%的准确性提升，其中仅使用了10%的全局数据子集。<br /><br /> <div>
arXiv:2410.17792v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized approach for collaborative model training on edge devices. This distributed method of model training offers advantages in privacy, security, regulatory compliance, and cost-efficiency. Our emphasis in this research lies in addressing statistical complexity in FL, especially when the data stored locally across devices is not identically and independently distributed (non-IID). We have observed an accuracy reduction of up to approximately 10\% to 30\%, particularly in skewed scenarios where each edge device trains with only 1 class of data. This reduction is attributed to weight divergence, quantified using the Euclidean distance between device-level class distributions and the population distribution, resulting in a bias term (\(\delta_k\)). As a solution, we present a method to improve convergence in FL by creating a global subset of data on the server and dynamically distributing it across devices using a Dynamic Data queue-driven Federated Learning (DDFL). Next, we leverage Data Entropy metrics to observe the process during each training round and enable reasonable device selection for aggregation. Furthermore, we provide a convergence analysis of our proposed DDFL to justify their viability in practical FL scenarios, aiming for better device selection, a non-sub-optimal global model, and faster convergence. We observe that our approach results in a substantial accuracy boost of approximately 5\% for the MNIST dataset, around 18\% for CIFAR-10, and 20\% for CIFAR-100 with a 10\% global subset of data, outperforming the state-of-the-art (SOTA) aggregation algorithms.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning</title>
<link>https://arxiv.org/abs/2410.17933</link>
<guid>https://arxiv.org/abs/2410.17933</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，医疗数据共享，区块链，联合学习，隐私保护

总结:
本文提出了一种利用来自欧洲、北美和亚洲多地的数据集进行全球医疗健康建模的框架，而无需分享本地数据集，以血糖管理为研究模型验证其有效性。该框架采用了适应医疗数据隐私与安全要求的区块链赋能的联合学习技术，并通过链上激励机制奖励诚实参与并惩罚恶意行为。实验结果显示，所提出的框架有效、高效且能保护隐私，其预测精度优于仅使用有限个人数据训练的模型，甚至接近或略高于集中式数据集的结果。这项工作为国际间医疗项目的合作开辟了道路，对于减少偏见并为人类带来更多福祉提供了重要支持。 <div>
arXiv:2410.17933v1 Announce Type: new 
Abstract: One of the biggest challenges of building artificial intelligence (AI) model in healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausted, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America and Asia) while without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaption to make it meet with the privacy and safety requirements of healthcare data, meanwhile rewards honest participation and penalize malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy preserved. Its prediction accuracy is much better than the models trained from limited personal data and is similar to, and even slightly better than, the results from a centralized dataset. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.
]]></content:encoded>
<pubDate>Thu, 24 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancements in Electric Vehicle Charging Optimization: A Survey of Reinforcement Learning Approaches</title>
<link>https://arxiv.org/abs/2410.16425</link>
<guid>https://arxiv.org/abs/2410.16425</guid>
<content:encoded><![CDATA[
<div> 关键词: 全球变暖、可再生能源、电动汽车、智能电网、强化学习

总结:
随着全球变暖和能源短缺问题凸显，可再生能源、储能系统以及电动汽车的整合日益受到重视。将电动汽车融入智能电网中，有助于减少碳排放。然而，电动汽车作为分布式电源的充放电管理面临挑战，同时还要应对间歇性可再生能源、电动车参数不确定性、电价波动及负荷变化等问题。有效的电动汽车电池充电管理系统对于协调这些过程并确保电力系统的稳定运行至关重要。其中，强化学习结合深度学习因其无模型化方法和实时优化能力，在电动车辆充电协调策略方面展现出巨大潜力。文章综述了现有基于强化学习的电动汽车充电协调策略的研究，按照集中式和分散式两大类进行了分类讨论，并对未来研究方向提出了建议。 <div>
arXiv:2410.16425v1 Announce Type: new 
Abstract: In response to global warming and energy shortages, there has been a significant shift towards integrating renewable energy sources, energy storage systems, and electric vehicles. Deploying electric vehicles within smart grids offers a promising solution to reduce carbon emissions. However, managing the charging and discharging processes of them as distributed power supplies present significant challenges. Additionally, the intermittent nature of renewable energy, uncertainties in electric vehicle-related parameters, fluctuating energy prices, and varying loads make maintaining stable power system operations more complex. Effective management systems for electric vehicle battery charging are crucial to coordinating these processes and ensuring a secure, efficient, and reliable power system. Reinforcement learning, enhanced by deep learning, has gained substantial interest for its model-free approach and real-time optimization, effectively managing electric vehicle charging by maximizing cumulative rewards. This review synthesizes existing literature on reinforcement learning-based frameworks, objectives, and architectures for electric vehicle charging coordination strategies in power systems, classifying methods into centralized and decentralized categories. Additionally, the article offers suggestions for future research directions to further enhance reinforcement learning-based electric vehicle charging optimization.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>RGMDT: Return-Gap-Minimizing Decision Tree Extraction in Non-Euclidean Metric Space</title>
<link>https://arxiv.org/abs/2410.16517</link>
<guid>https://arxiv.org/abs/2410.16517</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习（Deep Reinforcement Learning, DRL）、可解释性、决策树（Decision Tree, DT）、多智能体、回报差距上界

总结:

本文关注深度强化学习的可解释性问题，提出了一种新的方法用于从DRL策略中提取具有决策树结构的策略。研究者建立了专家策略与最优决策树策略之间回报差距上界的理论框架。在此基础上，他们将决策树提取问题转化为非欧几里得聚类问题，并设计了一个迭代生长决策树的算法来适应多智能体的分布式场景。此外，文章提出了“回报差距最小化决策树”（Return-Gap-Minimization Decision Tree, RGMDT）算法，该算法通过结合强化学习和新颖的正则化信息最大化损失函数进行集成。实验表明，RGMDT算法在如D4RL等任务上显著优于基于启发式的DT基线，并能在给定的决策树复杂度约束下实现接近最优的回报。 <div>
arXiv:2410.16517v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) algorithms have achieved great success in solving many challenging tasks while their black-box nature hinders interpretability and real-world applicability, making it difficult for human experts to interpret and understand DRL policies. Existing works on interpretable reinforcement learning have shown promise in extracting decision tree (DT) based policies from DRL policies with most focus on the single-agent settings while prior attempts to introduce DT policies in multi-agent scenarios mainly focus on heuristic designs which do not provide any quantitative guarantees on the expected return. In this paper, we establish an upper bound on the return gap between the oracle expert policy and an optimal decision tree policy. This enables us to recast the DT extraction problem into a novel non-euclidean clustering problem over the local observation and action values space of each agent, with action values as cluster labels and the upper bound on the return gap as clustering loss. Both the algorithm and the upper bound are extended to multi-agent decentralized DT extractions by an iteratively-grow-DT procedure guided by an action-value function conditioned on the current DTs of other agents. Further, we propose the Return-Gap-Minimization Decision Tree (RGMDT) algorithm, which is a surprisingly simple design and is integrated with reinforcement learning through the utilization of a novel Regularized Information Maximization loss. Evaluations on tasks like D4RL show that RGMDT significantly outperforms heuristic DT-based baselines and can achieve nearly optimal returns under given DT complexity constraints (e.g., maximum number of DT nodes).
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>NodeOP: Optimizing Node Management for Decentralized Networks</title>
<link>https://arxiv.org/abs/2410.16720</link>
<guid>https://arxiv.org/abs/2410.16720</guid>
<content:encoded><![CDATA[
<div> 关键词：NodeOP、Agent-Based Modeling (ABM)、Tendermint BFT、共识机制、分布式网络

总结:<br />
本文介绍了NodeOP，这是一个针对去中心化网络中通用节点运营商管理的新颖优化框架。该框架通过将Agent-Based Modeling (ABM)与基于Tendermint拜占庭容错(BFT)的共识机制相结合，解决了任务分配、共识形成和系统稳定性等关键挑战。通过严谨的数学建模和形式化优化，NodeOP确保了节点任务分布的稳定均衡。文章通过收敛分析和交易吞吐量、系统延迟及容错性等性能指标验证了框架的有效性。此外，作者通过两个实际应用案例——Layer 2网络中的去中心化序列器管理和离链支付验证，展示了NodeOP如何提高验证效率并创造大规模去中心化环境下的新的收益机会。这些结果表明，NodeOP是一个可扩展且灵活的解决方案，能显著提升分布式系统的运营效率和经济可持续性。 <div>
arXiv:2410.16720v1 Announce Type: new 
Abstract: We present NodeOP, a novel framework designed to optimize the management of General Node Operators in decentralized networks. By integrating Agent-Based Modeling (ABM) with a Tendermint Byzantine Fault Tolerance (BFT)-based consensus mechanism, NodeOP addresses key challenges in task allocation, consensus formation, and system stability. Through rigorous mathematical modeling and formal optimization, NodeOP ensures stable equilibrium in node task distribution. We validate the framework via convergence analysis and performance metrics such as transaction throughput, system latency, and fault tolerance. We further demonstrate NodeOP's practical utility through two use cases: decentralized sequencer management in Layer 2 networks and off-chain payment validation. These examples underscore how NodeOP enhances validation efficiency and unlocks new revenue opportunities in large-scale decentralized environments. Our results position NodeOP as a scalable and flexible solution, significantly improving operational efficiency and economic sustainability in decentralized systems.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering the Grid: Decentralized Autonomous Control for Effective Utilization and Resilience</title>
<link>https://arxiv.org/abs/2410.17143</link>
<guid>https://arxiv.org/abs/2410.17143</guid>
<content:encoded><![CDATA[
<div> 关键词：低惯性微电网、电网形成型逆变器(GFMs)、分布式自主控制器(DACs)、韧性约束操作、实时执行

<br /><br />总结:
本文关注于由逆变器基础发电构成的低惯性微电网的运行韧性感问题。为了解决这一问题，文章提出了基于局部、最小侵入式调整的分散式自主控制器（DACs），这些控制器可在现有的初级和次级控制层级结构中并存，以确保在各种 cyber-物理中断下的韧性约束操作，例如在暂态过程中维持关键的安全运行限值。该 DAC 控制方案具有计算效率高（仅需代数运算）的特点，能实现快速实时执行。通过使用 GridLAB-D-HELICS 基的控制-电网联合仿真，在IEEE 123节点网络化微电网中验证了该方法的有效性。最后，研究表明，开发的 DAC 能够充分利用可用资源，确保电网韧性，保持频率安全限制。 <div>
arXiv:2410.17143v1 Announce Type: new 
Abstract: With the emergence of low-inertia microgrids powered by inverter-based generation, there remains a concern about the operational resilience of these systems. Grid-forming inverters (GFMs), enabled by various device-level (primary) and system-level (secondary) control methods, are poised to play a significant role in achieving certain operational objectives, such as the effective utilization of clean energy resources while maintaining stability. However, despite the recent advances in GFMs, there is a lack of suitable controls that can ascertain resilience-constrained operations, like maintaining critical operational safety limits during transients under various cyber-physical disruptions. In this work, we develop decentralized autonomous controllers (DACs) that enforce resilience-constrained operation via local, minimally invasive adjustments (e.g., changes in set-points) while co-existing within the hierarchy of existing (primary and secondary) controls. The DACs work autonomously by sensing only local GFM measurements and act only when operational resilience constraints are violated. The proposed DAC scheme is computationally efficient (only algebraic computations), which enables fast, real-time execution and demonstrates the efficacy of the proposed control framework on GridLAB-D-HELICS-based control-grid co-simulations on the IEEE 123-node networked microgrid. Finally, we show how the developed DACs empower the grid by utilizing the available resources entirely to ensure resilience (maintain frequency safe limits).
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vulnerability anti-patterns in Solidity: Increasing smart contracts security by reducing false alarms</title>
<link>https://arxiv.org/abs/2410.17204</link>
<guid>https://arxiv.org/abs/2410.17204</guid>
<content:encoded><![CDATA[
<div> 关键词：Turing完备性、Ethereum智能合约、安全性工具、静态分析、误报率

总结:

本文探讨了以太坊智能合约由于图灵完备性而备受区块链开发者和攻击者的关注。为提升代码安全性，已有许多工具能够检测出大部分已知漏洞，但这些工具的误报率高达99%，导致其在实际工业应用中不切实际，进而引发了学术研究方向的疑问。文章提出了一种融合与拓展当前分析方法的轻量级静态检查方案，该方案基于开发人员中心化的漏洞概念，用于验证其他工具的输出、标记潜在的误报并提供验证建议。作者实现了一个开源原型并在其中针对排名前10的三个高危漏洞，在从区块链中挑选出的60个存在真实（和虚假）漏洞的去重智能合约上进行了测试。结果显示，对于这三个漏洞，该原型成功将其他工具产生的324个警告标记为误报，实现了对这三种漏洞误报率92%至100%的降低。 <div>
arXiv:2410.17204v1 Announce Type: new 
Abstract: Turing completeness has made Ethereum smart contracts attractive to blockchain developers and attackers alike. To increase code security, many tools can now spot most known vulnerabilities$-$at the cost of production efficiency. Recent studies show false-positive ratios over 99% in state-of-the-art technologies: this makes them impractical for use in industry and have raised questions on the direction of academic research. In this work we show how integrating and extending current analyses is not only feasible, but also a next logical step in smart-contract security. We propose light-weight static checks on the morphology and dynamics of Solidity code, stemming from a developer-centric notion of vulnerability, that we use to verify the output of other tools, flag potential false alarms, and suggest verifications. Besides technical details we implemented an open-source prototype. For three top-10 vulnerabilities it flags 324 warnings of other tools as false-positives, in 60 verified de-duplicated smart contracts selected from the blockchain by the presence of true (and false) vulnerabilities. This amounts to a 92%- to 100%-reduction in the number of false-positives for these vulnerabilities.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Causal Inference: Multi-Centric ATE Estimation beyond Meta-Analysis</title>
<link>https://arxiv.org/abs/2410.16870</link>
<guid>https://arxiv.org/abs/2410.16870</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Causal Inference、平均治疗效果(Average Treatment Effect, ATE)、插值G公式、联邦学习、随机对照试验(Randomized Controlled Trials, RCT)

总结:

本文研究了Federated Causal Inference，这是一种用于从分布式数据中估计治疗效果的方法。文章对比分析了三种基于Plug-in G-Formula的ATE估计器，包括简单的元分析以及一拍和多拍联邦学习方法，后者利用全部数据来学习结果模型（尽管需要更多的通信）。针对随机对照试验(RCT)，文中为线性模型下的这些估计器导出了渐近方差。研究结果为不同场景下选择合适的估计器提供了实践指导，考虑到了样本量差异、协变量分布、治疗分配方案及中心效应等异质性因素。此外，作者通过模拟研究验证了这些发现。 <div>
arXiv:2410.16870v1 Announce Type: cross 
Abstract: We study Federated Causal Inference, an approach to estimate treatment effects from decentralized data across centers. We compare three classes of Average Treatment Effect (ATE) estimators derived from the Plug-in G-Formula, ranging from simple meta-analysis to one-shot and multi-shot federated learning, the latter leveraging the full data to learn the outcome model (albeit requiring more communication). Focusing on Randomized Controlled Trials (RCTs), we derive the asymptotic variance of these estimators for linear models. Our results provide practical guidance on selecting the appropriate estimator for various scenarios, including heterogeneity in sample sizes, covariate distributions, treatment assignment schemes, and center effects. We validate these findings with a simulation study.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>PRIMER: Perception-Aware Robust Learning-based Multiagent Trajectory Planner</title>
<link>https://arxiv.org/abs/2406.10060</link>
<guid>https://arxiv.org/abs/2406.10060</guid>
<content:encoded><![CDATA[
<div> 关键词： decentralized multiagent trajectory planners, localization errors, PARM, PARM*, PRIMER

总结:

本文提出了解决在存在定位误差的分布式多智能体轨迹规划问题的方法。首先，为了解决由于不确定性导致的轨迹冲突，文章介绍了两个感知感知型、分布式的异步多智能体轨迹规划器——PARM和PARM*，它们利用感知信息使团队中的智能体能在不确定环境中实现避障与轨迹解冲突。其中，PARM*相较于PARM更为优化但计算量较大。然而，这类基于优化的方法面临高计算成本的问题，使得智能体难以高频重规划。为此，文章提出了第二个关键贡献——PRIMER，这是一种基于模仿学习（IL）训练的学习型规划器，它以PARM*作为专家演示者进行训练。PRIMER利用神经网络在部署时的低计算需求，实现了相对于优化方法高达5500倍的计算速度提升。 <div>
arXiv:2406.10060v2 Announce Type: replace 
Abstract: In decentralized multiagent trajectory planners, agents need to communicate and exchange their positions to generate collision-free trajectories. However, due to localization errors/uncertainties, trajectory deconfliction can fail even if trajectories are perfectly shared between agents. To address this issue, we first present PARM and PARM*, perception-aware, decentralized, asynchronous multiagent trajectory planners that enable a team of agents to navigate uncertain environments while deconflicting trajectories and avoiding obstacles using perception information. PARM* differs from PARM as it is less conservative, using more computation to find closer-to-optimal solutions. While these methods achieve state-of-the-art performance, they suffer from high computational costs as they need to solve large optimization problems onboard, making it difficult for agents to replan at high rates. To overcome this challenge, we present our second key contribution, PRIMER, a learning-based planner trained with imitation learning (IL) using PARM* as the expert demonstrator. PRIMER leverages the low computational requirements at deployment of neural networks and achieves a computation speed up to 5500 times faster than optimization-based approaches.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility</title>
<link>https://arxiv.org/abs/2202.08967</link>
<guid>https://arxiv.org/abs/2202.08967</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、加密货币、波动性、CoMForE模型、多模态预测

<br /><br />总结:

本文研究了影响比特币-美元汇率波动性的多种独立因素，并提出了一个多模态AdaBoost-LSTM集成模型——CoMForE。该模型不仅利用历史交易数据，还结合了与比特币相关的推文情绪、搜索量以及区块链哈希率等数据。通过全面实验验证，CoMForE模型能够更准确地预测加密货币价值分布的变化，相比现有预测工具和方法有显著优势，表现出了19.29%的提升，强调了外部独立因素对加密货币市场波动性的影响。 <div>
arXiv:2202.08967v2 Announce Type: replace-cross 
Abstract: Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have become a worldwide phenomenon as important decentralized financial assets. Their decentralized nature, however, leads to notable volatility against traditional fiat currencies, making the task of accurately forecasting the crypto-fiat exchange rate complex. This study examines the various independent factors that affect the volatility of the Bitcoin-Dollar exchange rate. To this end, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not only utilizes historical trading data but also incorporates public sentiments from related tweets, public interest demonstrated by search volumes, and blockchain hash-rate data. Our developed model goes a step further by predicting fluctuations in the overall cryptocurrency value distribution, thus increasing its value for investment decision-making. We have subjected this method to extensive testing via comprehensive experiments, thereby validating the importance of multimodal combination over exclusive reliance on trading data. Further experiments show that our method significantly surpasses existing forecasting tools and methodologies, demonstrating a 19.29% improvement. This result underscores the influence of external independent factors on cryptocurrency volatility.
]]></content:encoded>
<pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Domain Isolation and Sample Clustered Federated Learning for Semantic Segmentation</title>
<link>https://arxiv.org/abs/2410.14693</link>
<guid>https://arxiv.org/abs/2410.14693</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、非独立同分布、协变量偏移、深度域隔离、样例聚类联邦学习

<br /><br />总结:
该文首次探究了联邦学习在二维分割任务中因参与者数据间的协变量偏移而带来的收敛问题，发现其影响虽小于标签偏移但仍存在。现有的个性化联邦学习（PFL）和集群联邦学习（CFL）方法假设每个参与者的数据集内部是一致且与未来测试样本相匹配的。为了解决这一问题，文中提出了深度域隔离（DDI）技术，能够在模型梯度空间中直接隔离图像域。进一步地，文章提出了一种样例聚类联邦学习（SCFL）框架，结合了联邦高斯混合模型和谱聚类算法，以标准联邦学习方式训练针对不同分散图像域的独立模型。最后，通过训练一个分类器，可以在推理时将测试样本关联到对应的域簇，从而实现对每个参与者测试分布假设的无关性。实验证明，该方法在玩具分割数据集以及Cityscapes和GTA5数据集的不同划分上使用EfficientVIT-B0模型进行实验，相比其他方法有显著的性能提升。研究成果已开源发布于GitHub仓库https://github.com/MatthisManthe/DDI_SCFL 。 <div>
arXiv:2410.14693v1 Announce Type: new 
Abstract: Empirical studies show that federated learning exhibits convergence issues in Non Independent and Identically Distributed (IID) setups. However, these studies only focus on label distribution shifts, or concept shifts (e.g. ambiguous tasks). In this paper, we explore for the first time the effect of covariate shifts between participants' data in 2D segmentation tasks, showing an impact way less serious than label shifts but still present on convergence. Moreover, current Personalized (PFL) and Clustered (CFL) Federated Learning methods intrinsically assume the homogeneity of the dataset of each participant and its consistency with future test samples by operating at the client level. We introduce a more general and realistic framework where each participant owns a mixture of multiple underlying feature domain distributions. To diagnose such pathological feature distributions affecting a model being trained in a federated fashion, we develop Deep Domain Isolation (DDI) to isolate image domains directly in the gradient space of the model. A federated Gaussian Mixture Model is fit to the sample gradients of each class, while the results are combined with spectral clustering on the server side to isolate decentralized sample-level domains. We leverage this clustering algorithm through a Sample Clustered Federated Learning (SCFL) framework, performing standard federated learning of several independent models, one for each decentralized image domain. Finally, we train a classifier enabling to associate a test sample to its corresponding domain cluster at inference time, offering a final set of models that are agnostic to any assumptions on the test distribution of each participant. We validate our approach on a toy segmentation dataset as well as different partitionings of a combination of Cityscapes and GTA5 datasets using an EfficientVIT-B0 model, showing a significant performance gain compared to other approaches. Our code is available at https://github.com/MatthisManthe/DDI_SCFL .
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FACMIC: Federated Adaptative CLIP Model for Medical Image Classification</title>
<link>https://arxiv.org/abs/2410.14707</link>
<guid>https://arxiv.org/abs/2410.14707</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、通信成本、视觉基础模型、对比语言图像预训练（Contrastive Language Image Pretraining, CLIP）、特征注意力模块（Feature Attention Module）

总结:<br />
本文提出了一种用于分类任务的联邦学习环境下自适应的CLIP模型，名为FACMIC。该模型旨在解决在保证数据隐私的同时，进行深度模型训练时面临的通信成本问题。FACMIC采用了一个轻量级且高效的特征注意力模块，可以根据每个客户端的数据选择合适的特征。此外，还提出了一个领域适应技术以减小客户端间数据分布的差异。实验结果表明，FACMIC在处理真实世界和多源医学影像数据方面表现优越。相关代码已开源，可在https://github.com/AIPMLab/FACMIC获取。 <div>
arXiv:2410.14707v1 Announce Type: new 
Abstract: Federated learning (FL) has emerged as a promising approach to medical image analysis that allows deep model training using decentralized data while ensuring data privacy. However, in the field of FL, communication cost plays a critical role in evaluating the performance of the model. Thus, transferring vision foundation models can be particularly challenging due to the significant resource costs involved. In this paper, we introduce a federated adaptive Contrastive Language Image Pretraining CLIP model designed for classification tasks. We employ a light-weight and efficient feature attention module for CLIP that selects suitable features for each client's data. Additionally, we propose a domain adaptation technique to reduce differences in data distribution between clients. Experimental results on four publicly available datasets demonstrate the superior performance of FACMIC in dealing with real-world and multisource medical imaging data. Our codes are available at https://github.com/AIPMLab/FACMIC.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title>
<link>https://arxiv.org/abs/2410.14803</link>
<guid>https://arxiv.org/abs/2410.14803</guid>
<content:encoded><![CDATA[
<div> 关键词: on-device control agents, Multimodal Large Language Models (MLLMs), DistRL, reinforcement learning (RL), training efficiency

<br /><br />总结:

本文介绍了一种针对移动设备控制代理的新型框架DistRL，该框架旨在提高集成多模态大型语言模型（MLLMs）的在线强化学习（RL）微调效率。针对数据有限和在线训练过程低效的问题，DistRL采用集中式训练与分布式数据采集相结合的方式，确保动态在线交互下的高效微调。此外，DistRL还配备了一个定制的RL算法，有效地平衡了探索性与收集数据的优先使用，以实现稳定而健壮的训练。实验结果显示，相比于领先的同步多机器方法，DistRL的训练效率提高了3倍，训练数据收集速度提高了2.4倍。在完成实际设备控制任务方面，经过训练后，DistRL在公开基准测试中的成功率相对提升了20%，显著优于现有方法的同时，保持了相同的训练时间。这些结果验证了DistRL是一个可扩展、高效的解决方案，为现实世界中的设备控制任务提供了显著提升的训练效率和代理性能。 <div>
arXiv:2410.14803v1 Announce Type: new 
Abstract: On-device control agents, especially on mobile devices, are responsible for operating mobile devices to fulfill users' requests, enabling seamless and intuitive interactions. Integrating Multimodal Large Language Models (MLLMs) into these agents enhances their ability to understand and execute complex commands, thereby improving user experience. However, fine-tuning MLLMs for on-device control presents significant challenges due to limited data availability and inefficient online training processes. This paper introduces DistRL, a novel framework designed to enhance the efficiency of online RL fine-tuning for mobile device control agents. DistRL employs centralized training and decentralized data acquisition to ensure efficient fine-tuning in the context of dynamic online interactions. Additionally, the framework is backed by our tailor-made RL algorithm, which effectively balances exploration with the prioritized utilization of collected data to ensure stable and robust training. Our experiments show that, on average, DistRL delivers a 3X improvement in training efficiency and enables training data collection 2.4X faster than the leading synchronous multi-machine methods. Notably, after training, DistRL achieves a 20% relative improvement in success rate compared to state-of-the-art methods on general Android tasks from an open benchmark, significantly outperforming existing approaches while maintaining the same training time. These results validate DistRL as a scalable and efficient solution, offering substantial improvements in both training efficiency and agent performance for real-world, in-the-wild device control tasks.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordinated Frequency Regulation in Grid-Forming Storage Network via Safety-Consensus</title>
<link>https://arxiv.org/abs/2410.14877</link>
<guid>https://arxiv.org/abs/2410.14877</guid>
<content:encoded><![CDATA[
<div> 关键词: 变流器存储、电网、有源发电机控制、共识算法、安全限制<br /><br />总结:

本文探讨了变流器储能系统在未来大规模可再生能源并网中的关键作用。为了实现类似同步发电机特性的电网形成型逆变器(GFM)通过初级控制环路参与频率调节和故障后恢复频率至正常水平。然而，确保在电网从预扰动到后扰动运行点过渡期间，暂态频率跃变不会超出安全极限至关重要。文章提出了一种层次化的安全强制共识方法，该方法结合设备层（分布式）瞬态安全性滤波器与二级层（分布式）共识协调，以实现三个目标：将暂态频率跃变限制在安全范围内、最小化频率偏离额定值以及确保GFM接口存储单元间的协同功率共享。通过在IEEE 68节点系统上使用GFM接口储能网络模拟多种电网暂态场景，验证了所提出的两层安全共识技术的有效性。 <div>
arXiv:2410.14877v1 Announce Type: new 
Abstract: Inverter-based storages are poised to play a prominent role in future power grids with massive renewable generation. Grid-forming inverters (GFMs) are emerging as a dominant technology with synchronous generators (SG)-like characteristics through primary control loops. Advanced secondary control schemes, e.g., consensus algorithms, allow GFM-interfaced storage units to participate in frequency regulations and restore nominal frequency following grid disturbances. However, it is imperative to ensure transient frequency excursions do not violate critical safety limits while the grid transitions from pre- to post-disturbance operating point. This paper presents a hierarchical safety-enforced consensus method -- combining a device-layer (decentralized) transient safety filter with a secondary-layer (distributed) consensus coordination -- to achieve three distinct objectives: limiting transient frequency excursions to safe limits, minimizing frequency deviations from nominal, and ensuring coordinated power sharing among GFM-storage units. The proposed hierarchical (two-layered) safety-consensus technique is illustrated using a GFM-interfaced storage network on an IEEE 68-bus system under multiple grid transient scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperation and Fairness in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.14916</link>
<guid>https://arxiv.org/abs/2410.14916</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、公平性、强化学习、导航、效率

总结:
本文研究了在多智能体环境中使用强化学习实现公平导航的问题。为了解决效率与公平之间的平衡，作者提出了一个结合最小最大公平距离目标分配和鼓励公平性的奖励机制的训练方法。通过这种方法，智能体能够在仅依赖局部观测的情况下，学习到公平的目标分配并几乎完美地覆盖导航任务。实验结果显示，相比于随机目标分配基线，该模型在保持平均14%的效率提升的同时，实现了平均5%的公平性提升；相较于最优效率分配模型，虽然以7%的效率下降为代价，但公平性提升了21%。此外，该方法还被扩展到了需要按预定阵型完成覆盖任务的环境，并展示了无需针对特定阵型定制模型即可实现这一目标的可能性。 <div>
arXiv:2410.14916v1 Announce Type: new 
Abstract: Multi-agent systems are trained to maximize shared cost objectives, which typically reflect system-level efficiency. However, in the resource-constrained environments of mobility and transportation systems, efficiency may be achieved at the expense of fairness -- certain agents may incur significantly greater costs or lower rewards compared to others. Tasks could be distributed inequitably, leading to some agents receiving an unfair advantage while others incur disproportionately high costs. It is important to consider the tradeoffs between efficiency and fairness. We consider the problem of fair multi-agent navigation for a group of decentralized agents using multi-agent reinforcement learning (MARL). We consider the reciprocal of the coefficient of variation of the distances traveled by different agents as a measure of fairness and investigate whether agents can learn to be fair without significantly sacrificing efficiency (i.e., increasing the total distance traveled). We find that by training agents using min-max fair distance goal assignments along with a reward term that incentivizes fairness as they move towards their goals, the agents (1) learn a fair assignment of goals and (2) achieve almost perfect goal coverage in navigation scenarios using only local observations. For goal coverage scenarios, we find that, on average, our model yields a 14% improvement in efficiency and a 5% improvement in fairness over a baseline trained using random assignments. Furthermore, an average of 21% improvement in fairness can be achieved compared to a model trained on optimally efficient assignments; this increase in fairness comes at the expense of only a 7% decrease in efficiency. Finally, we extend our method to environments in which agents must complete coverage tasks in prescribed formations and show that it is possible to do so without tailoring the models to specific formation shapes.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration</title>
<link>https://arxiv.org/abs/2410.15048</link>
<guid>https://arxiv.org/abs/2410.15048</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 分布式多智能体系统 (MAS), 变形代理 (MorphAgent), 自我演进的代理配置文件, 动态角色演化

总结:
本文介绍了MorphAgent，这是一种用于分布式多智能体协作的新颖框架，允许代理动态地进化其角色和能力。该框架利用自我演进的代理配置文件，通过三个关键指标进行优化，引导代理在保持互补团队动态的同时细化各自的专长。MorphAgent实现了一个两阶段过程：初始配置文件优化的预热阶段，以及根据任务反馈持续调整角色的任务执行阶段。实验结果显示，与传统的静态角色MAS相比，MorphAgent在任务性能和适应变化需求方面表现出优越性，为构建更强大和灵活的多智能体协作系统开辟了道路。相关代码将在 https://github.com/LINs-lab/learn2collaborate 公开可用。<br /><br /> <div>
arXiv:2410.15048v1 Announce Type: new 
Abstract: Large Language Model (LLM) based multi-agent systems (MAS) have shown promise in tackling complex tasks, but often rely on predefined roles and centralized coordination, limiting their adaptability to evolving challenges. This paper introduces MorphAgent, a novel framework for decentralized multi-agent collaboration that enables agents to dynamically evolve their roles and capabilities. Our approach employs self-evolving agent profiles, optimized through three key metrics, guiding agents in refining their individual expertise while maintaining complementary team dynamics. MorphAgent implements a two-phase process: a warm-up phase for initial profile optimization, followed by a task execution phase where agents continuously adapt their roles based on task feedback. Our experimental results show that MorphAgent outperforms traditional static-role MAS in terms of task performance and adaptability to changing requirements, paving the way for more robust and versatile multi-agent collaborative systems. Our code will be publicly available at \url{https://github.com/LINs-lab/learn2collaborate}.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer</title>
<link>https://arxiv.org/abs/2410.15073</link>
<guid>https://arxiv.org/abs/2410.15073</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Personalized FL（个性化联邦学习）、Non-IID数据、FedAFK、性能提升

<br /><br />总结:
本文提出了一种名为FedAFK的新方法，用于解决联邦学习中的统计异质性挑战，特别是针对非独立同分布(Non-IID)数据的个性化联邦学习（pFL）问题。FedAFK通过自适应特征聚合和知识转移机制，旨在更好地训练特征提取器，同时在保证全局模型知识利用的同时实现客户端的个性化。实验结果表明，在三个数据集和两种常用的异构设置下，FedAFK相比于十三种主流基线方法具有更优的性能表现。 <div>
arXiv:2410.15073v1 Announce Type: new 
Abstract: Federated Learning(FL) is popular as a privacy-preserving machine learning paradigm for generating a single model on decentralized data. However, statistical heterogeneity poses a significant challenge for FL. As a subfield of FL, personalized FL (pFL) has attracted attention for its ability to achieve personalized models that perform well on non-independent and identically distributed (Non-IID) data. However, existing pFL methods are limited in terms of leveraging the global model's knowledge to enhance generalization while achieving personalization on local data. To address this, we proposed a new method personalized Federated learning with Adaptive Feature Aggregation and Knowledge Transfer (FedAFK), to train better feature extractors while balancing generalization and personalization for participating clients, which improves the performance of personalized models on Non-IID data. We conduct extensive experiments on three datasets in two widely-used heterogeneous settings and show the superior performance of our proposed method over thirteen state-of-the-art baselines.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning</title>
<link>https://arxiv.org/abs/2410.15093</link>
<guid>https://arxiv.org/abs/2410.15093</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, contribution evaluation, Shapley value, Dynamic Pruning Validation Set Shapley (DPVS-Shapley), data privacy

总结:<br />
本文介绍了在人工智能时代下，为了解决集中式学习中的数据隐私问题而出现的联邦学习。该分散式学习模型提出了一个新的挑战，即如何公平准确地评估每个参与者的贡献。为此，提出了一种名为动态修剪验证集沙利值（DPVS-Shapley）的方法，用于加速贡献评估过程并保持准确性。DPVS-Shapley方法能够根据不同样本的重要性赋予不同权重，使那些能区分困难示例的客户端获得更高的贡献评分。此外，有效的贡献评估机制可以激励参与者积极贡献数据和计算资源，从而提升整个联邦学习系统的性能并确保公平对待每个参与者。 <div>
arXiv:2410.15093v1 Announce Type: new 
Abstract: In the current era of artificial intelligence, federated learning has emerged as a novel approach to addressing data privacy concerns inherent in centralized learning paradigms. This decentralized learning model not only mitigates the risk of data breaches but also enhances the system's scalability and robustness. However, this approach introduces a new challenge: how to fairly and accurately assess the contribution of each participant. Developing an effective contribution evaluation mechanism is crucial for federated learning. Such a mechanism incentivizes participants to actively contribute their data and computational resources, thereby improving the overall performance of the federated learning system. By allocating resources and rewards based on the size of the contributions, it ensures that each participant receives fair treatment, fostering sustained engagement.Currently, Shapley value-based methods are widely used to evaluate participants' contributions, with many researchers proposing modifications to adapt these methods to real-world scenarios. In this paper, we introduce a component called Dynamic Pruning Validation Set Shapley (DPVS-Shapley). This method accelerates the contribution assessment process by dynamically pruning the original dataset without compromising the evaluation's accuracy. Furthermore, this component can assign different weights to various samples, thereby allowing clients capable of distinguishing difficult examples to receive higher contribution scores.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Augmented Lagrangian-Based Safe Reinforcement Learning Approach for Distribution System Volt/VAR Control</title>
<link>https://arxiv.org/abs/2410.15188</link>
<guid>https://arxiv.org/abs/2410.15188</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据驱动、有功无功控制、约束马尔科夫决策过程、强化学习、分布式系统

总结:<br />
本文提出了一种数据驱动的解决主动配电系统中伏特-瓦特(Volt-VAR)控制问题的方法。针对配电系统模型往往不准确和不完整的问题，该文将Volt-VAR控制问题建模为约束马尔科夫决策过程(CMDP)。通过结合增广拉格朗日法与软策略迭代算法，文中创新性地提出了一种安全的离线强化学习方法来求解CMDP。该算法利用拉格朗日值函数对策略网络进行梯度更新，并采用双批评网络同步估计动作价值函数以避免过估计偏差。此方法无需被优化问题具有强凸性保证，并具备样本效率。采取两阶段策略分别进行离线训练和在线执行，因此不再需要精确的配电系统模型。为了实现可扩展性，文章采用了集中式训练分布式执行的多智能体框架，实现了大规模配电系统的去中心化Volt-VAR控制。通过使用真实电力数据的综合数值实验表明，所提出的算法能够达到较高的解决方案最优性和约束满足性。 <div>
arXiv:2410.15188v1 Announce Type: new 
Abstract: This paper proposes a data-driven solution for Volt-VAR control problem in active distribution system. As distribution system models are always inaccurate and incomplete, it is quite difficult to solve the problem. To handle with this dilemma, this paper formulates the Volt-VAR control problem as a constrained Markov decision process (CMDP). By synergistically combining the augmented Lagrangian method and soft actor critic algorithm, a novel safe off-policy reinforcement learning (RL) approach is proposed in this paper to solve the CMDP. The actor network is updated in a policy gradient manner with the Lagrangian value function. A double-critics network is adopted to synchronously estimate the action-value function to avoid overestimation bias. The proposed algorithm does not require strong convexity guarantee of examined problems and is sample efficient. A two-stage strategy is adopted for offline training and online execution, so the accurate distribution system model is no longer needed. To achieve scalability, a centralized training distributed execution strategy is adopted for a multi-agent framework, which enables a decentralized Volt-VAR control for large-scale distribution system. Comprehensive numerical experiments with real-world electricity data demonstrate that our proposed algorithm can achieve high solution optimality and constraints compliance.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Can Enhance Creativity in Social Networks</title>
<link>https://arxiv.org/abs/2410.15264</link>
<guid>https://arxiv.org/abs/2410.15264</guid>
<content:encoded><![CDATA[
<div> 关键词：peer推荐引擎、创意表现、自组织社交网络、数据收集、干预设计<br /><br />总结: 该研究探索了在自组织社交网络中，同伴推荐引擎是否能够提升人们的创新表现。为了解答这一问题，文章解决了数据收集（如追踪灵感链接和节点的心理社会属性）和干预设计（如平衡思想刺激与信息环境中冗余的进化）方面的挑战。研究者训练了一个模型，用于预测在线平台上个人的创新表现，并基于此构建了SocialMuse系统，该系统能最大化预测的个人表现以生成同行推荐。实验结果显示，采用SocialMuse的处理组网络在多项创造力指标上优于不依赖AI的对照组网络。此外，处理组网络在较大的网络规模下更为去中心化，SocialMuse在推荐过程中更加重视网络结构特征，这种去中心化有助于分散人们的灵感来源，使受启发的想法更易于突出。这项研究为构建提升创新力的智能系统提供了可操作的见解。 <div>
arXiv:2410.15264v1 Announce Type: new 
Abstract: Can peer recommendation engines elevate people's creative performances in self-organizing social networks? Answering this question requires resolving challenges in data collection (e.g., tracing inspiration links and psycho-social attributes of nodes) and intervention design (e.g., balancing idea stimulation and redundancy in evolving information environments). We trained a model that predicts people's ideation performances using semantic and network-structural features in an online platform. Using this model, we built SocialMuse, which maximizes people's predicted performances to generate peer recommendations for them. We found treatment networks leveraging SocialMuse outperforming AI-agnostic control networks in several creativity measures. The treatment networks were more decentralized than the control, as SocialMuse increasingly emphasized network-structural features at large network sizes. This decentralization spreads people's inspiration sources, helping inspired ideas stand out better. Our study provides actionable insights into building intelligent systems for elevating creativity.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract</title>
<link>https://arxiv.org/abs/2410.15275</link>
<guid>https://arxiv.org/abs/2410.15275</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3, 智能合约, 编译器, Move AI Decompiler (MAD), 审计

总结:
本文介绍了针对Sui区块链平台上的智能合约审计问题，研究者开发了一种名为Move AI Decompiler (MAD)的新工具。MAD是一个基于大型语言模型（LLM）的网络应用，能够将智能合约字节码反编译为逻辑正确、可读性强且可以直接重新编译的源代码。评估结果显示，MAD生成的代码逻辑正确并通过了原始单元测试，对真实世界的智能合约有66.7%的成功再编译率。在一项涉及12名开发人员的研究中，相比于传统反编译器，MAD显著降低了审计工作量，其输出的代码被参与者认为与原始源代码相当，简化了智能合约逻辑理解和审计的过程。尽管存在偶尔的幻象错误和编译错误等问题，但MAD仍然明显优于传统反编译器。MAD对于提高区块链智能合约的透明度、审计效率以及教育具有实际意义，并有望扩展到如Solidity等其他智能合约语言，从而推动不同区块链平台的透明度提升。 <div>
arXiv:2410.15275v1 Announce Type: new 
Abstract: Web3 aims to enhance user control over data and assets, but this vision is challenged by non-transparent, scam-prone applications and vulnerable smart contracts. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code.
  Our evaluation shows that MAD produces logically correct code that successfully passes original unit tests and achieves a 66.7% recompilation success rate on real-world smart contracts. Additionally, in a user study involving 12 developers, MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, simplifying the process of smart contract logic comprehension and auditing. Despite some limitations, such as occasional hallucinations and compile errors, MAD still provides significant improvements over traditional decompilers.
  MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to review and audit non-open-source smart contracts, fostering trust and accountability. Additionally, MAD's approach could potentially extend to other smart contract languages, like Solidity, promoting transparency across various blockchains.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Attention Is All You Need for LLM-based Code Vulnerability Localization</title>
<link>https://arxiv.org/abs/2410.15288</link>
<guid>https://arxiv.org/abs/2410.15288</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件系统、漏洞定位、大型语言模型、LOVA、自注意力机制

总结:
本文介绍了随着软件系统的快速发展和越来越多的安全漏洞报告，准确识别易受攻击的代码段变得愈发重要。传统的漏洞定位方法如手动代码审查或基于规则的工具效率低下，且范围有限。近年来，GPT和LLaMA等大型语言模型为自动化漏洞检测开辟了新途径，但它们在处理长代码上下文时保持准确性方面存在挑战。为此，文章提出了LOVA这一新颖框架，它利用大型语言模型内在的自注意力机制增强漏洞定位能力。LOVA的核心思想是通过分析模型对输入代码各部分的不同关注度来追踪并重点考察可能具有更高风险的代码行。实验结果显示，LOVA在F1分数上相对于现有LLM基线方法表现出显著优势，提高了高达5.3倍的性能；同时，它在C、Python、Java和Solidity等多种编程语言的智能合约漏洞定位中展现出出色的可扩展性，效能提升达到14.6倍，并证明了其在不同LLM架构下的稳健性能。 <div>
arXiv:2410.15288v1 Announce Type: new 
Abstract: The rapid expansion of software systems and the growing number of reported vulnerabilities have emphasized the importance of accurately identifying vulnerable code segments. Traditional methods for vulnerability localization, such as manual code audits or rule-based tools, are often time-consuming and limited in scope, typically focusing on specific programming languages or types of vulnerabilities. In recent years, the introduction of large language models (LLMs) such as GPT and LLaMA has opened new possibilities for automating vulnerability detection. However, while LLMs show promise in this area, they face challenges, particularly in maintaining accuracy over longer code contexts. This paper introduces LOVA, a novel framework leveraging the self-attention mechanisms inherent in LLMs to enhance vulnerability localization. Our key insight is that self-attention mechanisms assign varying importance to different parts of the input, making it possible to track how much attention the model focuses on specific lines of code. In the context of vulnerability localization, the hypothesis is that vulnerable lines of code will naturally attract higher attention weights because they have a greater influence on the model's output. By systematically tracking changes in attention weights and focusing on specific lines of code, LOVA improves the precision of identifying vulnerable lines across various programming languages. Through rigorous experimentation and evaluation, we demonstrate that LOVA significantly outperforms existing LLM-based approaches, achieving up to a 5.3x improvement in F1-scores. LOVA also demonstrated strong scalability, with up to a 14.6x improvement in smart contract vulnerability localization across languages like C, Python, Java, and Solidity. Its robustness was proven through consistent performance across different LLM architectures.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Primal-Dual Method for Constrained Multi-agent Reinforcement Learning with General Parameterization</title>
<link>https://arxiv.org/abs/2410.15335</link>
<guid>https://arxiv.org/abs/2410.15335</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式、约束多智能体强化学习(CMARL)、全局目标函数、局部估计、对偶变量

总结:
<br />
本文提出了一种新颖的分布式方法来解决合作型约束多智能体强化学习问题。该方法允许智能体在完全去中心化的在线学习环境中，独立维护局部的原变量和对偶变量估计值。具体而言，文章开发了一个基于actor-critic方法的分布式原-对偶算法，利用局部信息来估计拉格朗日乘子，并实现了这些乘子在各智能体间的共识。此外，文中证明了该算法能收敛到一个平衡点，并分析了这个平衡点相对于无参数化问题精确解的次优性。为了验证算法在复杂现实场景中的性能，文中引入了一个具有随机动态的受约束的合作Cournot博弈作为测试环境。 <div>
arXiv:2410.15335v1 Announce Type: new 
Abstract: This paper proposes a novel distributed approach for solving a cooperative Constrained Multi-agent Reinforcement Learning (CMARL) problem, where agents seek to minimize a global objective function subject to shared constraints. Unlike existing methods that rely on centralized training or coordination, our approach enables fully decentralized online learning, with each agent maintaining local estimates of both primal and dual variables. Specifically, we develop a distributed primal-dual algorithm based on actor-critic methods, leveraging local information to estimate Lagrangian multipliers. We establish consensus among the Lagrangian multipliers across agents and prove the convergence of our algorithm to an equilibrium point, analyzing the sub-optimality of this equilibrium compared to the exact solution of the unparameterized problem. Furthermore, we introduce a constrained cooperative Cournot game with stochastic dynamics as a test environment to evaluate the algorithm's performance in complex, real-world scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Semi-decentralized and Variational-Equilibrium-Based Trajectory Planner for Connected and Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2410.15394</link>
<guid>https://arxiv.org/abs/2410.15394</guid>
<content:encoded><![CDATA[
<div> 关键词：车辆通信技术(V2X)，自动驾驶车辆(CAVs)，轨迹规划，交互公平性，变分均衡(VE)，半分布式规划器，计算效率，安全性，规模化。

总结:
本文提出了一种利用车辆通信技术（V2X）解决自动驾驶车辆（CAVs）未经协调方法中的计算效率和安全问题的新颖轨迹规划方法。该研究将CAVs的轨迹规划问题建模为具有耦合安全约束的游戏，并定义了交互公平的轨迹，证明它们对应于该游戏的变分均衡（VE）。文章设计了一个半分布式规划器，使车辆能够寻求基于VE的公平轨迹，从而通过CAVs之间的并行计算显著提高计算效率，并通过确保CAVs之间的均衡一致性增强规划轨迹的安全性。实验结果证实了该方法的优势，包括快速计算速度、高可扩展性、均衡一致性以及安全性。 <div>
arXiv:2410.15394v1 Announce Type: new 
Abstract: This paper designs a novel trajectory planning approach to resolve the computational efficiency and safety problems in uncoordinated methods by exploiting vehicle-to-everything (V2X) technology. The trajectory planning for connected and autonomous vehicles (CAVs) is formulated as a game with coupled safety constraints. We then define interaction-fair trajectories and prove that they correspond to the variational equilibrium (VE) of this game. We propose a semi-decentralized planner for the vehicles to seek VE-based fair trajectories, which can significantly improve computational efficiency through parallel computing among CAVs and enhance the safety of planned trajectories by ensuring equilibrium concordance among CAVs. Finally, experimental results show the advantages of the approach, including fast computation speed, high scalability, equilibrium concordance, and safety.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Power Plays: Unleashing Machine Learning Magic in Smart Grids</title>
<link>https://arxiv.org/abs/2410.15423</link>
<guid>https://arxiv.org/abs/2410.15423</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、智能电网、效率、可持续性、数据隐私

总结:<br />
本文探讨了将机器学习融入智能电网系统对于提升现代能源网络效率、可靠性和可持续性的变革性影响。通过高级数据分析，这些系统能更好地管理可再生能源整合、需求响应和预测性维护等方面的复杂性。利用机器学习算法分析来自智能电表、传感器等设备的大数据，可以优化能源分配、预测需求并检测可能预示故障的异常情况，从而实现更精确的负荷平衡、降低运营成本并增强对电网扰动的韧性。此外，预测模型有助于预见设备故障，进而提高能源供应的可靠性。随着智能电网的发展，机器学习在管理分布式能源源和实现实时决策中的作用将愈发关键。然而，部署这些技术也带来了关于数据隐私、安全以及对强大基础设施需求的挑战。本文的研究重点在于利用机器学习技术充分发掘智能电网的潜力，确保它们在满足日益增长的能源需求的同时，兼顾可持续性和效率。同时，文中还对比分析了多种机器学习算法及其优缺点，并展望了这些算法的未来应用前景。 <div>
arXiv:2410.15423v1 Announce Type: new 
Abstract: The integration of machine learning into smart grid systems represents a transformative step in enhancing the efficiency, reliability, and sustainability of modern energy networks. By adding advanced data analytics, these systems can better manage the complexities of renewable energy integration, demand response, and predictive maintenance. Machine learning algorithms analyze vast amounts of data from smart meters, sensors, and other grid components to optimize energy distribution, forecast demand, and detect irregularities that could indicate potential failures. This enables more precise load balancing, reduces operational costs, and enhances the resilience of the grid against disturbances. Furthermore, the use of predictive models helps in anticipating equipment failures, thereby improving the reliability of the energy supply. As smart grids continue to evolve, the role of machine learning in managing decentralized energy sources and enabling real-time decision-making will become increasingly critical. However, the deployment of these technologies also raises challenges related to data privacy, security, and the need for robust infrastructure. Addressing these issues in this research authors will focus on realizing the full potential of smart grids, ensuring they meet the growing energy demands while maintaining a focus on sustainability and efficiency using Machine Learning techniques. Furthermore, this research will help determine the smart grid's essentiality with the aid of Machine Learning. Multiple ML algorithms have been integrated along with their pros and cons. The future scope of these algorithms are also integrated.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Hybrid Precoding for Massive MU-MIMO ISAC</title>
<link>https://arxiv.org/abs/2410.15659</link>
<guid>https://arxiv.org/abs/2410.15659</guid>
<content:encoded><![CDATA[
<div> 关键词：集成感知与通信(ISAC)，大规模多用户多输入多输出(Massive MU MIMO-ISAC)，多用户干扰(MUI)，分布式基带处理(DBP)预编码，部分连接结构(PCS)，瑟姆林森-原田预编码(THP)

<br /><br />总结:

本文提出了一个针对大规模多用户多输入多输出集成感知与通信系统(Massive MU MIMO-ISAC)中密集用户接入引起的严重多用户干扰问题的解决方案。该方案采用分布式基带处理(DBP)预编码方法，将最小化Cramer-Rao下界(CRB)作为目标函数来建模密集用户场景下的MUI问题。同时，结合部分连接结构(PCS)的混合预编码技术，有效降低了硬件成本和功耗。通过应用瑟姆林森-原田预编码(THP)进一步减轻用户间的MUI。仿真实验表明，相较于现有方法，所提方法能显著提升密集用户接入场景下的通信数据速率和能源效率，并降低Massive MU MIMO-ISAC系统的硬件复杂度，验证了其在解决ISAC系统中密集用户接入场景下的MUI问题上的有效性。 <div>
arXiv:2410.15659v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) is a very promising technology designed to provide both high rate communication capabilities and sensing capabilities. However, in Massive Multi User Multiple-Input Multiple-Output (Massive MU MIMO-ISAC) systems, the dense user access creates a serious multi-user interference (MUI) problem, leading to degradation of communication performance. To alleviate this problem, we propose a decentralized baseband processing (DBP) precoding method. We first model the MUI of dense user scenarios with minimizing Cramer-Rao bound (CRB) as an objective function.Hybrid precoding is an attractive ISAC technique, and hybrid precoding using Partially Connected Structures (PCS) can effectively reduce hardware cost and power consumption. We mitigate the MUI between dense users based on ThomlinsonHarashima Precoding (THP). We demonstrate the effectiveness of the proposed method through simulation experiments. Compared with the existing methods, it can effectively improve the communication data rates and energy efficiency in dense user access scenario, and reduce the hardware complexity of Massive MU MIMO-ISAC systems. The experimental results demonstrate the usefulness of our method for improving the MUI problem in ISAC systems for dense user access scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Geographical Node Clustering and Grouping to Guarantee Data IIDness in Federated Learning</title>
<link>https://arxiv.org/abs/2410.15693</link>
<guid>https://arxiv.org/abs/2410.15693</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习 (Federated Learning)，非IID数据集问题，物联网设备 (IoT)，地理特性，动态聚类算法<br /><br />总结: 这篇文章主要探讨了联邦学习中非IID数据集问题对模型性能的影响。研究发现物联网设备的数据独立性和相同性与其相互间的距离有关。为此，文章提出了一个新颖的方法，利用设备的地理位置信息进行动态聚类和部分稳定分组算法，旨在确保每个FL小组内部的数据达到近似的IID性。实验结果显示，该机制相比于基准分组算法，在联合成本（包括设备掉线数量与各组设备数均衡度）上至少提高了110倍，同时仅使组别数量最多增加了0.93组。 <div>
arXiv:2410.15693v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized AI mechanism suitable for a large number of devices like in smart IoT. A major challenge of FL is the non-IID dataset problem, originating from the heterogeneous data collected by FL participants, leading to performance deterioration of the trained global model. There have been various attempts to rectify non-IID dataset, mostly focusing on manipulating the collected data. This paper, however, proposes a novel approach to ensure data IIDness by properly clustering and grouping mobile IoT nodes exploiting their geographical characteristics, so that each FL group can achieve IID dataset. We first provide an experimental evidence for the independence and identicalness features of IoT data according to the inter-device distance, and then propose Dynamic Clustering and Partial-Steady Grouping algorithms that partition FL participants to achieve near-IIDness in their dataset while considering device mobility. Our mechanism significantly outperforms benchmark grouping algorithms at least by 110 times in terms of the joint cost between the number of dropout devices and the evenness in per-group device count, with a mild increase in the number of groups only by up to 0.93 groups.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient and Universally Accessible Cross-Chain Options without Upfront Holder Collateral</title>
<link>https://arxiv.org/abs/2410.15724</link>
<guid>https://arxiv.org/abs/2410.15724</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、期权交易、无需抵押品、双认证防止签名(DAPS)、跨链

总结:<br />
本文提出了一种新的区块链期权交易协议，旨在解决现有机制中资产支持有限、交易延迟高以及期权持有者需要提供前期抵押品等问题。该协议实现了无需期权持有者提供抵押品即可高效、广泛地进行期权交易，且其创新性地运用了双认证防止签名（DAPS）技术，显著降低了交易延迟。此外，通过引入期权发行方的保证，本协议消除了持有人的预付抵押需求。评估结果显示，所提方案将期权转移延迟降低到现有方法的一半以下。同时，严格的security分析证明，即使面对恶意行为，该协议也能实现安全的期权交易。此协议还支持任意两条不同区块链之间几乎任何资产的跨链期权交易，只要这两条链的编程语言能够执行和强制实施必要的合同逻辑。 <div>
arXiv:2410.15724v1 Announce Type: new 
Abstract: Options are fundamental to blockchain-based financial markets, offering essential tools for risk management and price speculation, which enhance liquidity, flexibility, and market efficiency in decentralized finance (DeFi). Despite the growing interest in options for blockchain-resident assets, such as cryptocurrencies, current option mechanisms face significant challenges, including limited asset support, high trading delays, and the requirement for option holders to provide upfront collateral.
  In this paper, we present a protocol that addresses the aforementioned issues by facilitating efficient and universally accessible option trading without requiring holders to post collateral when establishing options. Our protocol's universality allows for cross-chain options involving nearly $\textit{any}$ assets on $\textit{any}$ two different blockchains, provided the chains' programming languages can enforce and execute the necessary contract logic. A key innovation in our approach is the use of Double-Authentication-Preventing Signatures (DAPS), which significantly reduces trading latency. Additionally, by introducing a guarantee from the option writer, our protocol removes the need of upfront collateral from holders. Our evaluation demonstrates that the proposed scheme reduces option transfer latency to less than half of that in existing methods. Rigorous security analysis proves that our protocol achieves secure option trading, even when facing adversarial behaviors.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Efficient Collaboration via Graph Modeling in Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.15841</link>
<guid>https://arxiv.org/abs/2410.15841</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning, centralized training, decentralized execution, Factor-based Multi-Agent Transformer ($f$-MAT), transformer

总结:

本文研究了多智能体强化学习中的集中训练与分散执行框架，并针对执行阶段因局部观察限制而难以实现协调策略的问题进行了探讨。文章提出了一种新的编码器-解码器架构——基于因子的多智能体变换器（$f$-MAT），该架构利用变压器在训练和执行过程中实现相邻智能体间的通信。通过将智能体划分为不同的重叠组并用每个组的因子进行表示，$f$-MAT能够借助因子注意力层实现在智能体之间的高效信息传递。实验结果表明，相比于强大的基线算法，$f$-MAT在网络系统如交通调度和电力控制等场景中表现出了优越性能，为解决复杂协作问题开辟了新途径。 <div>
arXiv:2410.15841v1 Announce Type: new 
Abstract: In multi-agent reinforcement learning, a commonly considered paradigm is centralized training with decentralized execution. However, in this framework, decentralized execution restricts the development of coordinated policies due to the local observation limitation. In this paper, we consider the cooperation among neighboring agents during execution and formulate their interactions as a graph. Thus, we introduce a novel encoder-decoder architecture named Factor-based Multi-Agent Transformer ($f$-MAT) that utilizes a transformer to enable the communication between neighboring agents during both training and execution. By dividing agents into different overlapping groups and representing each group with a factor, $f$-MAT fulfills efficient message passing among agents through factor-based attention layers. Empirical results on networked systems such as traffic scheduling and power control demonstrate that $f$-MAT achieves superior performance compared to strong baselines, thereby paving the way for handling complex collaborative problems.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AdChain: Decentralized Header Bidding</title>
<link>https://arxiv.org/abs/2410.16141</link>
<guid>https://arxiv.org/abs/2410.16141</guid>
<content:encoded><![CDATA[
<div> 关键词: AdChain、去中心化、广告印象差异、共识协议、区块链

总结:
<br />
AdChain 是一种针对在线广告中因多方中介缺乏信任、法规不完善和供应链复杂导致的广告印象差异问题提出的解决方案。该文介绍了一个去中心化、分布式和可验证的 AdChain 系统，它利用多个独立代理接收并记录日志级数据，并采用共识协议来验证每个广告数据，从而建立信任。AdChain 具有可扩展性、效率高并且与现有基础设施兼容的特点。实验结果显示，在超过五十万条广告数据上运行，AdChain 可以达到 98% 的准确性，将广告差异率从 20% 降低到 2%。此外，分析还表明 AdChain 上活跃节点的利润可以与比特币等主要区块链网络上的矿工相当。 <div>
arXiv:2410.16141v1 Announce Type: new 
Abstract: Due to the involvement of multiple intermediaries without trusted parties, lack of proper regulations, and a complicated supply chain, ad impression discrepancy affects online advertising. This issue causes up to $82 billion annual revenue loss for honest parties. The loss can be significantly reduced with a precise and trusted decentralized mechanism. This paper presents AdChain, a decentralized, distributed, and verifiable solution that detects and minimizes online advertisement impression discrepancies. AdChain establishes trust by employing multiple independent agents to receive and record log-level data, along with a consensus protocol to validate each ad data. AdChain is scalable, efficient, and compatible with the current infrastructure. Our experimental evaluation, using over half a million ad data points, identifies system parameters that achieve 98% accuracy, reducing the ad discrepancy rate from 20% to 2%. Our cost analysis shows that active nodes on AdChain can generate profits comparable to miners on major blockchain networks like Bitcoin.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Model for Multi-Agent Autonomy That Uses Opinion Dynamics and Multi-Objective Behavior Optimization</title>
<link>https://arxiv.org/abs/2311.11144</link>
<guid>https://arxiv.org/abs/2311.11144</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主多机器人系统(MRSs), 非线性动力学意见过程, 多目标行为优化, 分布式控制, 通信成本

总结:
本文提出了一种用于建模自主多机器人系统（MRSs）的新颖分层架构。该架构使用非线性动态意见过程来模拟高层级群体选择，并利用多目标行为优化方法来模拟个体决策。通过先前的理论结果，论文表明仅通过选取相对较小的一组参数即可设计MRS的行为，并且这种行为——包括集体行动和个体行动——可以直观地理解。该方法完全分布式实现，通信成本随群组选项的数量而非代理数量而增加。通过在一个假设的“探索-开发-迁移”场景中进行两小时的实地演示，利用八艘无人驾驶水面舰艇（USVs），实验结果显示即使在网络拓扑和代理退出等时间变化情况下，集体行为依然保持稳健。 <div>
arXiv:2311.11144v3 Announce Type: replace 
Abstract: This paper reports a new hierarchical architecture for modeling autonomous multi-robot systems (MRSs): a nonlinear dynamical opinion process is used to model high-level group choice, and multi-objective behavior optimization is used to model individual decisions. Using previously reported theoretical results, we show it is possible to design the behavior of the MRS by the selection of a relatively small set of parameters. The resulting behavior - both collective actions and individual actions - can be understood intuitively. The approach is entirely decentralized and the communication cost scales by the number of group options, not agents. We demonstrated the effectiveness of this approach using a hypothetical `explore-exploit-migrate' scenario in a two hour field demonstration with eight unmanned surface vessels (USVs). The results from our preliminary field experiment show the collective behavior is robust even with time-varying network topology and agent dropouts.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Connected and Automated Vehicles Control: Recent Advancements and Future Prospects</title>
<link>https://arxiv.org/abs/2312.11084</link>
<guid>https://arxiv.org/abs/2312.11084</guid>
<content:encoded><![CDATA[
<div> 关键词：Connected and Automated Vehicles (CAVs)，Multi-Agent Reinforcement Learning (MARL)，Control Dimensions，Simulation Platforms，Challenges and Solutions

<br /><br />总结：
本文针对互联与自动驾驶车辆（CAVs）领域的复杂协调控制问题，重点介绍了多智能体强化学习（MARL）的应用。文章首先阐述了MARL在处理复杂多智能体场景中的独特优势；接着，详细梳理了MARL在CAV控制的不同维度上的应用，如车队控制、变道和无信号交叉口管理等关键场景；同时，也回顾了用于开发和测试MARL算法的重要仿真平台。此外，文章还探讨了将MARL应用于CAV控制面临的挑战，包括宏观微观优化、通信、混合交通以及模拟到现实的转化等问题，并提出了可能的解决方案，如层次化MARL、去中心化MARL、自适应交互以及离线MARL等。 <div>
arXiv:2312.11084v3 Announce Type: replace 
Abstract: Connected and automated vehicles (CAVs) are considered a potential solution for future transportation challenges, aiming to develop systems that are efficient, safe, and environmentally friendly. However, CAV control presents significant challenges due to the complexity of interconnectivity and coordination required among vehicles. Multi-agent reinforcement learning (MARL), which has shown notable advancements in addressing complex problems in autonomous driving, robotics, and human-vehicle interaction, emerges as a promising tool to enhance CAV capabilities. Despite its potential, there is a notable absence of current reviews on mainstream MARL algorithms for CAVs. To fill this gap, this paper offers a comprehensive review of MARL's application in CAV control. The paper begins with an introduction to MARL, explaining its unique advantages in handling complex and multi-agent scenarios. It then presents a detailed survey of MARL applications across various control dimensions for CAVs, including critical scenarios such as platooning control, lane-changing, and unsignalized intersections. Additionally, the paper reviews prominent simulation platforms essential for developing and testing MARL algorithms. Lastly, it examines the current challenges in deploying MARL for CAV control, including macro-micro optimization, communication, mixed traffic, and sim-to-real challenges. Potential solutions discussed include hierarchical MARL, decentralized MARL, adaptive interactions, and offline MARL.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigating Side Effects in Multi-Agent Systems Using Blame Assignment</title>
<link>https://arxiv.org/abs/2405.04702</link>
<guid>https://arxiv.org/abs/2405.04702</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、协同优化、负外部性、分散式Markov决策过程、信用分配

<br />
总结:
本文针对在共享环境中独立训练或设计的机器人可能产生的意外负面效应问题，提出了将该问题建模为双目标优先级分散式Markov决策过程的方法。研究假设机器人任务间的转换和奖励相互独立，但联合的负面效应惩罚则在这种情况下形成了依赖关系。为提高可扩展性，文章利用信用分配方法将联合负面效应惩罚分解为每个机器人的个体惩罚，从而便于进行分散式的策略计算。通过移动机器人以及模拟实验，作者实证展示了所提出方法在减轻负面效应方面的有效性和可扩展性。 <div>
arXiv:2405.04702v2 Announce Type: replace 
Abstract: When independently trained or designed robots are deployed in a shared environment, their combined actions can lead to unintended negative side effects (NSEs). To ensure safe and efficient operation, robots must optimize task performance while minimizing the penalties associated with NSEs, balancing individual objectives with collective impact. We model the problem of mitigating NSEs in a cooperative multi-agent system as a bi-objective lexicographic decentralized Markov decision process. We assume independence of transitions and rewards with respect to the robots' tasks, but the joint NSE penalty creates a form of dependence in this setting. To improve scalability, the joint NSE penalty is decomposed into individual penalties for each robot using credit assignment, which facilitates decentralized policy computation. We empirically demonstrate, using mobile robots and in simulation, the effectiveness and scalability of our approach in mitigating NSEs.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-Critical Formation Control of Non-Holonomic Multi-Robot Systems in Communication-Limited Environments</title>
<link>https://arxiv.org/abs/2406.13707</link>
<guid>https://arxiv.org/abs/2406.13707</guid>
<content:encoded><![CDATA[
<div> 关键词: 非holonomic移动机器人, 形状控制, 通信限制环境, 控制 Barrier 函数, 状态估计算法

总结:
本文提出了一种针对非holonomic移动机器人在通信受限环境中的安全关键控制器，用于编队形状控制。该新颖的分布式框架将鲁棒状态估计算法与编队跟踪控制律相结合，解决了使用控制Barrier函数实现的相互避碰和扰动衰减问题。该估计器设计考虑了常量和时变速度剖面，增强了系统对动态场景的适应性。通过采用闭合形式解的跟踪控制器，实现了有效实施并保持编队完整性。通过引入串行稳定性指标，进一步强化了框架抵抗由前车传播的扰动的能力。利用Lyapunov函数进行严格稳定性分析，确保了估计误差的稳定性和编队向期望配置的收敛性。数值模拟和基于Gazebo的真实实验验证了所提方法在各种操作和仓库环境中保持安全性、实现精确编队控制以及缓解无通信条件下的干扰抑制的有效性和鲁棒性。 <div>
arXiv:2406.13707v2 Announce Type: replace 
Abstract: This paper presents a novel estimator-based safety-critical controller for formation control of non-holonomic mobile robots in communication-limited environments. The proposed decentralized framework integrates a robust state estimator with a formation tracking control law, addressing the challenges of inter-agent collision avoidance and disturbance attenuation in leader-follower formations using control barrier functions. The estimator's design accounts for both constant and time-varying velocity profiles, enhancing the system's adaptability to dynamic scenarios. A closed-form solution for the tracking controller facilitates efficient implementation while maintaining formation integrity. The incorporation of string stability metrics further reinforces the framework's resilience against propagating disturbances from predecessors. Rigorous stability analysis using Lyapunov functions ensures the stability of estimation errors and the convergence of the formation to desired configurations. The effectiveness and robustness of the proposed approach are validated through numerical simulations of various maneuvers and realistic Gazebo experiments involving formations in a warehouse environment. The results demonstrate the controller's ability to maintain safety, achieve precise formation control, and mitigate disturbances in scenarios without inter-robot communication.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Fine-Tuned Language Models for Efficient and Accurate Smart Contract Auditing</title>
<link>https://arxiv.org/abs/2410.13918</link>
<guid>https://arxiv.org/abs/2410.13918</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、大型语言模型、FTSmartAudit框架、安全性审计

<br /><br />总结:
随着区块链技术的发展和智能合约的应用普及，其安全问题日益凸显。本文针对智能合约的安全审计挑战，提出了一种新的解决方案——FTSmartAudit框架。该框架利用大型语言模型（LLMs）进行自动化安全漏洞检测，并探讨了通过微调较小规模的模型来达到与大型模型相当甚至更优的效果的可能性。研究内容包括：(1) 设计了一个单一任务学习框架，用于简化数据准备、训练、评估及持续学习流程；(2) 提出一种基于领域专业知识蒸馏的方法生成高质量训练数据集，这些数据源自如GPT-4等先进模型；(3) 开发了一种自适应学习策略，以保持模型的准确性和鲁棒性；(4) 证明了经过微调的小型模型在识别特定安全漏洞和复杂逻辑错误方面的有效性；(5) 强调了该框架可以扩展到其他需要LLM解决方案的领域。实验结果显示，经过微调的小型模型在检测智能合约中的漏洞方面能够超越现有商业模型和工具。 <div>
arXiv:2410.13918v1 Announce Type: new 
Abstract: The rise of blockchain technologies has greatly accelerated the development and deployment of smart contracts. However, their inherent vulnerabilities and susceptibility to bugs have led to significant financial losses, underscoring the challenges in securing smart contracts. While traditional auditing methods are crucial, they often fall short in addressing the increasing complexity and volume of smart contracts. Recent advancements in Large Language Models (LLMs) offer promising solutions for enhancing software auditing by automatically identifying security vulnerabilities. Despite their potential, the practical application of these models is hindered by substantial computational demands. This paper investigates the feasibility of using smaller, fine-tuned models to achieve comparable or even superior results in smart contract auditing. We introduce the FTSmartAudit framework, which is designed to develop cost-effective, specialized models for smart contract auditing through the fine-tuning of LLMs. Our contributions include: (1) a single-task learning framework that streamlines data preparation, training, evaluation, and continuous learning; (2) a robust dataset generation method utilizing domain-special knowledge distillation to produce high-quality datasets from advanced models like GPT-4o; (3) an adaptive learning strategy to maintain model accuracy and robustness; (4) the proven effectiveness of fine-tuned models in detecting specific vulnerabilities and complex logical errors; and (5) a framework that can be extended to other domains requiring LLM solutions. Our experimental results demonstrate that smaller models can surpass state-of-the-art commercial models and tools in detecting vulnerabilities in smart contracts.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Diffusion Models for Multi-Agent Partial Observability: Shared Attractors, Error Bounds, and Composite Flow</title>
<link>https://arxiv.org/abs/2410.13953</link>
<guid>https://arxiv.org/abs/2410.13953</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、部分可观测性、分布式部分可观测马尔科夫决策过程、扩散模型、深度学习

总结:
本文探讨了多智能体系统中处理部分可观测性的挑战，重点关注分布式部分可观测马尔科夫决策过程（Dec-POMDP）中的全局状态重构问题。研究发现，基于局部行动-观测历史的扩散模型能够将可能的状态表示为稳定固定点。在集体可观察的Dec-POMDP中，各智能体的条件扩散模型共享一个与全局状态相对应的独特固定点；而在非集体可观察场景下，则会产生一个由联合历史给出的可能状态分布。当涉及到深度学习近似误差时，固定点可能偏离真实状态，且这种偏差与雅可比矩阵秩负相关。为此，文章提出了一种利用低秩特性构建的代理线性回归模型来约束该偏差，并设计了一个迭代各智能体的复合扩散过程，理论上保证其收敛到真实状态。 <div>
arXiv:2410.13953v1 Announce Type: new 
Abstract: Multiagent systems grapple with partial observability (PO), and the decentralized POMDP (Dec-POMDP) model highlights the fundamental nature of this challenge. Whereas recent approaches to address PO have appealed to deep learning models, providing a rigorous understanding of how these models and their approximation errors affect agents' handling of PO and their interactions remain a challenge. In addressing this challenge, we investigate reconstructing global states from local action-observation histories in Dec-POMDPs using diffusion models. We first find that diffusion models conditioned on local history represent possible states as stable fixed points. In collectively observable (CO) Dec-POMDPs, individual diffusion models conditioned on agents' local histories share a unique fixed point corresponding to the global state, while in non-CO settings, the shared fixed points yield a distribution of possible states given joint history. We further find that, with deep learning approximation errors, fixed points can deviate from true states and the deviation is negatively correlated to the Jacobian rank. Inspired by this low-rank property, we bound the deviation by constructing a surrogate linear regression model that approximates the local behavior of diffusion models. With this bound, we propose a composite diffusion process iterating over agents with theoretical convergence guarantees to the true state.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Conformal Prediction for Federated Graph Neural Networks with Missing Neighbor Information</title>
<link>https://arxiv.org/abs/2410.14010</link>
<guid>https://arxiv.org/abs/2410.14010</guid>
<content:encoded><![CDATA[
<div> 关键词：Graphs, Federated Learning, Missing Links, Conformal Prediction, Variational Autoencoder

总结:<br />
本文研究了图数据在数据挖掘和机器学习中的重要性，特别是在大规模、分布式子图管理的联邦学习框架下。针对联邦学习中缺失邻居信息导致模型可靠性下降的问题，文章提出了将确立的不确定性量化方法——Conformal Prediction（CP）扩展应用于联邦图学习。为了减小缺失链接对CP集合大小的影响，作者探讨了分布式子图间的数据依赖关系并建立了保持CP有效性和精确测试时间覆盖的条件。文中还介绍了一种基于变分自编码器的方法，用于重建缺失的邻居以缓解缺失数据的负面影响。实验证明，该方法在确保覆盖率保证的同时，能有效地减小预测集的大小。 <div>
arXiv:2410.14010v1 Announce Type: new 
Abstract: Graphs play a crucial role in data mining and machine learning, representing real-world objects and interactions. As graph datasets grow, managing large, decentralized subgraphs becomes essential, particularly within federated learning frameworks. These frameworks face significant challenges, including missing neighbor information, which can compromise model reliability in safety-critical settings. Deployment of federated learning models trained in such settings necessitates quantifying the uncertainty of the models. This study extends the applicability of Conformal Prediction (CP), a well-established method for uncertainty quantification, to federated graph learning. We specifically tackle the missing links issue in distributed subgraphs to minimize its adverse effects on CP set sizes. We discuss data dependencies across the distributed subgraphs and establish conditions for CP validity and precise test-time coverage. We introduce a Variational Autoencoder-based approach for reconstructing missing neighbors to mitigate the negative impact of missing data. Empirical evaluations on real-world datasets demonstrate the efficacy of our approach, yielding smaller prediction sets while ensuring coverage guarantees.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedPAE: Peer-Adaptive Ensemble Learning for Asynchronous and Model-Heterogeneous Federated Learning</title>
<link>https://arxiv.org/abs/2410.14075</link>
<guid>https://arxiv.org/abs/2410.14075</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、个性化联邦学习、模型异质性、去中心化、Federated Peer-Adaptive Ensemble Learning (FedPAE)

总结:<br />
本文提出了一种名为Federated Peer-Adaptive Ensemble Learning (FedPAE)的新颖去中心化个性化联邦学习算法。该算法旨在解决现有联邦学习中的数据分布和系统能力异质性问题以及对中央实体的依赖。FedPAE支持模型异质性并采用异步学习方式，通过点对点模型分享机制和集成选择策略，更好地平衡了局部与全局信息的利用。实验结果显示，FedPAE相比现有的个性化联邦学习算法表现出更优的性能，有效应对了不同客户端的能力差异，并展现出对抗统计异质性的鲁棒性。 <div>
arXiv:2410.14075v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple clients with distributed data sources to collaboratively train a shared model without compromising data privacy. However, existing FL paradigms face challenges due to heterogeneity in client data distributions and system capabilities. Personalized federated learning (pFL) has been proposed to mitigate these problems, but often requires a shared model architecture and a central entity for parameter aggregation, resulting in scalability and communication issues. More recently, model-heterogeneous FL has gained attention due to its ability to support diverse client models, but existing methods are limited by their dependence on a centralized framework, synchronized training, and publicly available datasets. To address these limitations, we introduce Federated Peer-Adaptive Ensemble Learning (FedPAE), a fully decentralized pFL algorithm that supports model heterogeneity and asynchronous learning. Our approach utilizes a peer-to-peer model sharing mechanism and ensemble selection to achieve a more refined balance between local and global information. Experimental results show that FedPAE outperforms existing state-of-the-art pFL algorithms, effectively managing diverse client capabilities and demonstrating robustness against statistical heterogeneity.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Communication and Computation Efficient Fully First-order Method for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2410.14115</link>
<guid>https://arxiv.org/abs/2410.14115</guid>
<content:encoded><![CDATA[
<div> 关键词：bilevel优化，分布式联邦学习（DFL），第二秩序导数，通信效率，$\text{C}^2$DFB

总结:<br />
本文针对分布式联邦学习中的双层优化问题，提出了一种新的、计算和通信效率均高的完全一阶分布式双层优化算法——$\text{C}^2$DFB。该方法创新地仅依赖梯度信息来逼近上层模型的超梯度，避免了获取和共享二阶导数带来的计算和通信开销。为减轻解决下层问题时的内部循环通信负担，$\text{C}^2$DFB引入了一个轻量级通信协议，用于高效传输本地参数压缩残差。文章提供了严格的理论分析证明其收敛性，并通过在超参数调优和超表示任务上的实验验证了$\text{C}^2$DFB在各种网络拓扑和异构数据分布下的优越性能。 <div>
arXiv:2410.14115v1 Announce Type: new 
Abstract: Bilevel optimization, crucial for hyperparameter tuning, meta-learning and reinforcement learning, remains less explored in the decentralized learning paradigm, such as decentralized federated learning (DFL). Typically, decentralized bilevel methods rely on both gradients and Hessian matrices to approximate hypergradients of upper-level models. However, acquiring and sharing the second-order oracle is compute and communication intensive. % and sharing this information incurs heavy communication overhead. To overcome these challenges, this paper introduces a fully first-order decentralized method for decentralized Bilevel optimization, $\text{C}^2$DFB which is both compute- and communicate-efficient. In $\text{C}^2$DFB, each learning node optimizes a min-min-max problem to approximate hypergradient by exclusively using gradients information. To reduce the traffic load at the inner-loop of solving the lower-level problem, $\text{C}^2$DFB incorporates a lightweight communication protocol for efficiently transmitting compressed residuals of local parameters. % during the inner loops. Rigorous theoretical analysis ensures its convergence % of the algorithm, indicating a first-order oracle calls of $\tilde{\mathcal{O}}(\epsilon^{-4})$. Experiments on hyperparameter tuning and hyper-representation tasks validate the superiority of $\text{C}^2$DFB across various typologies and heterogeneous data distributions.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMSE: Federated learning for IoT network intrusion detection</title>
<link>https://arxiv.org/abs/2410.14121</link>
<guid>https://arxiv.org/abs/2410.14121</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网(IoT)，联邦学习(federated learning)，半监督学习(semi-supervised learning)，自编码器(Shrink Autoencoder)，中心点分类器(Centroid classifier)，均方误差(Mean Square Error)，入侵检测(intrusion detection)

<br /><br />总结:

本文提出了一种新颖的用于提升物联网网络入侵检测性能的联邦学习方法。针对传统集中式机器学习方法在处理 IoT 网络数据可用性、计算资源、传输成本以及特别是隐私保护方面存在的不足，研究者开发了一个结合了收缩自编码器和中心点一类分类器(SAE-CEN)的半监督联邦学习模型。该模型能有效地表征正常网络数据并准确识别分布式环境中的异常行为。同时，文中还引入了一个基于均方误差的聚合算法(MSEAvg)，通过优先考虑更精确的局部模型来提高全局模型的性能。实验结果表明，在使用N-BaIoT数据集和Dirichlet分布的不同设置下，这种方法在实际异构物联网网络中显著提高了检测精度（从93.98$\pm$2.90提升到97.30$\pm$0.49），并且在仅需要50%网关参与训练的情况下降低了学习成本，同时在大规模网络中表现出良好的鲁棒性。 <div>
arXiv:2410.14121v1 Announce Type: new 
Abstract: This paper proposes a novel federated learning approach for improving IoT network intrusion detection. The rise of IoT has expanded the cyber attack surface, making traditional centralized machine learning methods insufficient due to concerns about data availability, computational resources, transfer costs, and especially privacy preservation. A semi-supervised federated learning model was developed to overcome these issues, combining the Shrink Autoencoder and Centroid one-class classifier (SAE-CEN). This approach enhances the performance of intrusion detection by effectively representing normal network data and accurately identifying anomalies in the decentralized strategy. Additionally, a mean square error-based aggregation algorithm (MSEAvg) was introduced to improve global model performance by prioritizing more accurate local models. The results obtained in our experimental setup, which uses various settings relying on the N-BaIoT dataset and Dirichlet distribution, demonstrate significant improvements in real-world heterogeneous IoT networks in detection accuracy from 93.98$\pm$2.90 to 97.30$\pm$0.49, reduced learning costs when requiring only 50\% of gateways participating in the training process, and robustness in large-scale networks.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Cryptocurrency Market Forecasting: Advanced Machine Learning Techniques and Industrial Engineering Contributions</title>
<link>https://arxiv.org/abs/2410.14475</link>
<guid>https://arxiv.org/abs/2410.14475</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、机器学习、价格预测、工业工程师、市场情绪分析

<br /><br />总结:

本文回顾了从2014年至2024年间应用于加密货币价格预测的机器学习技术，重点关注线性模型、树基方法及深度学习架构（如变压器和大型语言模型）。文章强调了市场情绪分析在利用社交媒体和新闻文本数据预测价格波动中的作用。同时指出，工业工程师凭借其在系统优化、效率提升和风险减缓方面的专业知识，对改进这些预测模型起到关键作用。随着新兴技术的整合与预测模型的发展，该章节旨在解决现有局限并探索未来研究方向，以期构建更精确、稳健的预测系统，进而支持更为明智的投资决策和稳定市场行为。 <div>
arXiv:2410.14475v1 Announce Type: new 
Abstract: Cryptocurrencies, as decentralized digital assets, have experienced rapid growth and adoption, with over 23,000 cryptocurrencies and a market capitalization nearing \$1.1 trillion (about \$3,400 per person in the US) as of 2023. This dynamic market presents significant opportunities and risks, highlighting the need for accurate price prediction models to manage volatility. This chapter comprehensively reviews machine learning (ML) techniques applied to cryptocurrency price prediction from 2014 to 2024. We explore various ML algorithms, including linear models, tree-based approaches, and advanced deep learning architectures such as transformers and large language models. Additionally, we examine the role of sentiment analysis in capturing market sentiment from textual data like social media posts and news articles to anticipate price fluctuations. With expertise in optimizing complex systems and processes, industrial engineers are pivotal in enhancing these models. They contribute by applying principles of process optimization, efficiency, and risk mitigation to improve computational performance and data management. This chapter highlights the evolving landscape of cryptocurrency price prediction, the integration of emerging technologies, and the significant role of industrial engineers in refining predictive models. By addressing current limitations and exploring future research directions, this chapter aims to advance the development of more accurate and robust prediction systems, supporting better-informed investment decisions and more stable market behavior.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safeguarding Blockchain Ecosystem: Understanding and Detecting Attack Transactions on Cross-chain Bridges</title>
<link>https://arxiv.org/abs/2410.14493</link>
<guid>https://arxiv.org/abs/2410.14493</guid>
<content:encoded><![CDATA[
<div> 关键词: cross-chain bridges、attacks、security、BridgeGuard、graph mining

总结:
本文关注了跨链桥这一促进不同区块链网络间互操作性的关键去中心化应用，由于其涉及线上线下信息协作，面临着更广泛的安全攻击风险。据统计，自2021年以来，针对跨链桥的攻击已导致近43亿美元的损失。因此，理解和检测这类攻击至关重要。文章收集了迄今为止最大的跨链桥攻击事件数据集，共涵盖2021年6月至2024年9月间的49起攻击事件。分析发现，针对跨链业务逻辑的攻击造成的损害远大于非跨链攻击。为了应对此类严重损失及相关研究的稀缺性，本文提出了一种名为BridgeGuard的新工具，用于检测针对跨链业务逻辑的攻击。具体来说，BridgeGuard从图视角建模跨链交易，并采用两阶段检测框架，包括全局和局部图挖掘来识别跨链交易中的攻击模式。实验证明，在包含203笔攻击交易和4万笔正常跨链交易的数据集上，BridgeGuard报告的召回率比现有最先进的工具高出36.32%，并且能够检测未知攻击交易。 <div>
arXiv:2410.14493v1 Announce Type: new 
Abstract: Cross-chain bridges are essential decentralized applications (DApps) to facilitate interoperability between different blockchain networks. Unlike regular DApps, the functionality of cross-chain bridges relies on the collaboration of information both on and off the chain, which exposes them to a wider risk of attacks. According to our statistics, attacks on cross-chain bridges have resulted in losses of nearly 4.3 billion dollars since 2021. Therefore, it is particularly necessary to understand and detect attacks on cross-chain bridges. In this paper, we collect the largest number of cross-chain bridge attack incidents to date, including 49 attacks that occurred between June 2021 and September 2024. Our analysis reveal that attacks against cross-chain business logic cause significantly more damage than those that do not. These cross-chain attacks exhibit different patterns compared to normal transactions in terms of call structure, which effectively indicates potential attack behaviors. Given the significant losses in these cases and the scarcity of related research, this paper aims to detect attacks against cross-chain business logic, and propose the BridgeGuard tool. Specifically, BridgeGuard models cross-chain transactions from a graph perspective, and employs a two-stage detection framework comprising global and local graph mining to identify attack patterns in cross-chain transactions. We conduct multiple experiments on the datasets with 203 attack transactions and 40,000 normal cross-chain transactions. The results show that BridgeGuard's reported recall score is 36.32\% higher than that of state-of-the-art tools and can detect unknown attack transactions.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Based Trust and Transparency in Airline Reservation Systems using Microservices Architecture</title>
<link>https://arxiv.org/abs/2410.14518</link>
<guid>https://arxiv.org/abs/2410.14518</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、航空公司预订系统、信任、透明度、效率提升

<br /><br />总结:
该研究详细分析了区块链技术应用于航空公司的预订系统中，旨在增强客户信任、提高透明度和运营效率。通过利用区块链的去中心化数据库、永久交易记录以及通过代码执行的交易条款等功能，成功减少了预订差异达30%，并实现了数据同步性的提升。实施区块链技术包括采用多个API自动化的多方面记录保存系统及智能合约执行，使得流程周期时间平均减少40%，同时确保协议不会被违反。系统的架构无单点故障，可靠性超过98%，加强的安全措施使85%的客户对服务表示信任。然而，尽管区块链有望重塑航空行业的预订业务，但仍面临可扩展性和法规遵从性等挑战。此研究为进一步针对这些问题进行更深入、更适用航空行业的研究奠定了基础。 <div>
arXiv:2410.14518v1 Announce Type: new 
Abstract: This research gives a detailed analysis of the application of blockchain technology to the airline reservation systems in order to bolster trust, transparency, and operational efficiency by overcoming several challenges including customer control and data integrity issues. The study investigates the major components of blockchain technology such as decentralised databases, permanent records of transactions and transactional clauses executed via codes of programs and their impacts on automated systems and real-time tracking of audits. The results show a 30% decrease in booking variations together with greater data synchronization as a result of consensus processes and resistant data formations. The approach to the implementation of a blockchain technology for the purpose of this paper includes many APIs for the automatic multi-faceted record-keeping system including the smart contract execution and controllable end-users approach. Smart contracts organized the processes improving the cycle times by 40% on the average while guaranteeing no breach of agreements. In addition to this, the architecture of the system has no single point failure with over 98% reliability while measures taken to improve security have led to 85% of the customers expressing trust in the services provided. In summation, the results suggest that reservations in the airline sector stand a chance of being redefined with blockchain through savoring the benefits of a single source of truth while attempting to resolve this intrinsic problem of overcomplexity. Although the system improves the experience of customers and the level of operational transparency, issues concerning scalability and regulatory adherence. This research is also a stepping stone for further studies that are intended to address these challenges and more applicable to the airline industry.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Using Sentiment and Technical Analysis to Predict Bitcoin with Machine Learning</title>
<link>https://arxiv.org/abs/2410.14532</link>
<guid>https://arxiv.org/abs/2410.14532</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、价格预测、市场情绪、技术分析指标、机器学习

总结:
本文研究了一种新的比特币价格预测方法，该方法结合了市场情绪指标“恐惧与贪婪指数”、技术分析指标以及机器学习算法。相较于现有文献，本工作着重关注将市场情绪指标应用于加密货币预测中的重要性。初步实验显示，该模型在投资回报上超越了买入并持有的基准策略，证明了情绪和市场指标相结合在数字货币预测模型中的有效性。 <div>
arXiv:2410.14532v1 Announce Type: new 
Abstract: Cryptocurrencies have gained significant attention in recent years due to their decentralized nature and potential for financial innovation. Thus, the ability to accurately predict its price has become a subject of great interest for investors, traders, and researchers. Some works in the literature show how Bitcoin's market sentiment correlates with its price fluctuations in the market. However, papers that consider the sentiment of the market associated with financial Technical Analysis indicators in order to predict Bitcoin's price are still scarce. In this paper, we present a novel approach for predicting Bitcoin price movements by combining the Fear & Greedy Index, a measure of market sentiment, Technical Analysis indicators, and the potential of Machine Learning algorithms. This work represents a preliminary study on the importance of sentiment metrics in cryptocurrency forecasting. Our initial experiments demonstrate promising results considering investment returns, surpassing the Buy & Hold baseline, and offering valuable insights about the combination of indicators of sentiment and market in a cryptocurrency prediction model.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>$\pi$QLB: A Privacy-preserving with Integrity-assuring Query Language for Blockchain</title>
<link>https://arxiv.org/abs/2212.14141</link>
<guid>https://arxiv.org/abs/2212.14141</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据查询机制、安全性、隐私保护、$\pi$QLB<br /><br />总结:<br />
本文提出了一个名为$\pi$QLB的新颖区块链查询语言，旨在确保区块链系统中查询输入的机密性和查询结果的完整性。随着区块链技术在不同领域的广泛应用，如医疗系统和供应链管理，对支持安全及隐私保障的数据查询机制的需求日益增长。现有的区块链系统无法满足这一需求，用户需以明文形式提交查询给运营商，这可能导致用户隐私泄露。同时，用户若要验证查询结果的完整性，则需要存储整个区块链数据库并进行本地查询，这种方法成本高昂，不适用于轻量级设备（如智能手机）。为解决这些问题，$\pi$QLB引入了关系数据语义，使区块链数据库能够支持类似于SQL的查询，并利用最新的加密原语——函数秘密分享（FSS）来实现查询输入的机密性。此外，为了保证完整性，$\pi$QLB扩展了传统FSS设置，使得能高效验证FSS结果的正确性，从而让用户能信任没有恶意行为的服务器产生的结果。据作者所知，$\pi$QLB是首个支持机密性、完整性和类似SQL查询功能的区块链数据库查询模型。 <div>
arXiv:2212.14141v2 Announce Type: replace 
Abstract: The increase in the adoption of blockchain technology in different application domains e.g., healthcare systems, supplychain management, has raised the demand for a data query mechanism on blockchain. Since current blockchain systems lack the support for querying data with embedded security and privacy guarantees, there exists inherent security and privacy concerns on those systems. In particular, existing systems require users to submit queries to blockchain operators (e.g., a node validator) in plaintext. This directly jeopardizes users' privacy as the submitted queries may contain sensitive information, e.g., location or gender preferences, that the users may not be comfortable sharing. On the other hand, currently, the only way for users to ensure integrity of the query result is to maintain the entire blockchain database and perform the queries locally. Doing so incurs high storage and computational costs on the users, precluding this approach to be practically deployable on common light-weight devices (e.g., smartphones). To this end, this paper proposes $\pi$QLB, a query language for blockchain systems that ensures both confidentiality of query inputs and integrity of query results. Additionally, $\pi$QLB enables SQL-like queries over the blockchain data by introducing relational data semantics into the existing blockchain database. $\pi$QLB has applied the recent cryptography primitive, i.e., function secret sharing (FSS), to achieve confidentiality. To support integrity, we extend the traditional FSS setting in such a way that integrity of FSS results can be efficiently verified. Successful verification indicates absence of malicious behaviors on the servers, allowing the user to establish trust from the result. To the best of our knowledge, $\pi$QLB is the first query model designed for blockchain databases with support for confidentiality, integrity, and SQL-like queries.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning-Augmented Decentralized Online Convex Optimization in Networks</title>
<link>https://arxiv.org/abs/2306.10158</link>
<guid>https://arxiv.org/abs/2306.10158</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized online convex optimization, LADO算法, local online information, worst-case robustness, machine learning policy

总结:<br />
本文研究了网络化多智能体系统的分布式在线凸优化问题，并提出了一种新颖的算法——学习增强型分布式在线优化（LADO）。LADO允许每个代理仅基于本地在线信息选择行动，利用基准策略保障最坏情况下的鲁棒性保证，同时尽可能接近机器学习（ML）策略以提升平均性能。与现有关注集中式设置的学习增强型在线算法形成鲜明对比，LADO在分布式环境中实现了强大的鲁棒性保证。此外，文中还证明了LADO的平均成本界，揭示了平均性能与最坏情况鲁棒性之间的权衡，并表明通过明确考虑鲁棒性要求来训练ML策略的优势。 <div>
arXiv:2306.10158v3 Announce Type: replace 
Abstract: This paper studies decentralized online convex optimization in a networked multi-agent system and proposes a novel algorithm, Learning-Augmented Decentralized Online optimization (LADO), for individual agents to select actions only based on local online information. LADO leverages a baseline policy to safeguard online actions for worst-case robustness guarantees, while staying close to the machine learning (ML) policy for average performance improvement. In stark contrast with the existing learning-augmented online algorithms that focus on centralized settings, LADO achieves strong robustness guarantees in a decentralized setting. We also prove the average cost bound for LADO, revealing the tradeoff between average performance and worst-case robustness and demonstrating the advantage of training the ML policy by explicitly considering the robustness requirement.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-Efficient Distributed Deep Learning via Federated Dynamic Averaging</title>
<link>https://arxiv.org/abs/2405.20988</link>
<guid>https://arxiv.org/abs/2405.20988</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式深度学习（DDL）、通信瓶颈、Federated Dynamic Averaging (FDA)、模型同步、数据异质性

<br /><br />总结:
为了解决分布式深度学习(DDL)中因频繁模型同步导致的通信瓶颈和效率问题，本文提出了Federated Dynamic Averaging (FDA)策略。FDA是一种基于模型差异度动态触发同步的通信高效方法，仅当从全局模型初始化的局部模型发生显著偏离时才进行昂贵的同步步骤。每个分布式节点发送少量本地状态信息以辅助该决策。实验表明，与传统和前沿的通信效率算法相比，FDA能大幅降低通信成本并保持在不同数据异质性设置下的稳健性能。 <div>
arXiv:2405.20988v3 Announce Type: replace 
Abstract: Driven by the ever-growing volume and decentralized nature of data, coupled with the need to harness this data and generate knowledge from it, has led to the extensive use of distributed deep learning (DDL) techniques for training. These techniques rely on local training that is performed at the distributed nodes based on locally collected data, followed by a periodic synchronization process that combines these models to create a global model. However, frequent synchronization of DL models, encompassing millions to many billions of parameters, creates a communication bottleneck, severely hindering scalability. Worse yet, DDL algorithms typically waste valuable bandwidth, and make themselves less practical in bandwidth-constrained federated settings, by relying on overly simplistic, periodic, and rigid synchronization schedules. These drawbacks also have a direct impact on the time required for the training process, necessitating excessive time for data communication. To address these shortcomings, we propose Federated Dynamic Averaging (FDA), a communication-efficient DDL strategy that dynamically triggers synchronization based on the value of the model variance. In essence, the costly synchronization step is triggered only if the local models, which are initialized from a common global model after each synchronization, have significantly diverged. This decision is facilitated by the communication of a small local state from each distributed node/worker. Through extensive experiments across a wide range of learning tasks we demonstrate that FDA reduces communication cost by orders of magnitude, compared to both traditional and cutting-edge communication-efficient algorithms. Additionally, we show that FDA maintains robust performance across diverse data heterogeneity settings.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dyna-5G: A Dynamic, Flexible, and Self-Organizing 5G Network for M2M Ecosystems</title>
<link>https://arxiv.org/abs/2406.15681</link>
<guid>https://arxiv.org/abs/2406.15681</guid>
<content:encoded><![CDATA[
<div> 关键词: Dyna-5G, 5G-NR, 异构网络, 自组织, 机器间通信

总结:
本文介绍了Dyna-5G，这是一种针对大规模机器间通信（M2M）网络设计的动态、自组织的5G新无线（5G-NR）网络。传统集中式架构的5G NR网络在支持需要动态、分散通信的应用（如自动驾驶车辆和应急响应无人机群）时面临挑战，因为这些场景常常受到中心化模型单点故障的影响，从而削弱了对关键和全自主应用所需的高度可靠性。Dyna-5G解决了这些问题，允许网络中的每个设备同时充当无线接入网（RAN）、核心网络或用户设备（UE），即使常规基础设施组件受损也能保持网络功能。此外，Dyna-5G内置了专门针对M2M网络的设计机制，如故障恢复和临时加入与退出。通过定制的测试平台模拟实际任务来展示Dyna-5G的性能和可行性，结果显示该网络具有强大的鲁棒性、适应性和快速故障恢复能力，整个网络模型能在最多6秒内完全重新组织，而不影响任务执行。 <div>
arXiv:2406.15681v2 Announce Type: replace 
Abstract: In this work, we present Dyna-5G, a dynamic, self-organizing 5G New Radio (5G-NR) network designed for massive Machine-to-Machine (M2M) networks. Traditional 5G NR networks, characterized by their centralized architecture, face challenges in supporting applications that require dynamic, decentralized communication, such as autonomous vehicles and drone swarms for emergency responses. These scenarios often suffer from the centralized model's single point of failure, undermining the reliability required in critical and fully autonomous applications. Dyna-5G addresses these challenges by allowing each device in the network to function as either part of the Radio Access Network (RAN) and Core Network, or as User Equipment (UE), thus maintaining network functionality even when conventional infrastructure components are compromised. Dyna-5G has built-in mechanisms carefully designed specifically for M2M networks, such as failure-recovery and ad-hoc entry and exit. We demonstrate the performance and feasibility of Dyna-5G using a custom-built testbed that simulates real-world missions, demonstrating our network's robustness, adaptability, and failure recovery capabilities. The results indicate that our entire 5G network model can fully re-organize in 6 seconds at maximum, without compromising the mission.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design of an Efficient Fan-Shaped Clustered Trust-Based Routing Model with QoS &amp; Security-Aware Side-Chaining for IoV Deployments</title>
<link>https://arxiv.org/abs/2410.12798</link>
<guid>https://arxiv.org/abs/2410.12798</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网车辆, 可信路由模型, 服务质量, 安全, 旁链管理<br /><br />总结:<br /><br />本文介绍了一种针对物联网车辆(IoV)部署的新型扇形信任基础路由模型，该模型结合了服务质量(QoS)和安全意识旁链管理。通过使用细菌觅食优化器(BFO)算法动态调整旁链配置，提高了系统性能。研究采用了扇形聚类技术来提高通信效率和资源利用，并通过实验验证了其有效性。该模型在延迟、吞吐量、数据包递送率(PDR)和能量消耗方面均优于现有方法，分别减少了9.5%、提高了10.5%、提高了2.9%和减少了4.5%。此外，该模型对Sybil、伪装和泛洪攻击等常见IoV威胁具有更强的抵抗力，确保了持续和可靠的数据传输。这些成果对于智能城市、工业自动化、医疗系统、交通网络和环境监测等领域具有广泛应用价值。 <div>
arXiv:2410.12798v1 Announce Type: new 
Abstract: The rapid expansion of Internet of Vehicles (IoV) deployments has necessitated the creation of efficient and secure routing models to manage the massive data traffic generated by interconnected devices & vehicles. For IoV deployments, we propose a novel fan-shaped trust-based routing model with Quality of Service (QoS) and security-aware side-chaining. Our method employs temporal levels of delay, throughput, Packet Delivery Ratio (PDR), and energy consumption to determine optimal routing paths, thereby ensuring efficient data transmissions. We employ the Bacterial Foraging Optimizer (BFO) algorithm to manage side-chains within the network, which dynamically adjusts side-chain configurations to optimize system performance. The technique of fan-shaped clustering is used to group nodes into efficient clusters, allowing for more efficient communication and resource utilization sets. Extensive experimentation and performance analysis are utilized to evaluate the proposed model. Existing blockchain-based security models have been significantly improved by our findings. Our model achieves a remarkable 9.5% reduction in delay, a 10.5% improvement in throughput, a 2.9% improvement in PDR, and a 4.5% reduction in energy consumption compared to alternative approaches. In addition, we evaluate the model's resistance to Sybil, Masquerading, and Flooding attacks, which are prevalent security threats for IoV deployments. Even under these attack scenarios, our model provides consistently higher QoS levels compared to existing solutions, ensuring uninterrupted and reliable data transmissions. In IoV deployments, the proposed routing model and side-chaining management approach have numerous applications and use-cases like Smart cities, industrial automation, healthcare systems, transportation networks, and environmental monitoring.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation</title>
<link>https://arxiv.org/abs/2410.12926</link>
<guid>https://arxiv.org/abs/2410.12926</guid>
<content:encoded><![CDATA[
<div> 关键词: 低秩适应, 联邦学习, 差分隐私, 聚合偏差, 噪声调节<br /><br />总结:<br />
本文介绍了一种新的隐私保护联邦微调框架DEeR，旨在解决低秩适应（LoRA）与联邦学习（FL）结合时出现的聚合偏差和差分隐私（DP）噪声放大问题。首先，理论证明了消除聚合偏差的关键在于保证客户端LoRA参数的等价性，并设计了偏差消除器来优化LoRA参数矩阵，确保训练过程中聚合偏差为零。其次，对噪声放大效应进行了深入分析，发现该问题主要由DP噪声与LoRA参数之间的线性关系引起，因此提出了噪声调节器来解耦这种关系，从而实现更好的隐私保护和微调性能。最后，通过全面的实验验证了偏差消除器和噪声调节器的有效性，结果显示DEeR在公共医疗数据集上优于现有最先进的方法。相关代码已开源。 <div>
arXiv:2410.12926v1 Announce Type: new 
Abstract: Integrating low-rank adaptation (LoRA) with federated learning (FL) has received widespread attention recently, aiming to adapt pretrained foundation models (FMs) to downstream medical tasks via privacy-preserving decentralized training. However, owing to the direct combination of LoRA and FL, current methods generally undergo two problems, i.e., aggregation deviation, and differential privacy (DP) noise amplification effect. To address these problems, we propose a novel privacy-preserving federated finetuning framework called \underline{D}eviation \underline{E}liminating and Nois\underline{e} \underline{R}egulating (DEeR). Specifically, we firstly theoretically prove that the necessary condition to eliminate aggregation deviation is guaranteing the equivalence between LoRA parameters of clients. Based on the theoretical insight, a deviation eliminator is designed to utilize alternating minimization algorithm to iteratively optimize the zero-initialized and non-zero-initialized parameter matrices of LoRA, ensuring that aggregation deviation always be zeros during training. Furthermore, we also conduct an in-depth analysis of the noise amplification effect and find that this problem is mainly caused by the ``linear relationship'' between DP noise and LoRA parameters. To suppress the noise amplification effect, we propose a noise regulator that exploits two regulator factors to decouple relationship between DP and LoRA, thereby achieving robust privacy protection and excellent finetuning performance. Additionally, we perform comprehensive ablated experiments to verify the effectiveness of the deviation eliminator and noise regulator. DEeR shows better performance on public medical datasets in comparison with state-of-the-art approaches. The code is available at https://github.com/CUHK-AIM-Group/DEeR.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Future of Algorithmic Organization: Large-Scale Analysis of Decentralized Autonomous Organizations (DAOs)</title>
<link>https://arxiv.org/abs/2410.13095</link>
<guid>https://arxiv.org/abs/2410.13095</guid>
<content:encoded><![CDATA[
<div> DAO 去中心化 自治组织 治理模型 参与度<br /><br />总结:<br />本文研究了去中心化自治组织（DAO）的运作机制，分析了包括pleasrdao、lexdao等在内的100个DAO。研究发现，大规模的实证分析显示，DAO中草根参与度的提高与更高的去中心化水平相关，而投票权力分配的均衡性也影响着DAO的去中心化程度。这些发现对于政治科学领域关于决策中的权力分配及治理模型的影响有着重要启示，同时为新兴应用中民主治理系统的构建提供了参考依据。 <div>
arXiv:2410.13095v1 Announce Type: new 
Abstract: Decentralized Autonomous Organizations (DAOs) resemble early online communities, particularly those centered around open-source projects, and present a potential empirical framework for complex social-computing systems by encoding governance rules within "smart contracts" on the blockchain. A key function of a DAO is collective decision-making, typically carried out through a series of proposals where members vote on organizational events using governance tokens, signifying relative influence within the DAO. In just a few years, the deployment of DAOs surged with a total treasury of $24.5 billion and 11.1M governance token holders collectively managing decisions across over 13,000 DAOs as of 2024. In this study, we examine the operational dynamics of 100 DAOs, like pleasrdao, lexdao, lootdao, optimism collective, uniswap, etc. With large-scale empirical analysis of a diverse set of DAO categories and smart contracts and by leveraging on-chain (e.g., voting results) and off-chain data, we examine factors such as voting power, participation, and DAO characteristics dictating the level of decentralization, thus, the efficiency of management structures. As such, our study highlights that increased grassroots participation correlates with higher decentralization in a DAO, and lower variance in voting power within a DAO correlates with a higher level of decentralization, as consistently measured by Gini metrics. These insights closely align with key topics in political science, such as the allocation of power in decision-making and the effects of various governance models. We conclude by discussing the implications for researchers, and practitioners, emphasizing how these factors can inform the design of democratic governance systems in emerging applications that require active engagement from stakeholders in decision-making.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity</title>
<link>https://arxiv.org/abs/2410.13141</link>
<guid>https://arxiv.org/abs/2410.13141</guid>
<content:encoded><![CDATA[
<div> 关键词：神经网络 联邦学习 科学机器学习 偏微分方程 数据异质性<br /><br />总结:<br />
本文研究了联邦学习（FL）与科学机器学习（SciML）的结合，以解决数据分布、隐私和传输问题。文章提出了两种新模型：联邦物理信息神经网络（FedPINN）和联邦深度算子网络（FedDeepONet），并介绍了多种数据生成方法来控制非独立同分布（non-iid）数据的程度。通过使用1-瓦瑟斯坦距离量化函数逼近和偏微分方程（PDE）学习中的数据异质性，系统地探讨了数据异质性与联邦模型性能之间的关系。此外，文章提出了一种权重发散度量，并开发了一个理论框架，以建立联邦学习与传统集中式学习之间权重发散的增长界限。实验结果表明，所提出的联邦方法不仅优于仅使用本地数据训练的模型，而且在准确性上可与使用所有数据训练的集中式模型相媲美。 <div>
arXiv:2410.13141v1 Announce Type: new 
Abstract: By leveraging neural networks, the emerging field of scientific machine learning (SciML) offers novel approaches to address complex problems governed by partial differential equations (PDEs). In practical applications, challenges arise due to the distributed essence of data, concerns about data privacy, or the impracticality of transferring large volumes of data. Federated learning (FL), a decentralized framework that enables the collaborative training of a global model while preserving data privacy, offers a solution to the challenges posed by isolated data pools and sensitive data issues. Here, this paper explores the integration of FL and SciML to approximate complex functions and solve differential equations. We propose two novel models: federated physics-informed neural networks (FedPINN) and federated deep operator networks (FedDeepONet). We further introduce various data generation methods to control the degree of non-independent and identically distributed (non-iid) data and utilize the 1-Wasserstein distance to quantify data heterogeneity in function approximation and PDE learning. We systematically investigate the relationship between data heterogeneity and federated model performance. Additionally, we propose a measure of weight divergence and develop a theoretical framework to establish growth bounds for weight divergence in federated learning compared to traditional centralized learning. To demonstrate the effectiveness of our methods, we conducted 10 experiments, including 2 on function approximation, 5 PDE problems on FedPINN, and 3 PDE problems on FedDeepONet. These experiments demonstrate that proposed federated methods surpass the models trained only using local data and achieve competitive accuracy of centralized models trained using all data.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pricing Factors and TFMs for Scalability-Focused ZK-Rollups</title>
<link>https://arxiv.org/abs/2410.13277</link>
<guid>https://arxiv.org/abs/2410.13277</guid>
<content:encoded><![CDATA[
<div> ZK-Rollups 交易费机制 序列化 数据可用性 零知识证明 激励相容<br /><br />总结:<br />本文探讨了ZK-Rollups中的交易费机制（TFMs）设计，重点分析了序列化、数据可用性和零知识证明等关键组件如何相互作用影响成本结构。文章提出了适合TFMs应具备的特性，如激励相容和净盈利性，并讨论了不同TFM方案的权衡及开放问题，这些都需要进一步研究。 <div>
arXiv:2410.13277v1 Announce Type: new 
Abstract: ZK-Rollups have emerged as a leading solution for blockchain scalability, leveraging succinct proofs primarily based on ZKP protocols. This paper explores the design of transaction fee mechanisms (TFMs) for ZK-Rollups, focusing on how key components like sequencing, data availability~(DA), and ZK proving interact to influence cost structures. We outline the properties that a suitable TFM should possess, such as incentive compatibility and net profitability. In addition, we propose alternatives for TFMs, discuss trade-offs, and highlight open questions that require further investigation in the context of ZK-Rollups.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assessing the techno-economic benefits of LEMs for different grid topologies and prosumer shares</title>
<link>https://arxiv.org/abs/2410.13330</link>
<guid>https://arxiv.org/abs/2410.13330</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式能源资源, 本地能源市场, 经济效率, 网格稳定性, 可再生能源

<br /><br />总结:<br />
本文探讨了本地能源市场在整合分布式能源资源（如光伏系统、电动汽车和热泵）方面相对于传统市场设计的优势。研究使用自开发的基于代理的能量系统仿真工具，通过模拟不同电网拓扑结构（乡村、农村、郊区和城市）及不同的分布式能源渗透水平，证明了本地能源市场的引入能够提升经济效率并增强电网稳定性。具体而言，99%的场景显示平均能源价格降低，80%的场景显示运营峰值功率降低。研究表明，在高比例光伏和热泵地区，如果能将额外基础设施、管理成本和官僚复杂性控制在最低限度，本地能源市场将在未来能源系统中发挥重要作用。 <div>
arXiv:2410.13330v1 Announce Type: new 
Abstract: The shift towards decentralized and renewable energy sources has introduced significant challenges to traditional power systems, necessitating innovative market designs. Local energy markets present a viable solution for integrating distributed energy resources such as photovoltaic systems, electric vehicles, and heat pumps within various grid topologies. This study investigates the techno-economic benefits of local energy markets compared to conventional market designs, focusing on their impact on average energy prices and operational peak power, using a self-developed agent-based energy system simulation tool. Through comprehensive simulations across the countryside, rural, suburban, and urban grid topologies with varying penetration levels of the distributed energy resources, totaling 400 simulation setups, we demonstrate that local energy markets can enhance economic efficiency and grid stability with 99 % of the scenarios boasting lower average energy prices and 80 % lower operational peak power levels. Our findings suggest that local energy markets can play a role in the future energy system, especially in areas with high shares of PV and HP, provided that additional infrastructure, management costs, and bureaucratic complexity are kept to a minimum.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Formal Verification of Federated Learning Orchestration Protocols on Satellites</title>
<link>https://arxiv.org/abs/2410.13429</link>
<guid>https://arxiv.org/abs/2410.13429</guid>
<content:encoded><![CDATA[
<div> 关键词：Python Testbed、联邦学习、定时自动机、随机模型、航天器运动<br /><br />总结:<br />本文介绍了Python测试平台（PTB-FLA），这是一个用于智能物联网边缘系统的联邦学习算法框架，支持集中式和分布式联邦学习算法。这些算法通过CSP过程代数进行了形式化验证。然而，该方法适用于静态节点系统，不适用于移动节点系统。因此，本文使用天体力学建模航天器运动，并采用定时自动机（TA）对集中式联邦学习编排协议进行形式化和验证。验证分为两个阶段：第一阶段，创建传统TA模型以证明无死锁性和终止性；第二阶段，构建随机TA模型以验证时间正确性和估计终止概率。 <div>
arXiv:2410.13429v1 Announce Type: new 
Abstract: Python Testbed for Federated Learning Algorithms (PTB-FLA) is a simple FL framework targeting smart Internet of Things in edge systems that provides both generic centralized and decentralized FL algorithms, which implement the corresponding FL orchestration protocols that were formally verified using the process algebra CSP. This approach is appropriate for systems with stationary nodes but cannot be applied to systems with moving nodes. In this paper, we use celestial mechanics to model spacecraft movement, and timed automata (TA) to formalize and verify the centralized FL orchestration protocol, in two phases. In the first phase, we created a conventional TA model to prove traditional properties, namely deadlock freeness and termination. In the second phase, we created a stochastic TA model to prove timing correctness and to estimate termination probability.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal MEV Extraction Using Absolute Commitments</title>
<link>https://arxiv.org/abs/2410.13624</link>
<guid>https://arxiv.org/abs/2410.13624</guid>
<content:encoded><![CDATA[
<div> 攻击 去中心化交易所 绝对承诺 智能合约 垄断价格<br /><br />总结:<br />文章提出了一种针对去中心化交易所的新攻击方法。该攻击利用了绝对承诺，即承诺可以依赖于其他参与者的行为策略。通过这种策略，攻击者能够以垄断价格进行收费，从而从用户那里榨取最大可能的价格，甚至可能通过规避通常费用和低效性的侧信道来实现。这比现有的“三明治攻击”更为高效，后者主要通过诱导市场价波动来获利。文章指出，这种新攻击可以通过智能合约实现，因为智能合约具有不可撤销和自动执行的特点，广泛存在于主流区块链中。因此，这种攻击可能会严重损害受影响的去中心化交易所的功能。 <div>
arXiv:2410.13624v1 Announce Type: new 
Abstract: We propose a new, more potent attack on decentralized exchanges. This attack leverages absolute commitments, which are commitments that can condition on the strategies made by other agents. This attack allows an adversary to charge monopoly prices by committing to undercut those other miners that refuse to charge an even higher fee. This allows the miner to extract the maximum possible price from the user, potentially through side channels that evade the inefficiencies and fees usually incurred. This is considerably more efficient than the prevailing strategy of `sandwich attacks', wherein the adversary induces and profits from fluctuations in the market price to the detriment of users. The attack we propose can, in principle, be realized by the irrevocable and self-executing nature of smart contracts, which are readily available on many major blockchains. Thus, the attack could potentially be used against a decentralized exchange and could drastically reduce the utility of the affected exchange.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unconstrained Model Merging for Enhanced LLM Reasoning</title>
<link>https://arxiv.org/abs/2410.13699</link>
<guid>https://arxiv.org/abs/2410.13699</guid>
<content:encoded><![CDATA[
<div> 模型融合 专家模型 推理任务 去中心化 模型架构<br /><br />总结:<br />本文探讨了将多个专家模型融合成单一大语言模型（LLM）的潜力，作为资源友好型替代方案。研究重点在于推理任务，提出了一种不受约束的模型融合框架，适用于同构和异构模型架构。对于同构模型，设计了细粒度的层权重融合策略；对于异构模型，则基于指令响应微调数据的概率分布知识构建。实验结果显示，通过模型融合产生的组合推理能力超越了简单的加法效应。这表明，不受约束的模型融合可以作为去中心化LLM的基础，标志着从现有集中式LLM框架的重要进步，有助于促进更广泛参与和人工智能领域的进一步发展。 <div>
arXiv:2410.13699v1 Announce Type: new 
Abstract: Recent advancements in building domain-specific large language models (LLMs) have shown remarkable success, especially in tasks requiring reasoning abilities like logical inference over complex relationships and multi-step problem solving. However, creating a powerful all-in-one LLM remains challenging due to the need for proprietary data and vast computational resources. As a resource-friendly alternative, we explore the potential of merging multiple expert models into a single LLM. Existing studies on model merging mainly focus on generalist LLMs instead of domain experts, or the LLMs under the same architecture and size. In this work, we propose an unconstrained model merging framework that accommodates both homogeneous and heterogeneous model architectures with a focus on reasoning tasks. A fine-grained layer-wise weight merging strategy is designed for homogeneous models merging, while heterogeneous model merging is built upon the probabilistic distribution knowledge derived from instruction-response fine-tuning data. Across 7 benchmarks and 9 reasoning-optimized LLMs, we reveal key findings that combinatorial reasoning emerges from merging which surpasses simple additive effects. We propose that unconstrained model merging could serve as a foundation for decentralized LLMs, marking a notable progression from the existing centralized LLM framework. This evolution could enhance wider participation and stimulate additional advancement in the field of artificial intelligence, effectively addressing the constraints posed by centralized models.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On-device Federated Learning in Smartphones for Detecting Depression from Reddit Posts</title>
<link>https://arxiv.org/abs/2410.13709</link>
<guid>https://arxiv.org/abs/2410.13709</guid>
<content:encoded><![CDATA[
<div> 关键词：抑郁检测, 深度学习, 联邦学习, 异构环境, 通信成本<br /><br />总结:<br />本文研究了使用深度学习模型进行抑郁症检测，并特别关注联邦学习（FL）在该领域的应用。研究采用了GRU、RNN和LSTM三种神经网络架构，基于Reddit帖子数据进行抑郁迹象的识别。实验表明，联邦模型在异构环境下与集中式模型性能相当。此外，通过使用通用标记器减少计算负载，并分析了智能手机上的资源消耗和通信成本，证明了FL方法在保护用户隐私的同时，能够实现高效安全的模型训练。这项研究强调了FL在边缘设备上进行去中心化心理健康预测的潜力。 <div>
arXiv:2410.13709v1 Announce Type: new 
Abstract: Depression detection using deep learning models has been widely explored in previous studies, especially due to the large amounts of data available from social media posts. These posts provide valuable information about individuals' mental health conditions and can be leveraged to train models and identify patterns in the data. However, distributed learning approaches have not been extensively explored in this domain. In this study, we adopt Federated Learning (FL) to facilitate decentralized training on smartphones while protecting user data privacy. We train three neural network architectures--GRU, RNN, and LSTM on Reddit posts to detect signs of depression and evaluate their performance under heterogeneous FL settings. To optimize the training process, we leverage a common tokenizer across all client devices, which reduces the computational load. Additionally, we analyze resource consumption and communication costs on smartphones to assess their impact in a real-world FL environment. Our experimental results demonstrate that the federated models achieve comparable performance to the centralized models. This study highlights the potential of FL for decentralized mental health prediction by providing a secure and efficient model training process on edge devices.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Decentralized AI with Confidential Computing</title>
<link>https://arxiv.org/abs/2410.13752</link>
<guid>https://arxiv.org/abs/2410.13752</guid>
<content:encoded><![CDATA[
<div> Confidential Computing, Decentralized AI, Privacy Protection, Trusted Execution Environments, Atoma Network<br /><br />总结: 本文探讨了在去中心化人工智能（Decentralized AI）中利用保密计算（Confidential Computing）保护隐私的问题。文章指出，虽然去中心化AI可以提高透明度和鲁棒性，但其分布式特性也带来了隐私泄露的风险。为解决这一问题，文中提出使用基于硬件的可信执行环境（Trusted Execution Environments, TEEs）来保护敏感数据，确保模型参数和用户数据的安全。该方案被应用于Atoma网络，这是一个专为Web3领域设计的去中心化AI平台。尽管存在一些限制，作者认为这种技术可以有效填补去中心化AI中的隐私保护空白。 <div>
arXiv:2410.13752v1 Announce Type: new 
Abstract: This paper addresses privacy protection in decentralized Artificial Intelligence (AI) using Confidential Computing (CC) within the Atoma Network, a decentralized AI platform designed for the Web3 domain. Decentralized AI distributes AI services among multiple entities without centralized oversight, fostering transparency and robustness. However, this structure introduces significant privacy challenges, as sensitive assets such as proprietary models and personal data may be exposed to untrusted participants. Cryptography-based privacy protection techniques such as zero-knowledge machine learning (zkML) suffers prohibitive computational overhead. To address the limitation, we propose leveraging Confidential Computing (CC). Confidential Computing leverages hardware-based Trusted Execution Environments (TEEs) to provide isolation for processing sensitive data, ensuring that both model parameters and user data remain secure, even in decentralized, potentially untrusted environments. While TEEs face a few limitations, we believe they can bridge the privacy gap in decentralized AI. We explore how we can integrate TEEs into Atoma's decentralized framework.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Exposition of Pathfinding Strategies Within Lightning Network Clients</title>
<link>https://arxiv.org/abs/2410.13784</link>
<guid>https://arxiv.org/abs/2410.13784</guid>
<content:encoded><![CDATA[
<div> 路径搜索策略 路由费用 支付可靠性 连通性 费用锁<br /><br />总结:<br />本文研究了闪电网络中不同节点实现采用的路径搜索策略差异，包括成本函数、约束条件和最短路径贪心算法的不同。研究发现大多数LN节点实现的问题是NP完全问题，无法保证通过目前生产部署的Dijkstra算法变体得到最优解。通过比较分析和模拟实验，文中指出LND策略在支付可靠性方面占优；Eclair策略产生的路径费用较低；LDK策略在小金额支付下可靠性一般但费用较高；CLN则以最小时间锁定路径为特点。此外，文章还探讨了闪电网络节点连接水平对路由效率的影响。这些发现为未来改进路径搜索策略提供了见解。 <div>
arXiv:2410.13784v1 Announce Type: new 
Abstract: The Lightning Network is a peer-to-peer network designed to address Bitcoin's scalability challenges, facilitating rapid, cost-effective, and instantaneous transactions through bidirectional, blockchain-backed payment channels among network peers. Due to a source-based routing of payments, different pathfinding strategies are used in practice, trading off different objectives for each other such as payment reliability and routing fees. This paper explores differences within pathfinding strategies used by prominent Lightning Network node implementations, which include different underlying cost functions and different constraints, as well as different greedy algorithms of shortest path-type. Surprisingly, we observe that the pathfinding problems that most LN node implementations attempt to solve are NP-complete, and cannot be guaranteed to be optimally solved by the variants of Dijkstra's algorithm currently deployed in production. Through comparative analysis and simulations, we evaluate efficacy of different pathfinding strategies across metrics such as success rate, fees, path length, and timelock. Our experiments indicate that the strategies used by LND tend to be advantageous in terms of payment reliability, Eclair tends to result in paths with low fees, and that LDK exhibits average reliability with larger fee levels for smaller payment amounts; furthermore, CLN stands out for its minimal timelock paths. Additionally, we investigate the impact of Lightning node connectivity levels on routing efficiency. The findings of our analysis provide insights towards future improvements of pathfinding strategies and algorithms used within the Lightning Network.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Smart Contract Intent Detection</title>
<link>https://arxiv.org/abs/2211.10724</link>
<guid>https://arxiv.org/abs/2211.10724</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、开发意图、深度学习、F1得分、多标签分类<br /><br />总结:<br />本文介绍了智能合约领域的一个新研究，重点关注如何检测智能合约中的开发意图。由于恶意意图导致了巨大的经济损失，而现有研究缺乏有效的方法来识别这些意图。为了解决这个问题，作者提出了SmartIntentNN（智能合约意图神经网络），这是一种深度学习模型，旨在自动检测智能合约中的开发意图。该模型使用预训练的句子编码器生成智能合约代码的上下文表示，K-means聚类模型识别和突出显示显著的意图特征，并使用双向LSTM进行多标签分类。实验表明，SmartIntentNN在10个不同类别中识别意图的F1得分为0.8633，优于所有基线模型。这项研究填补了智能合约检测中意图分析的空白。 <div>
arXiv:2211.10724v2 Announce Type: replace 
Abstract: In recent years, researchers in the software security field have focused on detecting vulnerabilities in smart contracts to avoid significant losses of crypto assets on the blockchain. Despite early successes in this domain, detecting developers' intents in smart contracts is a more pressing issue, as malicious intents have resulted in substantial financial losses. Unfortunately, existing research lacks effective methods for detecting development intents in smart contracts. To address this gap, we propose \textsc{SmartIntentNN} (Smart Contract Intent Neural Network), a deep learning model designed to automatically detect development intent in smart contracts. \textsc{SmartIntentNN} utilizes a pre-trained sentence encoder to generate contextual representations of smart contract code, a K-means clustering model to identify and highlight prominent intent features, and a bidirectional LSTM-based deep neural network for multi-label classification. We trained and evaluated \textsc{SmartIntentNN} on a dataset comprising over 40,000 real-world smart contracts, employing self-comparison baselines in our experimental setup. The results demonstrate that \textsc{SmartIntentNN} achieves an F1-score of 0.8633 in identifying intents across 10 distinct categories, outperforming all baselines and filling the gap in smart contract detection by incorporating intent analysis.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Airdrops: Giving Money Away Is Harder Than It Seems</title>
<link>https://arxiv.org/abs/2312.02752</link>
<guid>https://arxiv.org/abs/2312.02752</guid>
<content:encoded><![CDATA[
<div> 设计空间 共识机制 经济激励 数据分析 指导方针<br /><br />总结:<br />本文研究了区块链领域中常见的吸引用户策略——空投。文章界定了空投的设计空间，并提出了有效的空投策略的关键成果。通过对六个大规模空投的数据分析，发现大量代币被“空投农民”出售。基于此，文章指出了空投设计中的常见问题，并提供了改进建议，旨在提高空投的有效性和长期社区参与度。 <div>
arXiv:2312.02752v3 Announce Type: replace 
Abstract: Airdrops are a common strategy used by blockchain protocols to attract and grow an initial user base. Tokens are typically distributed to select users as a "reward" for engaging with the protocol, aiming to foster long-term community loyalty and sustained economic activity. Despite their prevalence, there is limited understanding of what makes an airdrop successful. This paper outlines the design space for airdrops and proposes key outcomes for an effective strategy. We analyze on-chain data from six large-scale airdrops to assess their success and find that a substantial portion of tokens is often sold off by "airdrop farmers." Based on this analysis, we highlight common pitfalls and offer guidelines for improving airdrop design.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bluesky and the AT Protocol: Usable Decentralized Social Media</title>
<link>https://arxiv.org/abs/2402.03239</link>
<guid>https://arxiv.org/abs/2402.03239</guid>
<content:encoded><![CDATA[
<div> 关键词：Bluesky, AT协议, 去中心化, 用户切换, 内容管理<br /><br />总结:<br />本文介绍了基于AT协议构建的新社交网络Bluesky。Bluesky自2023年2月私人测试版推出以来，到2024年10月已拥有超过1000万注册用户。文章详细描述了Bluesky和AT协议的架构，并解释了其技术设计如何服务于去中心化、用户自由切换服务提供商、用户对内容的控制以及提供简洁用户体验的目标。系统开放性允许任何人参与内容管理和社区治理，同时鼓励研究界将Bluesky作为数据集和实验平台，用于探索社交媒体管理的新方法。 <div>
arXiv:2402.03239v2 Announce Type: replace 
Abstract: Bluesky is a new social network built upon the AT Protocol, a decentralized foundation for public social media. It was launched in private beta in February 2023, and has grown to over 10 million registered users by October 2024. In this paper we introduce the architecture of Bluesky and the AT Protocol, and explain how the technical design of Bluesky is informed by our goals: to enable decentralization by having multiple interoperable providers for every part of the system; to make it easy for users to switch providers; to give users agency over the content they see; and to provide a simple user experience that does not burden users with complexity arising from the system's decentralized nature. The system's openness allows anybody to contribute to content moderation and community management, and we invite the research community to use Bluesky as a dataset and testing ground for new approaches in social media moderation.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>NFT1000: A Cross-Modal Dataset for Non-Fungible Token Retrieval</title>
<link>https://arxiv.org/abs/2402.16872</link>
<guid>https://arxiv.org/abs/2402.16872</guid>
<content:encoded><![CDATA[
<div> NFT 数据集 CLIP 动态掩码微调 综合方差指数 元数据<br /><br />总结:<br />本文介绍了名为“NFT Top1000 Visual-Text Dataset”(NFT1000)的数据集，该数据集包含来自以太坊区块链上销量最高的1000个PFP NFT集合的756万张图像和文本对。基于此数据集，作者采用CLIP系列预训练模型并提出了一种动态掩码微调方案，这种方法仅使用13%的训练数据就将top1准确率提高了7.4%。此外，文中还提出了一种新的评估指标——综合方差指数(CVI)，用于衡量视觉-文本对数据的相似性和检索难度。该数据集将作为开源资源发布。 <div>
arXiv:2402.16872v2 Announce Type: replace 
Abstract: With the rise of "Metaverse" and "Web 3.0", Non-Fungible Token (NFT) has emerged as a kind of pivotal digital asset, garnering significant attention. By the end of March 2024, more than 1.7 billion NFTs have been minted across various blockchain platforms. To effectively locate a desired NFT, conducting searches within a vast array of NFTs is essential. The challenge in NFT retrieval is heightened due to the high degree of similarity among different NFTs, regarding regional and semantic aspects. In this paper, we will introduce a benchmark dataset named "NFT Top1000 Visual-Text Dataset" (NFT1000), containing 7.56 million image-text pairs, and being collected from 1000 most famous PFP1 NFT collections2 by sales volume on the Ethereum blockchain. Based on this dataset and leveraging the CLIP series of pre-trained models as our foundation, we propose the dynamic masking fine-tuning scheme. This innovative approach results in a 7.4\% improvement in the top1 accuracy rate, while utilizing merely 13\% of the total training data (0.79 million vs. 6.1 million). We also propose a robust metric Comprehensive Variance Index (CVI) to assess the similarity and retrieval difficulty of visual-text pairs data. The dataset will be released as an open-source resource. For more details, please refer to: https://github.com/ShuxunoO/NFT-Net.git.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Writing is on the Wall: Analyzing the Boom of Inscriptions and its Impact on EVM-compatible Blockchains</title>
<link>https://arxiv.org/abs/2405.15288</link>
<guid>https://arxiv.org/abs/2405.15288</guid>
<content:encoded><![CDATA[
<div> 关键词：rollups, 高负载性能, 交易激增, inscriptions, 扩展性<br /><br />总结:<br />
本文研究了在高负载情况下rollups的性能表现，特别是在2023年末至2024年初由inscriptions（一种在区块链上记录数据的方法）引发的交易激增。文章指出，在某些日期，inscriptions几乎占到了Arbitrum和ZKsync Era平台上交易量的90%，而Ethereum上则达到了53%。此外，99%的这些inscriptions与meme币铸造有关。<br />
研究还发现，在交易激增期间，ZKsync和Arbitrum平台的中位gas费用较低，其中ZKsync Era作为零知识rollup，其费用降低幅度大于所研究的乐观rollups（包括Arbitrum、Base和Optimism）。这表明，ZK-rollups在处理大规模交易激增时具有更好的扩展性和成本效益。<br /> <div>
arXiv:2405.15288v2 Announce Type: replace 
Abstract: Although rollups have attracted significant attention, there is limited empirical research on their performance under high load. To address this, we present a data-driven analysis of the transaction surge in late 2023 and early 2024, attributed to inscriptions -- a method for recording data on the blockchain. Initially introduced on Bitcoin, inscriptions enable the representation of NFTs or ERC-20-like tokens without smart contracts, and have since expanded to other blockchains. This paper examines inscription-related transactions on Ethereum and major EVM-compatible rollups, assessing their impact on scalability during transaction surges. Our results show that, on certain days, inscriptions accounted nearly 90% of transactions on Arbitrum and ZKsync Era, while 53% on Ethereum, with 99% of these inscriptions involving meme coin minting. Furthermore, we show that ZKsync and Arbitrum saw lower median gas fees during these surges. ZKsync Era, a ZK-rollup, showed a greater fee reduction than the optimistic rollups studied -- Arbitrum, Base, and Optimism.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-Rollup MEV: Non-Atomic Arbitrage Across L2 Blockchains</title>
<link>https://arxiv.org/abs/2406.02172</link>
<guid>https://arxiv.org/abs/2406.02172</guid>
<content:encoded><![CDATA[
<div> 关键词：Layer-2区块链, 三明治攻击, 价格差异, 套利机会, LVR指标

<br /><br />总结:<br />
本文研究了Layer-2（L2）区块链上的非原子MEV（最大可提取价值），通过测量跨Rollup和DEX-CEX之间的套利机会来量化。近年来，交易活动从以太坊转向Rollups，尽管Rollups上的交易量较低，但其频率更高。文章分析了L2上的交易成本和跨Rollup与DEX-CEX的价格差异，发现超过500,000次未被利用的套利机会。这些机会平均持续10到20个区块，需要修改LVR（损失对再平衡）指标以避免重复计算。研究发现，Arbitrum、Base和Optimism的套利机会占交易量的0.03%至0.05%，而ZKsync的套利机会波动在0.25%左右。 <div>
arXiv:2406.02172v2 Announce Type: replace 
Abstract: This study quantifies the potential non-atomic MEV on Layer-2 (L2) blockchains by measuring the arbitrage opportunities between cross-rollup and DEX-CEX. Over recent years, we observe a shift in trading activities from Ethereum to rollups, with swaps on rollups occurring 2-3 times more frequently, albeit with lower trade volumes. By analyzing the costs of swap on L2s and price discrepancies cross-rollup and DEX-CEX, we identify more than 500 000 unexplored arbitrage opportunities. In particular, we find that these opportunities persist, on average, for 10 to 20 blocks, necessitating the modification of the Loss Versus Rebalancing (LVR) metric to prevent double-counting. Our findings indicate that the arbitrage opportunities in Arbitrum, Base, and Optimism range between 0.03% and 0.05% of the trading volume, while in the ZKsync it fluctuates around 0.25%.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>From promise to practice: realizing high-performance decentralized training</title>
<link>https://arxiv.org/abs/2410.11998</link>
<guid>https://arxiv.org/abs/2410.11998</guid>
<content:encoded><![CDATA[
<div> 关键词: 去中心化训练, 深度神经网络, Adam算法, 变异积累技术, 迭代预算

<br /><br />总结:<br />
本文研究了去中心化训练深度神经网络的优势，并指出通信拓扑、计算模式和优化算法三个关键因素对提升性能的重要性。作者提出了一种去中心化的Adam算法，支持通信与计算的重叠，证明了其收敛性，并引入变异积累技术以应对小批量本地数据带来的高方差问题。实验部署显示，该方法在多达64个GPU的集群中展现出更优的运行时间和泛化性能，在固定迭代预算下具有显著优势。 <div>
arXiv:2410.11998v1 Announce Type: new 
Abstract: Decentralized training of deep neural networks has attracted significant attention for its theoretically superior scalability over synchronous data-parallel methods like All-Reduce. However, realizing this potential in multi-node training is challenging due to the complex design space that involves communication topologies, computation patterns, and optimization algorithms. This paper identifies three key factors that can lead to speedups over All-Reduce training and constructs a runtime model to determine when, how, and to what degree decentralization can yield shorter per-iteration runtimes. Furthermore, to support the decentralized training of transformer-based models, we study a decentralized Adam algorithm that allows for overlapping communications and computations, prove its convergence, and propose an accumulation technique to mitigate the high variance caused by small local batch sizes. We deploy the proposed approach in clusters with up to 64 GPUs and demonstrate its practicality and advantages in both runtime and generalization performance under a fixed iteration budget.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation</title>
<link>https://arxiv.org/abs/2410.12062</link>
<guid>https://arxiv.org/abs/2410.12062</guid>
<content:encoded><![CDATA[
<div> 'MAIF, 分布式, 意图保持, 偏好无关, 平均场控制'<br /><br />总结:<br />本文研究了分布式移动智能体队形（MAiF）问题，这是一种多智能体路径寻找变体，目标是在有限通信和部分观测条件下，让多个智能体快速达到目标同时保持期望队形。文章提出了一种名为平均场控制与包络Q学习（MFC-EQ）的可扩展适应性学习框架，该框架通过平均场理论近似所有智能体的动力学，并通过包络Q学习学习一个通用的偏好无关策略。实验结果表明，MFC-EQ不仅在多个实例中优于现有的集中式MAiF基线，还能有效处理动态变化队形的复杂情况。 <div>
arXiv:2410.12062v1 Announce Type: new 
Abstract: We study a decentralized version of Moving Agents in Formation (MAiF), a variant of Multi-Agent Path Finding aiming to plan collision-free paths for multiple agents with the dual objectives of reaching their goals quickly while maintaining a desired formation. The agents must balance these objectives under conditions of partial observation and limited communication. The formation maintenance depends on the joint state of all agents, whose dimensionality increases exponentially with the number of agents, rendering the learning process intractable. Additionally, learning a single policy that can accommodate different linear preferences for these two objectives presents a significant challenge. In this paper, we propose Mean-Field Control with Envelop $Q$-learning (MFC-EQ), a scalable and adaptable learning framework for this bi-objective multi-agent problem. We approximate the dynamics of all agents using mean-field theory while learning a universal preference-agnostic policy through envelop $Q$-learning. Our empirical evaluation of MFC-EQ across numerous instances shows that it outperforms state-of-the-art centralized MAiF baselines. Furthermore, MFC-EQ effectively handles more complex scenarios where the desired formation changes dynamically -- a challenge that existing MAiF planners cannot address.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proof of Team Sprint: A Collaborative Consensus Algorithm for Reducing Energy Consumption in Blockchain Systems</title>
<link>https://arxiv.org/abs/2410.12135</link>
<guid>https://arxiv.org/abs/2410.12135</guid>
<content:encoded><![CDATA[
<div> Proof of Team Sprint 能源效率 共识算法 区块链 安全性<br /><br />总结:<br />本文介绍了名为Proof of Team Sprint (PoTS)的新共识算法，旨在解决传统工作量证明（PoW）系统中的能源低效问题。PoTS将共识机制从个体竞争转变为团队协作模式，通过组织参与者为小组来协同解决加密难题以验证交易和添加新区块，从而显著降低网络整体能耗并保持高水平的安全性和去中心化。<br />研究显示，与PoW相比，PoTS能将能耗降低N倍，其中N是每组的参与者数量。此外，PoTS还保证了奖励分配的公平性，确保持续参与和网络完整性。文章还讨论了采用PoTS的可扩展性、安全性和潜在挑战，将其定位为可持续区块链技术的一个有前景的替代方案。 <div>
arXiv:2410.12135v1 Announce Type: new 
Abstract: This paper introduces Proof of Team Sprint (PoTS), a novel consensus algorithm designed to address the significant energy inefficiencies inherent in traditional Proof of Work (PoW) systems. PoTS shifts the consensus mechanism from an individual competition model to a collaborative team-based approach. Participants are organized into groups, with each group collaboratively working to solve cryptographic puzzles required to validate transactions and add new blocks to the blockchain. This collaborative approach significantly reduces the overall energy consumption of the network while maintaining high levels of security and decentralization. Our analysis shows that PoTS can reduce energy consumption by a factor of 1/N, where N is the number of participants in each group, compared to PoW. Furthermore, PoTS maintains a fair and equitable reward distribution among participants, ensuring continued engagement and network integrity. The paper also discusses the scalability, security implications, and potential challenges of adopting PoTS, positioning it as a promising alternative for sustainable blockchain technology.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>fAmulet: Finding Finalization Failure Bugs in Polygon zkRollup</title>
<link>https://arxiv.org/abs/2410.12210</link>
<guid>https://arxiv.org/abs/2410.12210</guid>
<content:encoded><![CDATA[
<div> 零知识二层协议 最终化失败漏洞 模糊测试 行为模型 漏洞检测<br /><br />总结:<br />
本文介绍了针对零知识二层协议中最终化失败漏洞的第一项系统性研究，并定义了两种此类漏洞。研究人员开发了fAmulet工具，通过模糊测试来检测Polygon zkRollup中的最终化失败漏洞。为了有效触发这些漏洞，引入了最终化行为模型指导模糊器生成和变异交易。此外，还根据不同的漏洞定义设计了漏洞探测器。评估显示，fAmulet发现了十二个Polygon zkRollup中的零日最终化失败漏洞，并覆盖了比基线更多的代码分支。初步研究表明，fAmulet也可应用于其他零知识二层协议，如Scroll zkRollup，目前所有发现的漏洞已被相关团队确认并修复。 <div>
arXiv:2410.12210v1 Announce Type: new 
Abstract: Zero-knowledge layer 2 protocols emerge as a compelling approach to overcoming blockchain scalability issues by processing transactions through the transaction finalization process. During this process, transactions are efficiently processed off the main chain. Besides, both the transaction data and the zero-knowledge proofs of transaction executions are reserved on the main chain, ensuring the availability of transaction data as well as the correctness and verifiability of transaction executions. Hence, any bugs that cause the transaction finalization failure are crucial, as they impair the usability of these protocols and the scalability of blockchains.
  In this work, we conduct the first systematic study on finalization failure bugs in zero-knowledge layer 2 protocols, and define two kinds of such bugs. Besides, we design fAmulet, the first tool to detect finalization failure bugs in Polygon zkRollup, a prominent zero-knowledge layer 2 protocol, by leveraging fuzzing testing. To trigger finalization failure bugs effectively, we introduce a finalization behavior model to guide our transaction fuzzer to generate and mutate transactions for inducing diverse behaviors across each component (e.g., Sequencer) in the finalization process. Moreover, we define bug oracles according to the distinct bug definitions to accurately detect bugs. Through our evaluation, fAmulet can uncover twelve zero-day finalization failure bugs in Polygon zkRollup, and cover at least 20.8% more branches than baselines. Furthermore, through our preliminary study, fAmulet uncovers a zero-day finalization failure bug in Scroll zkRollup, highlighting the generality of fAmulet to be applied to other zero-knowledge layer 2 protocols. At the time of writing, all our uncovered bugs have been confirmed and fixed by Polygon zkRollup and Scroll zkRollup teams.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Temporal Graph Clustering</title>
<link>https://arxiv.org/abs/2410.12343</link>
<guid>https://arxiv.org/abs/2410.12343</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习, 时序图聚类, 图神经网络, 数据隐私, 动态图<br /><br />总结:<br />本文提出了一种名为联邦时序图聚类（FTGC）的新框架，旨在解决时序图聚类中的隐私和通信问题。该方法通过联邦学习策略实现在多个客户端上的分布式训练，同时利用时序聚合机制捕捉图结构随时间的变化。FTGC框架在保护数据隐私的同时减少了通信开销，实现了与集中式方法相当的性能。这使得它成为处理动态数据且需保护隐私的实际应用中的一个有前景解决方案。 <div>
arXiv:2410.12343v1 Announce Type: new 
Abstract: Temporal graph clustering is a complex task that involves discovering meaningful structures in dynamic graphs where relationships and entities change over time. Existing methods typically require centralized data collection, which poses significant privacy and communication challenges. In this work, we introduce a novel Federated Temporal Graph Clustering (FTGC) framework that enables decentralized training of graph neural networks (GNNs) across multiple clients, ensuring data privacy throughout the process. Our approach incorporates a temporal aggregation mechanism to effectively capture the evolution of graph structures over time and a federated optimization strategy to collaboratively learn high-quality clustering representations. By preserving data privacy and reducing communication overhead, our framework achieves competitive performance on temporal graph datasets, making it a promising solution for privacy-sensitive, real-world applications involving dynamic data.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Private Order Flows and Builder Bidding Dynamics: The Road to Monopoly in Ethereum's Block Building Market</title>
<link>https://arxiv.org/abs/2410.12352</link>
<guid>https://arxiv.org/abs/2410.12352</guid>
<content:encoded><![CDATA[
<div> 关键词: Proposer Builder Separation, PBS, MEV-Boost拍卖, 私有订单流, 市场垄断<br /><br />总结:<br />本文研究了以太坊采用的Proposer Builder Separation (PBS)框架在引入私有订单流后的效果。文章提出了一种名为MEV-Boost拍卖的不对称拍卖模型，并对2023年1月至2024年5月间的以太坊区块进行了实证分析。结果显示，私有订单流占区块价值的54.59%，且拥有更多私有订单流的构建者更有可能赢得区块并保留更大比例的利润。这导致市场逐渐形成垄断。研究发现，当前阶段的PBS未能平衡利润分配，反而将利润集中到了垄断构建者手中，而非机构质押者。 <div>
arXiv:2410.12352v1 Announce Type: new 
Abstract: Ethereum, as a representative of Web3, adopts a novel framework called Proposer Builder Separation (PBS) to prevent the centralization of block profits in the hands of institutional Ethereum stakers. Introducing builders to generate blocks based on public transactions, PBS aims to ensure that block profits are distributed among all stakers. Through the auction among builders, only one will win the block in each slot. Ideally, the equilibrium strategy of builders under public information would lead them to bid all block profits. However, builders are now capable of extracting profits from private order flows. In this paper, we explore the effect of PBS with private order flows. Specifically, we propose the asymmetry auction model of MEV-Boost auction. Moreover, we conduct empirical study on Ethereum blocks from January 2023 to May 2024. Our analysis indicates that private order flows contribute to 54.59% of the block value, indicating that different builders will build blocks with different valuations. Interestingly, we find that builders with more private order flows (i.e., higher block valuations) are more likely to win the block, while retain larger proportion of profits. In return, such builders will further attract more private order flows, resulting in a monopolistic market gradually. Our findings reveal that PBS in current stage is unable to balance the profit distribution, which just transits the centralization of block profits from institutional stakers to the monopolistic builder.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SEMSO: A Secure and Efficient Multi-Data Source Blockchain Oracle</title>
<link>https://arxiv.org/abs/2410.12540</link>
<guid>https://arxiv.org/abs/2410.12540</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链预言机, 多数据源, 数据可靠性, 贝叶斯博弈, TBLS协议<br /><br />总结:<br />本文提出了一种名为SEMSO的新型多数据源区块链预言机框架，旨在通过减少资源开销和响应时间来提高系统的效率和安全性。首先，设计了一种名为TBLS的新协议以低成本保证数据源的多样性和可靠性。其次，基于不完全信息下的贝叶斯博弈模型，对节点的数据源选择任务进行建模和求解，从而在最大化节点收益的同时提升数据聚合成功率和系统响应速度。安全分析验证了所提方案的可靠性，实验表明，在相同环境假设下，SEMSO在保持数据多样性的同时，将响应时间减少了23.5%。 <div>
arXiv:2410.12540v1 Announce Type: new 
Abstract: In recent years, blockchain oracle, as the key link between blockchain and real-world data interaction, has greatly expanded the application scope of blockchain. In particular, the emergence of the Multi-Data Source (MDS) oracle has greatly improved the reliability of the oracle in the case of untrustworthy data sources. However, the current MDS oracle scheme requires nodes to obtain data redundantly from multiple data sources to guarantee data reliability, which greatly increases the resource overhead and response time of the system. Therefore, in this paper, we propose a Secure and Efficient Multi-data Source Oracle framework (SEMSO), which nodes only need to access one data source to ensure the reliability of final data. First, we design a new off-chain data aggregation protocol TBLS, to guarantee data source diversity and reliability at low cost. Second, according to the rational man assumption, the data source selection task of nodes is modeled and solved based on the Bayesian game under incomplete information to maximize the node's revenue while improving the success rate of TBLS aggregation and system response speed. Security analysis verifies the reliability of the proposed scheme, and experiments show that under the same environmental assumptions, SEMSO takes into account data diversity while reducing the response time by 23.5\%.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Communication Consistent Approach to Signal Temporal Logic Task Decomposition in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2410.12563</link>
<guid>https://arxiv.org/abs/2410.12563</guid>
<content:encoded><![CDATA[
<div> 任务分解 通信限制 信号时间逻辑 一致性优化 分布式算法<br /><br />总结:<br />本文研究了在多智能体系统中基于信号时间逻辑（STL）表达的全局任务分解问题，特别是在通信范围有限的情况下。文中提出了将任务依赖关系表示为任务图中的边，并利用通信图来定义哪些智能体可以访问彼此的状态。当任务依赖关系与通信链不匹配时，会导致不一致。作者提出了一种任务分解机制，通过重新分配非通信智能体的任务来保持任务和通信图之间的一致性。该机制假设STL任务中的超级水平集为有界多面体，并将其转化为参数优化问题，通过分布式凸优化算法解决。文章还讨论了任务不可满足的情况，并给出了确保任务可满足的充分条件。 <div>
arXiv:2410.12563v1 Announce Type: new 
Abstract: We consider the problem of decomposing a global task assigned to a multi-agent system, expressed as a formula within a fragment of Signal Temporal Logic (STL), under range-limited communication. Given a global task expressed as a conjunction of local tasks defined over the individual and relative states of agents in the system, we propose representing task dependencies among agents as edges of a suitably defined task graph. At the same time, range-limited communication naturally induces the definition of a communication graph that defines which agents have access to each other's states. Within these settings, inconsistencies arise when a task dependency between a pair of agents is not supported by a corresponding communication link due to the limited communication range. As a result, state feedback control laws previously derived to achieve the tasks' satisfaction can not be leveraged. We propose a task decomposition mechanism to distribute tasks assigned to pairs of non-communicating agents in the system as conjunctions of tasks defined over the relative states of communicating agents, thus enforcing consistency between task and communication graphs. Assuming the super-level sets of the predicate functions composing the STL tasks are bounded polytopes, our task decomposition mechanism can be cast as a parameter optimization problem and solved via state-of-the-art decentralized convex optimization algorithms. To guarantee the soundness of our approach, we present various conditions under which the tasks defined in the applied STL fragment are unsatisfiable, and we show sufficient conditions such that our decomposition approach yields satisfiable global tasks after decomposition.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression</title>
<link>https://arxiv.org/abs/2410.12707</link>
<guid>https://arxiv.org/abs/2410.12707</guid>
<content:encoded><![CDATA[
<div> FusionLLM 去中心化训练 网络通信 模型定义 异构硬件 自动微分<br /><br />总结: 本文介绍了FusionLLM，一种为解决大型深度神经网络（尤其是大规模语言模型）训练过程中硬件资源稀缺问题而设计的去中心化训练系统。该系统通过利用地理分布的不同计算集群或单个设备中的GPU来实现。为了解决去中心化训练中遇到的系统设计和效率问题，如远程自动微分、灵活的模型定义支持、异构硬件导致的资源利用率低或慢节点问题以及网络通信速度慢等，FusionLLM采用了一种基于操作有向无环图（OP-DAG）的设计方法。此外，系统还实现了工作负载估计器、OP-Fence调度器以及自适应TopK压缩器以提高效率。实验结果表明，使用FusionLLM系统与方法在不同网络条件下进行ResNet-101和GPT-2模型训练时，相比基线方法可获得1.45至9.39倍的速度提升，同时保证了模型的收敛性。 <div>
arXiv:2410.12707v1 Announce Type: new 
Abstract: To alleviate hardware scarcity in training large deep neural networks (DNNs), particularly large language models (LLMs), we present FusionLLM, a decentralized training system designed and implemented for training DNNs using geo-distributed GPUs across different computing clusters or individual devices. Decentralized training faces significant challenges regarding system design and efficiency, including: 1) the need for remote automatic differentiation (RAD), 2) support for flexible model definitions and heterogeneous software, 3) heterogeneous hardware leading to low resource utilization or the straggler problem, and 4) slow network communication. To address these challenges, in the system design, we represent the model as a directed acyclic graph of operators (OP-DAG). Each node in the DAG represents the operator in the DNNs, while the edge represents the data dependency between operators. Based on this design, 1) users are allowed to customize any DNN without caring low-level operator implementation; 2) we enable the task scheduling with the more fine-grained sub-tasks, offering more optimization space; 3) a DAG runtime executor can implement RAD withour requiring the consistent low-level ML framework versions.
  To enhance system efficiency, we implement a workload estimator and design an OP-Fence scheduler to cluster devices with similar bandwidths together and partition the DAG to increase throughput. Additionally, we propose an AdaTopK compressor to adaptively compress intermediate activations and gradients at the slowest communication links. To evaluate the convergence and efficiency of our system and algorithms, we train ResNet-101 and GPT-2 on three real-world testbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental results demonstrate that our system and method can achieve 1.45 - 9.39x speedup compared to baseline methods while ensuring convergence.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Control and Coordinate Mixed Traffic Through Robot Vehicles at Complex and Unsignalized Intersections</title>
<link>https://arxiv.org/abs/2301.05294</link>
<guid>https://arxiv.org/abs/2301.05294</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习 交通拥堵 混合交通 无人车 交叉口控制<br /><br />总结:<br />本文提出了一种基于多智能体强化学习的方法来管理和协调混合交通（包括人类驾驶车辆和机器人车辆）在复杂交叉口的运行。研究结果表明，即使只有5%的无人车辆存在，也能有效防止交通拥堵的发生，而在没有无人车辆的情况下，当交通流量达到每小时200辆车时就开始出现拥堵。当无人车辆占比超过60%时，该方法的表现可与传统红绿灯系统相媲美甚至更优。此外，该方法还显示出了对突发状况和无人车辆比例变化的鲁棒性和良好的泛化能力，并成功应用于两个未见过的交叉口场景。 <div>
arXiv:2301.05294v3 Announce Type: replace 
Abstract: Intersections are essential road infrastructures for traffic in modern metropolises. However, they can also be the bottleneck of traffic flows as a result of traffic incidents or the absence of traffic coordination mechanisms such as traffic lights. Recently, various control and coordination mechanisms that are beyond traditional control methods have been proposed to improve the efficiency of intersection traffic. Amongst these methods, the control of foreseeable mixed traffic that consists of human-driven vehicles (HVs) and robot vehicles (RVs) has emerged. In this project, we propose a decentralized multi-agent reinforcement learning approach for the control and coordination of mixed traffic at real-world, complex intersections--a topic that has not been previously explored. Comprehensive experiments are conducted to show the effectiveness of our approach. In particular, we show that using 5% RVs, we can prevent congestion formation inside a complex intersection under the actual traffic demand of 700 vehicles per hour. In contrast, without RVs, congestion starts to develop when the traffic demand reaches as low as 200 vehicles per hour. When there exist more than 60% RVs in traffic, our method starts to achieve comparable or even better performance to traffic signals on the average waiting time of all vehicles at the intersection. Our method is also robust against both blackout events and sudden RV percentage drops, and enjoys excellent generalizablility, which is illustrated by its successful deployment in two unseen intersections.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Robust Blockchain Price Oracle: A Study on Human-Centric Node Selection Strategy and Incentive Mechanism</title>
<link>https://arxiv.org/abs/2309.04689</link>
<guid>https://arxiv.org/abs/2309.04689</guid>
<content:encoded><![CDATA[
<div> 匿名节点选择 安全性 服务质量 激励机制 Stackelberg博弈<br /><br />总结:<br />本文针对区块链预言机在节点选择过程中面临的安全和服务质量困境，提出了一种匿名节点选择方案。该方案通过匿名方式选择高声誉节点参与任务，确保系统安全和服务质量。同时，文章分析了支付结算和资产估值场景中各利益相关方的需求和行为动机，并基于理性人假设提出了一个Stackelberg博弈激励机制，以平衡任务发布者和执行者的收益。实验结果表明，所提方案能够将获取价格数据的方差减少约55%，同时保证系统安全和各方收益。 <div>
arXiv:2309.04689v2 Announce Type: replace 
Abstract: As a trusted middleware connecting the blockchain and the real world, the blockchain oracle can obtain trusted real-time price information for financial applications such as payment and settlement, and asset valuation on the blockchain. However, the current oracle schemes face the dilemma of security and service quality in the process of node selection, and the implicit interest relationship in financial applications leads to a significant conflict of interest between the task publisher and the executor, which reduces the participation enthusiasm of both parties and system security. Therefore, this paper proposes an anonymous node selection scheme that anonymously selects nodes with high reputations to participate in tasks to ensure the security and service quality of nodes. Then, this paper also details the interest requirements and behavioral motives of all parties in the payment settlement and asset valuation scenarios. Under the hypothesis of rational man, an incentive mechanism based on the Stackelberg game is proposed. It can achieve equilibrium under the pursuit of the revenue of task publishers and executors, thereby ensuring the revenue of all types of users and improving the enthusiasm for participation. Finally, we verify the security of the proposed scheme through security analysis. The experimental results show that the proposed scheme can reduce the variance of obtaining price data by about 55\% while ensuring security, and meeting the revenue of all parties.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoViS-Net: A Cooperative Visual Spatial Foundation Model for Multi-Robot Applications</title>
<link>https://arxiv.org/abs/2405.01107</link>
<guid>https://arxiv.org/abs/2405.01107</guid>
<content:encoded><![CDATA[
<div> 关键词：自主机器人, 视觉空间理解, 去中心化, 相对姿态估计, 局部鸟瞰图<br /><br />总结:<br />本文介绍了一种名为CoViS-Net的去中心化视觉空间基础模型，该模型能够从数据中学习空间先验知识，实现姿态估计和空间理解。CoViS-Net适用于多个自主机器人在非结构化环境中的协同操作，能够在没有现有网络基础设施的情况下实现实时计算。该模型提供相对姿态估计和局部鸟瞰图表示，即使机器人之间没有相机重叠也能工作。研究展示了CoViS-Net在多机器人编队控制任务中的应用，并提供了在线代码、模型和补充材料。 <div>
arXiv:2405.01107v3 Announce Type: replace 
Abstract: Autonomous robot operation in unstructured environments is often underpinned by spatial understanding through vision. Systems composed of multiple concurrently operating robots additionally require access to frequent, accurate and reliable pose estimates. In this work, we propose CoViS-Net, a decentralized visual spatial foundation model that learns spatial priors from data, enabling pose estimation as well as spatial comprehension. Our model is fully decentralized, platform-agnostic, executable in real-time using onboard compute, and does not require existing networking infrastructure. CoViS-Net provides relative pose estimates and a local bird's-eye-view (BEV) representation, even without camera overlap between robots (in contrast to classical methods). We demonstrate its use in a multi-robot formation control task across various real-world settings. We provide code, models and supplementary material online. https://proroklab.github.io/CoViS-Net/
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-critical Motion Planning for Collaborative Legged Loco-Manipulation over Discrete Terrain</title>
<link>https://arxiv.org/abs/2410.11023</link>
<guid>https://arxiv.org/abs/2410.11023</guid>
<content:encoded><![CDATA[
<div> 关键词：腿足机器人, 协同操作, 预测控制, 离散地形, 自适应控制<br /><br />总结:<br />本文介绍了一种针对腿足机器人在未知负载和复杂地形中进行安全运动规划的方法。该方法使用两组模型预测控制器（MPC），一组全局MPC生成团队的安全轨迹以避免障碍物，另一组去中心化MPC确保每个机器人在离散地形上的稳定步态。通过模型参考自适应全身控制器（MRA-WBC）来跟踪期望路径，并补偿未知负载带来的模型不确定性。实验结果表明，该方法能够在模拟和硬件测试中成功引导机器人团队穿越障碍物，包括平面定位和高度调整，且所有操作均在离散地形上完成。 <div>
arXiv:2410.11023v1 Announce Type: new 
Abstract: As legged robots are deployed in industrial and autonomous construction tasks requiring collaborative manipulation, they must handle object manipulation while maintaining stable locomotion. The challenge intensifies in real-world environments, where they should traverse discrete terrain, avoid obstacles, and coordinate with other robots for safe loco-manipulation. This work addresses safe motion planning for collaborative manipulation of an unknown payload on discrete terrain while avoiding obstacles. Our approach uses two sets of model predictive controllers (MPCs) as motion planners: a global MPC generates a safe trajectory for the team with obstacle avoidance, while decentralized MPCs for each robot ensure safe footholds on discrete terrain as they follow the global trajectory. A model reference adaptive whole-body controller (MRA-WBC) then tracks the desired path, compensating for model uncertainties from the unknown payload. We validated our method in simulation and hardware on a team of Unitree robots. The results demonstrate that our approach successfully guides the team through obstacle courses, requiring planar positioning and height adjustments, and all happening on discrete terrain such as stepping stones.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments</title>
<link>https://arxiv.org/abs/2410.11134</link>
<guid>https://arxiv.org/abs/2410.11134</guid>
<content:encoded><![CDATA[
<div> 功能性适应签名 隐私保护 区块链 智能合约 线性函数<br /><br />总结:<br />本文介绍了一种新型的加密原语——功能性适应签名（FAS），旨在解决卖家持有敏感数据如病历，而买家需要评估特定函数$f(x)$的问题。FAS结合了智能合约和基于适配器签名方案的优点，同时提供隐私保护。作者定义了FAS的安全属性，包括见证隐私的概念，确保买家只能获取$f(x)$而无法获取额外信息。文章提出了两种基于素数阶群和格的高效构造方法来支持线性函数，并展示了其在普通硬件上的高效执行能力。通过揭示功能加密与适配器签名之间的联系，本文为实现公平的功能销售提供了新的解决方案。 <div>
arXiv:2410.11134v1 Announce Type: new 
Abstract: In scenarios where a seller holds sensitive data $x$, like patient records, and a buyer seeks to obtain an evaluation of a function $f$ on $x$, solutions in trustless environments like blockchain fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions using tools such as adaptor signatures. The former offers atomic transactions where the buyer learns $f(x)$ upon payment. However, this approach is inefficient, costly, lacks privacy for the seller's data, and is incompatible with blockchains such as bitcoin. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an "all-or-nothing" guarantee, where the buyer fully extracts $x$ and does not support extracting $f(x)$. In this work, we bridge the gap between these approaches, developing a solution that enables fair functional sales while offering all the above properties like adaptor signatures.
  Towards this, we propose functional adaptor signatures (FAS), a novel cryptographic primitive and show how it can be used to enable functional sales. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond $f(x)$. We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge.
  We introduce two efficient constructions of FAS supporting linear functions based on groups of prime-order and lattices, that satisfy the strongest notion of witness privacy. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption and adaptor signatures. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, all operations are quite efficient even for commodity hardware.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Objective-Optimization Multi-AUV Assisted Data Collection Framework for IoUT Based on Offline Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.11282</link>
<guid>https://arxiv.org/abs/2410.11282</guid>
<content:encoded><![CDATA[
<div> 关键词：水下物联网, 多智能体, 离线强化学习, 数据收集, 能量消耗

<br /><br />总结:<br />
本文提出了一种基于多智能体离线强化学习的水下物联网（IoUT）数据收集框架，旨在解决现有方法中计算成本高和数据利用率低的问题。该框架通过最大化数据速率和信息价值（VoI），同时最小化能耗并确保碰撞避免，有效应对了动态海洋环境带来的挑战。文中引入了半通信去中心化训练与执行（SC-DTDE）范式和多智能体独立保守Q学习算法（MAICQL）。模拟实验表明，所提出的框架具有高适用性、鲁棒性和数据收集效率。 <div>
arXiv:2410.11282v1 Announce Type: new 
Abstract: The Internet of Underwater Things (IoUT) offers significant potential for ocean exploration but encounters challenges due to dynamic underwater environments and severe signal attenuation. Current methods relying on Autonomous Underwater Vehicles (AUVs) based on online reinforcement learning (RL) lead to high computational costs and low data utilization. To address these issues and the constraints of turbulent ocean environments, we propose a multi-AUV assisted data collection framework for IoUT based on multi-agent offline RL. This framework maximizes data rate and the value of information (VoI), minimizes energy consumption, and ensures collision avoidance by utilizing environmental and equipment status data. We introduce a semi-communication decentralized training with decentralized execution (SC-DTDE) paradigm and a multi-agent independent conservative Q-learning algorithm (MAICQL) to effectively tackle the problem. Extensive simulations demonstrate the high applicability, robustness, and data collection efficiency of the proposed framework.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>WPFed: Web-based Personalized Federation for Decentralized Systems</title>
<link>https://arxiv.org/abs/2410.11378</link>
<guid>https://arxiv.org/abs/2410.11378</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化学习, 邻居选择, 数据隐私, 区块链, 性能提升<br /><br />总结:<br />本文介绍了一种名为WPFed的全新去中心化、基于网络的学习框架，旨在优化客户端之间的协作。该框架采用动态通信图和加权邻居选择机制，通过局部敏感哈希（LSH）评估客户端间相似性，并根据同行排名评价模型质量，从而实现个性化最优邻居的选择。WPFed还集成了验证机制，以确保数据隐私和系统安全，同时利用区块链技术增强透明度和可验证性。实验表明，与传统联邦学习方法相比，WPFed显著提升了学习效果和系统的鲁棒性，适用于多种现实世界的数据集。 <div>
arXiv:2410.11378v1 Announce Type: new 
Abstract: Decentralized learning has become crucial for collaborative model training in environments where data privacy and trust are paramount. In web-based applications, clients are liberated from traditional fixed network topologies, enabling the establishment of arbitrary peer-to-peer (P2P) connections. While this flexibility is highly promising, it introduces a fundamental challenge: the optimal selection of neighbors to ensure effective collaboration. To address this, we introduce WPFed, a fully decentralized, web-based learning framework designed to enable globally optimal neighbor selection. WPFed employs a dynamic communication graph and a weighted neighbor selection mechanism. By assessing inter-client similarity through Locality-Sensitive Hashing (LSH) and evaluating model quality based on peer rankings, WPFed enables clients to identify personalized optimal neighbors on a global scale while preserving data privacy. To enhance security and deter malicious behavior, WPFed integrates verification mechanisms for both LSH codes and performance rankings, leveraging blockchain-driven announcements to ensure transparency and verifiability. Through extensive experiments on multiple real-world datasets, we demonstrate that WPFed significantly improves learning outcomes and system robustness compared to traditional federated learning methods. Our findings highlight WPFed's potential to facilitate effective and secure decentralized collaborative learning across diverse and interconnected web environments.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOOGD: Federated Collaboration for Both Out-of-distribution Generalization and Detection</title>
<link>https://arxiv.org/abs/2410.11397</link>
<guid>https://arxiv.org/abs/2410.11397</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习, 分布外数据, 语义偏移, 变异系数偏移, 概率密度估计<br /><br />总结:<br />本文提出了一种名为FOOGD的方法，用于处理联邦学习（FL）中分布外（OOD）数据的问题。FOOGD通过估计每个客户端的概率密度，从而获得可靠的全局分布，作为后续FL过程的指导。具体而言，FOOGD中的SM3D模块能够无约束地估计任意分布的得分模型，有效地检测语义偏移数据；而SAG模块则为局部变异系数偏移泛化和客户端性能泛化提供了不变且多样化的知识。实验验证表明，FOOGD具有三个主要优势：可靠地估计非标准化的去中心化分布、通过得分值检测语义偏移数据以及通过正则化特征提取器泛化到变异系数偏移数据。该研究项目的代码已开源。 <div>
arXiv:2410.11397v1 Announce Type: new 
Abstract: Federated learning (FL) is a promising machine learning paradigm that collaborates with client models to capture global knowledge. However, deploying FL models in real-world scenarios remains unreliable due to the coexistence of in-distribution data and unexpected out-of-distribution (OOD) data, such as covariate-shift and semantic-shift data. Current FL researches typically address either covariate-shift data through OOD generalization or semantic-shift data via OOD detection, overlooking the simultaneous occurrence of various OOD shifts. In this work, we propose FOOGD, a method that estimates the probability density of each client and obtains reliable global distribution as guidance for the subsequent FL process. Firstly, SM3D in FOOGD estimates score model for arbitrary distributions without prior constraints, and detects semantic-shift data powerfully. Then SAG in FOOGD provides invariant yet diverse knowledge for both local covariate-shift generalization and client performance generalization. In empirical validations, FOOGD significantly enjoys three main advantages: (1) reliably estimating non-normalized decentralized distributions, (2) detecting semantic shift data via score values, and (3) generalizing to covariate-shift data by regularizing feature extractor. The prejoct is open in https://github.com/XeniaLLL/FOOGD-main.git.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CroCoDai: A Stablecoin for Cross-Chain Commerce</title>
<link>https://arxiv.org/abs/2306.09754</link>
<guid>https://arxiv.org/abs/2306.09754</guid>
<content:encoded><![CDATA[
<div> 跨链交易 稳定币 去中心化金融 执行开销 链平台<br /><br />总结:<br />本文介绍了一种用于跨链商业活动的实用稳定币设计，称为CroCoDai。该设计旨在解决支持大量区块链和抵御价格波动及区块链平台故障的问题。现有跨链交易方法通过锁定资产增加财务风险，而稳定币虽能缓解价格波动风险，但受限于单一区块链平台。CroCoDai通过原型实现展示了其小额执行开销，从而提供了一个高效且稳定的跨链解决方案。 <div>
arXiv:2306.09754v4 Announce Type: replace 
Abstract: Decentralized Finance (DeFi), in which digital assets are exchanged without trusted intermediaries, has grown rapidly in value in recent years. The global DeFi ecosystem is fragmented into multiple blockchains, fueling the demand for cross-chain commerce. Existing approaches for cross-chain transactions, e.g., bridges and cross-chain deals, achieve atomicity by locking assets in escrow. However, locking up assets increases the financial risks for the participants, especially due to price fluctuations and the long latency of cross-chain transactions. Stablecoins, which are pegged to a non-volatile asset such as the US dollar, help mitigate the risk associated with price fluctuations. However, existing stablecoin designs are tied to individual blockchain platforms, and trusted parties or complex protocols are needed to exchange stablecoin tokens between blockchains.
  Our goal is to design a practical stablecoin for cross-chain commerce. Realizing this goal requires addressing two challenges. The first challenge is to support a large and growing number of blockchains efficiently. The second challenge is to be resilient to price fluctuations and blockchain platform failures. We present CroCoDai to address these challenges. We also present three prototype implementations of our stablecoin system, and show that it incurs small execution overhead.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Hybrid Model Pruning in Federated Learning through Loss Exploration</title>
<link>https://arxiv.org/abs/2405.10271</link>
<guid>https://arxiv.org/abs/2405.10271</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习, 自动化, 模型剪枝, 非IID数据, 计算效率<br /><br />总结:<br />文章介绍了AutoFLIP，一种针对联邦学习（FL）的创新方法，旨在通过自适应混合剪枝来优化计算和通信效率。面对6G网络和智能设备普及带来的挑战，如高通信成本、计算限制以及非独立同分布（non-IID）数据的复杂性，AutoFLIP通过探索联邦损失来识别并剪枝模型子结构，从而提高模型性能和加速全局收敛。实验表明，AutoFLIP在多种数据集和FL任务上不仅提高了准确性与鲁棒性，还平均减少了48.8%的计算开销和35.5%的通信成本，为FL在实际应用中的高效部署提供了可能。 <div>
arXiv:2405.10271v2 Announce Type: replace 
Abstract: The rapid proliferation of smart devices coupled with the advent of 6G networks has profoundly reshaped the domain of collaborative machine learning. Alongside growing privacy-security concerns in sensitive fields, these developments have positioned federated learning (FL) as a pivotal technology for decentralized model training. Despite its vast potential, specially in the age of complex foundation models, FL encounters challenges such as elevated communication costs, computational constraints, and the complexities of non-IID data distributions. We introduce AutoFLIP, an innovative approach that utilizes a federated loss exploration phase to drive adaptive hybrid pruning, operating in a structured and unstructured way. This innovative mechanism automatically identifies and prunes model substructure by distilling knowledge on model gradients behavior across different non-IID client losses topology, thereby optimizing computational efficiency and enhancing model performance on resource constrained scenarios. Extensive experiments on various datasets and FL tasks reveal that AutoFLIP not only efficiently accelerates global convergence, but also achieves superior accuracy and robustness compared to traditional methods. On average, AutoFLIP reduces computational overhead by 48.8% and communication costs by 35.5%, while improving global accuracy. By significantly reducing these overheads, AutoFLIP offer the way for efficient FL deployment in real-world applications for a scalable and broad applicability.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intellectual Property Blockchain Odyssey: Navigating Challenges and Seizing Opportunities</title>
<link>https://arxiv.org/abs/2410.08359</link>
<guid>https://arxiv.org/abs/2410.08359</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、知识产权、透明度、安全性、操作效率

总结:

本文深入探讨了区块链技术与保护知识产权之间的动态关系。研究通过全面的文献回顾、案例分析和论文综述，揭示了区块链对知识产权领域的深远影响。研究结果表明，将区块链应用于知识产权管理，可以显著提升透明度、安全性和运营效率。同时，文章也指出了这一领域面临的主要挑战与机遇。

研究提出了一套综合框架，旨在指导区块链技术与知识产权的有效整合，涵盖已存在或由区块链解决的技术组件，以及需要特别关注的方面。这套框架为知识产权领域的多层面操作提供了全面视角，有望重塑知识产权景观。

通过构建这个框架，文章为知识产权领域引入了系统化的新视角，确保了从不同层面的覆盖，包括但不限于运营流程、数据管理、法律合规等关键领域。这不仅有助于提升知识产权管理的现代化水平，也为相关实践者提供了宝贵的参考依据。 <div>
arXiv:2410.08359v1 Announce Type: new 
Abstract: This paper investigates the evolving relationship between protecting Intellectual Property Rights (IPRs) and blockchain technology. We conducted a comprehensive literature review, supplemented by case study analyses and research paper reviews, to understand the scope and implications of blockchain about intellectual property rights. Our study demonstrates how applying blockchain technology for IPR could revolutionize transparency, security, and operational efficiency. It also identifies the primary challenges and openings in this area. We provide an extensive framework for integrating blockchain technology with intellectual property rights and other technical components (some of which already exist or are resolved by blockchain; some might need attention), drawing on current research and best practices. This framework has the potential to give a new perspective in a structured manner for the intellectual property landscape by providing 360-degree coverage across different layers of operation.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Identifying Money Laundering Subgraphs on the Blockchain</title>
<link>https://arxiv.org/abs/2410.08394</link>
<guid>https://arxiv.org/abs/2410.08394</guid>
<content:encoded><![CDATA[
<div> 关键词：RevTrack、RevClassify、RevFilter、AML、Elliptic2

<br />
<br />总结:

本文提出了一种名为RevTrack的框架，旨在通过跟踪资金的初始发送者和最终接收者来实现大规模的反洗钱（AML）分析，从而降低成本并提高准确性。RevTrack的核心理念在于识别资金流动的起点和终点，以此作为判断其所属子图性质的关键指标。

在此基础上，作者进一步开发了RevClassify，这是一种用于子图分类的神经网络模型，能够更准确地识别可疑活动。同时，为了解决实际操作中可能缺乏可疑子图候选的问题，文章还引入了RevFilter方法。该方法通过迭代筛选合法交易来发现新的可疑子图，有效提高了在真实世界场景中的应用价值。

在Elliptic2这一新的AML标准基准上，与现有最先进的子图分类技术相比，RevClassify在成本和准确度方面均表现出显著优势。此外，RevFilter在发现新可疑子图方面的实用性得到了验证，证明了其对于实际反洗钱工作的有效性。 <div>
arXiv:2410.08394v1 Announce Type: new 
Abstract: Anti-Money Laundering (AML) involves the identification of money laundering crimes in financial activities, such as cryptocurrency transactions. Recent studies advanced AML through the lens of graph-based machine learning, modeling the web of financial transactions as a graph and developing graph methods to identify suspicious activities. For instance, a recent effort on opensourcing datasets and benchmarks, Elliptic2, treats a set of Bitcoin addresses, considered to be controlled by the same entity, as a graph node and transactions among entities as graph edges. This modeling reveals the "shape" of a money laundering scheme - a subgraph on the blockchain. Despite the attractive subgraph classification results benchmarked by the paper, competitive methods remain expensive to apply due to the massive size of the graph; moreover, existing methods require candidate subgraphs as inputs which may not be available in practice. In this work, we introduce RevTrack, a graph-based framework that enables large-scale AML analysis with a lower cost and a higher accuracy. The key idea is to track the initial senders and the final receivers of funds; these entities offer a strong indication of the nature (licit vs. suspicious) of their respective subgraph. Based on this framework, we propose RevClassify, which is a neural network model for subgraph classification. Additionally, we address the practical problem where subgraph candidates are not given, by proposing RevFilter. This method identifies new suspicious subgraphs by iteratively filtering licit transactions, using RevClassify. Benchmarking these methods on Elliptic2, a new standard for AML, we show that RevClassify outperforms state-of-the-art subgraph classification techniques in both cost and accuracy. Furthermore, we demonstrate the effectiveness of RevFilter in discovering new suspicious subgraphs, confirming its utility for practical AML.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uncertainty-Aware Active Search with a Team of Aerial Robots</title>
<link>https://arxiv.org/abs/2410.08507</link>
<guid>https://arxiv.org/abs/2410.08507</guid>
<content:encoded><![CDATA[
<div> 关键词：快速救援、大型灾害区域、无人机系统、自主搜索、不确定目标

总结:

文章主要讨论了在自然灾害后的快速救援行动中，如何有效地使用无人机系统进行搜索和救援。文章指出，现有的方法存在需要预先规划路径、依赖人工操作或仅在模拟环境中评估的问题。为解决这些问题，研究团队开发了一种分散式的主动搜索系统，该系统能够根据不确定的目标位置调整飞行轨迹，以实现快速覆盖通信受限场景。在通信可用的情况下，无人机之间共享位置信息、目标信息和目标数据，从而加速搜索过程。

实验结果显示，与基于贪婪覆盖的计划相比，在通信受限的场景下，主动搜索方法表现更优，同时在有通信支持的场景中也能保持相近的性能。这表明，该系统在提高搜索效率和生存率方面具有显著优势，特别是在通信基础设施受损的紧急情况下。研究为多无人机自主搜索系统在实际应用中的部署提供了理论基础和技术支持。 <div>
arXiv:2410.08507v1 Announce Type: new 
Abstract: Rapid search and rescue is critical to maximizing survival rates following natural disasters. However, these efforts are challenged by the need to search large disaster zones, lack of reliability in the communications infrastructure, and a priori unknown numbers of objects of interest (OOIs), such as injured survivors. Aerial robots are increasingly being deployed for search and rescue due to their high mobility, but there remains a gap in deploying multi-robot autonomous aerial systems for methodical search of large environments. Prior works have relied on preprogrammed paths from human operators or are evaluated only in simulation. We bridge these gaps in the state of the art by developing and demonstrating a decentralized active search system, which biases its trajectories to take additional views of uncertain OOIs. The methodology leverages stochasticity for rapid coverage in communication denied scenarios. When communications are available, robots share poses, goals, and OOI information to accelerate the rate of search. Extensive simulations and hardware experiments in Bloomingdale, OH, are conducted to validate the approach. The results demonstrate the active search approach outperforms greedy coverage-based planning in communication-denied scenarios while maintaining comparable performance in communication-enabled scenarios.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhanced Robot Planning and Perception through Environment Prediction</title>
<link>https://arxiv.org/abs/2410.08560</link>
<guid>https://arxiv.org/abs/2410.08560</guid>
<content:encoded><![CDATA[
<div> 关键词：移动机器人、地图构建、预测能力、学习方法、环境导航

总结:
本文主要探讨了移动机器人如何通过学习方法提高其在未知环境中的导航能力。文章首先强调了地图在机器人导航中的重要性，接着指出在没有预设地图的情况下，机器人需要通过在线构建地图来适应环境。传统方法仅依赖直接观察，而人类则能够通过识别环境模式并做出预测。文章提出，通过结合学习方法和大量训练数据，机器人可以有效地模仿人类的模式识别能力。

在第一部分中，作者介绍了如何使用几何和结构模式进行预测。利用部分观测的地图作为线索，文章展示了如何通过通用的学习方法来建模这些模式，适用于不同类型的顶部视图地图。为了提高室内导航效率，文章进一步应用了任务特定的学习方法，预测附近区域的二维占用情况，并扩展到三维点云表示进行物体重建，从仅有的部分视角预测完整物体的形状。

第二部分关注于利用空间时间模式进行预测，特别是在动态任务如目标跟踪和覆盖中实现更高效的分散式协调。文章展示了如何使用图神经网络进行更具扩展性和速度的推理。

综上所述，本文旨在通过学习方法增强移动机器人的预测能力，使其在未知环境中更加高效和安全地导航，同时实现动态任务的分散式执行。 <div>
arXiv:2410.08560v1 Announce Type: new 
Abstract: Mobile robots rely on maps to navigate through an environment. In the absence of any map, the robots must build the map online from partial observations as they move in the environment. Traditional methods build a map using only direct observations. In contrast, humans identify patterns in the observed environment and make informed guesses about what to expect ahead. Modeling these patterns explicitly is difficult due to the complexity of the environments. However, these complex models can be approximated well using learning-based methods in conjunction with large training data. By extracting patterns, robots can use direct observations and predictions of what lies ahead to better navigate an unknown environment. In this dissertation, we present several learning-based methods to equip mobile robots with prediction capabilities for efficient and safer operation. In the first part of the dissertation, we learn to predict using geometrical and structural patterns in the environment. Partially observed maps provide invaluable cues for accurately predicting the unobserved areas. We first demonstrate the capability of general learning-based approaches to model these patterns for a variety of overhead map modalities. Then we employ task-specific learning for faster navigation in indoor environments by predicting 2D occupancy in the nearby regions. This idea is further extended to 3D point cloud representation for object reconstruction. Predicting the shape of the full object from only partial views, our approach paves the way for efficient next-best-view planning.
  In the second part of the dissertation, we learn to predict using spatiotemporal patterns in the environment. We focus on dynamic tasks such as target tracking and coverage where we seek decentralized coordination between robots. We first show how graph neural networks can be used for more scalable and faster inference.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cross-chain Sharing of Personal Health Records: Heterogeneous and Interoperable Blockchains</title>
<link>https://arxiv.org/abs/2410.08762</link>
<guid>https://arxiv.org/abs/2410.08762</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗信息化、区块链技术、数据共享、跨链技术、物联网设备

<br /><br />
总结:本文探讨了医疗信息化时代背景下，个人健康记录（PHR）的广泛生成与区块链技术对医疗机构安全性的提升。然而，医疗机构作为独立的数据孤岛限制了PHR价值的最大化利用。随着不同医院间区块链上的数据共享需求增长，跨链数据共享成为关键挑战。文章提出了一种在异构可互操作区块链间共享PHR的方案，通过将实时PHR加密存储于星际文件系统中，简化数据共享流程，仅需执行基本操作。为解决不同区块链加密系统的差异，文章引入改进的代理重加密（PRE）算法。多维分析表明，该方案提供了强大的安全性与出色的性能。 <div>
arXiv:2410.08762v1 Announce Type: new 
Abstract: With the widespread adoption of medical informatics, a wealth of valuable personal health records (PHR) has been generated. Concurrently, blockchain technology has enhanced the security of medical institutions. However, these institutions often function as isolated data silos, limiting the potential value of PHRs. As the demand for data sharing between hospitals on different blockchains grows, addressing the challenge of cross-chain data sharing becomes crucial. When sharing PHRs across blockchains, the limited storage and computational capabilities of medical Internet of Things (IoT) devices complicate the storage of large volumes of PHRs and the handling of complex calculations. Additionally, varying blockchain cryptosystems and the risk of internal attacks further complicate the cross-chain sharing of PHRs. This paper proposes a scheme for sharing PHRs across heterogeneous and interoperable blockchains. Medical IoT devices can encrypt and store real-time PHRs in an InterPlanetary File System, requiring only simple operations for data sharing. An enhanced proxy re-encryption(PRE) algorithm addresses the differences in blockchain cryptosystems. Multi-dimensional analysis demonstrates that this scheme offers robust security and excellent performance.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rapid Grassmannian Averaging with Chebyshev Polynomials</title>
<link>https://arxiv.org/abs/2410.08956</link>
<guid>https://arxiv.org/abs/2410.08956</guid>
<content:encoded><![CDATA[
<div> 关键词：新算法、Grassmannian平均、集中式、分布式、优化

总结:
本文提出了一种新的Grassmannian平均算法——Rapid Grassmannian Averaging (RGrAv)，以及其分布式版本Decentralized Rapid Grassmannian Averaging (DRGrAv)。Grassmannian点在机器学习、计算机视觉和信号处理领域广泛用于表示通过（通常是低维）子空间的数据。现有的方法由于需要考虑非欧几何的特性，计算成本较高。RGrAv和DRGrAv通过利用问题的谱结构，仅使用小矩阵乘法和QR分解快速计算平均值，从而解决了这一挑战。文中提供了算法最优性的理论保证，并通过数值实验展示了与现有最佳方法相比，我们的算法在提供高精度解决方案的同时节省了时间。此外，实验还展示了算法在视频运动数据K-means聚类任务中的应用，证明了RGrAv和DRGrAv是处理一般Grassmannian平均任务的强大工具。 <div>
arXiv:2410.08956v1 Announce Type: new 
Abstract: We propose new algorithms to efficiently average a collection of points on a Grassmannian manifold in both the centralized and decentralized settings. Grassmannian points are used ubiquitously in machine learning, computer vision, and signal processing to represent data through (often low-dimensional) subspaces. While averaging these points is crucial to many tasks (especially in the decentralized setting), existing methods unfortunately remain computationally expensive due to the non-Euclidean geometry of the manifold. Our proposed algorithms, Rapid Grassmannian Averaging (RGrAv) and Decentralized Rapid Grassmannian Averaging (DRGrAv), overcome this challenge by leveraging the spectral structure of the problem to rapidly compute an average using only small matrix multiplications and QR factorizations. We provide a theoretical guarantee of optimality and present numerical experiments which demonstrate that our algorithms outperform state-of-the-art methods in providing high accuracy solutions in minimal time. Additional experiments showcase the versatility of our algorithms to tasks such as K-means clustering on video motion data, establishing RGrAv and DRGrAv as powerful tools for generic Grassmannian averaging.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockMEDC: Blockchain Smart Contracts for Securing Moroccan Higher Education Digital Certificates</title>
<link>https://arxiv.org/abs/2410.07258</link>
<guid>https://arxiv.org/abs/2410.07258</guid>
<content:encoded><![CDATA[
<div> 关键词：Morocco、Vision 2030、Pacte ESRI 2030、BlockMEDC、区块链

总结:

本文聚焦于摩洛哥为实现其2030年数字愿景所采取的战略举措。摩洛哥通过“Maroc Digital 2030”计划，旨在将国家定位为地区数字技术领导者，重点提升数字基础设施，促进创新并加强数字技能。同时，2023年推出的“Pacte ESRI 2030”战略，旨在通过整合最新数字技术来改造高等教育、研究和创新领域。

为了与这些国家级策略相协调，文章介绍了一项名为“BlockMEDC”的创新项目，这是一个基于区块链技术的系统，用于保护和管理摩洛哥教育领域的电子证书。该系统利用以太坊智能合约和星际文件系统（InterPlanetary File System）自动化了学术证书的发行、管理和验证流程，覆盖了摩洛哥的多所大学。

BlockMEDC解决了一系列关键问题，包括文档的真实性、手动验证的繁琐以及缺乏互操作性等，提供了一个安全、透明且成本效益高的解决方案，这与摩洛哥教育部门的数字化转型目标紧密相关。 <div>
arXiv:2410.07258v1 Announce Type: new 
Abstract: Morocco's Vision 2030, known as Maroc Digital 2030, aims to position the country as a regional leader in digital technology by boosting digital infrastructure, fostering innovation, and advancing digital skills. Complementing this initiative, the Pacte ESRI 2030 strategy, launched in 2023, seeks to transform the higher education, research, and innovation sectors by integrating state-of-the-art digital technologies. In alignment with these national strategies, this paper introduces BlockMEDC, a blockchain-based system for securing and managing Moroccan educational digital certificates. Leveraging Ethereum smart contracts and the InterPlanetary File System, BlockMEDC automates the issuance, management, and verification of academic credentials across Moroccan universities. The proposed system addresses key issues such as document authenticity, manual verification, and lack of interoperability, delivering a secure, transparent, and cost-effective solution that aligns with Morocco's digital transformation goals for the education sector.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Boosting the Performance of Decentralized Federated Learning via Catalyst Acceleration</title>
<link>https://arxiv.org/abs/2410.07272</link>
<guid>https://arxiv.org/abs/2410.07272</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning、DFedCata、Catalyst Acceleration、Moreau envelope function、Nesterov's extrapolation step

<br /><br />
总结:
本文提出了一种名为DFedCata的加速分布式联邦学习算法，以解决分布式联邦学习中数据异质性导致的模型聚合方差增大、训练收敛速度慢和测试泛化性能差的问题。DFedCata由两个主要组件组成：Moreau envelope函数，用于解决由数据异质性引起客户端参数不一致的问题；以及Nesterov的外推步骤，用于加速聚合阶段。理论分析证明了算法的优化误差界和泛化误差界，为算法的性质提供了更深入的理解，并从理论上探讨了超参数选择。实验结果显示，DFedCata在CIFAR10/100上不同非iid数据分布下，不仅在收敛速度上有优势，而且在泛化性能上也表现出色。此外，实验证实了DFedCata的理论特性。

通过引入Catalyst加速方法，DFedCata有效地处理了数据异质性带来的问题，通过Moreau envelope函数优化参数一致性，使用Nesterov外推加速聚合过程。理论与实验结果均表明，该算法在分布式联邦学习场景下具有显著的性能提升，特别是在处理非iid数据分布时，能有效提高训练效率和模型泛化能力。 <div>
arXiv:2410.07272v1 Announce Type: new 
Abstract: Decentralized Federated Learning has emerged as an alternative to centralized architectures due to its faster training, privacy preservation, and reduced communication overhead. In decentralized communication, the server aggregation phase in Centralized Federated Learning shifts to the client side, which means that clients connect with each other in a peer-to-peer manner. However, compared to the centralized mode, data heterogeneity in Decentralized Federated Learning will cause larger variances between aggregated models, which leads to slow convergence in training and poor generalization performance in tests. To address these issues, we introduce Catalyst Acceleration and propose an acceleration Decentralized Federated Learning algorithm called DFedCata. It consists of two main components: the Moreau envelope function, which primarily addresses parameter inconsistencies among clients caused by data heterogeneity, and Nesterov's extrapolation step, which accelerates the aggregation phase. Theoretically, we prove the optimization error bound and generalization error bound of the algorithm, providing a further understanding of the nature of the algorithm and the theoretical perspectives on the hyperparameter choice. Empirically, we demonstrate the advantages of the proposed algorithm in both convergence speed and generalization performance on CIFAR10/100 with various non-iid data distributions. Furthermore, we also experimentally verify the theoretical properties of DFedCata.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain and Artificial Intelligence based System for Halal Food Traceability</title>
<link>https://arxiv.org/abs/2410.07305</link>
<guid>https://arxiv.org/abs/2410.07305</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、人工智能、Halal食品、供应链追溯、原料溯源

<br />
<br />
总结:本文探讨了Halal食品市场的需求增长及其面临的挑战，尤其是消费者对产品真伪的疑虑。为解决这一问题，作者提出了一种结合区块链技术和人工智能的创新系统。该系统旨在通过提供供应链中所有操作和流程的可追溯性，以及对原料来源的追踪，确保Halal食品的正宗性。通过在本地超市进行的测试，结果显示该解决方案有效，并得到了测试者的积极反馈，表明其有潜力在实际环境中实施。此系统利用区块链的分布式账本特性，确保信息的不可篡改性，同时AI则用于模式识别，共同构建起信任桥梁，促进Halal食品市场的健康发展。 <div>
arXiv:2410.07305v1 Announce Type: new 
Abstract: The demand of the halal food products is increasing rapidly around the world. The consumption of halal food product is just not among the Muslims but also among non-Muslims, due to the purity of the halal food products. However, there are several challenges that are faced by the halal food consumers. The challenges raise a doubt among the halal food consumers about the authenticity of the product being halal. Therefore, a solution that can address these issues and can establish trust between consumers and producers. Blockchain technology can provide a distributed ledger of an immutable record of the information. Artificial intelligence supports developing a solution for pattern identification. The proposed research utilizes blockchain an artificial intelligence-based system for developing a system that ensure the authenticity of the halal food products by providing the traceability related to all the operations and processes of the supply chain and sourcing the raw material. The proposed system has been tested with a local supermarket. The results and tests of the developed solution seemed effective and the testers expressed interest in real-world implementation of the proposed system.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revisiting the Primitives of Transaction Fee Mechanism Design</title>
<link>https://arxiv.org/abs/2410.07566</link>
<guid>https://arxiv.org/abs/2410.07566</guid>
<content:encoded><![CDATA[
<div> 关键词：交易费机制设计、矿工、用户、协同策略、不可离链影响证明

总结:

本文探讨了区块链中由不信任的矿工运行的交易纳入拍卖机制的设计。首先，作者提出了一种新的评估标准——“不可离链影响证明”，指出了在当前的评估标准下，以太坊改进提案EIP-1559并不能满足这一要求。因为一个能够最大化预期收益的矿工可能会通过威胁离链转移资金给其增加额外收入来误导竞标者。

其次，文章重新审视了基于多方计算的第二价格拍卖机制，虽然该机制不符合前文提出的“简单对矿工”的标准，但作者发现，如果允许矿工直接设定保留价，该机制不仅能满足“简单对用户和矿工”的条件，还能满足“不可离链影响证明”的要求。

最后，文章指出，要同时满足所有已考虑的属性以及“不可离链影响证明”这一新标准，即使在供给无限的情况下，甚至在向矿工征询意见后，也没有任何机制能实现这一目标。这表明在设计交易费机制时需要权衡多种因素，包括安全性、公平性以及操作的复杂性。 <div>
arXiv:2410.07566v1 Announce Type: new 
Abstract: Transaction Fee Mechanism Design studies auctions run by untrusted miners for transaction inclusion in a blockchain. Under previously-considered desiderata, an auction is considered `good' if, informally-speaking, each party (i.e., the miner, the users, and coalitions of both miners and users) has no incentive to deviate from the fixed and pre-determined protocol.
  In this paper, we propose a novel desideratum for transaction fee mechanisms. We say that a TFM is off-chain influence proof when the miner cannot achieve additional revenue by running a separate auction off-chain. While the previously-highlighted EIP-1559 is the gold-standard according to prior desiderata, we show that it does not satisfy off-chain influence proofness. Intuitively, this holds because a Bayesian revenue-maximizing miner can strictly increase profits by persuasively threatening to censor any bids that do not transfer a tip directly to the miner off-chain.
  On the other hand, we reconsider the Cryptographic (multi-party computation assisted) Second Price Auction mechanism, which is technically not `simple for miners' according to previous desiderata (since miners may wish to set a reserve by fabricating bids). We show that, in a slightly different model where the miner is allowed to set the reserve directly, this auction satisfies simplicity for users and miners, and off-chain influence proofness.
  Finally, we prove a strong impossibility result: no mechanism satisfies all previously-considered properties along with off-chain influence proofness, even with unlimited supply, and even after soliciting input from the miner.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Cloud in the Sky: Geo-Aware On-board Data Services for LEO Satellites</title>
<link>https://arxiv.org/abs/2410.07586</link>
<guid>https://arxiv.org/abs/2410.07586</guid>
<content:encoded><![CDATA[
<div> 关键词：卫星数据基础设施、区块链、直接到细胞连接、低地球轨道、分布式交易

<br /><br />
总结:
本文提出了一种为提供通信服务（如直接到细胞连接）的低地球轨道（LEO）星座设计的卫星数据基础设施架构与协议。该设计充分利用了LEO卫星在地球上未被居住地区（如海洋）上空运行时的未使用或利用率低的计算和通信资源。通过利用区块链技术支持的分布式交易，文章展示了如何在该架构上高效运行智能合约服务。不同于其他区块链系统，迁移账本不仅是为了应对故障，还定期且连续地进行，以适应卫星在轨道上的移动和进入或离开区块链服务区域的情况。文章通过模拟展示了如何使用不同大小的动态地理感知服务区域来控制消息和区块链处理的开销。这一创新方法为卫星网络提供了更高效的资源管理和服务交付机制。 <div>
arXiv:2410.07586v1 Announce Type: new 
Abstract: We propose an architecture with accompanying protocol for on-board satellite data infrastructure designed for Low Earth Orbit (LEO) constellations offering communication services, such as direct-to-cell connectivity. Our design leverages the unused or under-used computing and communication resources of LEO satellites that are orbiting over uninhabited parts of the earth, like the oceans. We show how blockchain-backed distributed transactions can be run efficiently on this architecture to offer smart contract services. A key aspect of the proposed architecture that sets it apart from other blockchain systems is that migration of the ledger is not done solely to recover from failures. Rather, migration is also performed periodically and continuously as the satellites circle around in their orbits and enter and leave the blockchain service area. We show in simulations how message and blockchain processing overhead can be contained using different sizes of dynamic geo-aware service areas.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedEP: Tailoring Attention to Heterogeneous Data Distribution with Entropy Pooling for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2410.07678</link>
<guid>https://arxiv.org/abs/2410.07678</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、非独立同分布、Federated Entropy Pooling、Kullback-Leibler（KL）散度、全局数据分布

总结:
本文聚焦于解决联邦学习(Federated Learning, FL)中非独立同分布(non-IID)问题，特别是针对去中心化联邦学习(Decentralized FL, DFL)场景。研究发现，数据分布的不均匀性导致了模型收敛速度减慢和性能下降。为了应对这一挑战，文章提出了一种创新的去中心化联邦学习聚合算法——Federated Entropy Pooling (FedEP)。

FedEP通过引入局部数据分布的统计特性来缓解客户端漂移问题，而不是直接使用实际数据。每个客户端在训练前使用高斯混合模型(Gaussian Mixture Model, GMM)对本地分布进行拟合，并与邻居共享这些统计特性。之后，每个节点试图拟合全球数据分布。在聚合阶段，每个节点计算其本地数据分布与拟合后的全球数据分布之间的Kullback-Leibler（KL）散度，以此作为权重生成聚合模型。

实验结果表明，FedEP能够实现更快的收敛速度并展现出优于现有方法的测试性能。这一研究为解决非IID问题提供了新的思路，尤其是对于去中心化联邦学习环境而言，具有重要的实践价值和理论意义。 <div>
arXiv:2410.07678v1 Announce Type: new 
Abstract: Federated Learning (FL) performance is highly influenced by data distribution across clients, and non-Independent and Identically Distributed (non-IID) leads to a slower convergence of the global model and a decrease in model effectiveness. The existing algorithms for solving the non-IID problem are focused on the traditional centralized FL (CFL), where a central server is used for model aggregation. However, in decentralized FL (DFL), nodes lack the overall vision of the federation. To address the non-IID problem in DFL, this paper proposes a novel DFL aggregation algorithm, Federated Entropy Pooling (FedEP). FedEP mitigates the client drift problem by incorporating the statistical characteristics of local distributions instead of any actual data. Prior to training, each client conducts a local distribution fitting using a Gaussian Mixture Model (GMM) and shares the resulting statistical characteristics with its neighbors. After receiving the statistical characteristics shared by its neighbors, each node tries to fit the global data distribution. In the aggregation phase, each node calculates the Kullback-Leibler (KL) divergences of the local data distribution over the fitted global data distribution, giving the weights to generate the aggregated model. Extensive experiments have demonstrated that FedEP can achieve faster convergence and show higher test performance than state-of-the-art approaches.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ormer: A Manipulation-resistant and Gas-efficient Blockchain Pricing Oracle for DeFi</title>
<link>https://arxiv.org/abs/2410.07893</link>
<guid>https://arxiv.org/abs/2410.07893</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化金融（DeFi）、时间加权平均价格（TWAP）、价格操纵攻击、中值估计算法（Ormer）

<br /><br />
总结:

文章主要探讨了区块链Oracle在去中心化金融（DeFi）中的重要性以及当前广泛使用的基于时间加权平均价格（TWAP）的Oracle面临的价格操纵攻击风险。针对这一问题，作者提出了一种新型的链上高效定价算法（Ormer），旨在通过利用分段抛物线公式和融合不同观察窗口大小的估计来准确估算实时资产价格流的中值，从而减少价格误差和延迟。相较于TWAP，Ormer在实证分析中显著降低了平均绝对价格误差（减少了15.3%）和时间延迟（减少了49.3%）。此外，为了优化智能合约设计并确保存储需求的稳定性，不随价格观测数量变化，作者还提出了针对Ormer的优化策略。

<br /><br /> <div>
arXiv:2410.07893v1 Announce Type: new 
Abstract: Blockchain oracle is a critical third-party web service for Decentralized Finance (DeFi) protocols. Oracles retrieve external information such as token prices from exchanges and feed them as trusted data sources into smart contracts, enabling core DeFi applications such as loaning protocols. Currently, arithmetic mean based time-weighted average price (TWAP) oracles are widely used in DeFi by averaging external price data with fixed time frame, which is considered reliable and gas-efficient for protocol execution. However, recent research shows that TWAP price feeds are vulnerable to price manipulation attack even with long time frame setting, which would further introduce long time delays and price errors hindering the service quality of DeFi applications. To address this issue, we propose a novel on-chain gas-efficient pricing algorithm (Ormer) that heuristically estimates the median of the current streaming asset price feed based on a piecewise-parabolic formula, while the time delay is suppressed by fusing estimations with different observation window size. Our evaluation based on Ethereum WETH/USDT swapping pair price feed shows that Ormer reduces the mean absolute price error by 15.3% and the time delay by 49.3% compared to TWAP. For gas efficiency, an optimized smart contract design and constant storage requirement regardless of the number of price observations is developed for Ormer.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Penalty-Based Method for Communication-Efficient Decentralized Bilevel Programming</title>
<link>https://arxiv.org/abs/2211.04088</link>
<guid>https://arxiv.org/abs/2211.04088</guid>
<content:encoded><![CDATA[
<div> 关键词：Bilevel编程、共识、分布式、交替梯度算法、去中心化

总结:

本文提出了一个基于惩罚函数的去中心化算法，旨在解决具有理论保证的共识双层优化问题。该方法在去中心化的网络环境中发展了一种分布式交替梯度类型算法来解决共识双层编程问题。其核心特征是通过去中心化的矩阵向量乘法和少量向量通信估计惩罚函数的超梯度。这种方法将估计集成到求解原问题惩罚形式化后的交替算法中。在适当的步长和惩罚参数下，理论框架确保了在各种凸性条件下非渐近收敛至原始问题的最优解。该理论结果强调了去中心化双层优化迭代复杂性的改进，同时高效利用向量通信。

文章主要贡献包括：

1. **算法设计**：提出一种基于惩罚函数的去中心化算法，能够有效解决共识双层优化问题。
   
2. **理论分析**：证明了在特定条件下的非渐近收敛性，确保算法的有效性和可靠性。
   
3. **步骤优化**：强调了在保证算法性能的同时，对通信成本的优化，通过减少中心节点的通信负担。
   
4. **实践验证**：通过实际案例展示算法在真实世界场景中的良好表现，证实了其实际应用价值。

该研究不仅丰富了双层优化问题的理论基础，也为实际应用提供了新的策略和工具，特别是在需要低通信开销和高扩展性的场景下。 <div>
arXiv:2211.04088v4 Announce Type: replace 
Abstract: Bilevel programming has recently received attention in the literature due to its wide range of applications, including reinforcement learning and hyper-parameter optimization. However, it is widely assumed that the underlying bilevel optimization problem is solved either by a single machine or, in the case of multiple machines connected in a star-shaped network, i.e., in a federated learning setting. The latter approach suffers from a high communication cost on the central node (e.g., parameter server). Hence, there is an interest in developing methods that solve bilevel optimization problems in a communication-efficient, decentralized manner. To that end, this paper introduces a penalty function-based decentralized algorithm with theoretical guarantees for this class of optimization problems. Specifically, a distributed alternating gradient-type algorithm for solving consensus bilevel programming over a decentralized network is developed. A key feature of the proposed algorithm is the estimation of the hyper-gradient of the penalty function through decentralized computation of matrix-vector products and a few vector communications. The estimation is integrated into an alternating algorithm for solving the penalized reformulation of the bilevel optimization problem. Under appropriate step sizes and penalty parameters, our theoretical framework ensures non-asymptotic convergence to the optimal solution of the original problem under various convexity conditions. Our theoretical result highlights improvements in the iteration complexity of decentralized bilevel optimization, all while making efficient use of vector communication. Empirical results demonstrate that the proposed method performs well in real-world settings.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SelfFed: Self-supervised Federated Learning for Data Heterogeneity and Label Scarcity in IoMT</title>
<link>https://arxiv.org/abs/2307.01514</link>
<guid>https://arxiv.org/abs/2307.01514</guid>
<content:encoded><![CDATA[
<div> 关键词：自监督学习、联邦学习、数据异质性、标签稀缺、医疗物联网

<br /><br />
总结:
文章提出了一种名为SelfFed的框架，专为医疗物联网（IoMT）设计。该框架分为两个阶段：预训练和微调。预训练阶段采用分布式方式，利用基于Swin Transformer的编码器进行增强建模，旨在解决数据异质性问题。微调阶段引入对比网络和新颖聚合策略，用于在有限标注数据上进行目标任务训练，以克服标签稀缺问题。实验在公开的医疗影像数据集上进行，结果表明，与现有基线相比，SelfFed框架在非独立同分布（non-IID）数据和标签稀缺情况下表现更优。特别是在Retina和COVID-FL数据集上，该方法分别实现了最大8.8%和4.1%的性能提升。即使在少量（10%）标注实例上训练，SelfFed也超越了现有基线，证明了其在资源受限环境下的有效性和适应性。 <div>
arXiv:2307.01514v2 Announce Type: replace 
Abstract: Self-supervised learning in federated learning paradigm has been gaining a lot of interest both in industry and research due to the collaborative learning capability on unlabeled yet isolated data. However, self-supervised based federated learning strategies suffer from performance degradation due to label scarcity and diverse data distributions, i.e., data heterogeneity. In this paper, we propose the SelfFed framework for Internet of Medical Things (IoMT). Our proposed SelfFed framework works in two phases. The first phase is the pre-training paradigm that performs augmentive modeling using Swin Transformer based encoder in a decentralized manner. The first phase of SelfFed framework helps to overcome the data heterogeneity issue. The second phase is the fine-tuning paradigm that introduces contrastive network and a novel aggregation strategy that is trained on limited labeled data for a target task in a decentralized manner. This fine-tuning stage overcomes the label scarcity problem. We perform our experimental analysis on publicly available medical imaging datasets and show that our proposed SelfFed framework performs better when compared to existing baselines concerning non-independent and identically distributed (IID) data and label scarcity. Our method achieves a maximum improvement of 8.8% and 4.1% on Retina and COVID-FL datasets on non-IID dataset. Further, our proposed method outperforms existing baselines even when trained on a few (10%) labeled instances.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockEmulator: An Emulator Enabling to Test Blockchain Sharding Protocols</title>
<link>https://arxiv.org/abs/2311.03612</link>
<guid>https://arxiv.org/abs/2311.03612</guid>
<content:encoded><![CDATA[
<div> 关键词：BlockEmulator、区块链模拟器、共识算法、区块链分片、实验平台

<br />
<br />总结:

本文介绍了一款名为BlockEmulator的新型区块链模拟器，旨在为研究者提供一个开发和评估新共识算法以及区块链分片系统新协议的实验平台。其特点在于采用轻量级区块链架构，使开发者能够专注于实现新协议或机制，而无需过多关注底层技术细节。BlockEmulator通过层次化模块和提供的编程接口，大大降低了新协议实现的难度。

在验证BlockEmulator的正确性时，作者通过理论分析与实验结果的对比，证明了模拟结果的准确性。进一步的实验展示了该工具在衡量吞吐量、交易确认延迟、跨分片交易比例、交易池排队状态、区块链分片工作负载分布等关键指标方面的应用价值。

此外，BlockEmulator已被开源发布在GitHub上，鼓励社区参与，促进区块链技术的研究与发展。

总之，BlockEmulator为区块链领域的研究提供了有力工具，不仅简化了新协议的开发流程，还支持了对区块链系统性能和行为的深入研究，为推动区块链技术进步做出了贡献。 <div>
arXiv:2311.03612v3 Announce Type: replace 
Abstract: Numerous blockchain simulators have been proposed to allow researchers to simulate mainstream blockchains. However, we have not yet found a testbed that enables researchers to develop and evaluate their new consensus algorithms or new protocols for blockchain sharding systems. To fill this gap, we developed BlockEmulator, which is designed as an experimental platform, particularly for emulating blockchain sharding mechanisms. BlockEmulator adopts a lightweight blockchain architecture so developers can only focus on implementing their new protocols or mechanisms. Using layered modules and useful programming interfaces offered by BlockEmulator, researchers can implement a new protocol with minimum effort. Through experiments, we test various functionalities of BlockEmulator in two steps. Firstly, we prove the correctness of the emulation results yielded by BlockEmulator by comparing the theoretical analysis with the observed experiment results. Secondly, other experimental results demonstrate that BlockEmulator can facilitate measuring a series of metrics, including throughput, transaction confirmation latency, cross-shard transaction ratio, the queuing status of transaction pools, workload distribution across blockchain shards, etc. We have made BlockEmulator open-source in Github.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Remeasuring the Arbitrage and Sandwich Attacks of Maximal Extractable Value in Ethereum</title>
<link>https://arxiv.org/abs/2405.17944</link>
<guid>https://arxiv.org/abs/2405.17944</guid>
<content:encoded><![CDATA[
<div> 关键词：Maximal Extractable Value（MEV）、区块链生态系统、盈利能力识别算法、私有交易架构、回滚机制

总结:
本文聚焦于Maximal Extractable Value（MEV）在区块链生态系统的驱动作用，特别是以太坊中的MEV现象。文章首先指出当前识别MEV活动的方法存在依赖于笨拙的规则基模式的问题，导致误报和漏报；同时，早期研究基于的以太坊阶段在合并后已不再适用。为解决这些挑战，作者创新性地提出了一个盈利能力识别算法，并基于此设计了两个强大的算法来识别在最大数据集上的MEV活动。

通过分析识别结果，研究全面描绘了以太坊MEV生态系统的整体图景，探讨了私有交易架构的影响以及回滚机制的采用情况。研究结果为未来MEV相关工作提供了洞察，揭示了MEV活动对区块链生态系统的重要性及其潜在影响。

文章的主要贡献在于提供了一种更准确、有效的MEV活动识别方法，以及对MEV生态系统深入的分析，为后续研究者提供了宝贵的参考信息。通过改进MEV检测技术，有助于提升区块链系统的透明度和公平性，促进其长期健康发展。 <div>
arXiv:2405.17944v2 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) drives the prosperity of the blockchain ecosystem. By strategically including, excluding, or reordering transactions within blocks, block producers can extract additional value, which in turn incentivizes them to keep the decentralization of the whole blockchain platform. Before September 2022, around $675M was extracted in terms of MEV in Ethereum. Despite its importance, current work on identifying MEV activities suffers from two limitations. On the one hand, current methods heavily rely on clumsy heuristic rule-based patterns, leading to numerous false negatives or positives. On the other hand, the observations and conclusions are drawn from the early stage of Ethereum, which cannot be used as effective guiding principles after The Merge. To address these challenges, in this work, we innovatively proposed a profitability identification algorithm. Based on this, we designed two robust algorithms to identify MEV activities on our collected largest-ever dataset. Based on the identified results, we have characterized the overall landscape of the Ethereum MEV ecosystem, the impact the private transaction architectures bring in, and the adoption of back-running mechanisms. Our research sheds light on future MEV-related work.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SoK: Towards Security and Safety of Edge AI</title>
<link>https://arxiv.org/abs/2410.05349</link>
<guid>https://arxiv.org/abs/2410.05349</guid>
<content:encoded><![CDATA[
<div> 关键词：AI应用、边缘计算、安全、性能瓶颈、集成

总结:

本文探讨了高级人工智能(AI)应用的普及及其带来的风险与性能瓶颈。随着大型语言模型(Large Language Models, LLMs)等AI应用的集中化管理，AI系统的安全性和性能面临挑战。边缘人工智能(Edge AI)作为解决这些问题的一种潜在方案，通过分布式计算提高了响应速度和隐私保护能力，但同时也带来了新的安全和可靠性问题。

文章首先分析了边缘AI面临的两大主要挑战：一是安全威胁，包括数据泄露、恶意攻击和系统脆弱性等；二是确保系统的安全性和可靠性，尤其是在缺乏集中管理的情况下，如何保证算法的正确执行和结果的可信度成为关键问题。文章指出，安全性和可靠性是边缘AI发展的核心要素，两者需要协同优化以克服现有挑战。

为推动边缘AI领域的发展，文章提出了一系列开放性研究问题，旨在鼓励科研人员探索更有效的安全防护机制、可靠性验证方法以及边缘计算环境下的系统设计策略，以构建更加安全、高效和可靠的AI生态系统。 <div>
arXiv:2410.05349v1 Announce Type: new 
Abstract: Advanced AI applications have become increasingly available to a broad audience, e.g., as centrally managed large language models (LLMs). Such centralization is both a risk and a performance bottleneck - Edge AI promises to be a solution to these problems. However, its decentralized approach raises additional challenges regarding security and safety. In this paper, we argue that both of these aspects are critical for Edge AI, and even more so, their integration. Concretely, we survey security and safety threats, summarize existing countermeasures, and collect open challenges as a call for more research in this area.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modeling Buffer Occupancy in bittide Systems</title>
<link>https://arxiv.org/abs/2410.05432</link>
<guid>https://arxiv.org/abs/2410.05432</guid>
<content:encoded><![CDATA[
<div> 关键词：bittide机制、分布式系统、弹性缓冲区、连续帧传输、逻辑同步计算

<br />
总结:
本文详细分析了bittide机制在分布式系统中实现逻辑同步计算的方式。它利用有线网络如以太网固有的连续帧传输特性，通过分散式控制系统调整各节点的本地时钟频率，确保所有节点以一致的时间概念运行。每个节点上的弹性缓冲区吸收频率变化，避免了对全局时钟的依赖。研究通过流模型分析了这些弹性缓冲区的稳态占用率，这是影响系统延迟的关键因素。文中证明了缓冲区占用率的收敛性，并推导出了稳态值的明确公式，该公式基于系统参数包括网络拓扑、物理延迟和控制器增益。这一分析为优化bittide基础分布式系统的缓冲区大小和最小化延迟提供了宝贵的见解。 <div>
arXiv:2410.05432v1 Announce Type: new 
Abstract: The bittide mechanism enables logically synchronous computation across distributed systems by leveraging the continuous frame transmission inherent to wired networks such as Ethernet. Instead of relying on a global clock, bittide uses a decentralized control system to adjust local clock frequencies, ensuring all nodes operate with a consistent notion of time by utilizing elastic buffers at each node to absorb frequency variations. This paper presents an analysis of the steady-state occupancy of these elastic buffers, a critical factor influencing system latency. Using a fluid model of the bittide system, we prove that buffer occupancy converges and derive an explicit formula for the steady-state value in terms of system parameters, including network topology, physical latencies, and controller gains. This analysis provides valuable insights for optimizing buffer sizes and minimizing latency in bittide-based distributed systems.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game of Coding: Sybil Resistant Decentralized Machine Learning with Minimal Trust Assumption</title>
<link>https://arxiv.org/abs/2410.05540</link>
<guid>https://arxiv.org/abs/2410.05540</guid>
<content:encoded><![CDATA[
<div> 关键词：编码理论、数据恢复、激励导向环境、节点数量、游戏编码框架

总结:

本文聚焦于编码理论在确保数据完整性和可靠性方面的关键作用，特别是在通信、计算和存储系统中。然而，编码理论依赖于信任假设进行数据恢复，这在新兴的去中心化系统中提出了重大挑战，因为这些系统中的信任稀缺。为解决这一问题，文章引入了“游戏编码”框架，旨在揭示激励导向环境中数据恢复策略的洞察。

文章特别关注了由一个诚实节点和多个敌对节点构成的场景。研究发现，尽管敌对节点数量增加为它们提供了更多的灵活性，但增加的权力实际上并不利于敌对节点，也不损害数据收集者，因此该方案具有抗Sybil攻击性。

此外，文章还阐述了数据收集者在接纳或拒绝输入方面的最优策略，并对敌对节点的最优噪声分布进行了特征分析。这一研究为理解在不同节点配置下编码理论的应用提供了新的视角，并为设计更安全、高效的去中心化系统提供了理论基础。 <div>
arXiv:2410.05540v1 Announce Type: new 
Abstract: Coding theory plays a crucial role in ensuring data integrity and reliability across various domains, from communication to computation and storage systems. However, its reliance on trust assumptions for data recovery poses significant challenges, particularly in emerging decentralized systems where trust is scarce. To address this, the game of coding framework was introduced, offering insights into strategies for data recovery within incentive-oriented environments. The focus of the earliest version of the game of coding was limited to scenarios involving only two nodes. This paper investigates the implications of increasing the number of nodes in the game of coding framework, particularly focusing on scenarios with one honest node and multiple adversarial nodes. We demonstrate that despite the increased flexibility for the adversary with an increasing number of adversarial nodes, having more power is not beneficial for the adversary and is not detrimental to the data collector, making this scheme sybil-resistant. Furthermore, we outline optimal strategies for the data collector in terms of accepting or rejecting the inputs, and characterize the optimal noise distribution for the adversary.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Blockchain-Enhanced Framework for Privacy and Data Integrity in Crowdsourced Drone Services</title>
<link>https://arxiv.org/abs/2410.05653</link>
<guid>https://arxiv.org/abs/2410.05653</guid>
<content:encoded><![CDATA[
<div> 关键词：消费者级无人机、 bushfire管理、数据隐私、澳大利亚隐私法、区块链

<br />
<br />
总结:
文章介绍了一种创新框架，旨在将消费者级无人机融入到丛林火灾管理中，同时考虑了服务改进和数据隐私保护问题，符合澳大利亚隐私法1988年规定。该系统构建了一个市场平台，其中丛林火灾管理部门作为数据消费者获取来自无人机运营商的数据。运营商作为数据提供者，其隐私通过本地差分隐私技术得到保护，确保了所有系统实体之间的隐私安全。此外，采用区块链技术处理数据和费用交换，保证了交易的公平性和不可篡改记录，增强了责任性。该框架通过概念验证实施进行了验证，展现出在大规模、实际应用中的可扩展性和适应性，适用于广泛的丛林火灾管理场景。 <div>
arXiv:2410.05653v1 Announce Type: new 
Abstract: We present an innovative framework that integrates consumer-grade drones into bushfire management, addressing both service improvement and data privacy concerns under Australia's Privacy Act 1988. This system establishes a marketplace where bushfire management authorities, as data consumers, access critical information from drone operators, who serve as data providers. The framework employs local differential privacy to safeguard the privacy of data providers from all system entities, ensuring compliance with privacy standards. Additionally, a blockchain-based solution facilitates fair data and fee exchanges while maintaining immutable records for enhanced accountability. Validated through a proof-of-concept implementation, the framework's scalability and adaptability make it well-suited for large-scale, real-world applications in bushfire management.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Scalable State Sharing Protocol for Low-Resource Validator Nodes in Blockchain Networks</title>
<link>https://arxiv.org/abs/2410.05854</link>
<guid>https://arxiv.org/abs/2410.05854</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据存储、Kademlia协议、Merkle证明、Verkle证明

总结:

本文提出了一种新的区块链网络参与协议，旨在让验证节点无需在每个节点上存储整个网络状态，以降低存储成本。该协议的核心理念是将区块链网络作为复制状态机和分布式存储系统使用，通过分布式状态和基于Kademlia启发式路由协议的高效数据检索机制来减少验证节点的存储需求。使用加密证明（如Merkle证明）允许节点验证其他节点存储的数据，而无需直接信任这些节点。

为了验证该状态共享协议的有效性，文章进行了对以太坊数据存储和访问模式的广泛定量分析。结果表明，虽然该协议显著降低了存储需求，但带来了从1.5MB到5MB不等的每区块额外带宽使用量，相当于每月额外319GB到1065GB的带宽消耗。尽管如此，这个增量仍然足够小，可以在以太坊的12秒块验证窗口内传递给所有节点并进行验证。进一步的分析显示，Merkle证明是增加带宽的主要因素。为了解决这一问题，文章还分析了转向更空间高效的Verkle证明的影响。 <div>
arXiv:2410.05854v1 Announce Type: new 
Abstract: The perpetual growth of data stored on popular blockchains such as Ethereum leads to significant scalability challenges and substantial storage costs for operators of full nodes. Increasing costs may lead to fewer independently operated nodes in the network, which poses risks to decentralization (and hence network security), but also pushes decentralized app developers towards centrally hosted API services.
  This paper introduces a new protocol that allows validator nodes to participate in a blockchain network without the need to store the full state of the network on each node. The key idea is to use the blockchain network as both a replicated state machine and as a distributed storage system. By distributing states across nodes and enabling efficient data retrieval through a Kademlia-inspired routing protocol, we reduce storage costs for validators. Cryptographic proofs (such as Merkle proofs) are used to allow nodes to verify data stored by other nodes without having to trust those nodes directly. While the protocol trades off data storage for increased network bandwidth, we show how gossiping and caching can minimize the increased bandwidth needs.
  To validate our state sharing protocol, we conduct an extensive quantitative analysis of Ethereum's data storage and data access patterns. Our findings indicate that while our protocol significantly lowers storage needs, it comes with an increased bandwidth usage ranging from 1.5 MB to 5 MB per block, translating to an additional monthly bandwidth of 319 GB to 1,065 GB. Despite this, the size remains small enough such that it can be passed to all nodes and validated within Ethereum's 12-second block validation window. Further analysis shows that Merkle proofs are the most significant contributor to the additional bandwidth. To address this concern, we also analyze the impact of switching to the more space-efficient Verkle Proofs.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Tomographic Reconstruction with Quantization</title>
<link>https://arxiv.org/abs/2410.06106</link>
<guid>https://arxiv.org/abs/2410.06106</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式重建、交替方向乘子法（ADMM）、可配置量化、K-均值聚类、JPEG压缩

<br /><br />
总结:

本文提出了一种基于分布式交替方向乘子法（ADMM）的图像重建方法，该方法通过将数据和计算任务分散到多个节点上，有效解决了传统集中式重建方法中遇到的内存限制和数据隐私问题。引入的可配置量化技术进一步增强了系统的灵活性和效率。为了优化节点间的通信效率，文中提出了基于K-均值聚类和JPEG压缩的两种量化策略。实验结果表明，这种方法在保持高重建精度的同时，能够有效降低通信开销和内存使用，实现了高效、低资源消耗的图像重建过程。这种方法特别适用于资源受限环境或对数据隐私有严格要求的应用场景。 <div>
arXiv:2410.06106v1 Announce Type: new 
Abstract: Conventional tomographic reconstruction typically depends on centralized servers for both data storage and computation, leading to concerns about memory limitations and data privacy. Distributed reconstruction algorithms mitigate these issues by partitioning data across multiple nodes, reducing server load and enhancing privacy. However, these algorithms often encounter challenges related to memory constraints and communication overhead between nodes. In this paper, we introduce a decentralized Alternating Directions Method of Multipliers (ADMM) with configurable quantization. By distributing local objectives across nodes, our approach is highly scalable and can efficiently reconstruct images while adapting to available resources. To overcome communication bottlenecks, we propose two quantization techniques based on K-means clustering and JPEG compression. Numerical experiments with benchmark images illustrate the tradeoffs between communication efficiency, memory use, and reconstruction accuracy.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>De-VertiFL: A Solution for Decentralized Vertical Federated Learning</title>
<link>https://arxiv.org/abs/2410.06127</link>
<guid>https://arxiv.org/abs/2410.06127</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Vertical Federated Learning（VFL）、De-VertiFL、模型训练、数据隐私

<br /><br />
总结:

本文介绍了De-VertiFL，一种专为垂直联邦学习（VFL）设计的新型解决方案。VFL在实际场景中尤为重要，特别是在客户端持有关于同一实体的不同但敏感数据的去中心化环境中。与传统的水平联邦学习（FL）不同，VFL关注于数据特征的差异性而非一致性。De-VertiFL的核心创新包括一种新的网络架构分布、一种创新的知识交换方案以及一个分布式联邦训练过程。

De-VertiFL允许联邦客户端共享隐藏层输出，通过这种方式，参与者可以利用中间计算结果来提高学习效率。该方法不仅在F1分数性能上优于当前最先进的方法，而且维持了去中心化和数据隐私保护的框架。研究团队使用了多种著名数据集进行评估，包括图像和表格数据，覆盖二分类和多类分类任务，证明了De-VertiFL的有效性和优越性。

通过引入这些关键组件，De-VertiFL为VFL环境下的模型训练提供了一种更为高效、灵活且安全的方法，显著提升了学习性能，同时保障了参与者的隐私安全。 <div>
arXiv:2410.06127v1 Announce Type: new 
Abstract: Federated Learning (FL), introduced in 2016, was designed to enhance data privacy in collaborative model training environments. Among the FL paradigm, horizontal FL, where clients share the same set of features but different data samples, has been extensively studied in both centralized and decentralized settings. In contrast, Vertical Federated Learning (VFL), which is crucial in real-world decentralized scenarios where clients possess different, yet sensitive, data about the same entity, remains underexplored. Thus, this work introduces De-VertiFL, a novel solution for training models in a decentralized VFL setting. De-VertiFL contributes by introducing a new network architecture distribution, an innovative knowledge exchange scheme, and a distributed federated training process. Specifically, De-VertiFL enables the sharing of hidden layer outputs among federation clients, allowing participants to benefit from intermediate computations, thereby improving learning efficiency. De-VertiFL has been evaluated using a variety of well-known datasets, including both image and tabular data, across binary and multiclass classification tasks. The results demonstrate that De-VertiFL generally surpasses state-of-the-art methods in F1-score performance, while maintaining a decentralized and privacy-preserving framework.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>blockLAW: Blockchain Technology for Legal Automation and Workflow -- Cyber Ethics and Cybersecurity Platforms</title>
<link>https://arxiv.org/abs/2410.06143</link>
<guid>https://arxiv.org/abs/2410.06143</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、blockLAW、法律自动化、网络安全、伦理问题

总结:
本文探讨了区块链技术，特别是以blockLAW形式存在的区块链，在促进法律自动化、增强网络安全以及处理伦理问题方面的作用。区块链通过其去中心化和不可篡改的特性，为简化法律程序、利用智能合约自动执行合同以及提高法律交易透明度提供了机会。它被视为更新法律流程、同时保持道德标准、解决诸如可扩展性、合规性和隐私公平等关键问题的重要工具。文章分析了区块链技术在法律结构中的最新发展，评估了其对法律程序改进和法律体系透明度保障的潜力。此外，文章强调了区块链技术如何改变法律专业人员处理敏感信息的方式，从而实现更强大、更有效、更可靠的法律程序。文章还讨论了将区块链技术整合到法律系统中时需要考虑的技术层面，包括规划、实施策略、创新、进步和趋势，提出了区块链集成框架在法律系统中的应用。

通过区块链技术的应用，可以实现法律流程的自动化，减少人为错误，提高效率；同时，确保数据的安全性和完整性，保护用户隐私；此外，区块链的透明特性有助于建立公众对法律系统的信任。然而，技术的引入也带来了一系列挑战，如法律法规的适应性、技术复杂性的管理、以及对伦理和隐私保护的考量。因此，制定合理的策略和框架至关重要，以确保区块链技术能够安全、有效地融入并提升现有的法律体系。 <div>
arXiv:2410.06143v1 Announce Type: new 
Abstract: In the current legal environment, it is essential to prioritize the protection and reliability of data to promote trust and effectiveness. This study examines how blockchain technology in the form of blockLAW can be applicable to investigate its effects on legal automation, cybersecurity, and ethical concerns. The decentralized ledger and unchangeable characteristics of Blockchain provide opportunities to simplify legal procedures, automate contract execution with smart contracts, and improve transparency in legal transactions. Blockchain is seen as a crucial instrument for updating legal processes while maintaining ethical standards, tackling issues like scalability, regulatory adherence, and ethical dilemmas such as privacy and fairness. The study examines recent developments and evaluates blockchain impact on legal structures, offering perspectives on its potential to enhance legal procedures and guarantee transparency in legal systems. It further emphasizes blockchain ability to redefine how legal professionals handle and protect sensitive information, leading to stronger, more effective, and reliable legal procedures. We have also discussed the technological considerations when it comes to blockchain integration into legal systems like integration planning, implementation strategies, innovations, advancements, trends with Blockchain Integration Framework for legal systems.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SC-Bench: A Large-Scale Dataset for Smart Contract Auditing</title>
<link>https://arxiv.org/abs/2410.06176</link>
<guid>https://arxiv.org/abs/2410.06176</guid>
<content:encoded><![CDATA[
<div> 关键词：SC-Bench、GPT-4、智能合约审计、自动化技术、机器学习

<br /><br />
总结:

文章介绍了SC-Bench，这是首个针对智能合约自动审计研究的数据集。数据集包含了5377个真实运行在以太坊区块链平台上的智能合约和15975个违反以太坊标准（ERCs）的实例。其中139个是程序员实际犯下的错误，其余则是通过系统性注入来反映不同ERC规则的错误。研究使用了GPT-4模型，首先不提供任何上下文信息，GPT-4只能检测到约0.9%的违规情况；当提供了上下文信息后，其检测比例提升至22.9%。

该结果揭示了智能合约审计领域中基于机器学习的自动化技术仍有巨大的改进空间。SC-Bench为智能合约审计的自动化研究提供了宝贵的资源，同时指出了现有技术在精确识别和定位违规情况方面的局限性。通过这个数据集和模型的应用，研究人员和开发人员可以更好地理解智能合约中的潜在风险，并推动更安全、更可靠的智能合约开发实践。 <div>
arXiv:2410.06176v1 Announce Type: new 
Abstract: There is a huge demand to ensure the compliance of smart contracts listed on blockchain platforms to safety and economic standards. Today, manual efforts in the form of auditing are commonly used to achieve this goal. ML-based automated techniques have the promise to alleviate human efforts and the resulting monetary costs. However, unlike other domains where ML techniques have had huge successes, no systematic ML techniques have been proposed or applied to smart contract auditing. We present SC-Bench, the first dataset for automated smart-contract auditing research. SC-Bench consists of 5,377 real-world smart contracts running on Ethereum, a widely used blockchain platform, and 15,975 violations of standards on Ehereum called ERCs. Out of these violations, 139 are real violations programmers made. The remaining are errors we systematically injected to reflect the violations of different ERC rules. We evaluate SC-Bench using GPT-4 by prompting it with both the contracts and ERC rules. In addition, we manually identify each violated rule and the corresponding code site (i.e., oracle) and prompt GPT-4 with the information asking for a True-or-False question. Our results show that without the oracle, GPT-4 can only detect 0.9% violations, and with the oracle, it detects 22.9% violations. These results show the potential room for improvement in ML-based techniques for smart-contract auditing.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FRESCO: Fast and Reliable Edge Offloading with Reputation-based Hybrid Smart Contracts</title>
<link>https://arxiv.org/abs/2410.06715</link>
<guid>https://arxiv.org/abs/2410.06715</guid>
<content:encoded><![CDATA[
<div> 关键词：FRESCO、区块链、可靠性、分布式边缘环境、智能合约

总结:
文章介绍了一种名为FRESCO的新框架，旨在解决移动设备在分布式不可靠边缘环境中为满足服务质量(QoS)截止时间而卸载延迟敏感应用任务时面临的挑战。FRESCO利用基于区块链的声誉系统来提高分布式边缘环境中的卸载可靠性。该系统通过历史性能跟踪边缘服务器的表现，并利用区块链共识机制确保敏感声誉信息的安全性，防止篡改。为了克服区块链共识带来的高延迟问题，FRESCO采用了混合智能合约(HSC)，在链上安全地管理声誉状态的同时，允许快速的离链卸载决策。卸载决策引擎利用声誉评分进行快速决策，基于此决策，应用延迟敏感且需要高可靠性的任务能够被分配到可靠的服务器上。FRESCO通过结合链上HSC声誉状态管理和离线SMT决策引擎，实现了在不阻碍区块链共识的情况下，快速、可靠地卸载任务。在对真实可用性轨迹和模拟应用程序的评估中，FRESCO将响应时间减少了高达7.86倍，节省了高达5.4%的能源，同时将QoS违规降至0.4%，平均决策时间为5.05毫秒。 <div>
arXiv:2410.06715v1 Announce Type: new 
Abstract: Mobile devices offload latency-sensitive application tasks to edge servers to satisfy applications' Quality of Service (QoS) deadlines. Consequently, ensuring reliable offloading without QoS violations is challenging in distributed and unreliable edge environments. However, current edge offloading solutions are either centralized or do not adequately address challenges in distributed environments. We propose FRESCO, a fast and reliable edge offloading framework that utilizes a blockchain-based reputation system, which enhances the reliability of offloading in the distributed edge. The distributed reputation system tracks the historical performance of edge servers, while blockchain through a consensus mechanism ensures that sensitive reputation information is secured against tampering. However, blockchain consensus typically has high latency, and therefore we employ a Hybrid Smart Contract (HSC) that automatically computes and stores reputation securely on-chain (i.e., on the blockchain) while allowing fast offloading decisions off-chain (i.e., outside of blockchain). The offloading decision engine uses a reputation score to derive fast offloading decisions, which are based on Satisfiability Modulo Theory (SMT). The SMT models edge resource constraints, and QoS deadlines, and can formally guarantee a feasible solution that is valuable for latency-sensitive applications that require high reliability. With a combination of on-chain HSC reputation state management and an off-chain SMT decision engine, FRESCO offloads tasks to reliable servers without being hindered by blockchain consensus. We evaluate FRESCO against real availability traces and simulated applications. FRESCO reduces response time by up to 7.86 times and saves energy by up to 5.4% compared to all baselines while minimizing QoS violations to 0.4% and achieving an average decision time of 5.05 milliseconds.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hybrid Renewable-Battery-Electrolyzer Facility under the Single Imbalance Pricing Scheme</title>
<link>https://arxiv.org/abs/2410.06773</link>
<guid>https://arxiv.org/abs/2410.06773</guid>
<content:encoded><![CDATA[
<div> 关键词：欧洲能源市场、不平衡管理、可再生能源、单不平衡定价、灵活资产

<br /><br />
总结:本文探讨了在欧洲分散式能源市场环境下，结合不可控可再生能源（RES）、电池和电解槽的混合设施的行为。研究旨在通过数学模型最大化日前瞻市场收益并最小化不平衡成本。文章采用随机场景捕捉RES输出不确定性，并提出了一种新的鲁棒方法来模拟电力系统偏差方向，这是单不平衡定价的一部分。研究结果表明，在预期有利的不平衡价格情况下，灵活资产可能会诱使故意偏离平衡。这一发现强调了在实施单不平衡定价机制时需要考虑的策略性行为风险。 <div>
arXiv:2410.06773v1 Announce Type: new 
Abstract: European energy markets are decentralized and entail balance responsibility of each market player. This stresses the importance of imbalance management of renewable energy sources (RES), as the imbalance payments can strongly reduce their profitability. According to the EU Electricity Balancing Guideline, each European transmission system operator should use the single imbalance pricing method which treats both deviation directions the same, no matter if a deviation helps the system or pushes it away from the balance. This paper aims to investigate the behavior of a hybrid facility consisting of an uncontrollable RES, a battery and an electrolyzer under such market setting. The formulated mathematical model of the hybrid facility seeks to maximize profit in the day-ahead energy market, while minimizing the imbalance costs. Uncertainty of the RES output is captured using stochastic scenarios, while the direction of the power system deviation, relevant for the imbalance pricing, is modeled using a newly proposed robust approach. Results of the case study indicate that the single imbalance pricing scheme might bring flexible assets to temptation of intentional deviations should they anticipate favorable imbalance prices.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph Network Models To Detect Illicit Transactions In Block Chain</title>
<link>https://arxiv.org/abs/2410.07150</link>
<guid>https://arxiv.org/abs/2410.07150</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、反洗钱、图注意力网络、残差网络、区块链

总结:
本文研究了加密货币领域中反洗钱与打击恐怖融资（AML/CFT）活动的挑战，特别是随着加密货币使用增加，传统基于规则的方法在检测和预防非法活动方面变得不那么有效。为此，作者提出了一种创新方法，即结合图注意力网络（GAT）与类似残差网络架构（ResNet）的模型，以提高在区块链上检测非法交易的能力。

具体而言，作者利用Elliptic Bitcoin交易数据集训练了多种模型，包括逻辑回归、随机森林、XGBoost、GCN（图卷积网络）、GAT（图注意力网络）以及他们提出的GAT-ResNet模型。研究结果表明，GAT-ResNet模型在准确性、可靠性和可扩展性方面可能优于现有的图网络模型。

这项研究为使用图相关机器学习模型来增强打击金融犯罪的努力提供了新的视角，并为未来在这方面的研究奠定了基础。通过比较不同模型的表现，研究揭示了图注意力网络架构在检测加密货币领域的非法活动中的潜在优势，为提升反洗钱系统效能提供了理论支持和实践指导。 <div>
arXiv:2410.07150v1 Announce Type: new 
Abstract: The use of cryptocurrencies has led to an increase in illicit activities such as money laundering, with traditional rule-based approaches becoming less effective in detecting and preventing such activities. In this paper, we propose a novel approach to tackling this problem by applying graph attention networks with residual network-like architecture (GAT-ResNet) to detect illicit transactions related to anti-money laundering/combating the financing of terrorism (AML/CFT) in blockchains. We train various models on the Elliptic Bitcoin Transaction dataset, implementing logistic regression, Random Forest, XGBoost, GCN, GAT, and our proposed GAT-ResNet model. Our results demonstrate that the GAT-ResNet model has a potential to outperform the existing graph network models in terms of accuracy, reliability and scalability. Our research sheds light on the potential of graph related machine learning models to improve efforts to combat financial crime and lays the foundation for further research in this area.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Immersion and Presence in the Metaverse with Over-the-Air Brain-Computer Interface</title>
<link>https://arxiv.org/abs/2303.10577</link>
<guid>https://arxiv.org/abs/2303.10577</guid>
<content:encoded><![CDATA[
<div> 关键词：脑机接口、无线边缘服务器、混合学习算法、元学习算法、资源分配

<br /><br />
总结:本文提出了一种创新框架，利用空中脑机接口(BCI)学习元宇宙用户的期望。通过解析用户的大脑活动，该框架能够优化物理资源并提升用户体验质量(QoE)。实现这一目标的关键在于，通过无线边缘服务器(WES)使用上行无线信道处理脑电图(EEG)信号，从而减轻元宇宙用户设备的计算负担。WES可以学习人类行为、调整系统配置并分配射频资源，以实现个性化的用户设置。尽管BCI具有潜力，但其固有的无线通道噪声和EEG信号不确定性使得相关资源分配和学习问题极具挑战性。本文将联合学习与资源分配问题建模为混合整数规划问题，并提出了两种算法：一种是结合学习算法，可有效求解此问题；另一种是元学习算法，能进一步利用多个用户间EEG信号的神经多样性，提高分类准确性。实验证明，基于真实BCI数据集的模拟结果充分展示了该框架的高效性，同时实现了低延迟和高EEG信号分类精度。 <div>
arXiv:2303.10577v3 Announce Type: replace 
Abstract: This article proposes a novel framework that utilizes an over-the-air Brain-Computer Interface (BCI) to learn Metaverse users' expectations. By interpreting users' brain activities, our framework can optimize physical resources and enhance Quality-of-Experience (QoE) for users. To achieve this, we leverage a Wireless Edge Server (WES) to process electroencephalography (EEG) signals via uplink wireless channels, thus eliminating the computational burden for Metaverse users' devices. As a result, the WES can learn human behaviors, adapt system configurations, and allocate radio resources to tailor personalized user settings. Despite the potential of BCI, the inherent noisy wireless channels and uncertainty of the EEG signals make the related resource allocation and learning problems especially challenging. We formulate the joint learning and resource allocation problem as a mixed integer programming problem. Our solution involves two algorithms: a hybrid learning algorithm and a meta-learning algorithm. The hybrid learning algorithm can effectively find the solution for the formulated problem. Specifically, the meta-learning algorithm can further exploit the neurodiversity of the EEG signals across multiple users, leading to higher classification accuracy. Extensive simulation results with real-world BCI datasets show the effectiveness of our framework with low latency and high EEG signal classification accuracy.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy of Solutions and Directions for Future Research</title>
<link>https://arxiv.org/abs/2410.03855</link>
<guid>https://arxiv.org/abs/2410.03855</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、联邦学习、群体公平性、敏感属性、数据分布

总结:

本文是一篇关于联邦学习中群体公平性的全面综述。主要关注在多元化的数据分布下，如何通过联邦学习实现不同群体间的公正结果。随着联邦学习的普及，确保模型对不同敏感属性（如性别、种族等）群体的公平性成为重要议题。文中指出，已有47项研究专门探讨了这一问题，但尚未有一份专注于此的全面综述。

首先，文章构建了一个基于数据分割、位置和实施策略的创新分类框架，系统梳理了相关研究方法。接着，文章深入探讨了这一领域面临的关键挑战及广泛考虑因素，强调了如何有效处理各种敏感群体及其交集带来的复杂性。

此外，文章还回顾了当前研究中常用的数据库和应用案例，为后续工作提供了参考。最后，文章提出未来研究的方向，着重于开发更多方法以解决联邦系统中群体公平性的复杂问题，旨在推动该领域的深入发展。

通过这一综合分析，文章不仅为现有研究提供了清晰的视角，也为未来在联邦学习中追求更高质量的群体公平性指明了路径。 <div>
arXiv:2410.03855v1 Announce Type: new 
Abstract: Group fairness in machine learning is a critical area of research focused on achieving equitable outcomes across different groups defined by sensitive attributes such as race or gender. Federated learning, a decentralized approach to training machine learning models across multiple devices or organizations without sharing raw data, amplifies the need for fairness due to the heterogeneous data distributions across clients, which can exacerbate biases. The intersection of federated learning and group fairness has attracted significant interest, with 47 research works specifically dedicated to addressing this issue. However, no dedicated survey has focused comprehensively on group fairness in federated learning. In this work, we present an in-depth survey on this topic, addressing the critical challenges and reviewing related works in the field. We create a novel taxonomy of these approaches based on key criteria such as data partitioning, location, and applied strategies. Additionally, we explore broader concerns related to this problem and investigate how different approaches handle the complexities of various sensitive groups and their intersections. Finally, we review the datasets and applications commonly used in current research. We conclude by highlighting key areas for future research, emphasizing the need for more methods to address the complexities of achieving group fairness in federated systems.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>YOLO-MARL: You Only LLM Once for Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.03997</link>
<guid>https://arxiv.org/abs/2410.03997</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、深度学习、大型语言模型、策略生成、决策协作

总结:

本文提出了一种名为“你只需要一次大型语言模型”（YOLO-MARL）的新框架，旨在利用大型语言模型（LLM）的高级任务规划能力来增强多智能体在合作游戏中的决策过程。YOLO-MARL的主要创新点在于，对于每个特定的游戏环境，它仅需要一次与LLM的交互，分别完成策略生成、状态解释和规划函数生成模块的任务，从而在多智能体策略训练阶段避免了频繁调用LLM API的成本和计算时间。

具体而言，该框架通过将LLM的决策过程前置，使得训练后的分布式小型神经网络基线策略能够独立运行，无需依赖于持续的LLM支持。这种方法在三个不同环境中进行了评估，并展示了与传统多智能体强化学习算法相比的显著性能提升。

综上所述，YOLO-MARL通过优化策略生成流程并减少对大型语言模型的依赖，为多智能体系统在复杂合作场景下的高效决策提供了新的解决方案。 <div>
arXiv:2410.03997v1 Announce Type: new 
Abstract: Advancements in deep multi-agent reinforcement learning (MARL) have positioned it as a promising approach for decision-making in cooperative games. However, it still remains challenging for MARL agents to learn cooperative strategies for some game environments. Recently, large language models (LLMs) have demonstrated emergent reasoning capabilities, making them promising candidates for enhancing coordination among the agents. However, due to the model size of LLMs, it can be expensive to frequently infer LLMs for actions that agents can take. In this work, we propose You Only LLM Once for MARL (YOLO-MARL), a novel framework that leverages the high-level task planning capabilities of LLMs to improve the policy learning process of multi-agents in cooperative games. Notably, for each game environment, YOLO-MARL only requires one time interaction with LLMs in the proposed strategy generation, state interpretation and planning function generation modules, before the MARL policy training process. This avoids the ongoing costs and computational time associated with frequent LLMs API calls during training. Moreover, the trained decentralized normal-sized neural network-based policies operate independently of the LLM. We evaluate our method across three different environments and demonstrate that YOLO-MARL outperforms traditional MARL algorithms.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Compositional Planning for Logically Constrained Multi-Agent Markov Decision Processes</title>
<link>https://arxiv.org/abs/2410.04004</link>
<guid>https://arxiv.org/abs/2410.04004</guid>
<content:encoded><![CDATA[
<div> 关键词：大型分布式系统、时间逻辑规格、Constrained Markov Decision Processes（CMDPs）、假设-保证分解、多代理环境

<br /><br />
总结:
本文探讨了设计大型分布式系统控制策略的挑战，特别是在满足关键的时间逻辑基于规格（如安全性）方面，这些规格必须以高概率实现。为了解决这个问题，文章提出了一种基于Constrained Markov Decision Processes（CMDPs）的框架，提供了一种假设-保证的分解方法，用于合成多代理环境下的去中心化控制策略，同时满足逻辑约束。该方法确保策略以高概率满足约束，并提供达到目标奖励的下限。通过实验证明，这种方法返回的策略不仅实现了接近最优的奖励，还显著减少了问题规模和执行时间，达到了约一个数量级的减少。这一成果对于提高大型分布式系统的效率和可靠性具有重要意义。

<br /><br /> <div>
arXiv:2410.04004v1 Announce Type: new 
Abstract: Designing control policies for large, distributed systems is challenging, especially in the context of critical, temporal logic based specifications (e.g., safety) that must be met with high probability. Compositional methods for such problems are needed for scalability, yet relying on worst-case assumptions for decomposition tends to be overly conservative. In this work, we use the framework of Constrained Markov Decision Processes (CMDPs) to provide an assume-guarantee based decomposition for synthesizing decentralized control policies, subject to logical constraints in a multi-agent setting. The returned policies are guaranteed to satisfy the constraints with high probability and provide a lower bound on the achieved objective reward. We empirically find the returned policies to achieve near-optimal rewards while enjoying an order of magnitude reduction in problem size and execution time.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BlockFound: Customized blockchain foundation model for anomaly detection</title>
<link>https://arxiv.org/abs/2410.04039</link>
<guid>https://arxiv.org/abs/2410.04039</guid>
<content:encoded><![CDATA[
<div> 关键词：BlockFound、基础模型、异常检测、区块链交易、定制设计

总结:
文章介绍了名为BlockFound的基础模型，这是一个专门用于检测区块链交易异常的新方法。与依赖于规则系统或直接应用现成大型语言模型的传统方法不同，BlockFound引入了一系列定制化的设计来适应区块链交易的独特数据结构。首先，它设计了一个模块化的分词器来处理多模态输入，平衡了不同模态的信息。其次，设计了一种定制的掩码语言学习机制进行预训练，使用RoPE嵌入和FlashAttention来处理更长的序列。

在对以太坊和索拉纳交易的广泛评估中，BlockFound展示了其在异常检测方面的卓越能力，同时保持了较低的误报率。值得注意的是，BlockFound是唯一能够以高精度在索拉纳上成功检测到异常交易的方法，而其他所有方法的检测召回分数都非常低甚至为零。这项工作不仅提供了新的区块链基础模型，还为将大型语言模型应用于区块链数据设定了新基准。 <div>
arXiv:2410.04039v1 Announce Type: new 
Abstract: We propose BlockFound, a customized foundation model for anomaly blockchain transaction detection. Unlike existing methods that rely on rule-based systems or directly apply off-the-shelf large language models, BlockFound introduces a series of customized designs to model the unique data structure of blockchain transactions. First, a blockchain transaction is multi-modal, containing blockchain-specific tokens, texts, and numbers. We design a modularized tokenizer to handle these multi-modal inputs, balancing the information across different modalities. Second, we design a customized mask language learning mechanism for pretraining with RoPE embedding and FlashAttention for handling longer sequences. After training the foundation model, we further design a novel detection method for anomaly detection. Extensive evaluations on Ethereum and Solana transactions demonstrate BlockFound's exceptional capability in anomaly detection while maintaining a low false positive rate. Remarkably, BlockFound is the only method that successfully detects anomalous transactions on Solana with high accuracy, whereas all other approaches achieved very low or zero detection recall scores. This work not only provides new foundation models for blockchain but also sets a new benchmark for applying LLMs in blockchain data.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>180 Days After EIP-4844: Will Blob Sharing Solve Dilemma for Small Rollups?</title>
<link>https://arxiv.org/abs/2410.04111</link>
<guid>https://arxiv.org/abs/2410.04111</guid>
<content:encoded><![CDATA[
<div> 关键词：EIP-4844、数据可用性（DA）、Blob共享、成本降低、服务质量提升

<br /><br />
总结: 文章主要探讨了在以太坊网络中引入EIP-4844之后，通过使用Blob共享技术来优化数据可用性（DA）成本的问题。在实施EIP-4844后，Blob的固定大小为128KB，导致数据吞吐量低的Rollup面临两难选择：要么不充分利用Blob资源，要么减少DA提交频率。文章提出并验证了Blob共享策略，即多个Rollup共享一个Blob，能够显著改善小规模Rollup的成本和DA服务质量，有效解决了上述问题。实证分析表明，当Rollup合作进行Blob共享时，成本降低幅度超过90%，这主要归因于通过Blob共享实现的Blob基础费用平滑效果。 <div>
arXiv:2410.04111v1 Announce Type: new 
Abstract: The introduction of blobs through EIP-4844 has significantly reduced the Data Availability (DA) costs for rollups on Ethereum. However, due to the fixed size of blobs at 128 KB, rollups with low data throughput face a dilemma: they either use blobs inefficiently or decrease the frequency of DA submissions. Blob sharing, where multiple rollups share a single blob, has been proposed as a solution to this problem. This paper examines the effectiveness of blob sharing based on real-world data collected approximately six months after the implementation of EIP-4844. By simulating cost changes using a simple blob sharing format, we demonstrate that blob sharing can substantially improve the costs and DA service quality for small rollups, effectively resolving their dilemma. Notably, we observed cost reductions in USD exceeding 90% for most of the rollups when they cooperate, attributable to the smoothing effect of the blob base fee achieved through blob sharing.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>ConDa: Fast Federated Unlearning with Contribution Dampening</title>
<link>https://arxiv.org/abs/2410.04144</link>
<guid>https://arxiv.org/abs/2410.04144</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、联邦卸载、隐私保护、效率、非IID数据

总结:

本文提出了贡献衰减(ConDa)框架，旨在解决联邦学习中卸载特定参与者及其相关数据的问题。在联邦卸载中，移除参与者的数据对模型性能的影响是一个挑战。ConDa通过追踪每个客户端影响全局模型的参数，并对具有隐私侵犯贡献的全局模型参数进行突触衰减，实现了高效卸载。该方法无需使用客户端数据或重新训练模型，也不对客户端或服务器端造成任何计算负担。

ConDa的实验结果在MNIST、CIFAR10和CIFAR100等数据集上得到了验证，证明了其在卸载客户端数据方面的有效性和速度优势，相比现有最先进的方法至少快100倍。特别地，本文强调了在非独立同分布（non-IID）联邦学习环境下卸载的挑战性，并展示了ConDa在此环境下的鲁棒性。此外，通过对抗后门攻击和成员推断攻击，验证了ConDa的防御能力。这项工作对于满足法律和伦理要求的联邦学习至关重要。 <div>
arXiv:2410.04144v1 Announce Type: new 
Abstract: Federated learning (FL) has enabled collaborative model training across decentralized data sources or clients. While adding new participants to a shared model does not pose great technical hurdles, the removal of a participant and their related information contained in the shared model remains a challenge. To address this problem, federated unlearning has emerged as a critical research direction, seeking to remove information from globally trained models without harming the model performance on the remaining data. Most modern federated unlearning methods use costly approaches such as the use of remaining clients data to retrain the global model or methods that would require heavy computation on client or server side. We introduce Contribution Dampening (ConDa), a framework that performs efficient unlearning by tracking down the parameters which affect the global model for each client and performs synaptic dampening on the parameters of the global model that have privacy infringing contributions from the forgetting client. Our technique does not require clients data or any kind of retraining and it does not put any computational overhead on either the client or server side. We perform experiments on multiple datasets and demonstrate that ConDa is effective to forget a client's data. In experiments conducted on the MNIST, CIFAR10, and CIFAR100 datasets, ConDa proves to be the fastest federated unlearning method, outperforming the nearest state of the art approach by at least 100x. Our emphasis is on the non-IID Federated Learning setting, which presents the greatest challenge for unlearning. Additionally, we validate ConDa's robustness through backdoor and membership inference attacks. We envision this work as a crucial component for FL in adhering to legal and ethical requirements.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Equitable Energy Access in Energy Communities</title>
<link>https://arxiv.org/abs/2410.04300</link>
<guid>https://arxiv.org/abs/2410.04300</guid>
<content:encoded><![CDATA[
<div> 关键词：能源社区、公平性、福利最大化、分散式实施、定价策略

总结:

本文探讨了在多元社会经济背景下的能源社区中实现公平能源接入的问题。文章关注点在于如何在确保整体福利最大化的前提下，同时考虑成员间公平性问题，这与目前优化能源消耗调度研究中较少涉及的公平性集成形成了鲜明对比。

首先，文章引入了“公平相关福利最大化”(EqWM)模型，这是一个旨在优化能源调度以最大化总体福利的框架，同时考虑到公平性约束条件。这一模型旨在平衡社区内不同成员的利益，确保每个人都能从能源使用中获益，而不仅仅是整体效益的最大化。

其次，为了实现EqWM模型的分散式实施，文章提出了“分散式公平最大化”(D-EqWM)概念。这是一种两层优化策略，其中非营利运营者设计了一种社区定价政策，以最大化整体福利，同时遵守确保公平接入的限制。社区成员根据这些价格优化他们的个人能源消费。

接着，文章详细阐述了最优定价政策及其关键特性。这包括了如何制定能够促进公平性、同时最大化整体福利的定价机制，以及这种机制如何在实际操作中运行。

最后，通过分析和讨论，文章为解决能源社区中的公平性挑战提供了一个理论框架和实践路径，即通过结合福利最大化和公平性原则来优化能源调度和定价策略，从而实现资源的更高效、更公平利用。 <div>
arXiv:2410.04300v1 Announce Type: new 
Abstract: We address the issue of equitable energy access within an energy community consisting of members with diverse socioeconomic backgrounds, including varying income levels and differing capacities to access distributed energy resources such as solar power and storage systems. While optimal energy consumption scheduling is well-studied, integrating equity into decentralized real-time energy access remains under-explored. This paper formulates Equity-regarding Welfare Maximization (EqWM)--a welfare optimization energy scheduling subject to equity constraints. We further develop a decentralized implementation (D-EqWM) as a bi-level optimization, where a non-profit operator designs a community pricing policy aimed at maximizing overall welfare, subject to constraints that ensure equitable access. Community members, in turn, optimize their individual consumption based on these prices. We present the optimal pricing policy along with its key properties.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CONFINE: Preserving Data Secrecy in Decentralized Process Mining</title>
<link>https://arxiv.org/abs/2410.04453</link>
<guid>https://arxiv.org/abs/2410.04453</guid>
<content:encoded><![CDATA[
<div> 关键词：过程矿工、跨组织协作、数据保密、可信执行环境、分布式架构

总结:
本文提出了一种名为CONFINE的系统，旨在解决跨组织过程事件数据的共享与分析过程中存在的数据保密问题。该系统通过采用分布式架构和运行在可信执行环境（TEE）中的受信任应用来确保数据的安全性和完整性。在跨组织合作中，通常会遇到对敏感数据暴露的担忧，这主要源于隐私和安全风险。CONFINE系统正是针对这些挑战而设计，其核心目标是在不泄露原始记录信息的前提下，实现多提供者间的流程挖掘。

CONFINE系统基于一个去中心化的结构，这意味着数据处理和分析在各个参与方的TEE中进行，减少了对外部和参与方的直接暴露，从而保护了敏感信息。通过这种方式，系统确保了在进行流程优化和协同工作的同时，数据的安全性和隐私得到了充分保障。

系统的主要组件和功能包括数据收集、数据加密、数据处理和分析、以及结果的解密和展示等，所有操作都在TEE环境下进行，以确保数据处理过程的安全性。此外，系统还详细描述了如何在保证数据安全的前提下，实现跨组织的合作与协调，为业务流程的改进提供了可能。 <div>
arXiv:2410.04453v1 Announce Type: new 
Abstract: In the contemporary business landscape, collaboration across multiple organizations offers a multitude of opportunities, including reduced operational costs, enhanced performance, and accelerated technological advancement. The application of process mining techniques in an inter-organizational setting, exploiting the recorded process event data, enables the coordination of joint effort and allows for a deeper understanding of the business. Nevertheless, considerable concerns pertaining to data confidentiality emerge, as organizations frequently demonstrate a reluctance to expose sensitive data demanded for process mining, due to concerns related to privacy and security risks. The presence of conflicting interests among the parties involved can impede the practice of open data sharing. To address these challenges, we propose our approach and toolset named CONFINE, which we developed with the intent of enabling process mining on process event data from multiple providers while preserving the confidentiality and integrity of the original records. To ensure that the presented interaction protocol steps are secure and that the processed information is hidden from both involved and external actors, our approach is based on a decentralized architecture and consists of trusted applications running in Trusted Execution Environments (TEE). In this demo paper, we provide an overview of the core components and functionalities as well as the specific details of its application.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models</title>
<link>https://arxiv.org/abs/2410.04810</link>
<guid>https://arxiv.org/abs/2410.04810</guid>
<content:encoded><![CDATA[
<div> 关键词：One-Shot Federated Learning（OSFL）、Latent Diffusion Models（LDM）、Federated Bi-Level Personalization（FedBiP）、Feature Space Heterogeneity、Client Data Scarcity

<br /><br />
总结:
文章主要讨论了针对One-Shot Federated Learning（OSFL）系统中遇到的数据异质性和数据量限制问题，提出了一种名为Federated Bi-Level Personalization（FedBiP）的方法。FedBiP旨在通过在实例级别和概念级别个性化预训练的Latent Diffusion Models（LDM），来合成遵循客户端本地数据分布的高质量图像。该方法不仅解决了特征空间异质性的问题，还应对了客户端数据稀缺的挑战。通过在三个具有特征空间异质性的OSFL基准上以及具有标签异质性的医疗和卫星图像数据集上的实验验证了FedBiP的有效性，结果显示其性能显著优于其他OSFL方法。FedBiP在解决OSFL系统中的数据异质性和数据量限制问题上提供了一种创新解决方案，对实际应用具有重要意义。 <div>
arXiv:2410.04810v1 Announce Type: new 
Abstract: One-Shot Federated Learning (OSFL), a special decentralized machine learning paradigm, has recently gained significant attention. OSFL requires only a single round of client data or model upload, which reduces communication costs and mitigates privacy threats compared to traditional FL. Despite these promising prospects, existing methods face challenges due to client data heterogeneity and limited data quantity when applied to real-world OSFL systems. Recently, Latent Diffusion Models (LDM) have shown remarkable advancements in synthesizing high-quality images through pretraining on large-scale datasets, thereby presenting a potential solution to overcome these issues. However, directly applying pretrained LDM to heterogeneous OSFL results in significant distribution shifts in synthetic data, leading to performance degradation in classification models trained on such data. This issue is particularly pronounced in rare domains, such as medical imaging, which are underrepresented in LDM's pretraining data. To address this challenge, we propose Federated Bi-Level Personalization (FedBiP), which personalizes the pretrained LDM at both instance-level and concept-level. Hereby, FedBiP synthesizes images following the client's local data distribution without compromising the privacy regulations. FedBiP is also the first approach to simultaneously address feature space heterogeneity and client data scarcity in OSFL. Our method is validated through extensive experiments on three OSFL benchmarks with feature space heterogeneity, as well as on challenging medical and satellite image datasets with label heterogeneity. The results demonstrate the effectiveness of FedBiP, which substantially outperforms other OSFL methods.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Block MedCare: Advancing healthcare through blockchain integration</title>
<link>https://arxiv.org/abs/2410.05251</link>
<guid>https://arxiv.org/abs/2410.05251</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、电子健康记录（EHR）、智能合约、数字签名、角色基于访问控制

总结:

本文深入探讨了区块链技术在医疗健康领域的应用，特别是在电子健康记录管理与数据共享方面的潜力。通过利用以太坊为基础的区块链技术和智能合约，研究团队提出了一种创新系统，旨在让患者安全存储和管理其医疗信息。该研究重点关注了实施区块链技术于医疗行业面临的挑战，如可扩展性、用户隐私保护和法规遵从性。

为解决这些挑战，提出了结合数字签名、角色基于访问控制以及多层次架构的安全解决方案。系统的关键功能，包括用户注册、数据追加和数据检索，通过智能合约得以实现，从而提供了一个既安全又高效的健康信息管理系统。为了验证这一方法的有效性，开发了一个去中心化应用（dApp），展示了基于区块链的医疗解决方案的实际应用。该dApp提供了面向患者、医生和管理员的用户界面，展示了如何简化医疗流程同时保持数据安全性和完整性。

此外，进行的一项调查揭示了医疗专业人士和IT专家对区块链采用的积极态度，同时也指出了整合成本和技术复杂性等潜在问题。研究结果强调了区块链技术在医疗健康领域应用的前景与挑战。 <div>
arXiv:2410.05251v1 Announce Type: new 
Abstract: In an era driven by information exchange, transparency and security hold crucial importance, particularly within the healthcare industry, where data integrity and confidentiality are paramount. This paper investigates the integration of blockchain technology in healthcare, focusing on its potential to revolutionize Electronic Health Records (EHR) management and data sharing. By leveraging Ethereum-based blockchain implementations and smart contracts, we propose a novel system that empowers patients to securely store and manage their medical data. Our research addresses critical challenges in implementing blockchain in healthcare, including scalability, user privacy, and regulatory compliance. We propose a solution that combines digital signatures, Role-Based Access Control, and a multi-layered architecture to enhance security and ensure controlled access. The system's key functions, including user registration, data append, and data retrieval, are facilitated through smart contracts, providing a secure and efficient mechanism for managing health information. To validate our approach, we developed a decentralized application (dApp) that demonstrates the practical implementation of our blockchain-based healthcare solution. The dApp incorporates user-friendly interfaces for patients, doctors, and administrators, showcasing the system's potential to streamline healthcare processes while maintaining data security and integrity. Additionally, we conducted a survey to gain insights into the perceived benefits and challenges of blockchain adoption in healthcare. The results indicate strong interest among healthcare professionals and IT experts, while also highlighting concerns about integration costs and technological complexity. Our findings...
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>pFedGame -- Decentralized Federated Learning using Game Theory in Dynamic Topology</title>
<link>https://arxiv.org/abs/2410.04058</link>
<guid>https://arxiv.org/abs/2410.04058</guid>
<content:encoded><![CDATA[
<div> 关键词：pFedGame、游戏理论、去中心化联邦学习、动态网络、模型中毒攻击

总结:

文章提出了一种基于游戏理论的新方法——pFedGame，用于解决去中心化联邦学习中的问题。该方法旨在避免中心化服务器的性能瓶颈、数据偏斜、模型收敛性差和模型中毒攻击风险，同时增强对集中式基础设施的信任。pFedGame通过两阶段过程工作：首先，参与者选择合适的协作伙伴；其次，执行两个玩家的常数和合作博弈，以达到收敛并应用最优的联邦学习聚合策略。实验结果显示，pFedGame在异构数据集上具有超过70%的准确率，与现有方法相比表现出色。

pFedGame的关键创新在于其去中心化的结构和引入游戏理论来优化协作过程。这种方法不仅能够提升模型训练效率，还能够确保在动态网络环境下稳定运行，为解决联邦学习面临的挑战提供了一个有前景的解决方案。 <div>
arXiv:2410.04058v1 Announce Type: cross 
Abstract: Conventional federated learning frameworks suffer from several challenges including performance bottlenecks at the central aggregation server, data bias, poor model convergence, and exposure to model poisoning attacks, and limited trust in the centralized infrastructure. In the current paper, a novel game theory-based approach called pFedGame is proposed for decentralized federated learning, best suitable for temporally dynamic networks. The proposed algorithm works without any centralized server for aggregation and incorporates the problem of vanishing gradients and poor convergence over temporally dynamic topology among federated learning participants. The solution comprises two sequential steps in every federated learning round, for every participant. First, it selects suitable peers for collaboration in federated learning. Secondly, it executes a two-player constant sum cooperative game to reach convergence by applying an optimal federated learning aggregation strategy. Experiments performed to assess the performance of pFedGame in comparison to existing methods in decentralized federated learning have shown promising results with accuracy higher than 70% for heterogeneous data.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing</title>
<link>https://arxiv.org/abs/2311.09592</link>
<guid>https://arxiv.org/abs/2311.09592</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式密钥生成、DLog基密码系统、抗适应性对手、随机信任组、扩展广播通道

<br /><br />
总结:
本文提出了一种针对DLog基密码系统的实用分布式密钥生成（DKG）协议。该协议通过使用共通硬币技术，实现了节点层面几乎线性的计算和通信成本，即使在面临最大数量的拜占庭节点时也是如此。此外，该协议具备对抗适应性对手的能力，可以抵御不超过全部节点一半的节点被恶意控制的情况。其创新之处在于将最耗资源的操作委托给一个随机选取的“随机信任组”，并结合了针对适应性安全性的多种技术。这个组由少量个体组成，群体仅信任其中至少有一个成员是诚实的，而无需知晓具体是哪位。文章还提供了一个通用转换器，使得传统的分布式协议能够在参与者具有不同权重的情况下高效部署。同时，引入了一种基于区块链和数据分散网络（如IPFS）的扩展广播通道，能够以常数大小的区块链存储成本可靠地广播任意大小的消息。 <div>
arXiv:2311.09592v4 Announce Type: replace 
Abstract: The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical large-scale deployments are still yet to come due to various challenges, including the heavy computation and communication (particularly broadcast) overhead in their adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to an Any-Trust group together with a set of techniques for adaptive security. This group is randomly sampled and consists of a small number of individuals. The population only trusts that at least one member in the group is honest, without knowing which one. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have different weights. Additionally, we introduce an extended broadcast channel based on a blockchain and data dispersal network (such as IPFS), enabling reliable broadcasting of arbitrary-size messages at the cost of constant-size blockchain storage.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Necessity of Collaboration for Online Model Selection with Decentralized Data</title>
<link>https://arxiv.org/abs/2404.09494</link>
<guid>https://arxiv.org/abs/2404.09494</guid>
<content:encoded><![CDATA[
<div> 关键词：在线模型选择、分散数据、合作必要性、计算约束、联邦学习

总结:
本文研究了在M个客户端上的在线模型选择问题，重点探讨了客户端间合作的必要性。通过引入计算约束这一新颖视角，文章提出了以下关键发现：

1. **无计算约束情况下的合作可有可无**：当客户端没有计算限制时，合作并不必要。这意味着，如果客户端能够轻松处理大量数据和计算任务，那么他们可以独立进行模型选择，无需与他人协作。

2. **有限计算成本下的合作必要性**：当每个客户端的计算成本限制在o(K)时（其中K为候选假设空间的数量），合作变得至关重要。这表明，当客户端资源有限时，共享信息和资源可以显著提高整体性能。

3. **澄清先前联邦算法的误解**：文章揭示了先前用于分布式在线多核学习的联邦算法中合作的不必要性，并通过改进的贝茨不等式、联邦在线镜像下降框架以及解耦模型选择与预测三个新技巧，提供了更优的性能边界。

4. **改进的性能边界**：通过上述方法，文章不仅澄清了合作的必要性，还提高了在较小计算和通信成本下的性能边界。

5. **独立贡献**：除了主要发现外，文章还提出了新的技术贡献，包括改进的贝茨不等式、联邦在线镜像下降框架以及解耦模型选择与预测的概念，这些可能对其他领域也具有独立价值。

综上所述，文章从计算约束的角度深入探讨了在线模型选择中的合作问题，通过理论分析和算法设计，为理解合作在不同资源条件下的作用提供了新的见解，并为后续研究提供了有价值的工具和技术。 <div>
arXiv:2404.09494v4 Announce Type: replace 
Abstract: We consider online model selection with decentralized data over $M$ clients, and study the necessity of collaboration among clients. Previous work proposed various federated algorithms without demonstrating their necessity,while we answer the question from a novel perspective of computational constraints. We prove lower bounds on the regret, and propose a federated algorithm and analyze the upper bound.Our results show (i) collaboration is unnecessary in the absence of computational constraints on clients; (ii) collaboration is necessary if the computational cost on each client is limited to $o(K)$, where $K$ is the number of candidate hypothesis spaces. We clarify the unnecessary nature of collaboration in previous federated algorithms for distributed online multi-kernel learning,and improve the regret bounds at a smaller computational and communication cost. Our algorithm relies on three new techniques including an improved Bernstein's inequality for martingale, a federated online mirror descent framework, and decoupling model selection and prediction, which might be of independent interest.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</title>
<link>https://arxiv.org/abs/2407.18074</link>
<guid>https://arxiv.org/abs/2407.18074</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、强化学习、代理理论、元算法、多智能体系统

总结:

本文探讨了AI在互联网未来生态中的角色，提出了通过结合强化学习与经济学中的代理理论来协调AI智能体之间互动的框架。强化学习提供了一种允许AI智能体进行自由干预的方法，但存在难以扩展到连续场景的问题；而代理理论则解决了个体利益与社会福利之间的冲突，但在大规模应用中遇到了挑战。通过将两者结合，本文提出了一种元算法框架，该框架允许智能体在马尔可夫决策过程中接受指导，通过一系列合同来规定基于智能体行动结果的支付方式。

元算法通过迭代优化智能体和引导者（即“主”）的策略，并证明其等价于引导者的Q函数上的收敛操作器，最终达到子博弈完美均衡状态。为了解决实际应用中的计算复杂性问题，作者进一步引入深度强化学习技术，并分析了在存在近似误差情况下的算法收敛性。针对多智能体系统，文章以组合硬币游戏为例，展示了如何应用上述方法解决更复杂的、具有社会困境特征的问题。这一研究为构建更加高效、协调的多智能体系统提供了理论基础和技术路径，预示着AI在社会协作领域的重要应用前景。 <div>
arXiv:2407.18074v2 Announce Type: replace 
Abstract: The increasing deployment of AI is shaping the future landscape of the internet, which is set to become an integrated ecosystem of AI agents. Orchestrating the interaction among AI agents necessitates decentralized, self-sustaining mechanisms that harmonize the tension between individual interests and social welfare. In this paper we tackle this challenge by synergizing reinforcement learning with principal-agent theory from economics. Taken separately, the former allows unrealistic freedom of intervention, while the latter struggles to scale in sequential settings. Combining them achieves the best of both worlds. We propose a framework where a principal guides an agent in a Markov Decision Process (MDP) using a series of contracts, which specify payments by the principal based on observable outcomes of the agent's actions. We present and analyze a meta-algorithm that iteratively optimizes the policies of the principal and agent, showing its equivalence to a contraction operator on the principal's Q-function, and its convergence to subgame-perfect equilibrium. We then scale our algorithm with deep Q-learning and analyze its convergence in the presence of approximation error, both theoretically and through experiments with randomly generated binary game-trees. Extending our framework to multiple agents, we apply our methodology to the combinatorial Coin Game. Addressing this multi-agent sequential social dilemma is a promising first step toward scaling our approach to more complex, real-world instances.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Robust Data-driven Predictive Control for Smoothing Mixed Traffic Flow</title>
<link>https://arxiv.org/abs/2401.15826</link>
<guid>https://arxiv.org/abs/2401.15826</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、预测控制、分散式、鲁棒优化、自动化车辆

<br />
<br />
总结:本文提出了一种名为“分散式鲁棒 DeeP-LCC”的方法，旨在通过分散式预测控制策略改善混合交通中自动驾驶车辆（CAV）与传统人工驾驶车辆（HDV）共存的交通性能。该方法的核心在于每个 CAV 基于本地可用数据独立计算控制输入，同时考虑到相邻子系统之间的交互作为扰动源，并提出相应的估计方法。为了确保系统的鲁棒性并减少计算负担，本文提出了一个鲁棒优化问题，并提供了可解的计算解决方案。与集中式设置相比，这种方法显著降低了计算复杂度，同时提高了安全性，并自然保护了数据隐私。通过广泛的交通模拟验证，该方法展现了其平滑交通流、安全性能以及计算效率的优势。 <div>
arXiv:2401.15826v2 Announce Type: replace-cross 
Abstract: In a mixed traffic with connected automated vehicles (CAVs) and human-driven vehicles (HDVs) coexisting, data-driven predictive control of CAVs promises system-wide traffic performance improvements. Yet, most existing approaches focus on a centralized setup, which is not computationally scalable while failing to protect data privacy. The robustness against unknown disturbances has not been well addressed either, causing safety concerns. In this paper, we propose a decentralized robust DeeP-LCC (Data-EnablEd Predictive Leading Cruise Control) approach for CAVs to smooth mixed traffic flow. In particular, each CAV computes its control input based on locally available data from its involved subsystem. Meanwhile, the interaction between neighboring subsystems is modeled as a bounded disturbance, for which appropriate estimation methods are proposed. Then, we formulate a robust optimization problem and present its tractable computational solutions. Compared with the centralized formulation, our method greatly reduces computation burden with better safety performance, while naturally preserving data privacy. Extensive traffic simulations validate its wave-dampening ability, safety performance, and computational benefits.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedCert: Federated Accuracy Certification</title>
<link>https://arxiv.org/abs/2410.03067</link>
<guid>https://arxiv.org/abs/2410.03067</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedCert、Robustness Evaluation、Certified Accuracy、Client Grouping Algorithm

<br /><br />
总结:

本文聚焦于Federated Learning（FL）领域的一个关键问题：如何评估模型在面对客户端数据扰动时的鲁棒性。在传统的集中式训练中，通过认证精度可以确保一定比例的预测即使在输入数据被扰动后也能保持正确。然而，这一评估方式难以直接应用于FL，因为FL模型的训练依赖于分散在不同客户端的数据，而这些数据的具体分布未知。

为解决这一挑战，研究团队提出了FedCert方法，这是评估FL系统鲁棒性的第一步。FedCert通过估计全局模型的认证精度，基于每个客户端的认证精度和类分布来实现这一目标。考虑到现实世界中数据非独立同分布（Non-IID）的特性，研究引入了客户端分组算法，以确保聚合步骤中的认证精度可靠性。

理论分析证明了FedCert的有效性，实验结果在CIFAR-10和CIFAR-100数据集下的多种场景下显示，FedCert能显著降低与基准方法相比的估计误差。这项工作为评估FL系统的鲁棒性和可靠性提供了解决方案，并为未来增强分散学习的可靠性铺平了道路。 <div>
arXiv:2410.03067v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for training machine learning models in a decentralized manner, preserving data privacy by keeping local data on clients. However, evaluating the robustness of these models against data perturbations on clients remains a significant challenge. Previous studies have assessed the effectiveness of models in centralized training based on certified accuracy, which guarantees that a certain percentage of the model's predictions will remain correct even if the input data is perturbed. However, the challenge of extending these evaluations to FL remains unresolved due to the unknown client's local data. To tackle this challenge, this study proposed a method named FedCert to take the first step toward evaluating the robustness of FL systems. The proposed method is designed to approximate the certified accuracy of a global model based on the certified accuracy and class distribution of each client. Additionally, considering the Non-Independent and Identically Distributed (Non-IID) nature of data in real-world scenarios, we introduce the client grouping algorithm to ensure reliable certified accuracy during the aggregation step of the approximation algorithm. Through theoretical analysis, we demonstrate the effectiveness of FedCert in assessing the robustness and reliability of FL systems. Moreover, experimental results on the CIFAR-10 and CIFAR-100 datasets under various scenarios show that FedCert consistently reduces the estimation error compared to baseline methods. This study offers a solution for evaluating the robustness of FL systems and lays the groundwork for future research to enhance the dependability of decentralized learning. The source code is available at https://github.com/thanhhff/FedCert/.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research Directions for Verifiable Crypto-Physically Secure TEEs</title>
<link>https://arxiv.org/abs/2410.03183</link>
<guid>https://arxiv.org/abs/2410.03183</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、Trusted Execution Environments（TEE）、物理不可复制函数（PUFs）、硬件安全、云计算信任问题

总结:

本文探讨了Web3领域如何利用硬件可信执行环境(TEE)构建去中心化基础设施的可能性，以及当前TEE存在的物理攻击风险和制造商信任问题。文章提出通过采用物理不可复制函数(Physical Unclonable Functions, PUFs)、计算保护的掩码和冗余技术、开源硬件以及验证芯片设计一致性的方法，来构建一种无需依赖云提供商和制造商信任的安全TEE架构。具体来说：

1. **物理不可复制函数（PUFs）**：用于确保TEE的安全基础，防止克隆和复制，提高TEE的物理安全性。
   
2. **计算保护的掩码和冗余技术**：用于保护TEE内的计算过程，增加数据处理的安全性，即使在面临攻击的情况下也能保持数据完整性和隐私。

3. **开源硬件**：提倡使用开源硬件方案，减少对特定制造商的依赖，增加透明度和可验证性，有助于构建更可信的TEE系统。

4. **验证芯片设计一致性**：通过先进的成像技术，确保芯片的设计与预期相符，进一步增强TEE系统的可信度和安全性。

5. **减少对云提供商和制造商的信任**：通过上述措施，旨在构建一种TEE系统，使得Web3应用程序能够直接信任硬件的安全性，而无需完全依赖于云服务提供商或制造商的信任。

综上所述，本文旨在激发Web3社区认识到现有硬件安全研究的价值，并探索通过结合PUFs、计算保护技术、开源硬件和验证方法，构建一个更加安全、自主可控的TEE体系，从而解决当前TEE面临的物理攻击和信任问题，为Web3应用提供更加可靠的基础设施支持。 <div>
arXiv:2410.03183v1 Announce Type: new 
Abstract: A niche corner of the Web3 world is increasingly making use of hardware-based Trusted Execution Environments (TEEs) to build decentralized infrastructure. One of the motivations to use TEEs is to go beyond the current performance limitations of cryptography-based alternatives such as zero-knowledge proofs (ZKP), fully homomorphic encryption (FHE), and multi-party computation (MPC). Despite their appealing advantages, current TEEs suffer from serious limitations as they are not secure against physical attacks, and their attestation mechanism is rooted in the chip manufacturer's trust. As a result, Web3 applications have to rely on cloud infrastruture to act as trusted guardians of hardware-based TEEs and have to accept to trust chip manufacturers. This work aims at exploring how we could potentially architect and implement chips that would be secure against physical attacks and would not require putting trust in chip manufacturers. One goal of this work is to motivate the Web3 movement to acknowledge and leverage the substantial amount of relevant hardware research that already exists. In brief, a combination of: (1) physical unclonable functions (PUFs) to secure the root-of-trust; (2) masking and redundancy techniques to secure computations; (3) open source hardware and imaging techniques to verify that a chip matches its expected design; can help move towards attesting that a given TEE can be trusted without the need to trust a cloud provider and a chip manufacturer.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BN-SCAFFOLD: controlling the drift of Batch Normalization statistics in Federated Learning</title>
<link>https://arxiv.org/abs/2410.03281</link>
<guid>https://arxiv.org/abs/2410.03281</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（FL）、Batch Normalization（BN）、FedTAN、SCAFFOLD、BN-SCAFFOLD

<br /><br />
总结:
文章主要探讨了在异构联邦学习(Federated Learning, FL)环境中，如何有效地利用批量归一化(Batch Normalization, BN)来训练深度神经网络(Depth Neural Networks, DNN)。文章首先指出，尽管联邦学习作为一种分散式机器学习范式正逐渐受到关注，但传统的批量归一化方法在异构环境中可能会降低模型性能。为此，作者提出了一种名为FedTAN的算法，旨在通过聚合所有客户端的批量归一化统计和梯度来减轻异构性的影响。然而，该算法存在较高的通信成本问题，其复杂度与DNN的深度成线性关系。

接着，文章引入了SCAFFOLD算法，这是一种能够以高效方式减少客户端漂移的偏差减少算法。虽然SCAFFOLD在异构联邦学习中显示出良好的潜力，但其在具有批量归一化的模型上表现不佳。为了解决这个问题，作者提出了BN-SCAFFOLD算法，它将SCAFFOLD的客户端漂移修正策略扩展到批量归一化统计。通过引入统一的理论框架，基于Wang等人2023年的工作，文章证明了BN-SCAFFOLD算法能够有效消除批量归一化引入的偏见，并通过实验验证了理论结果在MNIST和CIFAR-10数据集上的有效性。实验结果表明，BN-SCAFFOLD算法在性能上与FedTAN相当，但无需后者高昂的通信成本，同时优于传统的联邦平均(FedAvg)方法和其他旨在缓解批量归一化异构性的联邦学习算法。 <div>
arXiv:2410.03281v1 Announce Type: new 
Abstract: Federated Learning (FL) is gaining traction as a learning paradigm for training Machine Learning (ML) models in a decentralized way. Batch Normalization (BN) is ubiquitous in Deep Neural Networks (DNN), as it improves convergence and generalization. However, BN has been reported to hinder performance of DNNs in heterogeneous FL. Recently, the FedTAN algorithm has been proposed to mitigate the effect of heterogeneity on BN, by aggregating BN statistics and gradients from all the clients. However, it has a high communication cost, that increases linearly with the depth of the DNN. SCAFFOLD is a variance reduction algorithm, that estimates and corrects the client drift in a communication-efficient manner. Despite its promising results in heterogeneous FL settings, it has been reported to underperform for models with BN. In this work, we seek to revive SCAFFOLD, and more generally variance reduction, as an efficient way of training DNN with BN in heterogeneous FL. We introduce a unified theoretical framework for analyzing the convergence of variance reduction algorithms in the BN-DNN setting, inspired of by the work of Wang et al. 2023, and show that SCAFFOLD is unable to remove the bias introduced by BN. We thus propose the BN-SCAFFOLD algorithm, which extends the client drift correction of SCAFFOLD to BN statistics. We prove convergence using the aforementioned framework and validate the theoretical results with experiments on MNIST and CIFAR-10. BN-SCAFFOLD equals the performance of FedTAN, without its high communication cost, outperforming Federated Averaging (FedAvg), SCAFFOLD, and other FL algorithms designed to mitigate BN heterogeneity.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Practical Light Clients for Committee-Based Blockchains</title>
<link>https://arxiv.org/abs/2410.03347</link>
<guid>https://arxiv.org/abs/2410.03347</guid>
<content:encoded><![CDATA[
<div> 关键词：轻客户端、区块链、验证效率、通信成本、计算成本

总结:
本文通过实证研究发现，大部分用户并不经常处于离线状态超过一周，且在受权限控制的区块链以及Cosmos、Polkadot等无权限区块链中，验证节点变动的可能性较小。基于此，文章提出了一种新型的轻客户端系统，旨在优化现实情况下的需求，减少轻客户端的通信和计算成本。相较于现有文献中的两种先进轻客户端实现，该新系统在端到端延迟上降低了最高达90%，证明大小减少了最高达40000倍，且在某些情况下，证明大小甚至缩小了高达10000倍。这显著提高了轻客户端在实际应用中的效率和性能。 <div>
arXiv:2410.03347v1 Announce Type: new 
Abstract: Light clients are gaining increasing attention in the literature since they obviate the need for users to set up dedicated blockchain full nodes. While the literature features a number of light client instantiations, most light client protocols optimize for long offline phases and implicitly assume that the block headers to be verified are signed by highly dynamic validators.
  In this paper, we show that (i) most light clients are rarely offline for more than a week, and (ii) validators are unlikely to drastically change in most permissioned blockchains and in a number of permissionless blockchains, such as Cosmos and Polkadot. Motivated by these findings, we propose a novel practical system that optimizes for such realistic assumptions and achieves minimal communication and computational costs for light clients when compared to existing protocols. By means of a prototype implementation of our solution, we show that our protocol achieves a reduction by up to $90$ and $40000\times$ (respectively) in end-to-end latency and up to $1000$ and $10000\times$ (respectively) smaller proof size when compared to two state-of-the-art light client instantiations from the literature.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein Estimator</title>
<link>https://arxiv.org/abs/2410.03499</link>
<guid>https://arxiv.org/abs/2410.03499</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedStein、James-Stein Estimator、多域学习、数据非独立同分布

<br /><br />
总结:
文章介绍了针对多域联邦学习(Federated Learning)中数据来源不同、特征分布各异这一挑战的新方法——FedStein。FedStein通过使用詹姆斯-斯蒂恩(James-Stein)估计器来共享批量归一化(Batch Normalization, BN)统计量的估计值，同时保持本地BN参数不变，以此来提高多域联邦学习的性能和收敛性。该方法允许非BN层参数通过标准联邦学习技术进行交换，从而在多个数据集和模型上展现出显著优于现有方法（如FedAvg和FedBN）的准确性提升，特别是在特定领域的准确性提高了14%以上，增强了模型的泛化能力。此外，研究团队提供了实现FedStein方法的代码，以便其他研究者和开发者可以复现和扩展相关工作。 <div>
arXiv:2410.03499v1 Announce Type: new 
Abstract: Federated Learning (FL) facilitates data privacy by enabling collaborative in-situ training across decentralized clients. Despite its inherent advantages, FL faces significant challenges of performance and convergence when dealing with data that is not independently and identically distributed (non-i.i.d.). While previous research has primarily addressed the issue of skewed label distribution across clients, this study focuses on the less explored challenge of multi-domain FL, where client data originates from distinct domains with varying feature distributions. We introduce a novel method designed to address these challenges FedStein: Enhancing Multi-Domain Federated Learning Through the James-Stein Estimator. FedStein uniquely shares only the James-Stein (JS) estimates of batch normalization (BN) statistics across clients, while maintaining local BN parameters. The non-BN layer parameters are exchanged via standard FL techniques. Extensive experiments conducted across three datasets and multiple models demonstrate that FedStein surpasses existing methods such as FedAvg and FedBN, with accuracy improvements exceeding 14% in certain domains leading to enhanced domain generalization. The code is available at https://github.com/sunnyinAI/FedStein
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>What Matters for Model Merging at Scale?</title>
<link>https://arxiv.org/abs/2410.03617</link>
<guid>https://arxiv.org/abs/2410.03617</guid>
<content:encoded><![CDATA[
<div> 关键词：模型合并、大规模模型、综合性能提升、专家模型、分散式开发

<br /><br />总结:

本文主要探讨了模型合并技术在大规模模型中的应用与效果。首先，研究发现当合并的专家模型源自高质量的基础模型时，合并的效果更为显著，即零样本性能较好的基础模型有助于提高合并模型的整体性能。其次，较大的模型更容易进行有效合并，这意味着大模型在合并过程中表现出更好的适应性和融合性。第三，合并模型在泛化能力上普遍表现出优势，尤其是在合并多个大型专家模型时，合并后的模型往往在未见过的任务上表现得更好，相较于多任务训练的模型。第四，随着合并的专家模型数量增加，使用更大规模的模型可以更有效地进行合并，这揭示了在合并过程中的规模效应。最后，不同合并方法在大规模场景下的行为表现相似，说明选择何种合并策略对最终模型性能的影响在大型模型中可能不是决定性的。

通过这些发现，研究为未来在大规模模型合并领域的工作提供了有价值的参考点，对于促进高效、高质量模型的开发和利用具有重要意义。 <div>
arXiv:2410.03617v1 Announce Type: new 
Abstract: Model merging aims to combine multiple expert models into a more capable single model, offering benefits such as reduced storage and serving costs, improved generalization, and support for decentralized model development. Despite its promise, previous studies have primarily focused on merging a few small models. This leaves many unanswered questions about the effect of scaling model size and how it interplays with other key factors -- like the base model quality and number of expert models -- , to affect the merged model's performance. This work systematically evaluates the utility of model merging at scale, examining the impact of these different factors. We experiment with merging fully fine-tuned models using 4 popular merging methods -- Averaging, Task~Arithmetic, Dare, and TIES -- across model sizes ranging from 1B-64B parameters and merging up to 8 different expert models. We evaluate the merged models on both held-in tasks, i.e., the expert's training tasks, and zero-shot generalization to unseen held-out tasks. Our experiments provide several new insights about model merging at scale and the interplay between different factors. First, we find that merging is more effective when experts are created from strong base models, i.e., models with good zero-shot performance. Second, larger models facilitate easier merging. Third merging consistently improves generalization capabilities. Notably, when merging 8 large expert models, the merged models often generalize better compared to the multitask trained models. Fourth, we can better merge more expert models when working with larger models. Fifth, different merging methods behave very similarly at larger scales. Overall, our findings shed light on some interesting properties of model merging while also highlighting some limitations. We hope that this study will serve as a reference point on large-scale merging for upcoming research.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>TOB-SVD: Total-Order Broadcast with Single-Vote Decisions in the Sleepy Model</title>
<link>https://arxiv.org/abs/2310.11331</link>
<guid>https://arxiv.org/abs/2310.11331</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式共识、区块链、动态参与、总序广播、TOB-SVD

总结:
本文聚焦于大型、无许可系统中分布式共识研究的新方向，特别针对动态参与的挑战。对比传统的静态参与者模型，这类系统需要适应参与者数量和在线状态的频繁变化。比特币和“沉睡模型”等先驱工作为这一领域奠定了基础。

Momose和Ren（2022年CCS）的研究及后续工作引入了利用分级协议的总序广播机制，旨在支持动态参与度。然而，这些方法通常需要每个决策过程中的多轮投票，可能成为大规模实时系统的瓶颈。

针对这一问题，本文提出了一种新的总序广播协议——TOB-SVD，它在“沉睡模型”下工作，能够抵抗最多半数的敌对参与者。TOB-SVD的创新之处在于，它在最佳情况下只需一轮投票即可完成决策，同时实现与现有最优敌对方抗性方案相比更低的预期延迟。这项工作为在大型参与度波动的实时系统中实施更实用的总序广播协议铺平了道路。 <div>
arXiv:2310.11331v2 Announce Type: replace 
Abstract: Over the past years, distributed consensus research has extended its focus towards addressing challenges in large-scale, permissionless systems, such as blockchains. This shift is characterized by the need to accommodate dynamic participation, contrasting the traditional approach of a static set of continuously online participants. Works like Bitcoin and the sleepy model have set the stage for this evolving framework.
  Notable contributions from Momose and Ren (CCS 2022) and subsequent works have introduced Total-Order Broadcast protocols leveraging Graded Agreement primitives and supporting dynamic participation. However, these approaches often require multiple phases of voting per decision, creating a potential bottleneck for real-world large-scale systems.
  Addressing this, our paper introduces TOB-SVD, a novel Total-Order Broadcast protocol in the sleepy model, which is resilient to up to 1/2 of adversarial participants. TOB-SVD requires only a single phase of voting per decision in the best case and achieves lower expected latency compared to existing approaches offering the same optimal adversarial resilience. This work paves the way to more practical Total-Order Broadcast protocols to be implemented in real-world systems where a large number of participants are involved simultaneously and their participation level might fluctuate over time.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Insights and caveats from mining local and global temporal motifs in cryptocurrency transaction networks</title>
<link>https://arxiv.org/abs/2402.09272</link>
<guid>https://arxiv.org/abs/2402.09272</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式账本技术、交易数据、异常检测、反洗钱、时间网络

总结:
本文探讨了分布式账本技术（DLT）在加密货币如比特币和以太坊中产生的精细交易数据，为研究问题如异常检测、反洗钱、模式挖掘和活动聚类提供了可能。时间网络的框架为表示这些数据提供了一种自然的方式，并且提供了丰富的度量标准和模型。然而，大规模的数据对传统图分析技术构成了挑战。作者使用时间模式分析了两个比特币数据集和一个NFT数据集，利用了三个交易和最多三个用户序列。他们发现仅通过所有用户和所有时间的模式计数可能会导致误导性的结论。进一步的研究表明，每个用户的贡献模式分布呈重尾现象，关键参与者具有多样化的模式特征。通过对不同时间段发生的事件和异常活动进行分析，发现仅通过整个数据集的计数无法揭示的内容。此外，研究模式完成时间揭示了由人类行为和算法行为驱动的动力学。

文章详细阐述了如何使用时间模式分析大规模交易数据集，以及这种方法如何帮助识别异常行为和事件。研究结果不仅对理解加密货币市场的运作机制有重要意义，也为设计更有效的监控系统和策略提供了理论基础。通过对比特币和NFT数据集的应用，文章展示了时间网络方法在实际场景中的潜在应用价值。 <div>
arXiv:2402.09272v2 Announce Type: replace 
Abstract: Distributed ledger technologies have opened up a wealth of fine-grained transaction data from cryptocurrencies like Bitcoin and Ethereum. This allows research into problems like anomaly detection, anti-money laundering, pattern mining and activity clustering (where data from traditional currencies is rarely available). The formalism of temporal networks offers a natural way of representing this data and offers access to a wealth of metrics and models. However, the large scale of the data presents a challenge using standard graph analysis techniques. We use temporal motifs to analyse two Bitcoin datasets and one NFT dataset, using sequences of three transactions and up to three users. We show that the commonly used technique of simply counting temporal motifs over all users and all time can give misleading conclusions. Here we also study the motifs contributed by each user and discover that the motif distribution is heavy-tailed and that the key players have diverse motif signatures. We study the motifs that occur in different time periods and find events and anomalous activity that cannot be seen just by a count on the whole dataset. Studying motif completion time reveals dynamics driven by human behaviour as well as algorithmic behaviour.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dense Passage Retrieval: Is it Retrieving?</title>
<link>https://arxiv.org/abs/2402.11035</link>
<guid>https://arxiv.org/abs/2402.11035</guid>
<content:encoded><![CDATA[
<div> 关键词：Dense Passage Retrieval（DPR）、大型语言模型（LLM）、模型编辑、知识分散、知识不确定性

总结:
本文深入探讨了密集段落检索（Dense Passage Retrieval, DPR）在检索增强生成（RAG）范式中的作用及其对大型语言模型（LLM）性能提升的影响。研究者通过结合探针、层激活分析和模型编辑的方法，对经过DPR训练的模型进行了机制性探索。主要发现包括：

1. **知识分散**：DPR训练过程导致网络内部知识存储方式发生改变，使得相同信息可以通过多个途径访问，提高了检索效率。
   
2. **知识上限**：预训练模型内部的知识限制了检索模型的检索能力，表明了当前DPR训练风格的局限性。

3. **潜在改进方向**：
   - **更多知识暴露**：增加对DPR训练过程的知识输入，以促进更多知识的分散化。
   - **事实注入**：将具体事实作为分散表示注入到模型中，以丰富其检索能力。
   - **知识不确定性建模**：在检索过程中考虑知识的不确定性和不完整性，提高检索结果的可靠性。
   - **内部知识映射**：直接将模型内部的知识映射到知识库中，增强模型的可解释性和实用性。

这些发现为未来改进DPR和相关技术提供了理论基础和实践指导，旨在更全面地挖掘和利用模型内部的知识资源，进一步提升大规模语言模型的性能和应用潜力。 <div>
arXiv:2402.11035v3 Announce Type: replace 
Abstract: Dense passage retrieval (DPR) is the first step in the retrieval augmented generation (RAG) paradigm for improving the performance of large language models (LLM). DPR fine-tunes pre-trained networks to enhance the alignment of the embeddings between queries and relevant textual data. A deeper understanding of DPR fine-tuning will be required to fundamentally unlock the full potential of this approach. In this work, we explore DPR-trained models mechanistically by using a combination of probing, layer activation analysis, and model editing. Our experiments show that DPR training decentralizes how knowledge is stored in the network, creating multiple access pathways to the same information. We also uncover a limitation in this training style: the internal knowledge of the pre-trained model bounds what the retrieval model can retrieve. These findings suggest a few possible directions for dense retrieval: (1) expose the DPR training process to more knowledge so more can be decentralized, (2) inject facts as decentralized representations, (3) model and incorporate knowledge uncertainty in the retrieval process, and (4) directly map internal model knowledge to a knowledge base.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Experts to the Public: Governing Multimodal Language Models in Politically Sensitive Video Analysis</title>
<link>https://arxiv.org/abs/2410.01817</link>
<guid>https://arxiv.org/abs/2410.01817</guid>
<content:encoded><![CDATA[
<div> 关键词：大型多模态语言模型、集体决策、视频分析、民主治理、去中心化自治组织

总结:

本文探讨了通过个体与集体讨论来治理大型多模态语言模型（MM-LLMs）的方法，特别关注对政治敏感视频的分析。研究分为两步：首先，与10名记者进行访谈以建立专家对视频解读的基本理解；其次，114名普通公众通过Inclusive.AI平台参与讨论，该平台通过去中心化自治组织（DAO）机制促进民主决策。

研究发现，专家侧重于情感和叙事性，而公众更重视事实清晰度、情况客观性和情感中立性。此外，研究还探索了不同治理机制的影响，如二次投票与加权排名投票以及平等与20-80权力分配对用户决策的影响。结果显示，二次投票增强了对自由民主和平等政治的看法，而对AI持乐观态度的参与者认为投票过程具有更高的参与式民主水平。

本文建议将DAO机制应用于AI治理，以实现民主化，让AI的行为决策更加公正和透明。 <div>
arXiv:2410.01817v1 Announce Type: new 
Abstract: This paper examines the governance of multimodal large language models (MM-LLMs) through individual and collective deliberation, focusing on analyses of politically sensitive videos. We conducted a two-step study: first, interviews with 10 journalists established a baseline understanding of expert video interpretation; second, 114 individuals from the general public engaged in deliberation using Inclusive.AI, a platform that facilitates democratic decision-making through decentralized autonomous organization (DAO) mechanisms. Our findings show that while experts emphasized emotion and narrative, the general public prioritized factual clarity, objectivity of the situation, and emotional neutrality. Additionally, we explored the impact of different governance mechanisms: quadratic vs. weighted ranking voting and equal vs. 20-80 power distributions on users decision-making on how AI should behave. Specifically, quadratic voting enhanced perceptions of liberal democracy and political equality, and participants who were more optimistic about AI perceived the voting process to have a higher level of participatory democracy. Our results suggest the potential of applying DAO mechanisms to help democratize AI governance.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>NTK-DFL: Enhancing Decentralized Federated Learning in Heterogeneous Settings via Neural Tangent Kernel</title>
<link>https://arxiv.org/abs/2410.01922</link>
<guid>https://arxiv.org/abs/2410.01922</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式联邦学习、神经张量核（NTK）、模型平均、数据异质性、性能提升

总结:

本文探讨了分散式联邦学习(Distributed Federated Learning, DFL)领域的一个关键挑战——数据异质性。在没有中央服务器或原始数据交换的情况下，参与者合作训练模型。研究发现，传统的梯度下降方法在处理数据异质性方面存在局限性，而神经张量核(NTK)方法在集中式框架下的应用可以显著提高性能。

文章提出了一种利用NTK在分散式环境中训练客户端模型的新策略，并引入了NTK驱动的演化与模型平均之间的协同作用。这种协同作用通过利用模型间的差异来提升准确性和收敛速度，特别是在数据高度异质性的场景中。文中提出的方法在多个基准测试中显示出了明显的性能优势，尤其是在对比其他方法在高度异质性环境中的表现时，其准确性提升了至少10%，并且在达到目标性能所需通信轮数上减少了4.6倍。

此外，该方法的稳健性和普适性得到了多组数据集、网络拓扑结构和不同异质性设置的验证，确保了其在各种条件下的可靠性和广泛适用性。 <div>
arXiv:2410.01922v1 Announce Type: new 
Abstract: Decentralized federated learning (DFL) is a collaborative machine learning framework for training a model across participants without a central server or raw data exchange. DFL faces challenges due to statistical heterogeneity, as participants often possess different data distributions reflecting local environments and user behaviors. Recent work has shown that the neural tangent kernel (NTK) approach, when applied to federated learning in a centralized framework, can lead to improved performance. The NTK-based update mechanism is more expressive than typical gradient descent methods, enabling more efficient convergence and better handling of data heterogeneity. We propose an approach leveraging the NTK to train client models in the decentralized setting, while introducing a synergy between NTK-based evolution and model averaging. This synergy exploits inter-model variance and improves both accuracy and convergence in heterogeneous settings. Our model averaging technique significantly enhances performance, boosting accuracy by at least 10% compared to the mean local model accuracy. Empirical results demonstrate that our approach consistently achieves higher accuracy than baselines in highly heterogeneous settings, where other approaches often underperform. Additionally, it reaches target performance in 4.6 times fewer communication rounds. We validate our approach across multiple datasets, network topologies, and heterogeneity settings to ensure robustness and generalizability.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aerial-based Crisis Management Center (ACMC)</title>
<link>https://arxiv.org/abs/2410.01970</link>
<guid>https://arxiv.org/abs/2410.01970</guid>
<content:encoded><![CDATA[
<div> 关键词：危机管理、无人机系统、高性能计算资源、动态响应、分布式目标覆盖

总结:

本文研究了在应对关键基础设施危机、自然灾害、恐怖活动或社会动荡等情况下，高效通信和连接以及访问高性能计算资源对于及时动态响应的需求。文章提出了利用无人自主系统（UAS）提供空中危机管理中心（ACMC）的概念，以满足第一响应者所需的通信服务和计算资源。ACMC的服务被建模为深度神经网络（DNN）的物质传输方法，采用分散式方式覆盖分布的目标，这是一个具有时间变化通信权重的新颖分散式覆盖策略。通过分析证明了基于DNN的物质传输方法在团队UAS（如四旋翼无人机）中的稳定性和收敛性，每架无人机使用反馈非线性控制独立地达到预期的覆盖轨迹，从而实现分散式的操作。

无人机系统被动态组合以满足危机管理任务的通信和计算需求。这种架构能够检测、识别并传播大量异构动态事件，处理危机事件并开发实时响应，特别是在通讯和计算资源受限或严重受危机影响的情况下。文章所提出的方法为危机管理提供了创新的解决方案，通过利用无人机和深度学习技术，提高了危机响应的效率和灵活性。 <div>
arXiv:2410.01970v1 Announce Type: new 
Abstract: Crisis management (CM) for critical infrastructures, natural disasters such as wildfires and hurricanes, terrorist actions, or civil unrest requires high speed communications and connectivity, and access to high performance computational resources to deliver timely dynamic responses to the crisis being managed by different first responders. CM systems should detect, recognize, and disseminate huge amounts of heterogeneous dynamic events that operate at different speeds and formats. Furthermore, the processing of crisis events and the development of real-time responses are major research challenges when the communications and computational resources needed by CM stakeholders are not available or severely degraded by the crisis. The main goal of the research presented in this paper is to utilize Unmanned Autonomous Systems (UAS) to provide Aerial-based Crisis Management Center (ACMC) that will provide the required communications services and the computational resources that are critically needed by first responders. In our approach to develop an ACMC architecture, we utilize a set of flexible Unmanned Aerial Systems (UAS) that can be dynamically composed to meet the communications and computational requirements of CM tasks. The ACMC services will be modeled as a deep neural network (DNN) mass transport approach to cover a distributed target in a decentralized manner. This is indeed a new decentralized coverage approach with time-varying communication weights. Furthermore, our analysis proves the stability and convergence of the proposed DNN-based mass transport for a team of UAS (e.g., quadcopters), where each quadcopter uses a feedback nonlinear control to independently attain the intended coverage trajectory in a decentralized manner.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Addressing Data Heterogeneity in Federated Learning with Adaptive Normalization-Free Feature Recalibration</title>
<link>https://arxiv.org/abs/2410.02006</link>
<guid>https://arxiv.org/abs/2410.02006</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、统计异质性、自适应归一化、特征重校准、通道注意力

总结:

本文提出了一种名为Adaptive Normalization-free Feature Recalibration (ANFR) 的方法，以解决联邦学习中因客户端数据统计差异导致的系统性能下降问题。ANFR结合了权重标准化和通道注意力两种技术，旨在提升模型在不同条件下的性能。

- **权重标准化**：相较于激活标准化，权重标准化在层级别对权重进行归一化处理，这使得模型更加鲁棒，能更好地应对统计异质性带来的挑战。
- **通道注意力**：该技术生成可学习的特征图缩放因子，通过抑制因统计差异而产生的不一致特征，进一步优化模型性能。
- **独立于聚合方法**：ANFR在全局和个性化联邦学习场景下均有效，且在保持计算开销较低的情况下实现了性能提升。
- **隐私与性能的平衡**：在差分隐私训练中，ANFR能够提供强大的隐私保护同时保持高效率，实现性能与隐私的双赢。
- **跨领域应用**：实验结果显示，ANFR在多种聚合方法、数据集和异质性条件下，均能超越现有基准，表现出色。

综上所述，ANFR为应对联邦学习中的统计异质性挑战提供了一个新颖且灵活的解决方案，通过创新地结合权重标准化与通道注意力机制，显著提升了模型的泛化能力和性能表现。 <div>
arXiv:2410.02006v1 Announce Type: new 
Abstract: Federated learning is a decentralized collaborative training paradigm that preserves stakeholders' data ownership while improving performance and generalization. However, statistical heterogeneity among client datasets poses a fundamental challenge by degrading system performance. To address this issue, we propose Adaptive Normalization-free Feature Recalibration (ANFR), an architecture-level approach that combines weight standardization and channel attention. Weight standardization normalizes the weights of layers instead of activations. This is less susceptible to mismatched client statistics and inconsistent averaging, thereby more robust under heterogeneity. Channel attention produces learnable scaling factors for feature maps, suppressing those that are inconsistent between clients due to heterogeneity. We demonstrate that combining these techniques boosts model performance beyond their individual contributions, by enhancing class selectivity and optimizing channel attention weight distribution. ANFR operates independently of the aggregation method and is effective in both global and personalized federated learning settings, with minimal computational overhead. Furthermore, when training with differential privacy, ANFR achieves an appealing balance between privacy and utility, enabling strong privacy guarantees without sacrificing performance. By integrating weight standardization and channel attention in the backbone model, ANFR offers a novel and versatile approach to the challenge of statistical heterogeneity. We demonstrate through extensive experiments that ANFR consistently outperforms established baselines across various aggregation methods, datasets, and heterogeneity conditions.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>XChainWatcher: Monitoring and Identifying Attacks in Cross-Chain Bridges</title>
<link>https://arxiv.org/abs/2410.02029</link>
<guid>https://arxiv.org/abs/2410.02029</guid>
<content:encoded><![CDATA[
<div> 关键词：XChainWatcher、跨链桥、漏洞、Ronin桥、Nomad桥

<br /><br />
总结:

文章主要介绍了XChainWatcher，这是一种全新的跨链桥监控机制，旨在检测和预防跨链桥可能遭受的攻击。通过使用Datalog引擎驱动的跨链模型，XChainWatcher能够被轻松集成到任何跨链桥中。该系统通过对Ronin和Nomad桥的数据分析，成功识别出了导致6.11亿美元和1.9亿美元损失的交易。

XChainWatcher不仅能够发现成功的攻击行为，还揭示了未被注意的行为模式，如不应接受的37次跨链交易（cctx），对Nomad的未成功的攻击尝试，锁定在一条链上的超过780万美元但未能在以太坊上释放的资金，以及因与桥接交互不足而导致的20万美元损失。文章还提供了关于Nomad和Ronin桥上总计58.5亿美元和370亿美元代币转移的第一份开源数据集。

总的来说，XChainWatcher为跨链桥的安全性提供了一个重要的工具，通过检测潜在的攻击和异常行为，帮助保护区块链网络免受经济损失和安全威胁。 <div>
arXiv:2410.02029v1 Announce Type: new 
Abstract: Cross-chain bridges are widely used blockchain interoperability mechanisms. However, several of these bridges have vulnerabilities that have caused 3.2 billion dollars in losses since May 2021. Some studies have revealed the existence of these vulnerabilities, but little quantitative research is available, and there are no safeguard mechanisms to protect bridges from such attacks. We propose XChainWatcher, the first mechanism for monitoring bridges and detecting attacks against them. XChainWatcher relies on a cross-chain model powered by a Datalog engine, designed to be pluggable into any cross-chain bridge. Analyzing data from the Ronin and Nomad bridges, we successfully identified the transactions that led to losses of \$611M and \$190M USD, respectively. XChainWatcher not only uncovers successful attacks but also reveals unintended behavior, such as 37 cross-chain transactions (cctx) that these bridges should not have accepted, failed attempts to exploit Nomad, over \$7.8M locked on one chain but never released on Ethereum, and \$200K lost due to inadequate interaction with bridges. We provide the first open-source dataset of 81,000 cctxs across three blockchains, capturing \$585M and \$3.7B in token transfers in Nomad and Ronin, respectively.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>RiskSEA : A Scalable Graph Embedding for Detecting On-chain Fraudulent Activities on the Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2410.02160</link>
<guid>https://arxiv.org/abs/2410.02160</guid>
<content:encoded><![CDATA[
<div> 关键词：风险评分系统、区块链、节点2vec嵌入、动态性、交易行为特征

<br /><br />
总结:
本文提出了RiskSEA，一种旨在快速高效地识别与欺诈活动相关的加密货币地址的风险评分系统。该系统针对以太坊区块链进行了实施，其核心包括三个关键组件：一种用于整个地址集的可扩展节点2vec嵌入生成方法，以捕捉图结构；基于交易的特征，以捕获地址的交易行为模式；以及结合节点2vec嵌入和行为特征的分类模型来生成风险分数。为了应对大规模动态变化的区块链交易图的挑战，作者还引入了两种创新的节点2vec嵌入生成方法：节点2vec嵌入传播和动态节点2vec嵌入。通过实验证明，将行为特征与节点2vec嵌入相结合能够显著提升分类性能，而动态节点2vec嵌入在实验中表现出了优于传播嵌入的性能。 <div>
arXiv:2410.02160v1 Announce Type: new 
Abstract: Like any other useful technology, cryptocurrencies are sometimes used for criminal activities. While transactions are recorded on the blockchain, there exists a need for a more rapid and scalable method to detect addresses associated with fraudulent activities. We present RiskSEA, a scalable risk scoring system capable of effectively handling the dynamic nature of large-scale blockchain transaction graphs. The risk scoring system, which we implement for Ethereum, consists of 1. a scalable approach to generating node2vec embedding for entire set of addresses to capture the graph topology 2. transaction-based features to capture the transactional behavioral pattern of an address 3. a classifier model to generate risk score for addresses that combines the node2vec embedding and behavioral features. Efficiently generating node2vec embedding for large scale and dynamically evolving blockchain transaction graphs is challenging, we present two novel approaches for generating node2vec embeddings and effectively scaling it to the entire set of blockchain addresses: 1. node2vec embedding propagation and 2. dynamic node2vec embedding. We present a comprehensive analysis of the proposed approaches. Our experiments show that combining both behavioral and node2vec features boosts the classification performance significantly, and that the dynamic node2vec embeddings perform better than the node2vec propagated embeddings.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Point-of-Interest Recommendation: Models, Architectures, and Security</title>
<link>https://arxiv.org/abs/2410.02191</link>
<guid>https://arxiv.org/abs/2410.02191</guid>
<content:encoded><![CDATA[
<div> 关键词：智能手机、位置基社交网络、点兴趣推荐系统、新兴架构、安全考虑

总结:
本文是一篇关于点兴趣推荐系统的新颖性综述，旨在填补现有文献在深入探索现代方法、架构发展及安全考量方面的空白。文章围绕三个关键领域进行了详细阐述：第一，模型的演进，从传统的推荐算法过渡到先进的大型语言模型，揭示了技术进步如何推动个性化体验的提升；第二，架构的变革，从集中的服务器部署转向分散式和联邦学习架构，以增强系统的可扩展性和保护用户隐私；第三，安全与隐私的挑战，分析了当前推荐系统可能遭遇的安全漏洞，并探讨了保障用户数据安全的策略。

文章通过构建全面的分类体系，不仅回顾了点兴趣推荐系统的最新进展，还前瞻性地指出了未来研究的潜在方向，为该领域的学术研究和技术创新提供了宝贵的参考。这一研究对于促进智能设备和社交网络中更加精准、安全和个性化的服务具有重要意义。 <div>
arXiv:2410.02191v1 Announce Type: new 
Abstract: The widespread adoption of smartphones and Location-Based Social Networks has led to a massive influx of spatio-temporal data, creating unparalleled opportunities for enhancing Point-of-Interest (POI) recommendation systems. These advanced POI systems are crucial for enriching user experiences, enabling personalized interactions, and optimizing decision-making processes in the digital landscape. However, existing surveys tend to focus on traditional approaches and few of them delve into cutting-edge developments, emerging architectures, as well as security considerations in POI recommendations. To address this gap, our survey stands out by offering a comprehensive, up-to-date review of POI recommendation systems, covering advancements in models, architectures, and security aspects. We systematically examine the transition from traditional models to advanced techniques such as large language models. Additionally, we explore the architectural evolution from centralized to decentralized and federated learning systems, highlighting the improvements in scalability and privacy. Furthermore, we address the increasing importance of security, examining potential vulnerabilities and privacy-preserving approaches. Our taxonomy provides a structured overview of the current state of POI recommendation, while we also identify promising directions for future research in this rapidly advancing field.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Decentralized Learning</title>
<link>https://arxiv.org/abs/2410.02541</link>
<guid>https://arxiv.org/abs/2410.02541</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、特征异质性、模型公平性、集群化、Facade算法

<br /><br />
总结:

本文探讨了在存在特征异质性的数据集中实现公平机器学习模型训练的问题。通过引入一种名为Facade的创新集群化分布式学习算法，研究者解决了如何在无需节点预先知道所属集群的情况下，动态地将节点分配到与它们本地数据特征相似的集群中。Facade算法允许节点在完全去中心化的环境中为每个集群协作训练专门的模型，从而提高了模型的准确性和公平性。

理论分析证明了Facade算法的收敛性，实验证明了其在三个数据集上的性能优于三种最先进的基线方法。特别是在CIFAR-10数据集上，Facade算法在集群大小不平衡的情况下，不仅显著提高了模型准确性，还减少了通信成本达32.3%，充分体现了其在处理特征异质性数据集中的高效性和实用性。

<br /><br /> <div>
arXiv:2410.02541v1 Announce Type: new 
Abstract: Decentralized learning (DL) is an emerging approach that enables nodes to collaboratively train a machine learning model without sharing raw data. In many application domains, such as healthcare, this approach faces challenges due to the high level of heterogeneity in the training data's feature space. Such feature heterogeneity lowers model utility and negatively impacts fairness, particularly for nodes with under-represented training data. In this paper, we introduce \textsc{Facade}, a clustering-based DL algorithm specifically designed for fair model training when the training data exhibits several distinct features. The challenge of \textsc{Facade} is to assign nodes to clusters, one for each feature, based on the similarity in the features of their local data, without requiring individual nodes to know apriori which cluster they belong to. \textsc{Facade} (1) dynamically assigns nodes to their appropriate clusters over time, and (2) enables nodes to collaboratively train a specialized model for each cluster in a fully decentralized manner. We theoretically prove the convergence of \textsc{Facade}, implement our algorithm, and compare it against three state-of-the-art baselines. Our experimental results on three datasets demonstrate the superiority of our approach in terms of model accuracy and fairness compared to all three competitors. Compared to the best-performing baseline, \textsc{Facade} on the CIFAR-10 dataset also reduces communication costs by 32.3\% to reach a target accuracy when cluster sizes are imbalanced.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploiting Structure in Offline Multi-Agent RL: The Benefits of Low Interaction Rank</title>
<link>https://arxiv.org/abs/2410.01101</link>
<guid>https://arxiv.org/abs/2410.01101</guid>
<content:encoded><![CDATA[
<div> 关键词：离线多智能体强化学习、低交互秩、结构假设、函数类、分布偏移

总结:
本文研究了在离线多智能体强化学习（MARL）环境下学习近似均衡的问题。引入了“交互秩”这一结构性假设，指出具有较低交互秩的函数在面对分布偏移时更为稳健，相较于一般函数。利用这一观察结果，文章展示了通过结合低交互秩的函数类、正则化和无后悔学习策略，可以在离线MARL中实现去中心化的、计算上和统计上高效的算法设计。理论分析与实验验证相结合，展示了具有低交互秩的批评架构在离线MARL中的潜力，与常用的单智能体价值分解架构形成鲜明对比。实验结果进一步证实了低交互秩函数类在解决复杂多智能体任务时的优势。 <div>
arXiv:2410.01101v1 Announce Type: new 
Abstract: We study the problem of learning an approximate equilibrium in the offline multi-agent reinforcement learning (MARL) setting. We introduce a structural assumption -- the interaction rank -- and establish that functions with low interaction rank are significantly more robust to distribution shift compared to general ones. Leveraging this observation, we demonstrate that utilizing function classes with low interaction rank, when combined with regularization and no-regret learning, admits decentralized, computationally and statistically efficient learning in offline MARL. Our theoretical results are complemented by experiments that showcase the potential of critic architectures with low interaction rank in offline MARL, contrasting with commonly used single-agent value decomposition architectures.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Count of Monte Crypto: Accounting-based Defenses for Cross-Chain Bridges</title>
<link>https://arxiv.org/abs/2410.01107</link>
<guid>https://arxiv.org/abs/2410.01107</guid>
<content:encoded><![CDATA[
<div> 关键词：加密资产、桥梁服务、跨链交易、价值会计、安全审计

总结:

本文研究了2021年至2023年间，超过26亿美元的加密资产因“桥梁”攻击而被盗的情况。这些攻击的核心问题在于，缺乏跨链交易中的端到端价值会计机制。通过分析关键桥梁在这段时间内的二十万笔交易，作者发现了一个简单但有效的不变量——平衡跨链流入和流出的价值——既符合合法使用需求，又能准确识别已知的攻击事件（以及可能的攻击）。此外，该方法不仅适用于事后审计，还能集成到现有桥梁设计中，为防止多种桥梁漏洞提供通用保护。这种方法不仅能够追溯和识别攻击，还能在实际操作中预防未来的安全风险。 <div>
arXiv:2410.01107v1 Announce Type: new 
Abstract: Between 2021 and 2023, crypto assets valued at over \$US2.6 billion were stolen via attacks on "bridges" -- decentralized services designed to allow inter-blockchain exchange. While the individual exploits in each attack vary, a single design flaw underlies them all: the lack of end-to-end value accounting in cross-chain transactions. In this paper, we empirically analyze twenty million transactions used by key bridges during this period. We show that a simple invariant that balances cross-chain inflows and outflows is compatible with legitimate use, yet precisely identifies every known attack (and several likely attacks) in this data. Further, we show that this approach is not only sufficient for post-hoc audits, but can be implemented in-line in existing bridge designs to provide generic protection against a broad array of bridge vulnerabilities.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Expectation Propagation for Semi-Blind Channel Estimation in Cell-Free Networks</title>
<link>https://arxiv.org/abs/2410.01303</link>
<guid>https://arxiv.org/abs/2410.01303</guid>
<content:encoded><![CDATA[
<div> 关键词：cell-free、MA-MIMO、Semi-blind、Expectation Propagation、Central Limit Theorem

<br /><br />
总结:
本文探讨了在无基站(Cell-Free)大规模多输入多输出(MaMIMO)系统中上行通信的问题。通过使用半盲传输结构，旨在减轻试点污染现象。研究提出了一种基于期望传播(EP)的简化、去中心化方法进行半盲信道估计。利用正交试点预处理接收信号，从而建立了一个简化等效因子分解方案来优化传输过程。进一步地，该研究将中心极限定理与EP相结合，避免在因子分解方案中引入额外辅助变量。通过评估涉及的变量尺度，对算法进行了改进。最后，提出了一个去中心化的解决方案，显著降低了中央处理器(CPU)的计算需求。此工作为无基站MA-MIMO系统的高效上行通信提供了一种创新性的解决方案，通过简化信道估计和优化传输过程，提高了系统性能和资源利用率。 <div>
arXiv:2410.01303v1 Announce Type: new 
Abstract: This paper serves as a correction to the conference version. In this work, we explore uplink communication in cell-free (CF) massive multiple-input multiple-output (MaMIMO) systems, employing semi-blind transmission structures to mitigate pilot contamination. We propose a simplified, decentralized method based on Expectation Propagation (EP) for semi-blind channel estimation. By utilizing orthogonal pilots, we preprocess the received signals to establish a simplified equivalent factorization scheme for the transmission process. Moreover, this study integrates Central Limit Theory (CLT) with EP, eliminating the need to introduce new auxiliary variables in the factorization scheme. We also refine the algorithm by assessing the variable scales involved. Finally, a decentralized approach is proposed to significantly reduce the computational demands on the Central Processing Unit (CPU).
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Overpredictive Signal Analytics in Federated Learning: Algorithms and Analysis</title>
<link>https://arxiv.org/abs/2410.01399</link>
<guid>https://arxiv.org/abs/2410.01399</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘信号处理、分布式学习、联邦学习、信号近似、通信成本

<br /><br />
总结:
本文探讨了边缘信号处理在客户端-服务器模型中的应用，该模型是联邦学习的基础。在传统的机器学习框架中，收集原始信号样本的物联网设备（客户端）能够通过在第三方位置汇总这些分布式样本，协助数据中心（服务器）学习全局信号模型。然而，物联网部署面临着敏感隐私数据保护和通信速率限制的挑战。因此，本文提出了一种新的方法——分布式信号分析，通过在客户端计算信号的近似值而非原始信号来进行分散式学习。

文中提出了利用高效凸优化框架计算客户端设备上的过预测信号近似值的算法。通过数学分析，量化了通信成本、采样率与信号近似误差之间的权衡关系。此外，还展示了所提出分布式算法在公共住宅能源消耗数据集上的性能表现。

此研究为在通信受限和隐私保护环境下，利用边缘计算进行大规模分布式信号处理提供了一种可行的解决方案，对于网络需求规划等应用具有重要意义。 <div>
arXiv:2410.01399v1 Announce Type: cross 
Abstract: Edge signal processing facilitates distributed learning and inference in the client-server model proposed in federated learning. In traditional machine learning, clients (IoT devices) that acquire raw signal samples can aid a data center (server) learn a global signal model by pooling these distributed samples at a third-party location. Despite the promising capabilities of IoTs, these distributed deployments often face the challenge of sensitive private data and communication rate constraints. This necessitates a learning approach that communicates a processed approximation of the distributed samples instead of the raw signals. Such a decentralized learning approach using signal approximations will be termed distributed signal analytics in this work. Overpredictive signal approximations may be desired for distributed signal analytics, especially in network demand (capacity) planning applications motivated by federated learning. In this work, we propose algorithms that compute an overpredictive signal approximation at the client devices using an efficient convex optimization framework. Tradeoffs between communication cost, sampling rate, and the signal approximation error are quantified using mathematical analysis. We also show the performance of the proposed distributed algorithms on a publicly available residential energy consumption dataset.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Scaling LT-Coded Blockchains in Heterogeneous Networks and their Vulnerabilities to DoS Threats</title>
<link>https://arxiv.org/abs/2402.05620</link>
<guid>https://arxiv.org/abs/2402.05620</guid>
<content:encoded><![CDATA[
<div> 关键词：存储成本、区块链、Luby Transform（LT）编码、分布式网络、安全漏洞

总结:

本文研究了编码区块链技术在降低存储成本和促进可扩展性方面的重要性。文章首先指出传统的Luby Transform（LT）解码器如信念传播和在线飞行高斯消元法可能不适合具有不同计算和下载能力的异构网络。为了解决这个问题，作者提出了一种混合解码器家族，并为它们制定了最优操作模式以在最低解码成本下恢复区块链。

接着，文章指出了编码区块链架构在存储节省和可扩展性方面的研究，但对安全性漏洞了解不足的问题。作者提出了针对具有特定解码能力节点的新颖拒绝服务攻击，这些攻击旨在阻止节点加入网络。所提出的攻击是非盲目的，攻击者可以访问存档块并基于编码方案选择要执行攻击的部分块集。文章显示，优化的攻击能够与盲攻击达到相同的破坏水平，但所需的资源却有限。

最后，本文为设计同时提供存储节省、可扩展性和对抗优化威胁的编码区块链开辟了新的研究方向。 <div>
arXiv:2402.05620v2 Announce Type: replace 
Abstract: Coded blockchains have acquired prominence as a promising solution to reduce storage costs and facilitate scalability. Within this class, Luby Transform (LT) coded blockchains are an appealing choice for scalability owing to the availability of a wide range of low-complexity decoders. In the first part of this work, we identify that traditional LT decoders like Belief Propagation and On-the-Fly Gaussian Elimination may not be optimal for heterogeneous networks with nodes that have varying computational and download capabilities. To address this, we introduce a family of hybrid decoders for LT codes and propose optimal operating regimes for them to recover the blockchain at the lowest decoding cost. While LT coded blockchain architecture has been studied from the aspects of storage savings and scalability, not much is known in terms of its security vulnerabilities. Pointing at this research gap, in the second part, we present novel denial-of-service threats on LT coded blockchains that target nodes with specific decoding capabilities, preventing them from joining the network. Our proposed threats are non-oblivious in nature, wherein adversaries gain access to the archived blocks, and choose to execute their attack on a subset of them based on underlying coding scheme. We show that our optimized threats can achieve the same level of damage as that of blind attacks, however, with limited amount of resources. Overall, this is the first work of its kind that opens up new questions on designing coded blockchains to jointly provide storage savings, scalability and also resilience to optimized threats.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Web3 and the State: Indian state's redescription of blockchain</title>
<link>https://arxiv.org/abs/2405.00320</link>
<guid>https://arxiv.org/abs/2405.00320</guid>
<content:encoded><![CDATA[
<div> 关键词：文章、讨论、策略、印度国家转型机构、电子与信息技术部

<br /><br />
总结:

本文详细分析了印度国家转型机构(NITI Aayog)的一份讨论文件和电子与信息技术部(MeitY)的一份策略文件，这两份文件都强调了区块链技术在印度的非金融应用案例。研究发现，从文件中的语言表述可以看出，印度政府对区块链的理解经历了从强调透明度到信任，再到可调整的透明性的转变。这一转变不仅反映出区块链技术被定义为“去中心化”，但实际上却有强化中央控制的趋势，即政府重新定位自己作为中介角色。文中还指出，关于信任、透明度、(去)中心化和(去)中介化的论述是理解新兴社会技术系统再描述的关键领域。

通过这些讨论，文章揭示了政府在区块链政策制定过程中的角色转变和战略调整，以及这些调整如何影响技术的实施和应用。此外，它还强调了政府如何在理论上推崇技术的去中心化特性，但在实践中却倾向于强化其自身的作用，这涉及到对区块链技术潜在功能的复杂再解释。整体而言，该文旨在探讨技术政策制定中话语的力量及其对技术发展和应用的影响。 <div>
arXiv:2405.00320v2 Announce Type: replace 
Abstract: The article closely reads a discussion paper by the National Institution for Transforming India (NITI) Aayog and a strategy paper by the Ministry of Electronics and Information Technology (MeitY) advocating non-financial use cases of blockchain in India. By noting the discursive shift from transparency to trust to adjustably transparent enacted in these two documents, and consequently the Indian state's redescription of blockchain, the paper foregrounds how blockchain systems are being designated as "decentral" but have recentralizing effects where the state reinvents and re-establishes itself as an intermediary. The paper illustrates how discursive shifts concerning trust, transparency, (de)centralization and (dis)intermediation are crucial sites for investigating redescriptions of emerging sociotechnical systems.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Optimization in Time-Varying Networks with Arbitrary Delays</title>
<link>https://arxiv.org/abs/2405.19513</link>
<guid>https://arxiv.org/abs/2405.19513</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式优化、通信延迟、虚拟节点、共识算法、时间变异性

总结:

本文探讨了受通信延迟影响的网络中的分散式优化问题。通过引入虚拟非计算节点，构建了具有方向性的图结构，以此来模拟通信延迟。现有的解决方案往往假设节点已知其出度数，这限制了其应用范围。为克服这一局限性，本文提出了一种新颖的基于问候的算法——DT-GO，该算法无需知晓出度数即可应用于一般的方向性网络，如具有延迟或有限确认能力的网络。

对于凸性和非凸性目标函数，本文推导了收敛率，表明该算法在复杂度上与集中式随机梯度下降法具有相同的阶数。换句话说，图拓扑和延迟的影响仅体现在高阶项中。此外，分析还考虑了网络拓扑随时间变化的情况。为了支持理论发现，提供了数值仿真结果。 <div>
arXiv:2405.19513v2 Announce Type: replace 
Abstract: We consider a decentralized optimization problem for networks affected by communication delays. Examples of such networks include collaborative machine learning, sensor networks, and multi-agent systems. To mimic communication delays, we add virtual non-computing nodes to the network, resulting in directed graphs. This motivates investigating decentralized optimization solutions on directed graphs. Existing solutions assume nodes know their out-degrees, resulting in limited applicability. To overcome this limitation, we introduce a novel gossip-based algorithm, called DT-GO, that does not need to know the out-degrees. The algorithm is applicable in general directed networks, for example networks with delays or limited acknowledgment capabilities. We derive convergence rates for both convex and non-convex objectives, showing that our algorithm achieves the same complexity order as centralized Stochastic Gradient Descent. In other words, the effects of the graph topology and delays are confined to higher-order terms. Additionally, we extend our analysis to accommodate time-varying network topologies. Numerical simulations are provided to support our theoretical findings.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prediction and Detection of Terminal Diseases Using Internet of Medical Things: A Review</title>
<link>https://arxiv.org/abs/2410.00034</link>
<guid>https://arxiv.org/abs/2410.00034</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、物联网、医疗健康、机器学习、深度学习

总结:

本文探讨了人工智能（AI）与互联网医疗事物（IoMT）在医疗健康领域的应用，特别是通过机器学习（ML）和深度学习（DL）技术在慢性疾病预测与诊断方面的进展。AI驱动的模型如XGBoost、随机森林、卷积神经网络（CNNs）和长短期记忆循环神经网络（LSTM RNNs）在心脏病、慢性肾病（CKD）、阿尔茨海默症和肺癌的预测上取得了超过98%的准确率，数据来源包括Kaggle、UCI、私人机构和实时IoMT资源。

然而，这一领域仍面临挑战，包括数据质量的差异、患者人口统计学的多样性以及来自不同医院和研究来源的数据格式不一致。整合来自广泛且异构的IoMT数据增加了确保互操作性和保护患者隐私的复杂性。AI模型经常遇到过拟合问题，尽管在受控环境中表现良好，但在实际临床环境中效果较差。对于多病共存的情况，尤其是罕见疾病如痴呆症、中风和癌症的研究不足。未来的研究应集中在数据标准化和高级预处理技术上，以提高数据质量和互操作性。迁移学习和集成方法对于提高跨临床环境的模型泛化能力至关重要。此外，需要探索疾病之间的相互作用并开发慢性疾病交集的预测模型。创建标准化框架和开源工具，将联邦学习、区块链和差分隐私融入IoMT系统，将确保数据隐私和安全。 <div>
arXiv:2410.00034v1 Announce Type: new 
Abstract: The integration of Artificial Intelligence (AI) and the Internet of Medical Things (IoMT) in healthcare, through Machine Learning (ML) and Deep Learning (DL) techniques, has advanced the prediction and diagnosis of chronic diseases. AI-driven models such as XGBoost, Random Forest, CNNs, and LSTM RNNs have achieved over 98\% accuracy in predicting heart disease, chronic kidney disease (CKD), Alzheimer's disease, and lung cancer, using datasets from platforms like Kaggle, UCI, private institutions, and real-time IoMT sources. However, challenges persist due to variations in data quality, patient demographics, and formats from different hospitals and research sources. The incorporation of IoMT data, which is vast and heterogeneous, adds complexities in ensuring interoperability and security to protect patient privacy. AI models often struggle with overfitting, performing well in controlled environments but less effectively in real-world clinical settings. Moreover, multi-morbidity scenarios especially for rare diseases like dementia, stroke, and cancers remain insufficiently addressed. Future research should focus on data standardization and advanced preprocessing techniques to improve data quality and interoperability. Transfer learning and ensemble methods are crucial for improving model generalizability across clinical settings. Additionally, the exploration of disease interactions and the development of predictive models for chronic illness intersections is needed. Creating standardized frameworks and open-source tools for integrating federated learning, blockchain, and differential privacy into IoMT systems will also ensure robust data privacy and security.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial intelligence-based blockchain-driven financial default prediction</title>
<link>https://arxiv.org/abs/2410.00044</link>
<guid>https://arxiv.org/abs/2410.00044</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、人工智能、金融风险、数据存储、预测模型

<br />
<br />总结:
本文探讨了区块链与人工智能在金融领域的应用，特别是在信贷风险缓解和金融系统稳定方面的新思路。区块链技术通过去中心化和安全性，解决了传统系统中数据存储和管理的安全问题，为金融行业提供了可信且一致的数据环境。而人工智能则凭借强大的算法建模能力，在金融预测和风险管理上展现出巨大优势，能够通过大数据分析构建高级违约预测模型。

结合区块链与人工智能，金融机构得以优化信用风险控制策略，提升决策效率和准确性。区块链确保数据的真实性与一致性，增强了数据的安全性；人工智能则通过深度学习等技术，从海量数据中挖掘出预测违约的关键指标，构建出更加精准的预测模型。这一创新应用不仅有助于降低金融风险，还能促进金融系统的稳定性和可持续发展。未来，随着技术的不断进步，这种集成方案有望在更多领域展现出其独特价值。 <div>
arXiv:2410.00044v1 Announce Type: new 
Abstract: With the rapid development of technology, blockchain and artificial intelligence technology are playing a huge role in all walks of life. In the financial sector, blockchain solves many security problems in data storage and management in traditional systems with its advantages of decentralization and security. And artificial intelligence has huge advantages in financial forecasting and risk management through its powerful algorithmic modeling capabilities. In financial default prediction using blockchain and artificial intelligence technology is a very powerful application. Blockchain technology guarantees the credibility of data and consistency on all nodes, and machine learning builds a high-level default prediction model through detailed analysis of big data. This study offers financial institutions new thoughts on financial technology in terms of credit risk mitigation and financial system stabilization.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models</title>
<link>https://arxiv.org/abs/2410.00131</link>
<guid>https://arxiv.org/abs/2410.00131</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（FL）、Large Language Models（LLMs）、Fisher Information、Efficient Curriculum Federated Learning、LoRA

<br /><br />
总结:

本文提出了一种名为FibecFed的高效课程联邦学习框架，旨在通过利用Federated Learning（FL）在分布式数据上协作训练模型。针对大型语言模型（LLMs）参数量巨大和训练数据非独立同分布（non-IID）的问题，FibecFed引入了两个创新方法：自适应联邦课程学习和高效的稀疏参数更新。

首先，文章提出了基于费雪信息的方法，用于在每个设备上适当地采样数据，以提高FL微调过程的有效性。其次，通过动态选择合适的层进行全局聚合以及为本地更新选择合适的稀疏参数，FibecFed进一步优化了FL微调过程的效率。

实验结果表明，与17个基线方法相比，FibecFed在准确率上最高提高了45.35%，在微调速度上最快提高了98.61%，充分展示了其在提升性能和加速训练速度方面的显著优势。 <div>
arXiv:2410.00131v1 Announce Type: new 
Abstract: As a promising paradigm to collaboratively train models with decentralized data, Federated Learning (FL) can be exploited to fine-tune Large Language Models (LLMs). While LLMs correspond to huge size, the scale of the training data significantly increases, which leads to tremendous amounts of computation and communication costs. The training data is generally non-Independent and Identically Distributed (non-IID), which requires adaptive data processing within each device. Although Low Rank Adaptation (LoRA) can significantly reduce the scale of parameters to update in the fine-tuning process, it still takes unaffordable time to transfer the low-rank parameters of all the layers in LLMs. In this paper, we propose a Fisher Information-based Efficient Curriculum Federated Learning framework (FibecFed) with two novel methods, i.e., adaptive federated curriculum learning and efficient sparse parameter update. First, we propose a fisher information-based method to adaptively sample data within each device to improve the effectiveness of the FL fine-tuning process. Second, we dynamically select the proper layers for global aggregation and sparse parameters for local update with LoRA so as to improve the efficiency of the FL fine-tuning process. Extensive experimental results based on 10 datasets demonstrate that FibecFed yields excellent performance (up to 45.35% in terms of accuracy) and superb fine-tuning speed (up to 98.61% faster) compared with 17 baseline approaches).
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Input and State Estimation for Multi-agent System with Dynamic Topology and Heterogeneous Sensor Network</title>
<link>https://arxiv.org/abs/2410.00272</link>
<guid>https://arxiv.org/abs/2410.00272</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统、状态估计、未知输入、信息滤波、动态拓扑结构

<br /><br />
总结:

本文研究了在分布式系统中，特别是在具有异构传感器网络和动态拓扑结构的情况下，面对未知输入时的状态估计问题。传统的共识算法往往需要大量的信息交换或多次通信迭代来确保估计的准确性。文章提出了一种高效算法，该算法通过信息滤波分解和协方差交集的输入融合实现了与拥有其他代理完整信息的滤波器相媲美的无偏置、最优解。这一方法只需要一次通信迭代来交换个体估计值，避免了分享明确观察和系统方程，从而保护了代理的隐私。

此外，针对动态通信拓扑带来的挑战，文章提出了两种实用策略来处理因间歇性观测和不完整状态估计导致的问题，以增强估计过程的鲁棒性和准确性。实验和消融研究在静态和动态环境中均表明，该算法优于其他基准，并且在某些情况下甚至表现得更好于那些拥有所有邻居全局视图的算法。 <div>
arXiv:2410.00272v1 Announce Type: new 
Abstract: A crucial challenge in decentralized systems is state estimation in the presence of unknown inputs, particularly within heterogeneous sensor networks with dynamic topologies. While numerous consensus algorithms have been introduced, they often require extensive information exchange or multiple communication iterations to ensure estimation accuracy. This paper proposes an efficient algorithm that achieves an unbiased and optimal solution comparable to filters with full information about other agents. This is accomplished through the use of information filter decomposition and the fusion of inputs via covariance intersection. Our method requires only a single communication iteration for exchanging individual estimates between agents, instead of multiple rounds of information exchange, thus preserving agents' privacy by avoiding the sharing of explicit observations and system equations. Furthermore, to address the challenges posed by dynamic communication topologies, we propose two practical strategies to handle issues arising from intermittent observations and incomplete state estimation, thereby enhancing the robustness and accuracy of the estimation process. Experiments and ablation studies conducted in both stationary and dynamic environments demonstrate the superiority of our algorithm over other baselines. Notably, it performs as well as, or even better than, algorithms that have a global view of all neighbors.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smart Contract Vulnerability Detection based on Static Analysis and Multi-Objective Search</title>
<link>https://arxiv.org/abs/2410.00282</link>
<guid>https://arxiv.org/abs/2410.00282</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、漏洞检测、静态分析、多目标优化算法、Etherscan数据集

总结:

本文提出了一种基于静态分析与多目标优化算法的智能合约漏洞检测方法。该方法主要针对四种类型的漏洞进行检测，包括重入性（reentrancy）、调用栈溢出（call stack overflow）、整数溢出（integer overflow）和时间戳依赖（timestamp dependency）。首先，通过编译将智能合约转化为抽象语法树（AST），以此来分析合约之间的关系，如调用、继承和数据流等，并将其转化为静态评估和中间表示，以揭示内部关系。然后，通过对函数、变量和数据依赖性的检查，识别上述四种漏洞。

为了提高检测的准确性和覆盖率，文章引入了多目标优化算法。该算法对初始输入数据赋予数值，并监控语句覆盖度和检测准确度的变化。使用覆盖度和准确度作为适应度值，通过计算帕累托前沿和拥挤距离来选择最佳个体用于下一代父群体的生成，直至满足优化条件。实验结果表明，与现有最先进的工具相比，该方法在覆盖度、准确度、效率和检测效果方面均表现出色。

文章最后，通过收集自Etherscan的开源数据集验证了方法的有效性，该数据集包含了6693个智能合约，进一步证明了该方法在实际应用中的可行性和高效性。 <div>
arXiv:2410.00282v1 Announce Type: new 
Abstract: This paper introduces a method for detecting vulnerabilities in smart contracts using static analysis and a multi-objective optimization algorithm. We focus on four types of vulnerabilities: reentrancy, call stack overflow, integer overflow, and timestamp dependencies. Initially, smart contracts are compiled into an abstract syntax tree to analyze relationships between contracts and functions, including calls, inheritance, and data flow. These analyses are transformed into static evaluations and intermediate representations that reveal internal relations. Based on these representations, we examine contract's functions, variables, and data dependencies to detect the specified vulnerabilities. To enhance detection accuracy and coverage, we apply a multi-objective optimization algorithm to the static analysis process. This involves assigning initial numeric values to input data and monitoring changes in statement coverage and detection accuracy. Using coverage and accuracy as fitness values, we calculate Pareto front and crowding distance values to select the best individuals for the new parent population, iterating until optimization criteria are met. We validate our approach using an open-source dataset collected from Etherscan, containing 6,693 smart contracts. Experimental results show that our method outperforms state-of-the-art tools in terms of coverage, accuracy, efficiency, and effectiveness in detecting the targeted vulnerabilities.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Mathematical Theory of Hyper-simplex Fractal Network for Blockchain: Part I</title>
<link>https://arxiv.org/abs/2410.00583</link>
<guid>https://arxiv.org/abs/2410.00583</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、Web 3.0、新型网络拓扑、数学理论、无限扩展

总结:

本文提出了一种基于分形N维简单体的创新区块链网络拓扑结构理论。这种Hyper-simplex分形网络通过将一维数据块折叠成几何形状，反映了网络的内在和外层连接性。该理论为实现近无限扩展提供了可能，能够容纳数十亿节点的同时保持高效运行。通过推导生成和描述这些网络拓扑的基础数学，证明了节点数量、连接模式和分形维度等关键属性。此结构支持层次化的共识机制，并允许确定性地址映射以实现快速路由。这一理论框架为下一代区块链架构奠定了基础，有望彻底改变大规模去中心化系统的运作方式。研究工作于2024年3月至9月期间进行。

通过构建这种新型网络拓扑，文章旨在解决当前区块链技术在可扩展性方面的挑战，特别是在Web 3.0背景下。分形N维简单体的使用不仅提供了理论上无限的扩展能力，还优化了网络效率和性能。理论证明了该网络模型在节点规模、连接性和结构复杂性方面具有优越性。此外，通过引入层次化的共识机制和确定性地址映射，该理论还提出了实现高效数据路由的方法。这项研究的成果对于推动区块链技术在大规模应用中的发展具有重要意义，有可能引领未来区块链架构的变革。 <div>
arXiv:2410.00583v1 Announce Type: new 
Abstract: Blockchain technology holds promise for Web 3.0, but scalability remains a critical challenge. Here, we present a mathematical theory for a novel blockchain network topology based on fractal N-dimensional simplexes. This Hyper-simplex fractal network folds one-dimensional data blocks into geometric shapes, reflecting both underlying and overlaying network connectivities. Our approach offers near-infinite scalability, accommodating trillions of nodes while maintaining efficiency.
  We derive the mathematical foundations for generating and describing these network topologies, proving key properties such as node count, connectivity patterns, and fractal dimension. The resulting structure facilitates a hierarchical consensus mechanism and enables deterministic address mapping for rapid routing. This theoretical framework lays the groundwork for next-generation blockchain architectures, potentially revolutionizing large-scale decentralized systems. The Part I work was conducted between March and September 2024.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Web Spam Detection through a Blockchain-Enabled Crowdsourcing Mechanism</title>
<link>https://arxiv.org/abs/2410.00860</link>
<guid>https://arxiv.org/abs/2410.00860</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、激励机制、数据质量、机器学习、反垃圾邮件

<br /><br />
总结:
本文探讨了通过区块链技术实现的激励式众包方法，以提高网络反垃圾邮件系统的效能。关键点如下：

1. **动态挑战与现有解决方案的局限性**：文中首先指出了网络垃圾邮件的不断演变和复杂性对传统机器学习模型构成的挑战，即模型难以跟上攻击者的创新步伐。

2. **区块链技术的应用**：作者提出利用区块链的去中心化和透明特性，创建一种激励机制，鼓励用户参与数据收集和标注过程。通过智能合约，参与者需要以加密货币作为抵押，确保其贡献的准确性和诚信度。

3. **提升数据质量**：激励机制旨在提高数据质量和准确性，因为参与者有动机提供精确的信息，从而为机器学习算法提供更可靠的数据集。

4. **改进机器学习模型性能**：高质量的数据通过改善机器学习模型的训练效果，最终提升了垃圾邮件检测的准确率和效率。

5. **解决传统方法的局限性**：这种基于区块链的激励式众包方法提供了一种可扩展和适应性强的解决方案，旨在克服传统方法在应对动态垃圾邮件攻击时的不足。

通过上述分析，本文提出了一个创新的策略来增强反垃圾邮件系统，不仅解决了数据质量的问题，还通过引入激励机制和区块链技术提高了整个系统的效率和响应能力。 <div>
arXiv:2410.00860v1 Announce Type: new 
Abstract: The proliferation of spam on the Web has necessitated the development of machine learning models to automate their detection. However, the dynamic nature of spam and the sophisticated evasion techniques employed by spammers often lead to low accuracy in these models. Traditional machine-learning approaches struggle to keep pace with spammers' constantly evolving tactics, resulting in a persistent challenge to maintain high detection rates. To address this, we propose blockchain-enabled incentivized crowdsourcing as a novel solution to enhance spam detection systems. We create an incentive mechanism for data collection and labeling by leveraging blockchain's decentralized and transparent framework. Contributors are rewarded for accurate labels and penalized for inaccuracies, ensuring high-quality data. A smart contract governs the submission and evaluation process, with participants staking cryptocurrency as collateral to guarantee integrity. Simulations show that incentivized crowdsourcing improves data quality, leading to more effective machine-learning models for spam detection. This approach offers a scalable and adaptable solution to the challenges of traditional methods.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Review of blockchain application with Graph Neural Networks, Graph Convolutional Networks and Convolutional Neural Networks</title>
<link>https://arxiv.org/abs/2410.00875</link>
<guid>https://arxiv.org/abs/2410.00875</guid>
<content:encoded><![CDATA[
<div> 关键词：Graph Neural Networks（GNNs）、Graph Convolutional Networks（GCNs）、Convolutional Neural Networks（CNNs）、Blockchain Technology、Deep Learning Models

总结:
本文主要探讨了图神经网络（GNNs）、图卷积网络（GCNs）和卷积神经网络（CNNs）在区块链技术中的应用。随着区块链网络的复杂性和采用度持续增长，传统的分析方法在捕捉去中心化系统中复杂的关联和动态行为方面显得力不从心。为解决这一问题，深度学习模型如GNNs、GCNs和CNNs提供了强大的解决方案，它们通过利用区块链架构中固有的图结构和时间序列特性来建模节点与交易的关系。

GNNs和GCNs特别擅长处理区块链中节点间的关联数据，因此适用于欺诈检测、交易验证和智能合约分析等应用。同时，当区块链数据以结构化的矩阵形式表示时，CNNs可以通过分析揭示隐藏的时空模式在交易流中的模式。

本文还深入研究了这些模型如何增强线性区块链和有向无环图（DAG）为基础系统的效率、安全性和可扩展性，提供了一个全面的分析模型优势及其未来研究方向的概述。通过整合先进的神经网络技术，旨在展示这些模型在区块链分析领域革命性的潜力，从而为更高级的去中心化应用和网络性能改进铺平道路。 <div>
arXiv:2410.00875v1 Announce Type: new 
Abstract: This paper reviews the applications of Graph Neural Networks (GNNs), Graph Convolutional Networks (GCNs), and Convolutional Neural Networks (CNNs) in blockchain technology. As the complexity and adoption of blockchain networks continue to grow, traditional analytical methods are proving inadequate in capturing the intricate relationships and dynamic behaviors of decentralized systems. To address these limitations, deep learning models such as GNNs, GCNs, and CNNs offer robust solutions by leveraging the unique graph-based and temporal structures inherent in blockchain architectures. GNNs and GCNs, in particular, excel in modeling the relational data of blockchain nodes and transactions, making them ideal for applications such as fraud detection, transaction verification, and smart contract analysis. Meanwhile, CNNs can be adapted to analyze blockchain data when represented as structured matrices, revealing hidden temporal and spatial patterns in transaction flows. This paper explores how these models enhance the efficiency, security, and scalability of both linear blockchains and Directed Acyclic Graph (DAG)-based systems, providing a comprehensive overview of their strengths and future research directions. By integrating advanced neural network techniques, we aim to demonstrate the potential of these models in revolutionizing blockchain analytics, paving the way for more sophisticated decentralized applications and improved network performance.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning with Reduced Information Leakage and Computation</title>
<link>https://arxiv.org/abs/2310.06341</link>
<guid>https://arxiv.org/abs/2310.06341</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、信息泄露、隐私保护、模型更新、迭代过程

总结:

本文提出了Upcycled-FL策略，这是一种简单而有效的联邦学习方法，旨在通过在每一轮模型更新的偶数轮次中应用一阶近似，减少信息泄露和计算传输成本。该策略使得一半的模型更新不再产生信息泄露，从而在保证隐私的同时提高效率。

理论分析表明，Upcycled-FL在收敛速度上仍然具有良好的性能，并且通过引入两种扰动机制进一步增强了隐私保护能力。实验证明，这种策略可以适应多种现有的联邦学习框架，并且在合成数据和真实世界数据上均表现出一致的隐私-准确性权衡改善效果。

总的来说，Upcycled-FL策略通过优化联邦学习中的模型更新过程，不仅减少了信息泄露的风险，还降低了计算和通信的成本，同时保持了良好的收敛性能，为实现高效且隐私保护的联邦学习提供了新的途径。 <div>
arXiv:2310.06341v2 Announce Type: replace 
Abstract: Federated learning (FL) is a distributed learning paradigm that allows multiple decentralized clients to collaboratively learn a common model without sharing local data. Although local data is not exposed directly, privacy concerns nonetheless exist as clients' sensitive information can be inferred from intermediate computations. Moreover, such information leakage accumulates substantially over time as the same data is repeatedly used during the iterative learning process. As a result, it can be particularly difficult to balance the privacy-accuracy trade-off when designing privacy-preserving FL algorithms. This paper introduces Upcycled-FL, a simple yet effective strategy that applies first-order approximation at every even round of model update. Under this strategy, half of the FL updates incur no information leakage and require much less computational and transmission costs. We first conduct the theoretical analysis on the convergence (rate) of Upcycled-FL and then apply two perturbation mechanisms to preserve privacy. Extensive experiments on both synthetic and real-world data show that the Upcycled-FL strategy can be adapted to many existing FL frameworks and consistently improve the privacy-accuracy trade-off.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MEV Sharing with Dynamic Extraction Rates</title>
<link>https://arxiv.org/abs/2402.15849</link>
<guid>https://arxiv.org/abs/2402.15849</guid>
<content:encoded><![CDATA[
<div> 关键词：Maximal Extractable Value (MEV), 协议设计空间, EIP-1559, 动态机制, 目标值

总结:

本文探讨了区块链系统中一个新兴领域——最大可提取价值（MEV）的设计问题。MEV是区块生产者通过操纵交易顺序以获取利润的一种方式。研究提出将MEV提取率纳入协议设计空间，旨在通过动态调整该参数来平衡区块生产者和用户的利益。借鉴EIP-1559的思路，设计了一种动态机制，目标是使MEV提取率稳定在一个预定值上。

研究发现，该动态机制在特定参数下能确保向目标值收敛，但在其他情况下可能出现不稳定甚至混沌现象。然而，在一般条件下，系统会在目标均衡点附近集中，显示出长期性能的稳定性。

这项工作首次提出了动态框架来解决MEV在区块生产者与用户之间的共享问题，为MEV管理提供了理论基础和实践指导。通过动态调整MEV提取率，可以实现更公平合理的利益分配，促进区块链系统的健康发展。 <div>
arXiv:2402.15849v2 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) has emerged as a new frontier in the design of blockchain systems. In this paper, we propose making the MEV extraction rate as part of the protocol design space. Our aim is to leverage this parameter to maintain a healthy balance between block producers (who need to be compensated) and users (who need to feel encouraged to transact). We follow the approach introduced by EIP-1559 and design a similar mechanism to dynamically update the MEV extraction rate with the goal of stabilizing it at a target value. We study the properties of this dynamic mechanism and show that, while convergence to the target can be guaranteed for certain parameters, instability, and even chaos, can occur in other cases. Despite these complexities, under general conditions, the system concentrates in a neighborhood of the target equilibrium implying high long-term performance. Our work establishes, the first to our knowledge, dynamic framework for the integral problem of MEV sharing between extractors and users.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tax Policy Handbook for Crypto Assets</title>
<link>https://arxiv.org/abs/2403.15074</link>
<guid>https://arxiv.org/abs/2403.15074</guid>
<content:encoded><![CDATA[
<div> 关键词：金融系统、区块链技术、税收政策、监管挑战、全球数字基础设施

<br /><br />
总结:

本文深入探讨了金融科技领域的重大变革，尤其是比特币和其他基于分布式账本技术的加密资产的兴起，对传统金融体系的影响。文章指出，这些变化带来了监管和税收政策上的盲点，因为政府和税务机构需要时间来理解并制定相应的政策回应。创新和技术发展速度之快使得政策干预往往滞后于技术进步。

文章解释了加密资产的工作原理及其底层技术，并将这些概念与税收问题和生态系统中产生的可税事件联系起来。它还提到了在不同司法管辖区实施的现有税收和监管政策响应实例，包括金融行动特别工作组(FATF)和经济合作与发展组织(OECD)最近在报告标准方面的变化。

文章分析了加密资产相关的直接和间接税收问题，并详细讨论了更近期的技术发展，如权益证明和最大提取价值。此外，文章还提出创建全球公共数字基础设施的建议，以解决与匿名性和跨领土性相关的问题。

总的来说，本文旨在提供一个全面的视角，帮助理解加密资产领域内的税收和监管挑战，并提出了促进全球协调和有效管理这一新兴资产类别的潜在解决方案。 <div>
arXiv:2403.15074v3 Announce Type: replace-cross 
Abstract: The Financial system has witnessed rapid technological changes. The rise of Bitcoin and other crypto assets based on Distributed Ledger Technology mark a fundamental change in the way people transact and transmit value over a decentralized network, spread across geographies. This has created regulatory and tax policy blind spots, as governments and tax administrations take time to understand and provide policy responses to this innovative, revolutionary, and fast-paced technology. Due to the breakneck speed of innovation in blockchain technology and advent of Decentralized Finance, Decentralized Autonomous Organizations and the Metaverse, it is unlikely that the policy interventions and guidance by regulatory authorities or tax administrations would be ahead or in sync with the pace of innovation. This paper tries to explain the principles on which crypto assets function, their underlying technology and relates them to the tax issues and taxable events which arise within this ecosystem. It also provides instances of tax and regulatory policy responses already in effect in various jurisdictions, including the recent changes in reporting standards by the FATF and the OECD. This paper tries to explain the rationale behind existing laws and policies and the challenges in their implementation. It also attempts to present a ballpark estimate of tax potential of this asset class and suggests creation of global public digital infrastructure that can address issues related to pseudonymity and extra-territoriality. The paper analyses both direct and indirect taxation issues related to crypto assets and discusses more recent aspects like proof-of-stake and maximal extractable value in greater detail.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematisation of Knowledge: Connecting European Digital Identities with Web3</title>
<link>https://arxiv.org/abs/2409.19032</link>
<guid>https://arxiv.org/abs/2409.19032</guid>
<content:encoded><![CDATA[
<div> 关键词：自主权身份、去中心化身份、欧洲数字身份框架、开放身份认证、Web3

总结:

本文旨在澄清“自主权身份”(SSI)与“去中心化身份”之间的概念差异，特别是在修订后的《关于建立欧盟数字身份框架（eIDAS 2.0）》背景下。研究采用了归纳探索性方法，历时九个月，收集了从2005年到2024年的相关文献。

研究发现，去中心化身份领域在OpenID Connect（OIDC）的开放身份认证范式旁发展，而SSI则标志着该领域的转向区块链解决方案。文章指出，将SSI和去中心化身份混用与OIDC上的新协议相重合。

第一部分区分了OIDC与去中心化身份，强调了它们在技术上的区别。第二部分探讨了OIDC在eIDAS 2.0下的局限性以及与Web3的不兼容性。

最后，文章建议进一步研究以建立一个数字身份桥梁，连接基于公共无权限的区块链的应用程序与eIDAS 2.0提供的数据，以及使用OIDC进行展示的数据。这一研究成果有助于推动数字身份领域的标准化与互操作性，促进不同技术平台之间的融合与协同作用。 <div>
arXiv:2409.19032v1 Announce Type: new 
Abstract: The terms self-sovereign identity (SSI) and decentralised identity are often used interchangeably, which results in increasing ambiguity when solutions are being investigated and compared. This article aims to provide a clear distinction between the two concepts in relation to the revised Regulation as Regards establishing the European Digital Identity Framework (eIDAS 2.0) by providing a systematisation of knowledge of technological developments that led up to implementation of eIDAS 2.0. Applying an inductive exploratory approach, relevant literature was selected iteratively in waves over a nine months time frame and covers literature between 2005 and 2024. The review found that the decentralised identity sector emerged adjacent to the OpenID Connect (OIDC) paradigm of Open Authentication, whereas SSI denotes the sector's shift towards blockchain-based solutions. In this study, it is shown that the interchangeable use of SSI and decentralised identity coincides with novel protocols over OIDC. While the first part of this paper distinguishes OIDC from decentralised identity, the second part addresses the incompatibility between OIDC under eIDAS 2.0 and Web3. The paper closes by suggesting further research for establishing a digital identity bridge for connecting applications on public-permissionless ledgers with data originating from eIDAS 2.0 and being presented using OIDC.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secure Multiparty Generative AI</title>
<link>https://arxiv.org/abs/2409.19120</link>
<guid>https://arxiv.org/abs/2409.19120</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式AI、敏感信息、数据泄露、模型提供者、分布式计算

总结:

文章讨论了随着生成式人工智能工具的使用激增，敏感信息暴露给这些模型和中央模型提供商的问题日益严重。例如，三星的机密源代码通过ChatGPT的文本提示遭遇数据泄露就是一个实例。越来越多的公司因为数据泄露或保密问题而限制了大型语言模型（LLMs）的使用，包括苹果、Verizon、摩根大通等。此外，一些集中式的生成模型提供商也在限制、过滤、对齐或审查可以使用的数据。

针对这一问题，作者提出了一种安全且私密的方法来处理生成式人工智能，以防止敏感数据或模型暴露给第三方AI供应商。该方法修改了现代生成式AI算法的关键组成部分，如变换器，并引入了分布式网络中的保密和可验证多方计算。这不仅保护了用户输入的隐私和模型输出的混淆，还为模型本身引入了隐私性。分片过程减少了任何单个节点的计算负担，使得大型生成式AI进程的资源能够分散到多个较小的节点上。研究显示，只要计算中存在一个诚实的节点，安全性就能得到保障。同时，即使只有计算中大多数节点成功，推理过程仍然可以成功进行。因此，这种方法在分布式网络中提供了安全且可验证的计算能力。 <div>
arXiv:2409.19120v1 Announce Type: new 
Abstract: As usage of generative AI tools skyrockets, the amount of sensitive information being exposed to these models and centralized model providers is alarming. For example, confidential source code from Samsung suffered a data leak as the text prompt to ChatGPT encountered data leakage. An increasing number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing number of centralized generative model providers are restricting, filtering, aligning, or censoring what can be used. Midjourney and RunwayML, two of the major image generation platforms, restrict the prompts to their system via prompt filtering. Certain political figures are restricted from image generation, as well as words associated with women's health care, rights, and abortion.
  In our research, we present a secure and private methodology for generative artificial intelligence that does not expose sensitive data or models to third-party AI providers. Our work modifies the key building block of modern generative AI algorithms, e.g. the transformer, and introduces confidential and verifiable multiparty computations in a decentralized network to maintain the 1) privacy of the user input and obfuscation to the output of the model, and 2) introduce privacy to the model itself. Additionally, the sharding process reduces the computational burden on any one node, enabling the distribution of resources of large generative AI processes across multiple, smaller nodes. We show that as long as there exists one honest node in the decentralized computation, security is maintained. We also show that the inference process will still succeed if only a majority of the nodes in the computation are successful. Thus, our method offers both secure and verifiable computation in a decentralized network.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>IM: Optimizing Byzantine Consensus for High-Performance Distributed Networks</title>
<link>https://arxiv.org/abs/2409.19286</link>
<guid>https://arxiv.org/abs/2409.19286</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Fault Tolerant、Mempool、Coding Techniques、Fast-HotStuff、Throughput

总结:

本文提出了一种名为IM（Mempool）的新颖共识协议，旨在提升拜占庭容错（BFT）共识机制在故障节点和网络不稳定环境下的性能。通过将微块组织成链并结合编码技术，IM协议能够高效实现一致性与可用性。该协议易于集成到现有的BFT协议中，以增强其性能。

作为示例，作者将IM与Fast-HotStuff协议结合，形成了IM-FHS，该协议具备保持顺序、带宽适应性和抵抗过量分布等特性。在具有最高可达256个节点的系统中进行了IM-FHS的实验验证，结果显示，相比于当前最先进的Stratus-FHS协议，IM-FHS在处理故障节点时表现出更高的吞吐量和更小的延迟。随着故障节点数量的增加，IM-FHS的吞吐量优势更加显著。在100个节点中有33个故障节点的系统中，IM-FHS的吞吐量几乎是Stratus-FHS的9倍，同时保持了1/10的延迟水平，充分展示了其在高容错性场景下的优越性能。 <div>
arXiv:2409.19286v1 Announce Type: new 
Abstract: Byzantine Fault Tolerant (BFT) consensus, a crucial component of blockchains, has made significant advancements. However, the efficiency of existing protocols can still be damaged by certain attacks from faulty nodes and network instability. In this paper, we propose a novel Shared Mempool (SMP) protocol, namely IM, that enhances performance under these attacks. Technically, IM organizing microblocks into chains, combined with coding techniques, achieves totality and availability efficiently. IM can be easily integrated into a BFT protocol. We take Fast-HotStuff as an example and obtain the IM-FHS with guarantees of \emph{order keeping}, \emph{bandwidth adaptability} and \emph{over-distribution resistance}. IM-FHS is conducted in a system with up to 256 nodes, and experimental results validate the efficiency of our approach. IM-FHS achieves higher throughput and smaller latency with faulty nodes than Stratus-FHS, the state-of-the-art protocol, and the throughput gain increases as the number of fault nodes. In a system with 100 nodes with 33 faulty nodes, IM-FHS achieves 9 times the throughput of Stratus-FHS while maintaining 1/10 the latency when dealing with maximum resilience against faulty nodes.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secret Use of Large Language Models</title>
<link>https://arxiv.org/abs/2409.19450</link>
<guid>https://arxiv.org/abs/2409.19450</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、透明度、AI使用、秘密使用、用户行为

<br /><br />
总结:

文章探讨了大型语言模型（LLM）在现代社会中的应用与透明度问题。随着LLM的发展，用户被鼓励或要求公开其使用生成内容进行实际任务的情况。然而，发现了一种名为“秘密使用”的现象，即用户在不公开的情况下使用LLM。研究通过问卷调查和控制实验，收集了125个实际案例，并对300名参与者进行了实验，旨在深入理解秘密使用LLM的行为背景和原因。

研究发现，秘密使用行为往往由特定任务触发，不受用户年龄、性别等人口统计学特征的影响。任务类型影响着用户对秘密使用行为的意图，主要通过改变他们对外部对LLM使用的判断感知来实现。研究结果为未来设计促进更多透明披露LLM或其他AI技术使用的干预措施提供了重要见解。这一发现强调了在AI技术普及中确保透明度和责任的重要性，并提出了需要针对性策略以促进用户更负责任地使用这些工具。 <div>
arXiv:2409.19450v1 Announce Type: new 
Abstract: The advancements of Large Language Models (LLMs) have decentralized the responsibility for the transparency of AI usage. Specifically, LLM users are now encouraged or required to disclose the use of LLM-generated content for varied types of real-world tasks. However, an emerging phenomenon, users' secret use of LLM, raises challenges in ensuring end users adhere to the transparency requirement. Our study used mixed-methods with an exploratory survey (125 real-world secret use cases reported) and a controlled experiment among 300 users to investigate the contexts and causes behind the secret use of LLMs. We found that such secretive behavior is often triggered by certain tasks, transcending demographic and personality differences among users. Task types were found to affect users' intentions to use secretive behavior, primarily through influencing perceived external judgment regarding LLM usage. Our results yield important insights for future work on designing interventions to encourage more transparent disclosure of the use of LLMs or other AI technologies.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Infighting in the Dark: Multi-Labels Backdoor Attack in Federated Learning</title>
<link>https://arxiv.org/abs/2409.19601</link>
<guid>https://arxiv.org/abs/2409.19601</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Multi-Label Backdoor Attack、M2M、Trigger Pattern、Target Class Distribution

总结:
本文首先深入探讨了将现有研究应用于多标签后门攻击（MBA）时所面临的局限性。随后，提出了一种名为M2M的新颖多标签后门攻击方法，旨在联邦学习（FL）框架中通过巧妙地调整后门触发器，确保被后门化的样本在全局模型中被处理为干净的目标样本。M2M的关键创新在于建立触发模式与目标类分布之间的联系，使得不同的触发器能够在目标类别的清洁激活路径上激活后门，而无需担心潜在的抑制作用。通过全面的评估，该方法被证明优于各种先进的攻击技术。这项工作旨在提醒研究人员和开发者注意这一潜在威胁，并激发有效检测方法的设计。

本文的主要贡献在于：
1. 指出了现有方法在应用到MBA时存在的问题。
2. 提出了M2M策略，利用多标签数据的特点，实现后门化样本在全局模型中的有效激活。
3. 通过实验验证了M2M方法的有效性和优越性。
4. 强调了对联邦学习系统中多标签后门攻击威胁的认识，以及对防御策略的需求。
5. 表明了开发和部署针对性防御措施的重要性，以保护联邦学习系统的安全性和可靠性。 <div>
arXiv:2409.19601v1 Announce Type: new 
Abstract: Federated Learning (FL) has been demonstrated to be vulnerable to backdoor attacks. As a decentralized machine learning framework, most research focuses on the Single-Label Backdoor Attack (SBA), where adversaries share the same target but neglect the fact that adversaries may be unaware of each other's existence and hold different targets, i.e., Multi-Label Backdoor Attack (MBA). Unfortunately, directly applying prior work to the MBA would not only be ineffective but also potentially mitigate each other. In this paper, we first investigate the limitations of applying previous work to the MBA. Subsequently, we propose M2M, a novel multi-label backdoor attack in federated learning (FL), which adversarially adapts the backdoor trigger to ensure that the backdoored sample is processed as clean target samples in the global model. Our key intuition is to establish a connection between the trigger pattern and the target class distribution, allowing different triggers to activate backdoors along clean activation paths of the target class without concerns about potential mitigation. Extensive evaluations comprehensively demonstrate that M2M outperforms various state-of-the-art attack methods. This work aims to alert researchers and developers to this potential threat and to inspire the design of effective detection methods. Our code will be made available later.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Programming on Bitcoin: A Survey of Layer 1 and Layer 2 Technologies in Bitcoin Ecosystem</title>
<link>https://arxiv.org/abs/2409.19622</link>
<guid>https://arxiv.org/abs/2409.19622</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、编程功能、创新协议、Taproot升级、非同质化代币

<br />
<br />总结:

本文综述了增强比特币区块链编程功能的创新性协议，特别是围绕比特币生态系统的核心部分。比特币采用UTXO模型和基于堆栈的脚本语言，为点对点支付提供高效解决方案，但其在编程能力和吞吐量方面存在局限性。2021年的Taproot升级引入了Schnorr签名算法和P2TR交易类型，显著提升了比特币的隐私性和编程能力。

文章探讨了利用Taproot特性进行非同质化代币（NFT）编程的协议，如Ordinals和Atomicals，并分析了BRC-20和ARC-20等代币标准。此外，文章还分类了一些作为比特币生态层2解决方案的协议，类似于以太坊的方案，评估它们对比特币主网性能的影响。

通过分析比特币区块链数据，收集了关于区块容量、矿工费用和Taproot交易增长的指标。研究结果确认了这些协议对提升比特币编程能力和生态系统的积极效果，填补了关于比特币编程能力和生态协议研究的空白，并为实践者和研究者提供了有价值的信息。 <div>
arXiv:2409.19622v1 Announce Type: new 
Abstract: This paper surveys innovative protocols that enhance the programming functionality of the Bitcoin blockchain, a key part of the "Bitcoin Ecosystem." Bitcoin utilizes the Unspent Transaction Output (UTXO) model and a stack-based script language for efficient peer-to-peer payments, but it faces limitations in programming capability and throughput. The 2021 Taproot upgrade introduced the Schnorr signature algorithm and P2TR transaction type, significantly improving Bitcoin's privacy and programming capabilities. This upgrade has led to the development of protocols like Ordinals, Atomicals, and BitVM, which enhance Bitcoin's programming functionality and enrich its ecosystem. We explore the technical aspects of the Taproot upgrade and examine Bitcoin Layer 1 protocols that leverage Taproot's features to program non-fungible tokens (NFTs) into transactions, including Ordinals and Atomicals, along with the fungible token standards BRC-20 and ARC-20.
  Additionally, we categorize certain Bitcoin ecosystem protocols as Layer 2 solutions similar to Ethereum's, analyzing their impact on Bitcoin's performance. By analyzing data from the Bitcoin blockchain, we gather metrics on block capacity, miner fees, and the growth of Taproot transactions. Our findings confirm the positive effects of these protocols on Bitcoin's mainnet, bridging gaps in the literature regarding Bitcoin's programming capabilities and ecosystem protocols and providing valuable insights for practitioners and researchers.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Centric Design: Introducing An Informatics Domain Model And Core Data Ontology For Computational Systems</title>
<link>https://arxiv.org/abs/2409.19653</link>
<guid>https://arxiv.org/abs/2409.19653</guid>
<content:encoded><![CDATA[
<div> 关键词：Core Data Ontology（CDO）、Informatics Domain Model、数据为中心、AI开发、分布式数据生态系统

<br />
总结:

本文提出了Core Data Ontology（CDO）和Informatics Domain Model的创新概念，旨在通过从传统的节点中心设计转向数据为中心的范式来革新计算系统。数据被划分为四类模态：对象、事件、概念和行动，这一四元模态结构增强了数据安全、语义互操作性和分布式数据生态系统中的可扩展性。

CDO提供了一个全面的本体论框架，支持人工智能开发、基于角色的访问控制以及多模态数据管理。它重新定义了系统架构，优先考虑数据安全、来源证明和审计性，以解决当前模型中的脆弱性问题。文章详细介绍了CDO的开发方法，并探讨了其在人工智能、机器人技术和法律合规等领域的实际应用案例。同时，还展望了构建可扩展、去中心化和互操作性强的数据生态系统的未来方向。 <div>
arXiv:2409.19653v1 Announce Type: new 
Abstract: The Core Data Ontology (CDO) and the Informatics Domain Model represent a transformative approach to computational systems, shifting from traditional node-centric designs to a data-centric paradigm. This paper introduces a framework where data is categorized into four modalities: objects, events, concepts, and actions. This quadrimodal structure enhances data security, semantic interoperability, and scalability across distributed data ecosystems. The CDO offers a comprehensive ontology that supports AI development, role-based access control, and multimodal data management. By focusing on the intrinsic value of data, the Informatics Domain Model redefines system architectures to prioritize data security, provenance, and auditability, addressing vulnerabilities in current models. The paper outlines the methodology for developing the CDO, explores its practical applications in fields such as AI, robotics, and legal compliance, and discusses future directions for scalable, decentralized, and interoperable data ecosystems.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System</title>
<link>https://arxiv.org/abs/2409.19756</link>
<guid>https://arxiv.org/abs/2409.19756</guid>
<content:encoded><![CDATA[
<div> 关键词：学习型医疗系统、隐私保护、联邦学习、数据共享、医疗生态系统

<br />
<br />
总结:
文章探讨了学习型医疗系统(LHS)的概念及其面临的挑战，尤其是数据共享与隐私保护的问题。提出了通过隐私保护联邦学习(PPFL)技术来解决这些问题的愿景。PPFL允许在不共享原始数据的情况下进行跨机构学习，从而在保护患者隐私的同时，实现数据的有效利用。文中指出，将PPFL集成到医疗生态系统中，可以促进形成一个真正意义上的LHS，即能够自我改进并持续优化未来医疗服务的网络。这需要医疗机构、研究者和政策制定者之间的紧密合作，共同构建安全、高效的数据共享框架，以支持临床决策和医学研究的发展。实现这一目标的关键在于平衡数据的利用与隐私保护，确保医疗信息的安全性和患者的权益得到充分尊重。 <div>
arXiv:2409.19756v1 Announce Type: new 
Abstract: The concept of a learning healthcare system (LHS) envisions a self-improving network where multimodal data from patient care are continuously analyzed to enhance future healthcare outcomes. However, realizing this vision faces significant challenges in data sharing and privacy protection. Privacy-Preserving Federated Learning (PPFL) is a transformative and promising approach that has the potential to address these challenges by enabling collaborative learning from decentralized data while safeguarding patient privacy. This paper proposes a vision for integrating PPFL into the healthcare ecosystem to achieve a truly LHS as defined by the Institute of Medicine (IOM) Roundtable.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-enhanced Integrity Verification in Educational Content Assessment Platform: A Lightweight and Cost-Efficient Approach</title>
<link>https://arxiv.org/abs/2409.19828</link>
<guid>https://arxiv.org/abs/2409.19828</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、电子平台、教育内容评估、Polygon网络、成本节约

总结:

本文提出了一种基于区块链技术的新型框架，用于增强电子平台（EPEC）的可信度和透明度。该框架旨在解决教育数字化过程中数据完整性和信任度问题，特别是针对教师专业活动评估的透明和安全需求。通过集成Polygon网络作为Ethereum的Layer-2解决方案，实现加密评论的安全存储与检索，同时保障隐私和责任。利用Python、Flask和Web3.py进行与Solidity智能合约的交互，确保每个评论与唯一标识符（UID）相关联，从而实现链上数据与现实数据库的无缝链接。借助Docker容器化部署，系统提供了易于部署和集成的API端点，显著降低了交易费用，与Ethereum相比减少了98%的gas费用。此研究对教育内容验证中的区块链应用具有重要意义，提供了一个实用、安全的框架，有效增强了数字教育环境中的信任与透明度。 <div>
arXiv:2409.19828v1 Announce Type: new 
Abstract: The growing digitization of education presents significant challenges in maintaining the integrity and trustworthiness of educational content. Traditional systems often fail to ensure data authenticity and prevent unauthorized alterations, particularly in the evaluation of teachers' professional activities, where demand for transparent and secure assessment mechanisms is increasing. In this context, Blockchain technology offers a novel solution to address these issues. This paper introduces a Blockchain-enhanced framework for the Electronic Platform for Expertise of Content (EPEC), a platform used for reviewing and assessing educational materials. Our approach integrates the Polygon network, a Layer-2 solution for Ethereum, to securely store and retrieve encrypted reviews, ensuring both privacy and accountability. By leveraging Python, Flask, and Web3.py, we interact with a Solidity-based smart contract to securely link each review to a unique identifier (UID) that connects on-chain data with real-world databases. The system, containerized using Docker, facilitates easy deployment and integration through API endpoints. Our implementation demonstrates significant cost savings, with a 98\% reduction in gas fees compared to Ethereum, making it a scalable and cost-effective solution. This research contributes to the ongoing effort to implement Blockchain in educational content verification, offering a practical and secure framework that enhances trust and transparency in the digital education landscape.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalizability of Graph Neural Networks for Decentralized Unlabeled Motion Planning</title>
<link>https://arxiv.org/abs/2409.19829</link>
<guid>https://arxiv.org/abs/2409.19829</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人系统、分散式策略、图神经网络（GNN）、集中式匈牙利算法、强化学习

<br />
<br />总结:
本文探讨了在多机器人系统中解决无标签运动规划问题的方法，即在确保碰撞避免的前提下，将一组机器人分配至目标位置，以最小化总移动距离。该问题在探索、监控和运输等应用中扮演着关键角色。研究在分散式环境中进行，其中每个机器人仅知晓其最近的$k$个机器人与目标的位置信息，这一设置结合了组合分配与连续空间路径规划的特点，对传统的集中式方法提出了重大挑战。为解决这些挑战，提出了一种基于图神经网络（GNN）的分散式策略。GNN使机器人能够决定与邻居交流的信息类型以及如何整合接收到的信息与本地观察结果以做出决策。通过模仿学习和专家政策（集中式匈牙利算法）进行训练，进一步使用强化学习优化策略以避免碰撞并提升性能。实验结果表明，该方法具有良好的可扩展性和有效性，所训练的GNN策略在100个机器人的情况下，可以扩展到最多500个机器人的情景，并在平均性能上优于现有最佳解决方案8.6%，远超简单的分散式贪心方法。这项工作为解决大规模多机器人协调问题提供了基础。 <div>
arXiv:2409.19829v1 Announce Type: new 
Abstract: Unlabeled motion planning involves assigning a set of robots to target locations while ensuring collision avoidance, aiming to minimize the total distance traveled. The problem forms an essential building block for multi-robot systems in applications such as exploration, surveillance, and transportation. We address this problem in a decentralized setting where each robot knows only the positions of its $k$-nearest robots and $k$-nearest targets. This scenario combines elements of combinatorial assignment and continuous-space motion planning, posing significant scalability challenges for traditional centralized approaches. To overcome these challenges, we propose a decentralized policy learned via a Graph Neural Network (GNN). The GNN enables robots to determine (1) what information to communicate to neighbors and (2) how to integrate received information with local observations for decision-making. We train the GNN using imitation learning with the centralized Hungarian algorithm as the expert policy, and further fine-tune it using reinforcement learning to avoid collisions and enhance performance. Extensive empirical evaluations demonstrate the scalability and effectiveness of our approach. The GNN policy trained on 100 robots generalizes to scenarios with up to 500 robots, outperforming state-of-the-art solutions by 8.6\% on average and significantly surpassing greedy decentralized methods. This work lays the foundation for solving multi-robot coordination problems in settings where scalability is important.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Plug and Play Distributed Secondary Controller for Microgrids with Grid-Forming Inverters</title>
<link>https://arxiv.org/abs/2409.19866</link>
<guid>https://arxiv.org/abs/2409.19866</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式控制器、微电网、电网形成逆变器、二次控制、硬件在环实验

总结:
本文介绍了一种为基于电网形成的逆变器资源的微电网设计的分布式控制器，用于解决二次控制问题。该控制器基于分布式优化技术，实现分布式合成与实施，使每个电网形成逆变器资源能够利用本地测量和通信网络中的邻域信息。文章提供了一种收敛性分析，以验证电压调节和无功功率共享的特性。通过控制器-硬件在环实验，评估了提出控制器的性能。实验结果证明了所提出的分布式控制器在二次控制方面的有效性。

文章的主要内容包括：
1. **控制器设计**：提出了一种基于分布式优化的控制器，旨在解决微电网中的二次控制问题。
2. **实现方式**：控制器的实现依赖于分布式合成和实施，允许每个电网形成逆变器资源利用本地信息进行操作。
3. **性能分析**：进行了收敛性分析，以确保控制器能够有效地执行电压调节和无功功率共享。
4. **实验验证**：通过控制器-硬件在环实验，实际验证了控制器的性能和有效性。
5. **结论**：实验结果表明，所设计的分布式控制器在微电网的二次控制方面具有良好的应用前景。 <div>
arXiv:2409.19866v1 Announce Type: new 
Abstract: A distributed controller for secondary control problems in microgrids with grid-forming (GFM) inverter-based resources (IBRs) is developed. The controller is based on distributed optimization and is synthesized and implemented distributively enabling each GFM IBR to utilize decentralized measurements and the neighborhood information in the communication network. We present a convergence analysis establishing voltage regulation and reactive power sharing properties. A controller-hardware-in-the-loop experiment is conducted to evaluate the performance of the proposed controller. The experimental results corroborate the efficacy of the proposed distributed controller for secondary control.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal RANDAO Manipulation in Ethereum</title>
<link>https://arxiv.org/abs/2409.19883</link>
<guid>https://arxiv.org/abs/2409.19883</guid>
<content:encoded><![CDATA[
<div> 关键词：RANDAO、操纵、以太坊、提案率、战略参与者

总结:

本文探讨了在以太坊网络中，如果攻击者控制了一定比例的代币，即“stake”，他们能够操纵RANDAO（随机性权威证明）机制的程度。RANDAO是用于生成区块头随机性的关键组件。文章提出了计算方法，以确定攻击者拥有不同比例stake时，能控制的轮次提案比例的最大值。这种方法考虑了攻击者对最后几个周期的提案者进行操纵的可能性。

具体来说，作者通过数学建模和分析，得出结论：

- 拥有5% stake的战略参与者理论上可以控制约5.048%的提案。
- 当该比例增加到10%，攻击者理论上可以控制约10.19%的提案。
- 对于20%的stake，理论上的控制比例提高至约20.68%。

这些发现揭示了在以太坊网络中，即使在相对分散的系统下，通过集中stake也能实现对关键流程的操纵，从而影响区块链的安全性和公平性。这强调了加强系统安全机制和提高抗攻击能力的重要性。 <div>
arXiv:2409.19883v1 Announce Type: new 
Abstract: It is well-known that RANDAO manipulation is possible in Ethereum if an adversary controls the proposers assigned to the last slots in an epoch. We provide a methodology to compute, for any fraction $\alpha$ of stake owned by an adversary, the maximum fraction $f(\alpha)$ of rounds that a strategic adversary can propose. We further implement our methodology and compute $f(\cdot)$ for all $\alpha$. For example, we conclude that an optimal strategic participant with $5\%$ of the stake can propose a $5.048\%$ fraction of rounds, $10\%$ of the stake can propose a $10.19\%$ fraction of rounds, and $20\%$ of the stake can propose a $20.68\%$ fraction of rounds.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Pre-trained Models for Robust Federated Learning for Kidney Stone Type Recognition</title>
<link>https://arxiv.org/abs/2409.19934</link>
<guid>https://arxiv.org/abs/2409.19934</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、医疗影像、联邦学习、肾结石诊断、数据隐私

<br />
<br />
总结:
文章探讨了深度学习在医疗影像诊断领域的应用，特别是通过改进模型准确度来提升肾结石诊断效率。然而，面对数据量庞大和数据交换法律限制的挑战，研究提出联邦学习（FL）作为一种解决方案，它允许在不共享原始数据的情况下进行模型训练，从而保护数据隐私。但同时，FL模型面临数据污染的风险，可能影响其性能。

为解决这一问题，研究中引入了一种结合预训练模型与FL的新框架，旨在提高诊断准确性并增强对图像污染的鲁棒性。实验采用两个包含六类不同图像的肾结石数据集，结果显示，在学习参数优化阶段（LPO），模型达到84.1%的峰值准确率；而在联邦鲁棒验证阶段（FRV），准确率为77.2%，表明该方法有效提升了诊断精度和鲁棒性。

这项研究强调了将预训练模型与FL相结合的重要性，以解决医疗诊断中的隐私和性能问题，从而促进更优质的患者护理并增强公众对基于FL的医疗系统的信任。 <div>
arXiv:2409.19934v1 Announce Type: new 
Abstract: Deep learning developments have improved medical imaging diagnoses dramatically, increasing accuracy in several domains. Nonetheless, obstacles continue to exist because of the requirement for huge datasets and legal limitations on data exchange. A solution is provided by Federated Learning (FL), which permits decentralized model training while maintaining data privacy. However, FL models are susceptible to data corruption, which may result in performance degradation. Using pre-trained models, this research suggests a strong FL framework to improve kidney stone diagnosis. Two different kidney stone datasets, each with six different categories of images, are used in our experimental setting. Our method involves two stages: Learning Parameter Optimization (LPO) and Federated Robustness Validation (FRV). We achieved a peak accuracy of 84.1% with seven epochs and 10 rounds during LPO stage, and 77.2% during FRV stage, showing enhanced diagnostic accuracy and robustness against image corruption. This highlights the potential of merging pre-trained models with FL to address privacy and performance concerns in medical diagnostics, and guarantees improved patient care and enhanced trust in FL-based medical systems.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DBNode: A Decentralized Storage System for Big Data Storage in Consortium Blockchains</title>
<link>https://arxiv.org/abs/2409.20123</link>
<guid>https://arxiv.org/abs/2409.20123</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、存储系统、Hyperledger Fabric、数据隐私、访问控制

<br /><br />
总结:

本文提出了一种专为Hyperledger Fabric设计的去中心化存储系统。Hyperledger Fabric作为知名的合作区块链平台，具有独特属性如数据隐私和访问控制需求。为解决直接将大数据存储于区块链上的挑战，文章采用错误校正编码对文件进行分割，并构建层次结构以实现高效稳定的数据存储。同时，通过双层哈希槽机制与镜像策略确保高数据可用性。此外，基于智能合约设计了访问控制机制，以管理文件访问权限，满足Hyperledger Fabric特定需求，提升整体性能并保障数据安全。此存储系统旨在优化合作区块链环境下的数据存储与管理，兼顾性能与隐私保护。 <div>
arXiv:2409.20123v1 Announce Type: new 
Abstract: Storing big data directly on a blockchain poses a substantial burden due to the need to maintain a consistent ledger across all nodes. Numerous studies in decentralized storage systems have been conducted to tackle this particular challenge. Most state-of-the-art research concentrates on developing a general storage system that can accommodate diverse blockchain categories. However, it is essential to recognize the unique attributes of a consortium blockchain, such as data privacy and access control. Beyond ensuring high performance, these specific needs are often overlooked by general storage systems. This paper proposes a decentralized storage system for Hyperledger Fabric, which is a well-known consortium blockchain. First, we employ erasure coding to partition files, subsequently organizing these chunks into a hierarchical structure that fosters efficient and dependable data storage. Second, we design a two-layer hash-slots mechanism and a mirror strategy, enabling high data availability. Third, we design an access control mechanism based on a smart contract to regulate file access.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARLadona -- Towards Cooperative Team Play Using Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.20326</link>
<guid>https://arxiv.org/abs/2409.20326</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、MARLadona、深度学习、机器人足球、全球实体编码器

总结:

本文介绍了一种名为MARLadona的新方法，它利用多智能体强化学习（MARL）为机器人足球提供了一种更高级的团队协作策略。与传统的工程启发式策略相比，这种方法更加稳健和适应性强。通过使用一种基于深度学习的框架，MARLadona能够生成具有复杂团队行为的智能体，这在当前的机器人足球研究中是一个显著的进步。

为了验证MARLadona的有效性，作者们创建了一个基于Isaac Gym的开源多智能体足球环境。在这个环境中，他们将MARLadona与一个采用最先进的启发式策略的HELIOS智能体进行了对比。结果显示，MARLadona的智能体在对抗HELIOS时取得了66.8%的胜率，这表明其策略的优越性。

此外，文章还对MARLadona智能体的行为进行了深入分析，并通过批评网络解释了智能体的意图，提供了对策略决策过程的洞察。这一分析不仅有助于理解智能体如何做出决策，也为进一步改进和优化MARLadona提供了指导。整体而言，MARLadona代表了机器人足球领域的一个重要进展，展示了深度学习技术在解决复杂任务中的潜力。 <div>
arXiv:2409.20326v1 Announce Type: new 
Abstract: Robot soccer, in its full complexity, poses an unsolved research challenge. Current solutions heavily rely on engineered heuristic strategies, which lack robustness and adaptability. Deep reinforcement learning has gained significant traction in various complex robotics tasks such as locomotion, manipulation, and competitive games (e.g., AlphaZero, OpenAI Five), making it a promising solution to the robot soccer problem. This paper introduces MARLadona. A decentralized multi-agent reinforcement learning (MARL) training pipeline capable of producing agents with sophisticated team play behavior, bridging the shortcomings of heuristic methods. Further, we created an open-source multi-agent soccer environment based on Isaac Gym. Utilizing our MARL framework and a modified a global entity encoder as our core architecture, our approach achieves a 66.8% win rate against HELIOS agent, which employs a state-of-the-art heuristic strategy. Furthermore, we provided an in-depth analysis of the policy behavior and interpreted the agent's intention using the critic network.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials</title>
<link>https://arxiv.org/abs/2401.11735</link>
<guid>https://arxiv.org/abs/2401.11735</guid>
<content:encoded><![CDATA[
<div> 关键词：zkLogin、零知识证明（ZKP）、身份令牌、Sui区块链、数字内容验证

总结:
文章主要介绍了zkLogin，一种新型技术，旨在简化区块链应用的用户认证过程。通过利用主流平台提供的OpenID Connect身份令牌，zkLogin允许用户使用现有账户进行交易认证，无需记忆额外秘密，显著提升用户体验。其核心是结合签名方案和零知识证明，确保安全性和隐私性，同时依赖于平台的认证机制，无需额外信任方。zkLogin不仅适用于区块链场景，还能让数十亿用户利用现有数字身份生产可验证的数字内容，如通过电子邮件地址签署新闻文章，实现作者身份的透明验证。该技术已在Sui区块链上实施并部署，提供了一种替代传统数字签名地址的方案。 <div>
arXiv:2401.11735v2 Announce Type: replace 
Abstract: For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications.
  We develop zkLogin, a novel technique that leverages identity tokens issued by popular platforms (any OpenID Connect enabled platform e.g., Google, Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a signature scheme allowing the signer to sign using their existing OpenID accounts and nothing else. This improves the user experience significantly as users do not need to remember a new secret and can reuse their existing accounts.
  zkLogin provides strong security and privacy guarantees. Unlike prior works, zkLogin's security relies solely on the underlying platform's authentication mechanism without the need for any additional trusted parties (e.g., trusted hardware or oracles). As the name suggests, zkLogin leverages zero-knowledge proofs (ZKP) to ensure that the sensitive link between a user's off-chain and on-chain identities is hidden, even from the platform itself.
  zkLogin enables a number of important applications outside blockchains. It allows billions of users to produce \textit{verifiable digital content leveraging their existing digital identities}, e.g., email address. For example, a journalist can use zkLogin to sign a news article with their email address, allowing verification of the article's authorship by any party.
  We have implemented and deployed zkLogin on the Sui blockchain as an additional alternative to traditional digital signature-based addresses.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAVED: Data Acquisition via Experimental Design for Data Markets</title>
<link>https://arxiv.org/abs/2403.13893</link>
<guid>https://arxiv.org/abs/2403.13893</guid>
<content:encoded><![CDATA[
<div> 关键词：数据市场、数据收购、联邦学习、预测误差、数据估值

总结:
本文探讨了在数据市场环境下，如何高效地进行数据收购以提升机器学习应用的性能。主要贡献包括：
1. 提出了基于联邦学习框架的数据收购方法，旨在解决数据稀缺领域如医疗保健中数据供应不足的问题。
2. 与传统数据估值方法不同，该方法不依赖于集中化数据访问，而是采用激励机制吸引潜在数据提供者加入市场。
3. 方法通过直接估计收购数据对测试集预测的影响来选择最有价值的数据点，这与当前市场设置高度兼容。
4. 实现了无需额外标注验证数据的低预测误差目标，优化过程快速且分布式，有助于提高数据利用效率。
5. 该研究揭示了在分散式市场环境中，一种直接评估数据获取对测试集预测效果的方法特别适用，为数据买家提供了策略上的指导。 <div>
arXiv:2403.13893v2 Announce Type: replace 
Abstract: The acquisition of training data is crucial for machine learning applications. Data markets can increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data providers to join the market. A major challenge for a data buyer in such a market is choosing the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data acquisition problem that is inspired by linear experimental design. Our proposed data acquisition method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hypergraph Approach to Distributed Broadcast</title>
<link>https://arxiv.org/abs/2404.16376</link>
<guid>https://arxiv.org/abs/2404.16376</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式广播、网络通信、超图理论、数据共享、算法优化

<br /><br />
总结:本文深入探讨了网络通信中的分布式广播问题，这是分散式信息传播的关键挑战。通过提出一种基于超图的新颖方法，旨在最小化广播次数以确保所有网络用户的全面数据共享。主要贡献包括使用超图的最小割容量建立问题的一般下限，以及为具有独特结构的准树设计的分布式广播算法（DBQT），证明其为最优解。这项研究不仅推进了网络通信策略和超图理论的发展，而且对各种实际应用具有重要意义，例如车用网络、传感器网络和分布式存储系统等。通过优化数据传输过程，提高了网络效率和资源利用率，为未来复杂网络环境下的信息传播提供了理论基础和实践指导。 <div>
arXiv:2404.16376v2 Announce Type: replace 
Abstract: This paper explores the distributed broadcast problem within the context of network communications, a critical challenge in decentralized information dissemination. We put forth a novel hypergraph-based approach to address this issue, focusing on minimizing the number of broadcasts to ensure comprehensive data sharing among all network users. The key contributions of this work include the establishment of a general lower bound for the problem using the min-cut capacity of hypergraphs, and a distributed broadcast for quasi-trees (DBQT) algorithm tailored for the unique structure of quasi-trees, which is proven to be optimal. This paper advances both network communication strategies and hypergraph theory, with implications for a wide range of real-world applications, from vehicular and sensor networks to distributed storage systems.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable UTXO Smart Contracts via Fine-Grained Distributed State</title>
<link>https://arxiv.org/abs/2406.07700</link>
<guid>https://arxiv.org/abs/2406.07700</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、UTXO模型、效率瓶颈、分布式状态、并行化验证

总结:

文章探讨了基于UTXO模型的智能合约平台所面临的效率问题，即任何发送给合约的交易都必须指定整个更新后的合约状态。这种需求在许多应用场景中变得尤为棘手，尤其是当合约状态包含动态数据结构时，用于追踪用户与合约之间的交互。问题主要体现在两个方面：一方面，交易中的大状态意味着高昂的交易费用；另一方面，大集中式状态阻碍了交易的并行化，这是UTXO区块链相对于账户型区块链的一大优势。

为了解决这个问题，文章提出了一种技术，允许在扩展的UTXO区块链上执行智能合约，使得合约状态可以分布在多个UTXO中。这样一来，交易只需要指定需要访问的部分状态，从而减少了交易大小（和费用）。作者展示了如何利用此模型在多核CPU上并行化交易验证过程，并实施了该技术，提供了其有效性的实证验证。通过这种方式，不仅降低了交易成本，还提高了系统性能和可扩展性。 <div>
arXiv:2406.07700v2 Announce Type: replace 
Abstract: Smart contract platforms based on the UTXO model face an efficiency bottleneck, in that any transaction sent to a contract must specify the entire updated contract state. This requirement becomes particularly burdensome when the contract state contains dynamic data structures, as needed in many use cases to track interactions between users and the contract. The problem is twofold: on the one hand, a large state in transactions implies a large transaction fee; on the other hand, a large centralized state is detrimental to the parallelization of transactions -- a feature that is often cited as a key advantage of UTXO-based blockchains over account-based ones. We propose a technique to efficiently execute smart contracts on an extended UTXO blockchain, which allows the contract state to be distributed across multiple UTXOs. In this way, transactions only need to specify the part of the state they need to access, reducing their size (and fees). We show how to exploit our model to parallelize the validation of transactions on multi-core CPUs. We implement our technique and provide an empirical validation of its effectiveness.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence</title>
<link>https://arxiv.org/abs/2301.05872</link>
<guid>https://arxiv.org/abs/2301.05872</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、压缩梯度方法、适应性步长、强凸性函数、非凸性函数

<br /><br />
总结:
本文研究了在通信受限环境下的多代理网络分布式优化问题。提出了“压缩精确扩散与自适应步长（CEDAS）”方法，这是一种压缩分散随机梯度方法。在无偏压缩操作下，CEDAS方法能够实现与集中式随机梯度下降（SGD）相似的收敛率，适用于平滑强凸目标函数和平滑非凸目标函数。特别地，当目标函数为平滑强凸时，CEDAS的暂态时间（与图特性相关）较短，表现为$\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$；对于平滑非凸目标函数，暂态时间为$\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$，其中$(1-\lambda_2)$表示混合矩阵的谱间隙，$C>0$是压缩相关的参数。当$C < \mathcal{O}(1/(1 - \lambda_2)^2)$时，CEDAS表现出最短的暂态时间，这一情况在实践中常见。数值实验进一步验证了所提算法的有效性。

<br /><br /> <div>
arXiv:2301.05872v3 Announce Type: replace-cross 
Abstract: In this paper, we consider solving the distributed optimization problem over a multi-agent network under the communication restricted setting. We study a compressed decentralized stochastic gradient method, termed ``compressed exact diffusion with adaptive stepsizes (CEDAS)", and show the method asymptotically achieves comparable convergence rate as centralized { stochastic gradient descent (SGD)} for both smooth strongly convex objective functions and smooth nonconvex objective functions under unbiased compression operators. In particular, to our knowledge, CEDAS enjoys so far the shortest transient time (with respect to the graph specifics) for achieving the convergence rate of centralized SGD, which behaves as $\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$ under smooth strongly convex objective functions, and $\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$ under smooth nonconvex objective functions, where $(1-\lambda_2)$ denotes the spectral gap of the mixing matrix, and $C>0$ is the compression-related parameter. In particular, CEDAS exhibits the shortest transient times when $C < \mathcal{O}(1/(1 - \lambda_2)^2)$, which is common in practice. Numerical experiments further demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Architecture for Protecting Data Privacy in Decentralized Social Networks</title>
<link>https://arxiv.org/abs/2409.18360</link>
<guid>https://arxiv.org/abs/2409.18360</guid>
<content:encoded><![CDATA[
<div> 关键词：分散式社交网络、区块链技术、分散式储存网络、存取控制智能合约、用户隐私保护

<br /><br />
总结:

本文主要探讨了分散式社交网络的构建与应用，特别是通过结合区块链技术与分散式储存网络，并利用存取控制智能合约，以期解决传统集中式社交网络所面临的信息安全与隐私保护问题。研究首先进行了深入的文献回顾，对现有分散式社交网络进行分析，并指出其在隐私保护、数据控制权等方面的优点与局限性。

在回顾的基础上，作者提出了一种新的分散式社交网络架构设计，旨在为用户提供更强的数据主权和隐私保护。该架构通过区块链技术确保信息的不可篡改性与透明度，利用分散式储存网络降低数据存储成本和提高数据安全性，同时，存取控制智能合约则确保用户对其发布的信息有完全的控制权，符合通用数据保护条例（GDPR）的要求。

研究的主要成果强调了分散式社交网络在保护用户隐私方面的潜力，相较于传统集中式平台，用户能够更自主地管理自己的信息，享有更高的数据控制权。此外，该架构也展示了在实现高效、安全的信息分享的同时，兼顾了用户对隐私的保护需求，为未来社交网络的发展提供了一个可行的方向。 <div>
arXiv:2409.18360v1 Announce Type: new 
Abstract: Centralized social networks have experienced a transformative impact on our digital era communication, connection, and information-sharing information. However, it has also raised significant concerns regarding users' privacy and individual rights. In response to these concerns, this paper proposes a novel Decentralized Social Network employing Blockchain technology and Decentralized Storage Networks completed by Access Control Smart Contracts. The initial phase comprises a comprehensive literature review, delving into decentralized social networks, explaining the review methodology, and presenting the resulting findings. Building upon these findings and an analysis of previous research gaps, we propose a novel architecture for decentralized social networks. In conclusion, the principal results highlight the benefit of our decentralized social network to protect user privacy. Moreover, the users have all rights to their posted information following the General Data Protection Regulation (GDPR).
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Review of Digital Asset Development with Graph Neural Network Unlearning</title>
<link>https://arxiv.org/abs/2409.18455</link>
<guid>https://arxiv.org/abs/2409.18455</guid>
<content:encoded><![CDATA[
<div> 关键词：Graph Neural Networks、数据隐私、合规性、机器学习、数字资产

总结:
本文探讨了图神经网络（GNN）在数字资产管理中的关键作用，并引入了针对GNN架构的创新卸载技术。研究将卸载策略分为两大类：数据驱动的近似和模型驱动的近似。数据驱动的近似通过调整图结构来隔离并移除特定节点的影响；而模型驱动的近似则修改GNN的内部参数和架构。文章通过分析这些卸载方法的最新进展，强调了它们在欺诈检测、风险评估、代币关系预测和去中心化治理等应用场景中的适用性。同时，文章讨论了在实时金融应用中平衡模型性能与数据卸载需求的挑战。为了解决这一问题，提出了结合两种卸载策略优势的混合方法，以提高GNN在数字资产生态系统中的效率和有效性。最终目标是提供一个全面框架，用于理解并实施GNN卸载技术，为机器学习在数字资产领域的安全合规部署铺平道路。 <div>
arXiv:2409.18455v1 Announce Type: new 
Abstract: In the rapidly evolving landscape of digital assets, the imperative for robust data privacy and compliance with regulatory frameworks has intensified. This paper investigates the critical role of Graph Neural Networks (GNNs) in the management of digital assets and introduces innovative unlearning techniques specifically tailored to GNN architectures. We categorize unlearning strategies into two primary classes: data-driven approximation, which manipulates the graph structure to isolate and remove the influence of specific nodes, and model-driven approximation, which modifies the internal parameters and architecture of the GNN itself. By examining recent advancements in these unlearning methodologies, we highlight their applicability in various use cases, including fraud detection, risk assessment, token relationship prediction, and decentralized governance. We discuss the challenges inherent in balancing model performance with the requirements for data unlearning, particularly in the context of real-time financial applications. Furthermore, we propose a hybrid approach that combines the strengths of both unlearning strategies to enhance the efficiency and effectiveness of GNNs in digital asset ecosystems. Ultimately, this paper aims to provide a comprehensive framework for understanding and implementing GNN unlearning techniques, paving the way for secure and compliant deployment of machine learning in the digital asset domain.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartReco: Detecting Read-Only Reentrancy via Fine-Grained Cross-DApp Analysis</title>
<link>https://arxiv.org/abs/2409.18468</link>
<guid>https://arxiv.org/abs/2409.18468</guid>
<content:encoded><![CDATA[
<div> 关键词：SmartReco、Read-Only Reentrancy、DApps、智能合约、漏洞检测

总结:
本文提出了一种名为SmartReco的新框架，用于检测去中心化应用（DApps）中的读取只读重入（ROR）漏洞。SmartReco结合了静态分析和动态分析（即模糊测试）来检测智能合约中的漏洞。其核心设计包括：识别不同DApps之间的边界；对关键点进行精细静态分析；利用链上交易数据跨多个DApps执行多函数模糊测试验证ROR的存在。通过评估包含45个ROR的手动标记数据集，SmartReco实现了88.63%的精确度和86.36%的召回率。此外，SmartReco成功检测到123个流行DApps中的43个新ROR，受影响的资产总额约为52万美元。这表明SmartReco在提高DApps安全性方面具有显著潜力，能够有效识别和检测导致重大经济损失的新型漏洞。 <div>
arXiv:2409.18468v1 Announce Type: new 
Abstract: Despite the increasing popularity of Decentralized Applications (DApps), they are suffering from various vulnerabilities that can be exploited by adversaries for profits. Among such vulnerabilities, Read-Only Reentrancy (called ROR in this paper), is an emerging type of vulnerability that arises from the complex interactions between DApps. In the recent three years, attack incidents of ROR have already caused around 30M USD losses to the DApp ecosystem. Existing techniques for vulnerability detection in smart contracts can hardly detect Read-Only Reentrancy attacks, due to the lack of tracking and analyzing the complex interactions between multiple DApps. In this paper, we propose SmartReco, a new framework for detecting Read-Only Reentrancy vulnerability in DApps through a novel combination of static and dynamic analysis (i.e., fuzzing) over smart contracts. The key design behind SmartReco is threefold: (1) SmartReco identifies the boundary between different DApps from the heavy-coupled cross-contract interactions. (2) SmartReco performs fine-grained static analysis to locate points of interest (i.e., entry functions) that may lead to ROR. (3) SmartReco utilizes the on-chain transaction data and performs multi-function fuzzing (i.e., the entry function and victim function) across different DApps to verify the existence of ROR. Our evaluation of a manual-labeled dataset with 45 RORs shows that SmartReco achieves a precision of 88.63% and a recall of 86.36%. In addition, SmartReco successfully detects 43 new RORs from 123 popular DApps. The total assets affected by such RORs reach around 520,000 USD.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.18718</link>
<guid>https://arxiv.org/abs/2409.18718</guid>
<content:encoded><![CDATA[
<div> 关键词：GAIL、NTN、RL、IRL、Federated Learning

<br />
总结:

本文提出了一种基于生成对抗式模仿学习（GAIL）的新型策略学习方法，用于优化非地面网络（NTN）中的波束形成、频谱分配和远程用户设备（RUE）关联。该方法通过集成逆强化学习（IRL）与异步联邦学习，旨在最大化频谱效率（SE），同时满足RUE的最小信息速率要求。为了解决该问题的非凸性与NP-hard性质，引入了多对一匹配理论结合多代理异步联邦IRL（MA-AFIRL）框架。这种方法允许代理通过异步环境交互学习，提高了训练效率和可扩展性。

为了生成专家策略，使用鲸鱼优化算法（WOA）进行训练，以此作为GAIL框架中自动奖励函数的训练数据。实验结果表明，提出的MA-AFIRL方法在收敛速度和奖励值上相较于传统强化学习方法有14.6%的提升，这标志着6G NTN优化领域的一个新的基准。

本文的贡献在于提出了一种自动化、高效、可扩展的NTN优化策略学习方法，通过GAIL和联邦学习技术克服了传统RL方法的局限性，显著提高了网络性能并降低了人工设计奖励函数的复杂度。 <div>
arXiv:2409.18718v1 Announce Type: new 
Abstract: In this paper, a novel generative adversarial imitation learning (GAIL)-powered policy learning approach is proposed for optimizing beamforming, spectrum allocation, and remote user equipment (RUE) association in NTNs. Traditional reinforcement learning (RL) methods for wireless network optimization often rely on manually designed reward functions, which can require extensive parameter tuning. To overcome these limitations, we employ inverse RL (IRL), specifically leveraging the GAIL framework, to automatically learn reward functions without manual design. We augment this framework with an asynchronous federated learning approach, enabling decentralized multi-satellite systems to collaboratively derive optimal policies. The proposed method aims to maximize spectrum efficiency (SE) while meeting minimum information rate requirements for RUEs. To address the non-convex, NP-hard nature of this problem, we combine the many-to-one matching theory with a multi-agent asynchronous federated IRL (MA-AFIRL) framework. This allows agents to learn through asynchronous environmental interactions, improving training efficiency and scalability. The expert policy is generated using the Whale optimization algorithm (WOA), providing data to train the automatic reward function within GAIL. Simulation results show that the proposed MA-AFIRL method outperforms traditional RL approaches, achieving a $14.6\%$ improvement in convergence and reward value. The novel GAIL-driven policy learning establishes a novel benchmark for 6G NTN optimization.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Drawing the boundaries between Blockchain and Blockchain-like systems: A Comprehensive Survey on Distributed Ledger Technologies</title>
<link>https://arxiv.org/abs/2409.18799</link>
<guid>https://arxiv.org/abs/2409.18799</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、区块链、分类、参考模型、挑战

<br /><br />
总结:

本文是对区块链及其类似系统进行的一次全面的回顾和分类。首先，文章提出了一种以数据、共识、执行和应用四个关键层为基础的参考模型，为理解区块链的不同方面提供了一个框架。其次，引入了一种新的分类体系，旨在更准确地界定和区分各种分布式账本技术(DLT)和共识机制。通过对比分析44个DLT解决方案和26种共识机制，研究揭示了当前领域面临的几个主要挑战，并为未来的学术研究提供了方向。

这一研究有助于澄清“区块链”这一术语在不同系统中的应用，指出哪些系统遵循了区块链的核心原则，而哪些则偏离了这些原则，增加了生态系统中技术多样性和复杂性。此外，它强调了需要进一步研究的关键领域，以便更好地理解、设计和优化DLT和共识机制，从而推动区块链技术的发展与应用。 <div>
arXiv:2409.18799v1 Announce Type: new 
Abstract: Bitcoin's global success has led to the rise of blockchain, but many systems labeled as "blockchain" deviate from its core principles, adding complexity to the ecosystem. This survey addresses the need for a comprehensive review and taxonomy to clarify the differences between blockchain and blockchain-like systems. We propose a reference model with four key layers: data, consensus, execution, and application, and introduce a new taxonomy for better classification. Through a qualitative and quantitative analysis of 44 DLT solutions and 26 consensus mechanisms, we highlight key challenges and offer research directions in the field.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.18862</link>
<guid>https://arxiv.org/abs/2409.18862</guid>
<content:encoded><![CDATA[
<div> 关键词：安全控制、分散式多代理机器人、不确定黑盒模型、决策理论、控制障碍函数

<br /><br />
总结:本文聚焦于分散式多代理机器人环境中的安全控制问题，特别关注于利用不确定的黑盒模型预测其他代理行为轨迹的挑战。研究团队引入了近期提出的形变决策理论，以此来调整基于控制障碍函数的安全约束的严格程度，这些约束依赖于观察到的预测误差。通过这种方法，他们能够合成控制器，以平衡安全性和任务完成度之间的目标，即使存在预测误差。

为了验证理论的有效性，研究者们提供了时间平均值的上界，该值衡量了基于预测轨迹和实际轨迹的安全约束之间差别的单调函数价值。实验结果展示了在斯坦福无人机数据集中导航机器人时，所提出控制器的表现，证实了该方法在实际场景中的应用潜力与效果。

此研究为分散式多代理系统中的安全控制提供了一种新颖的方法，通过结合预测误差的动态适应性和任务目标的优化，旨在提高复杂环境下的机器人自主操作安全性。 <div>
arXiv:2409.18862v1 Announce Type: new 
Abstract: We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>XDC Gasless Subnet: Gasless Subnet Staking dApp for XDC Network</title>
<link>https://arxiv.org/abs/2409.17176</link>
<guid>https://arxiv.org/abs/2409.17176</guid>
<content:encoded><![CDATA[
<div> 关键词：XDPoS共识机制、XDC网络、低能耗、高效交易、无gas费

总结:

本文主要介绍了XDC网络，一个专注于企业应用的区块链平台。它结合了公共和私有区块链的优势，提供快速交易时间、低能耗和经济的气体费用。XDC设计用于互操作性，支持去中心化应用程序(dApps)，并能平滑地与金融系统集成。特别适合贸易融资和实物资产代币化，由于其强调安全性和可扩展性。

然而，文章指出了一些限制因素，阻碍了某些高频应用的广泛接受和使用。为解决这一问题，提出了一种创新的去中心化应用(dApp)，旨在创建一个无需gas费的子网。用户可以在主网上质押XDC，生成一个类似于非加密网络的子网，接受XDC网络上的货币费用。这使得质押过程更有效率、成本效益更高，并同时增强可扩展性。性能评估显示，在吞吐量、延迟、可扩展性、安全性和成本效率方面都有出色的结果。此外，文章讨论了此方法的应用案例、挑战以及应对策略。 <div>
arXiv:2409.17176v1 Announce Type: new 
Abstract: With a delegated proof-of-stake (XDPoS) consensus mechanism, the XDC Network is an enterprise-focused blockchain platform that combines the strength of public and private blockchains to provide quick transaction times, low energy consumption, and economical gas fees. XDC is designed for interoperability and supports decentralized apps (dApps) and integrates smoothly with financial systems. It is perfect for trade financing and tokenisation of physical assets because of its emphasis on security and scalability. However, there are a few critical issues that hamper wider acceptance and usability for certain high-frequency applications. This whitepaper introduces a novel and enthralling dApp for establishing a gasless subnet in which mainnet XDC can be staked to spin off a subnet that functions similarly to a non-crypto network, accepting currency fees on the XDC network. This would allow users to stake their tokens without incurring gas fees making the staking process more efficient, cost-effective, and simultaneously enhancing scalability. Performance evaluation of the dApp shows promising results in terms of throughput, latency, scalability, security, and cost efficiency. The use cases and applications of this approach along with challenges and ensuing solutions are included.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled Variational Information Bottleneck for Data Extraction Based on Mutual Information in Internet of Vehicles</title>
<link>https://arxiv.org/abs/2409.17287</link>
<guid>https://arxiv.org/abs/2409.17287</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、车辆网络（IoV）、数据压缩、VIB技术、安全性增强

总结:

本文探讨了将区块链技术与车辆网络（IoV）结合的应用，以解决IoV网络中的计算资源限制和数据处理能力问题，同时加强用户隐私保护。文章提出了名为BVIB（Blockchain and VIB）的新方法，旨在减轻计算负载并增强网络安全性。BVIB通过分离编码和解码网络来解决计算负担问题，并提出了一种新的算法来提高IoV网络的安全性。研究还分析了数据提取率对系统延迟的影响，以确定最佳的数据提取率。为验证BVIB的有效性，构建了一个结合Python和C++的实验框架。全面的模拟研究表明，与基础方法相比，BVIB在多个指标上表现出色。

文章主要贡献如下：

1. **区块链与VIB技术整合**：BVIB方法将区块链技术与VIB（一种用于训练编码和解码模型的技术）相结合，以优化IoV网络的数据处理和传输。

2. **减轻计算负担**：通过分离编码和解码网络，BVIB设计减少了每个车辆需要处理的数据量，从而减轻了计算负担。

3. **增强网络安全**：BVIB不仅优化了数据传输效率，还通过引入区块链机制提高了网络的整体安全性，防止数据泄露和篡改。

4. **数据提取率优化**：文章研究了不同数据提取率对系统性能的影响，为实际应用提供了指导，确保在保证数据传输效率的同时，达到最佳的系统响应速度。

5. **实验验证与模拟研究**：通过构建实验框架并进行模拟研究，证明了BVIB方法在提升IoV网络效率和安全性方面的有效性。 <div>
arXiv:2409.17287v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV) network can address the issue of limited computing resources and data processing capabilities of individual vehicles, but it also brings the risk of privacy leakage to vehicle users. Applying blockchain technology can establish secure data links within the IoV, solving the problems of insufficient computing resources for each vehicle and the security of data transmission over the network. However, with the development of the IoV, the amount of data interaction between multiple vehicles and between vehicles and base stations, roadside units, etc., is continuously increasing. There is a need to further reduce the interaction volume, and intelligent data compression is key to solving this problem. The VIB technique facilitates the training of encoding and decoding models, substantially diminishing the volume of data that needs to be transmitted. This paper introduces an innovative approach that integrates blockchain with VIB, referred to as BVIB, designed to lighten computational workloads and reinforce the security of the network. We first construct a new network framework by separating the encoding and decoding networks to address the computational burden issue, and then propose a new algorithm to enhance the security of IoV networks. We also discuss the impact of the data extraction rate on system latency to determine the most suitable data extraction rate. An experimental framework combining Python and C++ has been established to substantiate the efficacy of our BVIB approach. Comprehensive simulation studies indicate that the BVIB consistently excels in comparison to alternative foundational methodologies.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Nonlinear Model Predictive Control for Safe Collision Avoidance in Quadrotor Teams with Limited Detection Range</title>
<link>https://arxiv.org/abs/2409.17379</link>
<guid>https://arxiv.org/abs/2409.17379</guid>
<content:encoded><![CDATA[
<div> 关键词：多旋翼系统、分散式控制、安全保证、动作约束、感知范围限制

总结:

本文主要探讨了多旋翼系统在分散式控制下的挑战，特别是安全性和协调性，当面临传感和通信限制时。当前的方法通常依赖于控制障碍函数（CBFs）来提供安全性保障，但往往忽视了动作约束和有限的检测范围。为解决这一问题，研究团队提出了一种新的分散式非线性模型预测控制（NMPC），该方法整合了指数CBF（ECBFs），以增强多旋翼系统的安全性和优化性能。

通过设置保守和实用的最小范围界限，以保持ECBFs的安全性，研究者确保了系统在实际应用中的可靠性。他们进行了大量模拟实验，涉及多达10个旋翼体和20个障碍物，并通过现实世界的实验验证了3个旋翼体的可行性。结果表明，所提出的方法在真实场景中表现良好，显示出其在可靠多旋翼团队操作中的潜力。

这一研究不仅扩展了CBFs的应用范围，还为多旋翼系统的分散式控制提供了更安全、更高效的技术路径，对未来的无人机团队操作具有重要意义。 <div>
arXiv:2409.17379v1 Announce Type: new 
Abstract: Multi-quadrotor systems face significant challenges in decentralized control, particularly with safety and coordination under sensing and communication limitations. State-of-the-art methods leverage Control Barrier Functions (CBFs) to provide safety guarantees but often neglect actuation constraints and limited detection range. To address these gaps, we propose a novel decentralized Nonlinear Model Predictive Control (NMPC) that integrates Exponential CBFs (ECBFs) to enhance safety and optimality in multi-quadrotor systems. We provide both conservative and practical minimum bounds of the range that preserve the safety guarantees of the ECBFs. We validate our approach through extensive simulations with up to 10 quadrotors and 20 obstacles, as well as real-world experiments with 3 quadrotors. Results demonstrate the effectiveness of the proposed framework in realistic settings, highlighting its potential for reliable quadrotor teams operations.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Hierarchical Gradient Tracking Algorithm for Mitigating Subnet-Drift in Fog Learning Networks</title>
<link>https://arxiv.org/abs/2409.17430</link>
<guid>https://arxiv.org/abs/2409.17430</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Semi-decentralized FL、Gradient Tracking、Convergence、Efficiency

<br /><br />
总结:
本文主要探讨了在雾网络环境下，传统星型拓扑架构的联邦学习(Federated Learning, FL)所面临的可扩展性问题。针对基于设备到设备(D2D)通信的网络，提出了一种称为半去中心化联邦学习(Semi-decentralized Federated Learning, SD-FL)的方法。SD-FL将模型协作分为两个阶段：下层利用D2D通信在子网络内进行局部模型聚合，上层则负责设备到服务器(DEVICE-SERVER, DS)通信以实现全局模型聚合。然而，现有的SD-FL方案依赖于梯度多样性假设，当数据分布更加不均匀时，这些假设会成为性能瓶颈。

为了解决这一问题，作者提出了半去中心化梯度跟踪(Semi-decentralized Gradient Tracking, SD-GT)，这是第一个无需梯度多样性假设的SD-FL方法。通过在每个通信层中引入跟踪项，SD-GT能够改进模型训练质量和通信成本。作者对SD-GT进行了理论分析，给出了非凸、凸和强凸问题中的收敛性上界，并展示了如何通过调整子网采样率和D2D轮数来优化性能与效率之间的权衡。数值评估显示，与SD-FL和其他梯度跟踪基线相比，SD-GT在多个数据集上均表现出显著的改进。

通过上述研究，SD-GT提供了一种有效解决雾网络环境下联邦学习可扩展性问题的新方法，同时改善了模型性能并降低了通信成本。 <div>
arXiv:2409.17430v1 Announce Type: new 
Abstract: Federated learning (FL) encounters scalability challenges when implemented over fog networks that do not follow FL's conventional star topology architecture. Semi-decentralized FL (SD-FL) has proposed a solution for device-to-device (D2D) enabled networks that divides model cooperation into two stages: at the lower stage, D2D communications is employed for local model aggregations within subnetworks (subnets), while the upper stage handles device-server (DS) communications for global model aggregations. However, existing SD-FL schemes are based on gradient diversity assumptions that become performance bottlenecks as data distributions become more heterogeneous. In this work, we develop semi-decentralized gradient tracking (SD-GT), the first SD-FL methodology that removes the need for such assumptions by incorporating tracking terms into device updates for each communication layer. Our analytical characterization of SD-GT reveals upper bounds on convergence for non-convex, convex, and strongly-convex problems. We show how the bounds enable the development of an optimization algorithm that navigates the performance-efficiency trade-off by tuning subnet sampling rate and D2D rounds for each global training interval. Our subsequent numerical evaluations demonstrate that SD-GT obtains substantial improvements in trained model quality and communication cost relative to baselines in SD-FL and gradient tracking on several datasets.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Does Worst-Performing Agent Lead the Pack? Analyzing Agent Dynamics in Unified Distributed SGD</title>
<link>https://arxiv.org/abs/2409.17499</link>
<guid>https://arxiv.org/abs/2409.17499</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式学习、统一分布式SGD（UD-SGD）、联邦学习（FL）、采样策略、中央极限定理（CLT）

<br /><br />
总结:
本文对统一分布式随机梯度下降(UD-SGD)进行了渐近分析，研究了包括去中心化SGD、局部SGD在内的多种通信模式以及联邦学习(Federa ted Learning, FL)中的通信间隔递增。文章探讨了不同的采样策略，如i.i.d.采样、打乱采样和马尔科夫采样，如何影响UD-SGD的收敛速度。通过考虑中央极限定理描述的代理动态对限制协方差矩阵的影响，研究发现，各种采样策略对整体收敛性有显著影响。模拟结果显示，采用高效采样的少数代理能够实现或超越采用改进但不甚高效的多数代理的整体性能。这一发现提供了超越传统聚焦于表现最差代理分析的新见解，证明了在UD-SGD中，高效采样策略的贡献至关重要。此外，研究支持了线性加速和网络依赖性的现有理论，并展示了个体代理所采取的高效采样策略对整体收敛性的积极促进作用。 <div>
arXiv:2409.17499v1 Announce Type: new 
Abstract: Distributed learning is essential to train machine learning algorithms across heterogeneous agents while maintaining data privacy. We conduct an asymptotic analysis of Unified Distributed SGD (UD-SGD), exploring a variety of communication patterns, including decentralized SGD and local SGD within Federated Learning (FL), as well as the increasing communication interval in the FL setting. In this study, we assess how different sampling strategies, such as i.i.d. sampling, shuffling, and Markovian sampling, affect the convergence speed of UD-SGD by considering the impact of agent dynamics on the limiting covariance matrix as described in the Central Limit Theorem (CLT). Our findings not only support existing theories on linear speedup and asymptotic network independence, but also theoretically and empirically show how efficient sampling strategies employed by individual agents contribute to overall convergence in UD-SGD. Simulations reveal that a few agents using highly efficient sampling can achieve or surpass the performance of the majority employing moderately improved strategies, providing new insights beyond traditional analyses focusing on the worst-performing agent.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BioZero: An Efficient and Privacy-Preserving Decentralized Biometric Authentication Protocol on Open Blockchain</title>
<link>https://arxiv.org/abs/2409.17509</link>
<guid>https://arxiv.org/abs/2409.17509</guid>
<content:encoded><![CDATA[
<div> 关键词：数字身份、生物识别、区块链、去中心化、零知识证明

<br /><br />
总结:本文提出了BioZero，一种基于开放区块链的高效、隐私保护的去中心化生物特征认证协议。该协议利用Pedersen承诺和同态计算保护用户生物特征隐私的同时，实现高效验证。通过引入非交互式同态计算和零知识证明，BioZero实现了安全的链上验证。其独特的特性在于完全去中心化，并能由区块链智能合约高效执行。文章分析了BioZero的安全性，并通过原型实现验证了其性能。结果表明，BioZero在去中心化认证场景中具有有效性、效率和安全性。本研究对使用生物特征进行分散式身份认证的进展做出了贡献。 <div>
arXiv:2409.17509v1 Announce Type: new 
Abstract: Digital identity plays a vital role in enabling secure access to resources and services in the digital world. Traditional identity authentication methods, such as password-based and biometric authentications, have limitations in terms of security, privacy, and scalability. Decentralized authentication approaches leveraging blockchain technology have emerged as a promising solution. However, existing decentralized authentication methods often rely on indirect identity verification (e.g. using passwords or digital signatures as authentication credentials) and face challenges such as Sybil attacks. In this paper, we propose BioZero, an efficient and privacy-preserving decentralized biometric authentication protocol that can be implemented on open blockchain. BioZero leverages Pedersen commitment and homomorphic computation to protect user biometric privacy while enabling efficient verification. We enhance the protocol with non-interactive homomorphic computation and employ zero-knowledge proofs for secure on-chain verification. The unique aspect of BioZero is that it is fully decentralized and can be executed by blockchain smart contracts in a very efficient way. We analyze the security of BioZero and validate its performance through a prototype implementation. The results demonstrate the effectiveness, efficiency, and security of BioZero in decentralized authentication scenarios. Our work contributes to the advancement of decentralized identity authentication using biometrics.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>AsIf: Asset Interface Analysis of Industrial Automation Devices</title>
<link>https://arxiv.org/abs/2409.17593</link>
<guid>https://arxiv.org/abs/2409.17593</guid>
<content:encoded><![CDATA[
<div> 关键词：工业控制系统、威胁建模、资产分析、物理威胁、ISO/OSI参考模型

<br /><br />
总结:
本文探讨了随着工业4.0和工业物联网的发展，工业控制系统如何采用IT解决方案，特别是通信标准和协议。文章强调了在系统变得更加分散和互联时，增强安全措施的需求日益迫切。传统的威胁建模方法往往依赖于结构化的头脑风暴会议，由领域专家和安全专家参与，但这种方法经常未能提供全面的资产和接口识别，导致威胁建模不足，进而影响到安全架构的构建。

为解决这一问题，作者提出了一种方法，用于分析工业系统中的资产，特别关注物理威胁。该方法借鉴了ISO/OSI参考模型，引入了一种系统化的方法来识别并分类资产接口。通过这种方法，可以生成一个包含资产详细信息的丰富系统模型，以可视化形式呈现为接口树，从而为后续的威胁建模步骤打下基础。

为了验证所提方法的有效性，作者对一组12名安全专家进行了研究，展示了方法应用于可编程逻辑控制器（PLC）的结果。研究不仅展示了方法的应用实例，还提供了专家们对威胁建模的一般观点和工作流程的宝贵见解。这些发现对于理解当前威胁建模实践以及改进方法论具有重要意义。 <div>
arXiv:2409.17593v1 Announce Type: new 
Abstract: As Industry 4.0 and the Industrial Internet of Things continue to advance, industrial control systems are increasingly adopting IT solutions, including communication standards and protocols. As these systems become more decentralized and interconnected, a critical need for enhanced security measures arises. Threat modeling is traditionally performed in structured brainstorming sessions involving domain and security experts. Such sessions, however, often fail to provide an exhaustive identification of assets and interfaces due to the lack of a systematic approach. This is a major issue, as it leads to poor threat modeling, resulting in insufficient mitigation strategies and, lastly, a flawed security architecture.
  We propose a method for the analysis of assets in industrial systems, with special focus on physical threats. Inspired by the ISO/OSI reference model, a systematic approach is introduced to help identify and classify asset interfaces. This results in an enriched system model of the asset, offering a comprehensive overview visually represented as an interface tree, thereby laying the foundation for subsequent threat modeling steps. To demonstrate the proposed method, the results of its application to a programmable logic controller (PLC) are presented. In support of this, a study involving a group of 12 security experts was conducted. Additionally, the study offers valuable insights into the experts' general perspectives and workflows on threat modeling.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Verifying Randomized Consensus Protocols with Common Coins</title>
<link>https://arxiv.org/abs/2409.17627</link>
<guid>https://arxiv.org/abs/2409.17627</guid>
<content:encoded><![CDATA[
<div> 关键词：随机化、容错共识、公共硬币、阈值自动机、概率阈值自动机

<br />
<br />总结:

本文探讨了随机化容错共识协议在云计算和区块链平台中的广泛应用。这些协议的关键在于确保其正确性，因此需要一种形式化的模型进行验证。文章提出了一种扩展，将概率阈值自动机（PTA）应用于验证具有公共硬币的随机化容错共识协议。这与传统的PTA不同，后者仅适用于具有本地硬币的协议。

首先，作者引入了一个过程来模拟公共硬币（即“公共硬币过程”），以克服由于添加此过程而引发的对称性的破坏和技术挑战。通过一系列创新方法，他们证明了如何适应PTA以克服这些挑战。

接着，应用这一新方法验证了8个具有公共硬币的随机化共识协议的三个关键属性：一致性、有效性以及几乎必然终止。这表明该扩展的PTA模型不仅能够处理具有公共硬币的协议，而且能够有效地验证其核心特性，为确保此类协议的可靠性提供了坚实基础。 <div>
arXiv:2409.17627v1 Announce Type: new 
Abstract: Randomized fault-tolerant consensus protocols with common coins are widely used in cloud computing and blockchain platforms. Due to their fundamental role, it is vital to guarantee their correctness. Threshold automata is a formal model designed for the verification of fault-tolerant consensus protocols. It has recently been extended to probabilistic threshold automata (PTAs) to verify randomized fault-tolerant consensus protocols. Nevertheless, PTA can only model randomized consensus protocols with local coins.
  In this work, we extend PTA to verify randomized fault-tolerant consensus protocols with common coins. Our main idea is to add a process to simulate the common coin (the so-called common-coin process). Although the addition of the common-coin process destroys the symmetry and poses technical challenges, we show how PTA can be adapted to overcome the challenges. We apply our approach to verify the agreement, validity and almost-sure termination properties of 8 randomized consensus protocols with common coins.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Robust Aggregation for Securing Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2409.17754</link>
<guid>https://arxiv.org/abs/2409.17754</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、去中心化联邦学习、拜占庭鲁棒性、聚合算法、动态分散拓扑

总结:
本文提出了一种名为WFAgg的新型去中心化联邦学习（DFL）中的拜占庭鲁棒聚合算法。WFAgg通过采用多重过滤器来识别并缓解拜占庭攻击，同时处理动态分散拓扑的恶劣条件和强度稳定性问题。实验结果表明，该算法在各种拜占庭攻击场景下，能够保持模型准确性和收敛性，并在与现有集中式拜占庭鲁棒聚合方案（如Multi-Krum或聚类）比较中表现出优越性能。研究进一步验证了WFAgg在集中式和去中心化场景下的应用效果，特别是针对同方差图像分类问题。

文章首先介绍了联邦学习作为分布式机器学习方法，特别强调了其在保护隐私方面的优势。接着，指出去中心化联邦学习通过消除中央服务器，增强了系统的扩展性和鲁棒性，但同时也面临安全性的新挑战，尤其是拜占庭攻击。为此，文章提出了WFAgg算法，旨在提高DFL环境的安全性。通过实验验证，证明了WFAgg在不同拜占庭攻击情况下的有效性和优越性，特别是在模型准确性、收敛性和对动态分散拓扑的适应性方面优于现有的集中式鲁棒聚合方案。最后，研究还探讨了WFAgg在集中式和去中心化设置下的应用，特别是在同方差图像分类任务上的表现。 <div>
arXiv:2409.17754v1 Announce Type: new 
Abstract: Federated Learning (FL) emerges as a distributed machine learning approach that addresses privacy concerns by training AI models locally on devices. Decentralized Federated Learning (DFL) extends the FL paradigm by eliminating the central server, thereby enhancing scalability and robustness through the avoidance of a single point of failure. However, DFL faces significant challenges in optimizing security, as most Byzantine-robust algorithms proposed in the literature are designed for centralized scenarios. In this paper, we present a novel Byzantine-robust aggregation algorithm to enhance the security of Decentralized Federated Learning environments, coined WFAgg. This proposal handles the adverse conditions and strength robustness of dynamic decentralized topologies at the same time by employing multiple filters to identify and mitigate Byzantine attacks. Experimental results demonstrate the effectiveness of the proposed algorithm in maintaining model accuracy and convergence in the presence of various Byzantine attack scenarios, outperforming state-of-the-art centralized Byzantine-robust aggregation schemes (such as Multi-Krum or Clustering). These algorithms are evaluated on an IID image classification problem in both centralized and decentralized scenarios.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stackelberg Attack on Protocol Fee Governance</title>
<link>https://arxiv.org/abs/2409.17756</link>
<guid>https://arxiv.org/abs/2409.17756</guid>
<content:encoded><![CDATA[
<div> 关键词：Stackelberg攻击、流动性提供者、智能合约、Grim Forker、AMM

总结:

本文探讨了流动性提供者利用智能合约进行的Stackelberg攻击策略，以影响自动化市场制作（AMM）的治理。通过Grim Forker智能合约，流动性提供者可以实施分叉和承诺策略，动态地调整AMM储备和交易量，从而对系统产生影响。文章构建了一个基于区块的AMM模型，分析了存在协议费用的情况下的均衡条件，并深入研究了智能合约行动下的Stackelberg均衡。

首先，文章阐述了流动性提供者如何通过智能合约实施Stackelberg攻击，这种攻击策略旨在操纵AMM的治理过程，为自身利益服务。接着，作者构建了一个动态模型，该模型考虑了区块级别的AMM储备变化和交易量调整，揭示了在竞争性分叉环境中的行为模式。进一步地，文章引入了协议费用的概念，详细分析了这些费用如何影响系统的均衡状态，以及流动性提供者如何在这些条件下优化其策略。

最后，文章集中研究了在智能合约干预下出现的Stackelberg均衡问题，即在流动性提供者采取先发制人的策略与后续反应之间寻找最优解的过程。整体而言，该研究提供了对AMM中复杂交互和动态决策机制的深刻洞察，对于理解AMM的运作机制以及潜在的攻击手段具有重要意义。 <div>
arXiv:2409.17756v1 Announce Type: new 
Abstract: We establish a Stackelberg attack by Liquidity Providers against Governance of an AMM, leveraging forking and commitments through a Grim Forker smart contract. We produce a dynamic, block-by-block model of AMM reserves and trading volume in the presence of competing forks, derive equilibrium conditions in the presence of protocol fees, and analyze Stackelberg equilibria with smart contract moves.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Swarm-LIO2: Decentralized, Efficient LiDAR-inertial Odometry for UAV Swarms</title>
<link>https://arxiv.org/abs/2409.17798</link>
<guid>https://arxiv.org/abs/2409.17798</guid>
<content:encoded><![CDATA[
<div> 关键词：Aerial swarm systems、Swarm-LIO2、LiDAR-inertial odometry、Decentralized、Plug-and-play

总结:

本文提出了一种名为Swarm-LIO2的全分布式、插拔式、计算效率高且带宽效率高的激光雷达惯性导航系统，专为无人机群系统设计。Swarm-LIO2采用全分布式、插拔式网络作为通信基础设施，仅交换高效且低维的信息，如身份、自身状态、相互观测测量和全局外参。为了实现新成员的无缝加入，系统能够自动检测潜在的队友无人机并初始化时间偏移和全局外参。为了提高初始化效率，文章提出了基于反射率的无人机检测方法、轨迹匹配技术和因子图优化方法。

在状态估计方面，Swarm-LIO2在有效扩展卡尔曼滤波框架下融合了激光雷达、IMU和相互观测数据，对时间延迟进行了精确补偿，并对测量进行了建模，以提升准确性和一致性。此系统旨在解决无人机群中自我与相互状态估计的挑战，对于推进无人机群在协作探索、目标跟踪、搜索救援等任务中的应用具有重要意义。 <div>
arXiv:2409.17798v1 Announce Type: new 
Abstract: Aerial swarm systems possess immense potential in various aspects, such as cooperative exploration, target tracking, search and rescue. Efficient, accurate self and mutual state estimation are the critical preconditions for completing these swarm tasks, which remain challenging research topics. This paper proposes Swarm-LIO2: a fully decentralized, plug-and-play, computationally efficient, and bandwidth-efficient LiDAR-inertial odometry for aerial swarm systems. Swarm-LIO2 uses a decentralized, plug-and-play network as the communication infrastructure. Only bandwidth-efficient and low-dimensional information is exchanged, including identity, ego-state, mutual observation measurements, and global extrinsic transformations. To support the plug-and-play of new teammate participants, Swarm-LIO2 detects potential teammate UAVs and initializes the temporal offset and global extrinsic transformation all automatically. To enhance the initialization efficiency, novel reflectivity-based UAV detection, trajectory matching, and factor graph optimization methods are proposed. For state estimation, Swarm-LIO2 fuses LiDAR, IMU, and mutual observation measurements within an efficient ESIKF framework, with careful compensation of temporal delay and modeling of measurements to enhance the accuracy and consistency.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hypergame Theory for Decentralized Resource Allocation in Multi-user Semantic Communications</title>
<link>https://arxiv.org/abs/2409.17985</link>
<guid>https://arxiv.org/abs/2409.17985</guid>
<content:encoded><![CDATA[
<div> 关键词：多用户、语义通信、Stackelberg超博弈、资源分配、感知偏差

总结:

本文提出了一种针对多用户语义通信系统的新框架，旨在高效地在去中心化环境中分配通信和计算资源，以最大化用户体验质量。该框架利用Stackelberg超博弈理论解决资源分配问题，特别考虑了用户对彼此通信与控制策略的感知偏差。通过引入第二级超游戏概念，文章构建了描述感知偏差的新型分析模型，并对学习到的资源分配协议的均衡性进行了平衡分析，确保了计算与通信策略收敛至局部Stackelberg均衡点。

该方法通过优化资源分配策略，不仅实现了高效的资源使用，还显著提升了用户的体验质量，相较于不考虑感知偏差的传统方法，表现出更好的性能。实验结果证实了所提Stackelberg超博弈方法的有效性和优越性，证明其在多用户语义通信系统中的应用潜力巨大。 <div>
arXiv:2409.17985v1 Announce Type: new 
Abstract: Semantic communications (SC) is an emerging communication paradigm in which wireless devices can send only relevant information from a source of data while relying on computing resources to regenerate missing data points. However, the design of a multi-user SC system becomes more challenging because of the computing and communication overhead required for coordination. Existing solutions for learning the semantic language and performing resource allocation often fail to capture the computing and communication tradeoffs involved in multiuser SC. To address this gap, a novel framework for decentralized computing and communication resource allocation in multiuser SC systems is proposed. The challenge of efficiently allocating communication and computing resources (for reasoning) in a decentralized manner to maximize the quality of task experience for the end users is addressed through the application of Stackelberg hyper game theory. Leveraging the concept of second-level hyper games, novel analytical formulations are developed to model misperceptions of the users about each other's communication and control strategies. Further, equilibrium analysis of the learned resource allocation protocols examines the convergence of the computing and communication strategies to a local Stackelberg equilibria, considering misperceptions. Simulation results show that the proposed Stackelberg hyper game results in efficient usage of communication and computing resources while maintaining a high quality of experience for the users compared to state-of-the-art that does not account for the misperceptions.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Federated Learning with Gradient Tracking over Time-Varying Directed Networks</title>
<link>https://arxiv.org/abs/2409.17189</link>
<guid>https://arxiv.org/abs/2409.17189</guid>
<content:encoded><![CDATA[
<div> 关键词：时间变化、分布式学习、联邦学习、共识算法、线性收敛

总结:

本文研究了在随时间变化的有向图中，多智能体之间的交互问题，提出了名为DSGTm-TV的基于共识的算法。该算法结合了梯度跟踪和重球动量方法，用于分布式优化全局目标函数，同时保护本地数据隐私。通过行和列概率转移矩阵实现邻近智能体之间信息交换，确保了共识和最优性的达成。

分析表明，当可用精确梯度信息时，DSGTm-TV表现出线性收敛至精确全局最优解；使用随机梯度时，收敛于全局最优解的邻域。与现有方法相比，DSGTm-TV在不协调的步长和动量参数下仍能保持收敛，提供明确的边界。这使得智能体能够在完全去中心化的环境中独立优化其本地超参数。

研究通过在真实世界图像分类和自然语言处理任务上的比较实验，验证了DSGTm-TV的有效性，相较于最先进的基线方法显示出更好的性能。 <div>
arXiv:2409.17189v1 Announce Type: cross 
Abstract: We investigate the problem of agent-to-agent interaction in decentralized (federated) learning over time-varying directed graphs, and, in doing so, propose a consensus-based algorithm called DSGTm-TV. The proposed algorithm incorporates gradient tracking and heavy-ball momentum to distributively optimize a global objective function, while preserving local data privacy. Under DSGTm-TV, agents will update local model parameters and gradient estimates using information exchange with neighboring agents enabled through row- and column-stochastic mixing matrices, which we show guarantee both consensus and optimality. Our analysis establishes that DSGTm-TV exhibits linear convergence to the exact global optimum when exact gradient information is available, and converges in expectation to a neighborhood of the global optimum when employing stochastic gradients. Moreover, in contrast to existing methods, DSGTm-TV preserves convergence for networks with uncoordinated stepsizes and momentum parameters, for which we provide explicit bounds. These results enable agents to operate in a fully decentralized manner, independently optimizing their local hyper-parameters. We demonstrate the efficacy of our approach via comparisons with state-of-the-art baselines on real-world image classification and natural language processing tasks.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain</title>
<link>https://arxiv.org/abs/2409.16444</link>
<guid>https://arxiv.org/abs/2409.16444</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、物联网、深强化学习、智能城市、数据安全

总结:
本文探讨了区块链与深度强化学习（DRL）在物联网（IoT）辅助智能城市中的整合应用，以优化移动传输和确保数据交换的安全性。研究通过将物联网应用系统进行聚类和分类，展示了DRL与区块链结合如何提升IoT网络性能，同时维持隐私与安全性。文章回顾了2015年至2024年间发表的论文，对提出的方法进行了分类和提供实用分类体系，为研究人员提供了关键视角并指出了未来研究的潜在领域。研究发现，将区块链的去中心化架构与DRL结合，可以解决隐私和安全问题，提高移动传输效率，并确保稳定、隐私保护的物联网系统。此外，文章还探讨了区块链集成在DRL中的应用以及DRL技术的显著应用。通过解决机器学习与区块链集成的挑战，该研究提出了跨学科视角下的新观点，为研究人员提供了宝贵的资源。 <div>
arXiv:2409.16444v1 Announce Type: new 
Abstract: The accelerated expansion of the Internet of Things (IoT) has raised critical challenges associated with privacy, security, and data integrity, specifically in infrastructures such as smart cities or smart manufacturing. Blockchain technology provides immutable, scalable, and decentralized solutions to address these challenges, and integrating deep reinforcement learning (DRL) into the IoT environment offers enhanced adaptability and decision-making. This paper investigates the integration of blockchain and DRL to optimize mobile transmission and secure data exchange in IoT-assisted smart cities. Through the clustering and categorization of IoT application systems, the combination of DRL and blockchain is shown to enhance the performance of IoT networks by maintaining privacy and security. Based on the review of papers published between 2015 and 2024, we have classified the presented approaches and offered practical taxonomies, which provide researchers with critical perspectives and highlight potential areas for future exploration and research. Our investigation shows how combining blockchain's decentralized framework with DRL can address privacy and security issues, improve mobile transmission efficiency, and guarantee robust, privacy-preserving IoT systems. Additionally, we explore blockchain integration for DRL and outline the notable applications of DRL technology. By addressing the challenges of machine learning and blockchain integration, this study proposes novel perspectives for researchers and serves as a foundational exploration from an interdisciplinary standpoint.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Flight: A FaaS-Based Framework for Complex and Hierarchical Federated Learning</title>
<link>https://arxiv.org/abs/2409.16495</link>
<guid>https://arxiv.org/abs/2409.16495</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Flight框架、复杂层级多级拓扑、异步聚合、控制平面与数据平面解耦

总结:
文章介绍了一种新型联邦学习（FL）框架——Flight。相较于现有框架，Flight支持复杂层级多级网络拓扑结构，允许设备在异步情况下进行聚合操作，并实现了控制平面和数据平面的分离。与当前最先进的FL框架Flower相比，Flight展现出更好的扩展性，能够同时支持高达2048台设备。实验证明，Flight能够显著减少联邦学习的完成时间（即FL完成周期），并且通过其层级化的FL模型，降低了通信开销超过60%。这一创新为处理大规模分布式系统中的机器学习任务提供了更高效的解决方案，特别适用于物联网等实际应用场景。 <div>
arXiv:2409.16495v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning paradigm where models are trained on distributed devices and are aggregated at a central server. Existing FL frameworks assume simple two-tier network topologies where end devices are directly connected to the aggregation server. While this is a practical mental model, it does not exploit the inherent topology of real-world distributed systems like the Internet-of-Things. We present Flight, a novel FL framework that supports complex hierarchical multi-tier topologies, asynchronous aggregation, and decouples the control plane from the data plane. We compare the performance of Flight against Flower, a state-of-the-art FL framework. Our results show that Flight scales beyond Flower, supporting up to 2048 simultaneous devices, and reduces FL makespan across several models. Finally, we show that Flight's hierarchical FL model can reduce communication overheads by more than 60%.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning with Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16720</link>
<guid>https://arxiv.org/abs/2409.16720</guid>
<content:encoded><![CDATA[
<div> 关键词：自主无人机、时间最优飞行、多无人机系统、强化学习、分散式策略网络

<br />
<br />总结:

本文提出了一种基于多智能体强化学习的分散式策略网络，用于实现多无人机系统的高效时间最优飞行。该方法通过引入软碰撞惩罚机制，结合优化方法的思想，平衡了飞行效率与碰撞规避。利用集中式训练、分散式执行（CTDE）方式定制PPO算法，显著提升了训练效率和稳定性，同时保证了轻量化实施。模拟实验结果显示，尽管与单无人机系统相比在性能上略有折衷，但多无人机方案仍能保持接近时间最优的表现，并具有较低的碰撞率。实验证明，两个四旋翼无人机使用相同的网络模型，在一个5.5米*5.5米*2.0米的空间内，以最大速度达到13.65米/秒和最大身体角速度达到13.4弧度/秒，完全依赖于机载计算完成各种轨道任务。 <div>
arXiv:2409.16720v1 Announce Type: new 
Abstract: Recent innovations in autonomous drones have facilitated time-optimal flight in single-drone configurations and enhanced maneuverability in multi-drone systems through the application of optimal control and learning-based methods. However, few studies have achieved time-optimal motion planning for multi-drone systems, particularly during highly agile maneuvers or in dynamic scenarios. This paper presents a decentralized policy network for time-optimal multi-drone flight using multi-agent reinforcement learning. To strike a balance between flight efficiency and collision avoidance, we introduce a soft collision penalty inspired by optimization-based methods. By customizing PPO in a centralized training, decentralized execution (CTDE) fashion, we unlock higher efficiency and stability in training, while ensuring lightweight implementation. Extensive simulations show that, despite slight performance trade-offs compared to single-drone systems, our multi-drone approach maintains near-time-optimal performance with low collision rates. Real-world experiments validate our method, with two quadrotors using the same network as simulation achieving a maximum speed of 13.65 m/s and a maximum body rate of 13.4 rad/s in a 5.5 m * 5.5 m * 2.0 m space across various tracks, relying entirely on onboard computation.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Robot Informative Path Planning for Efficient Target Mapping using Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16967</link>
<guid>https://arxiv.org/abs/2409.16967</guid>
<content:encoded><![CDATA[
<div> 关键词：自主机器人、多机器人、信息路径规划、深度强化学习、开源代码

<br /><br />总结:

本文提出了一种利用深度强化学习进行多机器人信息路径规划的新方法，以在未知三维环境中高效地发现目标。该方法的核心在于构建了一个增强图模型，用于预测和避免其他机器人的轨迹冲突，同时规划通信路径和避障策略。通过集中式训练和分散式执行的方式，我们的算法可以适应不同数量的机器人，并且不需要重新训练，具有良好的扩展性和鲁棒性。实验结果表明，与现有的多机器人目标映射技术相比，我们的方法在发现目标数量上提高了33.75%。为了促进研究和应用，我们还公开了实现这一算法的源代码和模型。

文章主要贡献如下：

1. **提出增强图模型**：构建了一个模型来预测和避免其他机器人之间的轨迹冲突，同时考虑通信路径的规划，以优化多机器人系统的整体性能。

2. **集中式训练与分散式执行**：采用这种策略训练分散的机器人政策，使得系统能够有效应对不同数量的机器人，而无需重新训练，增强了系统的灵活性和适应性。

3. **多目标发现能力**：通过优化路径规划，提高了在未知环境中的目标发现效率，与现有技术相比，显著提升了目标发现的数量。

4. **开源资源**：提供了一个开放的平台，使得其他研究人员和开发者可以访问和使用我们的代码及模型，促进了多机器人技术的研究和应用。

5. **实际应用潜力**：该方法不仅在理论上有创新，而且在实践中具有很高的应用价值，适用于各种需要多机器人协作进行数据收集和环境探索的任务场景。 <div>
arXiv:2409.16967v1 Announce Type: new 
Abstract: Autonomous robots are being employed in several mapping and data collection tasks due to their efficiency and low labor costs. In these tasks, the robots are required to map targets-of-interest in an unknown environment while constrained to a given resource budget such as path length or mission time. This is a challenging problem as each robot has to not only detect and avoid collisions from static obstacles in the environment but also has to model other robots' trajectories to avoid inter-robot collisions. We propose a novel deep reinforcement learning approach for multi-robot informative path planning to map targets-of-interest in an unknown 3D environment. A key aspect of our approach is an augmented graph that models other robots' trajectories to enable planning for communication and inter-robot collision avoidance. We train our decentralized reinforcement learning policy via the centralized training and decentralized execution paradigm. Once trained, our policy is also scalable to varying number of robots and does not require re-training. Our approach outperforms other state-of-the-art multi-robot target mapping approaches by 33.75% in terms of the number of discovered targets-of-interest. We open-source our code and model at: https://github.com/AccGen99/marl_ipp
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Agent Multi-Environment Mixed Q-Learning for Partially Decentralized Wireless Network Optimization</title>
<link>https://arxiv.org/abs/2409.16450</link>
<guid>https://arxiv.org/abs/2409.16450</guid>
<content:encoded><![CDATA[
<div> 关键词：Q-learning、多环境混合Q学习（MEMQ）、无线网络、多代理、部分去中心化

总结:
文章探讨了在部分去中心化的无线网络中，特别是由多个移动发射器（TXs）和基站（BSs）构成的网络环境下，如何有效利用多环境混合Q学习（MEMQ）算法进行策略优化。主要关注于解决大型状态空间带来的挑战，通过将多个Q学习算法集成在相关环境（所谓的“数字表亲”）中来提高性能并降低复杂性。然而，传统的MEMQ设计局限于单一集中式代理网络，不适用于分散或多代理网络。

为解决这一问题，研究提出了一种新型的多代理MEMQ算法，专门针对部分去中心化无线网络。在这个算法中，独立的TXs在非协调状态下各自行动以最小化个体成本，而在协调状态下，TXs使用贝叶斯方法根据本地观察结果估计联合状态，并与领导TX共享有限信息以最小化联合成本。这种信息共享的成本线性增长，与联合状态-动作空间的大小无关。

该算法的实施显著提高了效率，相比集中式MEMQ，平均策略误差（APE）增加了20%，但比几种先进的分散式Q学习算法快了25%，同时APE减少了40%。此外，算法的收敛性也得到了验证。通过对比实验，证明了该算法在处理部分去中心化无线网络中的高效性和实用性。 <div>
arXiv:2409.16450v1 Announce Type: cross 
Abstract: Q-learning is a powerful tool for network control and policy optimization in wireless networks, but it struggles with large state spaces. Recent advancements, like multi-environment mixed Q-learning (MEMQ), improves performance and reduces complexity by integrating multiple Q-learning algorithms across multiple related environments so-called digital cousins. However, MEMQ is designed for centralized single-agent networks and is not suitable for decentralized or multi-agent networks. To address this challenge, we propose a novel multi-agent MEMQ algorithm for partially decentralized wireless networks with multiple mobile transmitters (TXs) and base stations (BSs), where TXs do not have access to each other's states and actions. In uncoordinated states, TXs act independently to minimize their individual costs. In coordinated states, TXs use a Bayesian approach to estimate the joint state based on local observations and share limited information with leader TX to minimize joint cost. The cost of information sharing scales linearly with the number of TXs and is independent of the joint state-action space size. The proposed scheme is 50% faster than centralized MEMQ with only a 20% increase in average policy error (APE) and is 25% faster than several advanced decentralized Q-learning algorithms with 40% less APE. The convergence of the algorithm is also demonstrated.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Physics Enhanced Residual Policy Learning (PERPL) for safety cruising in mixed traffic platooning under actuator and communication delay</title>
<link>https://arxiv.org/abs/2409.15595</link>
<guid>https://arxiv.org/abs/2409.15595</guid>
<content:encoded><![CDATA[
<div> 关键词：线性控制模型、强化学习、物理信息政策、分散式控制、混合交通队列

<br /><br />
总结:

本文提出了一种名为“物理增强残差策略学习”（PERPL）的框架，旨在结合物理基础模型和强化学习的优点。物理基础模型提供高效的数据处理能力和可解释性，而强化学习则具备适应多目标场景和快速计算的能力。PERPL框架通过引入物理组件来提升模型的可解释性和稳定性，同时利用学习到的残差策略对物理模型进行调整以适应环境变化，从而优化决策过程。

该研究将PERPL应用于分散式控制的混合交通队列管理中，包括连接和自动化车辆（CAVs）与传统驾驶车辆（HVs）。使用恒定时间间隔（CTG）策略进行巡航，并考虑了执行器和通信延迟的影响。实验结果表明，相较于传统的线性模型和单独的强化学习方法，在极端条件和真实前车轨迹下，PERPL方法能够实现更小的车距误差和更好的振荡衰减效果。

此外，从宏观角度来看，随着采用PERPL方案的CAVs渗透率增加，整体交通振荡也得到了有效降低。这表明PERPL不仅在微观层面改善了车辆控制性能，也在宏观层面优化了交通流，展现了其在复杂动态环境下显著的应用潜力。 <div>
arXiv:2409.15595v1 Announce Type: new 
Abstract: Linear control models have gained extensive application in vehicle control due to their simplicity, ease of use, and support for stability analysis. However, these models lack adaptability to the changing environment and multi-objective settings. Reinforcement learning (RL) models, on the other hand, offer adaptability but suffer from a lack of interpretability and generalization capabilities. This paper aims to develop a family of RL-based controllers enhanced by physics-informed policies, leveraging the advantages of both physics-based models (data-efficient and interpretable) and RL methods (flexible to multiple objectives and fast computing). We propose the Physics-Enhanced Residual Policy Learning (PERPL) framework, where the physics component provides model interpretability and stability. The learning-based Residual Policy adjusts the physics-based policy to adapt to the changing environment, thereby refining the decisions of the physics model. We apply our proposed model to decentralized control to mixed traffic platoon of Connected and Automated Vehicles (CAVs) and Human-driven Vehicles (HVs) using a constant time gap (CTG) strategy for cruising and incorporating actuator and communication delays. Experimental results demonstrate that our method achieves smaller headway errors and better oscillation dampening than linear models and RL alone in scenarios with artificially extreme conditions and real preceding vehicle trajectories. At the macroscopic level, overall traffic oscillations are also reduced as the penetration rate of CAVs employing the PERPL scheme increases.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockprint Accuracy Study</title>
<link>https://arxiv.org/abs/2409.15808</link>
<guid>https://arxiv.org/abs/2409.15808</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockprint、Ethereum beacon chain、K-Nearest Neighbors（KNN）、Multi-Layer Perceptron（MLP）、模型准确性

总结:
本文主要探讨了MigaLabs团队对评估以太坊信标链客户端多样性的工具——Blockprint进行的实验改进。文章关注于优化K-Nearest Neighbors（KNN）分类器配置和探索使用Multi-Layer Perceptron（MLP）分类器作为潜在替代方案，以提高Blockprint的准确性。研究结果表明，MLP分类器在较小的数据集上通常能实现更高的准确度。

文中还揭示了运行在不同模式下的客户端（特别是订阅所有子网的客户端），其对验证纳入的影响存在差异，这一发现导致了对缓解模型准确性下降问题的建议方法。最终推荐采用结合默认配置和订阅所有子网客户端设置的训练数据集来训练MLP模型。

通过上述分析，研究旨在提升Blockprint工具在评估以太坊信标链客户端多样性方面的效能，为理解网络的去中心化程度提供更精确的依据。 <div>
arXiv:2409.15808v1 Announce Type: new 
Abstract: Blockprint, a tool for assessing client diversity on the Ethereum beacon chain, is essential for analyzing decentralization. This paper details experiments conducted at MigaLabs to enhance Blockprint's accuracy, evaluating various configurations for the K-Nearest Neighbors (KNN) classifier and exploring the Multi-Layer Perceptron (MLP) classifier as a proposed alternative. Findings suggest that the MLP classifier generally achieves superior accuracy with a smaller training dataset. The study revealed that clients running in different modes, especially those subscribed to all subnets, impact attestation inclusion differently, leading to proposed methods for mitigating the decline in model accuracy. Consequently, the recommendation is to employ an MLP model trained with a combined dataset of slots from both default and subscribed-to-all-subnets client configurations.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MHRC: Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models</title>
<link>https://arxiv.org/abs/2409.16030</link>
<guid>https://arxiv.org/abs/2409.16030</guid>
<content:encoded><![CDATA[
<div> 关键词：大语言模型、机器人、协作任务、多模态、任务规划

<br />
<br />
总结:本文介绍了一种利用大型语言模型(Large Language Models, LLMs)实现多模态异构机器人分散协作的新框架。该框架支持移动机器人、操作机器人和移动操作机器人三大类机器人共同完成探索、运输和组织等任务。通过开发丰富的文本反馈机制和链式思维提示，提高了任务规划效率和系统整体性能。移动操作机器人能够灵活调整基座位置，以最佳条件执行抓取任务；操作机器人能理解任务需求，必要时寻求帮助并适当地处理物体；同时，移动机器人能广泛探索环境，标记物品位置，并将信息传达给移动操作机器人，从而提高任务执行效率。研究团队在PyBullet中构建了三种不同房间布局和任务的场景进行测试，并评估了不同LLM模型及其组件的贡献。实验结果证实了所提出框架的有效性和必要性。 <div>
arXiv:2409.16030v1 Announce Type: new 
Abstract: The integration of large language models (LLMs) with robotics has significantly advanced robots' abilities in perception, cognition, and task planning. The use of natural language interfaces offers a unified approach for expressing the capability differences of heterogeneous robots, facilitating communication between them, and enabling seamless task allocation and collaboration. Currently, the utilization of LLMs to achieve decentralized multi-heterogeneous robot collaborative tasks remains an under-explored area of research. In this paper, we introduce a novel framework that utilizes LLMs to achieve decentralized collaboration among multiple heterogeneous robots. Our framework supports three robot categories, mobile robots, manipulation robots, and mobile manipulation robots, working together to complete tasks such as exploration, transportation, and organization. We developed a rich set of textual feedback mechanisms and chain-of-thought (CoT) prompts to enhance task planning efficiency and overall system performance. The mobile manipulation robot can adjust its base position flexibly, ensuring optimal conditions for grasping tasks. The manipulation robot can comprehend task requirements, seek assistance when necessary, and handle objects appropriately. Meanwhile, the mobile robot can explore the environment extensively, map object locations, and communicate this information to the mobile manipulation robot, thus improving task execution efficiency. We evaluated the framework using PyBullet, creating scenarios with three different room layouts and three distinct operational tasks. We tested various LLM models and conducted ablation studies to assess the contributions of different modules. The experimental results confirm the effectiveness and necessity of our proposed framework.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-LLM Debiasing Framework</title>
<link>https://arxiv.org/abs/2409.13884</link>
<guid>https://arxiv.org/abs/2409.13884</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型（LLMs）、社会偏见、多LLM方法、集中式方法、分布式方法

总结:
本文探讨了大型语言模型（LLMs）中的社会偏见问题及其解决策略。随着LLMs在社会各领域的广泛应用，它们所展现出来的偏见问题引起了广泛关注。文章首先指出，尽管通过数据增强、零样本提示和模型微调等技术在一定程度上缓解了偏见，但仍有持续存在的偏见，包括可能难以察觉的微妙偏见。为了进一步改进这一状况，作者提出了一个创新的多LLM去偏见框架，旨在减少LLMs中的偏见。

该框架包括两种不同的方法：集中式方法和分布式方法。在集中式方法中，对话由单一中心LLM协调；而在分布式方法中，所有模型直接通信。研究结果表明，多LLM框架在多个社会群体中显著降低了偏见，其性能超越了基线方法。这一发现为LLMs的公平性和可靠性提供了新的途径，有助于促进更广泛的社会应用。

通过引入多LLM方法，本文不仅展示了如何有效减少LLMs中的偏见，还强调了在设计和应用这些技术时需要考虑的社会责任。这一研究对于推动LLMs成为更加公正、透明和包容的技术具有重要意义。 <div>
arXiv:2409.13884v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are powerful tools with the potential to benefit society immensely, yet, they have demonstrated biases that perpetuate societal inequalities. Despite significant advancements in bias mitigation techniques using data augmentation, zero-shot prompting, and model fine-tuning, biases continuously persist, including subtle biases that may elude human detection. Recent research has shown a growing interest in multi-LLM approaches, which have been demonstrated to be effective in improving the quality of reasoning and factuality in LLMs. Building on this approach, we propose a novel multi-LLM debiasing framework aimed at reducing bias in LLMs. Our work is the first to introduce and evaluate two distinct approaches within this framework for debiasing LLMs: a centralized method, where the conversation is facilitated by a single central LLM, and a decentralized method, where all models communicate directly. Our findings reveal that our multi-LLM framework significantly reduces bias in LLMs, outperforming the baseline method across several social groups.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive bias for dissensus in nonlinear opinion dynamics with application to evolutionary division of labor games</title>
<link>https://arxiv.org/abs/2409.13964</link>
<guid>https://arxiv.org/abs/2409.13964</guid>
<content:encoded><![CDATA[
<div> 关键词：非线性意见动力学、适应性控制、偏置参数、多任务分配、演化博弈

总结:

本文探讨了如何通过适当地调整非线性意见动力学（NOD）中的偏差参数，以实现将代理智能体分配到任意大小的群体中，从而最大化集体奖励的问题。研究基于之前在多机器人系统中利用NOD与多目标行为优化相结合的算法进行自主任务分配的实地实验结果。受此启发，本文提出并分析了一个新的任务分配模型，该模型将NOD与演化博弈框架综合在一起。

通过理论证明，我们确定了能够使用分布式反馈控制意见状态至特定两任务间代理智能体分配比例所需的充分条件。随后，通过合作演化分工游戏的仿真研究验证了这些理论结果的有效性。

主要贡献包括：

1. **提出新模型**：结合NOD与演化博弈，形成一种新的任务分配策略。
2. **理论分析**：证明了通过动态调整偏差参数可以实现期望的任务分配。
3. **仿真验证**：通过合作演化分工游戏的仿真，展示了模型的有效性。
4. **适应性控制**：强调了通过适应性控制机制来优化任务分配的重要性。
5. **多目标优化**：考虑了在最大化集体奖励的同时满足其他潜在目标的复杂性。

该研究为多智能体系统中的任务分配问题提供了新的视角和解决方案，特别适用于需要动态调整任务负载以优化整体性能的场景。 <div>
arXiv:2409.13964v1 Announce Type: new 
Abstract: This paper addresses the problem of adaptively controlling the bias parameter in nonlinear opinion dynamics (NOD) to allocate agents into groups of arbitrary sizes for the purpose of maximizing collective rewards. In previous work, an algorithm based on the coupling of NOD with an multi-objective behavior optimization was successfully deployed as part of a multi-robot system in an autonomous task allocation field experiment. Motivated by the field results, in this paper we propose and analyze a new task allocation model that synthesizes NOD with an evolutionary game framework. We prove sufficient conditions under which it is possible to control the opinion state in the group to a desired allocation of agents between two tasks through an adaptive bias using decentralized feedback. We then verify the theoretical results with a simulation study of a collaborative evolutionary division of labor game.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cyber-Physical Authentication Scheme for Secure V2G Transactions Using Blockchain and Smart Contracts</title>
<link>https://arxiv.org/abs/2409.14008</link>
<guid>https://arxiv.org/abs/2409.14008</guid>
<content:encoded><![CDATA[
<div> 关键词：电车辆、车辆到电网、智能充电基础设施、区块链、网络安全

<br />
<br />总结:

本文探讨了全球电动汽车（EV）的快速普及对车辆到电网（V2G）网络所引发的网络安全需求。随着V2G网络被越来越多地集成到智能充电基础设施中，新的安全漏洞开始出现，威胁着电网稳定性和用户隐私。为此，文章提出了一种针对插桩充电（PnC）操作的基于区块链的V2G系统中的网络认证协议和智能合约。该协议利用高级加密技术和区块链技术确保电动汽车与充电站之间进行安全、透明和防篡改的能量交易。

主要贡献包括开发一种结合物理和网络安全性的认证方法，实现智能合约框架以支持安全的能量交易，并进行了详细的安全性和隐私性分析。该提案有效应对分布式拒绝服务（DDoS）、中间人（MitM）攻击和重放攻击等风险，同时保持用户匿名性和数据完整性。通过这种综合策略，文章旨在提升V2G网络的安全性和可靠性，为电动汽车的广泛采用提供坚实的技术支撑。 <div>
arXiv:2409.14008v1 Announce Type: new 
Abstract: The rapid adoption of electric vehicles (EVs) globally has catalyzed the need for robust cybersecurity measures within vehicle-to-grid (V2G) networks. As these networks are increasingly being integrated into smart charging infrastructures, they also introduce new vulnerabilities that threaten grid stability and user privacy This paper proposes a cyber-physical authentication protocol and trading smart contract tailored to plug and charge (PnC) operations within blockchain-based V2G systems. The protocol leverages advanced cryptographic techniques and blockchain to ensure secure, transparent, and tamper-proof energy transactions between EVs and charging stations. Key contributions include the development of a cyber-physical authentication method, the implementation of a smart contract framework for secure energy trading, and a detailed security and privacy analysis. The proposed protocol effectively mitigates risks such as distributed denial of service (DDoS) attacks, man-in-the-middle (MitM) attacks and replay attacks while preserving user anonymity and data integrity.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Re-Evaluating Privacy in Centralized and Decentralized Learning: An Information-Theoretical and Empirical Study</title>
<link>https://arxiv.org/abs/2409.14261</link>
<guid>https://arxiv.org/abs/2409.14261</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning（DFL）、Centralized Federated Learning（CFL）、Privacy、Mutual Information、Secure Aggregation（SA）

<br /><br />
总结:

本文主要探讨了去中心化联邦学习(DFL)与集中式联邦学习(CFL)在隐私保护方面的差异。研究发现，尽管DFL因其去中心化的特性被认为在一定程度上提高了数据隐私，但Pasquini等人的研究挑战了这一观点，指出在某些假设下，DFL并不能显著提高隐私保护能力。为了深入分析这一问题，文章引入了一种基于信息论的理论框架，通过计算互信息来量化隐私泄漏。

研究还对增强隐私的技术，如安全聚合(SA)，在DFL和CFL中的有效性进行了评估。通过模拟和实际实验，结果表明，在不完全信任服务器的情况下，DFL通常能提供更强的隐私保护。文章指出，前人研究中关于网络拓扑结构和隐私攻击假设的局限性未能充分反映联邦学习中的信息泄露情况。

最后，研究揭示了先前研究中存在的不足之处，特别是在对网络结构和攻击模式的假设上，这些假设可能过于理想化，无法全面反映现实场景中的信息泄露风险。因此，该文为理解联邦学习中的隐私保护机制提供了新的视角，并强调了构建更精确理论模型的重要性。 <div>
arXiv:2409.14261v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) has garnered attention for its robustness and scalability compared to Centralized Federated Learning (CFL). While DFL is commonly believed to offer privacy advantages due to the decentralized control of sensitive data, recent work by Pasquini et, al. challenges this view, demonstrating that DFL does not inherently improve privacy against empirical attacks under certain assumptions. For investigating fully this issue, a formal theoretical framework is required. Our study offers a novel perspective by conducting a rigorous information-theoretical analysis of privacy leakage in FL using mutual information. We further investigate the effectiveness of privacy-enhancing techniques like Secure Aggregation (SA) in both CFL and DFL. Our simulations and real-world experiments show that DFL generally offers stronger privacy preservation than CFL in practical scenarios where a fully trusted server is not available. We address discrepancies in previous research by highlighting limitations in their assumptions about graph topology and privacy attacks, which inadequately capture information leakage in FL.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cluster-based Network Time Synchronization for Resilience with Energy Efficiency</title>
<link>https://arxiv.org/abs/2409.14323</link>
<guid>https://arxiv.org/abs/2409.14323</guid>
<content:encoded><![CDATA[
<div> 关键词：时间同步、物联网、故障容忍、能效、分布式协议

总结:
本文提出了一种名为C-sync的基于聚类的分布式时间同步协议，旨在解决物联网网络中设备间的时间同步问题。该协议具有故障容忍性，能够在网络中检测并隔离故障，从而快速恢复。与现有解决方案相比，C-sync通过引入多个参考节点来限制任何节点到其时间源的最大跳数，从而实现规模扩展。此外，C-sync在Contiki平台上采用模块化结构，支持应用程序转换。研究团队在真实测试床上进行了实验，该测试床由分布在不同楼层的40多个Tmote Sky硬件节点组成。实验结果表明，C-sync在最坏和最佳情况下分别减少了56.12%和75.75%的功率消耗，同时保持了与最先进的协议相当的准确性。与提供无/有限容错的分布式协议（源自GTSP）进行比较时，C-sync在能效和故障恢复方面表现出色。 <div>
arXiv:2409.14323v1 Announce Type: new 
Abstract: Time synchronization of devices in Internet-of-Things (IoT) networks is one of the challenging problems and a pre-requisite for the design of low-latency applications. Although many existing solutions have tried to address this problem, almost all solutions assume all the devices (nodes) in the network are faultless. Furthermore, these solutions exchange a large number of messages to achieve synchronization, leading to significant communication and energy overhead. To address these shortcomings, we propose C-sync, a clustering-based decentralized time synchronization protocol that provides resilience against several types of faults with energy-efficient communication. C-sync achieves scalability by introducing multiple reference nodes in the network that restrict the maximum number of hops any node can have to its time source. The protocol is designed with a modular structure on the Contiki platform to allow application transitions. We evaluate C-sync on a real testbed that comprises over 40 Tmote Sky hardware nodes distributed across different levels in a building and show through experiments the fault resilience, energy efficiency, and scalability of the protocol. C-sync detects and isolates faults to a cluster and recovers quickly. The evaluation makes a qualitative comparison with state-of-the-art protocols and a quantitative comparison with a class of decentralized protocols (derived from GTSP) that provide synchronization with no/limited fault-tolerance. Results also show a reduction of 56.12% and 75.75% in power consumption in the worst-case and best-case scenarios, respectively, compared to GTSP, while achieving similar accuracy.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain Based Information Security and Privacy Protection: Challenges and Future Directions using Computational Literature Review</title>
<link>https://arxiv.org/abs/2409.14472</link>
<guid>https://arxiv.org/abs/2409.14472</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、信息系统的安全性与隐私性、文献综述、计算文学审查、主题建模

总结:
本文主要探讨了区块链技术在增强信息系统安全性与隐私性方面的影响，以及随着研究文献数量激增，进行有效分析和综合所面临的挑战。为解决这一问题，作者采用了一种名为“计算文学审查（CLR）”的方法，结合了主题建模技术（使用了Latent Dirichlet Allocation，LDA）对相关文献进行了分析。通过此方法，作者识别出了与安全性和隐私性相关的十个关键主题，并对每个主题进行了详细描述。

在对文献进行深度分析后，作者揭示了当前研究中的一些局限性，并基于此提出了未来的研究方向。这表明尽管区块链技术在增强安全性与隐私性方面展现出巨大潜力，但仍然存在需要进一步探索和解决的问题。例如，如何更有效地利用区块链技术保护数据不被非法访问或滥用，以及如何确保在分布式网络环境下数据的安全传输等。这些发现对于推动区块链技术在实际应用中的发展和优化具有重要意义。 <div>
arXiv:2409.14472v1 Announce Type: new 
Abstract: Blockchain technology is an emerging digital innovation that has gained immense popularity in enhancing individual security and privacy within Information Systems (IS). This surge in interest is reflected in the exponential increase in research articles published on blockchain technology, highlighting its growing significance in the digital landscape. However, the rapid proliferation of published research presents significant challenges for manual analysis and synthesis due to the vast volume of information. The complexity and breadth of topics, combined with the inherent limitations of human data processing capabilities, make it difficult to comprehensively analyze and draw meaningful insights from the literature. To this end, we adopted the Computational Literature Review (CLR) to analyze pertinent literature impact and topic modelling using the Latent Dirichlet Allocation (LDA) technique. We identified 10 topics related to security and privacy and provided a detailed description of each topic. From the critical analysis, we have observed several limitations, and several future directions are provided as an outcome of this review.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Review of Scalable and Privacy-Preserving Multi-Agent Frameworks for Distributed Energy Resource Control</title>
<link>https://arxiv.org/abs/2409.14499</link>
<guid>https://arxiv.org/abs/2409.14499</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式能源资源（DERs）、隐私保护、规模化、多代理系统、电力系统操作

总结:

本文聚焦于分布式能源资源（DERs）在大规模电力系统中的管理挑战，特别是数据处理的隐私性和操作优化的规模化问题。文章从多代理系统的视角全面审视了现有和新兴解决方案。在规模化方面，文章回顾了依赖于分布式或去中心化信息交换结构的并行控制、优化与学习的前沿研究。在隐私保护方面，文章识别了可融入上述规模化结构的隐私保留措施。

尽管这些领域已取得进展，但仍面临挑战，因为这些高度跨学科的研究结合了来自不同领域的各种可扩展计算架构和隐私保护技术，使其难以在实践中应用。为解决这一问题，文章提供了从多代理视角全面审视大规模电力系统操作策略的综述，特别针对DER控制问题。此外，文章还提出了未来可扩展、隐私意识和网络安全路径的新方法，以解锁DER的全部潜力，通过控制、优化和学习通用的多代理基于物理系统的途径。 <div>
arXiv:2409.14499v1 Announce Type: new 
Abstract: Distributed energy resources (DERs) are gaining prominence due to their advantages in improving energy efficiency, reducing carbon emissions, and enhancing grid resilience. Despite the increasing deployment, the potential of DERs has yet to be fully explored and exploited. A fundamental question restrains the management of numerous DERs in large-scale power systems, "How should DER data be securely processed and DER operations be efficiently optimized?" To address this question, this paper considers two critical issues, namely privacy for processing DER data and scalability in optimizing DER operations, then surveys existing and emerging solutions from a multi-agent framework perspective. In the context of scalability, this paper reviews state-of-the-art research that relies on parallel control, optimization, and learning within distributed and/or decentralized information exchange structures, while in the context of privacy, it identifies privacy preservation measures that can be synthesized into the aforementioned scalable structures. Despite research advances in these areas, challenges remain because these highly interdisciplinary studies blend a wide variety of scalable computing architectures and privacy preservation techniques from different fields, making them difficult to adapt in practice. To mitigate this issue, this paper provides a holistic review of trending strategies that orchestrate privacy and scalability for large-scale power system operations from a multi-agent perspective, particularly for DER control problems. Furthermore, this review extrapolates new approaches for future scalable, privacy-aware, and cybersecure pathways to unlock the full potential of DERs through controlling, optimizing, and learning generic multi-agent-based cyber-physical systems.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Integrated Blockchain and IPFS Solution for Secure and Efficient Source Code Repository Hosting using Middleman Approach</title>
<link>https://arxiv.org/abs/2409.14530</link>
<guid>https://arxiv.org/abs/2409.14530</guid>
<content:encoded><![CDATA[
<div> 关键词：版本控制、区块链、IPFS、智能合约、加密

总结:

本文提出了一种新型的去中心化版本控制系统，旨在解决当前集中式版本控制系统（如SVN、Git等）存在的数据丢失、安全漏洞和所有权争议等问题。该系统基于以太坊区块链和IPFS（InterPlanetary File System）构建，旨在实现更安全、高效和可靠的代码仓库托管与治理。

系统架构采用混合设计，将区块链的不可篡改和去中心化特性与IPFS的高效率离线存储相结合。通过引入“中间人”IPFS，系统在保持长期安全性的同时，实现了快速的实时协作。智能合约被用于管理访问控制和密钥管理，动态验证用户权限，确保只有经过授权的用户能够访问和解密存储在IPFS上的数据。

此外，系统采用了结合对称和非对称加密的混合加密方案，将密钥存储在区块链上，而IPFS负责高效地存储代码库本身。中间人IPFS则提供了一种平衡集中化系统速度与去中心化架构韧性的机制，特别适合于需要多个同时访问共享资源的大规模协作编码项目。

这种集成方案不仅增强了系统的安全性，还支持了实时协作，为软件开发团队提供了更为灵活、高效的工作环境。 <div>
arXiv:2409.14530v1 Announce Type: new 
Abstract: Version control systems (VCS) are essential for software development, yet centralized VCS present risks such as data loss, security breaches, and ownership disputes. While blockchain-based approaches to decentralized source code repository hosting have been explored, many existing solutions struggle with challenges related to security, scalability, efficiency, and real-time collaboration. This study seeks to enhance these efforts by proposing a novel decentralized solution that leverages the Ethereum blockchain and IPFS for secure, efficient, and resilient code repository hosting and governance. Our approach introduces a hybrid architecture that combines the immutable and decentralized nature of blockchain with the efficiency of IPFS for off-chain storage. To facilitate real-time collaboration, we integrate a temporary centralized Middleman IPFS that manages transaction processing and enhances operational efficiency without compromising long-term security. This Middleman IPFS acts as an intermediary, balancing the speed of centralized systems with the resilience of decentralized architectures. Our system uses smart contracts to maintain access control and key management by dynamically verifying access rights, ensuring that only authorized users can retrieve and decrypt data stored on IPFS. This integration allows for secure, real-time collaboration in environments where multiple collaborators need concurrent access to shared resources. Our system employs a hybrid encryption scheme that combines symmetric and asymmetric cryptography. The encrypted keys are stored on the blockchain, while IPFS handles the efficient storage of the codebase itself, with a Middleman IPFS maintaining concurrent collaboration, providing a robust and scalable solution for managing large-scale, collaborative coding projects.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Brain Surgery: Ensuring GDPR Compliance in Large Language Models via Concept Erasure</title>
<link>https://arxiv.org/abs/2409.14603</link>
<guid>https://arxiv.org/abs/2409.14603</guid>
<content:encoded><![CDATA[
<div> 关键词：大型AI系统、GDPR、Brain Surgery、隐私管理、持续学习

总结:

本文介绍了名为“脑外科手术”的创新方法，旨在让每一种本地人工智能模型都符合《通用数据保护条例》（GDPR）的要求。通过实现实时隐私管理和针对特定情况的遗忘功能，该方法能确保人工智能系统的合规性。其核心包括嵌入式破坏提示（ECO提示）、基于区块链的隐私管理以及隐私意识持续学习等高级技术。

脑外科手术提供了一个模块化解决方案，适用于各种AI架构。它不仅确保了隐私法规的遵守，还赋予用户定义自身隐私界限的能力，从而开创了AI伦理和治理的新范式。通过引入这些先进的技术，该方法旨在为AI发展提供强大的隐私保护框架，确保在人工智能快速发展的时代，数据隐私能够得到充分尊重和保护。 <div>
arXiv:2409.14603v1 Announce Type: new 
Abstract: As large-scale AI systems proliferate, ensuring compliance with data privacy laws such as the General Data Protection Regulation (GDPR) has become critical. This paper introduces Brain Surgery, a transformative methodology for making every local AI model GDPR-ready by enabling real-time privacy management and targeted unlearning. Building on advanced techniques such as Embedding-Corrupted Prompts (ECO Prompts), blockchain-based privacy management, and privacy-aware continual learning, Brain Surgery provides a modular solution that can be deployed across various AI architectures. This tool not only ensures compliance with privacy regulations but also empowers users to define their own privacy limits, creating a new paradigm in AI ethics and governance.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>MECURY: Practical Cross-Chain Exchange via Trusted Hardware</title>
<link>https://arxiv.org/abs/2409.14640</link>
<guid>https://arxiv.org/abs/2409.14640</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数字货币、可信执行环境（TEE）、跨链交易、成本优化

<br /><br />总结:

本文介绍了一种名为MERCURY的新型跨链数字货币交易平台。该平台通过利用可信执行环境（TEE）技术来实现信任最小化和高效运行，无需在线客户端，从而提升用户体验。MERCURY的创新之处在于其采用高效的挑战响应机制和智能合约执行方式来解决TEE的不可用问题，同时通过轻量级交易验证机制和多项优化措施来降低链上成本。

具体而言，MERCURY相较于现有解决方案（如XClaim、ZK-bridge和Tesseract），显著降低了约67.87%、45.01%和47.70%的链上成本。这不仅提升了交易效率，也增强了平台的安全性和可靠性。通过上述改进，MERCURY为数字货币的跨链交易提供了更为便捷、安全且经济的解决方案。 <div>
arXiv:2409.14640v1 Announce Type: new 
Abstract: The proliferation of blockchain-backed cryptocurrencies has sparked the need for cross-chain exchanges of diverse digital assets. Unfortunately, current exchanges suffer from high on-chain verification costs, weak threat models of central trusted parties, or synchronous requirements, making them impractical for currency trading applications. In this paper, we present MERCURY, a practical cryptocurrency exchange that is trust-minimized and efficient without online-client requirements. MERCURY leverages Trusted Execution Environments (TEEs) to shield participants from malicious behaviors, eliminating the reliance on trusted participants and making on-chain verification efficient. Despite the simple idea, building a practical TEE-assisted cross-chain exchange is challenging due to the security and unavailability issues of TEEs. MERCURY tackles the unavailability problem of TEEs by implementing an efficient challenge-response mechanism executed on smart contracts. Furthermore, MERCURY utilizes a lightweight transaction verification mechanism and adopts multiple optimizations to reduce on-chain costs. Comparative evaluations with XClaim, ZK-bridge, and Tesseract demonstrate that MERCURY significantly reduces on-chain costs by approximately 67.87%, 45.01%, and 47.70%, respectively.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>TeeRollup: Efficient Rollup Design Using Heterogeneous TEE</title>
<link>https://arxiv.org/abs/2409.14647</link>
<guid>https://arxiv.org/abs/2409.14647</guid>
<content:encoded><![CDATA[
<div> 关键词：TeeRollup、Trusted Execution Environments（TEEs）、sequencers、Data Availability Providers（DAPs）、laziness penalty game

总结:
文章主要介绍了TeeRollup，一种新型的区块链扩展解决方案。TeeRollup旨在通过在可信执行环境(TEEs)中运行交易的验证器来提高区块链的可扩展性，同时降低验证成本和缩短提款延迟。该方案采用分布式系统设计，确保即使部分TEEs被破坏，系统也能保持安全。此外，TeeRollup引入了挑战机制来应对TEEs不可用导致的赎回问题，并通过数据可用性提供者(DAPs)减少链上存储开销。为了约束DAP行为，引入了懒惰惩罚游戏机制。实验结果显示，与零知识证明卷积（zk-rollups）相比，TeeRollup显著降低了链上验证成本（约86%）并将提款延迟缩短至几分钟。这一创新为区块链技术在去中心化应用中的广泛应用提供了可能。 <div>
arXiv:2409.14647v1 Announce Type: new 
Abstract: Rollups have emerged as a promising approach to improving blockchains' scalability by offloading transactions execution off-chain. Existing rollup solutions either leverage complex zero-knowledge proofs or optimistically assume execution correctness unless challenged. However, these solutions have practical issues such as high gas costs and significant withdrawal delays, hindering their adoption in decentralized applications. This paper introduces TeeRollup, an efficient rollup design with low gas costs and short withdrawal delays. TeeRollup employs Trusted Execution Environments (TEEs)-supported sequencers to execute transactions, requiring the blockchain to verify only the TEEs' signatures. TeeRollup is designed under a realistic threat model in which the integrity and availability of sequencers' TEEs may be compromised. To address these issues, we first introduce a distributed system of sequencers with heterogeneous TEEs, ensuring system security even if a minority of TEEs are compromised. Second, we propose a challenge mechanism to solve the redeemability issue caused by TEE unavailability. Furthermore, TeeRollup incorporates Data Availability Providers (DAPs) to reduce on-chain storage overhead and uses a laziness penalty game to regulate DAP behavior. We implement a prototype of TeeRollup in Golang, using the Ethereum test network, Sepolia. Our experimental results indicate that TeeRollup outperforms zero-knowledge rollups (zk-rollups), reducing on-chain verification costs by approximately 86% and withdrawal delays to a few minutes.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Loopy Movements: Emergence of Rotation in a Multicellular Robot</title>
<link>https://arxiv.org/abs/2409.15187</link>
<guid>https://arxiv.org/abs/2409.15187</guid>
<content:encoded><![CDATA[
<div> 关键词：生物系统、Loopy机器人、分散式旋转、自组织、适应性

总结:

本文研究了Loopy多细胞机器人中的自发分散式旋转现象。Loopy由同质的、物理相连的单自由度单元组成，通过模拟化学物质（即形态发生器）的扩散、反应和主动运输进行简单的局部交互，而无需中央控制或全局形态知识。这些交互使机器人能够自我组织并实现协调的旋转运动，形成局部凸起——由电机细胞集群产生的局部突出。研究发现，Loopy表现出两种独特行为：1）内部山谷之间的旋转速度比外部峰顶快，与刚体动力学相反；2）细胞的旋转方向与整体形态相反。

实验表明，尽管Loopy的形态对相对环境而言的角速度没有影响，但较大的叶片会增加细胞的旋转速度并降低形态的旋转速度。即使有三分之一的执行器失效并经历显著的形态变化，Loopy仍能保持其旋转能力。这揭示了分散式、生物启发策略在构建具有韧性和适应性的机器人系统方面的潜力。 <div>
arXiv:2409.15187v1 Announce Type: new 
Abstract: Unlike most human-engineered systems, many biological systems rely on emergent behaviors from low-level interactions, enabling greater diversity and superior adaptation to complex, dynamic environments. This study explores emergent decentralized rotation in the Loopy multicellular robot, composed of homogeneous, physically linked, 1-degree-of-freedom cells. Inspired by biological systems like sunflowers, Loopy uses simple local interactions-diffusion, reaction, and active transport of simulated chemicals, called morphogens-without centralized control or knowledge of its global morphology. Through these interactions, the robot self-organizes to achieve coordinated rotational motion and forms lobes-local protrusions created by clusters of motor cells. This study investigates how these interactions drive Loopy's rotation, the impact of its morphology, and its resilience to actuator failures. Our findings reveal two distinct behaviors: 1) inner valleys between lobes rotate faster than the outer peaks, contrasting with rigid body dynamics, and 2) cells rotate in the opposite direction of the overall morphology. The experiments show that while Loopy's morphology does not affect its angular velocity relative to its cells, larger lobes increase cellular rotation and decrease morphology rotation relative to the environment. Even with up to one-third of its actuators disabled and significant morphological changes, Loopy maintains its rotational abilities, highlighting the potential of decentralized, bio-inspired strategies for resilient and adaptable robotic systems.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Solvent: liquidity verification of smart contracts</title>
<link>https://arxiv.org/abs/2404.17864</link>
<guid>https://arxiv.org/abs/2404.17864</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、攻击目标、流动性属性、验证工具、Solvent

<br /><br />
总结:
本文聚焦于智能合约领域中的安全问题，指出智能合约因其独特的性质而成为攻击者青睐的目标。现有的智能合约验证工具在表达和验证与加密资产交换相关的流动性属性方面存在局限性。为解决这一问题，作者提出了一种名为“Solvent”的新型验证工具。Solvent旨在验证那些现有验证工具难以处理的流动性属性，如用户是否能在任何可达状态下通过一系列交易提取特定数量的加密资产。

该研究通过使用常见智能合约基准进行了评估，以检验Solvent的有效性和性能。结果显示，Solvent在验证复杂流动性属性方面表现出色，提高了智能合约的安全性。这一工具的开发不仅推动了智能合约领域的安全性提升，也为未来智能合约的可靠性和实用性提供了重要支持。 <div>
arXiv:2404.17864v3 Announce Type: replace 
Abstract: Smart contracts are an attractive target for attackers, as evidenced by a long history of security incidents. A current limitation of smart contract verification tools is that they are not really effective in expressing and verifying liquidity properties regarding the exchange of crypto-assets: for example, is it true that in every reachable state a user can fire a sequence of transactions to withdraw a given amount of crypto-assets? We propose Solvent, a tool aimed at verifying these kinds of properties, which are beyond the reach of existing verification tools for Solidity. We evaluate the effectiveness and performance of Solvent through a common benchmark of smart contracts.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Dataset of Uniswap daily transaction indices by network</title>
<link>https://arxiv.org/abs/2312.02660</link>
<guid>https://arxiv.org/abs/2312.02660</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance (DeFi), Layer 2 (L2) solutions, Ethereum, Uniswap, Python框架

总结:
本文研究了去中心化金融(DeFi)如何通过直接交易和消除中介，重塑传统金融领域，并引入了Layer 2(L2)解决方案以增强DeFi生态系统的可扩展性和效率。然而，L2解决方案的影响仍需深入探索，主要是因为缺乏全面的交易数据索引供经济分析使用。为了填补这一空白，研究团队分析了来自Uniswap的主要去中心化交易所超过5千万笔交易的数据，横跨L1和L2网络。他们从以太坊区块链数据中创建了一系列每日指标，涵盖了DeFi采用、可扩展性、去中心化和财富分配等方面。此外，研究团队还开发了一个开源Python框架来计算去中心化指数，使得该数据集对高级机器学习研究极具价值。这项工作提供了宝贵的数据资源，对数据科学家而言意义重大，并有助于推动智能Web3生态系统的发展。 <div>
arXiv:2312.02660v2 Announce Type: replace-cross 
Abstract: Decentralized Finance (DeFi) is reshaping traditional finance by enabling direct transactions without intermediaries, creating a rich source of open financial data. Layer 2 (L2) solutions are emerging to enhance the scalability and efficiency of the DeFi ecosystem, surpassing Layer 1 (L1) systems. However, the impact of L2 solutions is still underexplored, mainly due to the lack of comprehensive transaction data indices for economic analysis. This study bridges that gap by analyzing over 50 million transactions from Uniswap, a major decentralized exchange, across both L1 and L2 networks. We created a set of daily indices from blockchain data on Ethereum, Optimism, Arbitrum, and Polygon, offering insights into DeFi adoption, scalability, decentralization, and wealth distribution. Additionally, we developed an open-source Python framework for calculating decentralization indices, making this dataset highly useful for advanced machine learning research. Our work provides valuable resources for data scientists and contributes to the growth of the intelligent Web3 ecosystem.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stabl: Blockchain Fault Tolerance</title>
<link>https://arxiv.org/abs/2409.13142</link>
<guid>https://arxiv.org/abs/2409.13142</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、故障容忍性、Algorand、Avalanche、Solana

<br /><br />
总结:
本文评估了五种现代区块链系统（Algorand、Aptos、Avalanche、Redbelly和Solana）的故障容忍能力。研究中引入了一种新颖的敏感度指标，通过比较基线环境和对抗环境下的两个累积分布函数的积分差来量化这一指标。结果显示：

1. 除了Redbelly外，所有区块链系统都对网络中一小部分节点的失效高度敏感。
2. Avalanche和Redbelly得益于冗余信息，这有助于实现拜占庭容错，而其他系统则因冗余而受到阻碍。
3. 更为显著的是，Avalanche和Solana无法从局部瞬态故障中恢复。

这项研究揭示了区块链系统的故障容忍性存在显著差异，特别是当考虑特定于系统的架构决策时。这些发现对于理解区块链在实际部署中的可靠性和选择最适合特定需求的区块链技术至关重要。 <div>
arXiv:2409.13142v1 Announce Type: new 
Abstract: Blockchain promises to make online services more fault tolerant due to their inherent distributed nature. Their ability to execute arbitrary programs in different geo-distributed regions and on diverse operating systems make them an alternative of choice to our dependence on unique software whose recent failure affected 8.5 millions of machines. As of today, it remains, however, unclear whether blockchains can truly tolerate failures.
  In this paper, we assess the fault tolerance of blockchain. To this end, we inject failures in controlled deployments of five modern blockchain systems, namely Algorand, Aptos, Avalanche, Redbelly and Solana. We introduce a novel sensitivity metric, interesting in its own right, as the difference between the integrals of two cumulative distribution functions, one obtained in a baseline environment and one obtained in an adversarial environment. Our results indicate that (i) all blockchains except Redbelly are highly impacted by the failure of a small part of their network, (ii) Avalanche and Redbelly benefit from the redundant information needed for Byzantine fault tolerance while others are hampered by it, and more dramatically (iii) Avalanche and Solana cannot recover from localised transient failures.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative distributed model predictive control for embedded systems: Experiments with hovercraft formations</title>
<link>https://arxiv.org/abs/2409.13334</link>
<guid>https://arxiv.org/abs/2409.13334</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式模型预测控制、多旋翼飞行器、空气曲棍球台、交替方向乘子法、集中式最优控制问题

<br /><br />
总结:
本文报告了一项关于在空气曲棍球台上对一组多旋翼飞行器进行嵌入式合作分布式模型预测控制的实验。这些飞行器通过一种稳定的去中心化实时迭代方案解决每个采样步骤中的集中式最优控制问题，该方案使用交替方向乘子法。此方法无需中央协调器，可在飞行器上独立执行，实现毫秒级的采样间隔。实验展示了控制策略在点对点转换、轨迹跟踪、碰撞避免和移动障碍物等场景下的灵活性。通过这些实验，证明了分布式模型预测控制在复杂动态环境中的高效性和适应性。 <div>
arXiv:2409.13334v1 Announce Type: new 
Abstract: This paper presents experiments for embedded cooperative distributed model predictive control applied to a team of hovercraft floating on an air hockey table. The hovercraft collectively solve a centralized optimal control problem in each sampling step via a stabilizing decentralized real-time iteration scheme using the alternating direction method of multipliers. The efficient implementation does not require a central coordinator, executes onboard the hovercraft, and facilitates sampling intervals in the millisecond range. The formation control experiments showcase the flexibility of the approach on scenarios with point-to-point transitions, trajectory tracking, collision avoidance, and moving obstacles.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noise-Robust and Resource-Efficient ADMM-based Federated Learning</title>
<link>https://arxiv.org/abs/2409.13451</link>
<guid>https://arxiv.org/abs/2409.13451</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、通信噪声、权重最小二乘法、交替方向乘子法（ADMM）、性能提升

总结:
本文提出了一种针对联邦学习(Federated Learning, FL)的新算法，旨在提高模型对通信噪声的鲁棒性同时减少通信负载。通过将权重最小二乘法(WLS)回归问题作为示例，构建了一个分布式凸优化问题，该问题在具有随机调度的联邦网络中进行了解。应用交替方向乘子法(ADMM)解决这一问题。为对抗累积通信噪声的负面影响，引入关键修改，通过消除双变量和在每个参与客户端实施新的局部模型更新，使得每个客户端只需使用一次有噪声的全局模型更新，而非两次，从而提高了对加性通信噪声的鲁棒性。此外，通过允许客户端在未被服务器选择时继续进行本地更新，进一步提升了算法性能。理论分析证实了算法在通信噪声和服务器随机选择客户端的迭代过程中的收敛性，无论是在均值还是均方意义上。数值结果验证了所提算法的有效性，并与理论发现相吻合。 <div>
arXiv:2409.13451v1 Announce Type: new 
Abstract: Federated learning (FL) leverages client-server communications to train global models on decentralized data. However, communication noise or errors can impair model accuracy. To address this problem, we propose a novel FL algorithm that enhances robustness against communication noise while also reducing communication load. We derive the proposed algorithm through solving the weighted least-squares (WLS) regression problem as an illustrative example. We first frame WLS regression as a distributed convex optimization problem over a federated network employing random scheduling for improved communication efficiency. We then apply the alternating direction method of multipliers (ADMM) to iteratively solve this problem. To counteract the detrimental effects of cumulative communication noise, we introduce a key modification by eliminating the dual variable and implementing a new local model update at each participating client. This subtle yet effective change results in using a single noisy global model update at each client instead of two, improving robustness against additive communication noise. Furthermore, we incorporate another modification enabling clients to continue local updates even when not selected by the server, leading to substantial performance improvements. Our theoretical analysis confirms the convergence of our algorithm in both mean and the mean-square senses, even when the server communicates with a random subset of clients over noisy links at each iteration. Numerical results validate the effectiveness of our proposed algorithm and corroborate our theoretical findings.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proxion: Uncovering Hidden Proxy Smart Contracts for Finding Collision Vulnerabilities in Ethereum</title>
<link>https://arxiv.org/abs/2409.13563</link>
<guid>https://arxiv.org/abs/2409.13563</guid>
<content:encoded><![CDATA[
<div> 关键词：Proxion、智能合约、升级性、安全性、漏洞检测

总结:
文章介绍了一款名为Proxion的自动化跨合约分析工具，其主要功能在于识别Ethereum中的代理智能合约及其可能存在的冲突。与以往工具相比，Proxion的独特之处在于它能分析那些缺乏源代码和历史交易记录的隐藏智能合约。通过采用多种提升效率和准确性的技术手段，Proxion在识别代理智能合约的数量和检测未被报道的冲突方面表现出色，显著超越了现有工具。研究发现，从2015年到2023年的活跃合约中，有54.2%是代理合约，约有150万个合约存在至少一个冲突问题。

Proxion的开发旨在解决代理智能合约设计模式中存在的安全问题，特别是函数碰撞和存储碰撞。这些安全漏洞曾在现实世界中导致用户大量数字资产被盗。通过使用Proxion进行深入分析，可以更全面地识别并预防这类风险，为智能合约的安全性和稳定性提供重要保障。同时，该工具的广泛应用有助于提高整个区块链生态系统的安全性，防止未来类似事件的发生。 <div>
arXiv:2409.13563v1 Announce Type: new 
Abstract: The proxy design pattern allows Ethereum smart contracts to be simultaneously immutable and upgradeable, in which an original contract is split into a proxy contract containing the data storage and a logic contract containing the implementation logic. This architecture is known to have security issues, namely function collisions and storage collisions between the proxy and logic contracts, and has been exploited in real-world incidents to steal users' millions of dollars worth of digital assets. In response to this concern, several previous works have sought to identify proxy contracts in Ethereum and detect their collisions. However, they all fell short due to their limited coverage, often restricting analysis to only contracts with available source code or past transactions.
  To bridge this gap, we present Proxion, an automated cross-contract analyzer that identifies all proxy smart contracts and their collisions in Ethereum. What sets Proxion apart is its ability to analyze hidden smart contracts that lack both source code and past transactions. Equipped with various techniques to enhance efficiency and accuracy, Proxion outperforms the state-of-the-art tools, notably identifying millions more proxy contracts and thousands of unreported collisions. We apply Proxion to analyze over 36 million alive contracts from 2015 to 2023, revealing that 54.2% of them are proxy contracts, and about 1.5 million contracts exhibit at least one collision issue.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Credential Status Management: A Paradigm Shift in Digital Trust</title>
<link>https://arxiv.org/abs/2406.11511</link>
<guid>https://arxiv.org/abs/2406.11511</guid>
<content:encoded><![CDATA[
<div> 关键词：公共密钥基础设施、互联网安全、证书管理、去中心化、区块链技术

总结:
本文探讨了从集中式到分散式体系结构中证书状态管理的演变，重点关注区块链技术和高级密码学。文章首先分析了集中式系统面临的挑战，如单点故障和信任集中问题，并讨论了现有分散式技术提供的机遇。研究发现，尽管区块链技术提高了安全性与信任分布，但也存在计算并行性受限和加密计算效率低下的瓶颈。为解决这些问题，文章提出了一个分散式技术组件框架，旨在促进向分散式凭证状态管理范式的转变。这一框架旨在克服现有技术的局限性，实现更高效、安全的证书管理。通过整合分散式技术的优势，该框架有望提升互联网整体安全性和可靠性。 <div>
arXiv:2406.11511v2 Announce Type: replace 
Abstract: Public key infrastructures are essential for Internet security, ensuring robust certificate management and revocation mechanisms. The transition from centralized to decentralized systems presents challenges such as trust distribution and privacy-preserving credential management. The transition from centralized to decentralized systems is motivated by addressing the single points of failure inherent in centralized systems and leveraging decentralized technologies' transparency and resilience. This paper explores the evolution of certificate status management from centralized to decentralized frameworks, focusing on blockchain technology and advanced cryptography. We provide a taxonomy of the challenges of centralized systems and discuss opportunities provided by existing decentralized technologies. Our findings reveal that, although blockchain technologies enhance security and trust distribution, they represent a bottleneck for parallel computation and face inefficiencies in cryptographic computations. For this reason, we propose a framework of decentralized technology components that addresses such shortcomings to advance the paradigm shift toward decentralized credential status management.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>SplitVAEs: Decentralized scenario generation from siloed data for stochastic optimization problems</title>
<link>https://arxiv.org/abs/2409.12328</link>
<guid>https://arxiv.org/abs/2409.12328</guid>
<content:encoded><![CDATA[
<div> 关键词：Stochastic优化、分布式网络系统、数据驱动场景、变分自编码器（SplitVAEs）、隐私保护

<br /><br />
总结:

本文提出了一种名为SplitVAEs的分布式生成框架，旨在解决大型多利益相关者网络系统（如电力电网和供应链）中基于数据驱动的场景生成问题。SplitVAEs利用变分自编码器技术，无需移动数据即可生成高质量的场景，从而避免了数据孤岛带来的挑战。实验结果表明，SplitVAEs能够学习大规模网络中的空间和时间依赖性，以分散方式匹配多个利益相关者数据的历史联合分布。

通过在分布式内存系统上的实验，证明了SplitVAEs在不同领域中的广泛适用性，这些领域由大量利益相关者主导。与集中式最先进的基准方法相比，SplitVAEs显示出稳健的性能，并显著降低了数据传输成本，提供了比传统方法更可扩展、更注重隐私的场景生成替代方案。 <div>
arXiv:2409.12328v1 Announce Type: new 
Abstract: Stochastic optimization problems in large-scale multi-stakeholder networked systems (e.g., power grids and supply chains) rely on data-driven scenarios to encapsulate complex spatiotemporal interdependencies. However, centralized aggregation of stakeholder data is challenging due to the existence of data silos resulting from computational and logistical bottlenecks. In this paper, we present SplitVAEs, a decentralized scenario generation framework that leverages variational autoencoders to generate high-quality scenarios without moving stakeholder data. With the help of experiments on distributed memory systems, we demonstrate the broad applicability of SplitVAEs in a variety of domain areas that are dominated by a large number of stakeholders. Our experiments indicate that SplitVAEs can learn spatial and temporal interdependencies in large-scale networks to generate scenarios that match the joint historical distribution of stakeholder data in a decentralized manner. Our experiments show that SplitVAEs deliver robust performance compared to centralized, state-of-the-art benchmark methods while significantly reducing data transmission costs, leading to a scalable, privacy-enhancing alternative to scenario generation.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Data to Control: A Formal Compositional Framework for Large-Scale Interconnected Networks</title>
<link>https://arxiv.org/abs/2409.12469</link>
<guid>https://arxiv.org/abs/2409.12469</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、全分布式、安全控制器、未知模型、互联网络

总结:
本文提出了一种基于数据驱动的全分布式方法，用于设计适用于大规模互联网络的安全控制器，这些网络中的子系统具有未知的数学模型。该方法通过利用互联拓扑结构，将网络分析分解为对不同子系统的单独检查。为了捕获子系统之间的联合耗散性质，引入了控制存储证书（CSCs）的概念。CSCs在通过数据组成的推导中起着关键作用，以获得专为此互联网络设计的控制障碍证书（CBC），从而确保其安全性。

在数据驱动的方案中，仅需从每个未知子系统收集一段输入输出轨迹。通过满足特定的秩条件，可以构造出每个子系统的CSC。接着，遵循组成性耗散推理，将数据生成的CSCs组合起来，构建出未知网络的CBC，确保其在无限时间内的安全性，同时提供正确的保证。这种方法显著提高了CBC及其安全控制器在整个互联网络中的设计效率，通过将计算复杂度从与网络维度相关的多项式增长降低到与子系统数量成线性的比例，利用了互联拓扑的结构并可能不受子系统数量的影响来满足耗散型组成性条件。

通过应用于涉及未知模型和不同互联拓扑的物理网络的多种基准测试，证明了数据驱动方法的有效性和适用性。 <div>
arXiv:2409.12469v1 Announce Type: new 
Abstract: We introduce a compositional data-driven methodology for designing fully-decentralized safety controllers applicable to large-scale interconnected networks, encompassing subsystems with unknown mathematical models. Our compositional scheme leverages the interconnection topology and breaks down the network analysis into the examination of distinct subsystems. This is accompanied by utilizing a concept of control storage certificates (CSCs) to capture joint dissipativity-type properties among subsystems. These CSCs are instrumental in a compositional derivation of a control barrier certificate (CBC) specialized for the interconnected network, thereby ensuring its safety. In our data-driven scheme, we gather solely one input-output trajectory from each unknown subsystem within a specified time frame. By fulfilling a specific rank condition, this process facilitates the construction of a CSC for each subsystem. Following this, by adhering to compositional dissipativity reasoning, we compose CSCs derived from data and build a CBC for the unknown network, ensuring its safety over an infinite time horizon, while providing correctness guarantees. We demonstrate that our compositional data-driven approach significantly enhances the design of a CBC and its safety controller across the interconnected network. This advancement is achieved by reducing the computational complexity from a polynomial growth in relation to network dimension, when using sum-of-squares (SOS) optimization, to a linear scale based on the number of subsystems. We additionally demonstrate that the dissipativity-type compositionality condition can benefit from the structure of interconnection topology and potentially be fulfilled regardless of the number of subsystems. We apply our data-driven findings to a variety of benchmarks, involving physical networks with unknown models and diverse interconnection topologies.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Hardness of Decentralized Multi-Agent Policy Evaluation under Byzantine Attacks</title>
<link>https://arxiv.org/abs/2409.12882</link>
<guid>https://arxiv.org/abs/2409.12882</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、分布式评估、拜占庭故障、模型中毒、共识算法

总结:
本文研究了在最多存在$f$个故障智能体的全分布式多智能体策略评估问题。特别关注了由拜占庭故障模型与模型中毒设定下的多智能体系统。通常情况下，策略评估是评估给定策略的价值函数。在协作多智能体系统中，系统总奖励被建模为所有智能体奖励的均匀平均值。文章探讨了在拜占庭智能体存在的背景下，特别是异构局部奖励设置下的多智能体策略评估问题。理想目标是评估累积系统总奖励，即正常智能体给定策略的均匀平均奖励值。然而，证明了该目标不可实现。因此，文章提出了一个放松版本的问题，目标是评估累积系统总奖励，这被视为正常智能体给定策略的加权平均奖励。进一步证明了没有正确的算法能够保证正权重总数超过$|\mathcal{N}|-f $，其中$|\mathcal{N}|$表示正常智能体的数量。最后，提出了一种基于标量函数近似的拜占庭容错分布式时间差分算法，能够确保在渐进共识下算法的有效性，并通过实验验证了算法的有效性。 <div>
arXiv:2409.12882v1 Announce Type: new 
Abstract: In this paper, we study a fully-decentralized multi-agent policy evaluation problem, which is an important sub-problem in cooperative multi-agent reinforcement learning, in the presence of up to $f$ faulty agents. In particular, we focus on the so-called Byzantine faulty model with model poisoning setting. In general, policy evaluation is to evaluate the value function of any given policy. In cooperative multi-agent system, the system-wide rewards are usually modeled as the uniform average of rewards from all agents. We investigate the multi-agent policy evaluation problem in the presence of Byzantine agents, particularly in the setting of heterogeneous local rewards. Ideally, the goal of the agents is to evaluate the accumulated system-wide rewards, which are uniform average of rewards of the normal agents for a given policy. It means that all agents agree upon common values (the consensus part) and furthermore, the consensus values are the value functions (the convergence part). However, we prove that this goal is not achievable. Instead, we consider a relaxed version of the problem, where the goal of the agents is to evaluate accumulated system-wide reward, which is an appropriately weighted average reward of the normal agents. We further prove that there is no correct algorithm that can guarantee that the total number of positive weights exceeds $|\mathcal{N}|-f $, where $|\mathcal{N}|$ is the number of normal agents. Towards the end, we propose a Byzantine-tolerant decentralized temporal difference algorithm that can guarantee asymptotic consensus under scalar function approximation. We then empirically test the effective of the proposed algorithm.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Model for Multi-Agent Heterogeneous Interaction Problems</title>
<link>https://arxiv.org/abs/2208.01430</link>
<guid>https://arxiv.org/abs/2208.01430</guid>
<content:encoded><![CDATA[
<div> 关键词：多代理交互、异质团队、交叉反应性、资源优化、免疫系统启发

总结:

本文提出了一种模型，用于研究异质团队的代理如何组织资源以应对异质攻击者。该模型灵感源自人体免疫系统对抗多样病原体的方式。关键特征是“交叉反应性”核函数，它使得特定防御类型能够强烈响应某些攻击类型，但对少数不同的攻击类型则响应较弱。研究表明，由于这种交叉反应性，防御团队可以使用非常少的防御代理类型来最优地对抗异质攻击团队，从而最小化其资源消耗。

文章在不同设置下研究了此模型，以识别控制问题中异质代理团队的指导原则，包括损害敏感性对非最优防御分布的影响以及防御者之间的竞争如何导致接近最优行为的分散式计算。此外，与现有的方法进行了比较，如基于强化学习的策略、围栏防御和覆盖控制等。

该模型提供了一个新颖的方法论框架，旨在通过借鉴免疫系统的策略，为复杂多代理系统的资源分配和协调提供理论基础与实践指导。 <div>
arXiv:2208.01430v4 Announce Type: replace 
Abstract: We introduce a model for multi-agent interaction problems to understand how a heterogeneous team of agents should organize its resources to tackle a heterogeneous team of attackers. This model is inspired by how the human immune system tackles a diverse set of pathogens. The key property of this model is a ``cross-reactivity'' kernel which enables a particular defender type to respond strongly to some attacker types but weakly to a few different types of attackers. We show how due to such cross-reactivity, the defender team can optimally counteract a heterogeneous attacker team using very few types of defender agents, and thereby minimize its resources. We study this model in different settings to characterize a set of guiding principles for control problems with heterogeneous teams of agents, e.g., sensitivity of the harm to sub-optimal defender distributions, and competition between defenders gives near-optimal behavior using decentralized computation of the control. We also compare this model with existing approaches including reinforcement-learned policies, perimeter defense, and coverage control.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DAppSCAN: Building Large-Scale Datasets for Smart Contract Weaknesses in DApp Projects</title>
<link>https://arxiv.org/abs/2305.08456</link>
<guid>https://arxiv.org/abs/2305.08456</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart Contract Weakness Classification Registry、DApp、SWC Registry、DAPPSCAN、smart contract weakness detection tools

<br /><br />
总结:

本文主要关注于构建一个大规模的智能合约弱点数据集，以评估智能合约分析工具的性能。首先，通过分析1199份开源审计报告，从29个安全团队中识别出了9154个弱点，并创建了两个数据集：DAPPSCAN-SOURCE和DAPPSCAN-BYTECODE。其中，DAPPSCAN-SOURCE包含了39904个Solidity文件，以及源自682个真实DApp项目的1618个SWC弱点。然而，这些Solidity文件可能无法直接编译进行进一步分析。为了促进自动化分析，开发了一个工具来识别DApp项目中的依赖关系并完成缺失的公共库。基于此，创建了DAPPSCAN-BYTECODE数据集，其中包括6665个已编译的智能合约及888个SWC弱点。

在DAPPSCAN-BYTECODE数据集上进行了实证研究，评估了最先进的智能合约弱点检测工具的性能。结果显示，这些工具在有效性和成功检测率方面表现不佳，表明未来的研究应优先考虑现实世界的数据集，而非简单的玩具合同。 <div>
arXiv:2305.08456v3 Announce Type: replace 
Abstract: The Smart Contract Weakness Classification Registry (SWC Registry) is a widely recognized list of smart contract weaknesses specific to the Ethereum platform. Despite the SWC Registry not being updated with new entries since 2020, the sustained development of smart contract analysis tools for detecting SWC-listed weaknesses highlights their ongoing significance in the field. However, evaluating these tools has proven challenging due to the absence of a large, unbiased, real-world dataset. To address this problem, we aim to build a large-scale SWC weakness dataset from real-world DApp projects. We recruited 22 participants and spent 44 person-months analyzing 1,199 open-source audit reports from 29 security teams. In total, we identified 9,154 weaknesses and developed two distinct datasets, i.e., DAPPSCAN-SOURCE and DAPPSCAN-BYTECODE. The DAPPSCAN-SOURCE dataset comprises 39,904 Solidity files, featuring 1,618 SWC weaknesses sourced from 682 real-world DApp projects. However, the Solidity files in this dataset may not be directly compilable for further analysis. To facilitate automated analysis, we developed a tool capable of automatically identifying dependency relationships within DApp projects and completing missing public libraries. Using this tool, we created DAPPSCAN-BYTECODE dataset, which consists of 6,665 compiled smart contract with 888 SWC weaknesses. Based on DAPPSCAN-BYTECODE, we conducted an empirical study to evaluate the performance of state-of-the-art smart contract weakness detection tools. The evaluation results revealed sub-par performance for these tools in terms of both effectiveness and success detection rate, indicating that future development should prioritize real-world datasets over simplistic toy contracts.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CyberNFTs: Conceptualizing a decentralized and reward-driven intrusion detection system with ML</title>
<link>https://arxiv.org/abs/2409.11409</link>
<guid>https://arxiv.org/abs/2409.11409</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、区块链、机器学习、网络安全、非同质化代币

<br /><br />
总结:本文探讨了在Web3时代背景下，如何利用新兴技术构建去中心化的协作入侵检测网络（CIDN）。通过将区块链概念、机器学习算法以及出版/订阅架构整合，提出了一种新颖的信息安全模型。模型中引入了基于区块链的奖励机制——“CyberNFT”，旨在激励网络参与者进行安全贡献。文章还分析了该系统的优势和局限性，强调了去中心化在增强网络安全中的潜力。此研究为未来网络防御策略提供了创新思路，有望在保障数据安全与促进用户隐私保护之间找到平衡点。

通过结合区块链技术的透明性和不可篡改性，以及机器学习对异常行为的智能识别能力，该模型旨在实现更高效、更精准的入侵检测。同时，通过“CyberNFT”机制，鼓励用户或网络节点贡献安全信息或资源，形成一种正向的激励机制，促进整个网络的安全性和稳定性。然而，这一系统也面临着技术实现复杂性、经济激励可持续性等问题。因此，研究进一步讨论了这些挑战及其解决方案的可能性，为未来的网络安全建设提供了参考框架。 <div>
arXiv:2409.11409v1 Announce Type: new 
Abstract: The rapid evolution of the Internet, particularly the emergence of Web3, has transformed the ways people interact and share data. Web3, although still not well defined, is thought to be a return to the decentralization of corporations' power over user data. Despite the obsolescence of the idea of building systems to detect and prevent cyber intrusions, this is still a topic of interest. This paper proposes a novel conceptual approach for implementing decentralized collaborative intrusion detection networks (CIDN) through a proof-of-concept. The study employs an analytical and comparative methodology, examining the synergy between cutting-edge Web3 technologies and information security. The proposed model incorporates blockchain concepts, cyber non-fungible token (cyberNFT) rewards, machine learning algorithms, and publish/subscribe architectures. Finally, the paper discusses the strengths and limitations of the proposed system, offering insights into the potential of decentralized cybersecurity models.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multilevel Verification on a Single Digital Decentralized Distributed (DDD) Ledger</title>
<link>https://arxiv.org/abs/2409.11410</link>
<guid>https://arxiv.org/abs/2409.11410</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式数字（DDD）账本、区块链、多级验证、系统层次结构、系统故障概率

总结:

本文提出了一种利用具有多层次验证的去中心化分布式数字（DDD）账本（如区块链）的新方法。在传统的DDD账本中，仅提供单一级别的验证，这在需要在各个层级进行验证的系统中并不适用。引入层次结构意味着在同一层级内可以有多个验证，甚至多于一个级别的验证，从而引发不同层次间交互带来的新挑战，例如当前层级验证上一级层的工作。

文章旨在解决这些复杂性，为系统状态的追踪提供一种路线图，并计算系统的故障概率。通过多层次验证体系，能够更有效地处理存在自然层次结构的系统，确保数据的完整性和一致性。同时，这种方法还考虑了不同层次间的依赖关系和验证过程，以增强系统的整体稳定性和可靠性。

通过引入多层次验证机制，文章提供了一个全面的框架，不仅解决了传统DDD账本在处理层次化系统时的局限性，还为预测和管理系统故障提供了新的可能性。这一创新方法有望在需要高度可靠和透明数据记录的领域中得到广泛应用。 <div>
arXiv:2409.11410v1 Announce Type: new 
Abstract: This paper presents an approach to using decentralized distributed digital (DDD) ledgers like blockchain with multi-level verification. In regular DDD ledgers like Blockchain, only a single level of verification is available, which makes it not useful for those systems where there is a hierarchy and verification is required on each level. In systems where hierarchy emerges naturally, the inclusion of hierarchy in the solution for the problem of the system enables us to come up with a better solution. Introduction to hierarchy means there could be several verification within a level in the hierarchy and more than one level of verification, which implies other challenges induced by an interaction between the various levels of hierarchies that also need to be addressed, like verification of the work of the previous level of hierarchy by given level in the hierarchy. The paper will address all these issues, and provide a road map to trace the state of the system at any given time and probability of failure of the system.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advances in APPFL: A Comprehensive and Extensible Federated Learning Framework</title>
<link>https://arxiv.org/abs/2409.11585</link>
<guid>https://arxiv.org/abs/2409.11585</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、异构性、安全性、可扩展性、开源

总结:本文主要介绍了联邦学习（FL）作为分布式机器学习的一种范式，其在保护数据隐私的同时实现合作模型训练的潜力。特别是在医疗和电网等敏感领域，由于大多数数据为私有、机密且分布广泛，FL成为了一种有前景的方法来有效利用这些数据。然而，异构性和安全性是联邦学习面临的关键挑战，许多现有的联邦学习框架要么未能充分解决这些问题，要么缺乏灵活性以引入新的解决方案。为此，作者提出了一种名为APPFL的可扩展框架和基准测试套件，旨在全面解决异构性和安全问题，并提供用户友好的界面以集成新算法或适应新应用。

APPFL通过大量实验评估了联邦学习的各个方面，包括通信效率、隐私保护、计算性能和资源使用情况。此外，通过垂直、层级和去中心化联邦学习的案例研究，展示了APPFL的可扩展性。该框架已开源发布在GitHub上，为研究人员和开发者提供了宝贵的资源。 <div>
arXiv:2409.11585v1 Announce Type: new 
Abstract: Federated learning (FL) is a distributed machine learning paradigm enabling collaborative model training while preserving data privacy. In today's landscape, where most data is proprietary, confidential, and distributed, FL has become a promising approach to leverage such data effectively, particularly in sensitive domains such as medicine and the electric grid. Heterogeneity and security are the key challenges in FL, however; most existing FL frameworks either fail to address these challenges adequately or lack the flexibility to incorporate new solutions. To this end, we present the recent advances in developing APPFL, an extensible framework and benchmarking suite for federated learning, which offers comprehensive solutions for heterogeneity and security concerns, as well as user-friendly interfaces for integrating new algorithms or adapting to new applications. We demonstrate the capabilities of APPFL through extensive experiments evaluating various aspects of FL, including communication efficiency, privacy preservation, computational performance, and resource utilization. We further highlight the extensibility of APPFL through case studies in vertical, hierarchical, and decentralized FL. APPFL is open-sourced at https://github.com/APPFL/APPFL.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CountChain: A Decentralized Oracle Network for Counting Systems</title>
<link>https://arxiv.org/abs/2409.11592</link>
<guid>https://arxiv.org/abs/2409.11592</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、在线广告、精准计数系统、去中心化、Nash均衡

总结:
本文提出了CountChain，一种针对计数系统的去中心化预言机网络，旨在解决区块链在行业应用中与链下数据连接受限的问题。CountChain通过让所有节点接收数据并允许任意节点发起提议请求，实现了数据的广泛收集。每个提议包含足够的信息以判断事件的发生。随后，随机选择的节点参与游戏，通过提供证据和赌注来验证提议的真实性。只有经过验证为真的提议才会增加智能合约中的计数器。这种机制改变了传统的模式，即智能合约主动调用预言机获取数据，而是由预言机在数据可用时主动调用智能合约。

为了优化系统性能，作者进行了详细参数分析和大规模数据点实验，以确定最佳配置。基于博弈论的分析表明，在合理的参与者行为下，存在纳什均衡状态，确保了所有理性参与者都能以诚实的方式参与其中。此研究为区块链技术在在线广告等依赖精确计数系统的行业中的应用提供了新的思路和解决方案。 <div>
arXiv:2409.11592v1 Announce Type: new 
Abstract: Blockchain integration in industries like online advertising is hindered by its connectivity limitations to off-chain data. These industries heavily rely on precise counting systems for collecting and analyzing off-chain data. This requires mechanisms, often called oracles, to feed off-chain data into smart contracts. However, current oracle solutions are ill-suited for counting systems since the oracles do not know when to expect the data, posing a significant challenge.
  To address this, we present CountChain, a decentralized oracle network for counting systems. In CountChain, data is received by all oracle nodes, and any node can submit a proposition request. Each proposition contains enough data to evaluate the occurrence of an event. Only randomly selected nodes participate in a game to evaluate the truthfulness of each proposition by providing proof and some stake. Finally, the propositions with the outcome of True increment the counter in a smart contract. Thus, instead of a contract calling oracles for data, in CountChain, the oracles call a smart contract when the data is available. Furthermore, we present a formal analysis and experimental evaluation of the system's parameters on over half a million data points to obtain optimal system parameters. In such conditions, our game-theoretical analysis demonstrates that a Nash equilibrium exists wherein all rational parties participate with honesty.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Blockchain-Enabled IoV: Secure Communication and Trustworthy Decision-Making</title>
<link>https://arxiv.org/abs/2409.11621</link>
<guid>https://arxiv.org/abs/2409.11621</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Vehicles（IoV）、区块链、安全认证、数据交换、自动驾驶

总结:
本文提出了一种用于解决车辆间通信安全和可靠自动化决策问题的去中心化框架。该框架包括主层管理车际通信和次层保障车内交互的安全性。通过采用区块链集成安全认证(BiSA)和分布式区块链名称解析(DBNR)等协议，框架确保了分散的身份管理和可靠的数据交换，为安全高效的自动驾驶车辆运营提供了支持。BiSA协议负责提供安全、分散的身份管理机制，而DBNR则确保了分散的名称解析服务，使得车辆间的通信更加安全和高效。整个框架旨在提升IoV环境下的通信安全性与可靠性，从而促进自动驾驶技术的广泛应用。 <div>
arXiv:2409.11621v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV), which enables interactions between vehicles, infrastructure, and the environment, faces challenges in maintaining communication security and reliable automated decisions. This paper introduces a decentralized framework comprising a primary layer for managing inter-vehicle communication and a sub-layer for securing intra-vehicle interactions. By implementing blockchain-based protocols like Blockchain-integrated Secure Authentication (BiSA) and Decentralized Blockchain Name Resolution (DBNR), the framework ensures secure, decentralized identity management and reliable data exchanges, thereby supporting safe and efficient autonomous vehicle operations.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Few-Shot Class-Incremental Learning with Non-IID Decentralized Data</title>
<link>https://arxiv.org/abs/2409.11657</link>
<guid>https://arxiv.org/abs/2409.11657</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、小样本学习、增量学习、知识遗忘、数据异构性

总结:

本文提出了一种针对小样本增量学习的联邦学习框架，旨在解决在保护数据隐私和安全的前提下，开发可扩展且适应性强的智能系统的问题。该框架允许客户端在本地更新模型以学习新类别的同时，保持数据的隐私性，并将模型更新发送到中央服务器进行全局聚合。

为应对小样本学习的挑战，如灾难性遗忘和数据异构性，作者引入了合成数据驱动的方法，通过回放缓冲区数据来维护已有知识并促进新知识的学习。具体地，他们设计了一个噪声感知生成回放模块，以平衡新数据和回放数据，对本地模型进行微调，同时生成新类别数据以进一步扩充回放缓冲区。此外，还提出了基于局部模型在合成数据上性能的分类特定加权聚合策略，以适应数据异构性问题，从而实现有效的全局模型优化，而无需直接访问客户端数据。

通过在三个常用数据集上的全面实验，证实了所提出的框架的有效性和优越性，证明了其在联邦环境下的小样本增量学习能力。 <div>
arXiv:2409.11657v1 Announce Type: new 
Abstract: Few-shot class-incremental learning is crucial for developing scalable and adaptive intelligent systems, as it enables models to acquire new classes with minimal annotated data while safeguarding the previously accumulated knowledge. Nonetheless, existing methods deal with continuous data streams in a centralized manner, limiting their applicability in scenarios that prioritize data privacy and security. To this end, this paper introduces federated few-shot class-incremental learning, a decentralized machine learning paradigm tailored to progressively learn new classes from scarce data distributed across multiple clients. In this learning paradigm, clients locally update their models with new classes while preserving data privacy, and then transmit the model updates to a central server where they are aggregated globally. However, this paradigm faces several issues, such as difficulties in few-shot learning, catastrophic forgetting, and data heterogeneity. To address these challenges, we present a synthetic data-driven framework that leverages replay buffer data to maintain existing knowledge and facilitate the acquisition of new knowledge. Within this framework, a noise-aware generative replay module is developed to fine-tune local models with a balance of new and replay data, while generating synthetic data of new classes to further expand the replay buffer for future tasks. Furthermore, a class-specific weighted aggregation strategy is designed to tackle data heterogeneity by adaptively aggregating class-specific parameters based on local models performance on synthetic data. This enables effective global model optimization without direct access to client data. Comprehensive experiments across three widely-used datasets underscore the effectiveness and preeminence of the introduced framework.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revolutionizing Pharmaceutical Manufacturing: Advances and Challenges of 3D Printing System and Control</title>
<link>https://arxiv.org/abs/2409.11712</link>
<guid>https://arxiv.org/abs/2409.11712</guid>
<content:encoded><![CDATA[
<div> 关键词：3D打印、制药行业、个性化医疗、材料科学、法规框架

<br />
<br />总结:

本文深入探讨了3D打印技术在制药行业的应用及其对传统制药方法的革新。通过3D打印，制药企业能够实现药物的精准制造，包括控制释放模式、剂量和结构复杂性，从而满足日益增长的个性化医疗需求。滴喷打印、紫外固化墨水、材料科学的进步以及相关的法规框架，为这一领域的技术发展提供了重要支持。

然而，尽管3D打印技术在降低成本、提高灵活性和促进分散化生产方面展现出巨大潜力，但在规模化生产、重现性和适应监管方面仍面临挑战。本文对此进行了详尽分析，旨在为该技术在制药制造领域的主流整合提供全面的视角和指导。未来的研究和发展方向将聚焦于解决这些挑战，以实现3D打印技术在制药行业的更广泛和深入应用。 <div>
arXiv:2409.11712v1 Announce Type: new 
Abstract: The advent of 3D printing has transformed the pharmaceutical industry, enabling precision drug manufacturing with controlled release profiles, dosing, and structural complexity. Additive manufacturing (AM) addresses the growing demand for personalized medicine, overcoming limitations of traditional methods. This technology facilitates tailored dosage forms, complex geometries, and real-time quality control. Recent advancements in drop-on-demand printing, UV curable inks, material science, and regulatory frameworks are discussed. Despite opportunities for cost reduction, flexibility, and decentralized manufacturing, challenges persist in scalability, reproducibility, and regulatory adaptation. This review provides an in-depth analysis of the current state of AM in pharmaceutical manufacturing, exploring recent developments, challenges, and future directions for mainstream integration.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering Visual Artists with Tokenized Digital Assets with NFTs</title>
<link>https://arxiv.org/abs/2409.11790</link>
<guid>https://arxiv.org/abs/2409.11790</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币（NFT）、艺术行业、区块链技术、创意实践、版权产业

<br />
<br />
总结:
本文深入探讨了非同质化代币（NFT）对视觉艺术行业的颠覆性影响。首先，文章介绍了区块链领域的关键技术特征和优势，为后续分析奠定了基础。随后，文章回顾了传统艺术创作过程，包括不同类型的创作、生产流程、交易方式以及盈利模式。紧接着，文章详细阐述了区块链生态系统的核心要素，如结构、共识算法、智能合约和数字钱包，进一步明确了NFT的概念。

接下来，文章聚焦于NFT，概述了其历史、运作机制、生命周期以及在艺术领域中的应用，特别是NFT的铸造与交易过程，以及市场动态与定价策略。同时，文章还关注了NFT领域的主要安全问题，如洗盘交易，强调了这一领域中关键的网络安全挑战。

最后，文章展望了未来的研究方向，强调了提升用户体验、增强安全性及保护隐私的重要性。通过综合创意产业界与网络安全专家的意见，本文提供了关于NFT如何赋能视觉艺术家并重塑整个版权产业的新见解。 <div>
arXiv:2409.11790v1 Announce Type: new 
Abstract: The Non-Fungible Tokens (NFTs) has the transformative impact on the visual arts industry by examining the nexus between empowering art practices and leveraging blockchain technology. First, we establish the context for this study by introducing some basic but critical technological aspects and affordances of the blockchain domain. Second, we revisit the creative practices involved in producing traditional artwork, covering various types, production processes, trading, and monetization methods. Third, we introduce and define the key fundamentals of the blockchain ecosystem, including its structure, consensus algorithms, smart contracts, and digital wallets. Fourth, we narrow the focus to NFTs, detailing their history, mechanics, lifecycle, and standards, as well as their application in the art world. In particular, we outline the key processes for minting and trading NFTs in various marketplaces and discuss the relevant market dynamics and pricing. We also consider major security concerns, such as wash trading, to underscore some of the central cybersecurity issues facing this domain. Finally, we conclude by considering future research directions, emphasizing improvements in user experience, security, and privacy. Through this innovative research overview, which includes input from creative industry and cybersecurity sdomain expertise, we offer some new insights into how NFTs can empower visual artists and reshape the wider copyright industries.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>LMMCoDrive: Cooperative Driving with Large Multimodal Model</title>
<link>https://arxiv.org/abs/2409.11981</link>
<guid>https://arxiv.org/abs/2409.11981</guid>
<content:encoded><![CDATA[
<div> 关键词：LMMCoDrive、Large Multimodal Model（LMM）、Decentralized Optimization、Cooperative Autonomous Vehicles（CAVs）、Autonomous Mobility-on-Demand（AMoD）

<br />
<br />总结:
文章介绍了LMMCoDrive，一种利用大型多模态模型（LMM）来提升动态城市环境中交通效率的新型协同驾驶框架。LMMCoDrive将车辆与乘客请求的空间关系抽象为鸟瞰视图（BEV），充分利用了LMM的潜力，并通过安全约束谨慎地细化每个车辆的轨迹以避免碰撞。提出了一种基于交替方向乘子法（ADMM）的分散优化策略，用于驱动车辆图的演化。通过模拟结果，文章展示了LMM在优化车辆调度和增强分散协同优化过程中的关键作用，这标志着向实现高效、安全且实用的AMoD系统迈进的重要一步，旨在彻底改变城市交通格局。代码已开源在https://github.com/henryhcliu/LMMCoDrive。 <div>
arXiv:2409.11981v1 Announce Type: new 
Abstract: To address the intricate challenges of decentralized cooperative scheduling and motion planning in Autonomous Mobility-on-Demand (AMoD) systems, this paper introduces LMMCoDrive, a novel cooperative driving framework that leverages a Large Multimodal Model (LMM) to enhance traffic efficiency in dynamic urban environments. This framework seamlessly integrates scheduling and motion planning processes to ensure the effective operation of Cooperative Autonomous Vehicles (CAVs). The spatial relationship between CAVs and passenger requests is abstracted into a Bird's-Eye View (BEV) to fully exploit the potential of the LMM. Besides, trajectories are cautiously refined for each CAV while ensuring collision avoidance through safety constraints. A decentralized optimization strategy, facilitated by the Alternating Direction Method of Multipliers (ADMM) within the LMM framework, is proposed to drive the graph evolution of CAVs. Simulation results demonstrate the pivotal role and significant impact of LMM in optimizing CAV scheduling and enhancing decentralized cooperative optimization process for each vehicle. This marks a substantial stride towards achieving practical, efficient, and safe AMoD systems that are poised to revolutionize urban transportation. The code is available at https://github.com/henryhcliu/LMMCoDrive.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs</title>
<link>https://arxiv.org/abs/2409.12171</link>
<guid>https://arxiv.org/abs/2409.12171</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、健康3.0、标准接口、知识图谱

<br /><br />
总结:

本文主要探讨了如何利用区块链技术中的智能合约来实现健康3.0背景下的分布式决策。健康3.0允许基于多个机构的长期数据进行决策，这需要一种中立的中介来实施可信赖的决策过程。为了解决这一需求，文章提出了使用符合行业标准（如HL7 FHIR）的结构化数据和智能合约之间的互操作性。通过将智能合约逻辑编码到高阶语义知识图谱中，并在区块链上部署此知识图谱，可以实现数据在不同机构之间的无缝传输与处理。

文章介绍了生成智能合约的离链代码流程，该流程首先将知识图谱编译成具体的智能合约代码，然后在区块链上部署。这种方法避免了在区块链上使用可能成本更高且不可预测的规则引擎，从而遵循了区块链的经济规则。

文章以三个医疗保险案例为例，展示了生成的智能合约在正确性和执行成本（"gas"）方面的良好性能。此外，还讨论了这种基于知识图谱的智能合约生成方法在医疗保健领域的适用性以及未来研究方向，包括探索大型语言模型（LLM）在这一过程中的应用。

通过这种方式，文章证明了在尊重区块链经济规则的前提下，自动根据语义知识图谱生成智能合约是可行的，为医疗保健领域提供了新的技术支持。 <div>
arXiv:2409.12171v1 Announce Type: new 
Abstract: Background: Health 3.0 allows decision making to be based on longitudinal data from multiple institutions, from across the patient's healthcare journey. In such a distributed setting, blockchain smart contracts can act as neutral intermediaries to implement trustworthy decision making.
  Objective: In a distributed setting, transmitted data will be structured using standards (such as HL7 FHIR) for semantic interoperability. In turn, the smart contract will require interoperability with this standard, implement a complex communication setup (e.g., using oracles), and be developed using blockchain languages (e.g., Solidity). We propose the encoding of smart contract logic using a high-level semantic Knowledge Graph, using concepts from the domain standard. We then deploy this semantic KG on blockchain.
  Methods: Off-chain, a code generation pipeline compiles the KG into a concrete smart contract, which is then deployed on-chain. Our pipeline targets an intermediary bridge representation, which can be transpiled into a specific blockchain language. Our choice avoids on-chain rule engines, with unpredictable and likely higher computational cost; it is thus in line with the economic rules of blockchain.
  Results: We applied our code generation approach to generate smart contracts for 3 health insurance cases from Medicare. We discuss the suitability of our approach - the need for a neutral intermediary - for a number of healthcare use cases. Our evaluation finds that the generated contracts perform well in terms of correctness and execution cost ("gas") on blockchain.
  Conclusions: We showed that it is feasible to automatically generate smart contract code based on a semantic KG, in a way that respects the economic rules of blockchain. Future work includes studying the use of Large Language Models (LLM) in our approach, and evaluations on other blockchains.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedVeca: Federated Vectorized Averaging on Non-IID Data with Adaptive Bi-directional Global Objective</title>
<link>https://arxiv.org/abs/2209.13803</link>
<guid>https://arxiv.org/abs/2209.13803</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedVeca方法、非独立同分布数据、本地更新次数、全局模型优化

<br />
总结:
文章提出了一种名为FedVeca的新方法，旨在解决在非独立同分布数据(FedVeca)下的联邦学习问题。该方法通过定义局部梯度为具有步长和方向的双向向量来改进联邦学习过程。步长表示本地更新次数，而方向则根据特定定义分为正负两部分。FedVeca通过平均这些双向向量，以减少不同步长对全局模型优化的影响。作者进一步分析了步长与全局目标之间的关系，并根据此关系设计了一个算法，使服务器和客户端能够适应性地调整步长，使其接近最优值。实验结果表明，FedVeca方法在不同数据集、模型和场景中都能有效提高联邦学习的效果和效率。 <div>
arXiv:2209.13803v3 Announce Type: replace 
Abstract: Federated Learning (FL) is a distributed machine learning framework to alleviate the data silos, where decentralized clients collaboratively learn a global model without sharing their private data. However, the clients' Non-Independent and Identically Distributed (Non-IID) data negatively affect the trained model, and clients with different numbers of local updates may cause significant gaps to the local gradients in each communication round. In this paper, we propose a Federated Vectorized Averaging (FedVeca) method to address the above problem on Non-IID data. Specifically, we set a novel objective for the global model which is related to the local gradients. The local gradient is defined as a bi-directional vector with step size and direction, where the step size is the number of local updates and the direction is divided into positive and negative according to our definition. In FedVeca, the direction is influenced by the step size, thus we average the bi-directional vectors to reduce the effect of different step sizes. Then, we theoretically analyze the relationship between the step sizes and the global objective, and obtain upper bounds on the step sizes per communication round. Based on the upper bounds, we design an algorithm for the server and the client to adaptively adjusts the step sizes that make the objective close to the optimum. Finally, we conduct experiments on different datasets, models and scenarios by building a prototype system, and the experimental results demonstrate the effectiveness and efficiency of the FedVeca method.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Multi-Cell Spectrum and Power Allocation</title>
<link>https://arxiv.org/abs/2312.05746</link>
<guid>https://arxiv.org/abs/2312.05746</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式方法、多代理强化学习（MARL）、交通驱动、可扩展性、QoS性能

<br /><br />
总结:本文提出了一种基于分布式多代理强化学习(MARL)框架的新型多小区无线网络射频资源分配策略。通过让每个代理控制单个小区并根据局部信息进行频谱和功率分配，该方法实现了与使用全局信息的集中式方法相媲美的服务质量(QoS)表现，同时显著降低了执行时间。此研究将问题转化为分布式学习问题，利用多代理近端策略优化(MAPPO)算法结合循环神经网络和队列动力学来解决。这种交通驱动的MARL解决方案支持去中心化的训练与执行，确保了大型网络的可扩展性。通过广泛模拟验证，该方法不仅达到了与具备完美信息集中式算法相似的QoS性能，还展示了在不同网络规模和流量条件下的可扩展性和鲁棒性。 <div>
arXiv:2312.05746v2 Announce Type: replace 
Abstract: This paper introduces a novel approach to radio resource allocation in multi-cell wireless networks using a fully scalable multi-agent reinforcement learning (MARL) framework. A distributed method is developed where agents control individual cells and determine spectrum and power allocation based on limited local information, yet achieve quality of service (QoS) performance comparable to centralized methods using global information. The objective is to minimize packet delays across devices under stochastic arrivals and applies to both conflict graph abstractions and cellular network configurations. This is formulated as a distributed learning problem, implementing a multi-agent proximal policy optimization (MAPPO) algorithm with recurrent neural networks and queueing dynamics. This traffic-driven MARL-based solution enables decentralized training and execution, ensuring scalability to large networks. Extensive simulations demonstrate that the proposed methods achieve comparable QoS performance to genie-aided centralized algorithms with significantly less execution time. The trained policies also exhibit scalability and robustness across various network sizes and traffic conditions.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detection Made Easy: Potentials of Large Language Models for Solidity Vulnerabilities</title>
<link>https://arxiv.org/abs/2409.10574</link>
<guid>https://arxiv.org/abs/2409.10574</guid>
<content:encoded><![CDATA[
<div> 关键词：Solidity智能合约、大型语言模型（LLMs）、OWASP Top Ten漏洞、VulSmart数据集、SmartVD框架

<br /><br />
总结:
本文研究了大型语言模型（LLMs）在检测以太坊主网上使用Solidity编写的智能合约中的OWASP Top Ten漏洞的能力。研究团队创建了一个名为VulSmart的新型、平衡分类、结构化和标注的数据集，用于评估开源LLMs如CodeLlama、Llama2、CodeT5和Falcon，以及闭源模型GPT-3.5 Turbo和GPT-4o Mini的表现。他们提出了一个名为SmartVD的框架，通过广泛的自动化和人工评估来测试这些模型，利用BLEU和ROUGE指标来评估漏洞检测的有效性。研究还探索了零样本、少量样本和链式思维三种不同的提示策略，以评估SmartVD框架的多类分类和生成能力。研究发现，SmartVD在检测漏洞方面优于其开源同辈，甚至超越了闭源基础模型GPT-3.5和GPT-4 Mini的性能。在微调后，闭源模型GPT-3.5 Turbo和GPT-4o Mini在检测漏洞方面达到了99%的准确率，在识别漏洞类型和确定严重程度方面的表现分别为94%和98%。特别地，SmartVD在“链式思维”提示技术上表现最佳，而微调后的闭源模型则在“零样本”提示方法上表现出色。 <div>
arXiv:2409.10574v1 Announce Type: new 
Abstract: The large-scale deployment of Solidity smart contracts on the Ethereum mainnet has increasingly attracted financially-motivated attackers in recent years. A few now-infamous attacks in Ethereum's history includes DAO attack in 2016 (50 million dollars lost), Parity Wallet hack in 2017 (146 million dollars locked), Beautychain's token BEC in 2018 (900 million dollars market value fell to 0), and NFT gaming blockchain breach in 2022 ($600 million in Ether stolen). This paper presents a comprehensive investigation of the use of large language models (LLMs) and their capabilities in detecting OWASP Top Ten vulnerabilities in Solidity. We introduce a novel, class-balanced, structured, and labeled dataset named VulSmart, which we use to benchmark and compare the performance of open-source LLMs such as CodeLlama, Llama2, CodeT5 and Falcon, alongside closed-source models like GPT-3.5 Turbo and GPT-4o Mini. Our proposed SmartVD framework is rigorously tested against these models through extensive automated and manual evaluations, utilizing BLEU and ROUGE metrics to assess the effectiveness of vulnerability detection in smart contracts. We also explore three distinct prompting strategies-zero-shot, few-shot, and chain-of-thought-to evaluate the multi-class classification and generative capabilities of the SmartVD framework. Our findings reveal that SmartVD outperforms its open-source counterparts and even exceeds the performance of closed-source base models like GPT-3.5 and GPT-4 Mini. After fine-tuning, the closed-source models, GPT-3.5 Turbo and GPT-4o Mini, achieved remarkable performance with 99% accuracy in detecting vulnerabilities, 94% in identifying their types, and 98% in determining severity. Notably, SmartVD performs best with the `chain-of-thought' prompting technique, whereas the fine-tuned closed-source models excel with the `zero-shot' prompting approach.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deterministic Bounds in Committee Selection: Enhancing Decentralization and Scalability in Distributed Ledgers</title>
<link>https://arxiv.org/abs/2409.10727</link>
<guid>https://arxiv.org/abs/2409.10727</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式共识、随机委员会选择、公平性、确定性边界、敌对影响

总结:
本文聚焦于分布式共识系统中的公平随机委员会选举过程，特别是采用加密抽签方法确保委员会大小恒定的方案。与现有协议提供的概率性保证不同，本文提出的新方法旨在提供确定性的边界，以限制委员会中敌对方的影响。通过引入创新方法和进行数值实验，文章证明了这种方法能够有效增强系统的去中心化特性。

具体而言，文章首先概述了区块链系统中基于稀缺资源（如股权、存储、内存或计算能力）的加权彩票机制在选择负责共识过程及添加新信息至区块链的委员会成员中的重要性。接着，作者对比了两种主要的随机委员会选择方法：一种是每个验证候选者在共识阶段本地检查是否当选并展示证明；另一种是使用排序算法决定固定大小的全球验证委员会。

文章的重点在于后者，特别是加密抽签方法，该方法确保委员会大小恒定，同时提供确定性边界来限制委员会中敌对方的影响力。这种策略克服了现有协议仅提供概率性保证的局限性，通常导致委员会规模过大，不适合许多基于多数原则的应用场景，如原子广播和随机信标协议。通过引入新的方法和分析，文章为实现更强大、更公平的去中心化系统提供了理论基础和实践指导。 <div>
arXiv:2409.10727v1 Announce Type: new 
Abstract: Consensus plays a crucial role in distributed ledger systems, impacting both scalability and decentralization. Many blockchain systems use a weighted lottery based on a scarce resource such as a stake, storage, memory, or computing power to select a committee whose members drive the consensus and are responsible for adding new information to the ledger. Therefore, ensuring a robust and fair committee selection process is essential for maintaining security, efficiency, and decentralization.
  There are two main approaches to randomized committee selection. In one approach, each validator candidate locally checks whether they are elected to the committee and reveals their proof during the consensus phase. In contrast, in the second approach, a sortition algorithm decides a fixed-sized committee that is globally verified. This paper focuses on the latter approach, with cryptographic sortition as a method for fair committee selection that guarantees a constant committee size. Our goal is to develop deterministic guarantees that strengthen decentralization. We introduce novel methods that provide deterministic bounds on the influence of adversaries within the committee, as evidenced by numerical experiments. This approach overcomes the limitations of existing protocols that only offer probabilistic guarantees, often providing large committees that are impractical for many quorum-based applications like atomic broadcast and randomness beacon protocols.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Anti-disguise Authentication System Using the First Impression of Avatar in Metaverse</title>
<link>https://arxiv.org/abs/2409.10850</link>
<guid>https://arxiv.org/abs/2409.10850</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、身份认证、反伪装、签加密、区块链存储

<br /><br />
总结:
本文提出了一个基于元宇宙环境的反伪装身份认证方法，旨在解决虚拟世界中用户通过创建个性化数字形象（即头像）进行交互时可能出现的身份欺骗问题。该方法借鉴了现实世界中初次印象的作用，利用首次会面的场景信息来辅助用户间的身份验证过程。为防止对手替换和伪造初次印象，文中构建了一种基于变色龙的签加密机制，并设计了一个密文认证协议以确保加密身份的公开可验证性。安全分析显示，该签加密机制不仅满足了安全性需求，还实现了公开可验证性。此外，密文认证协议具备防御对手对初次印象进行替换和伪造的能力。实验结果显示，所提出的头像认证系统能够在区块链上以较低的存储消耗实现有效的反伪装身份认证。 <div>
arXiv:2409.10850v1 Announce Type: new 
Abstract: Metaverse is a vast virtual world parallel to the physical world, where the user acts as an avatar to enjoy various services that break through the temporal and spatial limitations of the physical world. Metaverse allows users to create arbitrary digital appearances as their own avatars by which an adversary may disguise his/her avatar to fraud others. In this paper, we propose an anti-disguise authentication method that draws on the idea of the first impression from the physical world to recognize an old friend. Specifically, the first meeting scenario in the metaverse is stored and recalled to help the authentication between avatars. To prevent the adversary from replacing and forging the first impression, we construct a chameleon-based signcryption mechanism and design a ciphertext authentication protocol to ensure the public verifiability of encrypted identities. The security analysis shows that the proposed signcryption mechanism meets not only the security requirement but also the public verifiability. Besides, the ciphertext authentication protocol has the capability of defending against the replacing and forging attacks on the first impression. Extensive experiments show that the proposed avatar authentication system is able to achieve anti-disguise authentication at a low storage consumption on the blockchain.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Inside Alameda Research: A Multi-Token Network Analysis</title>
<link>https://arxiv.org/abs/2409.10949</link>
<guid>https://arxiv.org/abs/2409.10949</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、Alameda Research、DeFi生态系统、网络分析、时间演变

<br /><br />
总结:

本文聚焦于对以太坊上与Alameda Research相关的代币转移网络进行的深入分析。Alameda Research是一家涉及FTX客户资金不当使用的加密货币交易公司。研究通过多代币网络表示法，分析节点中心性和网络骨架，以识别关键账户、代币和活动群体。对Alameda账户随时间的变化进行的研究揭示了其在破产前（2022年11月）的代币积累和分配模式的转变。通过网络分析，本文提供了关于塑造去中心化金融(DeFi)生态系统的活动和动态的见解。这一研究不仅有助于理解特定实体在加密市场中的行为，也为更广泛地理解DeFi生态系统中的资金流动和风险提供了洞见。 <div>
arXiv:2409.10949v1 Announce Type: new 
Abstract: We analyze the token transfer network on Ethereum, focusing on accounts associated with Alameda Research, a cryptocurrency trading firm implicated in the misuse of FTX customer funds. Using a multi-token network representation, we examine node centralities and the network backbone to identify critical accounts, tokens, and activity groups. The temporal evolution of Alameda accounts reveals shifts in token accumulation and distribution patterns leading up to its bankruptcy in November 2022. Through network analysis, our work offers insights into the activities and dynamics that shape the DeFi ecosystem.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Delay Analysis of EIP-4844</title>
<link>https://arxiv.org/abs/2409.11043</link>
<guid>https://arxiv.org/abs/2409.11043</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum改进提案、Proto-Danksharding、数据分片、数据可用性、延迟模型

总结:
文章主要讨论了Ethereum改进提案EIP-4844中提出的Proto-Danksharding技术，该技术旨在通过引入名为blob-carrying交易的新类型来逐步提高以太坊区块链的可扩展性。这些交易将大型二进制对象（blob）存储于链下，但通过在链上引用和验证来确保数据可用性。通过将数据可用性与交易执行分离，Proto-Danksharding缓解了网络拥堵并降低了气体费用，为更高级的数据分片解决方案打下了基础。

文章提供了一个分析模型，用于推导这些新交易的延迟。通过将系统建模为$\mathrm{M/D}^B/1$队列，并通过嵌入马尔可夫链和辅助变量方法找到其稳态分布，作者证明了与较低blob数量但更高频率的交易相比，具有更多blob但更少频率的交易对系统的延迟影响更大。这一发现对于优化交易处理和提高整体网络效率至关重要。 <div>
arXiv:2409.11043v1 Announce Type: new 
Abstract: Proto-Danksharding, proposed in Ethereum Improvement Proposal 4844 (EIP-4844), aims to incrementally improve the scalability of the Ethereum blockchain by introducing a new type of transaction known as blob-carrying transactions. These transactions incorporate binary large objects (blobs) of data that are stored off-chain but referenced and verified on-chain to ensure data availability. By decoupling data availability from transaction execution, Proto-Danksharding alleviates network congestion and reduces gas fees, laying the groundwork for future, more advanced sharding solutions. This letter provides an analytical model to derive the delay for these new transactions. We model the system as an $\mathrm{M/D}^B/1$ queue which we then find its steady state distribution through embedding a Markov chain and use of supplementary variable method. We show that transactions with more blobs but less frequent impose higher delays on the system compared to lower blobs but more frequent.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-UAV Uniform Sweep Coverage in Unknown Environments: A Mergeable Nervous System (MNS)-Based Random Exploration</title>
<link>https://arxiv.org/abs/2409.11116</link>
<guid>https://arxiv.org/abs/2409.11116</guid>
<content:encoded><![CDATA[
<div> 关键词：多无人机、均匀覆盖、随机漫步、自组织网络、未知环境

<br /><br />
总结:本文研究了多无人飞行器（UAV）在未知环境下进行均匀覆盖的问题。研究发现，基于随机游走的探索策略适用于此类覆盖场景，因为它们不需要定位信息，易于在机器人集群中实现。文中提出了一种基于自组织神经系统（MNS）框架的随机游走方法，该方法允许无人机群自我组织成一种基于局部通信的层次化自适应通信网络，并以线性队形的形式进行移动。通过模拟比较，该方法在达到全面覆盖所需的总时间以及覆盖均匀性方面，均优于几种分散的随机游走基准策略。实验结果表明，MNS基于的随机游走策略在环境覆盖效率和覆盖一致性上表现出色。 <div>
arXiv:2409.11116v1 Announce Type: new 
Abstract: This paper investigates the problem of multi-UAV uniform sweep coverage, where a homogeneous swarm of UAVs must collectively and evenly visit every portion of an unknown environment for a sampling task without having access to their own location and orientation. Random walk-based exploration strategies are practical for such a coverage scenario as they do not rely on localization and are easily implementable in robot swarms. We demonstrate that the Mergeable Nervous System (MNS) framework, which enables a robot swarm to self-organize into a hierarchical ad-hoc communication network using local communication, is a promising control approach for random exploration in unknown environments by UAV swarms. To this end, we propose an MNS-based random walk approach where UAVs self-organize into a line formation using the MNS framework and then follow a random walk strategy to cover the environment while maintaining the formation. Through simulations, we test the efficiency of our approach against several decentralized random walk-based strategies as benchmarks. Our results show that the MNS-based random walk outperforms the benchmarks in terms of the time required to achieve full coverage and the coverage uniformity at that time, assessed across both the entire environment and within local regions.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Incredible Shrinking Context... in a decompiler near you</title>
<link>https://arxiv.org/abs/2409.11157</link>
<guid>https://arxiv.org/abs/2409.11157</guid>
<content:encoded><![CDATA[
<div> 关键词：Shrknr、Elipmoc、静态分析、符号执行、智能合约

总结:

本文介绍了一种名为Shrknr的新一代智能合约二进制代码反编译工具。Shrknr通过引入“缩减上下文敏感性”这一创新技术，相较于现有的反编译工具如Elipmoc，在可扩展性、完整性、精确度等关键维度上实现了显著提升。具体而言，Shrknr能够处理更多的智能合约代码（覆盖更多代码的比例提高了67%，并达到99.5%的合约覆盖率），同时将关键的不精确度指标降低了超过65%。

Shrknr采用了基于静态分析的方法进行反编译，与依赖于符号执行的技术相比，它通过深挖静态分析上下文并积极“遗忘”控制流历史来释放进一步精确推理的空间，从而实现性能的提升。在标准基准测试集中，Shrknr的表现远超其他同类工具，展现了其在智能合约反编译领域的先进性和实用性。 <div>
arXiv:2409.11157v1 Announce Type: new 
Abstract: Decompilation of binary code has arisen as a highly-important application in the space of Ethereum VM (EVM) smart contracts. Major new decompilers appear nearly every year and attain popularity, for a multitude of reverse-engineering or tool-building purposes. Technically, the problem is fundamental: it consists of recovering high-level control flow from a highly-optimized continuation-passing-style (CPS) representation. Architecturally, decompilers can be built using either static analysis or symbolic execution techniques.
  We present Shrknr, a static-analysis-based decompiler succeeding the state-of-the-art Elipmoc decompiler. Shrknr manages to achieve drastic improvements relative to the state of the art, in all significant dimensions: scalability, completeness, precision. Chief among the techniques employed is a new variant of static analysis context: shrinking context sensitivity. Shrinking context sensitivity performs deep cuts in the static analysis context, eagerly "forgetting" control-flow history, in order to leave room for further precise reasoning.
  We compare Shrnkr to state-of-the-art decompilers, both static-analysis- and symbolic-execution-based. In a standard benchmark set, Shrnkr scales to over 99.5% of contracts (compared to ~95%), covers (i.e., reaches and manages to decompile) 67% more code, and reduces key imprecision metrics by over 65%.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Biometric Authentication based on Fuzzy Commitments and Blockchain</title>
<link>https://arxiv.org/abs/2409.11303</link>
<guid>https://arxiv.org/abs/2409.11303</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、生物识别认证、去中心化、隐私保护、模糊承诺方案

<br /><br />
总结:
本文聚焦于利用区块链技术实现生物识别认证的去中心化与隐私保护。传统上，生物识别认证依赖于中心化的系统进行，而区块链作为公开基础设施，其特性与生物识别需求存在矛盾——即需要保护个人生物特征的隐私性。为解决这一冲突，作者提出了一种基于区块链的生物识别认证协议，该协议通过引入模糊承诺方案，确保了在无需泄露生物数据的情况下完成认证过程。此外，文章还对所提出的协议进行了安全分析，考虑到可能的攻击方式，以确保其安全性。这一创新旨在为生物识别领域引入去中心化和增强的隐私保护机制，同时保持系统的可靠性和安全性。 <div>
arXiv:2409.11303v1 Announce Type: new 
Abstract: Blockchain technology, which was introduced for supporting cryptocurrencies, today provides a decentralized infrastructure for general information storage and execution of algorithms, thus enabling the conversion of many applications and services from a centralized and intermediated model to a decentralized and disintermediated one. In this paper we focus on biometric authentication, which is classically performed using centralized systems, and could hence benefit from decentralization. For such a purpose, however, an inherent contradiction between biometric applications and blockchain technology must be overcome, as the former require keeping biometric features private, while blockchain is a public infrastructure. We propose a blockchain-based biometric authentication protocol that enables decentralization and resilience while protecting the privacy, personal data, and, in particular, biometric features of users. The protocol we propose leverages fuzzy commitment schemes to allow biometric authentication to be performed without disclosing biometric data. We also analyze the security of the protocol we propose by considering some relevant attacks.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Constrained Learning for Decentralized Multi-Objective Coverage Control</title>
<link>https://arxiv.org/abs/2409.11311</link>
<guid>https://arxiv.org/abs/2409.11311</guid>
<content:encoded><![CDATA[
<div> 关键词：多目标优化、公平覆盖、约束覆盖、分布式学习、感知-行动-通信网络

<br /><br />
总结:
本文研究了机器人集群在多个异构重要性密度场（IDFs）上同时提供传感器覆盖的多目标覆盖控制问题。提出了公平覆盖和约束覆盖两种不同形式的问题，并探讨了在有限通信和局部感知能力下的分散设置。为了解决这一复杂问题，作者提出了一种新颖的分散式约束学习方法，结合了普鲁-杜尔优化和可学习感知-行动-通信（LPAC）神经网络架构。该方法将对偶问题的拉格朗日乘子重新表述为IDF的线性组合，使LPAC策略能够作为求解器。实验结果表明，该方法在覆盖成本上平均比现有最先进的分散控制器高出30%，并且在更大的环境和更多机器人的情况下表现出良好的转移性和可扩展性，特别是在处理数量更多的领域和集群机器人时。 <div>
arXiv:2409.11311v1 Announce Type: new 
Abstract: The multi-objective coverage control problem requires a robot swarm to collaboratively provide sensor coverage to multiple heterogeneous importance density fields (IDFs) simultaneously. We pose this as an optimization problem with constraints and study two different formulations: (1) Fair coverage, where we minimize the maximum coverage cost for any field, promoting equitable resource distribution among all fields; and (2) Constrained coverage, where each field must be covered below a certain cost threshold, ensuring that critical areas receive adequate coverage according to predefined importance levels. We study the decentralized setting where robots have limited communication and local sensing capabilities, making the system more realistic, scalable, and robust. Given the complexity, we propose a novel decentralized constrained learning approach that combines primal-dual optimization with a Learnable Perception-Action-Communication (LPAC) neural network architecture. We show that the Lagrangian of the dual problem can be reformulated as a linear combination of the IDFs, enabling the LPAC policy to serve as a primal solver. We empirically demonstrate that the proposed method (i) significantly outperforms existing state-of-the-art decentralized controllers by 30% on average in terms of coverage cost, (ii) transfers well to larger environments with more robots and (iii) is scalable in the number of fields and robots in the swarm.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Survey of Threshold Signatures: NIST Standards, Post-Quantum Cryptography, Exotic Techniques, and Real-World Applications</title>
<link>https://arxiv.org/abs/2311.05514</link>
<guid>https://arxiv.org/abs/2311.05514</guid>
<content:encoded><![CDATA[
<div> 关键词：阈值签名、分布式签名、后量子密码学、标准签名、安全多方计算

总结:

本文提供了一篇关于具有高级功能的阈值和分布式签名的全面系统综述。研究涵盖了传统和后量子密码学（PQC）环境下的阈值签名，以及定制设计和标准签名（如常规NIST和NIST-PQC）。文章深入探讨了各种签名家族中的通用（通过安全多方计算实现）和自定义阈值技术，同时考察了奇特签名、实际应用案例及其未来研究方向。该综述旨在为理解新兴去中心化下一代网络系统的安全性提供参考。

本文首先概述了阈值数字签名的概念与重要性，指出它们在确保分布式系统安全方面的关键作用。接着，详细对比分析了传统和后量子密码学环境下不同类型的阈值签名方案，强调了其在不同应用场景下的适用性和优势。文中还特别关注了安全多方计算在构建高效、安全的阈值签名机制中的作用，以及如何利用这一技术优化签名过程，提高系统的整体安全性。

此外，文章深入探讨了标准签名（如NIST和NIST-PQC）在现代网络安全体系中的角色，通过比较分析，揭示了它们在性能、安全性和实用性方面与其他签名方案的区别。同时，对于奇特签名的介绍，不仅展示了签名技术的多样性，也为未来的创新提供了灵感。

最后，文章展望了未来研究的方向，包括如何结合最新技术（如区块链、零知识证明等）进一步提升签名机制的安全性和效率，以及在实际应用中面临的挑战与机遇。通过全面审视阈值和分布式签名的现状与未来，本文旨在为相关领域的研究人员和实践者提供有价值的见解和指导。 <div>
arXiv:2311.05514v2 Announce Type: replace 
Abstract: Threshold digital signatures enable a distributed execution of signature functionalities and will play a crucial role in the security of emerging decentralized next-generation networked systems and applications. In this paper, we provide a comprehensive and systematic survey of threshold and distributed signatures with advanced features. Our survey encompasses threshold signatures in conventional and post-quantum cryptography (PQC) settings and captures custom-design and standard signatures (e.g., conventional NIST and NIST-PQC). We examine both generic (via secure multi-party computation) and custom thresholding techniques for a myriad of signature families while investigating exotic signatures, real-life applications, and potential future research direction.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Preserving Billing for Local Energy Markets</title>
<link>https://arxiv.org/abs/2404.15886</link>
<guid>https://arxiv.org/abs/2404.15886</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、本地能源市场、去中心化、信息论安全、多方计算

<br /><br />
总结:本文提出了一种名为PBP-LEM的隐私保护计费协议，旨在为本地能源市场提供一种方法，以确保市场参与者能够从其投标中偏离的能源量进行联合计算，同时保持私密性并避免内部勾结的风险。该协议基于一个高效且具有信息论安全性的个体计费方案，作为构建基础。通过结合多方计算、内积功能加密和佩尔森承诺等技术，PBP-LEM确保了数据的机密性和准确性。文章还提出了三种不同隐私保护级别和性能的实现方式。经过验证，无论使用哪种最复杂或最简单的方法，该协议都能满足其安全性和隐私要求，并适用于实际部署。例如，对于4000名用户，最复杂的计算方法可在不到五分钟内完成计费计算，而最简单的方法只需0.18秒。 <div>
arXiv:2404.15886v2 Announce Type: replace 
Abstract: We propose a privacy-preserving billing protocol for local energy markets (PBP-LEM) that takes into account market participants' energy volume deviations from their bids. PBP-LEM enables a group of market entities to jointly compute participants' bills in a decentralized and privacy-preserving manner without sacrificing correctness. It also mitigates risks on individuals' privacy arising from any potential internal collusion. We first propose an efficient and privacy-preserving individual billing scheme, achieving information-theoretic security, which serves as a building block. PBP-LEM utilizes this scheme, along with other techniques such as multiparty computation, inner product functional encryption and Pedersen commitments to ensure data confidentiality and accuracy. Additionally, we present three approaches, resulting in different levels of privacy protection and performance. We prove that the protocol meets its security and privacy requirements and is feasible for deployment in real LEMs: bills can be computed in less than five minutes for 4,000 users using the most computationally intensive approach, and in just 0.18 seconds using the least intensive one.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Give and Take: An End-To-End Investigation of Giveaway Scam Conversion Rates</title>
<link>https://arxiv.org/abs/2405.09757</link>
<guid>https://arxiv.org/abs/2405.09757</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、诈骗、社交媒体、直播、区块链

总结:
本文聚焦于加密货币赠品诈骗的规模性运作，通过整合Twitter、YouTube直播、Twitch、着陆页面与区块链数据，揭示了诈骗的模式与影响。研究发现，每1000条诈骗推文和每10万次直播观看中就有1人成为受害者，而诈骗者在观测期内从数百名受害者中榨取了近462万美元。这揭示了诈骗活动如何利用社交媒体和直播平台进行传播，以及加密货币的匿名特性为诈骗提供了便利。此外，通过区块链数据的分析，可以追踪资金流动路径，为制定更有效的反诈骗策略提供依据。此研究强调了理解诈骗生态系统的重要性，以设计出更具针对性的干预措施。 <div>
arXiv:2405.09757v2 Announce Type: replace 
Abstract: Scams -- fraudulent schemes designed to swindle money from victims -- have existed for as long as recorded history. However, the Internet's combination of low communication cost, global reach, and functional anonymity has allowed scam volumes to reach new heights. Designing effective interventions requires first understanding the context: how scammers reach potential victims, the earnings they make, and any potential bottlenecks for durable interventions. In this short paper, we focus on these questions in the context of cryptocurrency giveaway scams, where victims are tricked into irreversibly transferring funds to scammers under the pretense of even greater returns. Combining data from Twitter, YouTube and Twitch livestreams, landing pages, and cryptocurrency blockchains, we measure how giveaway scams operate at scale. We find that 1 in 1000 scam tweets, and 4 in 100,000 livestream views, net a victim, and that scammers managed to extract nearly \$4.62 million from just hundreds of victims during our measurement window.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reputation-Driven Peer-to-Peer Live Streaming Architecture for Preventing Free-Riding</title>
<link>https://arxiv.org/abs/2409.09329</link>
<guid>https://arxiv.org/abs/2409.09329</guid>
<content:encoded><![CDATA[
<div> 关键词：P2P、直播流、声誉系统、免费乘车、恶意节点

<br />
总结:

本文提出了一种用于解决P2P直播流中常见问题的新架构。该架构通过集成声誉系统，旨在激励积极参与的节点，同时惩罚机会主义行为和恶意节点。其核心机制包括：

1. **声誉系统激励**：该系统通过奖励积极贡献的节点（如提供资源或带宽的节点）并惩罚那些利用他人资源而未做贡献的“免费乘车者”和恶意行为者。

2. **动态策略更新**：算法持续评估和调整策略以应对网络中的变化，如节点的加入与离开，确保系统稳定性。

3. **请求加入机制**：在突发高流量情况下，源节点能够将请求分配给子节点，形成树状结构，有效管理流量高峰并保持系统稳定。

4. **去中心化声誉管理**：通过去中心化的声誉管理系统促进长期的可持续性，确保所有节点在公平条件下运行。

5. **高效需求处理**：通过上述机制的结合，系统能够有效地处理高流量需求，同时维持网络的稳定性和效率。

该架构旨在构建一个更加公平、高效、稳定的P2P直播流网络环境，通过声誉机制激励合理行为，优化资源分配，适应网络变化，最终实现系统整体性能的提升。 <div>
arXiv:2409.09329v1 Announce Type: new 
Abstract: We present a peer-to-peer (P2P) live-streaming architecture designed to address challenges such as free-riding, malicious peers, churn, and network instability through the integration of a reputation system. The proposed algorithm incentivizes active peer participation while discouraging opportunistic behaviors, with a reputation mechanism that rewards altruistic peers and penalizes free riders and malicious actors. To manage peer dynamics, the algorithm continuously updates the strategies and adjusts to changing neighbors. It also implements a request-to-join mechanism for flash crowd scenarios, allowing the source node to delegate requests to child nodes, forming an interconnected tree structure that efficiently handles high demand and maintains system stability. The decentralized reputation mechanism promotes long-term sustainability in the P2P live streaming system.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Safe and Scalable Multi-Agent Control under Limited Actuation</title>
<link>https://arxiv.org/abs/2409.09573</link>
<guid>https://arxiv.org/abs/2409.09573</guid>
<content:encoded><![CDATA[
<div> 关键词：安全、敏捷机器人、分散式控制器、输入限制、大规模扩展

总结:

本文提出了一种全新的算法，旨在为拥挤环境中的机器人部署提供安全且灵活的控制策略。该算法通过三个关键步骤实现目标：

1. **学习分散式神经积分控制障碍函数（神经ICBF）**：此步骤涉及构建一个可扩展的、针对输入受限控制设计的分散式神经网络模型，以确保在大量代理的情况下仍能有效运行。

2. **嵌入轻量级分散式模型预测控制基于积分控制障碍函数（MPC-ICBF）**：在神经网络策略中集成MPC-ICBF机制，以确保安全性的同时保持算法的可扩展性。

3. **引入基于机器学习的梯度优化技术来最小化死锁**：通过解决局部最小值问题，该方法有效减少系统中的死锁现象。

文中提供的数值模拟结果表明，该方法在安全性、输入约束满足和死锁最小化方面均优于当前最先进的多代理控制系统。此外，实验还展示了该方法在不同场景下对不同代理数量的强泛化能力，最高可达1000个代理。 <div>
arXiv:2409.09573v1 Announce Type: new 
Abstract: To deploy safe and agile robots in cluttered environments, there is a need to develop fully decentralized controllers that guarantee safety, respect actuation limits, prevent deadlocks, and scale to thousands of agents. Current approaches fall short of meeting all these goals: optimization-based methods ensure safety but lack scalability, while learning-based methods scale but do not guarantee safety. We propose a novel algorithm to achieve safe and scalable control for multiple agents under limited actuation. Specifically, our approach includes: $(i)$ learning a decentralized neural Integral Control Barrier function (neural ICBF) for scalable, input-constrained control, $(ii)$ embedding a lightweight decentralized Model Predictive Control-based Integral Control Barrier Function (MPC-ICBF) into the neural network policy to ensure safety while maintaining scalability, and $(iii)$ introducing a novel method to minimize deadlocks based on gradient-based optimization techniques from machine learning to address local minima in deadlocks. Our numerical simulations show that this approach outperforms state-of-the-art multi-agent control algorithms in terms of safety, input constraint satisfaction, and minimizing deadlocks. Additionally, we demonstrate strong generalization across scenarios with varying agent counts, scaling up to 1000 agents.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning in Adversarial Environments: Testbed Design and Poisoning Resilience in Cybersecurity</title>
<link>https://arxiv.org/abs/2409.09794</link>
<guid>https://arxiv.org/abs/2409.09794</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Flower框架、Poisoning攻击、网络安全、数据隐私

<br /><br />
总结:

本文介绍了一个设计用于网络安全领域的Federated Learning（FL）测试床。该测试床利用Flower框架构建，旨在评估FL在多个客户端协作训练全球模型时的数据隐私保护能力与分布式学习性能，特别是在敏感领域如网络安全中。通过实验分析了不同FL框架的性能、可扩展性和集成便捷性。

测试床的一个具体应用案例展示了如何使用联邦入侵检测系统进行异常检测和关键基础设施的安全保护，同时不泄露敏感网络数据。测试还对系统进行了全面的Poisoning攻击测试，以评估其在对抗敌对条件下的鲁棒性。

研究结果表明，尽管FL增强了数据隐私并支持分布式学习，但在实际应用中仍存在对Poisoning攻击的脆弱性，需要采取措施确保其可靠性。 <div>
arXiv:2409.09794v1 Announce Type: new 
Abstract: This paper presents the design and implementation of a Federated Learning (FL) testbed, focusing on its application in cybersecurity and evaluating its resilience against poisoning attacks. Federated Learning allows multiple clients to collaboratively train a global model while keeping their data decentralized, addressing critical needs for data privacy and security, particularly in sensitive fields like cybersecurity. Our testbed, built using the Flower framework, facilitates experimentation with various FL frameworks, assessing their performance, scalability, and ease of integration. Through a case study on federated intrusion detection systems, we demonstrate the testbed's capabilities in detecting anomalies and securing critical infrastructure without exposing sensitive network data. Comprehensive poisoning tests, targeting both model and data integrity, evaluate the system's robustness under adversarial conditions. Our results show that while federated learning enhances data privacy and distributed learning, it remains vulnerable to poisoning attacks, which must be mitigated to ensure its reliability in real-world applications.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coordination-free Collaborative Replication based on Operational Transformation</title>
<link>https://arxiv.org/abs/2409.09934</link>
<guid>https://arxiv.org/abs/2409.09934</guid>
<content:encoded><![CDATA[
<div> 关键词：Coordination-free Collaborative Replication（CCR）、Distributed Systems、Data-sharing systems、Conflict-free Replicated Data Type（CRDT）、Operational Transformation（OT）

<br />
<br />总结:
文章引入了协调自由协作复制(Coordination-free Collaborative Replication, CCR)，这是一种新的分布式系统一致性维护方法，无需明确的协调消息。相比传统数据共享系统依赖中心化更新管理和预定义一致性规则，CCR自动化冲突解决，提供了一种更直观和高效的数据协作方案。

具体而言，CCR通过基于数据流汇聚的通用协议，自动处理冲突，避免了如操作转换(OT)和冲突免费复制数据类型(CRDT)等方法的复杂性和潜在问题。OT虽然保证了文档一致性，但依赖于服务器协调，不适合现代去中心化的P2P环境。而CRDT虽然确保最终一致性，但可能导致非直觉的行为，如从购物车中移除的商品无法重新添加。

相比之下，CCR允许直接更新并基于当前数据状态进行冲突解决，提高了清晰度和易用性。此外，它解决了传统方法中的消息效率问题，提供了在分布式系统中进行高效和实际协作数据共享的解决方案。 <div>
arXiv:2409.09934v1 Announce Type: new 
Abstract: We introduce Coordination-free Collaborative Replication (CCR), a new method for maintaining consistency across replicas in distributed systems without requiring explicit coordination messages. CCR automates conflict resolution, contrasting with traditional Data-sharing systems that typically involve centralized update management or predefined consistency rules.
  Operational Transformation (OT), commonly used in collaborative editing, ensures consistency by transforming operations while maintaining document integrity across replicas. However, OT assumes server-based coordination, which is unsuitable for modern, decentralized Peer-to-Peer (P2P) systems.
  Conflict-free Replicated Data Type (CRDT), like Two-Phase Sets (2P-Sets), guarantees eventual consistency by allowing commutative and associative operations but often result in counterintuitive behaviors, such as failing to re-add an item to a shopping cart once removed.
  In contrast, CCR employs a more intuitive approach to replication. It allows for straightforward updates and conflict resolution based on the current data state, enhancing clarity and usability compared to CRDTs. Furthermore, CCR addresses inefficiencies in messaging by developing a versatile protocol based on data stream confluence, thus providing a more efficient and practical solution for collaborative data sharing in distributed systems.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimality Gap of Decentralized Submodular Maximization under Probabilistic Communication</title>
<link>https://arxiv.org/abs/2409.09979</link>
<guid>https://arxiv.org/abs/2409.09979</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式子模最大值、分区马尔杜姆约束、序贯贪心算法、概率性信息传递、通信意识框架

总结:

本文探讨了在不确定通信环境下的分布式子模最大值问题，特别是当系统受到分区马尔杜姆约束时。研究引入了一个通信意识框架，其中考虑了连接设备之间成功通信的概率。这一创新使得优化过程能够更好地适应实际网络中的不确定性。

首先，文章提出了概率最优性差距的概念，这一概念强调了在资源有限的环境中，基于代理广播可靠性和策略性决策来确定消息传递序列的重要性。具体而言，它关注于如何根据代理的广播能力（包括是否允许多次广播）和其在通信链路中的可靠性来优化信息传播路径。

其次，该框架不仅提供了理论上的分析工具，还具有实践意义，可以帮助设计和评估在通信不稳定环境下的分布式系统。通过考虑通信概率，可以更精确地预测系统的性能，从而优化资源配置和提高整体效率。

最后，文章通过一个数值示例直观地展示了所提出方法的有效性，证明了在不同通信概率下，优化策略对最终结果的影响。这不仅验证了理论分析的正确性，也为实际应用提供了参考。

综上所述，本文通过构建一个通信意识框架，为解决分布式子模最大值问题提供了一种新的视角，特别关注于在不确定性通信环境下，如何通过概率性信息传递来优化系统性能，具有重要的理论价值和实践指导意义。 <div>
arXiv:2409.09979v1 Announce Type: new 
Abstract: This paper considers the problem of decentralized submodular maximization subject to partition matroid constraint using a sequential greedy algorithm with probabilistic inter-agent message-passing. We propose a communication-aware framework where the probability of successful communication between connected devices is considered. Our analysis introduces the notion of the probabilistic optimality gap, highlighting its potential influence on determining the message-passing sequence based on the agent's broadcast reliability and strategic decisions regarding agents that can broadcast their messages multiple times in a resource-limited environment. This work not only contributes theoretical insights but also has practical implications for designing and analyzing decentralized systems in uncertain communication environments. A numerical example demonstrates the impact of our results.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>An integrated design of robust decentralized observer and controller for load frequency control</title>
<link>https://arxiv.org/abs/2409.10098</link>
<guid>https://arxiv.org/abs/2409.10098</guid>
<content:encoded><![CDATA[
<div> 关键词：多区域电力系统、全局优化性能、集成设计、H_∞优化、区域特征值分配

总结:

本文集中于为多区域电力系统设计完全去中心化的负荷频率控制(LFC)，以实现全球优化性能。通过引入集成设计概念，同时在线下设计去中心化LFC观察器和控制器，考虑了区域之间的相互作用以及每个区域内本地观察器与控制器之间的双向效应。集成设计通过单步线性矩阵不等式(LMI)形式的H_∞优化实现。进一步地，将H_∞优化与区域特征值分配技术结合，以提高闭环系统的瞬态性能。

为了验证所提出集成设计的优势，文中使用了一个三区域电力系统进行仿真。结果显示，与传统的去中心化设计相比，该集成设计能更有效地优化多区域电力系统的整体性能，特别是在改善瞬态响应方面展现出显著优势。通过集成设计方法，不仅能够确保各区域间的协调运行，还能够在保证系统稳定性的前提下，最大化系统的整体效率和性能。 <div>
arXiv:2409.10098v1 Announce Type: new 
Abstract: This paper focuses on designing completely decentralized load frequency control (LFC) for multi-area power systems to achieve global optimized performance. To this end, a new concept of integrated design is introduced for designing the decentralized LFC observers and controllers simultaneously off-line, by taking into account of the interactions between areas and the bidirectional effects between the local observer and controller in each area. The integrated design in this paper is realized via $H_\infty$ optimization with a single-step linear matrix inequality (LMI) formulation. The LMI regional eigenvalue assignment technique is further incorporated with $H_\infty$ optimization to improve the closed-loop system transient performance. A three-area power system is simulated to validate the superiority of the proposed integrated design over the conventional decentralized designs.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Analysing Attacks on Blockchain Systems in a Layer-based Approach</title>
<link>https://arxiv.org/abs/2409.10109</link>
<guid>https://arxiv.org/abs/2409.10109</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、攻击分类、层基方法、框架、系统强化

总结:

本文对23起针对区块链系统的攻击事件进行了全面研究，并采用了一种基于层次的方法来对这些攻击进行分类。这种方法深入探讨了这些攻击的可行性和动机，为理解区块链系统中的潜在威胁提供了新的视角。研究进一步提出了一个框架，旨在系统地分析各种攻击的影响及其相互关联性，这有助于识别可能的攻击路径，并设计适当的防御措施以增强区块链系统的安全性。

通过这种方法和框架，研究者能够更好地理解不同攻击之间的关系，从而识别出那些最有可能对系统造成损害的攻击类型，并据此制定更有效的防御策略。这一工作对于提升区块链系统的整体安全性和信任度具有重要意义，为未来的研究和实践提供了宝贵指导。 <div>
arXiv:2409.10109v1 Announce Type: new 
Abstract: Blockchain is a growing decentralized system built for transparency and immutability. There have been several major attacks on blockchain-based systems, leaving a gap in the trustability of this system. This article presents a comprehensive study of 23 attacks on blockchain systems and categorizes them using a layer-based approach. This approach provides an in-depth analysis of the feasibility and motivation of these attacks. In addition, a framework is proposed that enables a systematic analysis of the impact and interconnection of these attacks, thereby providing a means of identifying potential attack vectors and designing appropriate countermeasures to strengthen any blockchain system.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>PrePaMS: Privacy-Preserving Participant Management System for Studies with Rewards and Prerequisites</title>
<link>https://arxiv.org/abs/2409.10192</link>
<guid>https://arxiv.org/abs/2409.10192</guid>
<content:encoded><![CDATA[
<div> 关键词：PrePaMS、隐私保护、奖励支付、参与管理系统、安全解决方案

<br />
<br />总结:

文章主要介绍了一种名为PrePaMS的高效参与管理系统，该系统旨在通过隐私保护方式支持参与资格检查和奖励发放。其核心特点是利用匿名凭证和零知识证明等加密技术，确保参与者的身份在奖励过程中不被服务提供者或组织者识别，从而实现了对参与者的隐私保护。

PrePaMS系统能够组织与潜在的合格或不合格依赖关系相关的参与活动，并允许进行安全的奖励支付。它涵盖了参与者是否参与过调查、实验或研究的信息，并且当与这些事件中的实际数据收集安全解决方案结合使用时，PrePaMS可以成为更隐私保护的实证研究的基础。

为了验证PrePaMS的有效性和性能，文章设计并实现了一个原型，并在现实工作负载下进行了评估。通过这一系统，研究者可以在保护参与者隐私的同时，有效地管理和激励参与，为更广泛的隐私保护实证研究提供了可能。 <div>
arXiv:2409.10192v1 Announce Type: new 
Abstract: Taking part in surveys, experiments, and studies is often compensated by rewards to increase the number of participants and encourage attendance. While privacy requirements are usually considered for participation, privacy aspects of the reward procedure are mostly ignored. To this end, we introduce PrePaMS, an efficient participation management system that supports prerequisite checks and participation rewards in a privacy-preserving way. Our system organizes participations with potential (dis-)qualifying dependencies and enables secure reward payoffs. By leveraging a set of proven cryptographic primitives and mechanisms such as anonymous credentials and zero-knowledge proofs, participations are protected so that service providers and organizers cannot derive the identity of participants even within the reward process. In this paper, we have designed and implemented a prototype of PrePaMS to show its effectiveness and evaluated its performance under realistic workloads. PrePaMS covers the information whether subjects have participated in surveys, experiments, or studies. When combined with other secure solutions for the actual data collection within these events, PrePaMS can represent a cornerstone for more privacy-preserving empirical research.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Escaping Local Minima: Hybrid Artificial Potential Field with Wall-Follower for Decentralized Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2409.10332</link>
<guid>https://arxiv.org/abs/2409.10332</guid>
<content:encoded><![CDATA[
<div> 关键词：非凸障碍物、局部最小值、多机器人导航、局部传感器信息、无图导航

<br /><br />
总结:

本文提出了解决在非凸障碍物环境下进行多机器人导航的挑战，这些环境的特点是没有完整的环境知识。传统的反应式方法如人工势场法（APF）虽然简单高效，但容易陷入局部最小值，导致机器人被困，这是因为它们缺乏全局环境意识。现有的解决方案要么依赖于机器人间的通信，要么局限于单机器人场景，或者在处理非凸障碍物时表现不佳。

为了解决这些问题，本文提出了利用仅本地传感器和状态信息进行无图导航的方法。通过将墙壁跟随（WF）行为融入APF方法中，机器人能够避免陷入局部最小值，即使在存在非凸动态障碍物（包括其他机器人）的情况下。为了实现这一目标，文章引入了两种算法用于在APF和WF之间切换：一种基于规则的系统和一种使用专家演示训练的编码器网络。实验结果表明，这种方法在复杂环境中相比现有技术实现了显著更高的成功率，突显了其克服局部最小值限制的能力。 <div>
arXiv:2409.10332v1 Announce Type: new 
Abstract: We tackle the challenges of decentralized multi-robot navigation in environments with nonconvex obstacles, where complete environmental knowledge is unavailable. While reactive methods like Artificial Potential Field (APF) offer simplicity and efficiency, they suffer from local minima, causing robots to become trapped due to their lack of global environmental awareness. Other existing solutions either rely on inter-robot communication, are limited to single-robot scenarios, or struggle to overcome nonconvex obstacles effectively.
  Our proposed methods enable collision-free navigation using only local sensor and state information without a map. By incorporating a wall-following (WF) behavior into the APF approach, our method allows robots to escape local minima, even in the presence of nonconvex and dynamic obstacles including other robots. We introduce two algorithms for switching between APF and WF: a rule-based system and an encoder network trained on expert demonstrations. Experimental results show that our approach achieves substantially higher success rates compared to state-of-the-art methods, highlighting its ability to overcome the limitations of local minima in complex environments
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized and Asymmetric Multi-Agent Learning in Construction Sites</title>
<link>https://arxiv.org/abs/2409.10375</link>
<guid>https://arxiv.org/abs/2409.10375</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作、建筑工地、表面整平、学习算法、去中心化

总结:

本文探讨了在建筑工地上利用多智能体系统进行表面整平作业的合作模式。主要关注两个关键角色：推土机和铲车。研究提出了一种名为“去中心化和异构多智能体学习方法在建筑工地应用（DAMALCS）”的策略，旨在减少操作车辆间的预期碰撞。

DAMALCS通过设计两种专家级智能体来优化作业流程，它们能够通过一种创新的优先级分配方法，高效地实现共同目标。在这种机制下，推土机的操作优先于铲车，以确保道路畅通无阻，从而保证两台车辆的连续作业。尽管仅依赖启发式规则可能不足以应对现实世界的复杂性，但本文表明，将这些规则整合进人工智能训练过程中，能够显著提高其性能。

为了验证这一理论的有效性，研究人员在模拟环境以及真实世界实验室中对智能体进行了测试，同时考虑了视觉噪音和定位误差等变量因素。结果显示，与传统方法相比，DAMALCS策略显著降低了车辆间的碰撞率，提高了整体的工作效率和沙土处理能力。 <div>
arXiv:2409.10375v1 Announce Type: new 
Abstract: Multi-agent collaboration involves multiple participants working together in a shared environment to achieve a common goal. These agents share information, divide tasks, and synchronize their actions. Key aspects of multi agent collaboration include coordination, communication, task allocation, cooperation, adaptation, and decentralization. On construction sites, surface grading is the process of leveling sand piles to increase a specific area's height. In this scenario, a bulldozer grades while a dumper allocates sand piles. Our work aims to utilize a multi-agent approach to enable these vehicles to collaborate effectively. To this end, we propose a decentralized and asymmetric multi-agent learning approach for construction sites (DAMALCS). We formulate DAMALCS to reduce expected collisions for operating vehicles. Therefore, we develop two heuristic experts capable of achieving their joint goal optimally by applying an innovative prioritization method. In this approach, the bulldozer's movements take precedence over the dumper's operations, enabling the bulldozer to clear the path for the dumper and ensure continuous operation of both vehicles. Since heuristics alone are insufficient in real-world scenarios, we utilize them to train AI agents, which proves to be highly effective. We simultaneously train the bulldozer and dumper agents to operate within the same environment, aiming to avoid collisions and optimize performance in terms of time efficiency and sand volume handling. Our trained agents and heuristics are evaluated in both simulation and real-world lab experiments, testing them under various conditions, such as visual noise and localization errors. The results demonstrate that our approach significantly reduces collision rates for these vehicles.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Knowledge Proof-of-Identity: Sybil-Resistant, Anonymous Authentication on Permissionless Blockchains and Incentive Compatible, Strictly Dominant Cryptocurrencies</title>
<link>https://arxiv.org/abs/1905.09093</link>
<guid>https://arxiv.org/abs/1905.09093</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、身份验证、区块链、共识协议、社会网络

总结:

文章主要介绍了将基于受信任公共证书（如国家身份证、电子护照、eSIM）的零知识证明（Zero-Knowledge Proof）应用于无许可区块链的方案。该方案旨在解决现有区块链技术中效率低下问题，如工作量证明（Proof-of-Work）导致的高能源消耗和环境压力，以及权益证明（Proof-of-Stake）引发的资本囤积与交易量降低。通过限制单个个体可运行的挖矿节点数量，同时保持成员开放性，以规避完全去中心化和区块链可扩展性三难困境。同时，考虑了防止合谋的可能性。

文章提出了具有以下优势的零知识证明加密货币：

1. **激励兼容性**：设计了一种基于独特纳什均衡的激励兼容协议，用于根据唯一纳什均衡发放加密货币奖励。
2. **主导地位**：通过严格证明，零知识证明加密货币成为挖矿者的首选，证明了其作为纳什均衡和演化稳定策略的地位。
3. **社会最优效率**：零知识证明加密货币实现了社会最优效率，因此无需支付加密无政府主义的价格，而其他基于工作量证明或权益证明的加密货币则需承担此成本。
4. **帕累托改进**：零知识证明加密货币在流通方面优于其他工作量证明或权益证明加密货币。
5. **社会网络效应**：利用国家身份证、电子护照和eSIM固有的社交网络带来的网络效应，零知识证明加密货币主导其他支付形式。
6. **基础设施成本效益**：较低的基础设施成本意味着存在一个独特的均衡状态，其中它主导其他支付方式。

综上所述，文章提出的零知识证明加密货币解决方案旨在优化区块链技术的性能，通过创新的激励机制、提高效率、降低成本和促进社会网络效应，为区块链应用提供更高效、环保且公平的支付系统。 <div>
arXiv:1905.09093v3 Announce Type: replace 
Abstract: Zero-Knowledge Proof-of-Identity from trusted public certificates (e.g., national identity cards and/or ePassports; eSIM) is introduced here to permissionless blockchains in order to remove the inefficiencies of Sybil-resistant mechanisms such as Proof-of-Work (i.e., high energy and environmental costs) and Proof-of-Stake (i.e., capital hoarding and lower transaction volume). The proposed solution effectively limits the number of mining nodes a single individual would be able to run while keeping membership open to everyone, circumventing the impossibility of full decentralization and the blockchain scalability trilemma when instantiated on a blockchain with a consensus protocol based on the cryptographic random selection of nodes. Resistance to collusion is also considered.
  Solving one of the most pressing problems in blockchains, a zk-PoI cryptocurrency is proved to have the following advantageous properties:
  - an incentive-compatible protocol for the issuing of cryptocurrency rewards based on a unique Nash equilibrium
  - strict domination of mining over all other PoW/PoS cryptocurrencies, thus the zk-PoI cryptocurrency becoming the preferred choice by miners is proved to be a Nash equilibrium and the Evolutionarily Stable Strategy
  - PoW/PoS cryptocurrencies are condemned to pay the Price of Crypto-Anarchy, redeemed by the optimal efficiency of zk-PoI as it implements the social optimum
  - the circulation of a zk-PoI cryptocurrency Pareto dominates other PoW/PoS cryptocurrencies
  - the network effects arising from the social networks inherent to national identity cards and ePassports dominate PoW/PoS cryptocurrencies
  - the lower costs of its infrastructure imply the existence of a unique equilibrium where it dominates other forms of payment
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts</title>
<link>https://arxiv.org/abs/2401.07261</link>
<guid>https://arxiv.org/abs/2401.07261</guid>
<content:encoded><![CDATA[
<div> 关键词：DeFi攻击、智能合约漏洞、私有交易池、对抗性合约、机器学习

<br /><br />
总结:
本文针对去中心化金融（DeFi）中由智能合约漏洞引发的攻击事件，提出了一种新的检测方法，即通过识别对抗性合约而非攻击性交易来预防攻击。研究团队构建了一个综合数据集，包括从以太坊和BSC区块链上部署的合约中提取和构造的特征。他们设计了一种称为Pruned Semantic-Control Flow Tokenization (PSCFT)的智能合约程序精简语义控制流标记化方法，并利用此方法对基于函数调用、控制流程和其他符合模式特征的恶意代码行为进行训练。最终，该研究提供了LookAhead系统的完整实现以及其性能指标的评估，用于检测对抗性合约。这种新方法旨在提高DeFi系统的安全性，通过更早地识别潜在的攻击载体，从而防止可能的零日攻击。 <div>
arXiv:2401.07261v3 Announce Type: replace 
Abstract: Decentralized Finance (DeFi) incidents stemming from the exploitation of smart contract vulnerabilities have culminated in financial damages exceeding 3 billion US dollars. Existing defense mechanisms typically focus on detecting and reacting to malicious transactions executed by attackers that target victim contracts. However, with the emergence of private transaction pools where transactions are sent directly to miners without first appearing in public mempools, current detection tools face significant challenges in identifying attack activities effectively.
  Based on the fact that most attack logic rely on deploying one or more intermediate smart contracts as supporting components to the exploitation of victim contracts, in this paper, we propose a new direction for detecting DeFi attacks that focuses on identifying adversarial contracts instead of adversarial transactions. Our approach allows us to leverage common attack patterns, code semantics and intrinsic characteristics found in malicious smart contracts to build the LookAhead system based on Machine Learning (ML) classifiers and a transformer model that is able to effectively distinguish adversarial contracts from benign ones, and make just-in-time predictions of potential zero-day attacks. Our contributions are three-fold: First, we construct a comprehensive dataset consisting of features extracted and constructed from recent contracts deployed on the Ethereum and BSC blockchains. Secondly, we design a condensed representation of smart contract programs called Pruned Semantic-Control Flow Tokenization (PSCFT) and use it to train a combination of ML models that understand the behaviour of malicious codes based on function calls, control flows and other pattern-conforming features. Lastly, we provide the complete implementation of LookAhead and the evaluation of its performance metrics for detecting adversarial contracts.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aegis: A Decentralized Expansion Blockchain</title>
<link>https://arxiv.org/abs/2406.05904</link>
<guid>https://arxiv.org/abs/2406.05904</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、扩张链、EigenLayer、Aegis、安全

总结:

本文提出了一种基于主链质押的扩张链系统——Aegis。Aegis旨在利用现有的强大区块链基础设施，通过创建附加功能或独立功能的扩展链来增强原有系统的功能性与安全性。该系统的核心机制包括：

1. **使用主链质押**：节点通过向主链存入抵押品（即存款作为担保）来参与扩张链的运营。这一机制激励节点保持行为正确，因为违约将导致抵押品被削减（撤销）。

2. **参考与验证**：Aegis使用来自Aegis区块的主链区块引用来定义委员会成员，确保决策的连续性和稳定性。同时，主链上的检查点用于持续维护决策，而主链的重置则用于在先前的委员会变得过时后建立新的委员会。

3. **保证安全性与快速进展**：Aegis系统设计确保了在所有时间点的安全性，并在Aegis节点间延迟较低时实现了快速进展。

4. **应对挑战**：面对节点可能因撤回质押而不再保持正确性的挑战，Aegis通过假设主链写入时间有界，来解决新出现的难题。

综上所述，Aegis通过创新地结合主链质押与扩张链概念，为区块链技术提供了新的应用方向，旨在提升现有区块链系统的功能和安全性。 <div>
arXiv:2406.05904v2 Announce Type: replace 
Abstract: Blockchains implement monetary systems operated by committees of nodes. The robustness of established blockchains presents an opportunity to leverage their infrastructure for creating expansion chains. Expansion chains can provide additional functionality to the primary chain they leverage or implement separate functionalities, while benefiting from the primary chain's security and the stability of its tokens. Indeed, tools like Ethereum's EigenLayer enable nodes to stake (deposit collateral) on a primary chain to form a committee responsible for operating an expansion chain.
  But here is the rub. Classical protocols assume correct, well-behaved nodes stay correct indefinitely. Yet in our case, the stake incentivizes correctness--it will be slashed (revoked) if its owner deviates. Once a node withdraws its stake, there is no basis to assume its correctness.
  To address the new challenge, we present Aegis, an expansion chain based on primary-chain stake, assuming a bounded primary-chain write time. Aegis uses references from Aegis blocks to primary blocks to define committees, checkpoints on the primary chain to perpetuate decisions, and resets on the primary chain to establish a new committee if the previous one becomes obsolete. It ensures safety at all times and rapid progress when latency among Aegis nodes is low.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Supervised Inference of Agents in Trustless Environments</title>
<link>https://arxiv.org/abs/2409.08386</link>
<guid>https://arxiv.org/abs/2409.08386</guid>
<content:encoded><![CDATA[
<div> 关键词：新型方法、数据推理、LLM、恶意代理攻击、高效验证延迟

总结:

本文提出了一种新颖的方法，旨在通过让智能体形成群集来生成高质量的响应。该方法利用了具备数据推断和排名能力的智能体，通过采用语言模型（LLM）作为响应分类器得以实现。研究首先评估了现有的无信任代理推断策略，随后定义了其方法论并估算实际参数，同时对不同类型的恶意代理攻击进行了建模。这种方法的优势在于它能够利用群集的集体智慧，从而在分布式AI推理中实现更加可靠、安全和高效的系统，其准确率、安全性和稳定性均有所提升。实验结果显示，相较于其他无信任的推理策略，该方法在验证延迟上快了一个数量级，仅需不到125毫秒的时间。

通过将智能体组织成群集，我们不仅提高了响应的质量，而且确保了系统的整体效率和安全性。数据推断能力使得智能体能够从现有信息中进行有效的学习和决策，而LLM的应用则进一步增强了这一过程的智能化水平。此外，对恶意代理攻击的建模和防御策略的开发，确保了系统的鲁棒性，即使在面临潜在威胁的情况下，系统也能保持稳定运行。最终，通过实验证明，这种群集化的方法在速度和性能上都展现出了显著优势，为未来分布式AI系统的构建提供了新的思路和参考。 <div>
arXiv:2409.08386v1 Announce Type: new 
Abstract: In this paper, we propose a novel approach where agents can form swarms to produce high-quality responses effectively. This is accomplished by utilizing agents capable of data inference and ranking, which can be effectively implemented using LLMs as response classifiers. We assess existing approaches for trustless agent inference, define our methodology, estimate practical parameters, and model various types of malicious agent attacks. Our method leverages the collective intelligence of swarms, ensuring robust and efficient decentralized AI inference with better accuracy, security, and reliability. We show that our approach is an order of magnitude faster than other trustless inference strategies reaching less than 125 ms validation latency.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Cybersecurity Compliance and Threat Response Using AI, Blockchain &amp; Smart Contracts</title>
<link>https://arxiv.org/abs/2409.08390</link>
<guid>https://arxiv.org/abs/2409.08390</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、区块链、智能合约、安全政策、威胁响应

<br /><br />
总结:本文提出了一种集成人工智能(AI)、区块链和智能合约的创新框架，旨在解决组织内部安全政策遵守和动态威胁应对的挑战。通过自动化安全政策的执行，减少人工操作并降低人为错误的可能性。利用AI快速分析网络威胁情报，识别违规行为，并自动调整防御机制。区块链提供不可篡改的日志记录，确保透明的安全行动追踪，而智能合约确保了安全措施的一致应用。该框架通过模拟验证，显示了在遵守率和响应时间方面相对于传统方法的改进。最终，文章讨论了实施的实际影响，并提出了未来研究方向，以进一步优化系统并解决实施挑战。 <div>
arXiv:2409.08390v1 Announce Type: new 
Abstract: To address the challenges of internal security policy compliance and dynamic threat response in organizations, we present a novel framework that integrates artificial intelligence (AI), blockchain, and smart contracts. We propose a system that automates the enforcement of security policies, reducing manual effort and potential human error. Utilizing AI, we can analyse cyber threat intelligence rapidly, identify non-compliances and automatically adjust cyber defence mechanisms. Blockchain technology provides an immutable ledger for transparent logging of compliance actions, while smart contracts ensure uniform application of security measures. The framework's effectiveness is demonstrated through simulations, showing improvements in compliance enforcement rates and response times compared to traditional methods. Ultimately, our approach provides for a scalable solution for managing complex security policies, reducing costs and enhancing the efficiency while achieving compliance. Finally, we discuss practical implications and propose future research directions to further refine the system and address implementation challenges.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research on Data Right Confirmation Mechanism of Federated Learning based on Blockchain</title>
<link>https://arxiv.org/abs/2409.08476</link>
<guid>https://arxiv.org/abs/2409.08476</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、数据所有权、区块链、智能合约、分布式计算

<br />
总结:本文提出了一种基于区块链和智能合约的联邦学习数据所有权确认机制。该机制利用去中心化的区块链技术记录每个参与者对联邦学习的贡献，并通过区块链分配联邦学习成果的收益。在区块链的本地模拟环境中，相关智能合约和数据结构被模拟并实现，初步证明了方案的可行性。通过这一机制，确保了参与联邦学习各方的数据所有权、使用权和收益权得到保护与合理分配，实现了数据共享的安全与高效。同时，采用区块链技术保证了数据透明度与不可篡改性，有效提升了联邦学习合作的信任度与效率。 <div>
arXiv:2409.08476v1 Announce Type: new 
Abstract: Federated learning can solve the privacy protection problem in distributed data mining and machine learning, and how to protect the ownership, use and income rights of all parties involved in federated learning is an important issue. This paper proposes a federated learning data ownership confirmation mechanism based on blockchain and smart contract, which uses decentralized blockchain technology to save the contribution of each participant on the blockchain, and distributes the benefits of federated learning results through the blockchain. In the local simulation environment of the blockchain, the relevant smart contracts and data structures are simulated and implemented, and the feasibility of the scheme is preliminarily demonstrated.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Observer-Based Control of Second-Order Multi-vehicle Systems in Bearing-Persistently Exciting Formations</title>
<link>https://arxiv.org/abs/2409.08675</link>
<guid>https://arxiv.org/abs/2409.08675</guid>
<content:encoded><![CDATA[
<div> 关键词：多车辆系统、第二阶运动动力学、轴承持续激励（BPE）、分布式观测器、形成跟踪控制

<br /><br />
总结:
本文提出了一种基于观测器的多车辆系统形成跟踪控制方法，适用于第二阶运动动力学的系统，其中车辆无法直接获得相对或全局位置和速度测量。假设所有车辆都装备了能够感知邻近车辆相对方位的传感器，并且仅有一辆领航车辆能够访问其全球位置信息。通过利用相对方位测量以及网络接收的相邻车辆状态估计，每辆车都能够估算其绝对位置和速度。设计了一个依赖于方位和加速度测量的分布式观测器控制器。

进一步地，文章探索了基于方位的定位与状态估计的“轴承持续激励”（BPE）形成概念，提出了中央集权和去中心化方式下的新算法。研究了目标形成条件，以确保分布式观测器形成跟踪控制器的指数稳定性。为了支持理论结果的有效性，文章还提供了模拟结果，展示所提出的观测器及其基于观测器的跟踪控制器的性能。 <div>
arXiv:2409.08675v1 Announce Type: new 
Abstract: This paper proposes an observer-based formation tracking control approach for multi-vehicle systems with second-order motion dynamics, assuming that vehicles' relative or global position and velocity measurements are unavailable. It is assumed that all vehicles are equipped with sensors capable of sensing the bearings relative to neighboring vehicles and only one leader vehicle has access to its global position. Each vehicle estimates its absolute position and velocity using relative bearing measurements and the estimates of neighboring vehicles received over a communication network. A distributed observer-based controller is designed, relying only on bearing and acceleration measurements.
  This work further explores the concept of the \textit{Bearing Persistently Exciting} (BPE) formation by proposing new algorithms for bearing-based localization and state estimation of second-order systems in centralized and decentralized manners. It also examines conditions on the desired formation to guarantee the exponential stability of distributed observer-based formation tracking controllers. In support of our theoretical results, some simulation results are presented to illustrate the performance of the proposed observers as well as the observer-based tracking controllers.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BE-RAN: Blockchain-enabled Open RAN for 6G with DID and Privacy-Preserving Communication</title>
<link>https://arxiv.org/abs/2101.10856</link>
<guid>https://arxiv.org/abs/2101.10856</guid>
<content:encoded><![CDATA[
<div> 关键词：6G网络、区块链、认证、隐私保护、分布式系统

总结:
本文探讨了6G通信网络向通信、传感和计算协同系统的演进过程中，对分布式无线电接入网络（RAN）带来的挑战与需求。主要提出了“区块链增强型无线电接入网络”（Blockchain-enabled Radio Access Networks, BE-RAN）这一创新架构，旨在通过利用分布式账本技术来提升网络的安全性、隐私性和效率。BE-RAN架构的核心优势包括：

1. **信任建立**：借助区块链技术，构建了一个去中心化的信任基础，为用户提供了基于身份管理的认证服务。

2. **互认证**：实现终端设备间的相互认证，增强网络中各元素之间的安全交互。

3. **点对点通信**：支持基于区块链的点对点（P2P）通信机制，允许UE（用户设备）之间的直接通信，同时确保通信过程的透明性和可追溯性。

4. **公共网络用户服务**：为公共网络用户提供可追溯的计费和日志记录服务，确保服务的公正性和安全性。

5. **CSC集成**：BE-RAN设计旨在无缝融合通信、传感和计算功能，推动6G网络向更高效、更安全的方向发展。

通过这些特性，BE-RAN不仅减少了通信和计算开销，还通过分散的身份管理机制增强了隐私保护，为6G网络的未来发展提供了一种可行的解决方案。 <div>
arXiv:2101.10856v4 Announce Type: replace 
Abstract: As 6G networks evolve towards a synergistic system of Communication, Sensing, and Computing, Radio Access Networks become more distributed, necessitating robust end-to-end authentication. We propose Blockchain-enabled Radio Access Networks, a novel decentralized RAN architecture enhancing security, privacy, and efficiency in authentication processes. BE-RAN leverages distributed ledger technology to establish trust, offering user-centric identity management, enabling mutual authentication, and facilitating on-demand point-to-point inter-network elements and UE-UE communication with accountable logging and billing service add-on for public network users, all without relying on centralized authorities. We envision a thoroughly decentralized RAN model and propose a privacy-preserving P2P communication approach that complements existing security measures while supporting the CSC paradigm. Results demonstrate BE-RAN significantly reduces communication and computation overheads, enhances privacy through decentralized identity management, and facilitates CSC integration, advancing towards more efficient and secure 6G networks.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Elliptic Curve Pairing Stealth Address Protocols</title>
<link>https://arxiv.org/abs/2312.12131</link>
<guid>https://arxiv.org/abs/2312.12131</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、隐私保护、加密协议、椭圆曲线配对、零知识证明

总结:
本文探讨了保护区块链交易隐私的重要性，并介绍了四种使用椭圆曲线配对（ECPDKSAP）作为加密解决方案的隐蔽地址协议。这四种协议分别为ECPDKSAP、ECPSKSAP、Protocol 1和Protocol 2。ECPDKSAPs采用查看密钥和支出密钥的组合方式，而ECPSKSAP则使用单一密钥来生成查看和支出密钥。实验结果显示，Protocol 3（Elliptic Curve Pairing Dual Key Stealth Address Protocol）在视图标签方面表现最佳，特别适用于以太坊生态系统。

值得注意的是，ECPSKSAP虽然在速度上相对较慢，但其仅使用一个私有密钥的独特性质提供了理论上的价值。文章还对比了ECPDKSAP与传统方法（如DKSAP）的性能，表明前者在隐私保护方面具有显著优势。整体而言，这些协议旨在通过椭圆曲线配对技术提高区块链交易的匿名性和安全性，为用户提供更强大的隐私保护机制。 <div>
arXiv:2312.12131v3 Announce Type: replace 
Abstract: Protecting the privacy of blockchain transactions is extremely important for users. Stealth address protocols (SAP) allow users to receive assets via stealth addresses that they do not associate with their stealth meta-addresses. SAP can be generated using different cryptographic approaches. DKSAP uses an elliptic curve multiplication and hashing of the resulting shared secret. Another approach is to use a elliptic curve pairing. This paper presents four SA protocols that use elliptic curve pairing as a cryptographic solution. ECPDKSAPs are pairing-based protocols that include viewing key and spending key, while ECPSKSAP is a pairing-based protocol that uses a single key with which spending and the viewing key are derived. We find that ECPDKSAPs give significantly better results than DKSAP with the view tag. The best results are achieved with Protocol 3 (Elliptic Curve Pairing Dual Key Stealth Address Protocol), which is Ethereum-friendly. ECPSKSAP is significantly slower, but it provides an interesting theoretical result as it uses only one private key.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distribution-Free Fair Federated Learning with Small Samples</title>
<link>https://arxiv.org/abs/2402.16158</link>
<guid>https://arxiv.org/abs/2402.16158</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、公平性、分布自由、小样本、后处理算法

<br />
<br />总结:

本文提出了一种名为FedFaiREE的分布式设置下的公平学习后处理算法，专门针对小样本、分布自由的环境。该方法旨在解决联邦学习中数据分散训练带来的公平性问题，特别是在面对客户端异质性、通信成本和小样本数量的独特挑战时。FedFaiREE不仅提供了理论上的公平性和准确性保证，还在实验中得到了实证验证，证明了其在分布式系统中的有效性和实用性。

文章首先指出，随着联邦学习在实际应用中的重要性日益凸显，确保不同群体间的公平性变得至关重要。然而，现有的大多数用于保障公平性的机器学习算法设计基于集中式数据环境，并通常需要大量样本和分布假设，这与分布式、异构系统的特性不完全匹配。因此，提出了FedFaiREE这一创新解决方案。

FedFaiREE通过引入后处理算法的概念，实现了在有限样本和无分布假设条件下的公平学习。它旨在适应并克服分布式环境中常见的挑战，如客户端差异、通信开销以及样本量小等问题。理论分析和实验结果共同展示了FedFaiREE在实现公平性和保持模型性能方面的能力，验证了其在小样本、分布式学习场景中的适用性和有效性。

通过这种专门设计的方法，FedFaiREE为解决联邦学习中的公平性问题提供了一个有力的工具，不仅能够确保算法的公平性，同时还能在资源有限的环境下保持良好的性能表现。这为促进更加公平、高效的数据驱动决策过程奠定了基础。 <div>
arXiv:2402.16158v2 Announce Type: replace-cross 
Abstract: As federated learning gains increasing importance in real-world applications due to its capacity for decentralized data training, addressing fairness concerns across demographic groups becomes critically important. However, most existing machine learning algorithms for ensuring fairness are designed for centralized data environments and generally require large-sample and distributional assumptions, underscoring the urgent need for fairness techniques adapted for decentralized and heterogeneous systems with finite-sample and distribution-free guarantees. To address this issue, this paper introduces FedFaiREE, a post-processing algorithm developed specifically for distribution-free fair learning in decentralized settings with small samples. Our approach accounts for unique challenges in decentralized environments, such as client heterogeneity, communication costs, and small sample sizes. We provide rigorous theoretical guarantees for both fairness and accuracy, and our experimental results further provide robust empirical validation for our proposed method.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A proof of contribution in blockchain using game theoretical deep learning model</title>
<link>https://arxiv.org/abs/2409.07460</link>
<guid>https://arxiv.org/abs/2409.07460</guid>
<content:encoded><![CDATA[
<div> 关键词：智能城市、边缘计算、游戏理论、深度学习、区块链

总结:
本文针对智能城市服务中边缘资源弹性与可扩展性的需求，提出了一个利用游戏理论和深度学习相结合的方法，以解决边缘计算面临的资源限制问题。文章首先指出了智能城市服务对低延迟应用的需求以及边缘设备资源有限的挑战。接着，引入了游戏理论的概念，提出了一种激励服务提供商主动贡献资源并提供低延迟协作计算能力的机制。通过结合区块链技术实现资源的去中心化交易与调度，文章提出了一种基于贡献的证明机制来确保边缘计算的低延迟服务。

文中详细介绍了深度学习模型的设计，包括双编码器和单解码器结构，其中GNN（图神经网络）编码器处理结构化的决策行动数据，RNN（循环神经网络）编码器处理时间序列任务调度数据。实验结果表明，该模型相比现有最先进的方法能显著降低584%的延迟。

这一研究为智能城市服务提供了创新的边缘资源管理方案，通过优化任务调度和资源分配策略，提高了边缘计算系统的效率和响应速度，对促进智能城市基础设施的建设和运营具有重要意义。 <div>
arXiv:2409.07460v1 Announce Type: new 
Abstract: Building elastic and scalable edge resources is an inevitable prerequisite for providing platform-based smart city services. Smart city services are delivered through edge computing to provide low-latency applications. However, edge computing has always faced the challenge of limited resources. A single edge device cannot undertake the various intelligent computations in a smart city, and the large-scale deployment of edge devices from different service providers to build an edge resource platform has become a necessity. Selecting computing power from different service providers is a game-theoretic problem. To incentivize service providers to actively contribute their valuable resources and provide low-latency collaborative computing power, we introduce a game-theoretic deep learning model to reach a consensus among service providers on task scheduling and resource provisioning. Traditional centralized resource management approaches are inefficient and lack credibility, while the introduction of blockchain technology can enable decentralized resource trading and scheduling. We propose a contribution-based proof mechanism to provide the low-latency service of edge computing. The deep learning model consists of dual encoders and a single decoder, where the GNN (Graph Neural Network) encoder processes structured decision action data, and the RNN (Recurrent Neural Network) encoder handles time-series task scheduling data. Extensive experiments have demonstrated that our model reduces latency by 584% compared to the state-of-the-art.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning</title>
<link>https://arxiv.org/abs/2409.07494</link>
<guid>https://arxiv.org/abs/2409.07494</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum, 交易语言模型, 图形方法, 交易属性相似图, 账户交互图

<br />
<br />总结:
文章针对以太坊面临的日益严重的欺诈威胁问题，提出了一种名为TLMG4Eth的新方法。该方法结合了交易语言模型和图形方法，旨在捕获以太坊交易数据中的语义、相似性和结构特征。首先，通过构建交易语言模型，将数字交易数据转换为有意义的交易句子，以便模型学习交易的明确语义。其次，引入交易属性相似图，用于学习交易之间的相似信息，从而捕捉交易异常的直观见解。此外，还创建了一个账户交互图来捕捉账户交易网络的结构信息。通过深度多头注意力网络融合交易语义和相似性嵌入，并提出联合训练方法，使多头注意力网络和账户交互图协同工作，以获取两种方法的协同优势。

<br />
文章的主要贡献在于，通过整合交易语言模型与图形方法，TLMG4Eth能够更全面地分析交易数据，不仅考虑了交易的语义信息，还考虑了交易间的相似性以及账户间的交互关系，从而提供了一种更为有效的欺诈检测策略。这种方法的提出，有望提高以太坊等区块链平台的欺诈检测能力，增强系统的安全性。 <div>
arXiv:2409.07494v1 Announce Type: new 
Abstract: Ethereum faces growing fraud threats. Current fraud detection methods, whether employing graph neural networks or sequence models, fail to consider the semantic information and similarity patterns within transactions. Moreover, these approaches do not leverage the potential synergistic benefits of combining both types of models. To address these challenges, we propose TLMG4Eth that combines a transaction language model with graph-based methods to capture semantic, similarity, and structural features of transaction data in Ethereum. We first propose a transaction language model that converts numerical transaction data into meaningful transaction sentences, enabling the model to learn explicit transaction semantics. Then, we propose a transaction attribute similarity graph to learn transaction similarity information, enabling us to capture intuitive insights into transaction anomalies. Additionally, we construct an account interaction graph to capture the structural information of the account transaction network. We employ a deep multi-head attention network to fuse transaction semantic and similarity embeddings, and ultimately propose a joint training approach for the multi-head attention network and the account interaction graph to obtain the synergistic benefits of both.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DV-FSR: A Dual-View Target Attack Framework for Federated Sequential Recommendation</title>
<link>https://arxiv.org/abs/2409.07500</link>
<guid>https://arxiv.org/abs/2409.07500</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated推荐（FedRec）、隐私保护、目标攻击、协同攻击、防御机制

<br />
<br />
总结:

本文主要探讨了联邦推荐系统（FedRec）中的隐私保护问题以及其对目标攻击的脆弱性。FedRec作为一种分布式训练模型，旨在保护用户隐私，但同时也面临来自商业和社交影响的威胁。研究发现，现有针对FedRec系统的攻击方法在实现效果上存在局限性，尤其是在联邦序列推荐（FSR）任务中。

为了解决这一问题，作者提出了一种新的双视角攻击框架——DV-FSR。该框架创新性地结合了基于采样的显式策略与基于对比学习的隐式梯度策略，以实现协同攻击。同时，为了应对目标攻击，文章还引入了一种针对性的防御机制，旨在评估所提出的攻击方法的缓解效果。

通过广泛的实验验证，证明了所提出的方法在代表性的序列模型上的有效性，展示了在保护用户隐私的同时对抗目标攻击的可能性。此研究不仅为理解FedRec系统在安全方面的挑战提供了新的视角，也为开发更安全、更有效的推荐系统提供了理论基础和技术手段。 <div>
arXiv:2409.07500v1 Announce Type: new 
Abstract: Federated recommendation (FedRec) preserves user privacy by enabling decentralized training of personalized models, but this architecture is inherently vulnerable to adversarial attacks. Significant research has been conducted on targeted attacks in FedRec systems, motivated by commercial and social influence considerations. However, much of this work has largely overlooked the differential robustness of recommendation models. Moreover, our empirical findings indicate that existing targeted attack methods achieve only limited effectiveness in Federated Sequential Recommendation (FSR) tasks. Driven by these observations, we focus on investigating targeted attacks in FSR and propose a novel dualview attack framework, named DV-FSR. This attack method uniquely combines a sampling-based explicit strategy with a contrastive learning-based implicit gradient strategy to orchestrate a coordinated attack. Additionally, we introduce a specific defense mechanism tailored for targeted attacks in FSR, aiming to evaluate the mitigation effects of the attack method we proposed. Extensive experiments validate the effectiveness of our proposed approach on representative sequential models.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Analyzing the Impact of Copying-and-Pasting Vulnerable Solidity Code Snippets from Question-and-Answer Websites</title>
<link>https://arxiv.org/abs/2409.07586</link>
<guid>https://arxiv.org/abs/2409.07586</guid>
<content:encoded><![CDATA[
<div> 关键词：漏洞代码重用、智能合约、Stack Overflow、代码片段、代码克隆检测

总结:

本文研究了智能合约开发过程中从问答网站如Stack Overflow中重用可能含有漏洞代码的问题。研究发现，由于智能合约一旦部署便不可更改，且管理着价值数百万美元的资产，使得这类问题尤为重要。研究团队开发了一种基于模式的漏洞检测工具，该工具能够分析完整和不完整的智能合约代码片段，以识别潜在的漏洞代码模式。此外，他们还提出了一种利用模糊哈希技术快速检测部署智能合约中代码克隆的方法。

研究结果表明，这种新的检测方法在处理代码片段时与现有最佳实践相当，并且同样有效。大规模研究分析了18,660个代码片段，结果显示有4,596个存在漏洞，其中616个漏洞代码片段出现在7,852个已部署的智能合约中。这一发现强调了在当前已部署的智能合约中重用可能含有漏洞的代码片段是一个严重问题。

文章通过实证研究揭示了智能合约开发过程中的安全风险，并提供了有效的检测工具和方法来识别和预防此类风险，对提高智能合约的安全性具有重要意义。 <div>
arXiv:2409.07586v1 Announce Type: new 
Abstract: Ethereum smart contracts are executable programs deployed on a blockchain. Once deployed, they cannot be updated due to their inherent immutability. Moreover, they often manage valuable assets that are worth millions of dollars, making them attractive targets for attackers. The introduction of vulnerabilities in programs due to the reuse of vulnerable code posted on Q&amp;A websites such as Stack Overflow is not a new issue. However, little effort has been made to analyze the extent of this issue on deployed smart contracts. In this paper, we conduct a study on the impact of vulnerable code reuse from Q&amp;A websites during the development of smart contracts and provide tools uniquely fit to detect vulnerable code patterns in complete and incomplete Smart Contract code. This paper proposes a pattern-based vulnerability detection tool that is able to analyze code snippets (i.e., incomplete code) as well as full smart contracts based on the concept of code property graphs. We also propose a methodology that leverages fuzzy hashing to quickly detect code clones of vulnerable snippets among deployed smart contracts. Our results show that our vulnerability search, as well as our code clone detection, are comparable to state-of-the-art while being applicable to code snippets. Our large-scale study on 18,660 code snippets reveals that 4,596 of them are vulnerable, out of which 616 can be found in 7,852 deployed smart contracts. These results highlight that the reuse of vulnerable code snippets is indeed an issue in currently deployed smart contracts.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>HERL: Tiered Federated Learning with Adaptive Homomorphic Encryption using Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.07631</link>
<guid>https://arxiv.org/abs/2409.07631</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Homomorphic Encryption、Reinforcement Learning、Q-Learning、HERL

总结:
本文提出了一种名为HERL（Heterogeneous Environment Reinforced Learning）的方法，它结合了强化学习与联邦学习技术，旨在优化同态加密参数，特别是多项式模数N和系数模数q。该方法首先通过聚类分析对客户端进行分级，根据它们的计算能力和安全需求。随后，使用强化学习中的Q-learning算法动态选择最适合当前客户端层级的加密参数。

实验结果显示，HERL能够显著降低计算开销，同时保持良好的实用性和安全性水平。具体而言，其在提高模型实用性方面有17%的提升，将收敛时间缩短了高达24%，并且在增强收敛效率上提高了30%，同时保持了较低的安全风险。

通过这种方式，HERL不仅解决了同态加密在异构环境下的应用挑战，还有效平衡了隐私保护与性能优化之间的矛盾，为未来的联邦学习系统提供了更为灵活和高效的加密策略。 <div>
arXiv:2409.07631v1 Announce Type: new 
Abstract: Federated Learning is a well-researched approach for collaboratively training machine learning models across decentralized data while preserving privacy. However, integrating Homomorphic Encryption to ensure data confidentiality introduces significant computational and communication overheads, particularly in heterogeneous environments where clients have varying computational capacities and security needs. In this paper, we propose HERL, a Reinforcement Learning-based approach that uses Q-Learning to dynamically optimize encryption parameters, specifically the polynomial modulus degree, $N$, and the coefficient modulus, $q$, across different client tiers. Our proposed method involves first profiling and tiering clients according to the chosen clustering approach, followed by dynamically selecting the most suitable encryption parameters using an RL-agent. Experimental results demonstrate that our approach significantly reduces the computational overhead while maintaining utility and a high level of security. Empirical results show that HERL improves utility by 17%, reduces the convergence time by up to 24%, and increases convergence efficiency by up to 30%, with minimal security loss.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning Discovers Efficient Decentralized Graph Path Search Strategies</title>
<link>https://arxiv.org/abs/2409.07932</link>
<guid>https://arxiv.org/abs/2409.07932</guid>
<content:encoded><![CDATA[
<div> 关键词：图路径搜索、强化学习、多代理系统、社会网络、异构结构

<br /><br />
总结:
文章提出了一种基于强化学习的多代理系统，专门针对图路径搜索问题。该方法在不依赖全局网络视图的情况下，利用多个具有局部网络视图的代理进行协作，成功地结合了同质性和异构性网络结构的特点。实验结果表明，这种方法在合成和实际社会网络上的性能显著优于现有的学习和启发式基线方法。此外，研究发现，通过奖励驱动的学习，可以构建出对图导航有意义的嵌入表示，为解决图路径搜索问题提供了新的视角和解决方案。这种基于局部信息的多代理协作策略，对于处理大型、动态和隐私敏感的网络环境具有潜在优势。 <div>
arXiv:2409.07932v1 Announce Type: new 
Abstract: Graph path search is a classic computer science problem that has been recently approached with Reinforcement Learning (RL) due to its potential to outperform prior methods. Existing RL techniques typically assume a global view of the network, which is not suitable for large-scale, dynamic, and privacy-sensitive settings. An area of particular interest is search in social networks due to its numerous applications. Inspired by seminal work in experimental sociology, which showed that decentralized yet efficient search is possible in social networks, we frame the problem as a collaborative task between multiple agents equipped with a limited local view of the network. We propose a multi-agent approach for graph path search that successfully leverages both homophily and structural heterogeneity. Our experiments, carried out over synthetic and real-world social networks, demonstrate that our model significantly outperforms learned and heuristic baselines. Furthermore, our results show that meaningful embeddings for graph navigation can be constructed using reward-driven learning.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Study on Asynchronous Vote-based Blockchains</title>
<link>https://arxiv.org/abs/2409.08161</link>
<guid>https://arxiv.org/abs/2409.08161</guid>
<content:encoded><![CDATA[
<div> 关键词：投票式区块链、异步网络、验证强一致性、拜占庭容错共识、线性视图变化

总结:
本文提出了一种基于验证强一致性的拜占庭容错（BFT）共识模型，旨在解决投票式区块链在异步网络环境下的局限性。通过该模型，节点可以在异步设置中使用基于领导者的协调机制进行状态机复制（SMR），同时保持与二进制拜占庭协议相同的容错能力，但无需在投票前确保诚实节点的一致性。这意味着，节点可以操作在不同的、暂时互斥的状态上，直到最终达成共识并统一到相同的状态。

为实现这一目标，文章设计了一个针对投票式区块链的异步BFT协议。该协议解决了关键挑战，包括如何确保节点在投票轮次中最终达成一致，如何保证区块链在达成共识的同时持续前进，以及如何维持强大的拜占庭容错性。此外，该协议显著降低了消息复杂度，并首次实现了不依赖阈签名的线性视图变化。

通过采用这种新型的共识模型和协议，构建的异步区块链能够以与使用如HotStuff-2等部分同步区块链相同的方式运行，简单高效地部署于大规模网络中。 <div>
arXiv:2409.08161v1 Announce Type: new 
Abstract: Vote-based blockchains construct a state machine replication (SMR) system among participating nodes, using Byzantine Fault Tolerance (BFT) consensus protocols to transition from one state to another. Currently, they rely on either synchronous or partially synchronous networks with leader-based coordination or costly Asynchronous Common Subset (ACS) protocols in asynchronous settings, making them impractical for large-scale asynchronous applications.
  To make Asynchronous SMR scalable, this paper proposes a \emph{validated strong} BFT consensus model that allows leader-based coordination in asynchronous settings. Our BFT consensus model offers the same level of tolerance as binary byzantine agreement but does not demand consistency among honest nodes before they vote. An SMR using our model allows nodes to operate in different, tentative, but mutually exclusive states until they eventually converge on the same state. We propose an asynchronous BFT protocol for vote-based blockchains employing our consensus model to address several critical challenges: how to ensure that nodes eventually converge on the same state across voting rounds, how to assure that a blockchain will steadily progress through epochs while reaching consensus for previous epochs, and how to maintain robust byzantine fault tolerance.
  Our protocol greatly reduces message complexity and is the first one to achieve linear view changes without relying on threshold signatures. We prove that an asynchronous blockchain built on our protocol can operate with the \emph{same} simplicity and efficiency as partially synchronous blockchains built on, e.g. HotStuff-2. This facilitates deploying asynchronous blockchains across large-scale networks.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Secure Standard for NFT Fractionalization</title>
<link>https://arxiv.org/abs/2409.08190</link>
<guid>https://arxiv.org/abs/2409.08190</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币（NFT）、市场流动性、所有权分割、标准化框架、安全挑战

<br /><br />
总结:
本文聚焦于非同质化代币（NFT）市场面临的挑战，尤其是由于高准入门槛和有限的市场流动性导致的市场需求下降。为解决这一问题，文章提出了一种名为“所有权分割”的创新方法，允许多个实体共同持有单一NFT的一部分，从而降低投资者的准入门槛，提高市场流动性，并使有价值的数字资产更易于大众获取。然而，当前的NFT所有权分割领域缺乏统一的标准框架，这阻碍了安全、互操作性和可访问性平台的发展。因此，该文旨在提供深入的分析，着重于所有权分割的安全挑战，并引入一个标准化解决方案，以解决这些问题并促进更安全、更兼容和更广泛的NFT所有权分割平台的建立。 <div>
arXiv:2409.08190v1 Announce Type: new 
Abstract: Non-fungible tokens (NFTs) offer a unique method for representing digital and physical assets on the blockchain. However, the NFT market has recently experienced a downturn in interest, mainly due to challenges related to high entry barriers and limited market liquidity. Fractionalization emerges as a promising solution, allowing multiple parties to hold a stake in a single NFT. By breaking down ownership into fractional shares, this approach lowers the entry barrier for investors, enhances market liquidity, and democratizes access to valuable digital assets. Despite these benefits, the current landscape of NFT fractionalization is fragmented, with no standardized framework to guide the secure and interoperable implementation of fractionalization mechanisms. This paper contributions are twofold: first, we provide a detailed analysis of the current NFT fractionalization landscape focusing on security challenges; second, we introduce a standardized approach that addresses these challenges, paving the way for more secure, interoperable, and accessible NFT fractionalization platforms.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal Operation of Distribution System Operator and the Impact of Peer-to-Peer Transactions</title>
<link>https://arxiv.org/abs/2409.08191</link>
<guid>https://arxiv.org/abs/2409.08191</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式系统运营商、能源交易、用户侧分散化、能量匹配、实时功率一致性

总结:

本文提出了一种针对分布式系统运营商（DSO）的最优操作方法，该方法考虑了内部生产者与消费者之间的点对点（P2P）交易。研究假设DSO为中立财务实体，负责聚合生产者在P2P交易后的盈余能源和需求缺口，同时调度分布式能源资源并考虑网络完整性。文章探讨了P2P交易对DSO最优操作的影响。

1. 能量匹配型P2P交易影响了DSO与批发市场之间交换的能源数量，但不会改变DSO内部的调度决策。
   
2. 实时功率一致性水平不同会导致配电网总盈余的不同。
   
3. 对于实时功率匹配型P2P交易，提供的能源和总盈余不受影响，因此DSO可以安全地忽略遵循本文定义格式的P2P交易。
   
4. 案例研究表明，P2P交易不会影响整个系统的物理功率流动，而是影响DSO与生产者之间的财务分配。

5. 结论强调了P2P交易对DSO物理系统运行的独立性以及其对DSO与生产者之间财务关系的影响。 <div>
arXiv:2409.08191v1 Announce Type: new 
Abstract: Peer-to-peer (P2P) energy trading, commonly recognized as a decentralized approach, has emerged as a popular way to better utilize distributed energy resources (DERs). In order to better manage this user-side decentralized approach from a system operator's point of view, this paper proposes an optimal operation approach for distribution system operators (DSO), comprising internal prosumers who engage in P2P transactions. The DSO is assumed to be a financial neutral entity, holding the responsibility of aggregating the surplus energy and deficit demand of prosumers after their P2P transactions while dispatching DERs and considering network integrity. Impacts of P2P transactions on DSO's optimal operation have been studied. Results indicate that energy matching P2P trading where only the total amount of energy over a given period of time is defined may affect quantities of energy exchanged between the DSO and the wholesale market, but not internal dispatch decisions of the DSO. Different levels of real-time power consistency may lead to different total surpluses in the distribution network. For the real-time power matching P2P trading, as a special case of energy matching P2P trading, the provided energy and total surplus are not affected. In other words, DSO can safely ignore P2P transactions if they follow the format defined in this paper. Case studies verify these conclusions and further demonstrate that P2P trading will not affect physical power flow of the whole system, but the financial distribution between the DSO and prosumers.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Kronos: A Secure and Generic Sharding Blockchain Consensus with Optimized Overhead</title>
<link>https://arxiv.org/abs/2403.03655</link>
<guid>https://arxiv.org/abs/2403.03655</guid>
<content:encoded><![CDATA[
<div> 关键词：Kronos、跨区块交易、安全共识、低延迟、高吞吐量

<br /><br />
总结:本文提出了一种名为Kronos的安全分片区块链共识机制，旨在优化分片网络的性能和安全性。Kronos通过引入一种新的分片共识模式，利用共享缓冲区管理交易，实现高效传输有效交易和快速拒绝无效交易。该系统在恶意客户端攻击下，能保持原子性，并确保安全的同时，将内部分片的开销控制在最优水平。Kronos还提出了基于批处理认证和可靠跨分片传输的安全跨分片认证方法，进一步提高了系统的可靠性和效率。通过使用两种先进的分片容错协议（异步速Dumbo和部分同步Hotstuff），Kronos实现在数千节点下的高效共识，并展现出显著的吞吐量（每秒320千次交易）和较低的延迟。与以往解决方案相比，Kronos在吞吐量上提升了至少12倍，延迟减少了50%，充分展示了其在区块链领域内的创新和技术优势。 <div>
arXiv:2403.03655v3 Announce Type: replace 
Abstract: Sharding enhances blockchain scalability by dividing the network into shards, each managing specific unspent transaction outputs or accounts. As an introduced new transaction type, cross-shard transactions pose a critical challenge to the security and efficiency of sharding blockchains. Currently, there is a lack of a generic sharding consensus pattern that achieves both security and low overhead. In this paper, we present Kronos, a secure sharding blockchain consensus achieving optimized overhead. In particular, we propose a new secure sharding consensus pattern, based on a buffer managed jointly by shard members. Valid transactions are transferred to the payee via the buffer, while invalid ones are rejected through happy or unhappy paths. Kronos is proved to achieve security with atomicity under malicious clients with optimal intra-shard overhead $kB$ ($k$ for involved shard number and $B$ for a Byzantine fault tolerance (BFT) cost). Besides, we propose secure cross-shard certification methods based on batch certification and reliable cross-shard transfer. The former combines hybrid trees or vector commitments, while the latter integrates erasure coding. Handling $b$ transactions, Kronos is proved to achieve reliability with low cross-shard overhead $O(n b \lambda)$ ($n$ for shard size and $\lambda$ for the security parameter). Notably, Kronos imposes no restrictions on BFT and does not rely on time assumptions, offering optional constructions in various modules. We implement Kronos using two prominent BFT protocols: asynchronous Speeding Dumbo and partial synchronous Hotstuff. Extensive experiments demonstrate Kronos scales the consensus nodes to thousands, achieving a substantial throughput of 320 ktx/sec with 2.0 sec latency. Compared with the past solutions, Kronos outperforms, achieving up to a 12* improvement in throughput and a 50% reduction in latency.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolutionary Game Dynamics Applied to Strategic Adoption of Immersive Technologies in Cultural Heritage and Tourism</title>
<link>https://arxiv.org/abs/2409.06720</link>
<guid>https://arxiv.org/abs/2409.06720</guid>
<content:encoded><![CDATA[
<div> 关键词：arXiv, 2409.06720v1, 全新发表, 历史保护, 旅游增强

文章摘要：

文章探讨了元宇宙、AR和VR等沉浸式技术在文化与旅游业中的应用及其对行业的影响。当前，这些技术正处于发展的十字路口，各相关方正在考虑其采用的可能性，以及它们可能如何改变行业格局。文章指出，不同利益相关者的看法对于技术的采纳速度和范围至关重要。沉浸式技术有望彻底改变体验方式，因此，文化与旅游领域的决策者在权衡利弊的同时，也在考虑创新的潜在影响。

研究方法：

研究通过Q方法学将利益相关者观点分解为主要成分，并结合进化博弈模型，试图描绘可能的发展情景，揭示决策路径的潜在模式。这种方法强调了复杂系统中各种利益相关者共存动态下，如何通过演化动力学识别出长期主导策略。

总结：

文章通过分析沉浸式技术在文化与旅游业的应用前景，强调了利益相关者观点的重要性。它展示了技术如何重塑历史保存与旅游体验，同时探讨了决策过程中的复杂性。通过Q方法学和进化博弈模型的应用，文章揭示了技术采纳可能带来的长远影响和潜在策略方向。这一研究不仅提供了对未来趋势的洞察，也为决策者在采纳新技术时提供了理论依据。 <div>
arXiv:2409.06720v1 Announce Type: new 
Abstract: Immersive technologies such as Metaverse, AR, and VR are at a crossroads, with many actors pondering their adoption and potential sectors interested in integration. The cultural and tourism industries are particularly impacted, facing significant pressure to make decisions that could shape their future landscapes. Stakeholders' perceptions play a crucial role in this process, influencing the speed and extent of technology adoption. As immersive technologies promise to revolutionize experiences, stakeholders in these fields weigh the benefits and challenges of embracing such innovations. The current choices will likely determine the trajectory of cultural preservation and tourism enhancement, potentially transforming how we engage with history, art, and travel. Starting from a decomposition of stakeholders' perceptions into principal components using Q-methodology, this article employs an evolutionary game model to attempt to map possible scenarios and highlight potential decision-making trajectories. The proposed approach highlights how evolutionary dynamics lead to identifying a dominant long-term strategy that emerges from the complex system of coexistence among various stakeholders.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Cooperative AI for Large-Scale Eigenvalue Computations Using Neural Networks</title>
<link>https://arxiv.org/abs/2409.06746</link>
<guid>https://arxiv.org/abs/2409.06746</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式、神经网络、合作计算、大规模矩阵、最小特征值

<br /><br />
总结:

本文提出了一种新颖的方法，利用分布式的合作神经网络框架进行特征值计算。与传统技术在大型系统中难以实现可扩展性不同，我们的去中心化算法允许多个自主代理协作估计大型矩阵的最小特征值。每个代理使用局部神经网络模型，通过与其他代理的通信不断优化其估计结果。该方法保证即使在通信失败或网络中断的情况下也能收敛至真实特征值。理论分析证实了方法的稳健性和准确性，而实验证明了其相对于某些传统的集中式算法具有更好的性能。

文章详细介绍了算法的设计原理，包括代理间的通信机制和神经网络模型的更新规则。通过理论证明确保了算法的正确性和效率，并通过实验对比展示了在实际应用中的优势。此方法为大规模数据处理和高维问题求解提供了新的思路，特别是在分布式计算环境中，能有效提升计算速度和资源利用率。 <div>
arXiv:2409.06746v1 Announce Type: new 
Abstract: This paper presents a novel method for eigenvalue computation using a distributed cooperative neural network framework. Unlike traditional techniques that struggle with scalability in large systems, our decentralized algorithm enables multiple autonomous agents to collaboratively estimate the smallest eigenvalue of large matrices. Each agent uses a localized neural network model, refining its estimates through inter-agent communication. Our approach guarantees convergence to the true eigenvalue, even with communication failures or network disruptions. Theoretical analysis confirms the robustness and accuracy of the method, while empirical results demonstrate its better performance compared to some traditional centralized algorithms
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Synchronization Control-Plane Protocol for Quantum Link Layer</title>
<link>https://arxiv.org/abs/2409.07049</link>
<guid>https://arxiv.org/abs/2409.07049</guid>
<content:encoded><![CDATA[
<div> 关键词：量子互联网、节点间纠缠生成、分布式队列、网络仿真、同步协议

总结:
本文提出了一种面向未来量子互联网的去中心化同步协议，旨在解决节点间纠缠生成的协调挑战。该协议运行在链路层的古典控制平面，为多节点量子网络提供了一种可扩展的协调机制，以管理纠缠请求。通过NetSquid进行的量子网络仿真显示，与简单的分布式队列方法相比，该协议能够显著降低纠缠请求的平均延迟时间。具体而言，随着量子网络链接数量的增加，延迟增长减少了六倍。论文中的“事件最终同步协议”(ESP)允许网络中的多个节点以可扩展的方式协调纠缠生成过程，这是关于管理纠缠请求的第一个去中心化同步协议。这一创新对于推动量子通信和量子互联网的发展具有重要意义。 <div>
arXiv:2409.07049v1 Announce Type: new 
Abstract: Heralded entanglement generation between nodes of a future quantum internet is a fundamental operation that unlocks the potential for quantum communication. In this paper, we propose a decentralized synchronization protocol that operates at the classical control-plane of the link layer, to navigate the coordination challenges of generating heralded entanglement across few-qubit quantum network nodes. Additionally, with quantum network simulations using NetSquid, we show that our protocol achieves lower entanglement request latencies than a naive distributed queue approach. We observe a sixfold reduction in average request latency growth as the number of quantum network links increases. The Eventual Synchronization Protocol (ESP) allows nodes to coordinate on heralded entanglement generation in a scalable manner within multi-peer quantum networks. To the best of our knowledge, this is the first decentralized synchronization protocol for managing heralded entanglement requests.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Novel Voting System for Medical Catalogues in National Health Insurance</title>
<link>https://arxiv.org/abs/2409.07057</link>
<guid>https://arxiv.org/abs/2409.07057</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗保险、治疗投票系统、蒙特卡洛模拟、患者结果激励机制、区块链智能合约

总结:
本文探讨了一种医疗保险目录投票系统的概念发展。该系统的核心方法是让医生对治疗项目进行投票，以实现决策的透明度和诚信性。通过蒙特卡洛模拟，研究发现该系统能够有效地达成药物和治疗项目的共识选择。进一步的理论研究提出，应引入基于患者结果的激励机制，旨在通过优化和公平的保险目录来平衡多方利益，同时利用区块链智能合约确保透明性和诚信度。这一概念性的方法旨在改进医疗保健领域的决策过程，使其更加依赖于患者的结果和满意度。 <div>
arXiv:2409.07057v1 Announce Type: new 
Abstract: This study explores the conceptual development of a medical insurance catalogue voting system. The methodology is centred on creating a model where doctors would vote on treatment inclusions, aiming to demonstrate transparency and integrity. The results from Monte Carlo simulations suggest a robust consensus on the selection of medicines and treatments. Further theoretical investigations propose incorporating a patient outcome-based incentive mechanism. This conceptual approach could enhance decision-making in healthcare by aligning stakeholder interests with patient outcomes, aiming for an optimised, equitable insurance catalogue with potential blockchain-based smart-contracts to ensure transparency and integrity.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>XDC Staking and Tokenomics -- Improvement Proposal: Enhancing Sustainability and Decentralization on the Eve of XDC 2.0</title>
<link>https://arxiv.org/abs/2409.07420</link>
<guid>https://arxiv.org/abs/2409.07420</guid>
<content:encoded><![CDATA[
<div> 关键词：XDC网络、五周年、XDC 2.0、全面改进计划、稳定主网运营

<br /><br />
总结:
文章围绕着XDC网络的五周年庆祝和即将到来的XDC 2.0版本发布，提出了一项旨在优化网络中质押和通证经济机制的全面改进计划。此计划的核心目标在于构建一个更加可持续、去中心化和韧性的生态系统。通过引入创新概念如验证者NFT、去中心化治理和基于功能的通证经济学，该研究旨在增加验证节点的流动性并促进质押参与。提案的最终目的是为XDC 2.0建立一个坚实的基础，以培养一个既能奖励验证者、利益相关者也能惠及所有用户的繁荣生态体系。通过解决质押和通证经济学的复杂性，这项研究为XDC巩固其作为领先去中心化网络的地位铺平了道路，使其能够实现长期的成功与增长。 <div>
arXiv:2409.07420v1 Announce Type: new 
Abstract: As the XDC network celebrates five years of stable mainnet operation and prepares for the highly anticipated launch of XDC 2.0, this research proposes a comprehensive improvement plan for the network's staking and tokenomics mechanisms. Our analysis reveals opportunities to optimize the current model, ensuring a more sustainable, decentralized, and resilient ecosystem. We introduce novel concepts, including validator NFTs, decentralized governance, and utility-based tokenomics, to increase validator node liquidity and promote staking participation. Our proposal aims to establish a robust foundation for XDC 2.0, fostering a thriving ecosystem that rewards validators, stakeholders, and users alike. By addressing the intricacies of staking and tokenomics, this research paves the way for XDC to solidify its position as a leading decentralized network, poised for long-term success and growth.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Effect of Crypto Rewards in Fundraising: From a Quasi-Experiment to a Dictator Game</title>
<link>https://arxiv.org/abs/2207.07490</link>
<guid>https://arxiv.org/abs/2207.07490</guid>
<content:encoded><![CDATA[
<div> 关键词：感谢礼物、加密货币、非同质化代币（NFT）、慈善捐赠、激励设计

总结:
本文探讨了慈善捐赠中使用感谢礼物的激励设计，特别是加密货币和非同质化代币（NFT）的使用。通过分析乌克兰政府接受以太坊和比特币捐赠的案例，研究发现，以太坊比比特币更有效吸引捐赠，但捐赠金额减少更为明显。实验表明，没有实际价值的NFT感谢礼物未能有效激发捐赠行为，传统的一对一捐赠匹配策略效果更好。然而，当NFT的设计与捐赠者身份相关联并体现慈善受益方时，NFT感谢礼物能够增加捐赠规模。此研究表明，虽然加密货币在慈善捐赠中具有潜力，但其应用需考虑与捐赠者的心理关联和捐赠行为的影响。 <div>
arXiv:2207.07490v3 Announce Type: replace 
Abstract: Conditional thank-you gifts are one of the most widely used incentives for charitable giving. Past studies explored non-monetary thank-you gifts (e.g., mugs and shirts) and monetary thank-you gifts (e.g., rebates that return some of the donations to the giver). Following the rapid growth of blockchain technology, a novel form of thank-you gifts emerged: the crypto rewards. Through two studies, we analyze crypto thank-you gifts to shed light on fundraising designs in the digital world. In Study I, we examine the Ukrainian government's crypto fundraising plea that accepts donations in both Ethereum and Bitcoin. We find that Ethereum is substantially more effective in enticing giving than Bitcoin, as the hourly donation count increased 706.07% more for Ethereum than for Bitcoin when crypto rewards are present. This is likely because the crypto rewards are more likely to be issued on Ethereum than Bitcoin. However, the decrease in contribution sizes is also more substantial in Ethereum than in Bitcoin in response to the crypto rewards. In Study II, we conducted a laboratory experiment following a dictator game design to investigate the impact of crypto rewards in a more general scenario, with the crypto rewards specified as non-fungible tokens (NFTs). The crypto rewards in Study II carry no monetary value but only serve to recognize donors symbolically. As such, the NFT thank-you gifts did not effectively induce people to donate; a traditional 1:1 donation matching strictly outperforms both the condition without thank-you gifts and the condition with NFT thank-you gifts. Nevertheless, the NFT thank-you gifts effectively increased the contribution sizes, conditional on the choice to give, when the NFT's graphic design primes donor identity and encompasses the charity recipient.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Effectiveness of Local Updates for Decentralized Learning under Data Heterogeneity</title>
<link>https://arxiv.org/abs/2403.15654</link>
<guid>https://arxiv.org/abs/2403.15654</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Gradient Tracking（DGT）、Decentralized Gradient Descent（DGD）、Local Updates、Communication Complexity、Second-Order Heterogeneity

总结:

本文重新审视了在多轮本地更新情况下分布式优化方法中的两种基本技术：Decentralized Gradient Tracking（DGT）与Decentralized Gradient Descent（DGD）。研究主要集中在两个方面：

1. **通信复杂性与本地更新数量的关系**：文章通过理论分析证明，增加本地更新的数量（即K > 1），可以在保持一定网络连通性和降低数据异构性的情况下，有效减少通信复杂性。具体来说，对于μ强凸和L光滑的损失函数，DGT的通信复杂性为$\tilde{\mathcal{O}} \Big(\frac{L}{\mu K} + \frac{\delta}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$，其中ρ衡量网络连通性，δ衡量局部损失的第二阶异构性。

2. **过参数化情况下的DGD**：在局部损失具有相同最小值的过参数化场景中，即使DGD不进行梯度校正，引入本地更新也能达到与DGT相似的效果，从而进一步减少通信复杂性。

3. **理论结果的验证**：通过数值实验，文章验证了其理论分析的正确性，展示了在低数据异构性和良好网络连通性的条件下，增加本地更新次数可以显著降低通信成本。

4. **理论与应用的结合**：研究不仅提供了理论上的深入理解，还指出了在实际应用中如何更有效地利用分布式优化方法，特别是在考虑通信成本和数据分布特性时。

5. **潜在影响与未来方向**：通过揭示通信与计算之间的权衡关系，该研究为设计更高效、更具适应性的分布式学习算法提供了理论基础，未来可能在大数据处理、机器学习等领域有广泛的应用前景。 <div>
arXiv:2403.15654v2 Announce Type: replace 
Abstract: We revisit two fundamental decentralized optimization methods, Decentralized Gradient Tracking (DGT) and Decentralized Gradient Descent (DGD), with multiple local updates. We consider two settings and demonstrate that incorporating $K > 1$ local update steps can reduce communication complexity. Specifically, for $\mu$-strongly convex and $L$-smooth loss functions, we proved that local DGT achieves communication complexity $\tilde{\mathcal{O}} \Big(\frac{L}{\mu K} + \frac{\delta}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$, where $\rho$ measures the network connectivity and $\delta$ measures the second-order heterogeneity of the local loss. Our result reveals the tradeoff between communication and computation and shows increasing $K$ can effectively reduce communication costs when the data heterogeneity is low and the network is well-connected. We then consider the over-parameterization regime where the local losses share the same minimums, we proved that employing local updates in DGD, even without gradient correction, can yield a similar effect as DGT in reducing communication complexity. Numerical experiments validate our theoretical results.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Responsible Blockchain: STEADI Principles and the Actor-Network Theory-based Development Methodology (ANT-RDM)</title>
<link>https://arxiv.org/abs/2409.06179</link>
<guid>https://arxiv.org/abs/2409.06179</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、挑战与争议、负责任发展、STEADI原则、ANT-RDM方法

总结:

本文全面分析了区块链技术面临的挑战和争议。首先，它识别了技术挑战，如可扩展性、安全性、隐私性和互操作性，以及业务和采用挑战。此外，文章还探讨了当前区块链系统中存在的一些社会、经济、伦理和环境争议。

为了克服这些挑战并实现大规模采用，作者强调了“负责任的区块链开发”至关重要。为此，文章定义了“负责任的区块链”概念，并提出了“可持续性（Sustainable）、透明度（Transparent）、伦理（Ethical）、适应性（Adaptive）、去中心化（Decentralized）和包容性（Inclusive）”的六项原则（STEADI原则），作为负责任区块链发展的指导方针。

接着，文章介绍了基于行动者网络理论的区块链负责任发展方法（ANT-RDM）。此方法由四个步骤组成：问题化、兴趣投资、注册和动员。通过这四个步骤，可以系统地促进区块链的负责任发展，确保技术的进步不仅满足技术需求，而且考虑到社会、伦理和环境的影响。 <div>
arXiv:2409.06179v1 Announce Type: new 
Abstract: This paper provides a comprehensive analysis of the challenges and controversies associated with blockchain technology. It identifies technical challenges such as scalability, security, privacy, and interoperability, as well as business and adoption challenges, and the social, economic, ethical, and environmental controversies present in current blockchain systems. We argue that responsible blockchain development is key to overcoming these challenges and achieving mass adoption. This paper defines Responsible Blockchain and introduces the STEADI principles (sustainable, transparent, ethical, adaptive, decentralized, and inclusive) for responsible blockchain development. Additionally, it presents the Actor-Network Theory-based Responsible Development Methodology (ANT-RDM) for blockchains, which includes the steps of problematization, interessement, enrollment, and mobilization.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>BACKRUNNER: Mitigating Smart Contract Attacks in the Real World</title>
<link>https://arxiv.org/abs/2409.06213</link>
<guid>https://arxiv.org/abs/2409.06213</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、攻击预执行、攻击反向执行、资产保护、程序修复

总结:
本文揭示了智能合约漏洞导致的巨额经济损失问题。研究人员提出了防御性措施，旨在通过在恶意交易前插入“白帽”交易来预防攻击，从而保护资产安全。然而，作者发现现有的防御手段在实际场景中已失效，141起真实世界中的攻击案例成功绕过了最先进的防御技术。

为解决这一问题，文章提出了一种创新方法，包括预执行劫持和攻击反向执行。该方法通过将攻击利用应用到攻击前后相似或相同的合同上，以保护资产。作者将这种适应攻击的技术视为一种程序修复问题，并运用现有技术构建了一个名为BACKRUNNER的完整框架。在对2023年历史攻击的测试中，BACKRUNNER成功拯救了超过4.1亿美元的资产。而在现实世界中，它仅在两个月内就帮助拯救了价值超过1120万美元的资产，涉及28起独立事件。

这种方法不仅展示了对现有防御机制的突破，还提供了有效的资产保护策略，通过预执行和反向执行机制，有效地防止和应对智能合约攻击。 <div>
arXiv:2409.06213v1 Announce Type: new 
Abstract: Billions of dollars have been lost due to vulnerabilities in smart contracts. To counteract this, researchers have proposed attack frontrunning protections designed to preempt malicious transactions by inserting "whitehat" transactions ahead of them to protect the assets. In this paper, we demonstrate that existing frontrunning protections have become ineffective in real-world scenarios. Specifically, we collected 158 recent real-world attack transactions and discovered that 141 of them can bypass state-of-the-art frontrunning protections. We systematically analyze these attacks and show how inherent limitations of existing frontrunning techniques hinder them from protecting valuable assets in the real world. We then propose a new approach involving 1) preemptive hijack, and 2) attack backrunning, which circumvent the existing limitations and can help protect assets before and after an attack. Our approach adapts the exploit used in the attack to the same or similar contracts before and after the attack to safeguard the assets. We conceptualize adapting exploits as a program repair problem and apply established techniques to implement our approach into a full-fledged framework, BACKRUNNER. Running on previous attacks in 2023, BACKRUNNER can successfully rescue more than \$410M. In the real world, it has helped rescue over \$11.2M worth of assets in 28 separate incidents within two months.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models</title>
<link>https://arxiv.org/abs/2409.06277</link>
<guid>https://arxiv.org/abs/2409.06277</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型（LLMs）、参数高效微调（PEFT）、联邦学习、共享随机性、全参数调整

总结:
本文介绍了一种名为Ferret的新方法，旨在解决大规模细调大型语言模型（LLMs）时面临的数据隐私和通信效率问题。Ferret是首个在分散数据源上实现大规模全参数调整的联邦学习方法，同时保持了较高的模型准确度。其主要创新点在于：

1. **采用第一阶方法**：Ferret利用广泛应用于优化领域的第一阶方法进行本地更新，以提高计算效率。
2. **低维空间投影**：通过将这些更新投影到低维空间中，显著减少了通信开销，使得大规模数据集的传输更加经济。
3. **共享随机性重建**：Ferret使用共享随机性从低维空间中重建局部更新，以此促进有效全局聚合，确保快速收敛和最终性能的竞争力。
4. **理论分析与实验验证**：文章提供了详细的理论分析和广泛的实验结果，证明了Ferret在保持高计算效率、降低通信成本和加速收敛的同时，还能维持与现有方法相当的模型准确度。

综上所述，Ferret为大规模全参数调整LMLs提供了更高效的解决方案，不仅提高了模型训练的效率，还保护了数据隐私，为未来的多模态和多任务学习提供了有力支持。 <div>
arXiv:2409.06277v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have become indispensable in numerous real-world applications. Unfortunately, fine-tuning these models at scale, especially in federated settings where data privacy and communication efficiency are critical, presents significant challenges. Existing methods often resort to parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but this typically comes at the cost of model accuracy. To address these limitations, we propose federated full-parameter tuning at scale for LLMs (Ferret), the first first-order method with shared randomness to enable scalable full-parameter tuning of LLMs across decentralized data sources while maintaining competitive model accuracy. Ferret accomplishes this through three aspects: (1) it employs widely applied first-order methods for efficient local updates; (2) it projects these updates into a low-dimensional space to considerably reduce communication overhead; and (3) it reconstructs local updates from this low-dimensional space with shared randomness to facilitate effective full-parameter global aggregation, ensuring fast convergence and competitive final performance. Our rigorous theoretical analyses and insights along with extensive experiments, show that Ferret significantly enhances the scalability of existing federated full-parameter tuning approaches by achieving high computational efficiency, reduced communication overhead, and fast convergence, all while maintaining competitive model accuracy. Our implementation is available at https://github.com/allen4747/Ferret.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>DroneXNFT: An NFT-Driven Framework for Secure Autonomous UAV Operations and Flight Data Management</title>
<link>https://arxiv.org/abs/2409.06507</link>
<guid>https://arxiv.org/abs/2409.06507</guid>
<content:encoded><![CDATA[
<div> 关键词：非同质化代币、无人机、飞行数据管理、数据共享、加密技术

总结:
本文提出了一种利用非同质化代币（NFT）来管理无人机飞行数据的理论框架。通过集成加密方法、智能合约和访问控制机制，该框架旨在实现无人机飞行数据的不可篡改性和隐私保护，确保数据完整性、所有权转移以及各相关方之间的安全数据共享。NFT在此背景下扮演了重要角色，作为数字资产的唯一标识符，提供透明且安全的产权记录。加密技术确保数据的安全性，防止未经授权的访问或修改；智能合约自动执行合同条款，确保数据交换过程的公正与高效；而访问控制机制则进一步限制了数据的使用权限，只允许授权的用户访问特定信息。整体而言，该框架为无人机飞行数据管理提供了一个创新、高效且安全的解决方案。 <div>
arXiv:2409.06507v1 Announce Type: new 
Abstract: Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for managing digital assets, providing transparency and secure ownership records on a blockchain. In this paper, we present a theoretical framework for leveraging NFTs to manage UAV (Unmanned Aerial Vehicle) flight data. Our approach focuses on ensuring data integrity, ownership transfer, and secure data sharing among stakeholders. This framework utilizes cryptographic methods, smart contracts, and access control mechanisms to enable a tamper-proof and privacy-preserving management system for UAV flight data.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Agentic AI on Particle Accelerators</title>
<link>https://arxiv.org/abs/2409.06336</link>
<guid>https://arxiv.org/abs/2409.06336</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、多代理框架、自主加速器系统、人工智能应用、复杂系统管理

总结:

本文探讨了大型语言模型（LLM）在粒子加速器控制领域的潜在应用，提出了一种基于分布式多代理系统的新型控制架构。该系统旨在通过智能化的代理来处理高级任务与通信，同时每个代理专注于控制特定的加速器组件，实现自适应和自我改进。文章指出，未来AI在粒子加速器中的应用可能包括更高效的任务分配、实时故障检测与预防以及优化运行参数等。

实施这样的自主复杂系统时，需要考虑如何通过经验与人类反馈让代理逐渐学习和提升性能。引入“人机循环”（human-in-the-loop）机制对于标注操作数据、提供专业知识指导具有重要意义，有助于确保系统的可靠性和准确性。

文章通过两个案例演示了这种架构的可行性，表明了通过利用LLM驱动的多代理系统，可以有效提高粒子加速器的控制效率与精度，为粒子物理研究提供更强有力的支持。这一创新不仅推动了加速器技术的发展，也为AI在物理科学领域中的广泛应用开辟了新路径。 <div>
arXiv:2409.06336v1 Announce Type: cross 
Abstract: As particle accelerators grow in complexity, traditional control methods face increasing challenges in achieving optimal performance. This paper envisions a paradigm shift: a decentralized multi-agent framework for accelerator control, powered by Large Language Models (LLMs) and distributed among autonomous agents. We present a proposition of a self-improving decentralized system where intelligent agents handle high-level tasks and communication and each agent is specialized control individual accelerator components.
  This approach raises some questions: What are the future applications of AI in particle accelerators? How can we implement an autonomous complex system such as a particle accelerator where agents gradually improve through experience and human feedback? What are the implications of integrating a human-in-the-loop component for labeling operational data and providing expert guidance? We show two examples, where we demonstrate viability of such architecture.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Concealing Backdoor Model Updates in Federated Learning by Trigger-Optimized Data Poisoning</title>
<link>https://arxiv.org/abs/2405.06206</link>
<guid>https://arxiv.org/abs/2405.06206</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Backdoor攻击、DPOT、模型更新、数据污染

<br /><br />
总结:文章主要探讨了Federated Learning（FL）领域中的一种新型后门攻击策略——DPOT（Dynamic Poisoning Objective Tuning）。该策略通过动态构建后门目标并优化后门触发器，使得后门数据对模型更新的影响降至最低，从而巧妙地隐藏恶意行为。与现有的基于分析客户端模型更新的防御措施相比，DPOT能够有效对抗这些防御，且在多种数据集上的实验结果表明其性能优于当前的后门攻击技术。文章提供了对DPOT攻击原理的理论证明，并强调了其在FL环境下的隐秘性和破坏性。这一研究揭示了FL系统在对抗针对性攻击时面临的挑战，并为开发更有效的防御机制提供了新的视角。

<br /><br /> <div>
arXiv:2405.06206v2 Announce Type: replace 
Abstract: Federated Learning (FL) is a decentralized machine learning method that enables participants to collaboratively train a model without sharing their private data. Despite its privacy and scalability benefits, FL is susceptible to backdoor attacks, where adversaries poison the local training data of a subset of clients using a backdoor trigger, aiming to make the aggregated model produce malicious results when the same backdoor condition is met by an inference-time input. Existing backdoor attacks in FL suffer from common deficiencies: fixed trigger patterns and reliance on the assistance of model poisoning. State-of-the-art defenses based on analyzing clients' model updates exhibit a good defense performance on these attacks because of the significant divergence between malicious and benign client model updates. To effectively conceal malicious model updates among benign ones, we propose DPOT, a backdoor attack strategy in FL that dynamically constructs backdoor objectives by optimizing a backdoor trigger, making backdoor data have minimal effect on model updates. We provide theoretical justifications for DPOT's attacking principle and display experimental results showing that DPOT, via only a data-poisoning attack, effectively undermines state-of-the-art defenses and outperforms existing backdoor attack techniques on various datasets.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Edge Computing for IoT: Novel Insights from a Comparative Analysis of Access Control Models</title>
<link>https://arxiv.org/abs/2405.07685</link>
<guid>https://arxiv.org/abs/2405.07685</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网、边缘计算、数据安全、访问控制、区块链技术

<br /><br />
总结:
文章主要探讨了物联网（IoT）边缘计算中数据安全与访问控制的挑战及解决方案。首先，边缘计算通过将计算资源部署靠近数据源，有效降低了延迟，减轻了云网络带宽压力，并提升了数据安全性。然而，边缘计算环境下的数据安全仍然面临重大威胁，如数据泄露等，因此访问控制成为了保护数据的关键手段。

文章创新性地将访问控制措施按照数据生命周期的不同阶段——数据收集、存储和使用——进行了分类整理，并结合区块链技术进行了深入分析。这种分类方法提供了新的研究视角，有助于系统地识别现有技术的不足之处，并为未来的研究方向提供指导。通过这种方式，该文不仅为物联网边缘计算领域的研究人员提供了全面的综述，还为访问控制技术的发展指明了可能的路径。

文章强调了在边缘计算环境下，如何利用区块链技术等创新手段来优化访问控制策略，以实现资源节约、低延迟、灵活和可扩展的目标。这对于推动物联网边缘计算领域的发展具有重要意义，特别是对于构建更安全、高效的数据管理系统至关重要。 <div>
arXiv:2405.07685v3 Announce Type: replace 
Abstract: IoT edge computing positions computing resources closer to the data sources to reduce the latency, relieve the bandwidth pressure on the cloud, and enhance data security. Nevertheless, data security in IoT edge computing still faces critical threats (e.g., data breaches). Access control is fundamental for mitigating these threats. However, IoT edge computing introduces notable challenges for achieving resource-conserving, low-latency, flexible, and scalable access control. To review recent access control measures, we novelly organize them according to different data lifecycles--data collection, storage, and usage--and, meanwhile, review blockchain technology in this novel organization. In this way, we provide novel insights and envisage several potential research directions. This survey can help readers find gaps systematically and prompt the development of access control techniques in IoT edge computing under the intricacy of innovations in access control.
]]></content:encoded>
<pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting Buggy Contracts via Smart Testing</title>
<link>https://arxiv.org/abs/2409.04597</link>
<guid>https://arxiv.org/abs/2409.04597</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart合同、动态分析、基础模型、性能瓶颈、智能系统

总结:
文章主要探讨了针对Smart合同的脆弱性检测问题。作者指出，目前流行的混合动态分析方法，如基于约束的执行辅助模糊测试和基于基础模型的辅助模糊测试，在实际基准测试中显示出了初步的潜力，但仍然面临低可扩展性的问题，尤其是对于复杂代码模式中的深层bug。研究发现，现有动态分析的性能瓶颈和基础模型的幻觉是限制这种混合方法扩展性的两个主要因素。

为了克服这些挑战，作者设计了一种交互式、自我决定的基础模型支持系统——SmartSys，以支持Smart合同的混合动态分析。SmartSys通过教授基础模型不同动态分析技术的性能瓶颈，使其能够预测最适合的技术并生成有效的模糊目标，这些目标能够触及到深层、隐藏的bug。此外，系统利用动态分析期间的编译反馈和运行时反馈来过滤掉错误的模糊目标。

研究结果表明，SmartSys成功地发现了逃过11个工具和多次审计超过一年的Smart合同协议漏洞，并在真实世界基准测试中将覆盖率提高了14.3%相比基线。这证明了SmartSys在提高Smart合同安全性方面的有效性和潜力。 <div>
arXiv:2409.04597v1 Announce Type: new 
Abstract: Smart contracts are susceptible to critical vulnerabilities. Hybrid dynamic analyses, such as concolic execution assisted fuzzing and foundation model assisted fuzzing, have emerged as highly effective testing techniques for smart contract bug detection recently. This hybrid approach has shown initial promise in real-world benchmarks, but it still suffers from low scalability to find deep bugs buried in complex code patterns. We observe that performance bottlenecks of existing dynamic analyses and model hallucination are two main factors limiting the scalability of this hybrid approach in finding deep bugs.
  To overcome the challenges, we design an interactive, self-deciding foundation model based system, called SmartSys, to support hybrid smart contract dynamic analyses. The key idea is to teach foundation models about performance bottlenecks of different dynamic analysis techniques, making it possible to forecast the right technique and generates effective fuzz targets that can reach deep, hidden bugs. To prune hallucinated, incorrect fuzz targets, SmartSys feeds foundation models with feedback from dynamic analysis during compilation and at runtime.
  The interesting results of SmartSys include: i) discovering a smart contract protocol vulnerability that has escaped eleven tools and survived multiple audits for over a year; ii) improving coverage by up to 14.3\% on real-world benchmarks compared to the baselines.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Learning in General-sum Markov Games</title>
<link>https://arxiv.org/abs/2409.04613</link>
<guid>https://arxiv.org/abs/2409.04613</guid>
<content:encoded><![CDATA[
<div> 关键词：Markov游戏、近势函数、演员-评论家算法、分布式学习、纳什均衡

<br /><br />
总结:

本文研究了一种用于设计一般和动态社会系统中具有异质效用的代理之间的分布式学习算法的新框架。主要贡献包括：

1. **提出Markov近势函数（MNPF）**：为了解决设计能够收敛到精确纳什均衡的分布式算法的困难，作者引入了MNPF这一概念。MNPF在确保算法收敛至近似纳什均衡方面扮演着核心角色。

2. **利用双时间尺度方法**：通过快速更新Q函数估计并慢速更新策略，该方法加速了算法的收敛过程。这种方法确保了系统的长期稳定性和收敛性。

3. **证明收敛性**：文章证明了基于演员-评论家架构的分布式学习算法在长期运行中会收敛到MNPF定义的近似纳什均衡集合。如果纳什均衡集有限，则此收敛性更加强大。

4. **理论与实际应用结合**：研究不仅提供了理论分析，还为多代理系统中的分布式学习算法的设计与实现提供了新的视角，有助于解决现实世界中的复杂交互问题。

5. **扩展游戏类型**：该工作特别关注于一般和混合性的马尔科夫游戏，这比传统的零和或潜力游戏更具挑战性，因为它们既不是完全竞争也不是完全合作的。

通过这些创新，本文为分布式学习算法在多代理系统中的应用提供了坚实的理论基础和实用策略。 <div>
arXiv:2409.04613v1 Announce Type: new 
Abstract: The Markov game framework is widely used to model interactions among agents with heterogeneous utilities in dynamic and uncertain societal-scale systems. In these systems, agents typically operate in a decentralized manner due to privacy and scalability concerns, often acting without any information about other agents. The design and analysis of decentralized learning algorithms that provably converge to rational outcomes remain elusive, especially beyond Markov zero-sum games and Markov potential games, which do not adequately capture the nature of many real-world interactions that is neither fully competitive nor fully cooperative. This paper investigates the design of decentralized learning algorithms for general-sum Markov games, aiming to provide provable guarantees of convergence to approximate Nash equilibria in the long run. Our approach builds on constructing a Markov Near-Potential Function (MNPF) to address the intractability of designing algorithms that converge to exact Nash equilibria. We demonstrate that MNPFs play a central role in ensuring the convergence of an actor-critic-based decentralized learning algorithm to approximate Nash equilibria. By leveraging a two-timescale approach, where Q-function estimates are updated faster than policy updates, we show that the system converges to a level set of the MNPF over the set of approximate Nash equilibria. This convergence result is further strengthened if the set of Nash equilibria is assumed to be finite. Our findings provide a new perspective on the analysis and design of decentralized learning algorithms in multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Optimal Stable Matches in Decentralized Markets with Unknown Preferences</title>
<link>https://arxiv.org/abs/2409.04669</link>
<guid>https://arxiv.org/abs/2409.04669</guid>
<content:encoded><![CDATA[
<div> 关键词：匹配算法、分散式系统、有限信息、在线学习、稳定匹配

总结:

本文探讨了在缺乏中心协调和大量信息的情况下，设计分散式、有限信息匹配算法的可能性。主要关注的是两个独立集合（提案者和接受者）之间的双侧市场匹配问题，每个集合的成员都试图与市场对面的最理想伙伴进行匹配。然而，提案者并不了解自己的偏好，因此需要在形成匹配的同时学习其偏好。

研究中提出了一个简单的在线学习规则，该规则能够保证以概率方式收敛到游戏的福利最大化均衡点，即提案者最优稳定的匹配。这是首次报道的完全解耦、无通信算法，能够在不考虑市场结构的情况下保证概率收敛到最优稳定匹配。此工作为在有限信息条件下实现高效、分散式的匹配系统提供了理论基础和实用策略。 <div>
arXiv:2409.04669v1 Announce Type: new 
Abstract: Matching algorithms have demonstrated great success in several practical applications, but they often require centralized coordination and plentiful information. In many modern online marketplaces, agents must independently seek out and match with another using little to no information. For these kinds of settings, can we design decentralized, limited-information matching algorithms that preserve the desirable properties of standard centralized techniques? In this work, we constructively answer this question in the affirmative. We model a two-sided matching market as a game consisting of two disjoint sets of agents, referred to as proposers and acceptors, each of whom seeks to match with their most preferable partner on the opposite side of the market. However, each proposer has no knowledge of their own preferences, so they must learn their preferences while forming matches in the market. We present a simple online learning rule that guarantees a strong notion of probabilistic convergence to the welfare-maximizing equilibrium of the game, referred to as the proposer-optimal stable match. To the best of our knowledge, this represents the first completely decoupled, communication-free algorithm that guarantees probabilistic convergence to an optimal stable match, irrespective of the structure of the matching market.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal decentralized wavelength control in light sources for lithography</title>
<link>https://arxiv.org/abs/2409.04721</link>
<guid>https://arxiv.org/abs/2409.04721</guid>
<content:encoded><![CDATA[
<div> 关键词：脉冲光源、细光束波长控制、多光学模块、分散式线性二次高斯问题、时间延迟补偿

<br /><br />
总结:
本文探讨了在存在时间延迟的情况下，如何通过分散式线性二次高斯（LQG）方法实现最优的波长控制，这对于现代光刻中的精细光束波长控制至关重要。研究中将用于生成所需波长的多光学模块（包括光学元件和执行器）视为在有向无环图（DAG）上协作交互的系统。研究结果表明，任何测量和其它连续时间延迟都能被精确补偿，进而实现了在个体光学级别上的最佳控制器实施，这显著优于现有的波长控制技术。这一创新方法为提高光刻工艺的精度和效率提供了新的途径，对半导体制造领域具有重要意义。 <div>
arXiv:2409.04721v1 Announce Type: new 
Abstract: Pulsed light sources are a critical component of modern lithography, with fine light beam wavelength control paramount for wafer etching accuracy. We study optimal wavelength control by casting it as a decentralized linear quadratic Gaussian (LQG) problem in presence of time-delays. In particular, we consider the multi-optics module (optics and actuators) used for generating the requisite wavelength in light sources as cooperatively interacting systems defined over a directed acyclic graph (DAG). We show that any measurement and other continuous time-delays can be exactly compensated, and the resulting optimal controller implementation at the individual optics-level outperforms any existing wavelength control techniques.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noise-Based Authentication: Is It Secure?</title>
<link>https://arxiv.org/abs/2409.04931</link>
<guid>https://arxiv.org/abs/2409.04931</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、生物识别、热噪声、去中心化身份网络、安全认证

总结:

本文提出了一种基于区块链的去中心化身份网络中的三点生物特征认证系统。该系统利用现有生物识别技术，展示了每个个体独有的生物特性指纹及其生物特征信息泄露的可能性。通过探索每个用户生成的独特热噪声振幅，作者提出了一个全新的认证概念。这一方法旨在实现无条件安全的认证过程，其安全性基于热噪声的不可预测性和唯一性。文章还讨论了该认证系统在实际应用中可能遇到的挑战和需要解决的问题，特别是在确保其稳定性和可靠性方面。此研究为未来在区块链环境下构建更安全、隐私保护更强的身份验证机制提供了新的思路。 <div>
arXiv:2409.04931v1 Announce Type: new 
Abstract: This paper introduces a three-point biometric authentication system for a blockchain-based decentralized identity network. We use existing biometric authentication systems to demonstrate the unique noise fingerprints that belong to each individual human and the respective information leak from the biological characteristics. We then propose the concept of using unique thermal noise amplitudes generated by each user and explore the open questions regarding the robustness of unconditionally secure authentication.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>CONNECTOR: Enhancing the Traceability of Decentralized Bridge Applications via Automatic Cross-chain Transaction Association</title>
<link>https://arxiv.org/abs/2409.04937</link>
<guid>https://arxiv.org/abs/2409.04937</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized bridge、Cross-chain transaction、Bridge smart contract、Automated association、DeFi ecosystem

<br /><br />
总结:

本文主要探讨了跨链交易关联在去中心化金融（DeFi）生态系统中的重要性。在多链环境下运行的DeFi生态系统中，去中心化桥应用扮演着连接不同区块链和促进跨链资产转移的关键角色。然而，现有方法完全依赖于不可见的内部账本或API，这与区块链开放和去中心化的特性相违背。针对这一问题，本文提出了基于桥接智能合约的自动化跨链交易关联分析方法——CONNECTOR。

CONNECTOR首先通过从桥接合约的交易轨迹中提取独特的和通用的特征来识别存款交易。利用准确的存款交易，CONNECTOR进一步挖掘桥接合约的执行日志以实现提款交易匹配。通过在不同类型的桥梁上进行实际世界实验，证明了CONNECTOR的有效性。实验结果表明，CONNECTOR成功识别了100%的存款交易，关联了95.81%的提款交易，并在传统金融（CeFi）桥梁方法中表现出超越。基于关联结果，文章揭示了DeFi桥应用中的跨链交易行为，并分析了CONNECTOR的追踪能力，为DeFi桥应用提供辅助。 <div>
arXiv:2409.04937v1 Announce Type: new 
Abstract: Decentralized bridge applications are important software that connects various blockchains and facilitates cross-chain asset transfer in the decentralized finance (DeFi) ecosystem which currently operates in a multi-chain environment. Cross-chain transaction association identifies and matches unique transactions executed by bridge DApps, which is important research to enhance the traceability of cross-chain bridge DApps. However, existing methods rely entirely on unobservable internal ledgers or APIs, violating the open and decentralized properties of blockchain. In this paper, we analyze the challenges of this issue and then present CONNECTOR, an automated cross-chain transaction association analysis method based on bridge smart contracts. Specifically, CONNECTOR first identifies deposit transactions by extracting distinctive and generic features from the transaction traces of bridge contracts. With the accurate deposit transactions, CONNECTOR mines the execution logs of bridge contracts to achieve withdrawal transaction matching. We conduct real-world experiments on different types of bridges to demonstrate the effectiveness of CONNECTOR. The experiment demonstrates that CONNECTOR successfully identifies 100% deposit transactions, associates 95.81% withdrawal transactions, and surpasses methods for CeFi bridges. Based on the association results, we obtain interesting findings about cross-chain transaction behaviors in DeFi bridges and analyze the tracing abilities of CONNECTOR to assist the DeFi bridge apps.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balancing Security and Accuracy: A Novel Federated Learning Approach for Cyberattack Detection in Blockchain Networks</title>
<link>https://arxiv.org/abs/2409.04972</link>
<guid>https://arxiv.org/abs/2409.04972</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据共享、差分隐私、协作式网络攻击检测、模型融合

总结:
本文提出了一种创新的协作式网络攻击检测（CCD）系统，旨在通过解决联邦学习模型中噪声添加的复杂挑战，增强基于区块链的数据共享网络的安全性。该系统利用差分隐私的理论基础，通过在训练子模型后添加噪声，再通过传输重建全局模型的方式，实现了对网络攻击的高效检测。研究分析了不同类型的噪声（高斯、拉普拉斯和动量会计）对关键性能指标的影响，包括攻击检测准确性、深度学习模型收敛时间以及全球模型生成的整体运行时间。

研究发现，在确保数据隐私与维持系统性能之间存在微妙的权衡关系。通过深入的模拟实验，文章提供了优化这些参数以适应不同CCD环境的实用建议，旨在实现数据保护与系统效率之间的最佳平衡，为构建安全可靠的区块链网络做出贡献。 <div>
arXiv:2409.04972v1 Announce Type: new 
Abstract: This paper presents a novel Collaborative Cyberattack Detection (CCD) system aimed at enhancing the security of blockchain-based data-sharing networks by addressing the complex challenges associated with noise addition in federated learning models. Leveraging the theoretical principles of differential privacy, our approach strategically integrates noise into trained sub-models before reconstructing the global model through transmission. We systematically explore the effects of various noise types, i.e., Gaussian, Laplace, and Moment Accountant, on key performance metrics, including attack detection accuracy, deep learning model convergence time, and the overall runtime of global model generation. Our findings reveal the intricate trade-offs between ensuring data privacy and maintaining system performance, offering valuable insights into optimizing these parameters for diverse CCD environments. Through extensive simulations, we provide actionable recommendations for achieving an optimal balance between data protection and system efficiency, contributing to the advancement of secure and reliable blockchain networks.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Practical Overlay Networks for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2409.05331</link>
<guid>https://arxiv.org/abs/2409.05331</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized federated learning、Overlay network、FedLay、Fast training、Low communication

总结:

本文探讨了分布式设备上机器学习任务中分散式联邦学习(DFL)的关键网络挑战。DFL通过去中心化的通信方式避免了集中式联邦学习中的单点故障问题，被认为是具有吸引力的解决方案。然而，现有的研究主要集中在DFL的拓扑结构上，而缺乏实现去中心化构建和维护网络的协议。

为解决这一问题，作者提出了一种名为FedLay的去中心化网络解决方案。FedLay旨在提供快速训练和低通信成本，以实现实际应用中的高效DFL。其独特之处在于能够以去中心化的方式构建接近随机规则的拓扑结构，并在节点加入和失败的情况下维持拓扑。

实验结果表明，基于原型实现和模拟的测试显示，FedLay在真实数据集上的模型收敛速度最快，准确度最高，同时通信成本较低，并具备对节点加入和失败的鲁棒性。这一成果填补了现有DFL拓扑结构在构建和维护协议方面的空白，为DFL的实用性和效率提供了重要支持。 <div>
arXiv:2409.05331v1 Announce Type: new 
Abstract: Decentralized federated learning (DFL) uses peer-to-peer communication to avoid the single point of failure problem in federated learning and has been considered an attractive solution for machine learning tasks on distributed devices. We provide the first solution to a fundamental network problem of DFL: what overlay network should DFL use to achieve fast training of highly accurate models, low communication, and decentralized construction and maintenance? Overlay topologies of DFL have been investigated, but no existing DFL topology includes decentralized protocols for network construction and topology maintenance. Without these protocols, DFL cannot run in practice. This work presents an overlay network, called FedLay, which provides fast training and low communication cost for practical DFL. FedLay is the first solution for constructing near-random regular topologies in a decentralized manner and maintaining the topologies under node joins and failures. Experiments based on prototype implementation and simulations show that FedLay achieves the fastest model convergence and highest accuracy on real datasets compared to existing DFL solutions while incurring small communication costs and being resilient to node joins and failures.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning</title>
<link>https://arxiv.org/abs/2409.05701</link>
<guid>https://arxiv.org/abs/2409.05701</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、FedAvg、Personalized FL、Diffusion Model、pFedGPA

总结:

本文提出了一种名为pFedGPA的个性化联邦学习框架，旨在解决联邦学习中参数聚合问题。传统的联邦学习方法如FedAvg通常通过线性聚合参数，这在处理异构数据分布时可能会忽略参数空间的复杂性和高维性，从而影响模型性能。而个人化联邦学习虽然能在一定程度上缓解这一问题，但线性聚合的问题仍未得到解决。

pFedGPA利用生成模型的思路，通过在服务器端部署扩散模型来整合各客户端的参数分布，并引入了一个参数反转方法。该方法将上传的参数转换为潜在代码，然后通过去噪采样进行聚合，生成最终的个性化参数。通过使用具有高容量的扩散模型编码客户端模型参数对特定数据分布的依赖性，pFedGPA能够有效地分解所有客户端模型参数分布的整体复杂性与每个个体客户端参数分布的复杂性。

实验结果表明，pFedGPA在多个数据集上的表现均优于基线方法，证明了其在提升联邦学习性能方面的有效性和潜力。 <div>
arXiv:2409.05701v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized approach to model training, where data remains local and only model parameters are shared between the clients and the central server. Traditional methods, such as Federated Averaging (FedAvg), linearly aggregate these parameters which are usually trained on heterogeneous data distributions, potentially overlooking the complex, high-dimensional nature of the parameter space. This can result in degraded performance of the aggregated model. While personalized FL approaches can mitigate the heterogeneous data issue to some extent, the limitation of linear aggregation remains unresolved. To alleviate this issue, we investigate the generative approach of diffusion model and propose a novel generative parameter aggregation framework for personalized FL, \texttt{pFedGPA}. In this framework, we deploy a diffusion model on the server to integrate the diverse parameter distributions and propose a parameter inversion method to efficiently generate a set of personalized parameters for each client. This inversion method transforms the uploaded parameters into a latent code, which is then aggregated through denoising sampling to produce the final personalized parameters. By encoding the dependence of a client's model parameters on the specific data distribution using the high-capacity diffusion model, \texttt{pFedGPA} can effectively decouple the complexity of the overall distribution of all clients' model parameters from the complexity of each individual client's parameter distribution. Our experimental results consistently demonstrate the superior performance of the proposed method across multiple datasets, surpassing baseline approaches.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative Decision-Making for CAVs at Unsignalized Intersections: A MARL Approach with Attention and Hierarchical Game Priors</title>
<link>https://arxiv.org/abs/2409.05712</link>
<guid>https://arxiv.org/abs/2409.05712</guid>
<content:encoded><![CDATA[
<div> 关键词：自主驾驶车辆、复杂场景决策、多智能体强化学习、注意力机制、安全监督模块

总结:

本文针对复杂人类与机器混合交通场景中的决策问题，特别是无信号交叉口的自主驾驶车辆（CAV）决策，提出了一种创新方法——Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient（MA-GA-DDPG）。该方法将CAV的决策问题视为分布式多智能体强化学习问题，并引入注意力机制来捕捉CAV与其他代理之间的互动依赖性。通过计算CAV与其他代理之间的注意力权重，筛选互动对象并构建先验层次游戏关系，设计了安全监督模块以提升交通安全。研究通过仿真和硬件在环实验验证了该方法在驾驶安全性、效率和舒适性方面的优越性，相较于其他基准方法表现出显著优势。 <div>
arXiv:2409.05712v1 Announce Type: new 
Abstract: The development of autonomous vehicles has shown great potential to enhance the efficiency and safety of transportation systems. However, the decision-making issue in complex human-machine mixed traffic scenarios, such as unsignalized intersections, remains a challenge for autonomous vehicles. While reinforcement learning (RL) has been used to solve complex decision-making problems, existing RL methods still have limitations in dealing with cooperative decision-making of multiple connected autonomous vehicles (CAVs), ensuring safety during exploration, and simulating realistic human driver behaviors. In this paper, a novel and efficient algorithm, Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient (MA-GA-DDPG), is proposed to address these limitations. Our proposed algorithm formulates the decision-making problem of CAVs at unsignalized intersections as a decentralized multi-agent reinforcement learning problem and incorporates an attention mechanism to capture interaction dependencies between ego CAV and other agents. The attention weights between the ego vehicle and other agents are then used to screen interaction objects and obtain prior hierarchical game relations, based on which a safety inspector module is designed to improve the traffic safety. Furthermore, both simulation and hardware-in-the-loop experiments were conducted, demonstrating that our method outperforms other baseline approaches in terms of driving safety, efficiency, and comfort.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Double Tracking Method for Optimization with Decentralized Generalized Orthogonality Constraints</title>
<link>https://arxiv.org/abs/2409.04998</link>
<guid>https://arxiv.org/abs/2409.04998</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、泛化正交约束、约束消解操作、无约束惩罚模型、全局收敛性

<br />
<br />
总结:
本文研究了具有广义正交约束的分布式优化问题。这类问题在实际应用中普遍存在，但在存在分布约束的情况下，现有的算法无法解决。为了解决这一难题，作者将原始问题转化为一个无约束惩罚模型，通过引入最近提出的约束消解操作。然而，这种转换破坏了惩罚函数的分离性质，使得现有的算法无法应用。为此，作者提出了一种新颖的算法，该算法同时跟踪目标函数的梯度和约束映射的雅可比矩阵，确保了全局收敛性，并给出了迭代复杂性的证明。为了验证所提算法的有效性和效率，作者使用合成数据集和真实世界数据集进行了数值结果分析，充分展示了算法的性能优势。 <div>
arXiv:2409.04998v1 Announce Type: cross 
Abstract: In this paper, we consider the decentralized optimization problems with generalized orthogonality constraints, where both the objective function and the constraint exhibit a distributed structure. Such optimization problems, albeit ubiquitous in practical applications, remain unsolvable by existing algorithms in the presence of distributed constraints. To address this issue, we convert the original problem into an unconstrained penalty model by resorting to the recently proposed constraint-dissolving operator. However, this transformation compromises the essential property of separability in the resulting penalty function, rendering it impossible to employ existing algorithms to solve. We overcome this difficulty by introducing a novel algorithm that tracks the gradient of the objective function and the Jacobian of the constraint mapping simultaneously. The global convergence guarantee is rigorously established with an iteration complexity. To substantiate the effectiveness and efficiency of our proposed algorithm, we present numerical results on both synthetic and real-world datasets.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Summarizing and Analyzing the Privacy-Preserving Techniques in Bitcoin and other Cryptocurrencies</title>
<link>https://arxiv.org/abs/2109.07634</link>
<guid>https://arxiv.org/abs/2109.07634</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、隐私保护算法、匿名性、攻击技术、法律与伦理

总结:
本文探讨了比特币和类似加密货币在隐私保护方面的挑战及其解决方案。首先，文章概述了比特币以及其它加密货币如何通过分散化和伪匿名性特征来实现去中心化的交易记录。然而，尽管比特币声称提供了伪匿名用户身份，但多次成功地将用户匿名性破解的攻击表明，实际隐私保护存在漏洞。

接着，文章分析了几种已知的攻击技术，这些技术利用特定策略和数据挖掘方法来揭示用户的实际身份。同时，文章也探讨了隐私保护算法，这些算法旨在解决协议中存在的隐私问题，如增强用户数据的加密、混淆交易路径等。通过这些技术，可以显著提高加密货币系统的隐私性，使得追踪和识别用户变得困难。

最后，文章触及了隐私保护算法的伦理、社会影响、法律框架以及它们在市场上的接受度。讨论了在实施这些算法时需要平衡的多方面因素，包括对个人隐私的保护、对金融系统透明度的需求以及可能引发的法律问题。

综上所述，比特币和加密货币在隐私保护方面面临着复杂挑战，通过采用先进的隐私保护技术和深入理解其伦理、法律和社会影响，可以促进更安全、更私密的数字交易环境。 <div>
arXiv:2109.07634v3 Announce Type: replace 
Abstract: Bitcoin and many other similar Cryptocurrencies have been in existence for over a decade, prominently focusing on decentralized, pseudo-anonymous ledger-based transactions. Many protocol improvements and changes have resulted in new variants of Cryptocurrencies that are known for their peculiar characteristics. For instance, Storjcoin is a Proof-of-Storage-based Cryptocurrency that incentivizes its peers based on the amount of storage owned by them. Cryptocurrencies like Monero strive for user privacy by using privacy-centric cryptographic algorithms. While Cryptocurrencies strive to maintain peer transparency by making the transactions and the entire ledger public, user privacy is compromised at times. Monero and many other privacy-centric Cryptocurrencies have significantly improved from the original Bitcoin protocol after several problems were found in the protocol. Most of these deficiencies were related to the privacy of users. Even though Bitcoin claims to have pseudo-anonymous user identities, many attacks have managed to successfully de-anonymize users. In this paper, we present some well-known attacks and analysis techniques that have compromised the privacy of Bitcoin and many other similar Cryptocurrencies. We also analyze and study different privacy-preserving algorithms and the problems these algorithms manage to solve. Lastly, we touch upon the ethics, impact, legality, and acceptance of imposing these privacy algorithms.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game of Coding: Beyond Honest-Majority Assumptions</title>
<link>https://arxiv.org/abs/2401.16643</link>
<guid>https://arxiv.org/abs/2401.16643</guid>
<content:encoded><![CDATA[
<div> 关键词：编码理论、游戏论、区块链、数据恢复、激励设计

<br />
<br />
总结:本文提出了一种新颖的游戏理论框架——“编码游戏”，用于探索在分布式系统中，特别是在区块链相关应用中，编码技术如何在信任不足的情况下，通过博弈论的方法优化编码策略以实现更高效的数据保护与恢复。文章首先指出了传统编码理论对节点数量的假设在现实世界中的局限性，尤其是在区块链等去中心化平台中，这种假设往往不成立。接着，文章引入了编码游戏中敌手和数据收集者（解码器）之间的互动，其中敌手在数据可恢复给数据收集者时受益，并且偏好于提高数据恢复的错误率，以此来最大化自己的收益。

文章的主要贡献在于，对于重复编码（repetition code）和特定类别的效用函数，研究并确定了编码游戏的均衡状态。这为理解在敌手和数据收集者之间的博弈关系下，如何设计有效的编码策略提供了一个基础模型。该模型不仅考虑了数据完整性和恢复效率，还考虑了参与方的激励机制，旨在找到最优策略以平衡数据安全与效率。此外，这一研究为未来在分布式系统中进一步发展更为复杂的编码策略提供了理论基础，有望在区块链等领域实现更安全、更高效的数字资产管理和数据存储解决方案。 <div>
arXiv:2401.16643v5 Announce Type: replace 
Abstract: Coding theory revolves around the incorporation of redundancy into transmitted symbols, computation tasks, and stored data to guard against adversarial manipulation. However, error correction in coding theory is contingent upon a strict trust assumption. In the context of computation and storage, it is required that honest nodes outnumber adversarial ones by a certain margin. However, in several emerging real-world cases, particularly, in decentralized blockchain-oriented applications, such assumptions are often unrealistic. Consequently, despite the important role of coding in addressing significant challenges within decentralized systems, its applications become constrained. Still, in decentralized platforms, a distinctive characteristic emerges, offering new avenues for secure coding beyond the constraints of conventional methods. In these scenarios, the adversary benefits when the legitimate decoder recovers the data, and preferably with a high estimation error. This incentive motivates them to act rationally, trying to maximize their gains. In this paper, we propose a game theoretic formulation for coding, called the game of coding, that captures this unique dynamic where each of the adversaries and the data collector (decoder) have respective utility functions to optimize. The utility functions reflect the fact that both the data collector and the adversary are interested in increasing the chance of data being recoverable by the data collector. Moreover, the utility functions express the interest of the data collector to estimate the input with lower estimation error, but the opposite interest of the adversary. As a first, still highly non-trivial step, we characterize the equilibrium of the game for the repetition code with a repetition factor of 2 for a wide class of utility functions with minimal assumptions.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resilient Fleet Management for Energy-Aware Intra-Factory Logistics</title>
<link>https://arxiv.org/abs/2403.11034</link>
<guid>https://arxiv.org/abs/2403.11034</guid>
<content:encoded><![CDATA[
<div> 关键词：电池供电机器人、工厂物流、中央管理策略、蒙特卡洛树搜索、实时更新

<br />
总结:本文提出了一种针对电池供电机器人队列的创新管理策略，这些机器人负责自主制造设施内的内部物流任务。面对诸如道路堵塞和设备故障等实际不确定性，该策略通过中央管理方式增强系统的韧性，实现任务分配的即时调整。为解决计算成本问题，作者提出了两步法，首先使用蒙特卡洛树搜索算法预先解决理想状态下的任务分配问题，生成一个预先搜索树。当发生中断时，该预先搜索树能够快速更新以反映新问题的成本，并同时产生可行解决方案。通过计算实验，证明了所提算法在各种场景下的实时能力，并与未使用预先搜索树和不尝试重新分配任务的分散式方法进行了比较。这种方法不仅提高了系统响应中断的灵活性，还优化了资源利用效率，展现出在复杂动态环境中的适应性和有效性。 <div>
arXiv:2403.11034v2 Announce Type: replace 
Abstract: This paper presents a novel fleet management strategy for battery-powered robot fleets tasked with intra-factory logistics in an autonomous manufacturing facility. In this environment, repetitive material handling operations are subject to real-world uncertainties such as blocked passages, and equipment or robot malfunctions. In such cases, centralized approaches enhance resilience by immediately adjusting the task allocation between the robots. To overcome the computational expense, a two-step methodology is proposed where the nominal problem is solved a priori using a Monte Carlo Tree Search algorithm for task allocation, resulting in a nominal search tree. When a disruption occurs, the nominal search tree is rapidly updated a posteriori with costs to the new problem while simultaneously generating feasible solutions. Computational experiments prove the real-time capability of the proposed algorithm for various scenarios and compare it with the case where the search tree is not used and the decentralized approach that does not attempt task reassignment.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralization of Ethereum's Builder Market</title>
<link>https://arxiv.org/abs/2405.01329</link>
<guid>https://arxiv.org/abs/2405.01329</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、分散性、以太坊、区块构建市场、验证者集中化

总结:

本文通过实证研究了以太坊区块链中分散性最低的部分——区块构建市场。区块构建市场旨在公平分配最大可提取价值（MEV）并避免验证者集中化。然而，当前数据显示，仅有三个构建者主导了大部分区块生成，集中度超过80%，这一现象引发了对集中化的担忧。尽管社区认为这种集中不会导致验证者集中化，但研究挑战了这一观点。

主要发现表明，区块构建者的集中导致了验证者的利益损失，并可能进一步促进验证者的集中化。此外，旨在缓解MEV问题的即将实施解决方案也会受到影响，因为它们依赖于区块构建市场作为MEV的参考，而市场因集中化而失真。

研究揭示了区块构建者集中化的两个主要原因，并提出了一种对现有MEV供应链的结构改变和基于新结构的解决方案。然而，长期可持续性分析仍是一个开放课题，需要未来的研究来探讨新供应链结构是否能持续稳定。 <div>
arXiv:2405.01329v3 Announce Type: replace 
Abstract: Blockchains protect an ecosystem worth more than $500bn with strong security properties derived from the principle of decentralization. Is today's blockchain decentralized? In this paper, we empirically studied one of the least decentralized parts of Ethereum, its builder market.
  The builder market was introduced to fairly distribute Maximal Extractable Values (MEV) among validators and avoid validator centralization. As of the time of writing, three builders produced the vast majority (more than 80%) of blocks in Ethereum, creating a concerning centralization factor. However, the community believes that such centralization is okay, arguing that builder centralization will not lead to validator centralization. In this empirical study, we interrogate the causes and implications of builder centralization and challenge this belief that it is acceptable.
  Our main finding is that builder centralization has led to a significant loss by validators and, if left uncontrolled, could lead to validator centralization. Moreover, MEV mitigation solutions slated for adoption are affected too because they rely on the builder market as an MEV oracle, which is made inaccurate by centralization.
  Our investigation revealed two reasons behind builder centralization. We propose a structural change to the existing MEV supply chain and a solution based on the new supply chain structure. However, future work is required to analyze if the new supply chain structure is sustainable in the long term, which we leave open.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Socially Acceptable Competitive Equilibrium in Energy Markets</title>
<link>https://arxiv.org/abs/2409.04157</link>
<guid>https://arxiv.org/abs/2409.04157</guid>
<content:encoded><![CDATA[
<div> 关键词：价格接受者、分散式主对偶梯度动态、竞争均衡、社会可接受的均衡、动态反馈控制器

总结:

本文探讨了在价格接受者群体中通过分散式主对偶梯度动力学寻找竞争均衡（CE）的问题。尽管CE具有高效性，但它可能不保证公平性，并可能导致高价格。鉴于代理和市场运营商的社会责任是保持价格低于某个社会可接受的阈值，文章提出了一种方法，即代理通过分散的方式修改其效用函数。为此，引入了一个动态反馈控制器来引导代理向社会可接受的竞争均衡（SCE）移动。通过理论分析和案例研究，文章证明了这种方法的有效性，从而确保了均衡既高效又公平。这一解决方案强调了在市场机制中融入社会价值的重要性，以促进更广泛的经济和社会福祉。 <div>
arXiv:2409.04157v1 Announce Type: new 
Abstract: This paper addresses the problem of energy sharing between a population of price-taking agents who adopt decentralized primal-dual gradient dynamics to find the Competitive Equilibrium (CE). Although the CE is efficient, it does not ensure fairness and can potentially lead to high prices. As the agents and market operator share a social responsibility to keep the price below a certain socially acceptable threshold, we propose an approach where the agents modify their utility functions in a decentralized way. We introduce a dynamic feedback controller for the primal-dual dynamics to steer the agents to a Socially acceptable Competitive Equilibrium (SCE). We demonstrate our theoretical findings in a case study.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 00:00:00 -0400</pubDate>
</item>
</channel>
</rss>