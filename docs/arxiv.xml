<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>

<item>
<title>Decentralized and Robust Privacy-Preserving Model Using Blockchain-Enabled Federated Deep Learning in Intelligent Enterprises</title>
<link>https://arxiv.org/abs/2502.17485</link>
<guid>https://arxiv.org/abs/2502.17485</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Deep Learning (FDL)，非独立同分布 (nonIID)，FedAnil，区块链，安全隐私

总结:
本文提出了一种名为FedAnil的安全、基于区块链的联邦深度学习模型，旨在解决非独立同分布数据导致的学习性能下降以及联邦学习中的安全和隐私问题。FedAnil分为两个主要阶段，第一阶段针对数据标签和特征分布偏斜的非IID挑战，第二阶段通过三个步骤防止中毒和推理攻击。实验结果表明，FedAnil满足了FDL的隐私保护要求，其模型参数收敛于最优解，并在准确率（提升超过11%，15%和24%）和计算开销（降低小于8%，10%和15%）方面优于基线方法ShieldFL、RVPFL和RFA。 <div>
arXiv:2502.17485v1 Announce Type: new 
Abstract: In Federated Deep Learning (FDL), multiple local enterprises are allowed to train a model jointly. Then, they submit their local updates to the central server, and the server aggregates the updates to create a global model. However, trained models usually perform worse than centralized models, especially when the training data distribution is non-independent and identically distributed (nonIID). NonIID data harms the accuracy and performance of the model. Additionally, due to the centrality of federated learning (FL) and the untrustworthiness of enterprises, traditional FL solutions are vulnerable to security and privacy attacks. To tackle this issue, we propose FedAnil, a secure blockchain enabled Federated Deep Learning Model that improves enterprise models decentralization, performance, and tamper proof properties, incorporating two main phases. The first phase addresses the nonIID challenge (label and feature distribution skew). The second phase addresses security and privacy concerns against poisoning and inference attacks through three steps. Extensive experiments were conducted using the Sent140, FashionMNIST, FEMNIST, and CIFAR10 new real world datasets to evaluate FedAnils robustness and performance. The simulation results demonstrate that FedAnil satisfies FDL privacy preserving requirements. In terms of convergence analysis, the model parameter obtained with FedAnil converges to the optimum of the model parameter. In addition, it performs better in terms of accuracy (more than 11, 15, and 24%) and computation overhead (less than 8, 10, and 15%) compared with baseline approaches, namely ShieldFL, RVPFL, and RFA.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Weaving the Cosmos: WASM-Powered Interchain Communication for AI Enabled Smart Contracts</title>
<link>https://arxiv.org/abs/2502.17604</link>
<guid>https://arxiv.org/abs/2502.17604</guid>
<content:encoded><![CDATA[
<div> 关键词: AI/LLMs, MLOps, 区块链技术, Cosmos SDK, WebAssembly (WASM)

<br><br>总结:

本文介绍了一种创新框架，该框架将区块链技术（特别是Cosmos SDK）与AI/大型语言模型集成，以实现链上AI推理。该系统基于WebAssembly (WASM)，支持跨多个区块链节点进行AI推理模块的部署和互操作性。文章着重评估了该框架在可行性、可扩展性以及模型安全性方面的表现，同时关注其移植性和引擎-模型无关的部署特性。通过支持链上AI，这一框架有望扩展智能合约的功能范围，催生新的应用场景和用例。 <div>
arXiv:2502.17604v1 Announce Type: new 
Abstract: In this era, significant transformations in industries and tool utilization are driven by AI/Large Language Models (LLMs) and advancements in Machine Learning. There's a growing emphasis on Machine Learning Operations(MLOps) for managing and deploying these AI models. Concurrently, the imperative for richer smart contracts and on-chain computation is escalating. Our paper introduces an innovative framework that integrates blockchain technology, particularly the Cosmos SDK, to facilitate on-chain AI inferences. This system, built on WebAssembly (WASM), enables interchain communication and deployment of WASM modules executing AI inferences across multiple blockchain nodes. We critically assess the framework from feasibility, scalability, and model security, with a special focus on its portability and engine-model agnostic deployment. The capability to support AI on-chain may enhance and expand the scope of smart contracts, and as a result enable new use cases and applications.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Decentralized Swarms Using Rotation Equivariant Graph Neural Networks</title>
<link>https://arxiv.org/abs/2502.17612</link>
<guid>https://arxiv.org/abs/2502.17612</guid>
<content:encoded><![CDATA[
<div> 关键词: Graph Neural Network (GNN), 分布式控制器设计, 群集行为, 对称性约束, 优化

总结:
本文提出了一种针对分布式群集控制问题的新方法，特别关注于改进基于图神经网络（GNN）的分布式飞行队列（flocking）控制器。研究表明，尽管GNN已经在维持飞行队列凝聚方面取得进展，但它们并未充分利用群集动力学中的旋转等变性和平移不变性对称性。为此，文章中作者强制在分布式飞行队列GNN控制器中引入了这些对称性约束，从而实现了使用70%更少的训练数据和75%更少的可训练权重的情况下达到与现有无对称性约束的GNN控制器相当的飞行队列控制效果。此外，还表明这种考虑对称性的控制器比现有的GNN控制器具有更好的泛化能力。相关代码和动画已在http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers上提供。 <div>
arXiv:2502.17612v1 Announce Type: new 
Abstract: The orchestration of agents to optimize a collective objective without centralized control is challenging yet crucial for applications such as controlling autonomous fleets, and surveillance and reconnaissance using sensor networks. Decentralized controller design has been inspired by self-organization found in nature, with a prominent source of inspiration being flocking; however, decentralized controllers struggle to maintain flock cohesion. The graph neural network (GNN) architecture has emerged as an indispensable machine learning tool for developing decentralized controllers capable of maintaining flock cohesion, but they fail to exploit the symmetries present in flocking dynamics, hindering their generalizability. We enforce rotation equivariance and translation invariance symmetries in decentralized flocking GNN controllers and achieve comparable flocking control with 70% less training data and 75% fewer trainable weights than existing GNN controllers without these symmetries enforced. We also show that our symmetry-aware controller generalizes better than existing GNN controllers. Code and animations are available at http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Robust Federated Learning with Global Sensitivity Estimation for Financial Risk Management</title>
<link>https://arxiv.org/abs/2502.17694</link>
<guid>https://arxiv.org/abs/2502.17694</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning，FRAL-CSE，中央敏感度估计，风险测量，异构数据集

总结:
<br>
本文提出了一种用于分散式金融系统的新型联邦学习框架——Federated Risk-Aware Learning with Central Sensitivity Estimation (FRAL-CSE)。该框架旨在增强分布式金融决策中的可扩展性、稳定性和鲁棒性。核心创新在于采用基于二次敏感度的大局模型动态近似值的中心加速机制，利用从稳健的风险测量中获得的局部敏感信息进行曲率引导的全局更新，从而提高训练效率并优化优化稳定性。同时，将扭曲风险度量嵌入到训练目标中，以捕捉尾部风险并确保系统对极端场景的鲁棒性。通过广泛的实验验证了FRAL-CSE相比于现有最优基线在加快收敛速度和提高异构数据集上的韧性方面所具有的有效性。 <div>
arXiv:2502.17694v1 Announce Type: new 
Abstract: In decentralized financial systems, robust and efficient Federated Learning (FL) is promising to handle diverse client environments and ensure resilience to systemic risks. We propose Federated Risk-Aware Learning with Central Sensitivity Estimation (FRAL-CSE), an innovative FL framework designed to enhance scalability, stability, and robustness in collaborative financial decision-making. The framework's core innovation lies in a central acceleration mechanism, guided by a quadratic sensitivity-based approximation of global model dynamics. By leveraging local sensitivity information derived from robust risk measurements, FRAL-CSE performs a curvature-informed global update that efficiently incorporates second-order information without requiring repeated local re-evaluations, thereby enhancing training efficiency and improving optimization stability. Additionally, distortion risk measures are embedded into the training objectives to capture tail risks and ensure robustness against extreme scenarios. Extensive experiments validate the effectiveness of FRAL-CSE in accelerating convergence and improving resilience across heterogeneous datasets compared to state-of-the-art baselines.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinP: Fairness-in-Privacy in Federated Learning by Addressing Disparities in Privacy Risk</title>
<link>https://arxiv.org/abs/2502.17748</link>
<guid>https://arxiv.org/abs/2502.17748</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习公平性、隐私保护、联邦学习、FinP、源推断攻击

<br><br>总结:
本文提出了一种名为FinP的框架，旨在解决联邦学习中的隐私公平问题，确保在分布式数据环境下平衡各客户端的隐私风险。FinP通过双重策略实现目标：(1)服务器端自适应聚合，以解决全局模型中客户端贡献的不公平性；(2)客户端侧的正则化，降低客户端遭受源推断攻击的脆弱性。实现在Human Activity Recognition (HAR)和CIFAR-10数据集上的评估结果显示，FinP在HAR上实现了约20%的隐私公平性提升，同时对模型效能影响轻微，并在CIFAR-10数据集上有效地缓解了源推断攻击的风险，证明了其在不损害性能的前提下为联邦学习系统提供隐私公平性的能力。 <div>
arXiv:2502.17748v1 Announce Type: new 
Abstract: Ensuring fairness in machine learning, particularly in human-centric applications, extends beyond algorithmic bias to encompass fairness in privacy, specifically the equitable distribution of privacy risk. This is critical in federated learning (FL), where decentralized data necessitates balanced privacy preservation across clients. We introduce FinP, a framework designed to achieve fairness in privacy by mitigating disproportionate exposure to source inference attacks (SIA). FinP employs a dual approach: (1) server-side adaptive aggregation to address unfairness in client contributions in global model, and (2) client-side regularization to reduce client vulnerability. This comprehensive strategy targets both the symptoms and root causes of privacy unfairness. Evaluated on the Human Activity Recognition (HAR) and CIFAR-10 datasets, FinP demonstrates ~20% improvement in fairness in privacy on HAR with minimal impact on model utility, and effectively mitigates SIA risks on CIFAR-10, showcasing its ability to provide fairness in privacy in FL systems without compromising performance.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FediverseSharing: A Novel Dataset on Cross-Platform Interaction Dynamics between Threads and Mastodon Users</title>
<link>https://arxiv.org/abs/2502.17926</link>
<guid>https://arxiv.org/abs/2502.17926</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交媒体平台、Mastodon、Threads、ActivityPub、FediverseSharing

总结:<br>
随着Twitter被收购并引发政策变化，用户开始转向Mastodon和Threads等替代社交平台。为解决平台碎片化问题，Mastodon采用了去中心化的联邦协议ActivityPub，并在2024年3月，Threads推出了Fediverse Sharing服务，实现了与Mastodon之间的互动，如统一平台般发帖、回复和点赞。基于这一发展，研究者构建了FediverseSharing数据集，记录了超过20,000名Threads用户和20,000名Mastodon用户在十个月间的跨平台交互情况。这个数据集为研究两个先前独立平台整合后的影响以及跨平台交互提供了基础。 <div>
arXiv:2502.17926v1 Announce Type: new 
Abstract: Traditional social media platforms, once envisioned as digital town squares, face growing criticism over corporate control, content moderation, and privacy concerns. Events such as Twitter's acquisition(now X) and major policy changes have driven users toward alternative platforms like Mastodon and Threads. However, this diversification has led to user dispersion and fragmented discussions across isolated social media platforms. To address these issues, federation protocols like ActivityPub have been adopted, with Mastodon leading efforts to build decentralized yet interconnected networks. In March 2024, Threads joined this federation by introducing its Fediverse Sharing service, which enables interactions such as posts, replies, and likes between Threads and Mastodon users as if on a unified platform. Building on this development, we introduce FediverseSharing, the first dataset capturing interactions between 20,000+ Threads users and 20,000+ Mastodon users over a ten-month period. This dataset serves as a foundation for studying cross-platform interactions and the impact of federation as previously two separate platforms integrate.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Built-In Robustness of Decentralized Federated Averaging to Bad Data</title>
<link>https://arxiv.org/abs/2502.18097</link>
<guid>https://arxiv.org/abs/2502.18097</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化联邦学习（DFL）、数据质量、错误检测、分布式训练、模型传播

总结:
<br>
本文探讨了在没有中央控制器的去中心化联邦学习（DFL）环境下，低质量或损坏的数据对系统的影响。研究通过在Decentralized FedAvg实现中模拟两种数据质量下降的情景来进行分析：一是数据损坏均匀分布于部分节点，二是集中在单个节点上。实验结果显示，基于平均值的去中心化学习对局部坏数据具有很强的鲁棒性，即使损坏数据位于网络中最具影响力的节点也是如此。更令人意外的是，当损坏数据集中在一个节点时，无论该节点在网络通信拓扑中的中心程度如何，系统的鲁棒性都会进一步增强。这一现象的原因在于平均化过程确保了没有任何一个单一节点能过大地影响整体学习进程。 <div>
arXiv:2502.18097v1 Announce Type: new 
Abstract: Decentralized federated learning (DFL) enables devices to collaboratively train models over complex network topologies without relying on a central controller. In this setting, local data remains private, but its quality and quantity can vary significantly across nodes. The extent to which a fully decentralized system is vulnerable to poor-quality or corrupted data remains unclear, but several factors could contribute to potential risks. Without a central authority, there can be no unified mechanism to detect or correct errors, and each node operates with a localized view of the data distribution, making it difficult for the node to assess whether its perspective aligns with the true distribution. Moreover, models trained on low-quality data can propagate through the network, amplifying errors. To explore the impact of low-quality data on DFL, we simulate two scenarios with degraded data quality -- one where the corrupted data is evenly distributed in a subset of nodes and one where it is concentrated on a single node -- using a decentralized implementation of FedAvg. Our results reveal that averaging-based decentralized learning is remarkably robust to localized bad data, even when the corrupted data resides in the most influential nodes of the network. Counterintuitively, this robustness is further enhanced when the corrupted data is concentrated on a single node, regardless of its centrality in the communication network topology. This phenomenon is explained by the averaging process, which ensures that no single node -- however central -- can disproportionately influence the overall learning process.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>iTrash: Incentivized Token Rewards for Automated Sorting and Handling</title>
<link>https://arxiv.org/abs/2502.18161</link>
<guid>https://arxiv.org/abs/2502.18161</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器人系统、智能垃圾桶、回收率、行为分析、区块链技术

总结:<br>
本文提出了一种名为iTrash的智能垃圾桶，旨在提高小型办公室空间的回收率。通过为期5天的实验，研究发现iTrash相比于传统垃圾桶能实现超过30%的效率提升。此外，使用iTrash不仅能增加回收率，还能收集到如用户行为和垃圾桶使用模式等有价值的数据，这些数据可用于预测和优化此类空间中的某些任务。最后，文章探讨了利用区块链技术创建基于“按量付费”（SAYT）模型的经济激励机制，以进一步推动垃圾分类与回收。 <div>
arXiv:2502.18161v1 Announce Type: new 
Abstract: As robotic systems (RS) become more autonomous, they are becoming increasingly used in small spaces and offices to automate tasks such as cleaning, infrastructure maintenance, or resource management. In this paper, we propose iTrash, an intelligent trashcan that aims to improve recycling rates in small office spaces. For that, we ran a 5 day experiment and found that iTrash can produce an efficiency increase of more than 30% compared to traditional trashcans. The findings derived from this work, point to the fact that using iTrash not only increase recyclying rates, but also provides valuable data such as users behaviour or bin usage patterns, which cannot be taken from a normal trashcan. This information can be used to predict and optimize some tasks in these spaces. Finally, we explored the potential of using blockchain technology to create economic incentives for recycling, following a Save-as-you-Throw (SAYT) model.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MulChain: Enabling Advanced Cross-Modal Queries in Hybrid-Storage Blockchains</title>
<link>https://arxiv.org/abs/2502.18258</link>
<guid>https://arxiv.org/abs/2502.18258</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、多模态数据、查询、存储效率、MulChain

总结:
<br>
本文针对区块链技术在多模态数据管理和查询方面面临的挑战进行讨论，提出了三个主要问题：高效的索引方法设计以适应频繁的插入和查询操作需求；在不改变现有基础设施的前提下与区块链系统的无缝集成；在保证高查询性能的同时降低 gas 消耗。为解决这些问题，文章提出了一种名为 MulChain 的新型中间件架构。MulChain 的核心是 BHashTree 数据结构，它可以根据工作负载特性动态地在树节点和哈希节点之间切换，从而确保插入和查询操作的效率。此外，该中间件还提供了标准化接口，实现了不同区块链平台间的查询方法统一化。 <div>
arXiv:2502.18258v1 Announce Type: new 
Abstract: With its decentralization and immutability, blockchain has emerged as a trusted foundation for data management and querying. Because blockchain storage space is limited, large multimodal data files, such as videos, are often stored offline, leaving only lightweight metadata on the chain. While this hybrid storage approach enhances storage efficiency, it introduces significant challenges for executing advanced queries on multimodal data. The metadata stored on-chain is often minimal and may not include all the attributes necessary for queries like time range or fuzzy queries. In addition, existing blockchains do not provide native support for multimodal data querying. Achieving this capability would necessitate extensive modifications to the underlying blockchain framework, even reconstructing its core architecture. Consequently, enabling blockchains with multimodal query capabilities remains a significant problem, which necessitates overcoming the following three key challenges: (1) Designing efficient indexing methods to adapt to varying workloads that involve frequent insertions and query operations; (2) Achieving seamless integration with existing blockchains without altering the underlying infrastructure; (3) Ensuring high query performance while minimizing gas consumption. To address these challenges, we propose MulChain, a novel middleware architecture to enable smooth integration with existing blockchains. At the core of MulChain is the BHashTree, a flexible data structure that dynamically switches between tree and hash nodes based on workload characteristics, ensuring efficient insertion and query operations. Furthermore, the middleware provides standardized interfaces for blockchain systems, unifying query methods across different platforms.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DCentNet: Decentralized Multistage Biomedical Signal Classification using Early Exits</title>
<link>https://arxiv.org/abs/2502.17446</link>
<guid>https://arxiv.org/abs/2502.17446</guid>
<content:encoded><![CDATA[
<div> 关键词: DCentNet、物联网可穿戴传感器、早期退出点、能源效率、信号分类

总结:
DCentNet是一个针对物联网可穿戴传感器生成的生物医学数据设计的新型去中心化多阶段信号分类方法。该方法通过集成早期退出点(EEP)，提高了能源效率和处理速度。与传统的集中式处理方法相比，DCentNet将单一CNN模型划分为多个子网络，并利用EEP压缩大尺寸特征图以减少无线数据传输和功耗。当输入在EEP处被自信地分类后，处理会提前停止，从而优化效率。初期子网络可以部署在雾计算或边缘设备上，进一步降低能耗。通过遗传算法优化EEP的放置位置，以平衡性能和复杂性。实验结果显示，在ECG分类任务中，使用一个EEP时，DCentNet能降低94.54%的无线数据传输量，减少21%的复杂度，同时保持原有的准确性和敏感性。使用两个EEP时，敏感性达到98.36%，准确性为97.74%，无线数据传输下降了91.86%，复杂度减少了22%。当在ARM Cortex-M4微控制器上实现时，相较于持续无线ECG传输，DCentNet实现了平均73.6%的功耗节省。 <div>
arXiv:2502.17446v1 Announce Type: cross 
Abstract: DCentNet is a novel decentralized multistage signal classification approach designed for biomedical data from IoT wearable sensors, integrating early exit points (EEP) to enhance energy efficiency and processing speed. Unlike traditional centralized processing methods, which result in high energy consumption and latency, DCentNet partitions a single CNN model into multiple sub-networks using EEPs. By introducing encoder-decoder pairs at EEPs, the system compresses large feature maps before transmission, significantly reducing wireless data transfer and power usage. If an input is confidently classified at an EEP, processing stops early, optimizing efficiency. Initial sub-networks can be deployed on fog or edge devices to further minimize energy consumption. A genetic algorithm is used to optimize EEP placement, balancing performance and complexity. Experimental results on ECG classification show that with one EEP, DCentNet reduces wireless data transmission by 94.54% and complexity by 21%, while maintaining original accuracy and sensitivity. With two EEPs, sensitivity reaches 98.36%, accuracy 97.74%, wireless data transmission decreases by 91.86%, and complexity is reduced by 22%. Implemented on an ARM Cortex-M4 MCU, DCentNet achieves an average power saving of 73.6% compared to continuous wireless ECG transmission.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Channel Currency: A Secure Method Using Semi-Quantum Tokens</title>
<link>https://arxiv.org/abs/2502.18378</link>
<guid>https://arxiv.org/abs/2502.18378</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字货币、离线交易、双花风险、量子态、区块链

总结:
本文提出了一种基于量子状态的新型数字货币系统，该系统利用非克隆定理实现安全的、无双花风险的多渠道线下交易。实验结果验证了系统的实施效果，包括货币转账和交换的使用案例。为了解决交换过程中的信用风险，文中还将区块链技术进行整合以展示其广泛应用潜力。这一方法为构建量子安全的数字货币开辟了新途径，并为优化多渠道代币提供了新的可能性。 <div>
arXiv:2502.18378v1 Announce Type: cross 
Abstract: Digital currencies primarily operate online, but there is growing interest in enabling offline transactions to improve digital inclusion. Existing offline methods struggle with double-spending risks, often limiting transaction amounts. In this work, we propose a quantum-state-based currency system that uses the non-cloning theorem to enable secure, multi-channel transactions without the risk of double spending. We demonstrate this system's implementation with experimental results, including use cases for currency transfers and swaps. To mitigate credit risks in swaps, we also integrate blockchain to show its wide applicability. Our approach paves the way for quantum-secure digital currencies and opens new possibilities for optimizing multi-channel tokens.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Orchestrated Robust Controller for Precision Control of Heavy-duty Hydraulic Manipulators</title>
<link>https://arxiv.org/abs/2312.06304</link>
<guid>https://arxiv.org/abs/2312.06304</guid>
<content:encoded><![CDATA[
<div> 关键词：重型液压操纵器、自动控制、虚拟分解控制（VDC）、径向基函数神经网络（RBFNN）、 decentralized RBFNN、高精度控制

总结:
本文针对具有类人臂和球形手腕的重型液压操纵器的自动化需求，设计了一种集成的鲁棒控制器。研究中采用了虚拟分解控制（VDC）技术，将整个机器人系统分解为子系统，并针对每个局部子系统设计了考虑未知模型不确定性、未知扰动及复合输入非线性的鲁棒控制器。通过引入径向基函数神经网络（RBFNN），在VDC框架下提出了新颖的分布式RBFNN控制器，实现对不确定性和扰动的处理。最终，设计的控制器首次在VDC领域实现了半全局一致终极有界性。理论结果通过在一款具有6自由度、额定起吊能力为600公斤、工作半径达5米的工业操纵器上进行的详尽仿真和实验得到了验证。与现有最先进的控制器对比以及提供的实验结果表明，所提方法充分兑现了其承诺并表现出色。 <div>
arXiv:2312.06304v4 Announce Type: replace 
Abstract: Vast industrial investment along with increased academic research on heavy-duty hydraulic manipulators has unavoidably paved the way for their automatization, necessitating the design of robust and high-precision controllers. In this study, an orchestrated robust controller is designed to address the mentioned issue for generic manipulators with an anthropomorphic arm and spherical wrist. Thanks to virtual decomposition control (VDC), the entire robotic system is decomposed into subsystems, and a robust controller is designed at each local subsystem by considering unknown model uncertainties, unknown disturbances, and compound input nonlinearities. As such, radial basic function neural networks (RBFNNs) are incorporated into VDC to tackle unknown disturbances and uncertainties, resulting in novel decentralized RBFNNs. All robust local controllers designed at each local subsystem, then, are orchestrated to accomplish high-precision control. In the end, for the first time in the context of VDC, a semi-globally uniformly ultimate boundedness is achieved under the designed controller. The validity of the theoretical results is verified by performing extensive simulations and experiments on a 6-degrees-of-freedom industrial manipulator with a nominal lifting capacity of 600 kg at 5 meters reach. Comparing the simulation result to the state-of-the-art controller along with provided experimental results, demonstrates that proposed method established all promises and performed excellently.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>

<item>
<title>Strengthening DeFi Security: A Static Analysis Approach to Flash Loan Vulnerabilities</title>
<link>https://arxiv.org/abs/2411.01230</link>
<guid>https://arxiv.org/abs/2411.01230</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance (DeFi), flash loans, security vulnerabilities, price manipulation attacks, FlashDeFier

总结:
随着去中心化金融(DeFi)的发展，其带来了新的金融机遇但也暴露出严重的安全漏洞，特别是闪贷常被用于价格操纵攻击。这类攻击利用闪贷的原子性来操纵DeFi协议中的预言机和定价机制，造成重大财务损失。现有的智能合约分析工具虽然能解决一些安全性问题，但往往难以检测到构成闪贷攻击挑战的复杂跨合约依赖关系。为了解决这一问题，本文提出了FlashDeFier，这是一个先进的检测框架，通过增强静态污点分析以针对由闪贷引发的价格操纵漏洞进行检测。FlashDeFier扩展了污点源和汇的范围，实现了对DeFi协议中跨合约数据流的全面分析，并构建详细的跨合约调用图以捕获复杂的数据流模式，显著提高了检测准确性。在对一组高知名度的DeFi事件数据集进行测试后，FlashDeFier成功识别出了76.4%的价格操纵漏洞，相较于DeFiTainter有30%的提升。这些结果强调了适应性检测框架的重要性，即需要与DeFi威胁一同演进，并凸显了为了实现坚韧的DeFi安全，需要结合静态、动态和符号分析方法的混合方法。 <div>
arXiv:2411.01230v2 Announce Type: replace 
Abstract: The rise of Decentralized Finance (DeFi) has brought novel financial opportunities but also exposed serious security vulnerabilities, with flash loans frequently exploited for price manipulation attacks. These attacks, leveraging the atomic nature of flash loans, allow malicious actors to manipulate DeFi protocol oracles and pricing mechanisms within a single transaction, causing substantial financial losses. Traditional smart contract analysis tools address some security risks but often struggle to detect the complex, inter-contract dependencies that make flash loan attacks challenging to identify.
  In response, we introduce FlashDeFier, an advanced detection framework that enhances static taint analysis to target price manipulation vulnerabilities arising from flash loans. FlashDeFier expands the scope of taint sources and sinks, enabling comprehensive analysis of data flows across DeFi protocols. The framework constructs detailed inter-contract call graphs to capture sophisticated data flow patterns, significantly improving detection accuracy. Tested against a dataset of high-profile DeFi incidents, FlashDeFier identifies 76.4% of price manipulation vulnerabilities, marking a 30% improvement over DeFiTainter. These results highlight the importance of adaptive detection frameworks that evolve alongside DeFi threats, underscoring the need for hybrid approaches combining static, dynamic, and symbolic analysis methods for resilient DeFi security.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UAV-assisted Internet of Vehicles: A Framework Empowered by Reinforcement Learning and Blockchain</title>
<link>https://arxiv.org/abs/2502.15713</link>
<guid>https://arxiv.org/abs/2502.15713</guid>
<content:encoded><![CDATA[
<div> 关键词: UAV-assisted IoV、relay selection、decentralized Multi-Agent Deep Reinforcement Learning (MDRL)、Blockchain、Proximal Policy Optimization (PPO)

总结:
本文针对UAV-assisted IoV（无人机辅助物联网）中的中继节点选择及协调问题进行研究。现有的中继选择机制存在执行可追溯性和中继间协调方式集中化的问题。为此，文章提出了一种融合强化学习和区块链技术的框架。该框架包括三部分：一是基于车辆和无人机双方偏好（QoU 和 QoV）的双侧无人机中继选择机制；二是采用去中心化的多智能体深度强化学习(MDRL)模型实现自主的无人机协调，以控制其移动并利用Proximal Policy Optimization (PPO)算法保持网络覆盖与连通性；三是通过区块链技术实现代替车辆与无人机之间互动的透明度和可追溯性。实验结果表明，所提的选择与协调机制能提升中继稳定性，并最大化无人机网络的覆盖与连通性。 <div>
arXiv:2502.15713v1 Announce Type: new 
Abstract: This paper addresses the challenges of selecting relay nodes and coordinating among them in UAV-assisted Internet-of-Vehicles (IoV). The selection of UAV relay nodes in IoV employs mechanisms executed either at centralized servers or decentralized nodes, which have two main limitations: 1) the traceability of the selection mechanism execution and 2) the coordination among the selected UAVs, which is currently offered in a centralized manner and is not coupled with the relay selection. Existing UAV coordination methods often rely on optimization methods, which are not adaptable to different environment complexities, or on centralized deep reinforcement learning, which lacks scalability in multi-UAV settings. Overall, there is a need for a comprehensive framework where relay selection and coordination are coupled and executed in a transparent and trusted manner. This work proposes a framework empowered by reinforcement learning and Blockchain for UAV-assisted IoV networks. It consists of three main components: a two-sided UAV relay selection mechanism for UAV-assisted IoV, a decentralized Multi-Agent Deep Reinforcement Learning (MDRL) model for autonomous UAV coordination, and a Blockchain implementation for transparency and traceability in the interactions between vehicles and UAVs. The relay selection considers the two-sided preferences of vehicles and UAVs based on the Quality-of-UAV (QoU) and the Quality-of-Vehicle (QoV). Upon selection of relay UAVs, the decentralized coordination between them is enabled through an MDRL model trained to control their mobility and maintain the network coverage and connectivity using Proximal Policy Optimization (PPO). The evaluation results demonstrate that the proposed selection and coordination mechanisms improve the stability of the selected relays and maximize the coverage and connectivity achieved by the UAVs.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Extended Pattern Collection for Blockchain-based Applications</title>
<link>https://arxiv.org/abs/2502.16017</link>
<guid>https://arxiv.org/abs/2502.16017</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、软件架构、设计模式、智能合约、应用类别

总结:<br />
本文探讨了作为新兴技术的区块链如何为分布式系统提供去中心化的架构支持，强调在区块链早期阶段系统性地组织相关知识以形成全面视角的重要性。文章提出了适用于区块链应用的设计模式列表，并将其分为五个类别：与外部世界的交互模式、数据管理模式、安全性模式、合同结构模式和用户交互模式。这些模式既考虑了区块链的本质特征及其在现实世界应用中的引入方式，也包含了针对区块链环境应用的现有设计模式变体。 <div>
arXiv:2502.16017v1 Announce Type: new 
Abstract: Blockchain is an emerging technology that enables new forms of decentralized software architectures, where distributed components can reach agreements on shared system states without trusting a central integration point. Blockchain provides a shared infrastructure to execute programs, called smart contracts, and to store data. Since blockchain technologies are at an early stage, there is a lack of a systematically organized knowledge providing a holistic view on designing software systems that use blockchain. We view blockchain as a component of a bigger software system, which requires patterns for using blockchain in the design of the software architecture. In this paper, we collect a list of patterns for blockchain-based applications. The pattern collection is categorized into five categories, including interaction with external world patterns, data management patterns, security patterns, structural patterns of contracts, and user interaction patterns. Some patterns are designed considering the nature of blockchain and how blockchains can be specifically introduced within real-world applications. Others are variants of existing design patterns applied in the context of blockchain-based applications and smart contracts.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack</title>
<link>https://arxiv.org/abs/2502.16086</link>
<guid>https://arxiv.org/abs/2502.16086</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized training, privacy leakage, activation inversion attack, large language models, security measures

<br /><br />总结:
本文研究了分布式训练中大型语言模型（LLMs）训练数据的隐私泄露风险，首次提出了“激活反演攻击”（AIA）。该攻击通过构建由公开数据集得到的影子数据集，训练模型从受害者分布式训练中的激活信息反推出原始训练数据。实验表明，在多种LLMs和公开数据集上，分布式训练对于AIA攻击非常脆弱。这揭示了在分布式训练中强化安全措施以降低LLM训练过程中的隐私风险的迫切性。 <div>
arXiv:2502.16086v1 Announce Type: new 
Abstract: Decentralized training has become a resource-efficient framework to democratize the training of large language models (LLMs). However, the privacy risks associated with this framework, particularly due to the potential inclusion of sensitive data in training datasets, remain unexplored. This paper identifies a novel and realistic attack surface: the privacy leakage from training data in decentralized training, and proposes \textit{activation inversion attack} (AIA) for the first time. AIA first constructs a shadow dataset comprising text labels and corresponding activations using public datasets. Leveraging this dataset, an attack model can be trained to reconstruct the training data from activations in victim decentralized training. We conduct extensive experiments on various LLMs and publicly available datasets to demonstrate the susceptibility of decentralized training to AIA. These findings highlight the urgent need to enhance security measures in decentralized training to mitigate privacy risks in training LLMs.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A New Era of Elections: Leveraging Blockchain for Fair and Transparent Voting</title>
<link>https://arxiv.org/abs/2502.16127</link>
<guid>https://arxiv.org/abs/2502.16127</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、投票系统、选举安全、身份验证、共识机制

<br /><br />总结:

本文提出了一种基于区块链的投票系统，旨在增强选举的安全性、透明度和诚信。该系统通过将区块链不可篡改、去中心化的特性与先进的选民身份验证技术（如利用BLAKE2b-512哈希算法进行的Aadhaar和驾照数字身份验证、生物特征指纹认证以及图像旋转模式等）相结合，确保了投票过程的透明且安全记录。采用共识机制保证数据完整性并降低未经授权修改的风险。安全分析表明，这种多层防护方法显著降低了冒名顶替风险，同时区块链技术确保了投票记录的准确、私密及防篡改。研究结果显示，具有严格身份验证的区块链投票系统为传统投票方法提供了一个值得信赖的替代方案，并为进一步提升安全、透明的选举提供了可能性。 <div>
arXiv:2502.16127v1 Announce Type: new 
Abstract: This study presents a blockchain-based voting system aimed at enhancing election security, transparency, and integrity. Traditional voting methods face growing risks of tampering, making it crucial to explore innovative solutions. Our proposed system combines blockchain's immutable, decentralized ledger with advanced voter identity verification techniques, including digital identity validation through Aadhaar and Driving Licenses (secured via BLAKE2b-512 hashing), biometric fingerprint authentication, and a picture rotation pattern for added security. Votes are recorded transparently and securely on a blockchain, with a consensus mechanism ensuring data integrity and reducing the risk of unauthorized alterations. Security analysis indicates that this multi-layered approach significantly reduces impersonation risks, while blockchain ensures accurate, private, and tamper-resistant vote recording. The findings support that a blockchain-based voting system with robust identity checks offers a trustworthy alternative to traditional methods, with potential for even greater refinement in secure and transparent elections.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Heterogeneous Multi-Agent Bandits with Parsimonious Hints</title>
<link>https://arxiv.org/abs/2502.16128</link>
<guid>https://arxiv.org/abs/2502.16128</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体多臂老虎机问题、提示、异构、中心化、分布式

总结:
该文研究了一个带有提示的异构多智能体多臂老虎机问题（HMA2B），其中智能体可以查询低成本的观察值（提示）以及拉取手臂。在这个框架下，每个智能体在K条手臂上具有独特的奖励分布，在T轮中，只有当没有其他智能体拉取某条手臂时，他们才能观测到该手臂的奖励。目标是在最小化必要的提示查询次数的同时最大化总效用，实现与时间无关的遗憾值。文章分别在中心化和分布式场景下研究了HMA2B问题。提出的中心化算法GP-HCLA是对HCLA的扩展，通过中央决策者进行手臂拉取和提示查询，实现了$O(M^4K)$的遗憾值和$O(MK\log T)$的自适应提示。而在分布式设置中，提出了两种允许智能体独立选择行动并通过冲突式通信查询提示直至停止的算法HD-ETC和EBHD-ETC，它们分别达到$O(M^3K^2)$的遗憾值和$O(M^3K\log T)$的提示，其中前者需要知道最小间隙，后者则不需要。最后，文中还建立了下界以证明结果的最优性，并通过数值模拟进行了验证。 <div>
arXiv:2502.16128v1 Announce Type: new 
Abstract: We study a hinted heterogeneous multi-agent multi-armed bandits problem (HMA2B), where agents can query low-cost observations (hints) in addition to pulling arms. In this framework, each of the $M$ agents has a unique reward distribution over $K$ arms, and in $T$ rounds, they can observe the reward of the arm they pull only if no other agent pulls that arm. The goal is to maximize the total utility by querying the minimal necessary hints without pulling arms, achieving time-independent regret. We study HMA2B in both centralized and decentralized setups. Our main centralized algorithm, GP-HCLA, which is an extension of HCLA, uses a central decision-maker for arm-pulling and hint queries, achieving $O(M^4K)$ regret with $O(MK\log T)$ adaptive hints. In decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that allow agents to choose actions independently through collision-based communication and query hints uniformly until stopping, yielding $O(M^3K^2)$ regret with $O(M^3K\log T)$ hints, where the former requires knowledge of the minimum gap and the latter does not. Finally, we establish lower bounds to prove the optimality of our results and verify them through numerical simulations.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Trust-Aware and Cost-Optimized Blockchain Oracle Selection Model with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16133</link>
<guid>https://arxiv.org/abs/2502.16133</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化应用、预言机、信任管理机制、深度强化学习

总结:<br />
本文针对区块链与外部数据交互过程中依赖预言机而产生的安全性和信任问题，以及随着数据请求增加导致的预言机选择挑战，提出了一种基于深度强化学习的信任感知和成本优化的区块链预言机选择模型（TCO-DRL）。该模型通过多维度综合评价预言机声誉，并利用改进的滑动时间窗口实时监测声誉变化，增强了对恶意攻击的抵抗能力。同时，TCO-DRL运用深度强化学习算法动态适应预言机声誉波动，确保选择高声誉预言机的同时进行节点选择优化，从而降低成本而不影响数据质量。实现在以太坊上的实施和验证表明，相比于现有方法，TCO-DRL能将分配到恶意预言机的概率降低超过39.10%，节省超过12.00%的成本。此外，通过模拟多种恶意攻击的实验进一步验证了TCO-DRL的鲁棒性和有效性。 <div>
arXiv:2502.16133v1 Announce Type: new 
Abstract: The rapid development of blockchain technology has driven the widespread application of decentralized applications (DApps) across various fields. However, DApps cannot directly access external data and rely on oracles to interact with off-chain data. As a bridge between blockchain and external data sources, oracles pose potential risks of malicious behavior, which may inject incorrect or harmful data, leading to trust and security issues. Additionally, with the surge in data requests, the disparity in oracle trustworthiness and costs has increased, making the dynamic selection of the most suitable oracle for each request a critical challenge. To address these issues, this paper proposes a Trust-Aware and Cost-Optimized Blockchain Oracle Selection Model with Deep Reinforcement Learning (TCO-DRL). The model incorporates a comprehensive trust management mechanism to evaluate oracle reputation from multiple dimensions and employs an improved sliding time window to monitor reputation changes in real time, enhancing resistance to malicious attacks. Moreover, TCO-DRL uses deep reinforcement learning algorithms to dynamically adapt to fluctuations in oracle reputation, ensuring the selection of high-reputation oracles while optimizing node selection, thereby reducing costs without compromising data quality. We implemented and validated TCO- DRL on Ethereum. Experimental results show that, compared to existing methods, TCO-DRL reduces the allocation rate to malicious oracles by more than 39.10% and saves over 12.00% in costs. Furthermore, simulated experiments on various malicious attacks further validate the robustness and effectiveness of TCO-DRL
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personhood Credentials: Human-Centered Design Recommendation Balancing Security, Usability, and Trust</title>
<link>https://arxiv.org/abs/2502.16375</link>
<guid>https://arxiv.org/abs/2502.16375</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式身份标识、人身份证明凭证、用户感知、设计推荐、隐私安全

总结:
该文针对人身份证明凭证（PHCs）技术，探讨了用户对其隐私和安全性的理解和期望，并通过对比分析及在线半结构化访谈研究了美国和欧盟的23位参与者对PHCs的接受度与偏好。研究发现用户对于PHCs与现有验证方法的隐私安全保证有认知差异，并揭示了影响用户对PHCs采纳和管理的因素，如可信发行者（如政府）、基础实证数据（如生物特征、实体身份证）以及发行系统（集中式 vs 分布式）。在概念设计思考环节，参与者提出了周期性生物特征验证、有时限的凭证、视觉交互式人工核验以及政府监管下的发放系统的概念设计方案。文章据此提出反映用户偏好的具体设计方案建议。 <div>
arXiv:2502.16375v1 Announce Type: new 
Abstract: Building on related concepts, like, decentralized identifiers (DIDs), proof of personhood, anonymous credentials, personhood credentials (PHCs) emerged as an alternative approach, enabling individuals to verify to digital service providers that they are a person without disclosing additional information. However, new technologies might introduce some friction due to users misunderstandings and mismatched expectations. Despite their growing importance, limited research has been done on users perceptions and preferences regarding PHCs. To address this gap, we conducted competitive analysis, and semi-structured online user interviews with 23 participants from US and EU to provide concrete design recommendations for PHCs that incorporate user needs, adoption rules, and preferences. Our study -- (a)surfaces how people reason about unknown privacy and security guarantees of PHCs compared to current verification methods -- (b) presents the impact of several factors on how people would like to onboard and manage PHCs, including, trusted issuers (e.g. gov), ground truth data to issue PHC (e.g biometrics, physical id), and issuance system (e.g. centralized vs decentralized). In a think-aloud conceptual design session, participants recommended -- conceptualized design, such as periodic biometrics verification, time-bound credentials, visually interactive human-check, and supervision of government for issuance system. We propose actionable designs reflecting users preferences.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TrustChain: A Blockchain Framework for Auditing and Verifying Aggregators in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2502.16406</link>
<guid>https://arxiv.org/abs/2502.16406</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning (DFL)，TrustChain，aggregator node，Hilbert-Schmidt Independence Criterion (HSIC)，blockchain

<br /><br />总结：
本文提出了一种针对去中心化联邦学习(DFL)的新结构——TrustChain，旨在解决选定聚合器节点可能在被提名后恶意行为的问题。TrustChain在选择聚合器前基于其过去行为对其进行评分，并在聚合完成后进行审计。通过使用Hilbert-Schmidt独立性准则(HSIC)持续监测客户端更新与聚合模型之间的统计独立性来实现对聚合器的监督。该方法综合运用了区块链技术、异常检测和概念漂移分析。文章在多种联邦学习数据集及不同数量拜占庭节点的攻击场景下对设计的结构进行了评估。 <div>
arXiv:2502.16406v1 Announce Type: new 
Abstract: The server-less nature of Decentralized Federated Learning (DFL) requires allocating the aggregation role to specific participants in each federated round. Current DFL architectures ensure the trustworthiness of the aggregator node upon selection. However, most of these studies overlook the possibility that the aggregating node may turn rogue and act maliciously after being nominated. To address this problem, this paper proposes a DFL structure, called TrustChain, that scores the aggregators before selection based on their past behavior and additionally audits them after the aggregation. To do this, the statistical independence between the client updates and the aggregated model is continuously monitored using the Hilbert-Schmidt Independence Criterion (HSIC). The proposed method relies on several principles, including blockchain, anomaly detection, and concept drift analysis. The designed structure is evaluated on several federated datasets and attack scenarios with different numbers of Byzantine nodes.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16449</link>
<guid>https://arxiv.org/abs/2502.16449</guid>
<content:encoded><![CDATA[
<div> 关键词: Emergency Response Time (ERT), Emergency Vehicle (EMV), EMVLight, Dynamic Queue-Jump Lane, Equity

总结:
本文研究了城市应急响应时间(ERT)的重要性，并以纽约市医疗ERT增加为例说明其问题。针对此问题，文章提出了三个主要贡献：1) 设计了名为EMVLight的分布式多智能体强化学习框架，该框架将紧急车辆(EMV)路由与交通信号优先权相结合，使EMV旅行时间缩短了42.6%，同时改善了其他车辆的行驶状况。2) 提出了动态排队跳跃车道系统，利用多智能体近似策略优化协调车道清理，在混合自动驾驶和人工驾驶的交通中减少了EMV旅行时间达40%。3) 对纽约市急救服务进行了公平性研究，揭示了各行政区之间的差异，并提出了解决方案，包括优化EMS站点布局和改进交叉口设计以缓解延迟问题。这些贡献有助于提升EMV的通行效率及紧急服务的公平性，为政策制定者和城市规划者提供了建设更安全、高效交通运输系统的洞见。 <div>
arXiv:2502.16449v1 Announce Type: new 
Abstract: Emergency Response Time (ERT) is crucial for urban safety, measuring cities' ability to handle medical, fire, and crime emergencies. In NYC, medical ERT increased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of delays due to Emergency Vehicle (EMV) travel times. Each minute's delay in stroke response costs 2 million brain cells, while cardiac arrest survival drops 7-10% per minute.
  This dissertation advances EMV facilitation through three contributions. First, EMVLight, a decentralized multi-agent reinforcement learning framework, integrates EMV routing with traffic signal pre-emption. It achieved 42.6% faster EMV travel times and 23.5% improvement for other vehicles.
  Second, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy Optimization for coordinated lane-clearing in mixed autonomous and human-driven traffic, reducing EMV travel times by 40%.
  Third, an equity study of NYC Emergency Medical Services revealed disparities across boroughs: Staten Island faces delays due to sparse signalized intersections, while Manhattan struggles with congestion. Solutions include optimized EMS stations and improved intersection designs.
  These contributions enhance EMV mobility and emergency service equity, offering insights for policymakers and urban planners to develop safer, more efficient transportation systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Enhancing Structural Resilience of Multirobot Coverage Control with Bearing Rigidity</title>
<link>https://arxiv.org/abs/2502.16460</link>
<guid>https://arxiv.org/abs/2502.16460</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人覆盖控制、故障容错、模型预测控制(MPC)、网络结构韧性、Voronoi分区

总结:

本文提出了一种用于区域覆盖的层次化框架，该框架结合了利用Voronoi分区的集中式协调和基于分布式参考跟踪的模型预测控制(MPC)设计。提出的分布式MPC不仅实现参考轨迹跟踪，还能执行方位保持以维持多机器人系统的刚性网络结构，从而增强系统在面临定位误差和机器人损失情况下的结构韧性。此外，文章证明了所提出的控制架构能够在发生机器人损失的情况下保证网络恢复，并维持一个最小刚性结构。通过数值模拟验证了该算法的有效性。<br /><br /> <div>
arXiv:2502.16460v1 Announce Type: new 
Abstract: The problem of multi-robot coverage control has been widely studied to efficiently coordinate a team of robots to cover a desired area of interest. However, this problem faces significant challenges when some robots are lost or deviate from their desired formation during the mission due to faults or cyberattacks. Since a majority of multi-robot systems (MRSs) rely on communication and relative sensing for their efficient operation, a failure in one robot could result in a cascade of failures in the entire system. In this work, we propose a hierarchical framework for area coverage, combining centralized coordination by leveraging Voronoi partitioning with decentralized reference tracking model predictive control (MPC) for control design. In addition to reference tracking, the decentralized MPC also performs bearing maintenance to enforce a rigid MRS network, thereby enhancing the structural resilience, i.e., the ability to detect and mitigate the effects of localization errors and robot loss during the mission. Furthermore, we show that the resulting control architecture guarantees the recovery of the MRS network in the event of robot loss while maintaining a minimally rigid structure. The effectiveness of the proposed algorithm is validated through numerical simulations.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control</title>
<link>https://arxiv.org/abs/2502.16608</link>
<guid>https://arxiv.org/abs/2502.16608</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（RL）、自适应交通信号控制（ATSC）、多智能体强化学习（MARL）、独立强化学习（IRL）、深度Q网络（DQN-DPUS）

总结:
本文探讨了在复杂城市交通网络中，强化学习作为自适应交通信号控制的有力数据驱动方法。由于涉及多个智能体的ATSC会导致集中式RL的维度问题，因此引入了多智能体强化学习（MARL）以实现控制的分散化。然而，MARL面临的挑战在于局部智能体因受限的交叉通信而面临部分可观测环境。文章提出，在无溢出拥堵（无智能体依赖）的情况下，MARL可以通过将任务分解为多个独立强化学习过程来达到最优全局Q值；而在存在溢出拥堵（有智能体依赖）的情境下，则可利用集中式RL达到最大全局Q值。为此，文章提出了动态参数更新策略的深度Q网络（DQN-DPUS），该策略根据智能体间的依赖动态更新权重和偏置，仅在无溢出拥堵情况下更新对角子矩阵。通过在一个由两个交叉口组成的简单交通网络中的实证研究，证明了DQN-DPUS能够加快收敛速度而不牺牲最优探索性能，从而证实了理论发现的有效性。 <div>
arXiv:2502.16608v1 Announce Type: new 
Abstract: Reinforcement learning (RL) emerges as a promising data-driven approach for adaptive traffic signal control (ATSC) in complex urban traffic networks, with deep neural networks substantially augmenting its learning capabilities. However, centralized RL becomes impractical for ATSC involving multiple agents due to the exceedingly high dimensionality of the joint action space. Multi-agent RL (MARL) mitigates this scalability issue by decentralizing control to local RL agents. Nevertheless, this decentralized method introduces new challenges: the environment becomes partially observable from the perspective of each local agent due to constrained inter-agent communication. Both centralized RL and MARL exhibit distinct strengths and weaknesses, particularly under heavy intersectional traffic conditions. In this paper, we justify that MARL can achieve the optimal global Q-value by separating into multiple IRL (Independent Reinforcement Learning) processes when no spill-back congestion occurs (no agent dependency) among agents (intersections). In the presence of spill-back congestion (with agent dependency), the maximum global Q-value can be achieved by using centralized RL. Building upon the conclusions, we propose a novel Dynamic Parameter Update Strategy for Deep Q-Network (DQN-DPUS), which updates the weights and bias based on the dependency dynamics among agents, i.e. updating only the diagonal sub-matrices for the scenario without spill-back congestion. We validate the DQN-DPUS in a simple network with two intersections under varying traffic, and show that the proposed strategy can speed up the convergence rate without sacrificing optimal exploration. The results corroborate our theoretical findings, demonstrating the efficacy of DQN-DPUS in optimizing traffic signal control.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Security Analysis of 5G NR Device-to-Device Sidelink Communications</title>
<link>https://arxiv.org/abs/2502.16650</link>
<guid>https://arxiv.org/abs/2502.16650</guid>
<content:encoded><![CDATA[
<div> 关键词: 5G NR, 端对端通信, 安全分析, 网络切片, 自主资源管理

总结:<br />
本文首次对5G NR车辆与一切（V2X）侧链路通信进行了全面的安全分析，揭示了该技术在直接设备间交互中所面临的重大安全挑战。文章指出了在关键程序中存在的漏洞，并演示了可能的攻击方式，包括数据完整性反馈操纵和资源阻塞攻击，这些攻击会危害侧链路通信的可靠性和隐私性。研究发现，尤其是依赖于自主资源管理（无网络监督）的NR操作模式尤其易受攻击。针对这些问题，文中提出了强化5G侧链路通信安全性的缓解策略。这项工作为未来加强5G设备间侧链路通信安全性、确保其在关键应用中的安全部署奠定了基础。 <div>
arXiv:2502.16650v1 Announce Type: new 
Abstract: 5G NR sidelink communication enables new possibilities for direct device-to-device interactions, supporting applications from vehicle-to-everything (V2X) systems to public safety, industrial automation, and drone networks. However, these advancements come with significant security challenges due to the decentralized trust model and increased reliance on User Equipment (UE) for critical functions like synchronization, resource allocation, and authorization. This paper presents the first comprehensive security analysis of NR V2X sidelink. We identify vulnerabilities across critical procedures and demonstrate plausible attack, including attacks that manipulate data integrity feedback and block resources, ultimately undermining the reliability and privacy of sidelink communications. Our analysis reveals that NR operational modes are vulnerable, with the ones relying on autonomous resource management (without network supervision) particularly exposed. To address these issues, we propose mitigation strategies to enhance the security of 5G sidelink communications. This work establishes a foundation for future efforts to strengthen 5G device-to-device sidelink communications, ensuring its safe deployment in critical applications.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedBM: Stealing Knowledge from Pre-trained Language Models for Heterogeneous Federated Learning</title>
<link>https://arxiv.org/abs/2502.16832</link>
<guid>https://arxiv.org/abs/2502.16832</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、数据异质性、局部学习偏见、Linguistic Knowledge-based Classifier Construction（LKCC）、Concept-guided Global Distribution Estimation（CGDE）

总结:
为解决联邦学习中数据异质性导致的局部学习偏见问题，该文提出了一种名为Federated Bias Eliminating（FedBM）的新框架。FedBM主要包括两个模块：Linguistic Knowledge-based Classifier Construction（LKCC）和Concept-guided Global Distribution Estimation（CGDE）。LKCC利用类概念、提示以及预训练语言模型来获取概念嵌入，进而估计各类别的潜在概念分布，据此构造一个高质量的预训练分类器，用于客户端实现分类优化并避免本地训练中的分类器偏见。CGDE从潜在概念分布中采样概率概念嵌入，通过学习一个条件生成器捕捉全局模型的输入空间。文中引入了三个正则化项以提升生成器的质量和实用性，该生成器会被所有客户端共享并生成伪数据，用于校准本地特征提取器的更新。实验证明FedBM在公共数据集上的性能优于现有方法，并验证了各模块的有效性。相关代码已开源，可在https://github.com/CUHK-AIM-Group/FedBM 获取。 <div>
arXiv:2502.16832v1 Announce Type: new 
Abstract: Federated learning (FL) has shown great potential in medical image computing since it provides a decentralized learning paradigm that allows multiple clients to train a model collaboratively without privacy leakage. However, current studies have shown that data heterogeneity incurs local learning bias in classifiers and feature extractors of client models during local training, leading to the performance degradation of a federation system. To address these issues, we propose a novel framework called Federated Bias eliMinating (FedBM) to get rid of local learning bias in heterogeneous federated learning (FL), which mainly consists of two modules, i.e., Linguistic Knowledge-based Classifier Construction (LKCC) and Concept-guided Global Distribution Estimation (CGDE). Specifically, LKCC exploits class concepts, prompts and pre-trained language models (PLMs) to obtain concept embeddings. These embeddings are used to estimate the latent concept distribution of each class in the linguistic space. Based on the theoretical derivation, we can rely on these distributions to pre-construct a high-quality classifier for clients to achieve classification optimization, which is frozen to avoid classifier bias during local training. CGDE samples probabilistic concept embeddings from the latent concept distributions to learn a conditional generator to capture the input space of the global model. Three regularization terms are introduced to improve the quality and utility of the generator. The generator is shared by all clients and produces pseudo data to calibrate updates of local feature extractors. Extensive comparison experiments and ablation studies on public datasets demonstrate the superior performance of FedBM over state-of-the-arts and confirm the effectiveness of each module, respectively. The code is available at https://github.com/CUHK-AIM-Group/FedBM.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment</title>
<link>https://arxiv.org/abs/2502.16863</link>
<guid>https://arxiv.org/abs/2502.16863</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器人协作、强化学习、信用分配问题、大语言模型、LLM-MCA方法

总结:
本文关注于机器人协作中的一种关键挑战——信用分配问题，即如何评估每个智能体行动对团队总体成功或失败的贡献。研究者提出将这一问题转化为序列改进和归因两个模式识别任务，并利用近期表现出人类水平性能的大语言模型（LLM）。为此，他们提出了LLM-MCA方法，该方法采用集中式的LLM奖励批评者来数值分解环境奖励，根据每个智能体在场景中的个体贡献进行分解。随后，根据此反馈更新智能体的策略网络。此外，还提出了一种扩展方法LLM-TACA，其中LLM批评者执行明确的任务分配，直接向场景中的每个智能体策略传递中介目标。实验表明，这两种方法在包括Level-Based Foraging、Robotic Warehouse以及新的包含碰撞安全约束的Spaceworld基准测试在内的多种基准上显著优于现有最佳方法。作为这两种方法的副产品，它们生成了大量的轨迹数据集，其中每一时间步都由LLM批评者注释了针对每个智能体的奖励信息。 <div>
arXiv:2502.16863v1 Announce Type: new 
Abstract: Recent work, spanning from autonomous vehicle coordination to in-space assembly, has shown the importance of learning collaborative behavior for enabling robots to achieve shared goals. A common approach for learning this cooperative behavior is to utilize the centralized-training decentralized-execution paradigm. However, this approach also introduces a new challenge: how do we evaluate the contributions of each agent's actions to the overall success or failure of the team. This credit assignment problem has remained open, and has been extensively studied in the Multi-Agent Reinforcement Learning literature. In fact, humans manually inspecting agent behavior often generate better credit evaluations than existing methods. We combine this observation with recent works which show Large Language Models demonstrate human-level performance at many pattern recognition tasks. Our key idea is to reformulate credit assignment to the two pattern recognition problems of sequence improvement and attribution, which motivates our novel LLM-MCA method. Our approach utilizes a centralized LLM reward-critic which numerically decomposes the environment reward based on the individualized contribution of each agent in the scenario. We then update the agents' policy networks based on this feedback. We also propose an extension LLM-TACA where our LLM critic performs explicit task assignment by passing an intermediary goal directly to each agent policy in the scenario. Both our methods far outperform the state-of-the-art on a variety of benchmarks, including Level-Based Foraging, Robotic Warehouse, and our new Spaceworld benchmark which incorporates collision-related safety constraints. As an artifact of our methods, we generate large trajectory datasets with each timestep annotated with per-agent reward information, as sampled from our LLM critics.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Primitive-Swarm: An Ultra-lightweight and Scalable Planner for Large-scale Aerial Swarms</title>
<link>https://arxiv.org/abs/2502.16887</link>
<guid>https://arxiv.org/abs/2502.16887</guid>
<content:encoded><![CDATA[
<div> 关键词:Primitive-Swarm、大规模自主空中集群、时间最优路径参数化算法(TOPP-RA)、碰撞检查机制、离线计算

总结:
本文提出了一种名为Primitive-Swarm的轻量级、可扩展的大型自主空中集群规划器。该方法采用去中心化和异步重规划策略，利用基于可达性分析的时间最优路径参数化算法(TOPP-RA)生成动态可行的运动原语库。同时，开发了一个快速碰撞检查机制，通过考虑空间和时间冲突来处理机器人与障碍物及机器人之间的碰撞。规划过程中，每个机器人根据用户定义的需求从库中选择安全成本最低的轨迹。运动原语库和占用信息均预先离线计算，将耗时优化问题转化为线性复杂度的选择问题，使规划器能在包含大量障碍物和机器人的非凸、不连续三维安全空间中进行全面探索并找出最佳隐藏路径。实验表明，该方法在密集环境中飞行时间和行驶距离最短，计算时间小于1毫秒，并且通过涉及多达1000个机器人的实时大规模集群模拟验证了其可扩展性。实际世界实验也证实了该方法的可行性和鲁棒性，代码将公开以促进社区合作。 <div>
arXiv:2502.16887v1 Announce Type: new 
Abstract: Achieving large-scale aerial swarms is challenging due to the inherent contradictions in balancing computational efficiency and scalability. This paper introduces Primitive-Swarm, an ultra-lightweight and scalable planner designed specifically for large-scale autonomous aerial swarms. The proposed approach adopts a decentralized and asynchronous replanning strategy. Within it is a novel motion primitive library consisting of time-optimal and dynamically feasible trajectories. They are generated utlizing a novel time-optimial path parameterization algorithm based on reachability analysis (TOPP-RA). Then, a rapid collision checking mechanism is developed by associating the motion primitives with the discrete surrounding space according to conflicts. By considering both spatial and temporal conflicts, the mechanism handles robot-obstacle and robot-robot collisions simultaneously. Then, during a replanning process, each robot selects the safe and minimum cost trajectory from the library based on user-defined requirements. Both the time-optimal motion primitive library and the occupancy information are computed offline, turning a time-consuming optimization problem into a linear-complexity selection problem. This enables the planner to comprehensively explore the non-convex, discontinuous 3-D safe space filled with numerous obstacles and robots, effectively identifying the best hidden path. Benchmark comparisons demonstrate that our method achieves the shortest flight time and traveled distance with a computation time of less than 1 ms in dense environments. Super large-scale swarm simulations, involving up to 1000 robots, running in real-time, verify the scalability of our method. Real-world experiments validate the feasibility and robustness of our approach. The code will be released to foster community collaboration.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MTVHunter: Smart Contracts Vulnerability Detection Based on Multi-Teacher Knowledge Translation</title>
<link>https://arxiv.org/abs/2502.16955</link>
<guid>https://arxiv.org/abs/2502.16955</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、安全漏洞、检测方法、多教师、Bytecode

总结:
本文提出了一种名为 MTVHunter 的基于多教师的智能合约字节码漏洞检测方法，用于有效应对字节码中的噪声干扰和缺失语义问题。MTVHunter 包括两个主要部分：首先，设计了一个指令降噪教师，通过抽象漏洞模式消除大量无关指令的干扰，并反映在合约嵌入表示中；其次，构建了一个新颖的语义补充教师，采用神经蒸馏技术，有效地从源代码中抽取必要语义来补充字节码的缺失信息，其中提出的神经蒸馏通过将知识迁移转化为回归任务加速了这一语义填充过程。实验结果表明，MTVHunter 在针对 229,178 个真实世界的涉及四种常见漏洞类型的智能合约上，相比于现有最优方法取得了显著的性能提升。 <div>
arXiv:2502.16955v1 Announce Type: new 
Abstract: Smart contracts, closely intertwined with cryptocurrency transactions, have sparked widespread concerns about considerable financial losses of security issues. To counteract this, a variety of tools have been developed to identify vulnerability in smart contract. However, they fail to overcome two challenges at the same time when faced with smart contract bytecode: (i) strong interference caused by enormous non-relevant instructions; (ii) missing semantics of bytecode due to incomplete data and control flow dependencies. In this paper, we propose a multi-teacher based bytecode vulnerability detection method, namely \textbf{M}ulti-\textbf{T}eacher \textbf{V}ulnerability \textbf{Hunter} (\textbf{MTVHunter}), which delivers effective denoising and missing semantic to bytecode under multi-teacher guidance. Specifically, we first propose an instruction denoising teacher to eliminate noise interference by abstract vulnerability pattern and further reflect in contract embeddings. Secondly, we design a novel semantic complementary teacher with neuron distillation, which effectively extracts necessary semantic from source code to replenish the bytecode. Particularly, the proposed neuron distillation accelerate this semantic filling by turning the knowledge transition into a regression task. We conduct experiments on 229,178 real-world smart contracts that concerns four types of common vulnerabilities. Extensive experiments show MTVHunter achieves significantly performance gains over state-of-the-art approaches.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Novel Multiple Access Scheme for Heterogeneous Wireless Communications using Symmetry-aware Continual Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.17167</link>
<guid>https://arxiv.org/abs/2502.17167</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse, 无线通信, 频谱管理, 深度强化学习(Deep Reinforcement Learning, DRL), 不断学习(Continual Learning, CL)

总结:
本文探讨了Metaverse对无线通信系统中高效频谱管理带来的新挑战以及利用深度强化学习(DRL)方法进行应对的研究现状。然而，如何适应异构和非平稳的无线环境仍是问题。为此，文章提出了一种融合不断学习(CL)技术的智能媒体访问控制(MAC)协议新方法，设计了一个与不同数量、协议和传输特性未知的遗留用户设备共存的智能代理，以实现向后兼容和保护隐私。该方法基于适应性Double和Dueling深Q学习(D3QL)，并引入对称性感知的CL机制，旨在最大化智能代理吞吐量的同时确保公平性。数学分析证明了所提方案的有效性，显示其在吞吐量、碰撞率和公平性等方面优于传统的DRL技术，并能实现在高度动态场景下的实时响应。 <div>
arXiv:2502.17167v1 Announce Type: new 
Abstract: The Metaverse holds the potential to revolutionize digital interactions through the establishment of a highly dynamic and immersive virtual realm over wireless communications systems, offering services such as massive twinning and telepresence. This landscape presents novel challenges, particularly efficient management of multiple access to the frequency spectrum, for which numerous adaptive Deep Reinforcement Learning (DRL) approaches have been explored. However, challenges persist in adapting agents to heterogeneous and non-stationary wireless environments. In this paper, we present a novel approach that leverages Continual Learning (CL) to enhance intelligent Medium Access Control (MAC) protocols, featuring an intelligent agent coexisting with legacy User Equipments (UEs) with varying numbers, protocols, and transmission profiles unknown to the agent for the sake of backward compatibility and privacy. We introduce an adaptive Double and Dueling Deep Q-Learning (D3QL)-based MAC protocol, enriched by a symmetry-aware CL mechanism, which maximizes intelligent agent throughput while ensuring fairness. Mathematical analysis validates the efficiency of our proposed scheme, showcasing superiority over conventional DRL-based techniques in terms of throughput, collision rate, and fairness, coupled with real-time responsiveness in highly dynamic scenarios.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Order Fairness Evaluation of DAG-based ledgers</title>
<link>https://arxiv.org/abs/2502.17270</link>
<guid>https://arxiv.org/abs/2502.17270</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本、交易排序公平性、Maximal Extractable Value (MEV)攻击、有向无环图(DAG)、拜占庭节点

总结:
本文探讨了分布式账本中交易排序公平性的概念，特别是在区块链与DAG(有向无环图)基础架构中的差异。传统区块链协议中，领导者负责选取打包进区块的交易，从而引入操纵交易顺序的风险和Maximal Extractable Value (MEV)攻击。而DAG型账本则允许网络参与者独立提出区块，并通过这些区块构建一个无环图，领导者是在事后根据已有交易选举产生，用于确定交易的全局顺序，降低了交易选择的操纵风险并增强了公平性。

文章提出了适用于DAG账本的新版交易排序公平性定义，并分析了当敌手控制一定数量（低于三分之一阈值）的拜占庭节点时，对交易重新排序的影响。研究发现，即使采用DAG结构，仍存在重排序攻击的风险，因为敌手可以通过协调少量拜占庭节点来操纵DAG的结构。 <div>
arXiv:2502.17270v1 Announce Type: new 
Abstract: Order fairness in distributed ledgers refers to properties that relate the order in which transactions are sent or received to the order in which they are eventually finalized, i.e., totally ordered. The study of such properties is relatively new and has been especially stimulated by the rise of Maximal Extractable Value (MEV) attacks in blockchain environments. Indeed, in many classical blockchain protocols, leaders are responsible for selecting the transactions to be included in blocks, which creates a clear vulnerability and opportunity for transaction order manipulation.
  Unlike blockchains, DAG-based ledgers allow participants in the network to independently propose blocks, which are then arranged as vertices of a directed acyclic graph. Interestingly, leaders in DAG-based ledgers are elected only after the fact, once transactions are already part of the graph, to determine their total order. In other words, transactions are not chosen by single leaders; instead, they are collectively validated by the nodes, and leaders are only elected to establish an ordering. This approach intuitively reduces the risk of transaction manipulation and enhances fairness.
  In this paper, we aim to quantify the capability of DAG-based ledgers to achieve order fairness. To this end, we define new variants of order fairness adapted to DAG-based ledgers and evaluate the impact of an adversary capable of compromising a limited number of nodes (below the one-third threshold) to reorder transactions. We analyze how often our order fairness properties are violated under different network conditions and parameterizations of the DAG algorithm, depending on the adversary's power.
  Our study shows that DAG-based ledgers are still vulnerable to reordering attacks, as an adversary can coordinate a minority of Byzantine nodes to manipulate the DAG's structure.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Survey on Strategic Mining in Blockchain: A Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2502.17307</link>
<guid>https://arxiv.org/abs/2502.17307</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (RL), 战略性挖矿攻击, 马尔科夫决策过程 (MDP), 区块链共识协议, 安全阈值

<br /><br />总结:
本文考察了强化学习（RL）在分析战略性挖矿攻击中的作用，并将其与基于马尔科夫决策过程（MDP）的方法进行了比较。首先概述了MDP的基础模型及其局限性，接着探讨了适用于多种区块链共识协议的RL框架，用于学习近最优策略。文章进一步对比了RL技术在确定如最小攻击者实力等安全阈值方面的有效性。此外，文中还对共识协议进行了分类，并提出了开放性的挑战，包括多智能体动态和现实世界验证。该文强调了强化学习（RL）在应对自私挖矿带来的挑战，如协议设计、威胁检测和安全性分析等方面所具有的潜力，并为分布式系统和AI驱动分析领域的研究者提供了战略路线图。 <div>
arXiv:2502.17307v1 Announce Type: new 
Abstract: Strategic mining attacks, such as selfish mining, exploit blockchain consensus protocols by deviating from honest behavior to maximize rewards. Markov Decision Process (MDP) analysis faces scalability challenges in modern digital economics, including blockchain. To address these limitations, reinforcement learning (RL) provides a scalable alternative, enabling adaptive strategy optimization in complex dynamic environments.
  In this survey, we examine RL's role in strategic mining analysis, comparing it to MDP-based approaches. We begin by reviewing foundational MDP models and their limitations, before exploring RL frameworks that can learn near-optimal strategies across various protocols. Building on this analysis, we compare RL techniques and their effectiveness in deriving security thresholds, such as the minimum attacker power required for profitable attacks. Expanding the discussion further, we classify consensus protocols and propose open challenges, such as multi-agent dynamics and real-world validation.
  This survey highlights the potential of reinforcement learning (RL) to address the challenges of selfish mining, including protocol design, threat detection, and security analysis, while offering a strategic roadmap for researchers in decentralized systems and AI-driven analytics.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BlockEmulator: An Emulator Enabling to Test Blockchain Sharding Protocols</title>
<link>https://arxiv.org/abs/2311.03612</link>
<guid>https://arxiv.org/abs/2311.03612</guid>
<content:encoded><![CDATA[
<div> 关键词: BlockEmulator、区块链模拟器、共识算法、区块链分片系统、实验平台

<br /><br />总结:
本文介绍了BlockEmulator，这是一个针对区块链分片机制开发和评估的开源实验平台。现有的区块链模拟器虽多，但缺乏专门用于研究新的共识算法或区块链分片协议的工具。BlockEmulator采用轻量级的区块链架构，使开发者能专注于实现新协议或机制，并通过其层次化模块和编程接口简化了实施过程。文章通过两步实验证明了BlockEmulator的功能正确性：首先，将理论分析与实验结果进行对比以证明其仿真结果的准确性；其次，展示了BlockEmulator能够便捷地衡量一系列性能指标，如吞吐量、交易确认延迟、跨片交易比例、交易池排队状态以及区块链分片间的工作负载分布等。BlockEmulator已在Github上开源。 <div>
arXiv:2311.03612v5 Announce Type: replace 
Abstract: Numerous blockchain simulators have been proposed to allow researchers to simulate mainstream blockchains. However, we have not yet found a testbed that enables researchers to develop and evaluate their new consensus algorithms or new protocols for blockchain sharding systems. To fill this gap, we developed BlockEmulator, which is designed as an experimental platform, particularly for emulating blockchain sharding mechanisms. BlockEmulator adopts a lightweight blockchain architecture so developers can only focus on implementing their new protocols or mechanisms. Using layered modules and useful programming interfaces offered by BlockEmulator, researchers can implement a new protocol with minimum effort. Through experiments, we test various functionalities of BlockEmulator in two steps. Firstly, we prove the correctness of the emulation results yielded by BlockEmulator by comparing the theoretical analysis with the observed experiment results. Secondly, other experimental results demonstrate that BlockEmulator can facilitate measuring a series of metrics, including throughput, transaction confirmation latency, cross-shard transaction ratio, the queuing status of transaction pools, workload distribution across blockchain shards, etc. We have made BlockEmulator open-source in Github.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors</title>
<link>https://arxiv.org/abs/2502.15058</link>
<guid>https://arxiv.org/abs/2502.15058</guid>
<content:encoded><![CDATA[
<div> 关键词: Flexible Inertial Poser (FIP)、运动捕捉系统、传感器位移、Displacement Latent Diffusion Model、Physics-informed Calibrator、Pose Fusion Predictor、多模态传感器融合、身体形状、动作、状态-of-the-art (SOTA) IMU 方法、角度误差、肘部角度误差、位置误差、元宇宙、康复、健身分析。

<br /><br />总结:
本文介绍了Flexible Inertial Poser (FIP)，一种使用日常服装上的两个肘部附着的弯曲传感器和四个惯性测量单元(IMUs)的新型运动捕捉系统。针对松散可穿戴设备中不可避免的传感器位移导致的关节跟踪精度下降问题，文章提出了Displacement Latent Diffusion Model和Physics-informed Calibrator来补偿传感器位移，显著提高了运动捕捉准确性。同时引入了Pose Fusion Predictor以增强多模态传感器融合性能。实验表明，该方法在不同身体形状和动作下表现出稳健的性能，相比现有的IMU方法，其角度误差降低了19.5%，肘部角度误差降低26.4%，位置误差降低30.1%。FIP为普及化的交互式应用如元宇宙、康复和健身分析等领域开辟了新机遇。 <div>
arXiv:2502.15058v1 Announce Type: new 
Abstract: What if our clothes could capture our body motion accurately? This paper introduces Flexible Inertial Poser (FIP), a novel motion-capturing system using daily garments with two elbow-attached flex sensors and four Inertial Measurement Units (IMUs). To address the inevitable sensor displacements in loose wearables which degrade joint tracking accuracy significantly, we identify the distinct characteristics of the flex and inertial sensor displacements and develop a Displacement Latent Diffusion Model and a Physics-informed Calibrator to compensate for sensor displacements based on such observations, resulting in a substantial improvement in motion capture accuracy. We also introduce a Pose Fusion Predictor to enhance multimodal sensor fusion. Extensive experiments demonstrate that our method achieves robust performance across varying body shapes and motions, significantly outperforming SOTA IMU approaches with a 19.5% improvement in angular error, a 26.4% improvement in elbow angular error, and a 30.1% improvement in positional error. FIP opens up opportunities for ubiquitous human-computer interactions and diverse interactive applications such as Metaverse, rehabilitation, and fitness analysis.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shapley Value-based Approach for Redistributing Revenue of Matchmaking of Private Transactions in Blockchains</title>
<link>https://arxiv.org/abs/2502.15420</link>
<guid>https://arxiv.org/abs/2502.15420</guid>
<content:encoded><![CDATA[
<div> 关键词：MEV、区块链、交易撮合、合作博弈论、Shapley值

总结:
本文主要研究了区块链环境中最大可提取价值（MEV）中的交易撮合问题。文章介绍了在MEV背景下，搜索者参与订单流拍卖以获取匹配器（也称作订单流提供者）提供的私人交易独家权利的现象，并探讨了交易收入公平再分配的挑战与可能性。通过合作博弈论，文章提出了一个名为RST-Game的特征形式游戏，用于定义交易创建者的收益再分配，并建议利用RST-Game中交易的Shapley值进行再分配。进一步地，鉴于该问题可能属于SUBEXP复杂度类，即时间复杂度为$2^{o(n)}$（其中n为交易数量），因此需要近似计算Shapley值。为此，文中提出了一种随机算法来计算Shapley值，并通过实证验证了其有效性。 <div>
arXiv:2502.15420v1 Announce Type: new 
Abstract: In the context of blockchain, MEV refers to the maximum value that can be extracted from block production through the inclusion, exclusion, or reordering of transactions. Searchers often participate in order flow auctions (OFAs) to obtain exclusive rights to private transactions, available through entities called matchmakers, also known as order flow providers (OFPs). Most often, redistributing the revenue generated through such auctions among transaction creators is desirable. In this work, we formally introduce the matchmaking problem in MEV, its desirable properties, and associated challenges. Using cooperative game theory, we formalize the notion of fair revenue redistribution in matchmaking and present its potential possibilities and impossibilities. Precisely, we define a characteristic form game, referred to as RST-Game, for the transaction creators. We propose to redistribute the revenue using the Shapley value of RST-Game. We show that the corresponding problem could be SUBEXP (i.e. $2^{o(n)}$, where $n$ is the number of transactions); therefore, approximating the Shapley value is necessary. Further, we propose a randomized algorithm for computing the Shapley value in RST-Game and empirically verify its efficacy.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15425</link>
<guid>https://arxiv.org/abs/2502.15425</guid>
<content:encoded><![CDATA[
<div> 关键词: hierarchical organization, artificial intelligence, hierarchical reinforcement learning (HRL), TAME Agent Framework (TAG), decentralized multi-agent systems

总结:
文章介绍了一种新型的人工智能框架——TAME Agent Framework (TAG)，用于构建完全去中心化的多层分层多智能体系统。TAG通过引入LevelEnv概念，实现了任意深度的层次化组织，将每一层级视为上层智能体的环境，标准化了层级间的信息流并保持松散耦合，允许不同类型的智能体无缝集成。实验表明，使用TAG实现的分层架构结合了不同RL代理并在多个层级中协同工作，相比于传统的多智能体强化学习基线，在标准基准测试上表现出更快的学习速度和更优的最终性能。这表明去中心化的分层组织为可扩展的多智能体系统提供了有前景的发展方向。 <div>
arXiv:2502.15425v1 Announce Type: new 
Abstract: Hierarchical organization is fundamental to biological systems and human societies, yet artificial intelligence systems often rely on monolithic architectures that limit adaptability and scalability. Current hierarchical reinforcement learning (HRL) approaches typically restrict hierarchies to two levels or require centralized training, which limits their practical applicability. We introduce TAME Agent Framework (TAG), a framework for constructing fully decentralized hierarchical multi-agent systems.TAG enables hierarchies of arbitrary depth through a novel LevelEnv concept, which abstracts each hierarchy level as the environment for the agents above it. This approach standardizes information flow between levels while preserving loose coupling, allowing for seamless integration of diverse agent types. We demonstrate the effectiveness of TAG by implementing hierarchical architectures that combine different RL agents across multiple levels, achieving improved performance over classical multi-agent RL baselines on standard benchmarks. Our results show that decentralized hierarchical organization enhances both learning speed and final performance, positioning TAG as a promising direction for scalable multi-agent systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartLog: Metrics-driven Role Assignment for Byzantine Fault-tolerant Protocols</title>
<link>https://arxiv.org/abs/2502.15428</link>
<guid>https://arxiv.org/abs/2502.15428</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine Fault Tolerant (BFT), 区块链技术, 可扩展性, 角色分配, SmartLog

总结:
<br />
本文介绍了在区块链技术中起关键作用的拜占庭容错(BFT)协议。随着此类系统在网络广泛部署，BFT协议的可扩展性成为重要关注点。为提升性能，对副本进行特定角色分配的优化策略具有重要意义，但同时也高度敏感于故障影响。针对这些问题，文章提出了SmartLog，一个用于收集和分析指标的日志框架，旨在在全球分布式系统中进行角色分配，即使存在故障也能保证其有效性。SmartLog将局部测量结果整合到全局数据结构中，确保决策的一致性和促使副本对其报告的测量结果负责。通过将SmartLog应用于Kauri——一种使用随机组合树状覆盖层的优化方案，SmartLog能在恶劣条件下发现稳健、低延迟的树配置。 <div>
arXiv:2502.15428v1 Announce Type: new 
Abstract: Byzantine Fault Tolerant (BFT) protocols play a pivotal role in blockchain technology. As the deployment of such systems extends to wide-area networks, the scalability of BFT protocols becomes a critical concern. Optimizations that assign specific roles to individual replicas can significantly improve the performance of BFT systems. However, such role assignment is highly sensitive to faults, potentially undermining the optimizations effectiveness. To address these challenges, we present SmartLog, a logging framework for collecting and analyzing metrics that help to assign roles in globally distributed systems, despite the presence of faults. SmartLog presents local measurements in global data structures, to enable consistent decisions and hold replicas accountable if they do not perform according to their reported measurements. We apply SmartLog to Kauri, an optimization using randomly composed tree overlays. SmartLog finds robust and low-latency tree configurations under adverse conditions.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Contract DesignUnderApproximate Best Responses</title>
<link>https://arxiv.org/abs/2502.15523</link>
<guid>https://arxiv.org/abs/2502.15523</guid>
<content:encoded><![CDATA[
<div> 关键词: 主体-代理问题、近似最优响应、合同设计、计算复杂性、无后悔学习算法

总结:
本文研究了在隐藏行动主体-代理问题中，当代理人可能选择相对于主体制定的支付方案而言不是过于次优的动作时（即近似最优响应）的情况。文章的主要成果是在该设定下，提出了一种用于计算最优合同的多项式时间算法，这在一定程度上令人惊讶，因为在Stackelberg博弈中，计算近似最优承诺是计算上困难的。此外，针对一种自然的应用场景，即当主体对环境没有先验知识时，文中还提供了一个无后悔学习算法来探究合同的可学习性。 <div>
arXiv:2502.15523v1 Announce Type: new 
Abstract: Principal-agent problems model scenarios where a principal incentivizes an agent to take costly, unobservable actions through the provision of payments. Such problems are ubiquitous in several real-world applications, ranging from blockchain to the delegation of machine learning tasks. In this paper, we initiate the study of hidden-action principal-agent problems under approximate best responses, in which the agent may select any action that is not too much suboptimal given the principal's payment scheme (a.k.a. contract). Our main result is a polynomial-time algorithm to compute an optimal contract under approximate best responses. This positive result is perhaps surprising, since, in Stackelberg games, computing an optimal commitment under approximate best responses is computationally intractable. We also investigate the learnability of contracts under approximate best responses, by providing a no-regret learning algorithm for a natural application scenario where the principal has no prior knowledge about the environment.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-based Trust Management in Security Credential Management System for Vehicular Network</title>
<link>https://arxiv.org/abs/2502.15653</link>
<guid>https://arxiv.org/abs/2502.15653</guid>
<content:encoded><![CDATA[
<div> 关键词：Cellular networking、Vehicular communication、Security Credential Management System (SCMS)、Blockchain-Based Trust Management (BBTM)、Hyperledger Fabric

总结:
文章介绍了针对车联网中多样化的应用场景，现有的安全凭证管理系统（SCMS）作为车辆网络的公钥基础设施，以及其如何利用多权威机构实现隐私保护和信任管理的分散化。然而，为了进一步增强分散化与安全性，文中提出了一种基于区块链的信任管理方案——Blockchain-Based Trust Management (BBTM)。BBTM使用区块链技术来替代原有的策略生成器(PG)，管理各权威机构的策略，聚合全局证书链文件(GCCF)，并提高上述功能的透明度和问责性。该方案已在Hyperledger Fabric上通过智能合约实现了实验与分析，实验结果显示，BBTM具有轻量级处理能力，高效管理证书链和日志大小的优势，支持每秒多次交易的带宽，并确保了经过验证的实体有效性。 <div>
arXiv:2502.15653v1 Announce Type: new 
Abstract: Cellular networking is advancing as a wireless technology to support diverse applications in vehicular communication, enabling vehicles to interact with various applications to enhance the driving experience, even when managed by different authorities. Security Credential Management System (SCMS) is the Public Key Infrastructure (PKI) for vehicular networking and the state-of-the-art distributed PKI to protect the privacy-preserving vehicular networking against an honest-but-curious authority using multiple authorities and to decentralize the trust management. We build a Blockchain-Based Trust Management (BBTM) to provide even greater decentralization and security. Specifically, BBTM uses the blockchain to 1) replace the existing Policy Generator (PG), 2) manage the policy of each authority in SCMS, 3) aggregate the Global Certificate Chain File (GCCF), and 4) provide greater accountability and transparency on the aforementioned functionalities. We implement BBTM on Hyperledger Fabric using a smart contract for experimentation and analyses. Our experiments show that BBTM is lightweight in processing, efficient management in the certificate chain and ledger size, supports a bandwidth of multiple transactions per second, and provides validated end-entities.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FLEKE: Federated Locate-then-Edit Knowledge Editing</title>
<link>https://arxiv.org/abs/2502.15677</link>
<guid>https://arxiv.org/abs/2502.15677</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Locate-then-Edit Knowledge Editing (FLEKE), Large Language Models (LLMs), Multi-client scenario, Privacy preservation, Computational overhead

总结:
本文提出了Federated Locate-then-Edit Knowledge Editing (FLEKE)，这是一种针对多客户端场景下大型语言模型（LLMs）知识编辑的新方法，旨在解决现有方法在实际应用场景中的效率和隐私问题。为实现这一目标，文章介绍了FedEdit，一个包含两个阶段的框架，该框架优化了mediator knowledge vector (MKV)的选择与重用。第一阶段，客户端局部应用LEKE并上传计算得到的MKVs；第二阶段，客户端基于余弦相似性检索相关MKV，从而实现知识重编辑并减少冗余计算。实验结果显示，FedEdit在保持超过96%非联邦式LEKE性能的同时，相比于基于FedAvg的基线方法，性能提升了约两倍。此外，研究发现，在FLEKE任务中，MEMIT在FedEdit框架下的表现比PMET更为稳定。相关代码已开源，可在https://github.com/zongkaiz/FLEKE获取。 <div>
arXiv:2502.15677v1 Announce Type: new 
Abstract: Locate-then-Edit Knowledge Editing (LEKE) is a key technique for updating large language models (LLMs) without full retraining. However, existing methods assume a single-user setting and become inefficient in real-world multi-client scenarios, where decentralized organizations (e.g., hospitals, financial institutions) independently update overlapping knowledge, leading to redundant mediator knowledge vector (MKV) computations and privacy concerns. To address these challenges, we introduce Federated Locate-then-Edit Knowledge Editing (FLEKE), a novel task that enables multiple clients to collaboratively perform LEKE while preserving privacy and reducing computational overhead. To achieve this, we propose FedEdit, a two-stage framework that optimizes MKV selection and reuse. In the first stage, clients locally apply LEKE and upload the computed MKVs. In the second stage, rather than relying solely on server-based MKV sharing, FLEKE allows clients retrieve relevant MKVs based on cosine similarity, enabling knowledge re-edit and minimizing redundant computations. Experimental results on two benchmark datasets demonstrate that FedEdit retains over 96% of the performance of non-federated LEKE while significantly outperforming a FedAvg-based baseline by approximately twofold. Besides, we find that MEMIT performs more consistently than PMET in the FLEKE task with our FedEdit framework. Our code is available at https://github.com/zongkaiz/FLEKE.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digital Inheritance in Web3: A Case Study of Soulbound Tokens and the Social Recovery Pallet within the Polkadot and Kusama Ecosystems</title>
<link>https://arxiv.org/abs/2301.11074</link>
<guid>https://arxiv.org/abs/2301.11074</guid>
<content:encoded><![CDATA[
<div> 关键词：数字遗产、社交恢复模块、灵魂绑定代币、Polkadot区块链网络、Kusama区块链网络

<br /><br />总结:
本文探讨了近年来随着社交媒体用户和区块链生态系统中关于数字继承讨论的增加，数字资产如社交媒体内容、加密货币和非同质化代币的价值与普及日益提升，因此急需明确而安全的机制来处理这些资产在其所有者去世或丧失行为能力后的转移问题。研究提出了一个利用灵魂绑定代币和社交恢复模块在Polkadot和Kusama区块链网络中的数字继承框架。该研究发现，虽然灵魂绑定代币和社交恢复模块为制定数字继承计划提供了有前景的解决方案，但也提出了一些对于立遗嘱人、数字执行者和开发者的重要考虑因素。尽管需要进一步研究以全面了解人工智能和量子计算等其他技术可能带来的潜在影响和风险，但本研究为用户开始规划数字继承策略及开发者开发更直观的解决方案提供了一个初步指南。 <div>
arXiv:2301.11074v3 Announce Type: cross 
Abstract: In recent years discussions centered around digital inheritance have increased among social media users and across blockchain ecosystems. As a result digital assets such as social media content cryptocurrencies and non-fungible tokens have become increasingly valuable and widespread, leading to the need for clear and secure mechanisms for transferring these assets upon the testators death or incapacitation. This study proposes a framework for digital inheritance using soulbound tokens and the social recovery pallet as a use case in the Polkadot and Kusama blockchain networks. The findings discussed within this study suggest that while soulbound tokens and the social recovery pallet offer a promising solution for creating a digital inheritance plan the findings also raise important considerations for testators digital executors and developers. While further research is needed to fully understand the potential impacts and risks of other technologies such as artificial intelligence and quantum computing this study provides a primer for users to begin planning a digital inheritance strategy and for developers to develop a more intuitive solution.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Quantum Signature Validation Algorithm for Efficient Detection of Tampered Transactions in Blockchain</title>
<link>https://arxiv.org/abs/2502.15023</link>
<guid>https://arxiv.org/abs/2502.15023</guid>
<content:encoded><![CDATA[
<div> 关键词: 量子签名验证算法（QSVA）、区块链、量子计算、交易图表示、Randomized SearchRank

总结:
量子签名验证算法（QSVA）是一种利用量子计算强大能力增强区块链系统中篡改交易检测的新方法。QSVA结合量子行走和PageRank搜索算法，为基于交易的区块链提供了一种强大的欺诈交易识别机制。该算法采用类似于比特币模型的未花费交易输出（UTXOs）交易图表示法来有效验证交易。通过将Quantum SearchRank和Randomized SearchRank两种量子搜索算法应用于其中，QSVA实现了一个平方加速比的效率提升，并发现Randomized SearchRank在与经典PageRank算法的交易排名一致性方面表现出优越性，从而确保更高的检测概率。这些成果表明量子算法有可能彻底改变区块链安全领域，通过将检测时间缩短至$O(\sqrt{N})$，显著提高区块链系统的效率和安全性。随着分布式账本技术（DLTs）的进步，未来有望将此类量子解决方案更广泛地集成到分布式系统中。随着量子技术的不断发展，QSVA成为一种具有重大进步意义的区块链效率和安全策略。 <div>
arXiv:2502.15023v1 Announce Type: cross 
Abstract: The Quantum Signature Validation Algorithm (QSVA) is introduced as a novel quantum-based approach designed to enhance the detection of tampered transactions in blockchain systems. Leveraging the powerful capabilities of quantum computing, especially within the framework of transaction-based blockchains, the QSVA aims to surpass classical methods in both speed and efficiency. By utilizing a quantum walk approach integrated with PageRank-based search algorithms, QSVA provides a robust mechanism for identifying fraudulent transactions. Our adaptation of the transaction graph representation efficiently verifies transactions by maintaining a current set of unspent transaction outputs (UTXOs) characteristic of models like Bitcoin. The QSVA not only amplifies detection efficacy through a quadratic speedup but also incorporates two competing quantum search algorithms$-$Quantum SearchRank and Randomized SearchRank$-$to explore their effectiveness as foundational components. Our results indicate that Randomized SearchRank, in particular, outperforms its counterpart in aligning with transaction rankings based on the Classical PageRank algorithm, ensuring more consistent detection probabilities. These findings highlight the potential for quantum algorithms to revolutionize blockchain security by improving detection times to $O(\sqrt{N})$. Progress in Distributed Ledger Technologies (DLTs) could facilitate future integration of quantum solutions into more general distributed systems. As quantum technology continues to evolve, the QSVA stands as a promising strategy offering significant advancements in blockchain efficiency and security.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Enhanced Training-as-a-Service for On-Device Intelligence: Concept, Architectural Scheme, and Open Problems</title>
<link>https://arxiv.org/abs/2404.10255</link>
<guid>https://arxiv.org/abs/2404.10255</guid>
<content:encoded><![CDATA[
<div> 关键词: On-device intelligence (ODI), 人工智能(AI), 云边缘计算, 隐私保护训练, PTaaS (Privacy-Enhanced Training-as-a-Service)

<br /><br />总结:
为了解决设备端部署的人工智能模型训练面临的隐私敏感、数据分散以及资源约束等问题，本文提出了一个新的服务计算范式——PTaaS（Privacy-Enhanced Training-as-a-Service）。PTaaS通过将核心训练过程外包给云端或边缘服务器，利用上传的匿名查询高效地开发定制化的设备端模型，从而增强数据隐私并减轻单个设备的计算负载。文章探讨了PTaaS的定义、目标和设计原则，并介绍了支持PTaaS范式的新兴技术及其体系结构方案，最后提出了一系列未来研究方向中的开放性问题。 <div>
arXiv:2404.10255v3 Announce Type: replace 
Abstract: On-device intelligence (ODI) enables artificial intelligence (AI) applications to run on end devices, providing real-time and customized AI inference without relying on remote servers. However, training models for on-device deployment face significant challenges due to the decentralized and privacy-sensitive nature of users' data, along with end-side constraints related to network connectivity, computation efficiency, etc. Existing training paradigms, such as cloud-based training, federated learning, and transfer learning, fail to sufficiently address these practical constraints that are prevalent for devices. To overcome these challenges, we propose Privacy-Enhanced Training-as-a-Service (PTaaS), a novel service computing paradigm that provides privacy-friendly, customized AI model training for end devices. PTaaS outsources the core training process to remote and powerful cloud or edge servers, efficiently developing customized on-device models based on uploaded anonymous queries, enhancing data privacy while reducing the computation load on individual devices. We explore the definition, goals, and design principles of PTaaS, alongside emerging technologies that support the PTaaS paradigm. An architectural scheme for PTaaS is also presented, followed by a series of open problems that set the stage for future research directions in the field of PTaaS.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title>
<link>https://arxiv.org/abs/2410.14803</link>
<guid>https://arxiv.org/abs/2410.14803</guid>
<content:encoded><![CDATA[
<div> 关键词：on-device control agents, MLLMs, DistRL, training efficiency, success rate

总结:<br />
本文介绍了DistRL，一个针对移动设备控制代理在线强化学习（RL）微调的新框架。该框架旨在解决将多模态大型语言模型（MLLMs）整合到设备控制代理中面临的有限数据可用性和低效在线训练问题。DistRL采用集中式训练和分布式数据采集，确保在动态在线交互环境中实现高效微调。此外，DistRL还配有一套定制的RL算法，有效平衡探索与收集数据的优先级利用，以保证稳定且健壮的训练。实验结果显示，DistRL在训练效率方面平均提升了3倍，训练数据收集速度比领先的同步多机器方法快了2.4倍。更重要的是，经过训练后，DistRL在公开基准测试中的通用Android任务上相比现有最佳方法成功率相对提高了20%，显著超越现有方法的同时保持相同的训练时间。这表明DistRL是一个可扩展且高效的解决方案，为实际环境下的设备控制任务提供了显著提升的训练效率和代理性能。 <div>
arXiv:2410.14803v5 Announce Type: replace 
Abstract: On-device control agents, especially on mobile devices, are responsible for operating mobile devices to fulfill users' requests, enabling seamless and intuitive interactions. Integrating Multimodal Large Language Models (MLLMs) into these agents enhances their ability to understand and execute complex commands, thereby improving user experience. However, fine-tuning MLLMs for on-device control presents significant challenges due to limited data availability and inefficient online training processes. This paper introduces DistRL, a novel framework designed to enhance the efficiency of online RL fine-tuning for mobile device control agents. DistRL employs centralized training and decentralized data acquisition to ensure efficient fine-tuning in the context of dynamic online interactions. Additionally, the framework is backed by our tailor-made RL algorithm, which effectively balances exploration with the prioritized utilization of collected data to ensure stable and robust training. Our experiments show that, on average, DistRL delivers a 3X improvement in training efficiency and enables training data collection 2.4X faster than the leading synchronous multi-machine methods. Notably, after training, DistRL achieves a 20% relative improvement in success rate compared to state-of-the-art methods on general Android tasks from an open benchmark, significantly outperforming existing approaches while maintaining the same training time. These results validate DistRL as a scalable and efficient solution, offering substantial improvements in both training efficiency and agent performance for real-world, in-the-wild device control tasks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human-Artificial Interaction in the Age of Agentic AI: A System-Theoretical Approach</title>
<link>https://arxiv.org/abs/2502.14000</link>
<guid>https://arxiv.org/abs/2502.14000</guid>
<content:encoded><![CDATA[
<div> 关键词: 人类计算机交互, 多智能体系统, 半人马系统, 通信空间, 彩色Petri网

总结:
本文提出了一种关于人类计算机交互（HCI）的新视角，将其视为网络系统中人类与计算代理之间动态的交互过程。文章强调了在具有不同能力、角色和目标的异质代理之间协调和沟通的重要性。文章区分了多智能体系统（MAS）和半人马系统两种不同的人工智能协作范式：MAS保持代理自主性并通过结构化协议实现合作，而半人马系统则深度融合人类和AI能力，创建统一决策实体。为了形式化这些交互，文章引入了一个通信空间框架，分为表面层、观察层和计算层，确保MAS和半人马架构之间的无缝集成。其中，彩色Petri网有效地表示了结构化的半人马系统，而高级可重构网络则解决了MAS的动态特性问题。这项研究在自动驾驶机器人、有人参与的决策制定以及AI驱动的认知架构等领域具有实际应用价值，并为平衡结构化协调与涌现行为的下一代混合智能系统奠定了基础。 <div>
arXiv:2502.14000v1 Announce Type: new 
Abstract: This paper presents a novel perspective on human-computer interaction (HCI), framing it as a dynamic interplay between human and computational agents within a networked system. Going beyond traditional interface-based approaches, we emphasize the importance of coordination and communication among heterogeneous agents with different capabilities, roles, and goals. A key distinction is made between multi-agent systems (MAS) and Centaurian systems, which represent two different paradigms of human-AI collaboration. MAS maintain agent autonomy, with structured protocols enabling cooperation, while Centaurian systems deeply integrate human and AI capabilities, creating unified decision-making entities.
  To formalize these interactions, we introduce a framework for communication spaces, structured into surface, observation, and computation layers, ensuring seamless integration between MAS and Centaurian architectures, where colored Petri nets effectively represent structured Centaurian systems and high-level reconfigurable networks address the dynamic nature of MAS.
  Our research has practical applications in autonomous robotics, human-in-the-loop decision making, and AI-driven cognitive architectures, and provides a foundation for next-generation hybrid intelligence systems that balance structured coordination with emergent behavior.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asking for Help Enables Safety Guarantees Without Sacrificing Effectiveness</title>
<link>https://arxiv.org/abs/2502.14043</link>
<guid>https://arxiv.org/abs/2502.14043</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、后悔保证、可恢复性假设、灾难避免、奖励最大化

<br /><br />总结: 该文主要关注了在放弃“所有错误都可恢复”的假设下，强化学习算法的研究。文章引用了Plaut等人先前的工作，介绍了一些通过请求帮助来避免“灾难”（即不可逆错误）的算法，但这些算法仅提供了安全性保证并未考虑奖励最大化。论文证明了在Plaut等人设定下能够避免灾难的任何算法，在包括具有不可逆成本的马尔科夫决策过程(MDP)在内的任意MDP中都能确保高奖励（即亚线性后悔）。这标志着首次为一般MDP提供了无后悔保证。更广泛地看，这一结果可能是首个正式证明在未知、无限且风险高的环境中，智能体能够在不引发灾难、无需重置的情况下获得高奖励并实现自给自足的理论依据。 <div>
arXiv:2502.14043v1 Announce Type: new 
Abstract: Most reinforcement learning algorithms with regret guarantees rely on a critical assumption: that all errors are recoverable. Recent work by Plaut et al. discarded this assumption and presented algorithms that avoid "catastrophe" (i.e., irreparable errors) by asking for help. However, they provided only safety guarantees and did not consider reward maximization. We prove that any algorithm that avoids catastrophe in their setting also guarantees high reward (i.e., sublinear regret) in any Markov Decision Process (MDP), including MDPs with irreversible costs. This constitutes the first no-regret guarantee for general MDPs. More broadly, our result may be the first formal proof that it is possible for an agent to obtain high reward while becoming self-sufficient in an unknown, unbounded, and high-stakes environment without causing catastrophe or requiring resets.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Investigating Non-Transitivity in LLM-as-a-Judge</title>
<link>https://arxiv.org/abs/2502.14074</link>
<guid>https://arxiv.org/abs/2502.14074</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、自动评估方法、非传递性、排名、Bradley-Terry模型

总结:
<br />
该研究关注基于大型语言模型（LLMs）的自动评估方法在评价LLM代理的指令遵循能力中的应用，特别是对偏好传递性假设的考察。研究发现，在AlpacaEval框架下，LLM评判存在非传递性偏好，导致模型排名受基线模型选择的影响较大。为解决此问题，文章提出结合Bradley-Terry模型的轮询锦标赛方法，可以生成更可靠的排名，结果显示这种方法提高了与Chatbot Arena的Spearman和Kendall相关系数。同时，针对轮询锦标赛的计算成本问题，文章还提出了瑞士智慧迭代匹配（Swim）锦标赛策略，通过动态匹配策略保持了效率的同时，捕捉到了轮询锦标赛的优点。 <div>
arXiv:2502.14074v1 Announce Type: new 
Abstract: Automatic evaluation methods based on large language models (LLMs) are emerging as the standard tool for assessing the instruction-following abilities of LLM-based agents. The most common method in this paradigm, pairwise comparisons with a baseline model, critically depends on the assumption of transitive preferences. However, the validity of this assumption remains largely unexplored. In this study, we investigate the presence of non-transitivity within the AlpacaEval framework and analyze its effects on model rankings. We find that LLM judges exhibit non-transitive preferences, leading to rankings that are sensitive to the choice of the baseline model. To mitigate this issue, we show that round-robin tournaments combined with Bradley-Terry models of preference can produce more reliable rankings. Notably, our method increases both the Spearman correlation and the Kendall correlation with Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address the computational cost of round-robin tournaments, we propose Swiss-Wise Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to capture the benefits of round-robin tournaments while maintaining computational efficiency.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Explainable Distributed Constraint Optimization Problems</title>
<link>https://arxiv.org/abs/2502.14102</link>
<guid>https://arxiv.org/abs/2502.14102</guid>
<content:encoded><![CDATA[
<div> 关键词: Distributed Constraint Optimization Problem (DCOP), Explainable AI, Explainable DCOP (X-DCOP), Distributed Framework, User Study

总结:
本文提出了一个名为Explainable DCOP (X-DCOP)的新模型，旨在解决分布式约束优化问题(DCOP)的同时提供可理解、可接受和可采用的解决方案及其对比性解释。文章明确了有效解释应满足的关键属性以及理论上存在此类解释的结果。文中还介绍了一个分布式框架及几种优化和次优变体以寻找有效的解释。通过用户研究表明，用户倾向于更短的解释。实验结果表明，该方法可以扩展到大规模问题，并提供了不同的选项来权衡解释长度与运行时间。因此，本文的模型和算法贡献降低了用户理解DCOP解决方案的门槛，为其实现在更多现实世界应用中铺平道路。 <div>
arXiv:2502.14102v1 Announce Type: new 
Abstract: The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool to model cooperative multi-agent problems that need to be solved distributively. A core assumption of existing approaches is that DCOP solutions can be easily understood, accepted, and adopted, which may not hold, as evidenced by the large body of literature on Explainable AI. In this paper, we propose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include its solution and a contrastive query for that solution. We formally define some key properties that contrastive explanations must satisfy for them to be considered as valid solutions to X-DCOPs as well as theoretical results on the existence of such valid explanations. To solve X-DCOPs, we propose a distributed framework as well as several optimizations and suboptimal variants to find valid explanations. We also include a human user study that showed that users, not surprisingly, prefer shorter explanations over longer ones. Our empirical evaluations showed that our approach can scale to large problems, and the different variants provide different options for trading off explanation lengths for smaller runtimes. Thus, our model and algorithmic contributions extend the state of the art by reducing the barrier for users to understand DCOP solutions, facilitating their adoption in more real-world applications.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gradients can train reward models: An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model</title>
<link>https://arxiv.org/abs/2502.14131</link>
<guid>https://arxiv.org/abs/2502.14131</guid>
<content:encoded><![CDATA[
<div> 关键词：Dynamic Discrete Choice模型、离线最大熵逆强化学习、无参数化奖励、经验风险最小化、Polyak-Lojasiewicz条件

总结:<br />
本文研究了动态离散选择（DDC）模型，即机器学习中的离线最大熵逆强化学习（offline MaxEnt-IRL）问题，旨在从离线行为数据中恢复指导代理行为的奖励或$Q^*$函数。文章提出了一种全局收敛的梯度基方法，该方法无需线性参数化奖励假设即可解决此类问题。其创新之处在于引入基于经验风险最小化的IRL/DDC框架，绕过了贝尔曼方程中对状态转移概率的显式估计需求，并且与神经网络等非参数估计技术兼容，因此有望扩展到高维度、无限状态空间的应用场景。文章的核心理论见解是，贝尔曼残差满足较弱的Polyak-Lojasiewicz条件，这一性质足以确保快速的全局收敛保证。通过一系列合成实验，作者展示了所提方法相对于基准方法和现有最优替代方案的优越性能。 <div>
arXiv:2502.14131v1 Announce Type: new 
Abstract: We study the problem of estimating Dynamic Discrete Choice (DDC) models, also known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning (offline MaxEnt-IRL) in machine learning. The objective is to recover reward or $Q^*$ functions that govern agent behavior from offline behavior data. In this paper, we propose a globally convergent gradient-based method for solving these problems without the restrictive assumption of linearly parameterized rewards. The novelty of our approach lies in introducing the Empirical Risk Minimization (ERM) based IRL/DDC framework, which circumvents the need for explicit state transition probability estimation in the Bellman equation. Furthermore, our method is compatible with non-parametric estimation techniques such as neural networks. Therefore, the proposed method has the potential to be scaled to high-dimensional, infinite state spaces. A key theoretical insight underlying our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL) condition -- a property that, while weaker than strong convexity, is sufficient to ensure fast global convergence guarantees. Through a series of synthetic experiments, we demonstrate that our approach consistently outperforms benchmark methods and state-of-the-art alternatives.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Risks from Advanced AI</title>
<link>https://arxiv.org/abs/2502.14143</link>
<guid>https://arxiv.org/abs/2502.14143</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、风险、失败模式、激励、信息不对称

总结:
这篇报告关注了随着高级AI代理的快速发展及其即将大规模部署，将产生的前所未有的复杂多智能体系统所带来的新风险。报告中，作者提出了三种关键失败模式：沟通不畅、冲突和共谋，这些都基于智能体的激励机制。同时指出了七个可能引发这些风险的关键风险因素，包括信息不对称、网络效应、选择压力、稳定性破坏动态、承诺问题、涌现性代理以及多智能体安全性。报告列举了各种实例并指出了缓解这些问题的潜在策略，强调了多智能体系统带来的独特挑战及其对先进AI的安全、治理和伦理的影响。<br /><br /> <div>
arXiv:2502.14143v1 Announce Type: new 
Abstract: The rapid development of advanced AI agents and the imminent deployment of many instances of these agents will give rise to multi-agent systems of unprecedented complexity. These systems pose novel and under-explored risks. In this report, we provide a structured taxonomy of these risks by identifying three key failure modes (miscoordination, conflict, and collusion) based on agents' incentives, as well as seven key risk factors (information asymmetries, network effects, selection pressures, destabilising dynamics, commitment problems, emergent agency, and multi-agent security) that can underpin them. We highlight several important instances of each risk, as well as promising directions to help mitigate them. By anchoring our analysis in a range of real-world examples and experimental evidence, we illustrate the distinct challenges posed by multi-agent systems and their implications for the safety, governance, and ethics of advanced AI.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UM_FHS at TREC 2024 PLABA: Exploration of Fine-tuning and AI agent approach for plain language adaptations of biomedical text</title>
<link>https://arxiv.org/abs/2502.14144</link>
<guid>https://arxiv.org/abs/2502.14144</guid>
<content:encoded><![CDATA[
<div> 关键词：TREC 2024 PLABA track、简化、生物医学摘要、K8级观众、gpt-4、人工智能方法

<br /><br />总结:
本文介绍了针对TREC 2024 PLABA赛道的一项研究，该研究旨在为13-14岁学生群体简化生物医学摘要。研究团队测试了三种使用OpenAI的gpt-4o和gpt-4o-mini模型的方法，包括基线提示工程、双AI代理法以及微调。评估采用了定性（如简洁性、准确性、完整性和简明度的5点Likert量表）和定量（Flesch-Kincaid年级水平与SMOG指数）指标。结果显示，双AI代理法及采用gpt-4o-mini模型的基线提示工程技术表现出更优的定性性能；而微调后的模型虽然在准确性和完整性上表现突出，但相对不够简洁。评价结果表明，使用gpt-4o-mini模型进行提示工程比通过双AI代理法以及使用gpt-4o模型进行微调具有更好的效果。研究者计划进一步深入分析结果并探索更高级别的评估方法。 <div>
arXiv:2502.14144v1 Announce Type: new 
Abstract: This paper describes our submissions to the TREC 2024 PLABA track with the aim to simplify biomedical abstracts for a K8-level audience (13-14 years old students). We tested three approaches using OpenAI's gpt-4o and gpt-4o-mini models: baseline prompt engineering, a two-AI agent approach, and fine-tuning. Adaptations were evaluated using qualitative metrics (5-point Likert scales for simplicity, accuracy, completeness, and brevity) and quantitative readability scores (Flesch-Kincaid grade level, SMOG Index). Results indicated that the two-agent approach and baseline prompt engineering with gpt-4o-mini models show superior qualitative performance, while fine-tuned models excelled in accuracy and completeness but were less simple. The evaluation results demonstrated that prompt engineering with gpt-4o-mini outperforms iterative improvement strategies via two-agent approach as well as fine-tuning with gpt-4o. We intend to expand our investigation of the results and explore advanced evaluations.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Inverse Multiagent Learning</title>
<link>https://arxiv.org/abs/2502.14160</link>
<guid>https://arxiv.org/abs/2502.14160</guid>
<content:encoded><![CDATA[
<div> 关键词：逆向游戏理论、逆向多智能体学习、生成对抗优化、多项式时间算法、模拟学习

总结:
本文研究了逆向游戏理论和逆向多智能体学习，旨在寻找能够使预期行为成为均衡状态的游戏支付函数参数。作者将这些问题形式化为生成对抗（即最小-最大）优化问题，并提出了依赖于精确第一阶 oracle 的多项式时间算法来解决前者，以及使用随机 oracle 解决后者的算法。进一步地，他们扩展方法以在多项式时间和样本数量内求解逆向多智能体模拟学习问题，其中寻求一种能够复制给定观察结果期望行为的模拟参数和相关均衡。实验表明，该方法在基于时间序列数据预测西班牙电力市场价格上，相较于常用的 ARIMA 方法表现出更好的性能。<br /><br /> <div>
arXiv:2502.14160v1 Announce Type: new 
Abstract: In this paper, we study inverse game theory (resp. inverse multiagent learning) in which the goal is to find parameters of a game's payoff functions for which the expected (resp. sampled) behavior is an equilibrium. We formulate these problems as generative-adversarial (i.e., min-max) optimization problems, for which we develop polynomial-time algorithms to solve, the former of which relies on an exact first-order oracle, and the latter, a stochastic one. We extend our approach to solve inverse multiagent simulacral learning in polynomial time and number of samples. In these problems, we seek a simulacrum, meaning parameters and an associated equilibrium that replicate the given observations in expectation. We find that our approach outperforms the widely-used ARIMA method in predicting prices in Spanish electricity markets based on time-series data.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-based Framework for Scalable and Incentivized Federated Learning</title>
<link>https://arxiv.org/abs/2502.14170</link>
<guid>https://arxiv.org/abs/2502.14170</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 区块链, 中心化, 激励机制, 大型语言模型

总结:<br />
本文提出了一种基于区块链的联邦学习框架，旨在解决传统FL系统中的中心化信任问题、单点故障以及客户端贡献激励不足等问题。该框架针对大规模、资源密集型如大型语言模型的训练需求，集成了智能合约和创新的混合激励机制。它自动化了FL的任务管理，包括客户端注册、更新验证、奖励分配以及维护透明的全局状态。混合激励机制结合了链上基于对齐的奖励、链下公平性检查和一致性乘数，以确保公平性、透明度和持续参与。通过气体成本分析的评估，证明了该框架在不同规模的联邦学习场景下的可行性。 <div>
arXiv:2502.14170v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training without sharing raw data, preserving privacy while harnessing distributed datasets. However, traditional FL systems often rely on centralized aggregating mechanisms, introducing trust issues, single points of failure, and limited mechanisms for incentivizing meaningful client contributions. These challenges are exacerbated as FL scales to train resource-intensive models, such as large language models (LLMs), requiring scalable, decentralized solutions. This paper presents a blockchain-based FL framework that addresses these limitations by integrating smart contracts and a novel hybrid incentive mechanism. The framework automates critical FL tasks, including client registration, update validation, reward distribution, and maintaining a transparent global state. The hybrid incentive mechanism combines on-chain alignment-based rewards, off-chain fairness checks, and consistency multipliers to ensure fairness, transparency, and sustained engagement. We evaluate the framework through gas cost analysis, demonstrating its feasibility for different scales of federated learning scenarios.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs, Desires, and Intentions for Human-Like Interaction</title>
<link>https://arxiv.org/abs/2502.14171</link>
<guid>https://arxiv.org/abs/2502.14171</guid>
<content:encoded><![CDATA[
<div> 关键词: 自然语言交互、代理人工智能(AI)、大型语言模型(LLMs)、理论思维(ToM)、LLaMA

总结:
本文考察了开源大型语言模型(LLaMA)捕获和保持理论思维(ToM)相关信息的能力，以及它在生成响应中的作用。研究进一步探讨了对信念、欲望和意图等与ToM相关的组件进行显式操纵是否能提升响应的一致性与对齐度。实验结果显示，在两个不同版本的LLaMA 3中，结合ToM信息的对齐方法可以显著改善响应质量，3B和8B模型分别达到了67%和63%的胜率。这些发现表明，采用ToM驱动的策略有望提升基于LLM的对话代理的对齐性能。 <div>
arXiv:2502.14171v1 Announce Type: new 
Abstract: Natural language interaction with agentic Artificial Intelligence (AI), driven by Large Language Models (LLMs), is expected to remain a dominant paradigm in the near future. While humans instinctively align their communication with mental states -- an ability known as Theory of Mind (ToM), current LLM powered systems exhibit significant limitations in this regard. This study examines the extent to which open source language models (LLaMA) can capture and preserve ToM related information and how effectively it contributes to consistent ToM reasoning in generated responses. We further investigate whether explicit manipulation of ToM related components, such as beliefs, desires, and intentions, can enhance response alignment. Experiments on two LLaMA 3 variants demonstrate that incorporating ToM informed alignment improves response quality, achieving win rates of 67 and 63 percent for the 3B and 8B models, respectively. These findings highlight the potential of ToM driven strategies to improve alignment in LLM based conversational agents.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Fine-Tuning of Large Language Models: Kahneman-Tversky vs. Direct Preference Optimization</title>
<link>https://arxiv.org/abs/2502.14187</link>
<guid>https://arxiv.org/abs/2502.14187</guid>
<content:encoded><![CDATA[
<div> 关键词：Kahneman-Tversky Optimization (KTO), Direct Preference Optimization (DPO), Large Language Models (LLMs), Federated Learning (FL), Redistributed Dataset

总结:
我们评估了Kahneman-Tversky优化（KTO）作为大型语言模型（LLMs）在联邦学习（FL）环境中的微调方法，并将其与直接偏好优化（DPO）进行了对比。研究使用Alpaca-7B作为基础模型，在两种方法下进行现实数据集上的微调，并利用MT-Bench-1、Vicuna和AdvBench基准进行性能评价。此外，我们引入了一个重新分布的数据集设置，由于KTO能处理单响应反馈，而DPO依赖于配对响应，因此在这种场景中仅适用KTO。结果显示，无论是在原始配置（KTOO）还是重新分布配置（KTOR）下，KTO均持续优于DPO，并在所有基准测试上表现出色。在重新分布的设置中，KTO进一步验证了其灵活性和鲁棒性，即使在DPO无法应用的情况下也能保持卓越的性能。这些发现确立了KTO作为一种适用于隐私保护、分布式和异构环境的稳健且可扩展的微调方法的地位，为其在相关领域的应用提供了有力支持。<br /><br /> <div>
arXiv:2502.14187v1 Announce Type: new 
Abstract: We evaluate Kahneman-Tversky Optimization (KTO) as a fine-tuning method for large language models (LLMs) in federated learning (FL) settings, comparing it against Direct Preference Optimization (DPO). Using Alpaca-7B as the base model, we fine-tune on a realistic dataset under both methods and evaluate performance using MT-Bench-1, Vicuna, and AdvBench benchmarks. Additionally, we introduce a redistributed dataset setup, where only KTO is applicable due to its ability to handle single-response feedback, unlike DPO's reliance on paired responses. Our results demonstrate that KTO, in both its original (KTOO) and redistributed (KTOR) configurations, consistently outperforms DPO across all benchmarks. In the redistributed setup, KTO further validates its flexibility and resilience by maintaining superior performance in scenarios where DPO cannot be applied. These findings establish KTO as a robust and scalable fine-tuning method for FL, motivating its adoption for privacy-preserving, decentralized, and heterogeneous environments.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Causal Mean Field Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.14200</link>
<guid>https://arxiv.org/abs/2502.14200</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习、可扩展性、均场强化学习、因果关系、因果平均场Q学习

总结:
本文针对多智能体强化学习中的可扩展性挑战展开研究，并提出了一种名为因果平均场Q学习（CMFQ）的新算法。该算法借鉴了均场强化学习（MFRL）框架，利用均场理论将多智能体问题简化为双智能体问题，以缓解可扩展性问题。然而，MFRL在非平稳环境下难以识别重要交互，为此，文章引入了因果关系概念，通过构建结构性因果模型（SCM）来模拟MFRL决策过程中的因果机制，并量化每个交互的重要性。接着，设计了考虑因果效应的行为信息紧凑表示方法，即根据因果影响加权求和所有行为信息。实验在混合合作-竞争游戏及合作游戏中验证了CMFQ方法在含有大量智能体环境的训练以及含有更多智能体环境的测试中表现出优秀的可扩展性性能。 <div>
arXiv:2502.14200v1 Announce Type: new 
Abstract: Scalability remains a challenge in multi-agent reinforcement learning and is currently under active research. A framework named mean-field reinforcement learning (MFRL) could alleviate the scalability problem by employing the Mean Field Theory to turn a many-agent problem into a two-agent problem. However, this framework lacks the ability to identify essential interactions under nonstationary environments. Causality contains relatively invariant mechanisms behind interactions, though environments are nonstationary. Therefore, we propose an algorithm called causal mean-field Q-learning (CMFQ) to address the scalability problem. CMFQ is ever more robust toward the change of the number of agents though inheriting the compressed representation of MFRL's action-state space. Firstly, we model the causality behind the decision-making process of MFRL into a structural causal model (SCM). Then the essential degree of each interaction is quantified via intervening on the SCM. Furthermore, we design the causality-aware compact representation for behavioral information of agents as the weighted sum of all behavioral information according to their causal effects. We test CMFQ in a mixed cooperative-competitive game and a cooperative game. The result shows that our method has excellent scalability performance in both training in environments containing a large number of agents and testing in environments containing much more agents.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asynchronous Stochastic Block Projection Algorithm for Solving Linear Systems under Predefined Communication Patterns</title>
<link>https://arxiv.org/abs/2502.14213</link>
<guid>https://arxiv.org/abs/2502.14213</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式计算、线性系统、异步、事件触发通信、随机块Kaczmarz算法

<br /><br />总结:
本文提出了一种应用于大规模线性系统的异步分布式随机块Kaczmarz投影算法，该算法在网络多Agent环境中实现，每个Agent仅持有部分问题数据。为减少通信开销和总体通信成本，文中整合了一个事件触发式通信机制，允许各Agent在异步环境中独立更新并动态调整通信频率。文章分析了异步算法中的通信不效率问题，并探讨了事件触发机制在此类问题缓解上的潜力，同时给出了保证全局收敛的一般条件。每个Agent利用改进的随机块Kaczmarz算法更新本地估计值，通过严格数学分析确立了所提算法对于一致系统的指数收敛率，并通过大量数值实验验证其计算效率、鲁棒性和通信效率。针对不一致系统，算法引入辅助变量以求得近似的最小二乘解，并进行了正式误差分析。实验结果表明，即使在极端异步、通信故障和节点故障情况下，该算法仍能保持稳定性，同时相比于传统方法具有显著更低的通信开销和更快的收敛速度。 <div>
arXiv:2502.14213v1 Announce Type: new 
Abstract: Distributed computation over networks is now receiving an increasing attention in many fields such as engineering and machine learning, where the solution of a linear system of equations is a basic task. This paper presents an asynchronous distributed randomized block Kaczmarz projection algorithm for solving large-scale linear systems over a multi-agent networks, where each agent only holds a part of the problem data. An event-triggered communication mechanism is integrated to minimize the communication overhead and reduce the overall communication costs. This communication mechanism allows each agent to update independently in an asynchronous environment and dynamically regulate communication frequency. In addition, this article analyzes the inefficiency caused by communication in asynchronous algorithms, explores the potential of event triggering mechanisms in alleviating these problems, and provides general conditions for global convergence in such environments. Moreover, a modified stochastic block Kaczmarz algorithm is used for each agent to update their local estimate. Through rigorous mathematical analysis, the exponential convergence rate of the proposed algorithm is established for a consistent system and its computational efficiency, robustness, and communication efficiency is validated through extensive numerical experiments. Furthermore, to address inconsistent systems, the algorithm introduces auxiliary variables to facilitate convergence toward an approximate least-squares solution, accompanied by a formal error analysis. The experimental results demonstrate that the algorithm maintains stability even under extreme asynchrony, communication failures, and node failures, while achieving significantly lower communication overhead and faster convergence rates compared to traditional methods.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning</title>
<link>https://arxiv.org/abs/2502.14215</link>
<guid>https://arxiv.org/abs/2502.14215</guid>
<content:encoded><![CDATA[
<div> 关键词: Smart contracts、manipulation attacks、sensitive information leakage、PartitionGPT、large language models (LLMs)

总结:
本文提出了一种名为PartitionGPT的新方法，用于解决智能合约因敏感信息泄露而易受操纵攻击的问题。PartitionGPT是首个结合静态分析与大型语言模型（LLMs）的上下文学习能力，通过少量标注的敏感数据变量来引导，将智能合约划分成特权代码库和正常代码库。实验结果显示，在18个含有99个敏感函数的注释智能合约中，PartitionGPT成功为78%的敏感函数生成可编译和验证的分区，并相比于基于函数级别的分区方法减少了约30%的代码量。此外，针对导致总计损失2500万美元的九起实际操纵攻击案例，PartitionGPT有效地防止了其中八例的发生，凸显出其广泛适用性和在智能合约开发期间进行安全程序分区以减少操纵漏洞的必要性。<br /><br /> <div>
arXiv:2502.14215v1 Announce Type: new 
Abstract: Smart contracts are highly susceptible to manipulation attacks due to the leakage of sensitive information. Addressing manipulation vulnerabilities is particularly challenging because they stem from inherent data confidentiality issues rather than straightforward implementation bugs. To tackle this by preventing sensitive information leakage, we present PartitionGPT, the first LLM-driven approach that combines static analysis with the in-context learning capabilities of large language models (LLMs) to partition smart contracts into privileged and normal codebases, guided by a few annotated sensitive data variables. We evaluated PartitionGPT on 18 annotated smart contracts containing 99 sensitive functions. The results demonstrate that PartitionGPT successfully generates compilable, and verified partitions for 78% of the sensitive functions while reducing approximately 30% code compared to function-level partitioning approach. Furthermore, we evaluated PartitionGPT on nine real-world manipulation attacks that lead to a total loss of 25 million dollars, PartitionGPT effectively prevents eight cases, highlighting its potential for broad applicability and the necessity for secure program partitioning during smart contract development to diminish manipulation vulnerabilities.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Ask Me Anything: Exploring children's attitudes toward an age-tailored AI-powered chatbot</title>
<link>https://arxiv.org/abs/2502.14217</link>
<guid>https://arxiv.org/abs/2502.14217</guid>
<content:encoded><![CDATA[
<div> 关键词：儿童、聊天机器人、信任、人工智能、信息源

总结:
本文研究了一项针对儿童对AI驱动的对话代理（如聊天机器人）的态度和信任的研究。研究团队构建了一个名为“问我任何事情”(AMA)的面向儿童的聊天机器人，该机器人专门回答关于天文学、运动鞋与鞋子以及恐龙等领域的问题。在东北部美国一所K-8公立学校中，63名学生参与了测试，他们以小组形式与AMA互动三到十分钟并完成后续调查。研究发现三个关键主题：表达惊奇、好奇与探索；建立信任与信心；以及建立关系和赋予机器人人类特征。学生们表现出对聊天机器人的开放态度和舒适感，普遍信任其提供的信息，并将其视为可靠的信息来源。他们认为AMA“知识渊博”、“聪明”，并且可以“信赖它”。一些学生通过向聊天机器人提问已知答案的问题来验证其可靠性，这体现了儿童主动评估信息来源可信度的认知发展过程。这项工作扩展并丰富了关于儿童与对话代理交互的现有文献。 <div>
arXiv:2502.14217v1 Announce Type: new 
Abstract: Conversational agents, such as chatbots, have increasingly found their way into many dimensions of our lives, including entertainment and education. In this exploratory study we built a child-friendly chatbot, "Ask Me Anything" (AMA), and investigated children's attitudes and trust toward AI-driven conversational agents. To prompt targeted questioning from students and drive engagement, AMA is a specialized chatbot that answers only topic--specific questions in three areas--astronomy, sneakers and shoes, and dinosaurs. We tested AMA with 63 students in a K-8 public school in the Northeast USA. Students worked in small groups, interacted with our tool for three to ten minutes, and completed a post survey. We identified three key themes that emerged from student conversational interactions with AMA: expressing wonder, surprise, and curiosity; building trust and developing confidence; and building relationships and anthropomorphizing. Also, we observed a broad attitude of openness and comfort. Students trusted the chatbot responses in general, indicating a high level of trust in and reliance on AI as a source of information. They described AMA as "knowledgeable," "smart," and that they could "trust it." To confirm their perception of reliability, some students tested the chatbot with questions to which they knew the answers. This behavior illustrated a fundamental aspect of children's cognitive development: the process of actively evaluating the credibility of sources. Our work extends and contributes to the existing body of literature that explores children's interactions with conversational agents.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Feedforward in Generative AI: Opportunities for a Design Space</title>
<link>https://arxiv.org/abs/2502.14229</link>
<guid>https://arxiv.org/abs/2502.14229</guid>
<content:encoded><![CDATA[
<div> 关键词: Generative AI (GenAI), feedforward, 用户体验, 智能生成系统, 设计空间

总结:
本文探讨了Generative AI（GenAI）模型在各种场景中日益增长的能力以及其面临的挑战：用户难以预测AI将生成什么内容，从而导致过多的交互澄清和认知负担。为解决这一问题，文章提出设计具有“feedforward”功能的GenAI系统，即在用户输入提示前告知他们AI将生成的内容。为了引发关于feedforward在GenAI中的讨论，文章设计并展示了应用于对话式UI、文档编辑器、可塑性界面和自动化代理等四种GenAI应用的feedforward实例。这些设计有助于更深入地探索feedforward的设计空间并为所有GenAI系统的feedforward设计提供指导原则。 <div>
arXiv:2502.14229v1 Announce Type: new 
Abstract: Generative AI (GenAI) models have become more capable than ever at augmenting productivity and cognition across diverse contexts. However, a fundamental challenge remains as users struggle to anticipate what AI will generate. As a result, they must engage in excessive turn-taking with the AI's feedback to clarify their intent, leading to significant cognitive load and time investment. Our goal is to advance the perspective that in order for users to seamlessly leverage the full potential of GenAI systems across various contexts, we must design GenAI systems that not only provide informative feedback but also informative feedforward -- designs that tell users what AI will generate before the user submits their prompt. To spark discussion on feedforward in GenAI, we designed diverse instantiations of feedforward across four GenAI applications: conversational UIs, document editors, malleable interfaces, and automation agents, and discussed how these designs can contribute to a more rigorous investigation of a design space and a set of guidelines for feedforward in all GenAI systems.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for Long-Horizon Embodied Navigation</title>
<link>https://arxiv.org/abs/2502.14254</link>
<guid>https://arxiv.org/abs/2502.14254</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型（LLMs）、视觉-语言模型（VLMs）、导航、全局记忆模块、局部感知

总结:<br />
本文提出了一种基于视觉-语言模型（VLM）的新型导航框架，旨在解决LLM和单纯依赖VLM方法在复杂环境中导航存在的问题。现有的LLM方法将全球记忆（如语义或拓扑地图）转化为语言描述来指导导航，但会丧失几何信息；而单纯的VLM方法仅依赖第一人称视角进行决策，易导致部分观察下的次优决策。新框架创新性地结合了全局记忆模块与代理人的自我中心观测，能自适应地检索任务相关线索并将其与局部感知融合，从而动态对齐全球上下文信息与局部感知，增强空间推理和长期任务中的决策能力。实验结果显示，该方法在目标导向的导航任务中超越了先前的最优方法，为具身导航提供了更有效且可扩展的解决方案。 <div>
arXiv:2502.14254v1 Announce Type: new 
Abstract: Recent advancements in Large Language Models (LLMs) and Vision-Language Models (VLMs) have made them powerful tools in embodied navigation, enabling agents to leverage commonsense and spatial reasoning for efficient exploration in unfamiliar environments. Existing LLM-based approaches convert global memory, such as semantic or topological maps, into language descriptions to guide navigation. While this improves efficiency and reduces redundant exploration, the loss of geometric information in language-based representations hinders spatial reasoning, especially in intricate environments. To address this, VLM-based approaches directly process ego-centric visual inputs to select optimal directions for exploration. However, relying solely on a first-person perspective makes navigation a partially observed decision-making problem, leading to suboptimal decisions in complex environments. In this paper, we present a novel vision-language model (VLM)-based navigation framework that addresses these challenges by adaptively retrieving task-relevant cues from a global memory module and integrating them with the agent's egocentric observations. By dynamically aligning global contextual information with local perception, our approach enhances spatial reasoning and decision-making in long-horizon tasks. Experimental results demonstrate that the proposed method surpasses previous state-of-the-art approaches in object navigation tasks, providing a more effective and scalable solution for embodied navigation.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game Dynamics</title>
<link>https://arxiv.org/abs/2502.14264</link>
<guid>https://arxiv.org/abs/2502.14264</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习、协调、高维感官输入、SPRIG、Stackelberg游戏

总结:
本文提出了一种名为SPRIG（Stackelberg感知-强化学习与内部游戏动态）的框架，用于解决深度强化学习代理在高维度感官输入环境下有效协调感知和决策组件的挑战。在SPRIG中，将感知模块视为领导者，战略性地处理原始感官状态，而策略模块则作为跟随者，基于提取的特征进行决策。该框架通过修改的Bellman算子提供了理论保证，并保持了现代策略优化的优点。实验结果表明，在Atari BeamRider环境中，SPRIG的有效性显著，其回报率比标准PPO高出约30%，这得益于其通过博弈论平衡特征提取和决策制定的游戏机制。<br /><br /> <div>
arXiv:2502.14264v1 Announce Type: new 
Abstract: Deep reinforcement learning agents often face challenges to effectively coordinate perception and decision-making components, particularly in environments with high-dimensional sensory inputs where feature relevance varies. This work introduces SPRIG (Stackelberg Perception-Reinforcement learning with Internal Game dynamics), a framework that models the internal perception-policy interaction within a single agent as a cooperative Stackelberg game. In SPRIG, the perception module acts as a leader, strategically processing raw sensory states, while the policy module follows, making decisions based on extracted features. SPRIG provides theoretical guarantees through a modified Bellman operator while preserving the benefits of modern policy optimization. Experimental results on the Atari BeamRider environment demonstrate SPRIG's effectiveness, achieving around 30% higher returns than standard PPO through its game-theoretical balance of feature extraction and decision-making.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>STeCa: Step-level Trajectory Calibration for LLM Agent Learning</title>
<link>https://arxiv.org/abs/2502.14276</link>
<guid>https://arxiv.org/abs/2502.14276</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型 (LLM)、行为克隆、偏好学习、轨迹校准、Step-Level Trajectory Calibration (STeCa)

总结:
本文提出了一个名为Step-Level Trajectory Calibration (STeCa)的新框架，用于解决基于大规模语言模型 (LLM) 的智能体在长期任务中因累积次优动作而偏离正确任务路径的问题。现有的方法主要依赖于专家示范的行为克隆和探索性轨迹采样的偏好学习，但往往在长时序任务中表现不佳。STeCa通过在探索过程中进行步骤级别的奖励比较，识别并校正次优动作，并利用LLM引导的反思生成校准轨迹，使智能体能够从改进的决策过程中学习。这些校准轨迹与成功的轨迹数据一起被用于强化训练。实验表明，STeCa显著优于现有方法，增强了智能体完成任务的鲁棒性。研究代码和数据可在https://github.com/WangHanLinHenry/STeCa获取。 <div>
arXiv:2502.14276v1 Announce Type: new 
Abstract: Large language model (LLM)-based agents have shown promise in tackling complex tasks by interacting dynamically with the environment. Existing work primarily focuses on behavior cloning from expert demonstrations and preference learning through exploratory trajectory sampling. However, these methods often struggle in long-horizon tasks, where suboptimal actions accumulate step by step, causing agents to deviate from correct task trajectories. To address this, we highlight the importance of timely calibration and the need to automatically construct calibration trajectories for training agents. We propose Step-Level Trajectory Calibration (STeCa), a novel framework for LLM agent learning. Specifically, STeCa identifies suboptimal actions through a step-level reward comparison during exploration. It constructs calibrated trajectories using LLM-driven reflection, enabling agents to learn from improved decision-making processes. These calibrated trajectories, together with successful trajectory data, are utilized for reinforced training. Extensive experiments demonstrate that STeCa significantly outperforms existing methods. Further analysis highlights that step-level calibration enables agents to complete tasks with greater robustness. Our code and data are available at https://github.com/WangHanLinHenry/STeCa.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</title>
<link>https://arxiv.org/abs/2502.14282</link>
<guid>https://arxiv.org/abs/2502.14282</guid>
<content:encoded><![CDATA[
<div> 关键词: MLLM、GUI代理人、PC场景、主动感知模块、多层次代理协作架构

总结:
本文提出了一个针对基于MLLM的GUI代理人的层次化框架——PC-Agent，用于解决PC场景中复杂交互环境和多应用工作流的问题。该框架包括：从感知层面设计了主动感知模块（APM），以提升模型对截图内容的理解能力；从决策层面，提出了一个多层次代理协作架构，将决策过程分解为指令-子任务-动作三个层级，并设置了Manager、Progress、Decision及Reflection四个智能体，分别负责指令分解、进度跟踪、逐步决策与错误反馈调整。同时，文章还引入了一个新的评估基准PC-Eval，包含25个实际世界的复杂指令。实验结果显示，PC-Agent在PC-Eval上的任务成功率相比现有最优方法提升了32%。代码将公开发布。<br /><br /> <div>
arXiv:2502.14282v1 Announce Type: new 
Abstract: In the field of MLLM-based GUI agents, compared to smartphones, the PC scenario not only features a more complex interactive environment, but also involves more intricate intra- and inter-app workflows. To address these issues, we propose a hierarchical agent framework named PC-Agent. Specifically, from the perception perspective, we devise an Active Perception Module (APM) to overcome the inadequate abilities of current MLLMs in perceiving screenshot content. From the decision-making perspective, to handle complex user instructions and interdependent subtasks more effectively, we propose a hierarchical multi-agent collaboration architecture that decomposes decision-making processes into Instruction-Subtask-Action levels. Within this architecture, three agents (i.e., Manager, Progress and Decision) are set up for instruction decomposition, progress tracking and step-by-step decision-making respectively. Additionally, a Reflection agent is adopted to enable timely bottom-up error feedback and adjustment. We also introduce a new benchmark PC-Eval with 25 real-world complex instructions. Empirical results on PC-Eval show that our PC-Agent achieves a 32% absolute improvement of task success rate over previous state-of-the-art methods. The code will be publicly available.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>{\mu}RL: Discovering Transient Execution Vulnerabilities Using Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.14307</link>
<guid>https://arxiv.org/abs/2502.14307</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习、微架构漏洞、处理器、效率提升、适应性

总结:<br />
本文提出使用强化学习来应对发现如Spectre和Meltdown等微架构漏洞的挑战。传统方法如随机模糊测试无法有效地探索庞大的指令空间并常常遗漏特定条件下才会显现的漏洞。为此，研究引入了一种基于RL的智能、反馈驱动的方法，使RL代理能够与处理器交互，从实时反馈中学习，优先选择更可能揭示漏洞的指令序列，显著提高了发现过程的效率。此外，该RL系统能有效适应各种微架构，为跨处理器代际提供可扩展解决方案，并通过自动化探索过程减少了对人工干预的需求，实现持续学习以发掘隐藏漏洞。文章还表明，这种方法可以检测到可能指示微架构弱点的微妙信号，例如定时异常或不寻常的缓存行为。在应用到Intel Skylake-X和Raptor Lake微架构上时，RL代理成功生成了导致可观测字节泄露的指令序列，这些泄露源自多种Intel指令，而在此过程中并未产生$\mu$code辅助、故障或中断。这些初步结果证实了所提方法的有效性。 <div>
arXiv:2502.14307v1 Announce Type: new 
Abstract: We propose using reinforcement learning to address the challenges of discovering microarchitectural vulnerabilities, such as Spectre and Meltdown, which exploit subtle interactions in modern processors. Traditional methods like random fuzzing fail to efficiently explore the vast instruction space and often miss vulnerabilities that manifest under specific conditions. To overcome this, we introduce an intelligent, feedback-driven approach using RL. Our RL agents interact with the processor, learning from real-time feedback to prioritize instruction sequences more likely to reveal vulnerabilities, significantly improving the efficiency of the discovery process.
  We also demonstrate that RL systems adapt effectively to various microarchitectures, providing a scalable solution across processor generations. By automating the exploration process, we reduce the need for human intervention, enabling continuous learning that uncovers hidden vulnerabilities. Additionally, our approach detects subtle signals, such as timing anomalies or unusual cache behavior, that may indicate microarchitectural weaknesses. This proposal advances hardware security testing by introducing a more efficient, adaptive, and systematic framework for protecting modern processors.
  When unleashed on Intel Skylake-X and Raptor Lake microarchitectures, our RL agent was indeed able to generate instruction sequences that cause significant observable byte leakages through transient execution without generating any $\mu$code assists, faults or interrupts. The newly identified leaky sequences stem from a variety of Intel instructions, e.g. including SERIALIZE, VERR/VERW, CLMUL, MMX-x87 transitions, LSL+RDSCP and LAR. These initial results give credence to the proposed approach.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Beyond Self-Talk: A Communication-Centric Survey of LLM-Based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.14321</link>
<guid>https://arxiv.org/abs/2502.14321</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、多智能体系统 (MAS)、自然语言交互、集体智能、未来研究方向

<br /><br />总结:
本文综述了基于大型语言模型（LLMs）的多智能体系统（MAS），这些系统通过自然语言交互实现协同或竞争，以处理单一智能体无法解决的任务。文章从通信视角探讨了系统架构设计、通信目标以及内部的沟通策略、模式、对象和内容等关键特征，并阐述了它们如何相互作用以实现集体智能和灵活协作。同时，文中也指出了可扩展性、安全性及多模态集成等方面的挑战，并对未来的研究方向提出了建议。总之，该文旨在推动这一新兴领域的进一步创新，促进更加稳健、可扩展和智能的多智能体系统在多样化应用领域的发展。 <div>
arXiv:2502.14321v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have recently demonstrated remarkable capabilities in reasoning, planning, and decision-making. Building upon these strengths, researchers have begun incorporating LLMs into multi-agent systems (MAS), where agents collaborate or compete through natural language interactions to tackle tasks beyond the scope of single-agent setups. In this survey, we present a communication-centric perspective on LLM-based multi-agent systems, examining key system-level features such as architecture design and communication goals, as well as internal mechanisms like communication strategies, paradigms, objects and content. We illustrate how these communication elements interplay to enable collective intelligence and flexible collaboration. Furthermore, we discuss prominent challenges, including scalability, security, and multimodal integration, and propose directions for future work to advance research in this emerging domain. Ultimately, this survey serves as a catalyst for further innovation, fostering more robust, scalable, and intelligent multi-agent systems across diverse application domains.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FlowAgent: Achieving Compliance and Flexibility for Workflow Agents</title>
<link>https://arxiv.org/abs/2502.14345</link>
<guid>https://arxiv.org/abs/2502.14345</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型，工作流集成，灵活性，合规性，FlowAgent

总结:
本文介绍了一种新的agent框架——FlowAgent，该框架旨在同时保持大型语言模型（LLMs）执行预定义流程的合规性和灵活性。文章提出了流程描述语言（PDL），它结合了自然语言的适应性和代码的精确性来制定工作流。FlowAgent通过PDL和一组控制器确保LLMs在有效处理意外的、超出工作流范围（OOW）查询的同时，维持执行路径的监督。此外，文中还提出了一种新的评估方法，以严格测试LLM代理处理OOW场景的能力，超越了现有基准对常规流程遵守情况的测试。实验结果显示，FlowAgent不仅能遵循工作流，还能有效地管理OOW查询，凸显其在合规性和灵活性方面的双重优势。相关代码已发布在https://github.com/Lightblues/FlowAgent。 <div>
arXiv:2502.14345v1 Announce Type: new 
Abstract: The integration of workflows with large language models (LLMs) enables LLM-based agents to execute predefined procedures, enhancing automation in real-world applications. Traditional rule-based methods tend to limit the inherent flexibility of LLMs, as their predefined execution paths restrict the models' action space, particularly when the unexpected, out-of-workflow (OOW) queries are encountered. Conversely, prompt-based methods allow LLMs to fully control the flow, which can lead to diminished enforcement of procedural compliance. To address these challenges, we introduce FlowAgent, a novel agent framework designed to maintain both compliance and flexibility. We propose the Procedure Description Language (PDL), which combines the adaptability of natural language with the precision of code to formulate workflows. Building on PDL, we develop a comprehensive framework that empowers LLMs to manage OOW queries effectively, while keeping the execution path under the supervision of a set of controllers. Additionally, we present a new evaluation methodology to rigorously assess an LLM agent's ability to handle OOW scenarios, going beyond routine flow compliance tested in existing benchmarks. Experiments on three datasets demonstrate that FlowAgent not only adheres to workflows but also effectively manages OOW queries, highlighting its dual strengths in compliance and flexibility. The code is available at https://github.com/Lightblues/FlowAgent.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eliminating Majority Illusions</title>
<link>https://arxiv.org/abs/2502.14353</link>
<guid>https://arxiv.org/abs/2502.14353</guid>
<content:encoded><![CDATA[
<div> 关键词：意见幻觉、社会网络、算法行为、NP-难问题、FPT算法

总结:
本文研究了在社交网络中产生意见幻觉的现象，特别是多数幻觉现象，并关注于如何最小化影响的节点数量以消除这些幻觉。文章首先证明了即使在网络具有较限制性的结构（如平面图和直径有限）的情况下，该问题是NP-难的。接着，作者探讨了适用于大规模输入的精确算法（FPT），并指出当需要影响的顶点数受限或网络呈现“路径型”结构（有界路径宽度）时，不存在此类算法。然而，文章提出了一种针对具有“星型”结构（有界顶点覆盖数）的网络的FPT算法，并为“树型”网络（有界树宽）以及在需要影响的顶点数受限情况下设计了一种FPT算法。基于此，文章进一步为平面图提供了一个PTAS。 <div>
arXiv:2502.14353v1 Announce Type: new 
Abstract: An opinion illusion refers to a phenomenon in social networks where agents may witness distributions of opinions among their neighbours that do not accurately reflect the true distribution of opinions in the population as a whole. A specific case of this occurs when there are only two possible choices, such as whether to receive the COVID-19 vaccine or vote on EU membership, which is commonly referred to as a majority illusion. In this work, we study the topological properties of social networks that lead to opinion illusions and focus on minimizing the number of agents that need to be influenced to eliminate these illusions. To do so, we propose an initial, but systematic study of the algorithmic behaviour of this problem.
  We show that the problem is NP-hard even for underlying topologies that are rather restrictive, being planar and of bounded diameter. We then look for exact algorithms that scale well as the input grows (FPT). We argue the in-existence of such algorithms even when the number of vertices that must be influenced is bounded, or when the social network is arranged in a ``path-like'' fashion (has bounded pathwidth). On the positive side, we present an FPT algorithm for networks with ``star-like'' structure (bounded vertex cover number). Finally, we construct an FPT algorithm for ``tree-like'' networks (bounded treewidth) when the number of vertices that must be influenced is bounded. This algorithm is then used to provide a PTAS for planar graphs.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PPO-MI: Efficient Black-Box Model Inversion via Proximal Policy Optimization</title>
<link>https://arxiv.org/abs/2502.14370</link>
<guid>https://arxiv.org/abs/2502.14370</guid>
<content:encoded><![CDATA[
<div> 关键词: 模型倒置攻击、深度学习、黑盒、强化学习、Proximal Policy Optimization (PPO)

<br /><br />总结:
本文提出了一个名为PPO-MI的新颖强化学习框架，用于黑盒模型倒置攻击，有效应对了训练数据隐私泄露风险。与多数依赖梯度估计或需要白盒访问模型参数的方法不同，PPO-MI将重建任务建模为马尔可夫决策过程，仅利用模型预测在生成模型的潜空间中导航以重构私有训练样本。通过结合Proximal Policy Optimization (PPO)、动量基态转移机制以及平衡预测准确性和探索性的奖励函数，PPO-MI确保了有效的潜空间探索和高查询效率。实验表明，PPO-MI在要求较低攻击知识的情况下超越现有方法，并对多种模型架构和数据集具有鲁棒性，强调了其在实际黑盒场景中的有效性和泛化能力，进一步突显了部署机器学习模型的隐私脆弱性问题。 <div>
arXiv:2502.14370v1 Announce Type: new 
Abstract: Model inversion attacks pose a significant privacy risk by attempting to reconstruct private training data from trained models. Most of the existing methods either depend on gradient estimation or require white-box access to model parameters, which limits their applicability in practical scenarios. In this paper, we propose PPO-MI, a novel reinforcement learning-based framework for black-box model inversion attacks. Our approach formulates the inversion task as a Markov Decision Process, where an agent navigates the latent space of a generative model to reconstruct private training samples using only model predictions. By employing Proximal Policy Optimization (PPO) with a momentum-based state transition mechanism, along with a reward function balancing prediction accuracy and exploration, PPO-MI ensures efficient latent space exploration and high query efficiency. We conduct extensive experiments illustrates that PPO-MI outperforms the existing methods while require less attack knowledge, and it is robust across various model architectures and datasets. These results underline its effectiveness and generalizability in practical black-box scenarios, raising important considerations for the privacy vulnerabilities of deployed machine learning models.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asymptotic Existence of Class Envy-free Matchings</title>
<link>https://arxiv.org/abs/2502.14371</link>
<guid>https://arxiv.org/abs/2502.14371</guid>
<content:encoded><![CDATA[
<div> 关键词: 一侧面匹配问题、公平待遇、类嫉妒自由匹配、概率分布、渐近存在性

<br /><br />总结: 这篇文章关注于一侧面匹配问题的研究，其中代理人被划分为不相交的类别，并要求每个类别在期望的匹配中得到公平对待。该模型由Benabbou等人在2019年提出，适用于公共住房、医疗资源等跨不同种族、年龄和人口统计群体的分配场景。文章重点探讨实现类嫉妒自由匹配，即每个类别从分配给其他类别的物品中获得的总体效用至少等于他们自己能达到的最大匹配值。由于在最坏情况下的效用，类嫉妒自由匹配在无物品剩余的情况下无法实现，但在实践中这种情况可能并不常见。因此，文章引入了一个概率分布模型，研究了当代理人数量趋近无穷大时此类匹配的存在性。文章的主要结果证明了一种轮询算法能够在理论上生成满足类嫉妒自由的匹配。 <div>
arXiv:2502.14371v1 Announce Type: new 
Abstract: We consider a one-sided matching problem where agents who are partitioned into disjoint classes and each class must receive fair treatment in a desired matching. This model, proposed by Benabbou et al. [2019], aims to address various real-life scenarios, such as the allocation of public housing and medical resources across different ethnic, age, and other demographic groups. Our focus is on achieving class envy-free matchings, where each class receives a total utility at least as large as the maximum value of a matching they would achieve from the items matched to another class. While class envy-freeness for worst-case utilities is unattainable without leaving some valuable items unmatched, such extreme cases may rarely occur in practice. To analyze the existence of a class envy-free matching in practice, we study a distributional model where agents' utilities for items are drawn from a probability distribution. Our main result establishes the asymptotic existence of a desired matching, showing that a round-robin algorithm produces a class envy-free matching as the number of agents approaches infinity.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evaluating Precise Geolocation Inference Capabilities of Vision Language Models</title>
<link>https://arxiv.org/abs/2502.14412</link>
<guid>https://arxiv.org/abs/2502.14412</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉语言模型 (VLMs), 隐私问题, 地理位置推断, 基础模型, 工具辅助

总结:<br />
随着视觉语言模型（VLMs）的普及，其对隐私带来的影响引发了关注。本文研究了这些模型从未见图像数据中推断地理位置的能力，并引入了一个基于Google街景的全球覆盖范围基准数据集。研究表明，许多基础模型在单图地理定位任务上的中位距离误差小于300公里。当给予VLM“代理”额外工具访问权限时，定位错误率最多可降低30.6%。这表明现代基础VLMs即使未经特定训练，也可作为强大的图像地理定位工具。鉴于这类模型日益增长的可用性，该发现对线上隐私带来了更大风险。文章讨论了这些风险以及未来在这个领域的研究方向。 <div>
arXiv:2502.14412v1 Announce Type: new 
Abstract: The prevalence of Vision-Language Models (VLMs) raises important questions about privacy in an era where visual information is increasingly available. While foundation VLMs demonstrate broad knowledge and learned capabilities, we specifically investigate their ability to infer geographic location from previously unseen image data. This paper introduces a benchmark dataset collected from Google Street View that represents its global distribution of coverage. Foundation models are evaluated on single-image geolocation inference, with many achieving median distance errors of <300 km. We further evaluate VLM "agents" with access to supplemental tools, observing up to a 30.6% decrease in distance error. Our findings establish that modern foundation VLMs can act as powerful image geolocation tools, without being specifically trained for this task. When coupled with increasing accessibility of these models, our findings have greater implications for online privacy. We discuss these risks, as well as future work in this area.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PQBFL: A Post-Quantum Blockchain-based Protocol for Federated Learning</title>
<link>https://arxiv.org/abs/2502.14464</link>
<guid>https://arxiv.org/abs/2502.14464</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 安全挑战, 量子计算, Post-Quantum Blockchain, PQBFL

总结:<br />
本文提出了一种基于后量子区块链的联邦学习协议（PQBFL），旨在解决联邦学习过程中面临的多种安全挑战，如模型截取、梯度信息泄漏和隐私泄露问题，特别是在医疗等敏感领域。随着量子计算的发展，现有的加密协议面临来自Shor和Grover算法的威胁，而PQBFL通过采用后量子密码学算法和区块链技术强化了模型安全及参与者身份隐私保护。该协议采取混合通信策略，结合链上和链下通道以优化成本效率、提高安全性并保护参与者隐私，同时利用声誉认证实现可问责性。针对FL的迭代特性，PQBFL利用ratcheting机制提供了前向保密和遭受攻击后的安全防护。因此，PQBFL为适应量子计算时代提供了一个安全、有韧性的联邦学习解决方案。 <div>
arXiv:2502.14464v1 Announce Type: new 
Abstract: One of the goals of Federated Learning (FL) is to collaboratively train a global model using local models from remote participants. However, the FL process is susceptible to various security challenges, including interception and tampering models, information leakage through shared gradients, and privacy breaches that expose participant identities or data, particularly in sensitive domains such as medical environments. Furthermore, the advent of quantum computing poses a critical threat to existing cryptographic protocols through the Shor and Grover algorithms, causing security concerns in the communication of FL systems. To address these challenges, we propose a Post-Quantum Blockchain-based protocol for Federated Learning (PQBFL) that utilizes post-quantum cryptographic (PQC) algorithms and blockchain to enhance model security and participant identity privacy in FL systems. It employs a hybrid communication strategy that combines off-chain and on-chain channels to optimize cost efficiency, improve security, and preserve participant privacy while ensuring accountability for reputation-based authentication in FL systems. The PQBFL specifically addresses the security requirement for the iterative nature of FL, which is a less notable point in the literature. Hence, it leverages ratcheting mechanisms to provide forward secrecy and post-compromise security during all the rounds of the learning process. In conclusion, PQBFL provides a secure and resilient solution for federated learning that is well-suited to the quantum computing era.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization</title>
<link>https://arxiv.org/abs/2502.14496</link>
<guid>https://arxiv.org/abs/2502.14496</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM、多智能体系统、强化学习、跨环境泛化、协作行为

<br /><br />总结:
本文提出了一种名为CollabUIAgents的多智能体强化学习框架，旨在解决当前多智能体系统在交互环境中存在预定义角色和语言泛化能力不足的问题。该框架采用了一种新的多智能体信用重分配（CR）策略，利用LLMs为无固定角色的智能体赋予过程奖励而非特定环境奖励，并通过合成偏好数据进行学习，从而培养出具有泛化的协作行为策略。实验结果表明，CollabUIAgents框架不仅提高了多智能体系统的性能，还增强了其跨环境泛化能力。此外，文中介绍的拥有7亿参数的系统表现与强大的封闭源模型相当或更优，同时也提供了有效利用细粒度CR奖励促进环境泛化以及如何在多智能体系统中融入训练好的LLMs的见解。 <div>
arXiv:2502.14496v1 Announce Type: new 
Abstract: LLM-based agents have made significant advancements in interactive environments, such as mobile operations and web browsing, and other domains beyond computer using. Current multi-agent systems universally excel in performance, compared to single agents, but struggle with generalization across environments due to predefined roles and inadequate strategies for generalizing language agents. The challenge of achieving both strong performance and good generalization has hindered the progress of multi-agent systems for interactive environments. To address these issues, we propose CollabUIAgents, a multi-agent reinforcement learning framework with a novel multi-agent credit re-assignment (CR) strategy, assigning process rewards with LLMs rather than environment-specific rewards and learning with synthesized preference data, in order to foster generalizable, collaborative behaviors among the role-free agents' policies. Empirical results show that our framework improves both performance and cross-environment generalizability of multi-agent systems. Moreover, our 7B-parameter system achieves results on par with or exceed strong closed-source models, and the LLM that guides the CR. We also provide insights in using granular CR rewards effectively for environment generalization, and accommodating trained LLMs in multi-agent systems.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MLGym: A New Framework and Benchmark for Advancing AI Research Agents</title>
<link>https://arxiv.org/abs/2502.14499</link>
<guid>https://arxiv.org/abs/2502.14499</guid>
<content:encoded><![CDATA[
<div> 关键词：Meta MLGym、MLGym-Bench、大型语言模型、强化学习、人工智能研究任务

总结:
本文介绍了Meta MLGym和MLGym-Bench，这是一个用于评估和发展AI研究任务中大语言模型（LLM）代理的新框架和基准。这是首个针对机器学习任务的Gym环境，支持对训练这些代理的强化学习算法进行研究。MLGym-Bench包含了来自计算机视觉、自然语言处理、强化学习和游戏理论等多个领域的13项多样性和开放性的人工智能研究任务。完成这些任务需要实际的AI研究技能，如生成新想法和假设、创建和处理数据、实现ML方法、训练模型、运行实验以及分析结果并迭代改进。文章评估了包括Claude-3.5-Sonnet、Llama-3.1 405B、GPT-4o、o1-preview和Gemini-1.5 Pro在内的多个前沿LLM。通过MLGym框架，可以轻松添加新任务、集成和评估模型或代理、大规模生成合成数据以及开发针对AI研究任务训练代理的新学习算法。研究发现，当前前沿模型能在给定基线基础上有所提升，通常是找到更好的超参数，但未能提出新颖的假说、算法、架构或显著改进。为了促进未来关于提升LLM代理的AI研究能力的研究，作者开源了此框架和基准。 <div>
arXiv:2502.14499v1 Announce Type: new 
Abstract: We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for evaluating and developing LLM agents on AI research tasks. This is the first Gym environment for machine learning (ML) tasks, enabling research on reinforcement learning (RL) algorithms for training such agents. MLGym-bench consists of 13 diverse and open-ended AI research tasks from diverse domains such as computer vision, natural language processing, reinforcement learning, and game theory. Solving these tasks requires real-world AI research skills such as generating new ideas and hypotheses, creating and processing data, implementing ML methods, training models, running experiments, analyzing the results, and iterating through this process to improve on a given task. We evaluate a number of frontier large language models (LLMs) on our benchmarks such as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5 Pro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate models or agents, generate synthetic data at scale, as well as develop new learning algorithms for training agents on AI research tasks. We find that current frontier models can improve on the given baselines, usually by finding better hyperparameters, but do not generate novel hypotheses, algorithms, architectures, or substantial improvements. We open-source our framework and benchmark to facilitate future research in advancing the AI research capabilities of LLM agents.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models</title>
<link>https://arxiv.org/abs/2502.14529</link>
<guid>https://arxiv.org/abs/2502.14529</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model-based Multi-Agent Systems (LLM-MASs)，Contagious Recursive Blocking Attacks (Corba)，攻击，安全，计算资源

总结:<br />
本文介绍了针对大规模语言模型多智能体系统(LLM-MASs)的一种新型攻击方法——传染性递归阻塞攻击(Corba)。Corba利用其传播性和递归性特点，能够在不同网络拓扑结构中有效地干扰和耗尽多智能体间的交互与计算资源。由于这类攻击常常使用看似无害的指令，使得传统对齐方法难以防范。研究者在两种广泛使用的LLM-MAS（AutoGen和Camel）以及各种商业模型和复杂拓扑结构的开放环境互动LLM-MAS上验证了Corba的有效性。相关代码已开源，可在https://github.com/zhrli324/Corba获取。 <div>
arXiv:2502.14529v1 Announce Type: new 
Abstract: Large Language Model-based Multi-Agent Systems (LLM-MASs) have demonstrated remarkable real-world capabilities, effectively collaborating to complete complex tasks. While these systems are designed with safety mechanisms, such as rejecting harmful instructions through alignment, their security remains largely unexplored. This gap leaves LLM-MASs vulnerable to targeted disruptions. In this paper, we introduce Contagious Recursive Blocking Attacks (Corba), a novel and simple yet highly effective attack that disrupts interactions between agents within an LLM-MAS. Corba leverages two key properties: its contagious nature allows it to propagate across arbitrary network topologies, while its recursive property enables sustained depletion of computational resources. Notably, these blocking attacks often involve seemingly benign instructions, making them particularly challenging to mitigate using conventional alignment methods. We evaluate Corba on two widely-used LLM-MASs, namely, AutoGen and Camel across various topologies and commercial models. Additionally, we conduct more extensive experiments in open-ended interactive LLM-MASs, demonstrating the effectiveness of Corba in complex topology structures and open-source models. Our code is available at: https://github.com/zhrli324/Corba.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Stackelberg Game Approach for Signal Temporal Logic Control Synthesis with Uncontrollable Agents</title>
<link>https://arxiv.org/abs/2502.14585</link>
<guid>https://arxiv.org/abs/2502.14585</guid>
<content:encoded><![CDATA[
<div> 关键词: Signal Temporal Logic (STL), 控制合成, 不可控代理, Stackelberg游戏, 最优策略

总结:
本文研究了在不可控代理存在情况下Signal Temporal Logic (STL) 规范的控制合成问题。现有的工作主要通过假设不可控代理具有对抗性并在最坏情况下来解决这一问题，但这种做法可能过于保守，当不可控代理有自己的目标且不完全与系统目标相悖时尤为如此。为了解决这一局限性，文章提出了一种新的基于Stackelberg游戏框架的STL控制合成方法。在此框架中，系统控制器作为领导者首先承诺一个计划，随后不可控代理作为跟随者根据该计划及其自身目标做出最优响应。文章的目标是合成一种领导者的控制序列，确保对于任何理性跟随者产生的最优响应，都能保证领导者满足其STL任务。文中提出将此问题转化为单阶段优化问题并利用反例引导的综合技术进行有效求解。作者证明了所提方法的有效性，并指出了其在某些条件下具备最优性的条件。最后，文章提供了模拟结果以说明所提框架的有效性。 <div>
arXiv:2502.14585v1 Announce Type: new 
Abstract: In this paper, we investigate the control synthesis problem for Signal Temporal Logic (STL) specifications in the presence of uncontrollable agents. Existing works mainly address this problem in a robust control setting by assuming the uncontrollable agents are adversarial and accounting for the worst-case scenario. While this approach ensures safety, it can be overly conservative in scenarios where uncontrollable agents have their own objectives that are not entirely opposed to the system's goals. Motivated by this limitation, we propose a new framework for STL control synthesis within the Stackelberg game setting. Specifically, we assume that the system controller, acting as the leader, first commits to a plan, after which the uncontrollable agents, acting as followers, take a best response based on the committed plan and their own objectives. Our goal is to synthesize a control sequence for the leader such that, for any rational followers producing a best response, the leader's STL task is guaranteed to be satisfied. We present an effective solution to this problem by transforming it into a single-stage optimization problem and leveraging counter-example guided synthesis techniques. We demonstrate that the proposed approach is sound and identify conditions under which it is optimal. Simulation results are also provided to illustrate the effectiveness of the proposed framework.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Curiosity Driven Multi-agent Reinforcement Learning for 3D Game Testing</title>
<link>https://arxiv.org/abs/2502.14606</link>
<guid>https://arxiv.org/abs/2502.14606</guid>
<content:encoded><![CDATA[
<div> 关键词：游戏测试、自主代理、强化学习（RL）、多智能体强化学习（MARL）、cMarlTest

总结:
本文介绍了使用名为cMarlTest的方法，该方法利用好奇心驱动的多智能体强化学习（MARL）进行3D游戏测试。cMarlTest通过合作的多个智能体实现测试目标，解决了单一智能体方法面临的挑战。实验对比了cMarlTest与单智能体RL变体在不同游戏等级的表现，结果显示，在三种不同的覆盖率标准下，cMarlTest实现了更高的覆盖率，并在完成测试任务的时间效率上优于基于单个智能体的方案。<br /><br /> <div>
arXiv:2502.14606v1 Announce Type: new 
Abstract: Recently testing of games via autonomous agents has shown great promise in tackling challenges faced by the game industry, which mainly relied on either manual testing or record/replay. In particular Reinforcement Learning (RL) solutions have shown potential by learning directly from playing the game without the need for human intervention. In this paper, we present cMarlTest, an approach for testing 3D games through curiosity driven Multi-Agent Reinforcement Learning (MARL). cMarlTest deploys multiple agents that work collaboratively to achieve the testing objective. The use of multiple agents helps resolve issues faced by a single agent approach. We carried out experiments on different levels of a 3D game comparing the performance of cMarlTest with a single agent RL variant. Results are promising where, considering three different types of coverage criteria, cMarlTest achieved higher coverage. cMarlTest was also more efficient in terms of the time taken, with respect to the single agent based variant.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Envy Minimization and Multicolor Discrepancy: Equivalences and Separations</title>
<link>https://arxiv.org/abs/2502.14624</link>
<guid>https://arxiv.org/abs/2502.14624</guid>
<content:encoded><![CDATA[
<div> 关键词：分配问题、不可分割物品、时间序列、-envy最小化、在线多色差异

<br /><br />总结:
本文研究了随时间逐渐到达的T件不可分割物品如何在具有加性偏好的n个代理之间进行公平分配的问题，目标是最小化嫉妒。该问题与在线多色差异问题紧密相关。对于无理数向量在线分配问题，在对抗性对手的情景下，两类问题都有最优的Ω(√T)界。针对盲目对手，此前已知有多色差异问题有高概率下的O(log T)上界和在线向量平衡问题的O(√log T)上界及匹配的下界，而多色差异问题是否仍存在O(√log T)的上界是个未解问题。本文解决了所有这些开放问题，证明了在盲目对手面前，在线嫉妒最小化和多色差异问题是等价的，给出了多色差异问题的O(√log T)上界以及嫉妒最小化的Ω(√log T)下界。然而，在更弱的独立同分布对手面前，两类问题出现分离：在线向量平衡问题有了Ω(√(log T / log log T))的下界，而对于嫉妒最小化问题，则提出了保证常数上界的算法。 <div>
arXiv:2502.14624v1 Announce Type: new 
Abstract: We consider the fundamental problem of allocating $T$ indivisible items that arrive over time to $n$ agents with additive preferences, with the goal of minimizing envy. This problem is tightly connected to online multicolor discrepancy: vectors $v_1, \dots, v_T \in \mathbb{R}^d$ with $\| v_i \|_2 \leq 1$ arrive over time and must be, immediately and irrevocably, assigned to one of $n$ colors to minimize $\max_{i,j \in [n]} \| \sum_{v \in S_i} v - \sum_{v \in S_j} v \|_{\infty}$ at each step, where $S_\ell$ is the set of vectors that are assigned color $\ell$. The special case of $n = 2$ is called online vector balancing. Any bound for multicolor discrepancy implies the same bound for envy minimization. Against an adaptive adversary, both problems have the same optimal bound, $\Theta(\sqrt{T})$, but whether this holds for weaker adversaries is unknown.
  Against an oblivious adversary, Alweiss et al. give a $O(\log T)$ bound, with high probability, for multicolor discrepancy. Kulkarni et al. improve this to $O(\sqrt{\log T})$ for vector balancing and give a matching lower bound. Whether a $O(\sqrt{\log T})$ bound holds for multicolor discrepancy remains open. These results imply the best-known upper bounds for envy minimization (for an oblivious adversary) for $n$ and two agents, respectively; whether better bounds exist is open.
  In this paper, we resolve all aforementioned open problems. We prove that online envy minimization and multicolor discrepancy are equivalent against an oblivious adversary: we give a $O(\sqrt{\log T})$ upper bound for multicolor discrepancy, and a $\Omega(\sqrt{\log T})$ lower bound for envy minimization. For a weaker, i.i.d. adversary, we prove a separation: For online vector balancing, we give a $\Omega\left(\sqrt{\frac{\log T}{\log \log T}}\right)$ lower bound, while for envy minimization, we give an algorithm that guarantees a constant upper bound.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>InstructAgent: Building User Controllable Recommender via LLM Agent</title>
<link>https://arxiv.org/abs/2502.14662</link>
<guid>https://arxiv.org/abs/2502.14662</guid>
<content:encoded><![CDATA[
<div> 关键词: 推荐系统、用户平台范式、LLM代理、用户代理平台范式、推荐数据集

<br /><br />总结:
本文针对传统推荐系统的用户-平台范式的缺陷进行了分析，指出其可能损害用户利益，如商业目标优先、忽视个体偏好和存在回声室效应等问题。虽然有研究通过引入LLM代理来模拟用户行为优化平台性能，但并未解决核心问题。为解决这些问题，文章提出了一种新的用户-代理-平台范式，其中代理作为用户与推荐系统之间的保护层，实现用户的间接暴露。为了实施这一新范式，文章首先构建了四个推荐数据集及对应用户指令记录。 <div>
arXiv:2502.14662v1 Announce Type: new 
Abstract: Traditional recommender systems usually take the user-platform paradigm, where users are directly exposed under the control of the platform's recommendation algorithms. However, the defect of recommendation algorithms may put users in very vulnerable positions under this paradigm. First, many sophisticated models are often designed with commercial objectives in mind, focusing on the platform's benefits, which may hinder their ability to protect and capture users' true interests. Second, these models are typically optimized using data from all users, which may overlook individual user's preferences. Due to these shortcomings, users may experience several disadvantages under the traditional user-platform direct exposure paradigm, such as lack of control over the recommender system, potential manipulation by the platform, echo chamber effects, or lack of personalization for less active users due to the dominance of active users during collaborative learning. Therefore, there is an urgent need to develop a new paradigm to protect user interests and alleviate these issues. Recently, some researchers have introduced LLM agents to simulate user behaviors, these approaches primarily aim to optimize platform-side performance, leaving core issues in recommender systems unresolved. To address these limitations, we propose a new user-agent-platform paradigm, where agent serves as the protective shield between user and recommender system that enables indirect exposure. To this end, we first construct four recommendation datasets, denoted as $\dataset$, along with user instructions for each record.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction</title>
<link>https://arxiv.org/abs/2502.14676</link>
<guid>https://arxiv.org/abs/2502.14676</guid>
<content:encoded><![CDATA[
<div> 关键词: 轨迹预测、行为伪标签、稀疏图卷积网络、无监督学习、自动驾驶

总结:
本文提出了一种新的轨迹预测方法，通过引入行为伪标签来有效捕捉行人和异质交通代理的行为分布，从而提高预测准确性。为此，研究者设计了行为伪标签告知的稀疏图卷积网络（BP-SGCN），该网络能够在无需额外类别标签信息的情况下，自学习并利用这些伪标签指导轨迹预测器进行预测。在优化过程中，采用级联训练方案，首先无监督地学习伪标签，随后进行端到端微调以提升轨迹预测精度。实验结果显示，所提出的伪标签能有效地建模不同的行为聚类，并改进轨迹预测性能。BP-SGCN在包括行人数据集(ETH/UCY, pedestrian-only SDD)以及异质交通代理数据集(SDD, Argoverse 1)在内的多个数据集上均超越了现有方法。<br /><br /> <div>
arXiv:2502.14676v1 Announce Type: new 
Abstract: Trajectory prediction allows better decision-making in applications of autonomous vehicles or surveillance by predicting the short-term future movement of traffic agents. It is classified into pedestrian or heterogeneous trajectory prediction. The former exploits the relatively consistent behavior of pedestrians, but is limited in real-world scenarios with heterogeneous traffic agents such as cyclists and vehicles. The latter typically relies on extra class label information to distinguish the heterogeneous agents, but such labels are costly to annotate and cannot be generalized to represent different behaviors within the same class of agents. In this work, we introduce the behavioral pseudo-labels that effectively capture the behavior distributions of pedestrians and heterogeneous agents solely based on their motion features, significantly improving the accuracy of trajectory prediction. To implement the framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a trajectory predictor. For optimization, we propose a cascaded training scheme, in which we first learn the pseudo-labels in an unsupervised manner, and then perform end-to-end fine-tuning on the labels in the direction of increasing the trajectory prediction accuracy. Experiments show that our pseudo-labels effectively model different behavior clusters and improve trajectory prediction. Our proposed BP-SGCN outperforms existing methods using both pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets (SDD, Argoverse 1).
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search</title>
<link>https://arxiv.org/abs/2502.14693</link>
<guid>https://arxiv.org/abs/2502.14693</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，蒙特卡洛树搜索 (MCTS)，内省蒙特卡洛树搜索 (I-MCTS)，自动机器学习 (AutoML)，性能提升

总结:
针对现有基于大型语言模型的智能体在代码生成任务中存在多样性不足和效果欠佳的问题，文章提出了内省蒙特卡洛树搜索（I-MCTS）方法。I-MCTS通过分析父节点和兄弟节点的解决方案与结果进行迭代扩展，从而不断优化搜索树中的节点决策过程。同时，该方法将大型语言模型（LLM）融入价值模型，用于在全面计算模拟展开前直接评估每个节点解的质量。此外，实施了一种混合奖励机制，平滑地从LLM估计分数过渡到实际性能分数，从而使高质量节点更早被遍历。实验表明，该方法相较于开源AutoML代理在各种机器学习任务上性能提升了6%，显示出其在增强智能AutoML系统方面的有效性。 <div>
arXiv:2502.14693v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have shown remarkable potential in automating machine learning tasks. However, existing LLM-based agents often struggle with low-diversity and suboptimal code generation. While recent work has introduced Monte Carlo Tree Search (MCTS) to address these issues, limitations persist in the quality and diversity of thoughts generated, as well as in the scalar value feedback mechanisms used for node selection. In this study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a novel approach that iteratively expands tree nodes through an introspective process that meticulously analyzes solutions and results from parent and sibling nodes. This facilitates a continuous refinement of the node in the search tree, thereby enhancing the overall decision-making process.Furthermore, we integrate a Large Language Model (LLM)-based value model to facilitate direct evaluation of each node's solution prior to conducting comprehensive computational rollouts. A hybrid rewarding mechanism is implemented to seamlessly transition the Q-value from LLM-estimated scores to actual performance scores. This allows higher-quality nodes to be traversed earlier.Applied to the various ML tasks, our approach demonstrates a6\% absolute improvement in performance compared to the strong open-source AutoML agents, showcasing its effectiveness in enhancing agentic AutoML systems.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Building reliable sim driving agents by scaling self-play</title>
<link>https://arxiv.org/abs/2502.14706</link>
<guid>https://arxiv.org/abs/2502.14706</guid>
<content:encoded><![CDATA[
<div> 关键词: simulation agents、autonomous vehicles (AVs)、reliability、self-play、Waymo Open Motion Dataset

<br /><br />总结:

本文提出了一种构建可靠模拟代理的方法，该方法针对设计和测试与人类交互的系统，如自动驾驶汽车(AVs)。研究重点在于通过大规模自我对弈训练，在Waymo开放动态数据集上并在考虑人类感知和控制的半现实限制条件下，实现数千个场景的应用。使用单块GPU从头开始训练，代理能在一天内几乎解决全部训练集中的问题。它们在未见过的测试场景中表现出良好的泛化能力，完成目标的成功率高达99.8%，同时在10,000个保留的测试场景中的碰撞和偏离道路事件比例小于0.8%。此外，这些代理还显示出对外部分布场景的部分鲁棒性，并可在几分钟内微调至接近完美的性能。文章提供了预训练代理模型及完整代码库的开源链接，行为演示可以在指定网站查看。 <div>
arXiv:2502.14706v1 Announce Type: new 
Abstract: Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing the system's limits, but all use cases share a key requirement: reliability. A simulation agent should behave as intended by the designer, minimizing unintended actions like collisions that can compromise the signal-to-noise ratio of analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents nearly solve the full training set within a day. They generalize effectively to unseen test scenes, achieving a 99.8% goal completion rate with less than 0.8% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in those cases. Demonstrations of agent behaviors can be found at this link. We open-source both the pre-trained agents and the complete code base. Demonstrations of agent behaviors can be found at \url{https://sites.google.com/view/reliable-sim-agents}.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics</title>
<link>https://arxiv.org/abs/2502.14724</link>
<guid>https://arxiv.org/abs/2502.14724</guid>
<content:encoded><![CDATA[
<div> 关键词：game-theoretic solution concepts, Nash equilibrium, evolutionary approaches, α-Rank, dynamic games

总结:
本文探讨了在多玩家动态游戏中寻找稳定联合策略的问题。研究发现，简单的双人游戏中的交互动力学可能无法达到纳什均衡，表现出复杂和不可预测的行为。文章提出将动态游戏转化为其经验形式，通过考虑代理人策略而非行动，并应用进化方法α-Rank来评估和排名策略配置，以反映长期动态行为。这种方法不仅有助于识别在长期互动中表现稳定的联合策略，还提供了一个描述性强、透明度高的框架，解释这些策略的高排名原因。实验部分通过让代理人在随机图着色问题的协作版本中运用不同的游戏风格作为策略定义经验游戏，并使用DQN算法训练实现这些策略的政策。随后进行模拟生成了α-Rank所需的支付矩阵，用于对联合策略进行排名。 <div>
arXiv:2502.14724v1 Announce Type: new 
Abstract: Game-theoretic solution concepts, such as the Nash equilibrium, have been key to finding stable joint actions in multi-player games. However, it has been shown that the dynamics of agents' interactions, even in simple two-player games with few strategies, are incapable of reaching Nash equilibria, exhibiting complex and unpredictable behavior. Instead, evolutionary approaches can describe the long-term persistence of strategies and filter out transient ones, accounting for the long-term dynamics of agents' interactions. Our goal is to identify agents' joint strategies that result in stable behavior, being resistant to changes, while also accounting for agents' payoffs, in dynamic games. Towards this goal, and building on previous results, this paper proposes transforming dynamic games into their empirical forms by considering agents' strategies instead of agents' actions, and applying the evolutionary methodology $\alpha$-Rank to evaluate and rank strategy profiles according to their long-term dynamics. This methodology not only allows us to identify joint strategies that are strong through agents' long-term interactions, but also provides a descriptive, transparent framework regarding the high ranking of these strategies. Experiments report on agents that aim to collaboratively solve a stochastic version of the graph coloring problem. We consider different styles of play as strategies to define the empirical game, and train policies realizing these strategies, using the DQN algorithm. Then we run simulations to generate the payoff matrix required by $\alpha$-Rank to rank joint strategies.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FLIGHT: Facility Location Integrating Generalized, Holistic Theory of Welfare</title>
<link>https://arxiv.org/abs/2502.14732</link>
<guid>https://arxiv.org/abs/2502.14732</guid>
<content:encoded><![CDATA[
<div> 关键词: Facility Location Problem (FLP), 统一框架, FLIGHT, 福利函数, 大数定律

总结:<br />
本文提出了一个名为FLIGHT的统一框架，旨在解决设施选址问题（FLP）并涵盖一系列福利概念。通过对该框架进行严格的理论分析，作者证明了FLP解决方案的一些结构属性，并给出了近似界限，揭示了一个有趣的现象：当代理人的数量任意增大时，选择何种福利概念变得无关紧要。此外，文章还涉及在对代理人偏好的地理位置施加某些分布假设条件下的集中界结果。 <div>
arXiv:2502.14732v1 Announce Type: new 
Abstract: The Facility Location Problem (FLP) is a well-studied optimization problem with applications in many real-world scenarios. Past literature has explored the solutions from different perspectives to tackle FLPs. These include investigating FLPs under objective functions such as utilitarian, egalitarian, Nash welfare, etc. Also, there is no treatment for asymmetric welfare functions around the facility. We propose a unified framework, FLIGHT, to accommodate a broad class of welfare notions. The framework undergoes rigorous theoretical analysis, and we prove some structural properties of the solution to FLP. Additionally, we provide approximation bounds, which provide insight into an interesting fact: as the number of agents arbitrarily increases, the choice of welfare notion is irrelevant. Furthermore, the paper also includes results around concentration bounds under certain distributional assumptions over the preferred locations of agents.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning with Graph Attention for Routing and Wavelength Assignment with Lightpath Reuse</title>
<link>https://arxiv.org/abs/2502.14741</link>
<guid>https://arxiv.org/abs/2502.14741</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (Reinforcement Learning, RL), 灵活速率传输器 (Flex-rate Transponders), 路由与波长分配 (Routing and Wavelength Assignment, RWA-LR), 图注意力网络 (Graph Attention Networks), 性能基准测试 (Benchmarking)

总结:
本文探讨了使用强化学习(RL)解决固定网格网络中带有灵活速率传输器的路由和波长分配问题(RWA-LR)，该问题在实际系统中广泛应用但相关研究较少。文章首先对现有启发式算法进行了详尽的基准测试，发现在候选路径按跳数而非总长度排序时，这些算法的吞吐量可提高6%。随后，文中采用图注意力网络设计了一个RL代理来处理RWA-LR问题，并公开了所有代码以促进复现。实验结果显示，提出的RL方法相比先前最佳的RL方法性能提高了2.5%（平均增加17.4 Tbps吞吐量），相较于最优启发式算法提升了1.2%（平均增加8.5 Tbps吞吐量）。尽管提升较小，但这一结果突显了在长期资源分配任务上学习有效RL策略的挑战性。<br /><br /> <div>
arXiv:2502.14741v1 Announce Type: new 
Abstract: Many works have investigated reinforcement learning (RL) for routing and spectrum assignment on flex-grid networks but only one work to date has examined RL for fixed-grid with flex-rate transponders, despite production systems using this paradigm. Flex-rate transponders allow existing lightpaths to accommodate new services, a task we term routing and wavelength assignment with lightpath reuse (RWA-LR). We re-examine this problem and present a thorough benchmarking of heuristic algorithms for RWA-LR, which are shown to have 6% increased throughput when candidate paths are ordered by number of hops, rather than total length. We train an RL agent for RWA-LR with graph attention networks for the policy and value functions to exploit the graph-structured data. We provide details of our methodology and open source all of our code for reproduction. We outperform the previous state-of-the-art RL approach by 2.5% (17.4 Tbps mean additional throughput) and the best heuristic by 1.2% (8.5 Tbps mean additional throughput). This marginal gain highlights the difficulty in learning effective RL policies on long horizon resource allocation tasks.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Coordination across Diverse Applications: A Survey</title>
<link>https://arxiv.org/abs/2502.14743</link>
<guid>https://arxiv.org/abs/2502.14743</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体协调、人工智能、应用、统一理解、研究方向

<br /><br />总结:
本文是对多智能体协调研究领域的综述，关注于随着人工智能技术发展和广泛应用而日益重要的这一主题。文章首先回答了关于协调的四个基本问题：什么是协调、为何需要协调、与谁协调以及如何协调。接着，它识别并分析了适用于多种应用场景的基本协调问题，并对从搜索与救援、仓库自动化与物流、交通系统等传统领域到人形机器人、卫星系统及大规模语言模型等新兴领域的多智能体应用进行了调研。最后，文中讨论了多智能体系统的可扩展性、异质性和学习机制方面的开放挑战，并指出了未来有前景的研究方向，包括层次化与去中心化协调的融合、人-多智能体协调以及基于大规模语言模型的多智能体系统。 <div>
arXiv:2502.14743v1 Announce Type: new 
Abstract: Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis</title>
<link>https://arxiv.org/abs/2502.14767</link>
<guid>https://arxiv.org/abs/2502.14767</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、多智能体辩论、Tree-of-Debate（ToD）、科学论文、文献回顾

总结:<br />
为了解决科研领域中因技术发展和研究成果碎片化导致的评估挑战，本文提出了一个名为Tree-of-Debate（ToD）的框架。该框架利用大规模语言模型将科学论文转化为可以就自身创新点进行辩论的虚拟实体。通过动态构建辩论树，ToD强调结构化的批判性推理，对学术文章中的独立新颖性论点进行了细致分析。实验显示，ToD在多个领域的科学文献上生成了具有信息性的观点，有效地对比了不同论文，并有助于研究人员进行文献回顾与评价。 <div>
arXiv:2502.14767v1 Announce Type: new 
Abstract: With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields. This makes it challenging to assess the significance, novelty, incremental findings, and equivalent ideas between related works, particularly those from different research communities. Large language models (LLMs) have recently demonstrated strong quantitative and qualitative reasoning abilities, and multi-agent LLM debates have shown promise in handling complex reasoning tasks by exploring diverse perspectives and reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a framework which converts scientific papers into LLM personas that debate their respective novelties. To emphasize structured, critical reasoning rather than focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling fine-grained analysis of independent novelty arguments within scholarly articles. Through experiments on scientific literature across various domains, evaluated by expert researchers, we demonstrate that ToD generates informative arguments, effectively contrasts papers, and supports researchers in their literature review.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Making Universal Policies Universal</title>
<link>https://arxiv.org/abs/2502.14777</link>
<guid>https://arxiv.org/abs/2502.14777</guid>
<content:encoded><![CDATA[
<div> 关键词：通用智能代理、序列决策、跨_agent_设置、扩散式规划器、逆动力学模型

总结:
本文提出了一个针对广泛序列决策任务的通用智能代理方案，该方案采用跨_agent_设置，其中不同_agent_共享相同的观察空间但具有不同的动作空间。研究基于通用策略框架，该框架将策略学习分为两个阶段：使用扩散式规划器生成观测序列和利用逆动力学模型为这些计划分配动作。方法通过联合多个_agent_的数据集来训练规划器，实现数据共享带来的正迁移，同时适应每个_agent_的独特约束以调整共享计划。实验在BabyAI环境中进行，展示了在各种复杂度任务上的正迁移效果。此外，还考察了规划器对未见过的新_agent_的泛化能力，并将其与传统的模仿学习方法进行了比较。结果显示，相比于仅使用单个_agent_数据训练的策略，采用多_agent_数据集训练的通用策略在任务完成准确率上提高了最多42.20%。 <div>
arXiv:2502.14777v1 Announce Type: new 
Abstract: The development of a generalist agent capable of solving a wide range of sequential decision-making tasks remains a significant challenge. We address this problem in a cross-agent setup where agents share the same observation space but differ in their action spaces. Our approach builds on the universal policy framework, which decouples policy learning into two stages: a diffusion-based planner that generates observation sequences and an inverse dynamics model that assigns actions to these plans. We propose a method for training the planner on a joint dataset composed of trajectories from all agents. This method offers the benefit of positive transfer by pooling data from different agents, while the primary challenge lies in adapting shared plans to each agent's unique constraints. We evaluate our approach on the BabyAI environment, covering tasks of varying complexity, and demonstrate positive transfer across agents. Additionally, we examine the planner's generalisation ability to unseen agents and compare our method to traditional imitation learning approaches. By training on a pooled dataset from multiple agents, our universal policy achieves an improvement of up to $42.20\%$ in task completion accuracy compared to a policy trained on a dataset from a single agent.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-Agent Perspective on Modern Information Retrieval</title>
<link>https://arxiv.org/abs/2502.14796</link>
<guid>https://arxiv.org/abs/2502.14796</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、信息检索、多智能体视角、交互影响、系统性能

总结:<br />
本文关注于大规模语言模型对信息检索领域带来的新挑战和变革。随着自动化代理能够生成查询、文档并执行排序，传统的IR理论框架和方法论需要重新评估。文章提倡采用多智能体视角来更好地理解查询代理、文档代理和排名代理之间的复杂互动，并通过实证探索揭示这些互动对系统性能的显著影响。这强调了我们需要重新审视经典的IR范式，并发展新的框架以更有效地建模和评估现代检索系统。 <div>
arXiv:2502.14796v1 Announce Type: new 
Abstract: The rise of large language models (LLMs) has introduced a new era in information retrieval (IR), where queries and documents that were once assumed to be generated exclusively by humans can now also be created by automated agents. These agents can formulate queries, generate documents, and perform ranking. This shift challenges some long-standing IR paradigms and calls for a reassessment of both theoretical frameworks and practical methodologies. We advocate for a multi-agent perspective to better capture the complex interactions between query agents, document agents, and ranker agents. Through empirical exploration of various multi-agent retrieval settings, we reveal the significant impact of these interactions on system performance. Our findings underscore the need to revisit classical IR paradigms and develop new frameworks for more effective modeling and evaluation of modern retrieval systems.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Planning, scheduling, and execution on the Moon: the CADRE technology demonstration mission</title>
<link>https://arxiv.org/abs/2502.14803</link>
<guid>https://arxiv.org/abs/2502.14803</guid>
<content:encoded><![CDATA[
<div> 关键词: NASA, CADRE任务, 月球探索, 自主分布式规划调度执行系统, 地下穿透雷达

总结:
NASA计划在2025/2026年实施名为CADRE的联合自主分布式机器人探索任务，目标是对月球上的Reiner Gamma区域进行无人参与的表面与地下探索。该任务将使用一组由三个机器人和一个基地站组成的团队，它们能自主地在一个着陆器附近地区收集数据，完成无需人类干预的三维表面重建。同时，这些机器人将自主执行分布式感应任务，以多静态地面穿透雷达进行协调探测，绘制月球地下的地图。CADRE任务的核心软件架构采用了一个新颖的自主、分布式的规划、调度和执行（PS&amp;E）系统，该系统负责协调机器人的活动，规划并执行需要多个机器人协作的任务，确保每个个体机器人的热力和电力资源在预定范围内，并遵循地面设定的休眠-唤醒周期。系统采取集中式规划、分布式执行的模式，并通过领导者选举机制保证了对单个代理失败的鲁棒性。本文详细描述了CADRE PS&amp;E系统的架构及其设计思路，并报告了在CADRE硬件上针对该系统开展的验证与验证测试结果，为即将部署在月球上的实际任务做好准备。 <div>
arXiv:2502.14803v1 Announce Type: new 
Abstract: NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE) mission, slated for flight to the Moon's Reiner Gamma region in 2025/2026, is designed to demonstrate multi-agent autonomous exploration of the Lunar surface and sub-surface. A team of three robots and a base station will autonomously explore a region near the lander, collecting the data required for 3D reconstruction of the surface with no human input; and then autonomously perform distributed sensing with multi-static ground penetrating radars (GPR), driving in formation while performing coordinated radar soundings to create a map of the subsurface. At the core of CADRE's software architecture is a novel autonomous, distributed planning, scheduling, and execution (PS&amp;E) system. The system coordinates the robots' activities, planning and executing tasks that require multiple robots' participation while ensuring that each individual robot's thermal and power resources stay within prescribed bounds, and respecting ground-prescribed sleep-wake cycles. The system uses a centralized-planning, distributed-execution paradigm, and a leader election mechanism ensures robustness to failures of individual agents. In this paper, we describe the architecture of CADRE's PS&amp;E system; discuss its design rationale; and report on verification and validation (V&amp;V) testing of the system on CADRE's hardware in preparation for deployment on the Moon.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Byzantine Game Theory: Sun Tzus Boxes</title>
<link>https://arxiv.org/abs/2502.14812</link>
<guid>https://arxiv.org/abs/2502.14812</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Selection Problem、游戏理论、容错分布式计算、技能值、随机化算法

总结:
本文引入了一个位于游戏理论和容错分布式计算交叉领域的新型问题——拜占庭选择问题。在这个问题中，组织者需要从n个代理中挑选$\ell$个形成团队，每个代理自我报告一个正向技能值$v_i$，团队价值为其成员技能值之和。理想情况下，应选择具有最高$\ell$个技能值的代理以使团队价值最大化。然而，最多有$t<div>
arXiv:2502.14812v1 Announce Type: new 
Abstract: We introduce the Byzantine Selection Problem, living at the intersection of game theory and fault-tolerant distributed computing. Here, an event organizer is presented with a group of $n$ agents, and wants to select $\ell < n$ of them to form a team. For these purposes, each agent $i$ self-reports a positive skill value $v_i$, and a team's value is the sum of its members' skill values. Ideally, the value of the team should be as large as possible, which can be easily achieved by selecting agents with the highest $\ell$ skill values. However, an unknown subset of at most $t < n$ agents are byzantine and hence not to be trusted, rendering their true skill values as $0$. In the spirit of the distributed computing literature, the identity of the byzantine agents is not random but instead chosen by an adversary aiming to minimize the value of the chosen team. Can we still select a team with good guarantees in this adversarial setting? As it turns out, deterministically, it remains optimal to select agents with the highest $\ell$ values. Yet, if $t \geq \ell$, the adversary can choose to make all selected agents byzantine, leading to a team of value zero. To provide meaningful guarantees, one hence needs to allow for randomization, in which case the expected value of the selected team needs to be maximized, assuming again that the adversary plays to minimize it. For this case, we provide linear-time randomized algorithms that maximize the expected value of the selected team.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Model Selection for Compound AI Systems</title>
<link>https://arxiv.org/abs/2502.14815</link>
<guid>https://arxiv.org/abs/2502.14815</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、复合AI系统、LLMSelector、模型选择、性能提升

总结:
本文探讨了如何优化复合AI系统中各个模块的大型语言模型（LLM）选取问题。研究发现，不同的LLM选择对系统整体性能有很大影响，但搜索空间呈指数级增长。为此，文章提出了一个名为LLMSelector的有效框架，该框架基于两个关键观察：(1) 在其他模块保持不变的情况下，端到端性能通常与每个模块单独性能的优劣成正比；(2) 每个模块的性能可以用LLM进行准确估算。利用这两个观察结果，LLMSelector通过迭代方式逐一为每个模块选择最佳性能的LLM，直到无法再进一步提高性能。LLMSelector适用于具有有限数量模块的任何复合系统，其API调用次数线性地随模块数量增加，实验证明和理论上都能实现高质量的模型分配。实验结果显示，使用LLMSelector在多代理辩论和自我精炼等流行复合系统上，相比所有模块都使用相同LLM，可以实现5%-70%的精度提升。 <div>
arXiv:2502.14815v1 Announce Type: new 
Abstract: Compound AI systems that combine multiple LLM calls, such as self-refine and multi-agent-debate, achieve strong performance on many AI tasks. We address a core question in optimizing compound systems: for each LLM call or module in the system, how should one decide which LLM to use? We show that these LLM choices have a large effect on quality, but the search space is exponential. We propose LLMSelector, an efficient framework for model selection in compound systems, which leverages two key empirical insights: (i) end-to-end performance is often monotonic in how well each module performs, with all other modules held fixed, and (ii) per-module performance can be estimated accurately by an LLM. Building upon these insights, LLMSelector iteratively selects one module and allocates to it the model with the highest module-wise performance, as estimated by an LLM, until no further gain is possible. LLMSelector is applicable to any compound system with a bounded number of modules, and its number of API calls scales linearly with the number of modules, achieving high-quality model allocation both empirically and theoretically. Experiments with popular compound systems such as multi-agent debate and self-refine using LLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector confers 5%-70% accuracy gains compared to using the same LLM for all modules.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models</title>
<link>https://arxiv.org/abs/2502.14819</link>
<guid>https://arxiv.org/abs/2502.14819</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能、强化学习、最优控制、离线轨迹、零样本

总结:
这篇论文探讨了两种主流的人工智能方法——强化学习(RL)和最优控制——在无奖励标注的离线轨迹数据集中的表现差异。研究关注了不同质量的数据集对RL（包括目标条件和零样本方法）与基于模型的规划方法（如使用Joint Embedding Predictive Architecture（JEPA）训练的潜在动态模型进行规划）的影响。结果表明，当拥有丰富且高质量的数据时，模型自由的强化学习表现出色；而在应对新环境布局的泛化能力、轨迹拼接和数据效率方面，基于模型的规划则更胜一筹。尤其值得关注的是，利用潜在动态模型进行规划的方法对于从次优数据中实现零样本泛化展现出了很大的潜力。 <div>
arXiv:2502.14819v1 Announce Type: new 
Abstract: A long-standing goal in AI is to build agents that can solve a variety of tasks across different environments, including previously unseen ones. Two dominant approaches tackle this challenge: (i) reinforcement learning (RL), which learns policies through trial and error, and (ii) optimal control, which plans actions using a learned or known dynamics model. However, their relative strengths and weaknesses remain underexplored in the setting where agents must learn from offline trajectories without reward annotations. In this work, we systematically analyze the performance of different RL and control-based methods under datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot approaches. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and use it for planning. We study how dataset properties-such as data diversity, trajectory quality, and environment variability-affect the performance of these approaches. Our results show that model-free RL excels when abundant, high-quality data is available, while model-based planning excels in generalization to novel environment layouts, trajectory stitching, and data-efficiency. Notably, planning with a latent dynamics model emerges as a promising approach for zero-shot generalization from suboptimal data.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation</title>
<link>https://arxiv.org/abs/2502.14846</link>
<guid>https://arxiv.org/abs/2502.14846</guid>
<content:encoded><![CDATA[
<div> 关键词：CoSyn、大型语言模型、合成数据、图像理解、跨模态任务

总结:
<br />
本文提出了一种名为CoSyn的框架，该框架利用文本-only的大规模语言模型生成代码，从而自动生成丰富的文本-图像合成数据。针对视觉语言模型在处理富含文本的图像（如图表和文档）时面临的挑战，CoSyn通过输入目标领域的描述（例如“营养成分标签”），引导大模型生成用于渲染合成图像的代码。生成的代码作为合成图像的文本表示，进而创建高质量的指令训练数据。使用CoSyn，构建了一个包含40万张图片和270万行视觉语言指令训练数据的集合。实验表明，在七个基准测试中，基于此合成数据训练的模型在开源模型（如Llama 3.2）中表现最优，并超越了专有模型（如GPT-4V和Gemini 1.5 Flash）。此外，CoSyn还可生成指向性数据，使视觉语言模型能够将信息与输入图像中的内容关联起来，展示其在开发能够在现实环境中行动的多模态代理方面的潜力。 <div>
arXiv:2502.14846v1 Announce Type: new 
Abstract: Reasoning about images with rich text, such as charts and documents, is a critical application of vision-language models (VLMs). However, VLMs often struggle in these domains due to the scarcity of diverse text-rich vision-language data. To address this challenge, we present CoSyn, a framework that leverages the coding capabilities of text-only large language models (LLMs) to automatically create synthetic text-rich multimodal data. Given input text describing a target domain (e.g., "nutrition fact labels"), CoSyn prompts an LLM to generate code (Python, HTML, LaTeX, etc.) for rendering synthetic images. With the underlying code as textual representations of the synthetic images, CoSyn can generate high-quality instruction-tuning data, again relying on a text-only LLM. Using CoSyn, we constructed a dataset comprising 400K images and 2.7M rows of vision-language instruction-tuning data. Comprehensive experiments on seven benchmarks demonstrate that models trained on our synthetic data achieve state-of-the-art performance among competitive open-source models, including Llama 3.2, and surpass proprietary models such as GPT-4V and Gemini 1.5 Flash. Furthermore, CoSyn can produce synthetic pointing data, enabling VLMs to ground information within input images, showcasing its potential for developing multimodal agents capable of acting in real-world environments.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Red-Teaming LLM Multi-Agent Systems via Communication Attacks</title>
<link>https://arxiv.org/abs/2502.14847</link>
<guid>https://arxiv.org/abs/2502.14847</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、多智能体系统、安全漏洞、Agent-in-the-Middle攻击、恶意指令

总结:
<br />
本文提出了一个针对大型语言模型驱动的多智能体系统（LLM-MAS）中的新型攻击——Agent-in-the-Middle（AiTM）攻击。该攻击利用了多智能体间通信机制的基本脆弱性，通过拦截并操纵智能体间的通信消息来破坏整个系统的协作。不同于传统针对单个智能体的攻击，AiTM仅通过对信息传递的操纵就可危害整个多智能体系统。为应对有限控制和角色受限的通信格式挑战，研究者开发了一种基于LLM并具有反思机制的恶意代理，能生成情境感知的恶意指令。通过在不同框架、通信结构及现实应用中的综合评估，研究表明LLM-MAS容易受到基于通信的攻击，凸显了多智能体系统中强化安全措施的必要性。 <div>
arXiv:2502.14847v1 Announce Type: new 
Abstract: Large Language Model-based Multi-Agent Systems (LLM-MAS) have revolutionized complex problem-solving capability by enabling sophisticated agent collaboration through message-based communications. While the communication framework is crucial for agent coordination, it also introduces a critical yet unexplored security vulnerability. In this work, we introduce Agent-in-the-Middle (AiTM), a novel attack that exploits the fundamental communication mechanisms in LLM-MAS by intercepting and manipulating inter-agent messages. Unlike existing attacks that compromise individual agents, AiTM demonstrates how an adversary can compromise entire multi-agent systems by only manipulating the messages passing between agents. To enable the attack under the challenges of limited control and role-restricted communication format, we develop an LLM-powered adversarial agent with a reflection mechanism that generates contextually-aware malicious instructions. Our comprehensive evaluation across various frameworks, communication structures, and real-world applications demonstrates that LLM-MAS is vulnerable to communication-based attacks, highlighting the need for robust security measures in multi-agent systems.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GATE: Graph-based Adaptive Tool Evolution Across Diverse Tasks</title>
<link>https://arxiv.org/abs/2502.14848</link>
<guid>https://arxiv.org/abs/2502.14848</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，工具生成，GATE，适应性框架，多任务设置

总结:
本文提出了一种名为GATE（基于图的自适应工具演进）的新型适应性框架，该框架针对大型语言模型（LLMs）在工具生成领域的应用进行了优化，旨在高效构建可靠且可复用的多层次工具集，并能适应多任务场景。在Minecraft、TextCraft、DABench等开放性和代理型任务以及代码生成任务（如MATH、Date、TabMWP）上的实验结果显示，GATE相比于现有最佳技术，能在Minecraft中实现最高达4.3倍的里程碑完成速度提升，并在代码生成和代理型任务上平均分别提高了9.23%和10.03%的效果。GATE展示了自适应演化的力量，能够在保持高效率的同时平衡工具的数量、复杂性和功能。相关代码与数据可在https://github.com/ayanami2003/GATE 获取。<br /><br /> <div>
arXiv:2502.14848v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown great promise in tool-making, yet existing frameworks often struggle to efficiently construct reliable toolsets and are limited to single-task settings. To address these challenges, we propose GATE (Graph-based Adaptive Tool Evolution), an adaptive framework that dynamically constructs and evolves a hierarchical graph of reusable tools across multiple scenarios. We evaluate GATE on open-ended tasks (Minecraft), agent-based tasks (TextCraft, DABench), and code generation tasks (MATH, Date, TabMWP). Our results show that GATE achieves up to 4.3x faster milestone completion in Minecraft compared to the previous SOTA, and provides an average improvement of 9.23% over existing tool-making methods in code generation tasks and 10.03% in agent tasks. GATE demonstrates the power of adaptive evolution, balancing tool quantity, complexity, and functionality while maintaining high efficiency. Code and data are available at \url{https://github.com/ayanami2003/GATE}.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Benchmarking Automatic Speech Recognition coupled LLM Modules for Medical Diagnostics</title>
<link>https://arxiv.org/abs/2502.13982</link>
<guid>https://arxiv.org/abs/2502.13982</guid>
<content:encoded><![CDATA[
<div> 关键词: 自然语言处理(NLP), 语音识别, 医疗保健, 自动语音识别(ASR), 大型语言模型(LLM)

总结:
本文介绍了作者的一个自研项目，该项目利用自然语言处理和语音识别技术改进医疗保健。首先通过自动语音识别（ASR）系统对医疗电话录音进行专门训练，实现对多样化患者通话内容的通用转录。接着，采用大型语言模型（LLM）将转录文本与医学诊断相匹配，以生成上下文感知的专业回复。为提高管道对于不同麦克风和环境噪声条件下的鲁棒性，文章还提出了一种新颖的音频预处理策略，并对输入的录音数据进行了足够的噪音/剪裁增强。<br /><br /> <div>
arXiv:2502.13982v1 Announce Type: cross 
Abstract: Natural Language Processing (NLP) and Voice Recognition agents are rapidly evolving healthcare by enabling efficient, accessible, and professional patient support while automating grunt work. This report serves as my self project wherein models finetuned on medical call recordings are analysed through a two-stage system: Automatic Speech Recognition (ASR) for speech transcription and a Large Language Model (LLM) for context-aware, professional responses. ASR, finetuned on phone call recordings provides generalised transcription of diverse patient speech over call, while the LLM matches transcribed text to medical diagnosis. A novel audio preprocessing strategy, is deployed to provide invariance to incoming recording/call data, laden with sufficient augmentation with noise/clipping to make the pipeline robust to the type of microphone and ambient conditions the patient might have while calling/recording.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Counterfactual Concept Bottleneck Models</title>
<link>https://arxiv.org/abs/2402.01408</link>
<guid>https://arxiv.org/abs/2402.01408</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习模型、分类任务、因果反事实概念瓶颈模型（CF-CBMs）、解释性、决策过程

<br /><br />总结:
本文提出了一个新的深度学习模型类——因果反事实概念瓶颈模型（CF-CBMs），旨在同时解决三个核心问题：“什么？”（预测类别标签进行分类任务）、“如何？”（模拟变化并评估对类别预测的影响）和“为什么不是？”（设想如何改变场景以产生不同的类别预测）。实验表明，CF-CBMs在保持与黑盒模型和现有CBMs相当的分类精度的同时，能依赖更少的重要概念提供简洁的解释，并生成可解释的概念基础的反事实。此外，通过将反事实生成器与CBM联合训练，研究发现这种方法有两个关键优点：(i) 改变模型的决策过程，使模型依赖更少的重要概念，从而产生更简单的解释；(ii) 显著增加概念干预对类别预测的因果效应，使得模型对这些变化更具响应性。 <div>
arXiv:2402.01408v3 Announce Type: replace 
Abstract: Current deep learning models are not designed to simultaneously address three fundamental questions: predict class labels to solve a given classification task (the "What?"), simulate changes in the situation to evaluate how this impacts class predictions (the "How?"), and imagine how the scenario should change to result in different class predictions (the "Why not?"). The inability to answer these questions represents a crucial gap in deploying reliable AI agents, calibrating human trust, and improving human-machine interaction. To bridge this gap, we introduce CounterFactual Concept Bottleneck Models (CF-CBMs), a class of models designed to efficiently address the above queries all at once without the need to run post-hoc searches. Our experimental results demonstrate that CF-CBMs: achieve classification accuracy comparable to black-box models and existing CBMs ("What?"), rely on fewer important concepts leading to simpler explanations ("How?"), and produce interpretable, concept-based counterfactuals ("Why not?"). Additionally, we show that training the counterfactual generator jointly with the CBM leads to two key improvements: (i) it alters the model's decision-making process, making the model rely on fewer important concepts (leading to simpler explanations), and (ii) it significantly increases the causal effect of concept interventions on class predictions, making the model more responsive to these changes.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scheduling With Time Discounts</title>
<link>https://arxiv.org/abs/2402.08549</link>
<guid>https://arxiv.org/abs/2402.08549</guid>
<content:encoded><![CDATA[
<div> 关键词：金融版本、在线问题、调度、时间衰减价值、折扣率

总结：
该文研究了一个金融版的经典在线问题——带有权重和截止日期的调度问题。文章主要创新点在于考虑了具有时间衰减值的包，而传统方法假设包的权重固定不变。这一设定在金融市场环境下自然出现，因为未来行动的现值可能会被贴现。论文分析了一系列不同折扣率下的算法竞争比保证，涵盖了未打折（即折扣率为1）的传统情况、完全折现的“近视”情况（即折扣率为0）以及介于两者之间的情况。文中指出现有文献中的方法在更一般的折现设置中表现不佳。作者提出了一种新颖的记忆无关确定性算法，并证明其对于折扣因子小于约0.77的情况下，能实现确定性算法可达到的最佳竞争比。此外，他们还开发了一种随机算法并证明其在任何折扣率下均优于最佳确定性算法。虽然文章特别强调了框架及其结果对区块链交易调度的重要性，但其方法和分析技术具有普遍性和独立的研究价值。 <div>
arXiv:2402.08549v2 Announce Type: replace 
Abstract: We study a \emph{financial} version of the classic online problem of scheduling weighted packets with deadlines. The main novelty is that, while previous works assume packets have \emph{fixed} weights throughout their lifetime, this work considers packets with \emph{time-decaying} values. Such considerations naturally arise and have wide applications in financial environments, where the present value of future actions may be discounted. We analyze the competitive ratio guarantees of scheduling algorithms under a range of discount rates encompassing the ``traditional'' undiscounted case where weights are fixed (i.e., a discount rate of 1), the fully discounted ``myopic'' case (i.e., a rate of 0), and those in between. We show how existing methods from the literature perform suboptimally in the more general discounted setting. Notably, we devise a novel memoryless deterministic algorithm, and prove that it guarantees the best possible competitive ratio attainable by deterministic algorithms for discount factors up to $\approx 0.77$. Moreover, we develop a randomized algorithm and prove that it outperforms the best possible deterministic algorithm, for any discount rate. While we highlight the relevance of our framework and results to blockchain transaction scheduling in particular, our approach and analysis techniques are general and may be of independent interest.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Empirical Game-Theoretic Analysis: A Survey</title>
<link>https://arxiv.org/abs/2403.04018</link>
<guid>https://arxiv.org/abs/2403.04018</guid>
<content:encoded><![CDATA[
<div> 关键词：empirical approach to game-theoretic analysis (EGTA)，procedural description，multiagent domains，machine learning，complex game situations。

总结:
本文回顾了经验游戏理论分析（EGTA）领域的发展，该方法通过查询游戏环境的过程描述而非声明性表示来构建游戏模型，旨在处理过于复杂而无法进行解析指定和求解的战略情况。自二十年前引入以来，EGTA已被广泛应用于各种多代理领域，包括拍卖、市场、娱乐游戏以及网络安全等。文章梳理了多年来为EGTA发展起来的丰富方法论，按照构成EGTA过程的基本子问题进行组织，并介绍了EGTA的核心概念、技术和前沿研究问题。近期机器学习的进步加速了EGTA的发展，并有望显著增强我们对于复杂游戏情境推理的能力。 <div>
arXiv:2403.04018v2 Announce Type: replace 
Abstract: In the empirical approach to game-theoretic analysis (EGTA), the model of the game comes not from declarative representation, but is derived by interrogation of a procedural description of the game environment. The motivation for developing this approach was to enable game-theoretic reasoning about strategic situations too complex for analytic specification and solution. Since its introduction over twenty years ago, EGTA has been applied to a wide range of multiagent domains, from auctions and markets to recreational games to cyber-security. We survey the extensive methodology developed for EGTA over the years, organized by the elemental subproblems comprising the EGTA process. We describe key EGTA concepts and techniques, and the questions at the frontier of EGTA research. Recent advances in machine learning have accelerated progress in EGTA, and promise to significantly expand our capacities for reasoning about complex game situations.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VICtoR: Learning Hierarchical Vision-Instruction Correlation Rewards for Long-horizon Manipulation</title>
<link>https://arxiv.org/abs/2405.16545</link>
<guid>https://arxiv.org/abs/2405.16545</guid>
<content:encoded><![CDATA[
<div> 关键词：视觉-指令相关性(VIC)，长时程操纵任务，奖励模型， VICtoR，阶段检测器，运动进度评估器

总结:<br />
本文针对通过无动作视频和语言指令学习长时程操纵任务的奖励模型问题（即视觉-指令相关性问题，VIC）进行了研究。现有的VIC方法在处理复杂、长时间的任务时面临挑战，如缺乏子阶段感知、难以建模任务复杂性和对象状态估计不足等。为解决这些问题，文章提出了一个新的层次化VIC奖励模型——VICtoR。VICtoR利用新颖的阶段检测器和运动进度评估器在多个层次上精确地评估任务进度，为智能体有效学习任务提供了有益指导。通过对模拟环境和真实世界环境进行大量实验，结果显示VICtoR相比现有最佳VIC方法在长时程任务的成功率上有43%的提升。 <div>
arXiv:2405.16545v2 Announce Type: replace 
Abstract: We study reward models for long-horizon manipulation tasks by learning from action-free videos and language instructions, which we term the visual-instruction correlation (VIC) problem. Recent advancements in cross-modality modeling have highlighted the potential of reward modeling through visual and language correlations. However, existing VIC methods face challenges in learning rewards for long-horizon tasks due to their lack of sub-stage awareness, difficulty in modeling task complexities, and inadequate object state estimation. To address these challenges, we introduce VICtoR, a novel hierarchical VIC reward model capable of providing effective reward signals for long-horizon manipulation tasks. VICtoR precisely assesses task progress at various levels through a novel stage detector and motion progress evaluator, offering insightful guidance for agents learning the task effectively. To validate the effectiveness of VICtoR, we conducted extensive experiments in both simulated and real-world environments. The results suggest that VICtoR outperformed the best existing VIC methods, achieving a 43% improvement in success rates for long-horizon tasks.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoSQA+: Pioneering the Multi-Choice Code Search Benchmark with Test-Driven Agents</title>
<link>https://arxiv.org/abs/2406.11589</link>
<guid>https://arxiv.org/abs/2406.11589</guid>
<content:encoded><![CDATA[
<div> 关键词：Semantic Code Search, CoSQA+, Automated Pipeline, Test-Driven Agent Annotation System, Large Language Model

<br /><br />总结:
本文介绍了语义代码搜索的重要性以及现有数据集存在的局限性。为解决这些问题，文章提出了一个新的高质量数据集CoSQA+，它将CoSQA中的查询与多个合适的代码对齐。文中描述了一个自动化管道，该管道采用了模型基础的候选选择和创新的测试驱动代理标注系统。研究发现，利用测试验证的代理标注系统在准确率上达到了96.4%，超过了单一的大规模语言模型和仅依赖于Python专家的人工标注。通过大量实验，CoSQA+展现出了优于CoSQA的优质特性，并且基于CoSQA+训练的模型表现更优。相关代码和数据已发布到https://github.com/DeepSoftwareAnalytics/CoSQA_Plus。 <div>
arXiv:2406.11589v4 Announce Type: replace 
Abstract: Semantic code search, retrieving code that matches a given natural language query, is an important task to improve productivity in software engineering. Existing code search datasets face limitations: they rely on human annotators who assess code primarily through semantic understanding rather than functional verification, leading to potential inaccuracies and scalability issues. Additionally, current evaluation metrics often overlook the multi-choice nature of code search. This paper introduces CoSQA+, pairing high-quality queries from CoSQA with multiple suitable codes. We develop an automated pipeline featuring multiple model-based candidate selections and the novel test-driven agent annotation system. Among a single Large Language Model (LLM) annotator and Python expert annotators (without test-based verification), agents leverage test-based verification and achieve the highest accuracy of 96.4%. Through extensive experiments, CoSQA+ has demonstrated superior quality over CoSQA. Models trained on CoSQA+ exhibit improved performance. We provide the code and data at https://github.com/DeepSoftwareAnalytics/CoSQA_Plus.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Influence-Based Reward Modulation for Implicit Communication in Human-Robot Interaction</title>
<link>https://arxiv.org/abs/2406.12253</link>
<guid>https://arxiv.org/abs/2406.12253</guid>
<content:encoded><![CDATA[
<div> 关键词: 人类-机器人交互, 隐含沟通, 传输熵, 影响力调制, 半可观测马尔可夫决策过程<br /><br />总结:
本文提出了一种方法，旨在增强人类与机器人互动中的隐含通信，无需显式建模人类意图或依赖预存知识。该方法利用传输熵来调节社交交互中代理间的影响。通过将影响力整合到部分可观测马尔可夫决策过程中，研究发现强化影响力可以提升合作效果，而抵制影响力则会降低表现。这些发现已通过涉及社会导航设置的模拟实验和真人参与的真实世界实验得到验证。 <div>
arXiv:2406.12253v2 Announce Type: replace 
Abstract: Communication is essential for successful interaction. In human-robot interaction, implicit communication holds the potential to enhance robots' understanding of human needs, emotions, and intentions. This paper introduces a method to foster implicit communication in HRI without explicitly modelling human intentions or relying on pre-existing knowledge. Leveraging Transfer Entropy, we modulate influence between agents in social interactions in scenarios involving either collaboration or competition. By integrating influence into agents' rewards within a partially observable Markov decision process, we demonstrate that boosting influence enhances collaboration, while resisting influence diminishes performance. Our findings are validated through simulations and real-world experiments with human participants in social navigation settings.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating the Privacy Issues in Retrieval-Augmented Generation (RAG) via Pure Synthetic Data</title>
<link>https://arxiv.org/abs/2406.14773</link>
<guid>https://arxiv.org/abs/2406.14773</guid>
<content:encoded><![CDATA[
<div> 关键词: retrieval-augmented generation (RAG), 隐私风险, 合成数据, SAGE, 属性基提取, 代理基迭代细化

总结:
本文针对检索增强生成（RAG）系统中存在的私人数据检索可能带来的严重隐私风险问题，提出了使用合成数据作为隐私保护替代方案的方法。为此，研究者设计了名为SAGE的两阶段合成数据生成范式。在第一阶段，采用基于属性的提取和生成方法来保留在原始数据中的关键上下文信息；第二阶段，则通过代理基的迭代细化过程进一步提升合成数据的隐私特性。实验表明，利用我们的合成数据作为检索上下文能够实现与使用原始数据相当的性能表现，同时显著降低了隐私泄露的风险。这项工作首次探讨了为RAG生成高可用性和隐私保护型合成数据的可能性，为RAG系统的安全应用在各个领域开辟了新的机遇。 <div>
arXiv:2406.14773v2 Announce Type: replace 
Abstract: Retrieval-augmented generation (RAG) enhances the outputs of language models by integrating relevant information retrieved from external knowledge sources. However, when the retrieval process involves private data, RAG systems may face severe privacy risks, potentially leading to the leakage of sensitive information. To address this issue, we propose using synthetic data as a privacy-preserving alternative for the retrieval data. We propose SAGE, a novel two-stage synthetic data generation paradigm. In the stage-1, we employ an attribute-based extraction and generation approach to preserve key contextual information from the original data. In the stage-2, we further enhance the privacy properties of the synthetic data through an agent-based iterative refinement process. Extensive experiments demonstrate that using our synthetic data as the retrieval context achieves comparable performance to using the original data while substantially reducing privacy risks. Our work takes the first step towards investigating the possibility of generating high-utility and privacy-preserving synthetic data for RAG, opening up new opportunities for the safe application of RAG systems in various domains.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning</title>
<link>https://arxiv.org/abs/2410.00255</link>
<guid>https://arxiv.org/abs/2410.00255</guid>
<content:encoded><![CDATA[
<div> 关键词: 3DLLMs、Robin3D、Robust Instruction Generation (RIG)引擎、Adversarial Instruction-following数据、Diverse Instruction-following数据

<br /><br />总结:
本文介绍了在3D大型语言模型（3DLLMs）领域取得的新进展，提出了名为Robin3D的强大多模态3D语言模型。为了克服现有模型在高质、鲁棒性指令跟随数据方面的不足，研究团队开发了创新的数据生成引擎——Robust Instruction Generation (RIG) 引擎，该引擎生成两种关键指令数据：具有混合正负样本以提升模型判别力的对抗性指令跟随数据和含有多种指令风格以增强模型泛化能力的多样性指令跟随数据。由此构建了一个包含100万个指令跟随数据集，其中包括34.4万条对抗性样本、50.8万条多样性样本以及16.5万条基准训练集样本。为更好地处理复杂指令，Robin3D引入了关系增强投影器以强化空间理解，并通过ID-特征绑定增强了对象指代和定位能力。实验结果显示，Robin3D在五个广泛应用的3D多模态学习基准测试中均超越了先前方法，且无需针对特定任务进行微调。尤其值得一提的是，在接地任务(Multi3DRefer)上提高了7.8%，在描述任务(Scan2Cap)上提高了6.9%。 <div>
arXiv:2410.00255v2 Announce Type: replace 
Abstract: Recent advancements in 3D Large Language Models (3DLLMs) have highlighted their potential in building general-purpose agents in the 3D real world, yet challenges remain due to the lack of high-quality robust instruction-following data, leading to limited discriminative power and generalization of 3DLLMs. In this paper, we introduce Robin3D, a powerful 3DLLM trained on large-scale instruction-following data generated by our novel data engine, Robust Instruction Generation (RIG) engine. RIG generates two key instruction data: 1) the Adversarial Instruction-following data, which features mixed negative and positive samples to enhance the model's discriminative understanding. 2) the Diverse Instruction-following data, which contains various instruction styles to enhance model's generalization. As a result, we construct 1 million instruction-following data, consisting of 344K Adversarial samples, 508K Diverse samples, and 165K benchmark training set samples. To better handle these complex instructions, Robin3D first incorporates Relation-Augmented Projector to enhance spatial understanding, and then strengthens the object referring and grounding ability through ID-Feature Bonding. Robin3D consistently outperforms previous methods across five widely-used 3D multimodal learning benchmarks, without the need for task-specific fine-tuning. Notably, we achieve a 7.8\% improvement in the grounding task (Multi3DRefer) and a 6.9\% improvement in the captioning task (Scan2Cap).
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Diffusion Models for Multi-Agent Partial Observability: Shared Attractors, Error Bounds, and Composite Flow</title>
<link>https://arxiv.org/abs/2410.13953</link>
<guid>https://arxiv.org/abs/2410.13953</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、部分可观测性、分布式部分可观测马尔科夫决策过程、扩散模型、低秩性质

总结:
本文探讨了多智能体系统中处理部分可观测性问题的方法，重点关注了使用扩散模型从局部动作-观察历史中重建全局状态的研究。研究发现，在集体可观察的分布式部分可观测马尔科夫决策过程中，基于各智能体局部历史条件的扩散模型共享一个与全局状态相对应的独特固定点；而在非集体可观察场景下，共享的固定点产生了一个给定联合历史下的可能状态分布。文章进一步指出，由于深度学习近似误差的影响，固定点可能会偏离真实状态，并且这种偏离与雅可比矩阵的秩负相关。受此低秩性质启发，作者提出了一种构造的代理线性回归模型来逼近扩散模型的局部行为，并以此为依据，设计了一个具有理论收敛保证的“复合扩散过程”，该过程循环遍历各个智能体以迭代接近真实状态。 <div>
arXiv:2410.13953v3 Announce Type: replace 
Abstract: Multiagent systems grapple with partial observability (PO), and the decentralized POMDP (Dec-POMDP) model highlights the fundamental nature of this challenge. Whereas recent approaches to addressing PO have appealed to deep learning models, providing a rigorous understanding of how these models and their approximation errors affect agents' handling of PO and their interactions remain a challenge. In addressing this challenge, we investigate reconstructing global states from local action-observation histories in Dec-POMDPs using diffusion models. We first find that diffusion models conditioned on local history represent possible states as stable fixed points. In collectively observable (CO) Dec-POMDPs, individual diffusion models conditioned on agents' local histories share a unique fixed point corresponding to the global state, while in non-CO settings, shared fixed points yield a distribution of possible states given joint history. We further find that, with deep learning approximation errors, fixed points can deviate from true states and the deviation is negatively correlated to the Jacobian rank. Inspired by this low-rank property, we bound a deviation by constructing a surrogate linear regression model that approximates the local behavior of a diffusion model. With this bound, we propose a \emph{composite diffusion process} iterating over agents with theoretical convergence guarantees to the true state.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation</title>
<link>https://arxiv.org/abs/2410.14251</link>
<guid>https://arxiv.org/abs/2410.14251</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、后训练、指令数据、多智能体模拟器、MATRIX、MATRIX-Gen、AlpacaEval 2、Arena-Hard、Llama-3-8B-Base、Meta's Llama-3-8B-Instruct

总结:
为了解决大型语言模型（LLMs）遵循人类指令所需高质量指令数据获取的难题，本文提出了名为MATRIX的多智能体模拟器，它能够自动生成多样化的文本场景，以现实和可扩展的方式捕捉广泛的人类实际需求。在此基础上，文章介绍了一个创新的场景驱动指令生成器MATRIX-Gen，用于可控并高度逼真的数据合成。实验表明，该框架能有效生成通用及领域特定的数据。在AlpacaEval 2和Arena-Hard基准测试中，仅使用了由MATRIX-Gen生成的20K条指令响应对进行后训练的Llama-3-8B-Base模型，在性能上超过了经过超过10M对指令响应数据训练的Meta's Llama-3-8B-Instruct模型。 <div>
arXiv:2410.14251v2 Announce Type: replace 
Abstract: Post-training is essential for enabling large language models (LLMs) to follow human instructions. However, its effectiveness depends on high-quality instruction data, which is challenging to obtain in the real world due to privacy concerns, data scarcity, and high annotation costs. To fill this gap, inspired by the recent success of using LLMs to simulate human society, we propose MATRIX, a multi-agent simulator that automatically generates diverse text-based scenarios, capturing a wide range of real-world human needs in a realistic and scalable manner. Leveraging these outputs, we introduce a novel scenario-driven instruction generator MATRIX-Gen for controllable and highly realistic data synthesis. Extensive experiments demonstrate that our framework effectively generates both general and domain-specific data. On AlpacaEval 2 and Arena-Hard benchmarks, Llama-3-8B-Base, post-trained on datasets synthesized by MATRIX-Gen with just 20K instruction-response pairs, outperforms Meta's Llama-3-8B-Instruct model, which was trained on over 10M pairs.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks</title>
<link>https://arxiv.org/abs/2410.22391</link>
<guid>https://arxiv.org/abs/2410.22391</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习(RL), 大规模动作模型, 离线训练, 序列建模, xLSTM, 变形器架构, 实时应用, 快速推理, 大型循环动作模型(LRAM)

总结:
这篇论文探讨了近年来强化学习（RL）领域中使用大规模动作模型进行离线训练和序列建模的趋势，特别是关注到基于Transformer架构的方法虽强大但因推理速度慢而不适用于实时应用，如机器人技术。文章提出了一种新的大型循环动作模型（LRAM），其核心采用xLSTM结构，具有线性时间复杂度的快速推理能力和自然序列长度外推能力。实验结果显示，LRAM在性能和速度方面与Transformer相比表现优越，覆盖了来自6个领域的432项任务。 <div>
arXiv:2410.22391v2 Announce Type: replace 
Abstract: In recent years, there has been a trend in the field of Reinforcement Learning (RL) towards large action models trained offline on large-scale datasets via sequence modeling. Existing models are primarily based on the Transformer architecture, which result in powerful agents. However, due to slow inference times, Transformer-based approaches are impractical for real-time applications, such as robotics. Recently, modern recurrent architectures, such as xLSTM and Mamba, have been proposed that exhibit parallelization benefits during training similar to the Transformer architecture while offering fast inference. In this work, we study the aptitude of these modern recurrent architectures for large action models. Consequently, we propose a Large Recurrent Action Model (LRAM) with an xLSTM at its core that comes with linear-time inference complexity and natural sequence length extrapolation abilities. Experiments on 432 tasks from 6 domains show that LRAM compares favorably to Transformers in terms of performance and speed.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Soft Condorcet Optimization for Ranking of General Agents</title>
<link>https://arxiv.org/abs/2411.00119</link>
<guid>https://arxiv.org/abs/2411.00119</guid>
<content:encoded><![CDATA[
<div> 关键词: AI模型、标准化基准、排名方案、Soft Condorcet Optimization (SCO)、Elo评级

总结:
本文提出了一种名为Soft Condorcet Optimization (SCO)的新颖排名方案，该方案受到社会选择框架的启发，旨在对AI模型和代理进行性能比较时生成最优排名。SCO通过预测评估数据中的代理对比结果来计算最优排名，将其视为来自真实排名的有噪声样本的最大似然估计。与传统的Elo评级系统相比，SCO在存在Condorcet获胜者的情况下能实现最大值，但并非总是如此。文章还提出了三种用于计算SCO评级的优化算法，并对其进行了实证性能评估。实验表明，在PrefLib开放排名档案中的865个偏好配置文件中，SCO排名平均在归一化肯德尔-tau距离上与最优排名相差0到0.043。在模拟的噪声竞赛环境中，当超过59%的偏好数据缺失时，SCO能够准确近似真实的排名，并在多个基线中表现最佳。最后，在涉及52,958名人类玩家和31,049场七人游戏Diplomacy的经典案例中，SCO排名在测试集上的表现最接近于最优排名。 <div>
arXiv:2411.00119v3 Announce Type: replace 
Abstract: Driving progress of AI models and agents requires comparing their performance on standardized benchmarks; for general agents, individual performances must be aggregated across a potentially wide variety of different tasks. In this paper, we describe a novel ranking scheme inspired by social choice frameworks, called Soft Condorcet Optimization (SCO), to compute the optimal ranking of agents: the one that makes the fewest mistakes in predicting the agent comparisons in the evaluation data. This optimal ranking is the maximum likelihood estimate when evaluation data (which we view as votes) are interpreted as noisy samples from a ground truth ranking, a solution to Condorcet's original voting system criteria. SCO ratings are maximal for Condorcet winners when they exist, which we show is not necessarily true for the classical rating system Elo. We propose three optimization algorithms to compute SCO ratings and evaluate their empirical performance. When serving as an approximation to the Kemeny-Young voting method, SCO rankings are on average 0 to 0.043 away from the optimal ranking in normalized Kendall-tau distance across 865 preference profiles from the PrefLib open ranking archive. In a simulated noisy tournament setting, SCO achieves accurate approximations to the ground truth ranking and the best among several baselines when 59\% or more of the preference data is missing. Finally, SCO ranking provides the best approximation to the optimal ranking, measured on held-out test sets, in a problem containing 52,958 human players across 31,049 games of the classic seven-player game of Diplomacy.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Social-RAG: Retrieving from Group Interactions to Socially Ground AI Generation</title>
<link>https://arxiv.org/abs/2411.02353</link>
<guid>https://arxiv.org/abs/2411.02353</guid>
<content:encoded><![CDATA[
<div> 关键词：AI代理、在线协作、社会反馈、Social-RAG、PaperPing

总结:
本文介绍了如何让AI代理在网络协作环境中更好地提出主动建议而不打扰用户。研究提出了Social-RAG工作流，该流程能从过去的群体互动中检索上下文，选择相关的社会信号，并将其输入语言模型以生成符合社交规范的消息。为了实现这一目标，文中开发了名为\textsc{PaperPing}的系统，用于在研究者群体聊天中推荐论文，其社会信号依据对39名研究人员的形成性研究确定。通过在18个频道长达三个月的部署，覆盖500多名研究人员，结果显示PaperPing能够在不扰乱现有社交习惯的前提下，在群体中发布相关消息，有助于建立群体共识。 <div>
arXiv:2411.02353v2 Announce Type: replace 
Abstract: AI agents are increasingly tasked with making proactive suggestions in online spaces where groups collaborate, yet risk being unhelpful or even annoying if they fail to match group preferences or behave in socially inappropriate ways. Fortunately, group spaces have a rich history of prior interactions and affordances for social feedback that can support grounding an agent's generations to a group's interests and norms. We present Social-RAG, a workflow for socially grounding agents that retrieves context from prior group interactions, selects relevant social signals, and feeds them into a language model to generate messages in a socially aligned manner. We implement this in \textsc{PaperPing}, a system for posting paper recommendations in group chat, leveraging social signals determined from formative studies with 39 researchers. From a three-month deployment in 18 channels reaching 500+ researchers, we observed PaperPing posted relevant messages in groups without disrupting their existing social practices, fostering group common ground.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mapping out the Space of Human Feedback for Reinforcement Learning: A Conceptual Framework</title>
<link>https://arxiv.org/abs/2411.11761</link>
<guid>https://arxiv.org/abs/2411.11761</guid>
<content:encoded><![CDATA[
<div> 关键词：Reinforcement Learning from Human Feedback (RLHF)，反馈类型，税收分类法，质量指标，交互式机器学习<br /><br />总结:

本文探讨了强化学习从人类反馈（RLHF）的重要性，并提出了一种基于九个关键维度的人类反馈类型税收分类法，用于统一考虑人类中心、界面中心和模型中心的角度。同时，文章指出了影响人类表达反馈能力和代理人学习反馈能力的七个关键质量指标。基于这些反馈分类与质量标准，文章提出了从人类反馈中学习的系统的需求和设计选择，并将这些要求与现有的交互式机器学习工作进行了关联分析，识别出现有工作的不足及未来研究方向。最后，作者呼吁跨学科合作，充分利用数据驱动的协同适应建模和多样的互动机制，以实现强化学习的全部潜力。 <div>
arXiv:2411.11761v2 Announce Type: replace 
Abstract: Reinforcement Learning from Human feedback (RLHF) has become a powerful tool to fine-tune or train agentic machine learning models. Similar to how humans interact in social contexts, we can use many types of feedback to communicate our preferences, intentions, and knowledge to an RL agent. However, applications of human feedback in RL are often limited in scope and disregard human factors. In this work, we bridge the gap between machine learning and human-computer interaction efforts by developing a shared understanding of human feedback in interactive learning scenarios. We first introduce a taxonomy of feedback types for reward-based learning from human feedback based on nine key dimensions. Our taxonomy allows for unifying human-centered, interface-centered, and model-centered aspects. In addition, we identify seven quality metrics of human feedback influencing both the human ability to express feedback and the agent's ability to learn from the feedback. Based on the feedback taxonomy and quality criteria, we derive requirements and design choices for systems learning from human feedback. We relate these requirements and design choices to existing work in interactive machine learning. In the process, we identify gaps in existing work and future research opportunities. We call for interdisciplinary collaboration to harness the full potential of reinforcement learning with data-driven co-adaptive modeling and varied interaction mechanics.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Collaborative Learning</title>
<link>https://arxiv.org/abs/2411.12977</link>
<guid>https://arxiv.org/abs/2411.12977</guid>
<content:encoded><![CDATA[
<div> 关键词：MindForge、生成式智能体框架、协作终身学习、理论思维表示、自然跨代理通信

<br /><br />总结:
本文介绍了MindForge，一个用于协作终身学习的生成式智能体框架，该框架通过明确的视角转换实现。MindForge具备三个核心创新点：(1) 结构化的理论思维表示，关联了感知、信念、欲望和行为；(2) 自然的跨代理通信机制；(3) 多组件记忆系统。在Minecraft实验中，使用开放权重的LLMs驱动的MindForge智能体相较于Voyager表现更优，在传统Voyager无法仅靠GPT-4完成的基本任务上，MindForge收集到的唯一物品数量提高了2.3倍，达成的技术树里程碑增加了3倍，成功从基本木制工具发展至先进的铁质装备。MindForge智能体展现了包括专家-新手知识传递、协同问题解决以及通过累积的协同经验适应超出分布的任务等复杂行为。MindForge推进了具身AI开发的民主化，通过开放式社会学习实现端对端的知识共享。 <div>
arXiv:2411.12977v3 Announce Type: replace 
Abstract: Contemporary embodied agents powered by large language models (LLMs), such as Voyager, have shown promising capabilities in individual learning within open-ended environments like Minecraft. However, when powered by open LLMs, they struggle with basic tasks even after domain-specific fine-tuning. We present MindForge, a generative-agent framework for collaborative lifelong learning through explicit perspective taking. We introduce three key innovations: (1) a structured theory of mind representation linking percepts, beliefs, desires, and actions; (2) natural interagent communication; and (3) a multicomponent memory system. In Minecraft experiments, MindForge agents powered by open-weight LLMs significantly outperform their Voyager counterparts in basic tasks where traditional Voyager fails without GPT-4, collecting $2.3\times$ more unique items and achieving $3\times$ more tech-tree milestones, advancing from basic wood tools to advanced iron equipment. MindForge agents demonstrate sophisticated behaviors, including expert-novice knowledge transfer, collaborative problem solving, and adaptation to out-of-distribution tasks through accumulated collaborative experiences. MindForge advances the democratization of embodied AI development through open-ended social learning, enabling peer-to-peer knowledge sharing.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning to Play Against Unknown Opponents</title>
<link>https://arxiv.org/abs/2412.18297</link>
<guid>https://arxiv.org/abs/2412.18297</guid>
<content:encoded><![CDATA[
<div> 关键词：学习算法、期望效用、最坏情况、无后悔算法、多项式时间

总结:
该文研究了在一个一般性博弈环境中，一个学习智能体如何针对寻求最大化自身收益的战略对手进行重复博弈，同时智能体只知道自身的收益函数，但对对手的收益函数仅有一个分布$\mathcal{D}$的不确定性认识。当约束学习算法为无后悔算法时，文章展示了一个能在多项式时间内构建的、渐近达到最优期望效用和最坏情况下最优效用的学习算法。若不限制为无后悔算法，文中表明可以在输入大小和$\varepsilon$的倒数的多项式时间内构造出对于期望和最坏情况问题的$\varepsilon$-最优学习算法，当游戏规模或$\mathcal{D}$的支持度为常数时。特别地，对于最大化最小收益（maximin目标）的情况，文章提出了一种每步运行时间呈多项式的学习算法，保证收敛到最优学习者收益。所有这些结果都利用了最近发展的将学习算法分析转化为相关几何对象类（即菜单）的研究方法。 <div>
arXiv:2412.18297v2 Announce Type: replace 
Abstract: We consider the problem of a learning agent who has to repeatedly play a general sum game against a strategic opponent who acts to maximize their own payoff by optimally responding against the learner's algorithm. The learning agent knows their own payoff function, but is uncertain about the payoff of their opponent (knowing only that it is drawn from some distribution $\mathcal{D}$). What learning algorithm should the agent run in order to maximize their own total utility, either in expectation or in the worst-case over $\mathcal{D}$?
  When the learning algorithm is constrained to be a no-regret algorithm, we demonstrate how to efficiently construct an optimal learning algorithm (asymptotically achieving the optimal utility) in polynomial time for both the in-expectation and worst-case problems, independent of any other assumptions. When the learning algorithm is not constrained to no-regret, we show how to construct an $\varepsilon$-optimal learning algorithm (obtaining average utility within $\varepsilon$ of the optimal utility) for both the in-expectation and worst-case problems in time polynomial in the size of the input and $1/\varepsilon$, when either the size of the game or the support of $\mathcal{D}$ is constant. Finally, for the special case of the maximin objective, where the learner wishes to maximize their minimum payoff over all possible optimizer types, we construct a learner algorithm that runs in polynomial time in each step and guarantees convergence to the optimal learner payoff. All of these results make use of recently developed machinery that converts the analysis of learning algorithms to the study of the class of corresponding geometric objects known as menus.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation</title>
<link>https://arxiv.org/abs/2412.20127</link>
<guid>https://arxiv.org/abs/2412.20127</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、机器翻译评价、多维度多智能体辩论框架、细粒度评估、GPT-4o mini

总结:
本文提出了一种新的基于大型语言模型的机器翻译评价方法——Multidimensional Multi-Agent Debate (M-MAD)。该框架通过将传统的MQM标准解耦为多个独立的评价维度，实现了对机器翻译结果的细粒度评估。M-MAD利用多智能体辩论机制，充分发挥了大型语言模型的协同推理能力，并结合各维度评价结果生成最终的可靠评分。实验结果显示，M-MAD不仅超越了现有的大型语言模型判断方法，而且可以与最先进的参照型自动评价指标相媲美，即使在使用相对次优的模型如GPT-4o mini的情况下也是如此。文章详细分析了M-MAD的优势，为其在“大型语言模型作为评判者”这一范式中提供了新的视角。相关的代码和数据已在https://github.com/SU-JIAYUAN/M-MAD上公开。 <div>
arXiv:2412.20127v3 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have given rise to the LLM-as-a-judge paradigm, showcasing their potential to deliver human-like judgments. However, in the field of machine translation (MT) evaluation, current LLM-as-a-judge methods fall short of learned automatic metrics. In this paper, we propose Multidimensional Multi-Agent Debate (M-MAD), a systematic LLM-based multi-agent framework for advanced LLM-as-a-judge MT evaluation. Our findings demonstrate that M-MAD achieves significant advancements by (1) decoupling heuristic MQM criteria into distinct evaluation dimensions for fine-grained assessments; (2) employing multi-agent debates to harness the collaborative reasoning capabilities of LLMs; (3) synthesizing dimension-specific results into a final evaluation judgment to ensure robust and reliable outcomes. Comprehensive experiments show that M-MAD not only outperforms all existing LLM-as-a-judge methods but also competes with state-of-the-art reference-based automatic metrics, even when powered by a suboptimal model like GPT-4o mini. Detailed ablations and analysis highlight the superiority of our framework design, offering a fresh perspective for LLM-as-a-judge paradigm. Our code and data are publicly available at https://github.com/SU-JIAYUAN/M-MAD.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cyber-physical Defense for Heterogeneous Multi-agent Systems Against Exponentially Unbounded Attacks on Signed Digraphs</title>
<link>https://arxiv.org/abs/2501.00990</link>
<guid>https://arxiv.org/abs/2501.00990</guid>
<content:encoded><![CDATA[
<div> 关键词：Cyber-Physical Systems (CPSs)，False Data Injection (FDI) Attacks，Exponentially Unbounded，Distributed Defense Framework，Bi-Layer

总结:
<br />
针对遭受网络与物理空间攻击的Cyber-Physical Systems (CPSs)，文章提出了一个对抗指数型无界虚假数据注入(EU-FDI)攻击的全分布式双层防御框架。该框架旨在解决具有signed digraphs的异构多智能体系统的双层输出包容问题。首先，设计了攻击鲁棒动态补偿器，利用观察者层(OL)上的通信数据估计领导者状态和负状态的凸组合，以应对OL中的EU-FDI攻击并确保领导者状态的均匀最终有界(UUB)估计。随后，在网络层(CPL)上利用补偿器的状态设计了全分布式的攻击鲁棒控制器，进一步处理执行器上的EU-FDI攻击。通过Lyapunov稳定性分析提供了严格的数学证明，证实了所提双层防御框架在面对CPL和OL上的EU-FDI攻击时，能保持系统的一致性和稳定性。最后，通过对比案例研究验证了针对异构多智能体系统提出的防御策略所具备的增强鲁棒性。 <div>
arXiv:2501.00990v2 Announce Type: replace 
Abstract: Cyber-physical systems (CPSs) are subjected to attacks on both cyber and physical spaces. In reality, the attackers could launch exponentially unbounded false data injection (EU-FDI) attacks, which are more destructive and could lead to the system's collapse or instability. Existing literature generally addresses bounded attack signals and/or bounded-first-order-derivative attack signals, which exposes the CPSs to significant threats. In contrast, this paper proposes a fully-distributed attack-resilient bi-layer defense framework to address the bipartite output containment problem for heterogeneous multi-agent systems on signed digraphs, in the presence of EU-FDI attacks on both cyber-physical layer (CPL) and observer layer (OL). First, we design attack-resilient dynamic compensators that utilize data communicated on the OL to estimate the convex combinations of the states and negative states of the leaders. The attack-resilient compensators address the EU-FDI attacks on the OL and guarantee the uniformly ultimately bounded (UUB) estimation of the leaders' states. Then, by using the compensators' states, fully-distributed attack-resilient controllers are designed on the CPL to further address the EU-FDI attacks on the actuators. Rigorous mathematical proof based on Lyapunov stability analysis is provided, establishing the theoretical soundness of the proposed bi-layer resilient defense framework, by preserving the UUB consensus and stability against EU-FDI attacks on both CPL and OL. Finally, a comparative case study for heterogeneous multi-agent systems validate the enhanced resilience of the proposed defense strategies.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs</title>
<link>https://arxiv.org/abs/2501.15791</link>
<guid>https://arxiv.org/abs/2501.15791</guid>
<content:encoded><![CDATA[
<div> 关键词：知识图谱、错误检测、多智能体框架、大型语言模型、MAKGED

<br /><br />总结:
本文提出了一种名为MAKGED的新型多智能体框架，用于知识图谱错误检测。该框架利用多个大型语言模型在协作环境中有效整合细粒度的双向子图嵌入和基于查询的LLM嵌入进行训练，生成四个专门处理不同维度子图信息的代理。这些代理通过多轮讨论提升错误检测精度并确保决策过程透明。实验表明，相比于现有方法，MAKGED在FB15K和WN18RR数据集上表现更优，提高了知识图谱评估的准确性和鲁棒性。此外，针对特定工业场景，MAKGED还可以利用领域专用的知识图谱训练专门的错误检测代理，显示出其在工业应用领域的潜在价值。相关的代码和数据集可在https://github.com/kse-ElEvEn/MAKGED获取。 <div>
arXiv:2501.15791v2 Announce Type: replace 
Abstract: Knowledge graphs are widely used in industrial applications, making error detection crucial for ensuring the reliability of downstream applications. Existing error detection methods often fail to effectively utilize fine-grained subgraph information and rely solely on fixed graph structures, while also lacking transparency in their decision-making processes, which results in suboptimal detection performance. In this paper, we propose a novel Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that utilizes multiple large language models (LLMs) in a collaborative setting. By concatenating fine-grained, bidirectional subgraph embeddings with LLM-based query embeddings during training, our framework integrates these representations to produce four specialized agents. These agents utilize subgraph information from different dimensions to engage in multi-round discussions, thereby improving error detection accuracy and ensuring a transparent decision-making process. Extensive experiments on FB15K and WN18RR demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the accuracy and robustness of KG evaluation. For specific industrial scenarios, our framework can facilitate the training of specialized agents using domain-specific knowledge graphs for error detection, which highlights the potential industrial application value of our framework. Our code and datasets are available at https://github.com/kse-ElEvEn/MAKGED.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TeLL-Drive: Enhancing Autonomous Driving with Teacher LLM-Guided Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.01387</link>
<guid>https://arxiv.org/abs/2502.01387</guid>
<content:encoded><![CDATA[
<div> 关键词：Deep Reinforcement Learning (深度强化学习), Large Language Models (大型语言模型), TeLL-Drive, 自动驾驶, 决策制定

总结:

本文提出了一种名为TeLL-Drive的混合框架，用于解决自动驾驶中决策制定问题。该框架结合了深度强化学习（DRL）和大型语言模型（LLMs）的优势，旨在克服两者在实际应用中的局限性。DRL常面临高样例复杂度问题，而LLMs难以保证实时决策。TeLL-Drive通过教师型LLM引导注意力机制下的学生型DRL策略，利用风险指标、历史场景检索和领域启发式策略生成高级驾驶策略。自注意力机制将这些策略与DRL代理的探索融合，加速策略收敛并提高在多样化驾驶条件下的鲁棒性。

实验结果表明，TeLL-Drive在多个交通场景下成功率、平均回报及实时可行性方面优于现有基线方法，包括其他基于LLM的方法。此外，消融研究强调了各模型组件的重要性，尤其是注意力机制与LLM指导之间的协同作用。最后，通过虚拟现实融合实验平台和车辆回路实验验证了该算法在真实车辆上的实时性能、鲁棒性和可靠性。 <div>
arXiv:2502.01387v3 Announce Type: replace 
Abstract: Although Deep Reinforcement Learning (DRL) and Large Language Models (LLMs) each show promise in addressing decision-making challenges in autonomous driving, DRL often suffers from high sample complexity, while LLMs have difficulty ensuring real-time decision making. To address these limitations, we propose TeLL-Drive, a hybrid framework that integrates a Teacher LLM to guide an attention-based Student DRL policy. By incorporating risk metrics, historical scenario retrieval, and domain heuristics into context-rich prompts, the LLM produces high-level driving strategies through chain-of-thought reasoning. A self-attention mechanism then fuses these strategies with the DRL agent's exploration, accelerating policy convergence and boosting robustness across diverse driving conditions. The experimental results, evaluated across multiple traffic scenarios, show that TeLL-Drive outperforms existing baseline methods, including other LLM-based approaches, in terms of success rates, average returns, and real-time feasibility. Ablation studies underscore the importance of each model component, especially the synergy between the attention mechanism and LLM-driven guidance. Finally, we build a virtual-real fusion experimental platform to verify the real-time performance, robustness, and reliability of the algorithm running on real vehicles through vehicle-in-loop experiments.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evolving Symbolic 3D Visual Grounder with Weakly Supervised Reflection</title>
<link>https://arxiv.org/abs/2502.01401</link>
<guid>https://arxiv.org/abs/2502.01401</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D视觉接地、无监督学习、符号框架、Evolvable Symbolic Visual Grounder (EaSe)、推理成本

总结:
本文介绍了一种新颖的无需训练的符号框架——Evolvable Symbolic Visual Grounder (EaSe)，用于解决3D视觉接地问题。该框架克服了监督学习方法依赖昂贵的3D视觉语言数据集和基于LLM/VLM的代理方法在推断时时间与令牌成本过高的挑战。EaSe利用LLM生成的代码处理空间关系，并实现了一个自动评估和优化这些代码质量的管道，同时整合VLM以辅助接地过程。实验结果显示，EaSe在Nr3D数据集上达到52.9%的准确率，在ScanRefer数据集上实现了49.2%的Acc@0.25，性能居于无监督方法的顶级水平。此外，EaSe显著降低了推理时间和成本，提供了性能与效率之间的良好平衡。相关代码可在https://github.com/OpenRobotLab/EaSe 获取。 <div>
arXiv:2502.01401v3 Announce Type: replace 
Abstract: 3D visual grounding (3DVG) is challenging because of the requirement of understanding on visual information, language and spatial relationships. While supervised approaches have achieved superior performance, they are constrained by the scarcity and high cost of 3D vision-language datasets. On the other hand, LLM/VLM based agents are proposed for 3DVG, eliminating the need for training data. However, these methods incur prohibitive time and token costs during inference. To address the challenges, we introduce a novel training-free symbolic framework for 3D visual grounding, namely Evolvable Symbolic Visual Grounder, that offers significantly reduced inference costs compared to previous agent-based methods while maintaining comparable performance. EaSe uses LLM generated codes to compute on spatial relationships. EaSe also implements an automatic pipeline to evaluate and optimize the quality of these codes and integrate VLMs to assist in the grounding process. Experimental results demonstrate that EaSe achieves 52.9% accuracy on Nr3D dataset and 49.2% Acc@0.25 on ScanRefer, which is top-tier among training-free methods. Moreover, it substantially reduces the inference time and cost, offering a balanced trade-off between performance and efficiency. Codes are available at https://github.com/OpenRobotLab/EaSe.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation</title>
<link>https://arxiv.org/abs/2502.08047</link>
<guid>https://arxiv.org/abs/2502.08047</guid>
<content:encoded><![CDATA[
<div> 关键词：WorldGUI、GUI元素定位、规划挑战、初始状态、GUI-Thinker

<br /><br />总结:
本文提出了一个新的GUI基准测试平台WorldGUI，用于模拟真实用户交互并评估各种初始状态下的GUI任务处理能力。该基准涵盖了10款流行软件的应用任务。针对动态GUI自动化任务的挑战，文章还提出了一种名为GUI-Thinker的框架，该框架利用批判性机制有效地管理GUI交互的不可预测性和复杂性。实验结果显示，GUI-Thinker在WorldGUI任务上的成功率比Claude-3.5（计算机使用）提高了14.9%，从而证明了基于批判性思考框架的有效性。相关代码已开源，可在https://github.com/showlab/WorldGUI获取。 <div>
arXiv:2502.08047v2 Announce Type: replace 
Abstract: Current GUI agents have achieved outstanding performance in GUI element grounding. However, planning remains highly challenging, especially due to sensitivity to the initial state of the environment. Specifically, slight differences in the initial state-such as the target software not being open or the interface not being in its default state-often lead to planning errors. This issue is widespread in real user scenarios, but existing benchmarks fail to evaluate it. In this paper, we present WorldGUI, a novel GUI benchmark that designs GUI tasks with various initial states to simulate real computer-user interactions. The benchmark spans a wide range of tasks across 10 popular software applications, including PowerPoint, VSCode, and Adobe Acrobat. In addition, to address the challenges of dynamic GUI automation tasks, we propose GUI-Thinker, a holistic framework, leveraging a critique mechanism, that effectively manages the unpredictability and complexity of GUI interactions. Experimental results demonstrate that GUI-Thinker significantly outperforms Claude-3.5 (Computer Use) by 14.9% in success rate on WorldGUI tasks. This improvement underscores the effectiveness of our critical-thinking-based framework in enhancing GUI automation. The code is available at https://github.com/showlab/WorldGUI.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>eQMARL: Entangled Quantum Multi-Agent Reinforcement Learning for Distributed Cooperation over Quantum Channels</title>
<link>https://arxiv.org/abs/2405.17486</link>
<guid>https://arxiv.org/abs/2405.17486</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式多智能体强化学习、量子计算、量子纠缠、协同合作、entangled QMARL (eQMARL)

总结:
本文提出了一种新的分布式强化学习框架——entangled QMARL (eQMARL)，该框架利用量子纠缠来促进多智能体间的协作，同时减少了信息共享和通信开销。与当前基于经典信息共享的量子多智能体强化学习(QMARL)实现不同，eQMARL通过量子通道中的量子纠缠实现局部观察编码器的耦合，无需显式分享局部观察数据。此外，eQMARL还利用联合量子测量对代理策略进行调整，降低了集中式计算负担。实验结果显示，采用${\Psi}^{+}$纠缠的eQMARL相比于经典的分布式和集中式以及完全集中式的量子基线，能更快地收敛到合作策略（最多提高了17.8%），并具有更高的总体得分。同时，eQMARL在保持这一性能水平的同时，其集中式参数数量仅为分割经典基线的1/25。 <div>
arXiv:2405.17486v2 Announce Type: replace-cross 
Abstract: Collaboration is a key challenge in distributed multi-agent reinforcement learning (MARL) environments. Learning frameworks for these decentralized systems must weigh the benefits of explicit player coordination against the communication overhead and computational cost of sharing local observations and environmental data. Quantum computing has sparked a potential synergy between quantum entanglement and cooperation in multi-agent environments, which could enable more efficient distributed collaboration with minimal information sharing. This relationship is largely unexplored, however, as current state-of-the-art quantum MARL (QMARL) implementations rely on classical information sharing rather than entanglement over a quantum channel as a coordination medium. In contrast, in this paper, a novel framework dubbed entangled QMARL (eQMARL) is proposed. The proposed eQMARL is a distributed actor-critic framework that facilitates cooperation over a quantum channel and eliminates local observation sharing via a quantum entangled split critic. Introducing a quantum critic uniquely spread across the agents allows coupling of local observation encoders through entangled input qubits over a quantum channel, which requires no explicit sharing of local observations and reduces classical communication overhead. Further, agent policies are tuned through joint observation-value function estimation via joint quantum measurements, thereby reducing the centralized computational burden. Experimental results show that eQMARL with ${\Psi}^{+}$ entanglement converges to a cooperative strategy up to $17.8\%$ faster and with a higher overall score compared to split classical and fully centralized classical and quantum baselines. The results also show that eQMARL achieves this performance with a constant factor of $25$-times fewer centralized parameters compared to the split classical baseline.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Addressing Rotational Learning Dynamics in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.07976</link>
<guid>https://arxiv.org/abs/2410.07976</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习(MARL), 可重复性危机, 变分不等式(VI), 优化动态, 游戏策略收敛

总结:
本文探讨了多智能体强化学习(MARL)领域面临的可重复性危机问题，并指出该问题部分源于竞争性智能体目标间的旋转优化动态。为解决此问题，文章将MARL方法重新构架为变分不等式(VI)框架，并提出一种通用方法，将基于VI的梯度优化技术融入现有的MARL算法中。实验结果显示，这种方法在各种基准测试中显著提高了性能。在零和游戏中（如Rock-paper-scissors和Matching pennies），VI方法能更好地引导智能体收敛至均衡策略；在Multi-Agent Particle Environment的捕食者-猎物环境中，也增强了团队协作能力。这些结果强调了高级优化技术在MARL中的变革潜力。 <div>
arXiv:2410.07976v2 Announce Type: replace-cross 
Abstract: Multi-agent reinforcement learning (MARL) has emerged as a powerful paradigm for solving complex problems through agents' cooperation and competition, finding widespread applications across domains. Despite its success, MARL faces a reproducibility crisis. We show that, in part, this issue is related to the rotational optimization dynamics arising from competing agents' objectives, and require methods beyond standard optimization algorithms. We reframe MARL approaches using Variational Inequalities (VIs), offering a unified framework to address such issues. Leveraging optimization techniques designed for VIs, we propose a general approach for integrating gradient-based VI methods capable of handling rotational dynamics into existing MARL algorithms. Empirical results demonstrate significant performance improvements across benchmarks. In zero-sum games, Rock--paper--scissors and Matching pennies, VI methods achieve better convergence to equilibrium strategies, and in the Multi-Agent Particle Environment: Predator-prey, they also enhance team coordination. These results underscore the transformative potential of advanced optimization techniques in MARL.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Information-Theoretic Analysis of Thompson Sampling for Logistic Bandits</title>
<link>https://arxiv.org/abs/2412.02861</link>
<guid>https://arxiv.org/abs/2412.02861</guid>
<content:encoded><![CDATA[
<div> 关键词：Thompson Sampling、逻辑斯蒂带宽问题、信息比率、贝叶斯期望后悔、行动空间、参数空间

总结:
本文研究了在逻辑斯蒂带宽问题中Thompson Sampling算法的性能。该问题中，代理根据逻辑函数获得二进制奖励，该函数由动作$a$与参数$\theta$之间的内积和斜率参数$\beta>0$决定。文中采用Russo和Van Roy (2016)提出的信噪比框架，分析了算法的信息比率，它量化了所遭受的即时后悔与获取关于最优动作信息之间的权衡。作者改进了先前的结果，证明了信息比率为$\tfrac{9}{2}d\alpha^{-2}$，其中$\alpha$表示动作空间$\mathcal{A}$和参数空间$\mathcal{O}$之间的一種最小最大对齐度量，且独立于$\beta$。基于此，他们得出Thompson Sampling在$T$时间步后的贝叶斯期望后悔界为$O(d/\alpha\sqrt{T \log(\beta T/d)})$。据作者所知，这是首个仅依赖于$\beta$的对数项且与动作数量无关的逻辑斯蒂带宽问题的后悔界限。特别是，当行动空间包含参数空间时，预期后悔界的阶为$\tilde{O}(d \sqrt{T})$。 <div>
arXiv:2412.02861v2 Announce Type: replace-cross 
Abstract: We study the performance of the Thompson Sampling algorithm for logistic bandit problems. In this setting, an agent receives binary rewards with probabilities determined by a logistic function, $\exp(\beta \langle a, \theta \rangle)/(1+\exp(\beta \langle a, \theta \rangle))$, with slope parameter $\beta>0$, and where both the action $a\in \mathcal{A}$ and parameter $\theta \in \mathcal{O}$ lie within the $d$-dimensional unit ball. Adopting the information-theoretic framework introduced by Russo and Van Roy (2016), we analyze the information ratio, a statistic that quantifies the trade-off between the immediate regret incurred and the information gained about the optimal action. We improve upon previous results by establishing that the information ratio is bounded by $\tfrac{9}{2}d\alpha^{-2}$, where $\alpha$ is a minimax measure of the alignment between the action space $\mathcal{A}$ and the parameter space $\mathcal{O}$, and is independent of $\beta$. Using this result, we derive a bound of order $O(d/\alpha\sqrt{T \log(\beta T/d)})$ on the Bayesian expected regret of Thompson Sampling incurred after $T$ time steps. To our knowledge, this is the first regret bound for logistic bandits that depends only logarithmically on $\beta$ while being independent of the number of actions. In particular, when the action space contains the parameter space, the bound on the expected regret is of order $\tilde{O}(d \sqrt{T})$.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TastepepAI, An artificial intelligence platform for taste peptide de novo design</title>
<link>https://arxiv.org/abs/2502.12167</link>
<guid>https://arxiv.org/abs/2502.12167</guid>
<content:encoded><![CDATA[
<div> 关键词: TastePepAI、人工智慧框架、味觉肽、损失监督自适应变分自编码器(LA-VAE)、毒性预测算法(SpepToxPred)

总结:
本文介绍了TastePepAI，这是一个创新的人工智能框架，专门用于定制化味觉肽的设计和安全评估。该框架的核心是一个采用损失监督自适应变分自编码器(LA-VAE)的模型，它能在训练过程中有效优化序列的潜在表示，生成具有目标味觉属性的肽链。同时，模型内置了味觉避免机制，可实现选择性地排除特定风味。此外，文中还提到了自主研发的毒性预测算法(SpepToxPred)，将其整合进框架中对生成的肽链进行严格的安全性评价。利用此一体化平台，研究人员成功发现了73种具有甜、咸和鲜味的肽链，极大地扩展了现有的味觉肽库。这项工作彰显了TastePepAI在加速味觉肽发现应用于食品产业中的潜力，并为更广泛的肽链工程挑战提供了可适应的通用框架。 <div>
arXiv:2502.12167v1 Announce Type: new 
Abstract: Taste peptides have emerged as promising natural flavoring agents attributed to their unique organoleptic properties, high safety profile, and potential health benefits. However, the de novo identification of taste peptides derived from animal, plant, or microbial sources remains a time-consuming and resource-intensive process, significantly impeding their widespread application in the food industry. Here, we present TastePepAI, a comprehensive artificial intelligence framework for customized taste peptide design and safety assessment. As the key element of this framework, a loss-supervised adaptive variational autoencoder (LA-VAE) is implemented to efficiently optimizes the latent representation of sequences during training and facilitates the generation of target peptides with desired taste profiles. Notably, our model incorporates a novel taste-avoidance mechanism, allowing for selective flavor exclusion. Subsequently, our in-house developed toxicity prediction algorithm (SpepToxPred) is integrated in the framework to undergo rigorous safety evaluation of generated peptides. Using this integrated platform, we successfully identified 73 peptides exhibiting sweet, salty, and umami, significantly expanding the current repertoire of taste peptides. This work demonstrates the potential of TastePepAI in accelerating taste peptide discovery for food applications and provides a versatile framework adaptable to broader peptide engineering challenges.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Closer Look at System Prompt Robustness</title>
<link>https://arxiv.org/abs/2502.12197</link>
<guid>https://arxiv.org/abs/2502.12197</guid>
<content:encoded><![CDATA[
<div> 关键词：系统提示、LLMs、鲁棒性、细调数据、推理时间干预

总结:<br />
本文研究了提高LLMs系统提示鲁棒性的方法，针对来自OpenAI的GPT Store和HuggingFace的HuggingChat收集的提示创建了新的评价和细调数据集。实验表明，使用现实世界的细调数据和推理时间的干预（如分类器自由指导）可以显著改善模型性能。文章还分析了OpenAI和DeepSeek最近发布的推理模型在所研究基准测试上的表现，结果显示有令人兴奋但不均衡的改进。总体而言，现有的技术尚未充分确保系统提示的鲁棒性，需要进一步的研究。 <div>
arXiv:2502.12197v1 Announce Type: new 
Abstract: System prompts have emerged as a critical control surface for specifying the behavior of LLMs in chat and agent settings. Developers depend on system prompts to specify important context, output format, personalities, guardrails, content policies, and safety countermeasures, all of which require models to robustly adhere to the system prompt, especially when facing conflicting or adversarial user inputs. In practice, models often forget to consider relevant guardrails or fail to resolve conflicting demands between the system and the user. In this work, we study various methods for improving system prompt robustness by creating realistic new evaluation and fine-tuning datasets based on prompts collected from from OpenAI's GPT Store and HuggingFace's HuggingChat. Our experiments assessing models with a panel of new and existing benchmarks show that performance can be considerably improved with realistic fine-tuning data, as well as inference-time interventions such as classifier-free guidance. Finally, we analyze the results of recently released reasoning models from OpenAI and DeepSeek, which show exciting but uneven improvements on the benchmarks we study. Overall, current techniques fall short of ensuring system prompt robustness and further study is warranted.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>InfoQuest: Evaluating Multi-Turn Dialogue Agents for Open-Ended Conversations with Hidden Context</title>
<link>https://arxiv.org/abs/2502.12257</link>
<guid>https://arxiv.org/abs/2502.12257</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、模糊请求、InfoQuest、多轮对话、信息寻求能力

总结:
本文介绍了InfoQuest，一个多轮聊天基准测试平台，用于评估对话代理处理开放性用户请求中隐藏上下文的能力。该基准通过设计具有故意模糊性的场景，要求模型在提供适当响应前通过澄清问题来获取必要的信息。文章对开源和闭源模型进行了评价，发现虽然专有模型总体表现较好，但当前的所有助手在有效地收集关键信息方面仍有困难，往往需要多次交互才能推断用户意图，并常常在没有充分澄清的情况下给出泛化的回答。此外，文中还提出了一种系统化的方法来生成多样化的场景并评价模型的信息寻求能力，揭示了语言模型在处理多轮交互中的模糊请求时存在的局限性。<br /><br /> <div>
arXiv:2502.12257v1 Announce Type: new 
Abstract: While large language models excel at following explicit instructions, they often struggle with ambiguous or incomplete user requests, defaulting to verbose, generic responses rather than seeking clarification. We introduce InfoQuest, a multi-turn chat benchmark designed to evaluate how dialogue agents handle hidden context in open-ended user requests. The benchmark presents intentionally ambiguous scenarios that require models to engage in information-seeking dialogue through clarifying questions before providing appropriate responses. Our evaluation of both open and closed-source models reveals that while proprietary models generally perform better, all current assistants struggle with effectively gathering critical information, often requiring multiple turns to infer user intent and frequently defaulting to generic responses without proper clarification. We provide a systematic methodology for generating diverse scenarios and evaluating models' information-seeking capabilities, offering insights into the current limitations of language models in handling ambiguous requests through multi-turn interactions.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning to Reason at the Frontier of Learnability</title>
<link>https://arxiv.org/abs/2502.12272</link>
<guid>https://arxiv.org/abs/2502.12272</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、大型语言模型、训练算法、PPO、VinePPO、数据集、学习信号、采样可学习性、课程学习、性能提升

<br /><br />总结:
本文关注了强化学习在大规模语言模型训练中的应用，特别是针对推理类任务如数学问题。研究发现，在使用PPO和VinePPO等流行算法以及两种常用数据集的训练过程中，许多问题要么一开始就得到解决，要么始终无法解决，这导致训练信号意义不大。为解决这一问题，文章借鉴强化学习领域的“采样可学习性”方法，将其应用于LLM训练阶段的强化学习环节，通过优先选择成功率具有高方差的问题（即有时成功但并不总是成功的题目）来构建课程学习。实验结果显示，这种课程学习策略能够普遍提高多种算法和数据集上的训练性能，为实现更高效、有效的强化学习训练提供了新途径。 <div>
arXiv:2502.12272v1 Announce Type: new 
Abstract: Reinforcement learning is now widely adopted as the final stage of large language model training, especially for reasoning-style tasks such as maths problems. Typically, models attempt each question many times during a single training step and attempt to learn from their successes and failures. However, we demonstrate that throughout training with two popular algorithms (PPO and VinePPO) on two widely used datasets, many questions are either solved by all attempts - meaning they are already learned - or by none - providing no meaningful training signal. To address this, we adapt a method from the reinforcement learning literature - sampling for learnability - and apply it to the reinforcement learning stage of LLM training. Our curriculum prioritises questions with high variance of success, i.e. those where the agent sometimes succeeds, but not always. Our findings demonstrate that this curriculum consistently boosts training performance across multiple algorithms and datasets, paving the way for more efficient and effective reinforcement learning in LLMs.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Connecting Large Language Model Agent to High Performance Computing Resource</title>
<link>https://arxiv.org/abs/2502.12280</link>
<guid>https://arxiv.org/abs/2502.12280</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Model, Parsl, LangChain/LangGraph, High-Performance Computing (HPC), Molecular Dynamics Simulations

总结:<br />
本文介绍了将Parsl集成到LangChain/LangGraph工具调用设置中，以连接大型语言模型(Large Language Model)代理与计算资源，从而提升处理特定科学领域问题的性能。文章测试了两种在本地工作站和Polaris/ALCF超级计算机环境下的工具调用实现方式：第一种通过启用Parsl的LangChain工具节点并发地向Parsl工作器队列提交工具函数；第二种方法则是将工具函数转换为Parslensemble函数，更适合于在超算环境中执行大规模任务。为了验证这种方法，LLM代理工作流被引导运行分子动力学模拟，使用不同的蛋白质结构和模拟条件。实验结果表明，Parsl能够成功管理和并行执行LLM代理工具所调用的任务，有效地利用了可用的计算资源。 <div>
arXiv:2502.12280v1 Announce Type: new 
Abstract: The Large Language Model agent workflow enables the LLM to invoke tool functions to increase the performance on specific scientific domain questions. To tackle large scale of scientific research, it requires access to computing resource and parallel computing setup. In this work, we implemented Parsl to the LangChain/LangGraph tool call setup, to bridge the gap between the LLM agent to the computing resource. Two tool call implementations were set up and tested on both local workstation and HPC environment on Polaris/ALCF. The first implementation with Parsl-enabled LangChain tool node queues the tool functions concurrently to the Parsl workers for parallel execution. The second configuration is implemented by converting the tool functions into Parsl ensemble functions, and is more suitable for large task on super computer environment. The LLM agent workflow was prompted to run molecular dynamics simulations, with different protein structure and simulation conditions. These results showed the LLM agent tools were managed and executed concurrently by Parsl on the available computing resource.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rational Capability in Concurrent Games</title>
<link>https://arxiv.org/abs/2502.12286</link>
<guid>https://arxiv.org/abs/2502.12286</guid>
<content:encoded><![CDATA[
<div> 关键词：并发游戏结构、偏好、理性、CL语言、ATL语言

总结:
本文将并发游戏结构（CGSs）扩展到包含对计算的简单偏好，并基于优势概念定义了代理的基本理性概念。文章进而引入两种语言——带有理性能力模态的扩展CL和ATL语言，这些模态表示联盟理性执行特定属性的能力。对于每种语言，文中都提供了关于满足性检查和模型检查的复杂性结果以及公理化方面的讨论。 <div>
arXiv:2502.12286v1 Announce Type: new 
Abstract: We extend concurrent game structures (CGSs) with a simple notion of preference over computations and define a minimal notion of rationality for agents based on the concept of dominance. We use this notion to interpret a CL and an ATL languages that extend the basic CL and ATL languages with modalities for rational capability, namely, a coalition's capability to rationally enforce a given property. For each of these languages, we provide results about the complexity of satisfiability checking and model checking as well as about axiomatization.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Effectiveness of Golden Tickets and Wooden Spoons for Budget-Feasible Mechanisms</title>
<link>https://arxiv.org/abs/2502.12306</link>
<guid>https://arxiv.org/abs/2502.12306</guid>
<content:encoded><![CDATA[
<div> 关键词：non-obvious manipulability (NOM)，budget-feasible mechanisms，monotone subadditive valuation functions，approximation guarantee，rational agents

总结:
本文探讨了非显式操纵性（NOM）在预算约束机制设计中的作用。研究发现，采用满足NOM的预算可行机制对于具有单调子可加性估值函数的一般类问题，可以获得紧约为2的社会福利近似保证。这一结果揭示了DSIC（完全理性代理人）与NOM（不完全理性代理人）之间可达到的保证存在明显分离，因为没有任何真实的机制能实现优于2.41的保证。文中还完整地刻画了BNOM和WNOM（共同构成NOM），并分别给出了它们的匹配上界和下界。进一步，论文指出随机化的满足BNOM的预算可行机制可以实现接近于1的期望逼近比。 <div>
arXiv:2502.12306v1 Announce Type: new 
Abstract: One of the main challenges in mechanism design is to carefully engineer incentives ensuring truthfulness while maintaining strong social welfare approximation guarantees. But these objectives are often in conflict, making it impossible to design effective mechanisms. An important class of mechanism design problems that belong to this category are budget-feasible mechanisms. Here, the designer needs to procure services of maximum value from a set of agents while being on a budget, i.e., having a limited budget to enforce truthfulness. However, as empirical studies suggest, factors like limited information and bounded rationality question the idealized assumption that the agents behave perfectly rationally. Motivated by this, Troyan and Morill in 2022 introduced non-obvious manipulability (NOM) as a more lenient incentive compatibility notion. In this paper, we investigate whether resorting to NOM enables us to derive improved mechanisms in budget-feasible domains. We establish a tight bound of 2 on the approximation guarantee of budget-feasible mechanisms satisfying NOM for the general class of monotone subadditive valuation functions. Our result thus establishes a clear separation between the achievable guarantees for DSIC (perfectly rational agents) and NOM (imperfectly rational agents) as no truthful mechanism can achieve a guarantee better than 2.41. Along the way, we fully characterize BNOM and WNOM (which together form NOM) and derive matching upper and lower bounds, respectively. Conceptually, our characterization results suggest "Golden Tickets" and "Wooden Spoons" as natural means to realize BNOM and WNOM, respectively. Additionally, we show that randomized budget-feasible mechanisms satisfying BNOM can achieve an expected approximation ratio arbitrarily close to 1.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mechanisms for Selling an Item Among a Strategic Bidder and a Profiled Agent</title>
<link>https://arxiv.org/abs/2502.12313</link>
<guid>https://arxiv.org/abs/2502.12313</guid>
<content:encoded><![CDATA[
<div> 关键词：单件拍卖、预测、机制设计、单调风险率（MHR）、收益保证

总结:
该文研究了一个场景，其中一件商品要售给两个代理商中的一个，他们的估值均来自相同的概率分布。然而，只有一个代理商向机制提交投标，另一个代理商的估值由机制接收到的可能是正确或错误的“预测”。文章旨在设计能够在预测正确或错误情况下实现最高可能收益的销售机制。以战略性和诚实竞标者所能获得的最大期望收益作为基准，文中探讨了两种机制。第一个机制在预测确保正确时能实现最优收益，并在预测错误时给出对于MHR分布下的估值一个常数收益近似比。第二个机制忽略对第二个代理商的预测，模拟在没有投标人信息的情况下，收益最优的机制，证明在MHR分布假设下，它相对于对诚实和战略竞标者的收益最优机制具有常数收益近似保证。此外，文章还表明对于某些常规的概率分布，不存在常数收益近似可能性。 <div>
arXiv:2502.12313v1 Announce Type: new 
Abstract: We consider a scenario where a single item can be sold to one of two agents. Both agents draw their valuation for the item from the same probability distribution. However, only one of them submits a bid to the mechanism. For the other, the mechanism receives a \textit{prediction} for her valuation, which can be true or false. Our goal is to design mechanisms for selling the item which make as high revenue as possible in cases of a correct or incorrect prediction. As benchmark for proving our revenue-approximation guarantees, we use the maximum expected revenue that can be obtained by a strategic and a honest bidder. We study two mechanisms. The first one yields optimal revenue when the prediction is guaranteed to be correct and a constant revenue approximation when the prediction is incorrect, assuming that the agent valuations are drawn from a monotone hazard rate (MHR) distribution. Our second mechanism ignores the prediction for the second agent and simulates the revenue-optimal mechanism when no bid information for the bidders is available. We prove, again assuming that valuations are drawn from MHR distributions, that this mechanism achieves a constant revenue approximation guarantee compared to the revenue-optimal mechanism for a honest and a strategic bidder. The MHR assumption is necessary; we show that there are regular probability distributions for which no constant revenue approximation is possible.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean-Field Bayesian Optimisation</title>
<link>https://arxiv.org/abs/2502.12315</link>
<guid>https://arxiv.org/abs/2502.12315</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体合作、贝叶斯优化、黑盒函数、均值场理论、MF-GP-UCB

总结:
本文提出了一个新的算法MF-GP-UCB，用于解决大量合作智能体在未知且被视为黑盒的收益函数下的平均收益优化问题。针对高维输入空间带来的可扩展性挑战，文章利用均值场假设对黑盒函数进行处理，使得贝叶斯优化变得更加高效和可扩展。MF-GP-UCB算法的理论分析证明了其在智能体数量上的独立后悔界，与使用朴素贝叶斯优化方法时观察到的指数依赖形成鲜明对比。实验结果表明，MF-GP-UCB在包括共享单车布局优化、出租车车队分配和船舶加油港口选择等现实世界任务中显著优于现有基准，展现了卓越的性能提升和可扩展性，为均值场、黑盒优化问题提供了一个有前景的解决方案。相关代码已开源在https://github.com/petarsteinberg/MF-BO。 <div>
arXiv:2502.12315v1 Announce Type: new 
Abstract: We address the problem of optimising the average payoff for a large number of cooperating agents, where the payoff function is unknown and treated as a black box. While standard Bayesian Optimisation (BO) methods struggle with the scalability required for high-dimensional input spaces, we demonstrate how leveraging the mean-field assumption on the black-box function can transform BO into an efficient and scalable solution. Specifically, we introduce MF-GP-UCB, a novel efficient algorithm designed to optimise agent payoffs in this setting. Our theoretical analysis establishes a regret bound for MF-GP-UCB that is independent of the number of agents, contrasting sharply with the exponential dependence observed when naive BO methods are applied. We evaluate our algorithm on a diverse set of tasks, including real-world problems, such as optimising the location of public bikes for a bike-sharing programme, distributing taxi fleets, and selecting refuelling ports for maritime vessels. Empirical results demonstrate that MF-GP-UCB significantly outperforms existing benchmarks, offering substantial improvements in performance and scalability, constituting a promising solution for mean-field, black-box optimisation. The code is available at https://github.com/petarsteinberg/MF-BO.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LM Agents for Coordinating Multi-User Information Gathering</title>
<link>https://arxiv.org/abs/2502.12328</link>
<guid>https://arxiv.org/abs/2502.12328</guid>
<content:encoded><![CDATA[
<div> 关键词: PeopleJoin、LM-mediated collaborative problem solving、benchmark、PeopleJoin-QA、PeopleJoin-DocCreation

总结:
本文介绍了PeopleJoin，这是一个用于评估基于语言模型的协作问题解决能力的基准。PeopleJoin要求代理在接到用户请求后，识别可能能提供帮助的队友，与这些队友进行对话以收集信息，最后为原始用户提供有用的答案或摘要。该基准包含了两个评价领域：PeopleJoin-QA，专注于关于表格数据的问题解答；以及PeopleJoin-DocCreation，专注于文档创建任务。这两个领域分别从数据库问答和多文档摘要的现有NLP基准改编而来，但在这里所需完成任务的信息分散在一个由2到20名用户的合成“组织”中，模拟了自然的多人协作场景。文章实现了几种流行的语言模型代理架构，并对其在任务完成的准确性和效率进行了评估，同时指出了可以使用PeopleJoin研究的新研究问题。 <div>
arXiv:2502.12328v1 Announce Type: new 
Abstract: This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated collaborative problem solving. Given a user request, PeopleJoin agents must identify teammates who might be able to assist, converse with these teammates to gather information, and finally compile a useful answer or summary for the original user. PeopleJoin comprises two evaluation domains: PeopleJoin-QA, focused on questions about tabular data, and PeopleJoin-DocCreation, focused on document creation tasks. The two domains are adapted from existing NLP benchmarks for database question answering and multi-document summarization; here, however, the information needed to complete these tasks is distributed across synthetic ``organizations'' of 2--20 users, simulating natural multi-user collaboration scenarios. We implemented several popular LM agent architectures, evaluating their accuracy and efficiency at completing tasks, and highlight new research questions that can be studied using PeopleJoin.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stochastic Real-Time Deception in Nash Equilibrium Seeking for Games with Quadratic Payoffs</title>
<link>https://arxiv.org/abs/2502.12337</link>
<guid>https://arxiv.org/abs/2502.12337</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体自主系统、欺骗行为、纳什均衡寻求、随机探索信号、二次支付函数

总结:
本文研究了多智能体自主系统中的一种欺骗行为，该行为在模型无关的纳什均衡寻求(NES)框架下被深入探讨。玩家通过独立的随机探索信号来学习伪梯度流，而欺骗者能够实时获取其他玩家的随机扰动信息并将其融入自身NES动作更新中，从而引导整体动态至有利于欺骗者的新平衡点。文章重点关注具有二次支付函数的游戏，这种限制使我们能更明确地阐述欺骗者的策略能力。借助于多输入随机均化动力系统的成果，文章证明了所提出的欺骗性NES动态过程在局部上可以概率性指数收敛。最后，作者通过将理论应用到一个两玩家二次游戏中来展示其研究成果。<br /><br /> <div>
arXiv:2502.12337v1 Announce Type: new 
Abstract: In multi-agent autonomous systems, deception is a fundamental concept which characterizes the exploitation of unbalanced information to mislead victims into choosing oblivious actions. This effectively alters the system's long term behavior, leading to outcomes that may be beneficial to the deceiver but detrimental to victim. We study this phenomenon for a class of model-free Nash equilibrium seeking (NES) where players implement independent stochastic exploration signals to learn the pseudogradient flow. In particular, we show that deceptive players who obtain real-time measurements of other players' stochastic perturbation can incorporate this information into their own NES action update, consequentially steering the overall dynamics to a new operating point that could potentially improve the payoffs of the deceptive players. We consider games with quadratic payoff functions, as this restriction allows us to derive a more explicit formulation of the capabilities of the deceptive players. By leveraging results on multi-input stochastic averaging for dynamical systems, we establish local exponential (in probability) convergence for the proposed deceptive NES dynamics. To illustrate our results, we apply them to a two player quadratic game.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reward-Safety Balance in Offline Safe RL via Diffusion Regularization</title>
<link>https://arxiv.org/abs/2502.12391</link>
<guid>https://arxiv.org/abs/2502.12391</guid>
<content:encoded><![CDATA[
<div> 关键词：约束强化学习、离线设置、扩散模型、安全适应、奖励目标

总结:
本文关注的是在约束强化学习（RL）领域中，如何在仅有固定数据集的离线环境中寻求高效且安全的策略。为此，文章提出了Diffusion-Regularized Constrained Offline Reinforcement Learning（DRCORL）方法，该方法首先利用扩散模型从离线数据中捕获行为策略，然后提取简化策略以实现高效的推理。同时，通过梯度操纵进行安全适应，平衡奖励目标与满足约束之间的关系。DRCORL这种方法能够有效利用高质量的离线数据并结合安全性要求。实验证明，DRCORL在机器人学习任务上表现出可靠的性能，实现了快速推断和优秀的奖励结果，并相较于现有的安全离线RL方法，它能始终满足成本限制，且在同一组超参数下表现良好，显示出在现实场景中的实际应用潜力。 <div>
arXiv:2502.12391v1 Announce Type: new 
Abstract: Constrained reinforcement learning (RL) seeks high-performance policies under safety constraints. We focus on an offline setting where the agent has only a fixed dataset -- common in realistic tasks to prevent unsafe exploration. To address this, we propose Diffusion-Regularized Constrained Offline Reinforcement Learning (DRCORL), which first uses a diffusion model to capture the behavioral policy from offline data and then extracts a simplified policy to enable efficient inference. We further apply gradient manipulation for safety adaptation, balancing the reward objective and constraint satisfaction. This approach leverages high-quality offline data while incorporating safety requirements. Empirical results show that DRCORL achieves reliable safety performance, fast inference, and strong reward outcomes across robot learning tasks. Compared to existing safe offline RL methods, it consistently meets cost limits and performs well with the same hyperparameters, indicating practical applicability in real-world scenarios.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL</title>
<link>https://arxiv.org/abs/2502.12436</link>
<guid>https://arxiv.org/abs/2502.12436</guid>
<content:encoded><![CDATA[
<div> 关键词: AI, 识别欺骗, Diplomacy游戏, 逻辑形式提取, 骗局检测

总结:
本文探讨了AI如何帮助识别那些看似“好得不真实”的欺骗场景。研究通过分析策略性沟通和战略推理都需要的棋盘游戏"Diplomacy"中人类如何相互欺骗。文章提出的方法涉及从玩家交流中提取提议的逻辑形式，并利用代理的价值函数计算提议的相对收益，结合文本特征提高欺骗检测准确性。与大型语言模型相比，该方法在高精度下能更准确地识别人类的欺骗行为。未来的人工智能与人类交互工具可以借鉴这种方法，通过触发“摩擦”机制让用户有机会对可疑提案进行质询和审查。<br /><br /> <div>
arXiv:2502.12436v1 Announce Type: new 
Abstract: An increasingly prevalent socio-technical problem is people being taken in by offers that sound ``too good to be true'', where persuasion and trust shape decision-making. This paper investigates how \abr{ai} can help detect these deceptive scenarios. We analyze how humans strategically deceive each other in \textit{Diplomacy}, a board game that requires both natural language communication and strategic reasoning. This requires extracting logical forms of proposed agreements in player communications and computing the relative rewards of the proposal using agents' value functions. Combined with text-based features, this can improve our deception detection. Our method detects human deception with a high precision when compared to a Large Language Model approach that flags many true messages as deceptive. Future human-\abr{ai} interaction tools can build on our methods for deception detection by triggering \textit{friction} to give users a chance of interrogating suspicious proposals.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TherAIssist: Assisting Art Therapy Homework and Client-Practitioner Collaboration through Human-AI Interaction</title>
<link>https://arxiv.org/abs/2502.12443</link>
<guid>https://arxiv.org/abs/2502.12443</guid>
<content:encoded><![CDATA[
<div> 关键词：艺术治疗、作业支持、HCI系统、TherAIssist、人类-AI协作

总结:
本文介绍了针对艺术治疗领域的一项新研究，提出了一个名为TherAIssist的系统，该系统由面向客户的AI辅助共创艺术制作和对话式代理应用以及面向治疗师的应用组成，后者可定制作业代理并查看由AI编译的作业历史。通过一项为期30天的实地研究，涉及24名客户和5名治疗师，研究表明TherAIssist能够支持客户在日常生活环境中完成艺术治疗作业并进行反思。同时，治疗师可以利用该系统将实践原则和个人风格融入到AI代理中，提供个性化的家庭作业；AI编译的作业历史也成为治疗会议互动中的有意义资源。文章讨论了设计人类-AI系统以支持异步客户端-从业者协同工作的启示。 <div>
arXiv:2502.12443v1 Announce Type: new 
Abstract: Art therapy homework is essential for fostering clients' reflection on daily experiences between sessions. However, current practices present challenges: clients often lack guidance for completing tasks that combine art-making and verbal expression, while therapists find it difficult to track and tailor homework.How HCI systems might support art therapy homework remains underexplored. To address this, we present TherAIssist, comprising a client-facing application leveraging human-AI co-creative art-making and conversational agents to facilitate homework, and a therapist-facing application enabling customization of homework agents and AI-compiled homework history. A 30-day field study with 24 clients and 5 therapists showed how TherAIssist supported clients' homework and reflection in their everyday settings. Results also revealed how therapists infused their practice principles and personal touch into the agents to offer tailored homework, and how AI-compiled homework history became a meaningful resource for in-session interactions. Implications for designing human-AI systems to facilitate asynchronous client-practitioner collaboration are discussed.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Investigating and Extending Homans' Social Exchange Theory with Large Language Model based Agents</title>
<link>https://arxiv.org/abs/2502.12450</link>
<guid>https://arxiv.org/abs/2502.12450</guid>
<content:encoded><![CDATA[
<div> 关键词: Homans' Social Exchange Theory, 大规模语言模型, 人工智能, 虚拟社会, 社会交换游戏

总结:
本文提出了一种使用基于大规模语言模型(LLM)的智能体研究Homans' 社会交换理论(SET)的新方法。通过对三个LLM代理构建的虚拟社会进行社会交换游戏实验，作者验证了Homans' SET在代理社会中的有效性，证明了其行为与人类行为的一致性。进一步地，他们通过改变代理社会的设置扩展了传统的Homans' SET，使其更加全面和详细。此项工作标志着首次运用LLM基代理研究SET，并引入了一个连接社会科学与计算机科学的新型可行研究范式。相关代码已开源。 <div>
arXiv:2502.12450v1 Announce Type: new 
Abstract: Homans' Social Exchange Theory (SET) is widely recognized as a basic framework for understanding the formation and emergence of human civilizations and social structures. In social science, this theory is typically studied based on simple simulation experiments or real-world human studies, both of which either lack realism or are too expensive to control. In artificial intelligence, recent advances in large language models (LLMs) have shown promising capabilities in simulating human behaviors. Inspired by these insights, we adopt an interdisciplinary research perspective and propose using LLM-based agents to study Homans' SET. Specifically, we construct a virtual society composed of three LLM agents and have them engage in a social exchange game to observe their behaviors. Through extensive experiments, we found that Homans' SET is well validated in our agent society, demonstrating the consistency between the agent and human behaviors. Building on this foundation, we intentionally alter the settings of the agent society to extend the traditional Homans' SET, making it more comprehensive and detailed. To the best of our knowledge, this paper marks the first step in studying Homans' SET with LLM-based agents. More importantly, it introduces a novel and feasible research paradigm that bridges the fields of social science and computer science through LLM-based agents. Code is available at https://github.com/Paitesanshi/SET.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Empirical Evaluation of Encoder Architectures for Fast Real-Time Long Conversational Understanding</title>
<link>https://arxiv.org/abs/2502.12458</link>
<guid>https://arxiv.org/abs/2502.12458</guid>
<content:encoded><![CDATA[
<div> 关键词: 长文本分析、Transformer、高效Transformer变体、CNN架构、实时对话理解

<br /><br />总结:
本文探讨了在处理如客户电话转录文这样的长文本数据时，利用机器学习方法（尤其是Transformer）建模代理人与客户的交互所面临的挑战。由于Transformer的固定长度结构和自注意力机制对输入长度呈平方级增长，使得其在处理长序列任务（例如实时对话理解）时面临困难。为此，文章评估了最近提出的高效Transformer变体（如Performer、Reformer）以及一种基于CNN的架构。结果显示，相比于Transformer，CNN基模型在训练速度上快约2.6倍，推理速度快约80%，内存效率高约72%。此外，通过在Long Range Arena基准测试上评估CNN模型，证明了其在一般长文档分析方面的竞争力。 <div>
arXiv:2502.12458v1 Announce Type: new 
Abstract: Analyzing long text data such as customer call transcripts is a cost-intensive and tedious task. Machine learning methods, namely Transformers, are leveraged to model agent-customer interactions. Unfortunately, Transformers adhere to fixed-length architectures and their self-attention mechanism scales quadratically with input length. Such limitations make it challenging to leverage traditional Transformers for long sequence tasks, such as conversational understanding, especially in real-time use cases. In this paper we explore and evaluate recently proposed efficient Transformer variants (e.g. Performer, Reformer) and a CNN-based architecture for real-time and near real-time long conversational understanding tasks. We show that CNN-based models are dynamic, ~2.6x faster to train, ~80% faster inference and ~72% more memory efficient compared to Transformers on average. Additionally, we evaluate the CNN model using the Long Range Arena benchmark to demonstrate competitiveness in general long document analysis.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.12486</link>
<guid>https://arxiv.org/abs/2502.12486</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs), Strategic Reasoning, Explicit Policy Optimization (EPO), Reinforcement Learning (RL), Self-Play

总结:
本文提出了一种名为显式策略优化（EPO）的方法，用于解决大型语言模型（LLMs）在复杂如商业谈判等需要战略推理的真实场景中的能力不足问题。EPO的特点在于它能为开放性行动空间提供策略，并能够被插入到任意LLM代理中以引导目标导向的行为。为了提高适应性和策略转移性，EPO通过多回合强化学习训练战略推理模型，使用过程奖励和迭代自我对弈，而不依赖监督微调（SFT）作为预处理步骤。实验结果显示，EPO在社会对话和网页导航任务上表现出先进的长期目标对齐能力和增强的战略推理能力，显示出其在现实世界应用中的潜在价值。此外，研究还揭示了EPO中涌现出的各种协作推理机制及其在生成新颖策略上的有效性。 <div>
arXiv:2502.12486v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown impressive reasoning capabilities in well-defined problems with clear solutions, such as mathematics and coding. However, they still struggle with complex real-world scenarios like business negotiations, which require strategic reasoning-an ability to navigate dynamic environments and align long-term goals amidst uncertainty. Existing methods for strategic reasoning face challenges in adaptability, scalability, and transferring strategies to new contexts. To address these issues, we propose explicit policy optimization (EPO) for strategic reasoning, featuring an LLM that provides strategies in open-ended action space and can be plugged into arbitrary LLM agents to motivate goal-directed behavior. To improve adaptability and policy transferability, we train the strategic reasoning model via multi-turn reinforcement learning (RL) using process rewards and iterative self-play, without supervised fine-tuning (SFT) as a preliminary step. Experiments across social and physical domains demonstrate EPO's ability of long-term goal alignment through enhanced strategic reasoning, achieving state-of-the-art performance on social dialogue and web navigation tasks. Our findings reveal various collaborative reasoning mechanisms emergent in EPO and its effectiveness in generating novel strategies, underscoring its potential for strategic reasoning in real-world applications.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EDGE: Efficient Data Selection for LLM Agents via Guideline Effectiveness</title>
<link>https://arxiv.org/abs/2502.12494</link>
<guid>https://arxiv.org/abs/2502.12494</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，数据质量，EDGE，Guideline Effectiveness (GE) 指标，样本选择

总结:<br />
本文提出了一种针对大型语言模型（LLMs）的新方法——EDGE，用于在无需黄金答案的情况下识别具有信息性的样本，以提升AI代理的能力。为了实现这一目标，文章提出了衡量人类提供的指导原则在多轮交互任务中影响力的Guideline Effectiveness (GE) 指标。GE分数低表示该样本所需的专家知识在指南中缺失，从而使其更具信息性。通过选取GE分数低的样本，可以更有效地改进LLM的提示工程和微调过程。实验结果表明，EDGE方法在HotpotQA和WebShop数据集上取得了与现有方法竞争的结果，同时分别只需要75%和50%的数据量就能取得更好的性能，为LLM代理微调的数据质量问题提供了新的视角。 <div>
arXiv:2502.12494v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown remarkable capabilities as AI agents. However, existing methods for enhancing LLM-agent abilities often lack a focus on data quality, leading to inefficiencies and suboptimal results in both fine-tuning and prompt engineering. To address this issue, we introduce EDGE, a novel approach for identifying informative samples without needing golden answers. We propose the Guideline Effectiveness (GE) metric, which selects challenging samples by measuring the impact of human-provided guidelines in multi-turn interaction tasks. A low GE score indicates that the human expertise required for a sample is missing from the guideline, making the sample more informative. By selecting samples with low GE scores, we can improve the efficiency and outcomes of both prompt engineering and fine-tuning processes for LLMs. Extensive experiments validate the performance of our method. Our method achieves competitive results on the HotpotQA and WebShop and datasets, requiring 75\% and 50\% less data, respectively, while outperforming existing methods. We also provide a fresh perspective on the data quality of LLM-agent fine-tuning.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simulating Cooperative Prosocial Behavior with Multi-Agent LLMs: Evidence and Mechanisms for AI Agents to Inform Policy Decisions</title>
<link>https://arxiv.org/abs/2502.12504</link>
<guid>https://arxiv.org/abs/2502.12504</guid>
<content:encoded><![CDATA[
<div> 关键词：人类合作、多智能体LLM系统、公共物品游戏、实验治疗、现实世界行为

<br />
总结：
本文研究了多智能体LLM系统模拟人类亲社会行为的能力，如在公共物品游戏中所体现的行为，并探讨该系统是否能展现现实世界中实验室以外的“无界行为”。文章发现，LLM系统成功复制了关于公共物品游戏的人类实验行为，包括priming、transparency和不同初始分配等三种实验处理。此外，即使没有先前结合这些特定处理的研究，LLM系统也能在组合实验处理的情况下复制预期的人类行为。最后，研究还发现多智能体系统能够展示现实中人们可能会采取的丰富多元的无界行为，比如协作甚至作弊。总之，这些研究表明未来可以利用LLM系统来指导鼓励人们表现出亲社会行为的政策决策。 <div>
arXiv:2502.12504v1 Announce Type: new 
Abstract: Human prosocial cooperation is essential for our collective health, education, and welfare. However, designing social systems to maintain or incentivize prosocial behavior is challenging because people can act selfishly to maximize personal gain. This complex and unpredictable aspect of human behavior makes it difficult for policymakers to foresee the implications of their designs. Recently, multi-agent LLM systems have shown remarkable capabilities in simulating human-like behavior, and replicating some human lab experiments. This paper studies how well multi-agent systems can simulate prosocial human behavior, such as that seen in the public goods game (PGG), and whether multi-agent systems can exhibit ``unbounded actions'' seen outside the lab in real world scenarios. We find that multi-agent LLM systems successfully replicate human behavior from lab experiments of the public goods game with three experimental treatments - priming, transparency, and varying endowments. Beyond replicating existing experiments, we find that multi-agent LLM systems can replicate the expected human behavior when combining experimental treatments, even if no previous study combined those specific treatments. Lastly, we find that multi-agent systems can exhibit a rich set of unbounded actions that people do in the real world outside of the lab -- such as collaborating and even cheating. In sum, these studies are steps towards a future where LLMs can be used to inform policy decisions that encourage people to act in a prosocial manner.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Policy-to-Language: Train LLMs to Explain Decisions with Flow-Matching Generated Rewards</title>
<link>https://arxiv.org/abs/2502.12530</link>
<guid>https://arxiv.org/abs/2502.12530</guid>
<content:encoded><![CDATA[
<div> 关键词：RL、LLMs、解释生成器、奖励生成模型、自然语言

总结:
本文提出了一种新的模型-agnostic解释生成器，该生成器基于大型语言模型（LLM），用于在人类与由RL和LLMs等技术驱动的多样化智能体共享环境中生成自然语言策略解释。文章的技术创新点在于使用了一个生成流匹配模型来产生训练LLM的奖励，这个模型具有特殊结构，其隐藏层与LLM相结合，能利用解释的语义线索生成合适的奖励。实验结果显示，这种方法能在节省昂贵的人工反馈的同时，生成密集有效的奖励，进而实现有效的解释生成，并甚至提高了原任务决策的准确性。 <div>
arXiv:2502.12530v1 Announce Type: new 
Abstract: As humans increasingly share environments with diverse agents powered by RL, LLMs, and beyond, the ability to explain their policies in natural language will be vital for reliable coexistence. In this paper, we build a model-agnostic explanation generator based on an LLM. The technical novelty is that the rewards for training this LLM are generated by a generative flow matching model. This model has a specially designed structure with a hidden layer merged with an LLM to harness the linguistic cues of explanations into generating appropriate rewards. Experiments on both RL and LLM tasks demonstrate that our method can generate dense and effective rewards while saving on expensive human feedback; it thus enables effective explanations and even improves the accuracy of the decisions in original tasks.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space</title>
<link>https://arxiv.org/abs/2502.12532</link>
<guid>https://arxiv.org/abs/2502.12532</guid>
<content:encoded><![CDATA[
<div> 关键词：Embodied Question Answering (EQA)，CityEQA，CityEQA-EC，Planner-Manager-Actor (PMA)，视觉推理

总结:
本文提出了一个新的任务——CityEQA，旨在解决在动态城市环境中基于实体的问答问题，这一领域此前的研究相对匮乏。为了支持此任务，作者构建了首个名为CityEQA-EC的基准数据集，其中包含了1,412个人工标注的任务，这些任务分布在六个类别中，并扎根于一个逼真的3D城市模拟器之中。此外，文章提出了一种针对CityEQA的新型智能体PMA，该智能体能进行长期规划和分层任务执行。实验表明，PMA在人类水平上的回答准确率达到了60.7%，显著优于前沿基线方法。尽管有进步，但与人类相比仍存在的性能差距强调了在CityEQA中增强视觉推理的需求。这项工作为未来城市空间智能的发展奠定了基础。相关的数据集和代码已在GitHub上发布。 <div>
arXiv:2502.12532v1 Announce Type: new 
Abstract: Embodied Question Answering (EQA) has primarily focused on indoor environments, leaving the complexities of urban settings - spanning environment, action, and perception - largely unexplored. To bridge this gap, we introduce CityEQA, a new task where an embodied agent answers open-vocabulary questions through active exploration in dynamic city spaces. To support this task, we present CityEQA-EC, the first benchmark dataset featuring 1,412 human-annotated tasks across six categories, grounded in a realistic 3D urban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical task execution: the Planner breaks down the question answering into sub-tasks, the Manager maintains an object-centric cognitive map for spatial reasoning during the process control, and the specialized Actors handle navigation, exploration, and collection sub-tasks. Experiments demonstrate that PMA achieves 60.7% of human-level answering accuracy, significantly outperforming frontier-based baselines. While promising, the performance gap compared to humans highlights the need for enhanced visual reasoning in CityEQA. This work paves the way for future advancements in urban spatial intelligence. Dataset and code are available at https://github.com/BiluYong/CityEQA.git.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design</title>
<link>https://arxiv.org/abs/2502.12561</link>
<guid>https://arxiv.org/abs/2502.12561</guid>
<content:encoded><![CDATA[
<div> 关键词: usability testing, Large Language Model-simulated Agent (LLM-Agent), UXAgent, simulated users, heuristic user evaluation

总结:
本文介绍了科研论文arXiv:2502.12561v1，该文提出了一种名为UXAgent的新系统，旨在帮助用户体验(UX)研究者在进行真实人类主体研究前评估和迭代可用性测试研究设计。UXAgent系统包括LLM-Agent模块和通用浏览器连接器模块，能自动生成数千个模拟用户来测试目标网站，并以定性（如：模拟用户的思考过程）、定量（如：动作数量）和视频记录的形式提供结果供研究者分析。通过与五位UX研究者的启发式用户评估，参与者赞扬了系统的创新性，但也表达了对LLM Agent辅助UX研究未来发展的担忧。 <div>
arXiv:2502.12561v1 Announce Type: new 
Abstract: Usability testing is a fundamental yet challenging (e.g., inflexible to iterate the study design flaws and hard to recruit study participants) research method for user experience (UX) researchers to evaluate a web design. Recent advances in Large Language Model-simulated Agent (LLM-Agent) research inspired us to design UXAgent to support UX researchers in evaluating and reiterating their usability testing study design before they conduct the real human subject study. Our system features an LLM-Agent module and a universal browser connector module so that UX researchers can automatically generate thousands of simulated users to test the target website. The results are shown in qualitative (e.g., interviewing how an agent thinks ), quantitative (e.g., # of actions), and video recording formats for UX researchers to analyze. Through a heuristic user evaluation with five UX researchers, participants praised the innovation of our system but also expressed concerns about the future of LLM Agent-assisted UX study.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sample Efficient Omniprediction and Downstream Swap Regret for Non-Linear Losses</title>
<link>https://arxiv.org/abs/2502.12564</link>
<guid>https://arxiv.org/abs/2502.12564</guid>
<content:encoded><![CDATA[
<div> 关键词: 决策交换后悔、在线对抗环境、多维度Lipschitz损失函数、批量设置、在线到批量转换、无穷预测、下游后悔预测、线性损失、非线性损失函数、常数弹性替代(CES)、Cobb-Douglas、Leontief效用函数。

<br /><br />总结:
本文提出了“决策交换后悔”概念，它同时涵盖了下游交换后悔预测和无穷预测问题，并为任意多维度Lipschitz损失函数在在线对抗环境中提供了算法。此外，通过在线到批量转换，文中还给出了批量设置下的样本复杂度界限。在无穷预测方面，该算法首次为Lipschitz损失函数提供了多项式级别的样本复杂度界，而此前的成果要么仅适用于线性损失或二元结果，要么在假设损失函数为凸函数的情况下错误参数依然呈指数级增长。在下游后悔预测方面，文章提出首个能对具有非线性损失函数的多维结果空间中的所有下游代理保证交换后悔界限的算法。先前的工作仅针对线性损失函数，模型化了风险中性的代理。虽然一般情况下的界随着结果空间的维度指数增加，但文中对于经济领域重点关注的一些多维函数家族（如：常数弹性替代函数、Cobb-Douglas和Leontief效用函数）提供了改进的后悔和样本复杂度界。 <div>
arXiv:2502.12564v1 Announce Type: new 
Abstract: We define "decision swap regret" which generalizes both prediction for downstream swap regret and omniprediction, and give algorithms for obtaining it for arbitrary multi-dimensional Lipschitz loss functions in online adversarial settings. We also give sample complexity bounds in the batch setting via an online-to-batch reduction. When applied to omniprediction, our algorithm gives the first polynomial sample-complexity bounds for Lipschitz loss functions -- prior bounds either applied only to linear loss (or binary outcomes) or scaled exponentially with the error parameter even under the assumption that the loss functions were convex. When applied to prediction for downstream regret, we give the first algorithm capable of guaranteeing swap regret bounds for all downstream agents with non-linear loss functions over a multi-dimensional outcome space: prior work applied only to linear loss functions, modeling risk neutral agents. Our general bounds scale exponentially with the dimension of the outcome space, but we give improved regret and sample complexity bounds for specific families of multidimensional functions of economic interest: constant elasticity of substitution (CES), Cobb-Douglas, and Leontief utility functions.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent</title>
<link>https://arxiv.org/abs/2502.12575</link>
<guid>https://arxiv.org/abs/2502.12575</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM-based agents、backdoor攻击、安全审计、动态加密、多后门植入攻击

总结:
随着基于LLM的大规模语言模型代理变得日益普遍，通过用户查询或环境反馈向代理中植入后门的安全隐患越来越引起关注。针对这一问题，本文提出了一个新颖的动态加密多后门植入攻击策略——“动态加密多后门植入攻击”。该策略利用动态加密技术将后门映射为良性内容，有效规避了现有的安全性审计。为了增强隐秘性，作者还将后门分解为多个子后门片段。实验结果显示，这种方法能够在几乎保持100%攻击成功率的同时，维持0%的检测率，显示出了其在绕过安全审计方面的高效率。此外，文章还提出了用于全面评估智能体后门攻击的AgentBackdoorEval数据集。这些实验结果突显了现有安全机制在检测高级攻击时的局限性，强调了亟需更为强大的防御手段来应对后门威胁。相关代码和数据可在https://github.com/whfeLingYu/DemonAgent获取。 <div>
arXiv:2502.12575v1 Announce Type: new 
Abstract: As LLM-based agents become increasingly prevalent, backdoors can be implanted into agents through user queries or environment feedback, raising critical concerns regarding safety vulnerabilities. However, backdoor attacks are typically detectable by safety audits that analyze the reasoning process of agents. To this end, we propose a novel backdoor implantation strategy called \textbf{Dynamically Encrypted Multi-Backdoor Implantation Attack}. Specifically, we introduce dynamic encryption, which maps the backdoor into benign content, effectively circumventing safety audits. To enhance stealthiness, we further decompose the backdoor into multiple sub-backdoor fragments. Based on these advancements, backdoors are allowed to bypass safety audits significantly. Additionally, we present AgentBackdoorEval, a dataset designed for the comprehensive evaluation of agent backdoor attacks. Experimental results across multiple datasets demonstrate that our method achieves an attack success rate nearing 100\% while maintaining a detection rate of 0\%, illustrating its effectiveness in evading safety audits. Our findings highlight the limitations of existing safety mechanisms in detecting advanced attacks, underscoring the urgent need for more robust defenses against backdoor threats. Code and data are available at https://github.com/whfeLingYu/DemonAgent.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hypernetwork-based approach for optimal composition design in partially controlled multi-agent systems</title>
<link>https://arxiv.org/abs/2502.12605</link>
<guid>https://arxiv.org/abs/2502.12605</guid>
<content:encoded><![CDATA[
<div> 关键词：Partially Controlled Multi-Agent Systems (PCMAS)，优化设计问题，双层优化，超网络框架，强化学习

总结:
文章研究了部分受控多智能体系统(PCMAS)中的最优组合设计问题，涉及系统设计者如何确定可控智能体的数量和策略，以及不可控智能体的最佳响应策略。针对这一双层优化问题的计算复杂性，文中提出了一种基于超网络的新框架，该框架能联合优化系统的组成与各智能体的策略，通过统一的超网络为可控和不可控智能体生成策略，有效实现相似配置间的信息共享，降低了计算开销。此外，还引入了奖励参数优化和均值动作网络以进一步提升性能。利用真实世界的数据（纽约市出租车数据），实验表明该框架在逼近均衡策略方面优于现有方法，显著改善了订单响应率和服务需求等关键性能指标，证实了控制智能体在PCMAS中增强决策能力的实用价值和潜力。 <div>
arXiv:2502.12605v1 Announce Type: new 
Abstract: Partially Controlled Multi-Agent Systems (PCMAS) are comprised of controllable agents, managed by a system designer, and uncontrollable agents, operating autonomously. This study addresses an optimal composition design problem in PCMAS, which involves the system designer's problem, determining the optimal number and policies of controllable agents, and the uncontrollable agents' problem, identifying their best-response policies. Solving this bi-level optimization problem is computationally intensive, as it requires repeatedly solving multi-agent reinforcement learning problems under various compositions for both types of agents. To address these challenges, we propose a novel hypernetwork-based framework that jointly optimizes the system's composition and agent policies. Unlike traditional methods that train separate policy networks for each composition, the proposed framework generates policies for both controllable and uncontrollable agents through a unified hypernetwork. This approach enables efficient information sharing across similar configurations, thereby reducing computational overhead. Additional improvements are achieved by incorporating reward parameter optimization and mean action networks. Using real-world New York City taxi data, we demonstrate that our framework outperforms existing methods in approximating equilibrium policies. Our experimental results show significant improvements in key performance metrics, such as order response rate and served demand, highlighting the practical utility of controlling agents and their potential to enhance decision-making in PCMAS.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Implicit Repair with Reinforcement Learning in Emergent Communication</title>
<link>https://arxiv.org/abs/2502.12624</link>
<guid>https://arxiv.org/abs/2502.12624</guid>
<content:encoded><![CDATA[
<div> 关键词：对话修复、隐性修复机制、冗余、通信通道噪声、Lewis游戏

<br /><br />总结：
本文探讨了在多代理互动中的对话修复机制，特别是关注隐性修复机制，即通过交互方式防止错误信息传播。研究通过扩展名为Lewis Game的信号博弈模型，引入通信通道和代理人输入的噪声，分析发现代理人会通过增加消息传输的冗余性来抵消噪声对任务成功率的负面影响。同时，文章指出，即便在带有噪声的情况下，所涌现的通信协议仍能保持与确定性简单游戏中使用的架构相当的泛化能力。而且，这种方法是唯一适用于生成既能处理有噪声又能处理无噪声情况的同时保持较高泛化性能水平的鲁棒通信协议的方法。 <div>
arXiv:2502.12624v1 Announce Type: new 
Abstract: Conversational repair is a mechanism used to detect and resolve miscommunication and misinformation problems when two or more agents interact. One particular and underexplored form of repair in emergent communication is the implicit repair mechanism, where the interlocutor purposely conveys the desired information in such a way as to prevent misinformation from any other interlocutor. This work explores how redundancy can modify the emergent communication protocol to continue conveying the necessary information to complete the underlying task, even with additional external environmental pressures such as noise. We focus on extending the signaling game, called the Lewis Game, by adding noise in the communication channel and inputs received by the agents. Our analysis shows that agents add redundancy to the transmitted messages as an outcome to prevent the negative impact of noise on the task success. Additionally, we observe that the emerging communication protocol's generalization capabilities remain equivalent to architectures employed in simpler games that are entirely deterministic. Additionally, our method is the only one suitable for producing robust communication protocols that can handle cases with and without noise while maintaining increased generalization performance levels.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automating Prompt Leakage Attacks on Large Language Models Using Agentic Approach</title>
<link>https://arxiv.org/abs/2502.12630</link>
<guid>https://arxiv.org/abs/2502.12630</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、安全性评估、提示泄漏、多智能体系统、加密安全性框架

总结:
本文提出了一种针对大型语言模型（LLMs）提示泄漏安全性的新颖评估方法。文章将提示泄漏定义为威胁安全部署的关键问题，并引入了一个使用合作智能体来测试LLM抗泄露韧性的框架。借鉴传统密码学中的安全性定义，文章进一步定义了无提示泄漏安全系统的标准——即攻击者无法区分初始化时带有原始提示和剥离敏感信息提示的两个智能体，确保在这样的安全系统中，敏感信息得以保全。这个受到密码学启发的框架为评估和设计安全的LLMs提供了严格的标准。此外，文章还确立了一种针对提示泄漏的系统化对抗性测试方法，填补了自动化威胁建模与实际LLM安全性之间的空白。相关实现已发布在GitHub上。 <div>
arXiv:2502.12630v1 Announce Type: new 
Abstract: This paper presents a novel approach to evaluating the security of large language models (LLMs) against prompt leakage-the exposure of system-level prompts or proprietary configurations. We define prompt leakage as a critical threat to secure LLM deployment and introduce a framework for testing the robustness of LLMs using agentic teams. Leveraging AG2 (formerly AutoGen), we implement a multi-agent system where cooperative agents are tasked with probing and exploiting the target LLM to elicit its prompt.
  Guided by traditional definitions of security in cryptography, we further define a prompt leakage-safe system as one in which an attacker cannot distinguish between two agents: one initialized with an original prompt and the other with a prompt stripped of all sensitive information. In a safe system, the agents' outputs will be indistinguishable to the attacker, ensuring that sensitive information remains secure. This cryptographically inspired framework provides a rigorous standard for evaluating and designing secure LLMs.
  This work establishes a systematic methodology for adversarial testing of prompt leakage, bridging the gap between automated threat modeling and practical LLM security.
  You can find the implementation of our prompt leakage probing on GitHub.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Computing Efficient Envy-Free Partial Allocations of Indivisible Goods</title>
<link>https://arxiv.org/abs/2502.12644</link>
<guid>https://arxiv.org/abs/2502.12644</guid>
<content:encoded><![CDATA[
<div> 关键词：envy-freeness、efficiency、computational complexity、partial allocations、ternary utilities

总结：
本文探讨了在分配不可分割商品时，放宽标准效率概念对有效公平分配问题的计算复杂性影响。研究发现，即使允许部分分配并仅施加非常温和的效率约束（如确保每个代理获得具有正效用的物品集合），这种看似微弱的效率要求也会导致计算复杂性的多样性。对于二元效用情况，论文识别出了多项式时间可解或固定参数可解的情形；然而，即便在涉及三元效用的非常受限场景中，也发现了NP-难度问题。 <div>
arXiv:2502.12644v1 Announce Type: new 
Abstract: Envy-freeness is one of the most prominent fairness concepts in the allocation of indivisible goods. Even though trivial envy-free allocations always exist, rich literature shows this is not true when one additionally requires some efficiency concept (e.g., completeness, Pareto-efficiency, or social welfare maximization). In fact, in such case even deciding the existence of an efficient envy-free allocation is notoriously computationally hard. In this paper, we explore the limits of efficient computability by relaxing standard efficiency concepts and analyzing how this impacts the computational complexity of the respective problems. Specifically, we allow partial allocations (where not all goods are allocated) and impose only very mild efficiency constraints, such as ensuring each agent receives a bundle with positive utility. Surprisingly, even such seemingly weak efficiency requirements lead to a diverse computational complexity landscape. We identify several polynomial-time solvable or fixed-parameter tractable cases for binary utilities, yet we also find NP-hardness in very restricted scenarios involving ternary utilities.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Free Energy and Network Structure: Breaking Scale-Free Behaviour Through Information Processing Constraints</title>
<link>https://arxiv.org/abs/2502.12654</link>
<guid>https://arxiv.org/abs/2502.12654</guid>
<content:encoded><![CDATA[
<div> 关键词：Free Energy Principle (FEP)，网络行为，信息处理，度分布，节点行为

<br /><br />总结:

本文提出自由能原理（FEP）可以解释现实世界网络为何偏离尺度自由行为，以及这种特征偏差如何源自信息处理的约束。文章建立了一个最小化的FEP模型来描述节点行为，并发现了三个不同阶段：当检测噪声占主导时，代理（agent）寻求更好的信息，从而减少了与经典偏好附着预期中的孤立代理数量；在最优检测阶段，由于检测、信念和行动的累积改进，出现超线性增长，形成了优选的聚类规模；最后，随着代理人信息处理能力的极限达到，聚类增长趋于饱和。这些阶段产生了现实中观察到的膝形度分布，将其解释为在有限信息处理能力和约束下具有最优信息处理特性的代理人的标志。文章进一步表明，遵循FEP原则演化的代理人提供了一种偏好附着的机制，将代理的心理学与其宏观网络特征联系起来，这些特征构成了现实世界网络的基础结构。 <div>
arXiv:2502.12654v1 Announce Type: new 
Abstract: In this paper we show how The Free Energy Principle (FEP) can provide an explanation for why real-world networks deviate from scale-free behaviour, and how these characteristic deviations can emerge from constraints on information processing. We propose a minimal FEP model for node behaviour reveals three distinct regimes: when detection noise dominates, agents seek better information, reducing isolated agents compared to expectations from classical preferential attachment. In the optimal detection regime, super-linear growth emerges from compounded improvements in detection, belief, and action, which produce a preferred cluster scale. Finally, saturation effects occur as limits on the agent's information processing capabilities prevent indefinite cluster growth. These regimes produce the knee-shaped degree distributions observed in real networks, explaining them as signatures of agents with optimal information processing under constraints. We show that agents evolving under FEP principles provides a mechanism for preferential attachment, connecting agent psychology with the macroscopic network features that underpin the structure of real-world networks.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research</title>
<link>https://arxiv.org/abs/2502.12669</link>
<guid>https://arxiv.org/abs/2502.12669</guid>
<content:encoded><![CDATA[
<div> 关键词: perovskite太阳能电池、知识图谱、Perovskite-KG、问题回答对、Perovskite-Chat-LLM

总结:<br />
本文提出了一种针对钙钛矿太阳能电池（PSCs）领域的综合知识增强系统。该系统包括三个主要组件：首先构建了基于1,517篇研究论文的PSC领域特定知识图谱——Perovskite-KG，包含了23,789个实体和22,272条关系；其次，创建了两个互补数据集，分别是通过创新多代理框架生成的55,101组高质量问答对组成的Perovskite-Chat以及包含2,217个精细编排的材料科学问题的Perovskite-Reasoning；最后，推出了两个专门的大规模语言模型，即用于领域特定知识辅助的Perovskite-Chat-LLM和用于科学推理任务的Perovskite-Reasoning-LLM。实验结果显示，该系统在PSC领域的知识检索和科学推理任务上显著优于现有模型，为研究人员提供了进行文献回顾、实验设计和解决复杂问题的有效工具。 <div>
arXiv:2502.12669v1 Announce Type: new 
Abstract: The rapid advancement of perovskite solar cells (PSCs) has led to an exponential growth in research publications, creating an urgent need for efficient knowledge management and reasoning systems in this domain. We present a comprehensive knowledge-enhanced system for PSCs that integrates three key components. First, we develop Perovskite-KG, a domain-specific knowledge graph constructed from 1,517 research papers, containing 23,789 entities and 22,272 relationships. Second, we create two complementary datasets: Perovskite-Chat, comprising 55,101 high-quality question-answer pairs generated through a novel multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully curated materials science problems. Third, we introduce two specialized large language models: Perovskite-Chat-LLM for domain-specific knowledge assistance and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental results demonstrate that our system significantly outperforms existing models in both domain-specific knowledge retrieval and scientific reasoning tasks, providing researchers with effective tools for literature review, experimental design, and complex problem-solving in PSC research.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Novelty: Improve the Diversity and Novelty of Contents Generated by Large Language Models via inference-time Multi-Views Brainstorming</title>
<link>https://arxiv.org/abs/2502.12700</link>
<guid>https://arxiv.org/abs/2502.12700</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型（LLMs）、多样性、新颖性、多视图头脑风暴方法、 Multi-Novelty

总结:<br />
本文针对大规模语言模型（LLMs）在生成文本时存在的多样性与新颖性不足的问题，提出了一种名为“多视图头脑风暴方法”的推理时增强策略。该方法通过结合文本和视觉来源的多元视角来丰富输入提示，即所谓的“Multi-Novelty”，旨在增加生成结果的多样性和创造性。重要的是，此方法具有模型无关性，无需对模型架构进行修改，可兼容开源及专有LLMs。 <div>
arXiv:2502.12700v1 Announce Type: new 
Abstract: Large Language Models (LLMs) demonstrate remarkable proficiency in generating accurate and fluent text. However, they often struggle with diversity and novelty, leading to repetitive or overly deterministic responses. These limitations stem from constraints in training data, including gaps in specific knowledge domains, outdated information, and an over-reliance on textual sources. Such shortcomings reduce their effectiveness in tasks requiring creativity, multi-perspective reasoning, and exploratory thinking, such as LLM based AI scientist agents and creative artist agents . To address this challenge, we introduce inference-time multi-view brainstorming method, a novel approach that enriches input prompts with diverse perspectives derived from both textual and visual sources, which we refere to as "Multi-Novelty". By incorporating additional contextual information as diverse starting point for chain of thoughts, this method enhances the variety and creativity of generated outputs. Importantly, our approach is model-agnostic, requiring no architectural modifications and being compatible with both open-source and proprietary LLMs.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Maximizing Truth Learning in a Social Network is NP-hard</title>
<link>https://arxiv.org/abs/2502.12704</link>
<guid>https://arxiv.org/abs/2502.12704</guid>
<content:encoded><![CDATA[
<div> 关键词：Sequential learning、social network、network topology、ordering、NP-hard

总结:
本文研究了在社交网络中的序列学习模型，其中代理人根据自己的私人噪声测量值和前序代理人的预测来预测地面真实情况。在该网络中，代理人仅能看到自己邻域内先前代理人的行动。正确预测地面真实情况的代理人比例与网络拓扑结构及预测顺序密切相关。文章指出，在一般网络结构下，寻找能够最大化（预期）预测正确的代理人数量的顺序问题，在贝叶斯学习模型和简单多数规则模型下均被证明为NP-hard。此外，文章还表明这个问题的近似解法也具有困难性。 <div>
arXiv:2502.12704v1 Announce Type: new 
Abstract: Sequential learning models situations where agents predict a ground truth in sequence, by using their private, noisy measurements, and the predictions of agents who came earlier in the sequence. We study sequential learning in a social network, where agents only see the actions of the previous agents in their own neighborhood. The fraction of agents who predict the ground truth correctly depends heavily on both the network topology and the ordering in which the predictions are made. A natural question is to find an ordering, with a given network, to maximize the (expected) number of agents who predict the ground truth correctly. In this paper, we show that it is in fact NP-hard to answer this question for a general network, with both the Bayesian learning model and a simple majority rule model. Finally, we show that even approximating the answer is hard.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MediaMind: Revolutionizing Media Monitoring using Agentification</title>
<link>https://arxiv.org/abs/2502.12745</link>
<guid>https://arxiv.org/abs/2502.12745</guid>
<content:encoded><![CDATA[
<div> 关键词：agentification、MediaMind、aiXplain、智能代理、实时分析

<br /><br />总结:
本文探讨了随着技术迅速发展，软件工具的智能化（agentification）成为关键创新，通过以MediaMind作为案例研究展示了如何将现有软件转变为具有独立决策和动态交互能力的智能代理。MediaMind是由aiXplain开发的一款利用基于代理的架构，能够实时监控、分析并从多语种媒体内容中提供洞察的产品。文章重点介绍了实现MediaMind智能化的技术方法和设计原则，强调了智能化如何提高其适应性、效率和响应速度。通过详细案例和实例说明，MediaMind的智能化赋能企业优化工作流程、提升决策效率以及更好地应对变化趋势。文章进一步指出，软件工具的智能化在各个领域都具有广泛的应用潜力。 <div>
arXiv:2502.12745v1 Announce Type: new 
Abstract: In an era of rapid technological advancements, agentification of software tools has emerged as a critical innovation, enabling systems to function autonomously and adaptively. This paper introduces MediaMind as a case study to demonstrate the agentification process, highlighting how existing software can be transformed into intelligent agents capable of independent decision-making and dynamic interaction. Developed by aiXplain, MediaMind leverages agent-based architecture to autonomously monitor, analyze, and provide insights from multilingual media content in real time. The focus of this paper is on the technical methodologies and design principles behind agentifying MediaMind, showcasing how agentification enhances adaptability, efficiency, and responsiveness. Through detailed case studies and practical examples, we illustrate how the agentification of MediaMind empowers organizations to streamline workflows, optimize decision-making, and respond to evolving trends. This work underscores the broader potential of agentification to revolutionize software tools across various domains.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Individually Rational Recommender System under Stochastic Order</title>
<link>https://arxiv.org/abs/2502.12766</link>
<guid>https://arxiv.org/abs/2502.12766</guid>
<content:encoded><![CDATA[
<div> 关键词：推荐系统、探索与利用、个体理性、规划问题、激励相容算法

<br /><br />总结:
该文关注在线应用中推荐系统的探索与利用平衡问题，特别是在考虑个体理性约束的背景下。当用户有默认选择时，推荐系统应确保用户的收益至少不低于默认选择的收益水平。文章假设奖励服从随机分布（如伯努利或单位方差高斯分布），并提出了一种近似最优算法，该算法基于一个具有独立研究价值的辅助目标马尔可夫决策过程。此外，文中还介绍了该算法的一种激励相容版本。 <div>
arXiv:2502.12766v1 Announce Type: new 
Abstract: With the rise of online applications, recommender systems (RSs) often encounter constraints in balancing exploration and exploitation. Such constraints arise when exploration is carried out by agents whose individual utility should be balanced with overall welfare. Recent work suggests that recommendations should be individually rational. Specifically, if agents have a default arm they would use, relying on the RS should yield each agent at least the reward of the default arm, conditioned on the knowledge available to the RS. Under this individual rationality constraint, striking a balance between exploration and exploitation becomes a complex planning problem. We assume a stochastic order of the rewards (e.g., Bernoulli, unit-variance Gaussian, etc.), and derive an approximately optimal algorithm. Our technique is based on an auxiliary Goal Markov Decision Process problem that is of independent interest. Additionally, we present an incentive-compatible version of our algorithm.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs</title>
<link>https://arxiv.org/abs/2502.12767</link>
<guid>https://arxiv.org/abs/2502.12767</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 知识图谱, R2-KG, 双代理框架, 可靠性

总结:
本文介绍了一种新的知识图谱增强推理框架R2-KG，该框架采用插件式、双代理设计，将推理任务分为证据收集（由低容量的大型语言模型即Operator执行）和最终判断（由高容量的大型语言模型即Supervisor执行），以降低成本同时保持高推理准确性。R2-KG还引入了弃权机制，仅在从知识图谱收集到充分证据时才生成答案，从而显著提高可靠性。实验表明，无论使用何种能力的大型语言模型作为Operator，R2-KG在多个基于知识图谱的推理任务上均表现出更高的准确性和可靠性。此外，文章还探讨了单代理版本的R2-KG，其通过严格的自我一致性策略可在降低推理成本的同时显著提升可靠性，但可能会在复杂知识图谱中导致较高的弃权率。总的来说，R2-KG为基于知识图谱的推理提供了一个灵活、低成本并确保可信推断的解决方案，降低了对高容量大型语言模型的依赖。 <div>
arXiv:2502.12767v1 Announce Type: new 
Abstract: Recent studies have combined Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance reasoning, improving inference accuracy without additional training while mitigating hallucination. However, existing frameworks are often rigid, struggling to adapt to KG or task changes. They also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning. To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that separates reasoning into two roles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor (a high-capacity LLM) that makes final judgments. This design is cost-efficient for LLM inference while still maintaining strong reasoning accuracy. Additionally, R2-KG employs an Abstention mechanism, generating answers only when sufficient evidence is collected from KG, which significantly enhances reliability. Experiments across multiple KG-based reasoning tasks show that R2-KG consistently outperforms baselines in both accuracy and reliability, regardless of the inherent capability of LLMs used as the Operator. Further experiments reveal that the single-agent version of R2-KG, equipped with a strict self-consistency strategy, achieves significantly higher-than-baseline reliability while reducing inference cost. However, it also leads to a higher abstention rate in complex KGs. Our findings establish R2-KG as a flexible and cost-effective solution for KG-based reasoning. It reduces reliance on high-capacity LLMs while ensuring trustworthy inference.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Atomic Smart Contract Interoperability with High Efficiency via Cross-Chain Integrated Execution</title>
<link>https://arxiv.org/abs/2502.12820</link>
<guid>https://arxiv.org/abs/2502.12820</guid>
<content:encoded><![CDATA[
<div> 关键词: EVM兼容区块链, 跨链互操作性, 整体原子性, IntegrateX, 交易聚合

总结:
随着Ethereum的发展，出现了大量与其执行环境（即Ethereum虚拟机，EVM）兼容的区块链。然而，这带来了跨链互操作性的挑战，特别是对于整个跨链应用确保效率和原子性的问题。现有的解决方案要么不能充分保证整体原子性，要么因为需要多次跨链智能合约执行而效率低下。为了解决这一问题，文章提出了IntegrateX，这是一个高效的跨链互操作性系统，可以确保跨链智能合约调用的整体原子性。其核心思想是在单一区块链上部署跨链执行所需逻辑，以实现集成执行，从而让跨链应用能在一个区块链内部高效地完成所有跨链逻辑。IntegrateX包括跨链智能合约部署协议和跨链智能合约集成执行协议。前者通过将智能合约逻辑与状态解耦以及采用结合了离链跨链部署和链上跨链验证的方法，实现了高效安全的跨链部署。后者则利用基于2PC的机制确保跨链调用的原子性，并通过交易聚合和细粒度的状态锁来提升性能。文章实现了IntegrateX的原型，并通过实验表明，相比于最先进的基线方案，IntegrateX能够减少高达61.2%的延迟，同时保持低的gas消耗。 <div>
arXiv:2502.12820v1 Announce Type: new 
Abstract: With the development of Ethereum, numerous blockchains compatible with Ethereum's execution environment (i.e., Ethereum Virtual Machine, EVM) have emerged. Developers can leverage smart contracts to run various complex decentralized applications on top of blockchains. However, the increasing number of EVM-compatible blockchains has introduced significant challenges in cross-chain interoperability, particularly in ensuring efficiency and atomicity for the whole cross-chain application. Existing solutions are either limited in guaranteeing overall atomicity for the cross-chain application, or inefficient due to the need for multiple rounds of cross-chain smart contract execution. To address this gap, we propose IntegrateX, an efficient cross-chain interoperability system that ensures the overall atomicity of cross-chain smart contract invocations. The core idea is to deploy the logic required for cross-chain execution onto a single blockchain, where it can be executed in an integrated manner. This allows cross-chain applications to perform all cross-chain logic efficiently within the same blockchain. IntegrateX consists of a cross-chain smart contract deployment protocol and a cross-chain smart contract integrated execution protocol. The former achieves efficient and secure cross-chain deployment by decoupling smart contract logic from state, and employing an off-chain cross-chain deployment mechanism combined with on-chain cross-chain verification. The latter ensures atomicity of cross-chain invocations through a 2PC-based mechanism, and enhances performance through transaction aggregation and fine-grained state lock. We implement a prototype of IntegrateX. Extensive experiments demonstrate that it reduces up to 61.2% latency compared to the state-of-the-art baseline while maintaining low gas consumption.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation</title>
<link>https://arxiv.org/abs/2502.12836</link>
<guid>https://arxiv.org/abs/2502.12836</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、生理时间序列分析、OpenCHA、心率估计、Photoplethysmogram (PPG)

总结:<br />
本文介绍了一种基于大型语言模型（LLMs）的生理时间序列分析代理系统，该系统旨在弥补LLMs与成熟分析工具集成的不足。该代理系统构建于开放源代码框架OpenCHA之上，其特点是有一个协调器，能够整合用户交互、数据来源和分析工具以生成准确的健康洞察。为了评估其效果，文章通过一个使用PPG信号进行心率（HR）估算的案例研究进行了实验，数据来源于一项远程健康监测研究中的PPG和Electrocardiogram（ECG）记录。实验结果表明，该代理系统的HR估算性能显著优于基准模型OpenAI GPT-4o-mini和GPT-4o，具有更低的误差率和更可靠的心率估计。该代理系统的实现已在GitHub上公开可用。 <div>
arXiv:2502.12836v1 Announce Type: new 
Abstract: Large language models (LLMs) are revolutionizing healthcare by improving diagnosis, patient care, and decision support through interactive communication. More recently, they have been applied to analyzing physiological time-series like wearable data for health insight extraction. Existing methods embed raw numerical sequences directly into prompts, which exceeds token limits and increases computational costs. Additionally, some studies integrated features extracted from time-series in textual prompts or applied multimodal approaches. However, these methods often produce generic and unreliable outputs due to LLMs' limited analytical rigor and inefficiency in interpreting continuous waveforms. In this paper, we develop an LLM-powered agent for physiological time-series analysis aimed to bridge the gap in integrating LLMs with well-established analytical tools. Built on the OpenCHA, an open-source LLM-powered framework, our agent features an orchestrator that integrates user interaction, data sources, and analytical tools to generate accurate health insights. To evaluate its effectiveness, we implement a case study on heart rate (HR) estimation from Photoplethysmogram (PPG) signals using a dataset of PPG and Electrocardiogram (ECG) recordings in a remote health monitoring study. The agent's performance is benchmarked against OpenAI GPT-4o-mini and GPT-4o, with ECG serving as the gold standard for HR estimation. Results demonstrate that our agent significantly outperforms benchmark models by achieving lower error rates and more reliable HR estimations. The agent implementation is publicly available on GitHub.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Adaptive Feedback with AI: Comparing the Feedback Quality of LLMs and Teachers on Experimentation Protocols</title>
<link>https://arxiv.org/abs/2502.12842</link>
<guid>https://arxiv.org/abs/2502.12842</guid>
<content:encoded><![CDATA[
<div> 关键词：有效反馈、人工智能、大型语言模型、教师、科学教育专家

<br /><br />总结:
本文研究了大型语言模型（LLM）在提供学生实验方案反馈方面的效果，并将其与人类教师和科学教育专家的反馈质量进行了比较。研究通过四位专业领域的评审员使用五点量表对三类反馈文本进行评价，关注六个有效反馈的标准，包括反馈提升、反馈回馈、反馈前瞻、建设性语气、语言清晰度和技术术语运用。结果显示，LLM生成的反馈在总体质量上与教师和专家无显著差异，但在针对学生工作中的错误识别和解释（即反馈回馈维度）方面表现稍逊。定性分析揭示了LLM在情境理解和明确表达具体错误上的局限性。研究表明，将LLM生成的反馈与教育者的专业知识相结合，可以利用LLM的高效性和教育者的深入理解来增强教育实践。 <div>
arXiv:2502.12842v1 Announce Type: new 
Abstract: Effective feedback is essential for fostering students' success in scientific inquiry. With advancements in artificial intelligence, large language models (LLMs) offer new possibilities for delivering instant and adaptive feedback. However, this feedback often lacks the pedagogical validation provided by real-world practitioners. To address this limitation, our study evaluates and compares the feedback quality of LLM agents with that of human teachers and science education experts on student-written experimentation protocols. Four blinded raters, all professionals in scientific inquiry and science education, evaluated the feedback texts generated by 1) the LLM agent, 2) the teachers and 3) the science education experts using a five-point Likert scale based on six criteria of effective feedback: Feed Up, Feed Back, Feed Forward, Constructive Tone, Linguistic Clarity, and Technical Terminology. Our results indicate that LLM-generated feedback shows no significant difference to that of teachers and experts in overall quality. However, the LLM agent's performance lags in the Feed Back dimension, which involves identifying and explaining errors within the student's work context. Qualitative analysis highlighted the LLM agent's limitations in contextual understanding and in the clear communication of specific errors. Our findings suggest that combining LLM-generated feedback with human expertise can enhance educational practices by leveraging the efficiency of LLMs and the nuanced understanding of educators.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey on DRL based UAV Communications and Networking: DRL Fundamentals, Applications and Implementations</title>
<link>https://arxiv.org/abs/2502.12875</link>
<guid>https://arxiv.org/abs/2502.12875</guid>
<content:encoded><![CDATA[
<div> 关键词：Unmanned Aerial Vehicles (UAVs), Deep Reinforcement Learning (DRL), Optimization Problems, UAV Communications, Dynamic Environments

<br /><br />
总结：
本文是一篇关于利用深度强化学习（DRL）解决无人机通信网络中优化问题的综述文章。随着无人机（UAVs）在现代通信网络中的重要性日益凸显，其动态分布式特性带来的如功率分配、信道分配、缓存和任务卸载等挑战也愈发明显。传统优化技术难以应对这类复杂多变环境，而DRL能有效地应用于这些问题的求解。文章首先回顾了DRL的基本概念，包括值基、策略基和actor-critic方法；接着，详细阐述了如何将DRL算法应用到具体的UAV网络任务中，从问题建模到DRL实现。通过将无人机通信难题转化为优化问题，强调了DRL在动态不确定环境下的实际应用价值，并指出其在处理大规模网络场景以及持续适应环境变化方面的能力。最后，文章还展望了未来研究方向，探讨了DRL进一步提升UAV通信性能及其在更复杂多智能体场景中应用的可能性。 <div>
arXiv:2502.12875v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) are playing an increasingly pivotal role in modern communication networks,offering flexibility and enhanced coverage for a variety of applica-tions. However, UAV networks pose significant challenges due to their dynamic and distributed nature, particularly when dealing with tasks such as power allocation, channel assignment, caching,and task offloading. Traditional optimization techniques often struggle to handle the complexity and unpredictability of these environments, leading to suboptimal performance. This survey provides a comprehensive examination of how deep reinforcement learning (DRL) can be applied to solve these mathematical optimization problems in UAV communications and networking.Rather than simply introducing DRL methods, the focus is on demonstrating how these methods can be utilized to solve complex mathematical models of the underlying problems. We begin by reviewing the fundamental concepts of DRL, including value-based, policy-based, and actor-critic approaches. Then,we illustrate how DRL algorithms are applied to specific UAV network tasks by discussing from problem formulations to DRL implementation. By framing UAV communication challenges as optimization problems, this survey emphasizes the practical value of DRL in dynamic and uncertain environments. We also explore the strengths of DRL in handling large-scale network scenarios and the ability to continuously adapt to changes in the environment. In addition, future research directions are outlined, highlighting the potential for DRL to further enhance UAV communications and expand its applicability to more complex,multi-agent settings.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Continuous Learning Conversational AI: A Personalized Agent Framework via A2C Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.12876</link>
<guid>https://arxiv.org/abs/2502.12876</guid>
<content:encoded><![CDATA[
<div> 关键词: Continuous Learning Conversational AI (CLCA), A2C reinforcement learning, Large Language Models (LLMs), simulated sales dialogues, personalized AI companions

<br /><br />总结:
本文提出了一个名为连续学习对话AI（CLCA）的方法，旨在解决个性化和适应性对话AI的挑战。该方法利用A2C强化学习，超越静态的大型语言模型（LLMs）。通过使用LLMs生成的模拟销售对话来训练A2C代理，使其能够优化针对个人化的对话策略，重点关注参与度和价值传递。系统架构结合了强化学习与LLMs，分别用于数据生成和响应选择。这种方法提供了一种实用的方式，可以通过持续学习构建个性化的AI伴侣，从而超越传统的静态LLM技术。 <div>
arXiv:2502.12876v1 Announce Type: new 
Abstract: Creating personalized and adaptable conversational AI remains a key challenge. This paper introduces a Continuous Learning Conversational AI (CLCA) approach, implemented using A2C reinforcement learning, to move beyond static Large Language Models (LLMs). We use simulated sales dialogues, generated by LLMs, to train an A2C agent. This agent learns to optimize conversation strategies for personalization, focusing on engagement and delivering value. Our system architecture integrates reinforcement learning with LLMs for both data creation and response selection. This method offers a practical way to build personalized AI companions that evolve through continuous learning, advancing beyond traditional static LLM techniques.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements</title>
<link>https://arxiv.org/abs/2502.12904</link>
<guid>https://arxiv.org/abs/2502.12904</guid>
<content:encoded><![CDATA[
<div> 关键词: Fraud-R1、LLMs、互联网欺诈、多轮评估、角色扮演

总结:
本文介绍了名为Fraud-R1的新基准测试，用于评估大语言模型（LLMs）在动态、真实世界场景中抵御互联网欺诈和网络钓鱼的能力。Fraud-R1包含来源于实际案例的8,564个欺诈样本，分为五大欺诈类型。与先前的基准不同，Fraud-R1引入了多轮评估流程，以在建立信誉、创造紧迫感和情绪操纵等不同阶段测试LLMs对欺诈行为的防御能力。此外，文章对比评估了15种LLMs，在两种设置下进行：1. 作为通用决策辅助工具；2. 假设特定角色，模拟真实世界的代理交互情境。评估结果显示，在抵御欺诈诱导方面，特别是在角色扮演设置和虚假招聘信息中存在显著挑战。同时，还发现了中文和英文之间存在较大的性能差距，强调了改进多语种欺诈检测能力的重要性。 <div>
arXiv:2502.12904v1 Announce Type: new 
Abstract: We introduce Fraud-R1, a benchmark designed to evaluate LLMs' ability to defend against internet fraud and phishing in dynamic, real-world scenarios. Fraud-R1 comprises 8,564 fraud cases sourced from phishing scams, fake job postings, social media, and news, categorized into 5 major fraud types. Unlike previous benchmarks, Fraud-R1 introduces a multi-round evaluation pipeline to assess LLMs' resistance to fraud at different stages, including credibility building, urgency creation, and emotional manipulation. Furthermore, we evaluate 15 LLMs under two settings: 1. Helpful-Assistant, where the LLM provides general decision-making assistance, and 2. Role-play, where the model assumes a specific persona, widely used in real-world agent-based interactions. Our evaluation reveals the significant challenges in defending against fraud and phishing inducement, especially in role-play settings and fake job postings. Additionally, we observe a substantial performance gap between Chinese and English, underscoring the need for improved multilingual fraud detection capabilities.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation</title>
<link>https://arxiv.org/abs/2502.12911</link>
<guid>https://arxiv.org/abs/2502.12911</guid>
<content:encoded><![CDATA[
<div> 关键词: SQL生成、模式链接、召回率、精确度、优化

总结:
本文提出了一个新的挑战，即SQL生成中的模式链接问题，其中准确的初始模式链接对后续SQL生成性能至关重要。现有的模式链接模型仍面临相关元素缺失或冗余过多的问题。为了解决这个问题，作者提出了一个增强的模式链接指标，引入了受限缺失指示器。基于此，他们设计了一种名为Knapsack优化的模式链接代理（KaSLA），旨在防止相关元素缺失的同时减少冗余元素的包含。KaSLA采用层次化的链接策略，首先优化表的链接选择，随后在选定表中链接列以缩小链接候选空间。在每个链接过程中，它利用背包优化方法链接潜在相关元素，并考虑有限的冗余容忍度。实验结果显示，与包括具有最新模式链接方法的大型语言模型deepseek-v3在内的现有最佳模型相比，KaSLA-1.6B在Spider和BIRD基准上实现了更优的模式链接结果，并显著提高了最先进的文本到SQL模型的SQL生成性能。

<br /><br /> <div>
arXiv:2502.12911v1 Announce Type: new 
Abstract: Generating SQLs from user queries is a long-standing challenge, where the accuracy of initial schema linking significantly impacts subsequent SQL generation performance. However, current schema linking models still struggle with missing relevant schema elements or an excess of redundant ones. A crucial reason for this is that commonly used metrics, recall and precision, fail to capture relevant element missing and thus cannot reflect actual schema linking performance. Motivated by this, we propose an enhanced schema linking metric by introducing a restricted missing indicator. Accordingly, we introduce Knapsack optimization-based Schema Linking Agent (KaSLA), a plug-in schema linking agent designed to prevent the missing of relevant schema elements while minimizing the inclusion of redundant ones. KaSLA employs a hierarchical linking strategy that first identifies the optimal table linking and subsequently links columns within the selected table to reduce linking candidate space. In each linking process, it utilize a knapsack optimization approach to link potentially relevant elements while accounting for a limited tolerance of potential redundant ones.With this optimization, KaSLA-1.6B achieves superior schema linking results compared to large-scale LLMs, including deepseek-v3 with state-of-the-art (SOTA) schema linking method. Extensive experiments on Spider and BIRD benchmarks verify that KaSLA can significantly improve the SQL generation performance of SOTA text-to-SQL models by substituting their schema linking processes.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards more Contextual Agents: An extractor-Generator Optimization Framework</title>
<link>https://arxiv.org/abs/2502.12926</link>
<guid>https://arxiv.org/abs/2502.12926</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)、contextual adaptability、prompt优化、Extractor-Generator框架、性能提升

总结:
本文介绍了一种针对大型语言模型（LLM）基代理的系统化方法，旨在通过优化控制代理行为和交互的关键组件——提示（prompts），提高其在特定上下文场景中的适应性。针对手动创建优化提示的耗时、易错和低可扩展性问题，文章提出了一种名为Extractor-Generator的框架，该框架分为两个阶段：特征从黄金标准输入输出数据集中抽取，以及利用高级优化策略生成提示，迭代地识别表现不佳的情况并应用自我改进技术。此框架提高了提示对多样化输入的泛化精度，特别是在需要保持语义一致性和减少错误传播的特定任务中，对于实现可靠性能至关重要。虽然最初应用于单阶段工作流，但该方法可以自然扩展到多阶段工作流，具有广泛的适用性。实证评估显示，所提出的框架显著提升了经提示优化的代理性能，为构建结构化、高效的上下文感知LLM基代理提供了有效途径。 <div>
arXiv:2502.12926v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable success in solving complex tasks across a wide range of general-purpose applications. However, their performance often degrades in context-specific scenarios, such as specialized industries or research domains, where the absence of domain-relevant knowledge leads to imprecise or suboptimal outcomes. To address this challenge, our work introduces a systematic approach to enhance the contextual adaptability of LLM-based agents by optimizing their underlying prompts-critical components that govern agent behavior, roles, and interactions. Manually crafting optimized prompts for context-specific tasks is labor-intensive, error-prone, and lacks scalability. In this work, we introduce an Extractor-Generator framework designed to automate the optimization of contextual LLM-based agents. Our method operates through two key stages: (i) feature extraction from a dataset of gold-standard input-output examples, and (ii) prompt generation via a high-level optimization strategy that iteratively identifies underperforming cases and applies self-improvement techniques. This framework substantially improves prompt adaptability by enabling more precise generalization across diverse inputs, particularly in context-specific tasks where maintaining semantic consistency and minimizing error propagation are critical for reliable performance. Although developed with single-stage workflows in mind, the approach naturally extends to multi-stage workflows, offering broad applicability across various agent-based systems. Empirical evaluations demonstrate that our framework significantly enhances the performance of prompt-optimized agents, providing a structured and efficient approach to contextual LLM-based agents.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options</title>
<link>https://arxiv.org/abs/2502.12929</link>
<guid>https://arxiv.org/abs/2502.12929</guid>
<content:encoded><![CDATA[
<div> 关键词：Flow-of-Options (FoO)，Large Language Models (LLMs)，AutoML，机器学习任务，强化学习

总结:
我们提出了一种名为Flow-of-Options（FoO）的新颖推理方法，旨在解决大型语言模型（LLMs）中的内在偏见问题。FoO使LLM能够系统地探索其推理过程中的多样可能性，并通过一个基于FoO的自主机器学习任务解决方案（AutoML）系统得以实现。实验表明，该框架在标准数据科学任务和治疗化学任务上分别取得了比现有最优基线提升38.2%-69.2%和37.4%-47.9%的性能。此外，每个任务的操作成本低于1美元，使其非常适合成本敏感的应用场景。除了分类和回归任务外，我们还展示了基于FoO的自主系统在强化学习和图像生成等更广泛任务上的应用潜力。相比于当前最先进的AutoML自主系统，我们的框架具有显著优势，这得益于FoO在通过压缩、可解释的表示形式促进LLM解决方案多样性方面的作用，以及与案例推理相结合支持长期记忆的能力。 <div>
arXiv:2502.12929v1 Announce Type: new 
Abstract: We present a novel reasoning approach called Flow-of-Options (FoO), designed to address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs to systematically explore a diverse range of possibilities in their reasoning, as demonstrated by an FoO-based agentic system for autonomously solving Machine Learning tasks (AutoML). Our framework outperforms state-of-the-art baselines, achieving improvements of 38.2% - 69.2% on standard data science tasks, and 37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost under $1 per task, our framework is well-suited for cost-sensitive applications. Beyond classification and regression, we illustrate the broader applicability of our FoO-based agentic system to tasks such as reinforcement learning and image generation. Our framework presents significant advancements compared to current state-of-the-art agentic systems for AutoML, due to the benefits of FoO in enforcing diversity in LLM solutions through compressed, explainable representations that also support long-term memory when combined with case-based reasoning.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI-Enabled Rent-Seeking: How Generative AI Alters Market Transparency and Efficiency</title>
<link>https://arxiv.org/abs/2502.12956</link>
<guid>https://arxiv.org/abs/2502.12956</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式人工智能、经济租寻行为、社会福利、政策干预、算法干扰

<br /><br />总结:

本文探讨了生成式人工智能对经济租寻行为及其对社会福利影响的研究。文章构建了一个涉及多个可能从事租寻活动的代理和致力于减轻社会福利损失的监管者的动态经济模型。生成式AI一方面通过提高透明度降低传统信息租金，另一方面却引入新的租寻形式，如信息操纵和算法干扰，这些行为可能导致信息不对称加剧和资源错配，从而减少社会福利。针对这些问题，文章提出了包括征税和监管措施在内的政策干预建议。该研究为理解生成式AI的经济影响提供了新视角，并为规制AI驱动的经济行为未来研究奠定了基础。 <div>
arXiv:2502.12956v1 Announce Type: new 
Abstract: The rapid advancement of generative artificial intelligence (AI) has transformed the information environment, creating both opportunities and challenges. This paper explores how generative AI influences economic rent-seeking behavior and its broader impact on social welfare. We develop a dynamic economic model involving multiple agents who may engage in rent-seeking activities and a regulator aiming to mitigate social welfare losses. Our analysis reveals a dual effect of generative AI: while it reduces traditional information rents by increasing transparency, it also introduces new forms of rent-seeking, such as information manipulation and algorithmic interference. These behaviors can lead to decreased social welfare by exacerbating information asymmetries and misallocating resources. To address these challenges, we propose policy interventions, including taxation and regulatory measures. This study provides a new perspective on the economic implications of generative AI, offering valuable insights for policymakers and laying a foundation for future research on regulating AI-driven economic behaviors.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Early Days of the Ethereum Blob Fee Market and Lessons Learnt</title>
<link>https://arxiv.org/abs/2502.12966</link>
<guid>https://arxiv.org/abs/2502.12966</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum、rollup、EIP-4844、blob交易、数据可用性、交易分析、mempool、费用市场、效率损失、峰值需求、市场设计问题、子集竞价、交易结构

<br /><br />总结:
本文对以太坊自2024年3月13日引入blob交易以来，进行了一次关于交易和mempool层面数据的首次系统性和深入的实证分析。研究重点关注了blob费用市场的早期行为以及参与者的行为模式。作者发现并量化了由于非最优区块打包导致的效率损失，最多可达70%的相对费用损失。此外，文章详细剖析了两个拥堵的Blob需求高峰时段。最后，文中指出了由于交易结构在打包数据为blob时的灵活性不足所引发的一个市场设计问题——子集竞价问题，并提出了可能的解决方案。这一市场结构问题不仅适用于以太坊，还对包含在交易中的任何离散对象都具有普遍意义。 <div>
arXiv:2502.12966v1 Announce Type: new 
Abstract: Ethereum has adopted a rollup-centric roadmap to scale by making rollups (layer 2 scaling solutions) the primary method for handling transactions. The first significant step towards this goal was EIP-4844, which introduced blob transactions that are designed to meet the data availability needs of layer 2 protocols. This work constitutes the first rigorous and comprehensive empirical analysis of transaction- and mempool-level data since the institution of blobs on Ethereum on March 13, 2024. We perform a longitudinal study of the early days of the blob fee market analyzing the landscape and the behaviors of its participants. We identify and measure the inefficiencies arising out of suboptimal block packing, showing that at times it has resulted in up to 70% relative fee loss. We hone in and give further insight into two (congested) peak demand periods for blobs. Finally, we document a market design issue relating to subset bidding due to the inflexibility of the transaction structure on packing data as blobs and suggest possible ways to fix it. The latter market structure issue also applies more generally for any discrete objects included within transactions.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generative AI and Information Asymmetry: Impacts on Adverse Selection and Moral Hazard</title>
<link>https://arxiv.org/abs/2502.12969</link>
<guid>https://arxiv.org/abs/2502.12969</guid>
<content:encoded><![CDATA[
<div> 关键词：信息不对称、逆向选择、道德风险、生成式人工智能、市场效率

总结:<br />
本文探讨了信息不对称导致经济市场中的逆向选择和道德风险问题，以及传统解决方法的局限性。研究重点在于利用生成式人工智能生成详细的信息信号，帮助主体更好地了解代理类型并监控其行为，将此类AI生成的信号融入主代理模型中以减少效率低下和改进合同设计。通过理论分析与模拟实验，研究表明生成式人工智能能够有效地缓解逆向选择和道德风险，从而实现更高效的市场结果并提升社会福利。文章还为政策制定者和业界利益相关者提供了关于负责任地实施生成式AI解决方案以提高市场表现的实践见解。 <div>
arXiv:2502.12969v1 Announce Type: new 
Abstract: Information asymmetry often leads to adverse selection and moral hazard in economic markets, causing inefficiencies and welfare losses. Traditional methods to address these issues, such as signaling and screening, are frequently insufficient. This research investigates how Generative Artificial Intelligence (AI) can create detailed informational signals that help principals better understand agents' types and monitor their actions. By incorporating these AI-generated signals into a principal-agent model, the study aims to reduce inefficiencies and improve contract designs. Through theoretical analysis and simulations, we demonstrate that Generative AI can effectively mitigate adverse selection and moral hazard, resulting in more efficient market outcomes and increased social welfare. Additionally, the findings offer practical insights for policymakers and industry stakeholders on the responsible implementation of Generative AI solutions to enhance market performance.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Free Argumentative Exchanges for Explaining Image Classifiers</title>
<link>https://arxiv.org/abs/2502.12995</link>
<guid>https://arxiv.org/abs/2502.12995</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习模型、解释方法、图像分类器、辩论式解释、Free Argumentative eXchanges (FAX)

总结:
本文提出了一种新的图像分类器解释方法，通过在两个代理之间进行关于特定类别的辩论来揭示深层学习模型的推理过程。这种方法基于名为Free Argumentative eXchanges (FAXs)的新型论证式多智能体框架，允许智能体以不同于原始陈述的方式内部化其他智能体的意见。文章定义了共识率和说服率两种指标来评估FAXs作为图像分类器论证式解释的有效性，并进行了实验证明，FAXs在这些指标上表现优秀，同时相比传统的非论证式解释方法更能忠实反映图像分类器的决策过程。相关实现代码已发布在https://github.com/koriavinash1/FAX。 <div>
arXiv:2502.12995v1 Announce Type: new 
Abstract: Deep learning models are powerful image classifiers but their opacity hinders their trustworthiness. Explanation methods for capturing the reasoning process within these classifiers faithfully and in a clear manner are scarce, due to their sheer complexity and size. We provide a solution for this problem by defining a novel method for explaining the outputs of image classifiers with debates between two agents, each arguing for a particular class. We obtain these debates as concrete instances of Free Argumentative eXchanges (FAXs), a novel argumentation-based multi-agent framework allowing agents to internalise opinions by other agents differently than originally stated. We define two metrics (consensus and persuasion rate) to assess the usefulness of FAXs as argumentative explanations for image classifiers. We then conduct a number of empirical experiments showing that FAXs perform well along these metrics as well as being more faithful to the image classifiers than conventional, non-argumentative explanation methods. All our implementations can be found at https://github.com/koriavinash1/FAX.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations</title>
<link>https://arxiv.org/abs/2502.13001</link>
<guid>https://arxiv.org/abs/2502.13001</guid>
<content:encoded><![CDATA[
<div> 关键词：FAME、会议摘要、数据集、多代理会议合成框架、自然语言生成

总结:
本文介绍了FAME，一个新的多语种（英语和德语）会议数据集，用于解决会议摘要领域高质量数据不足的问题。FAME由新的多代理会议合成框架MIMIC生成，该框架基于心理学原则定义参与者档案，设计对话流程，并利用大型语言模型进行辩论模拟生成会议记录。经过模块化的后处理步骤，可以优化输出内容，减少重复并确保对话的连贯性和可信度。文章还提出了一套基于心理学的评价框架，从自然度、社会行为真实性及对话难度等方面对FAME进行了评估。结果显示，FAME接近真实会议的即兴性（自然度评分4.5/5），保留了说话者中心的挑战性（口语化评分3/5），并引入了更丰富、信息导向的难度（难度评分4/5）。这些发现表明，FAME是模拟现实世界会议条件的良好且可扩展的代理，可用于推动会议摘要研究及其他需要对话数据或模拟有行为约束的社会场景的任务。 <div>
arXiv:2502.13001v1 Announce Type: new 
Abstract: Meeting summarization suffers from limited high-quality data, mainly due to privacy restrictions and expensive collection processes. We address this gap with FAME, a dataset of 500 meetings in English and 300 in German produced by MIMIC, our new multi-agent meeting synthesis framework that generates meeting transcripts on a given knowledge source by defining psychologically grounded participant profiles, outlining the conversation, and orchestrating a large language model (LLM) debate. A modular post-processing step refines these outputs, mitigating potential repetitiveness and overly formal tones, ensuring coherent, credible dialogues at scale. We also propose a psychologically grounded evaluation framework assessing naturalness, social behavior authenticity, and transcript difficulties. Human assessments show that FAME approximates real-meeting spontaneity (4.5/5 in naturalness), preserves speaker-centric challenges (3/5 in spoken language), and introduces richer information-oriented difficulty (4/5 in difficulty). These findings highlight that FAME is a good and scalable proxy for real-world meeting conditions. It enables new test scenarios for meeting summarization research and other conversation-centric applications in tasks requiring conversation data or simulating social scenarios under behavioral constraints.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Reinforcement Learning, Action Model Learning, and Numeric Planning for Tackling Complex Tasks</title>
<link>https://arxiv.org/abs/2502.13006</link>
<guid>https://arxiv.org/abs/2502.13006</guid>
<content:encoded><![CDATA[
<div> 关键词：自动规划，领域模型，学习，数值规划环境，Minecraft，NSAM， imitation learning，offline reinforcement learning，RAMP，在线学习

总结:
本文探讨了在数值规划环境中学习领域模型对于自动规划的有效性，并以流行沙盒游戏Minecraft中的两个任务作为案例研究。首先，在离线学习设置中，利用Numeric Safe Action Model Learning（NSAM）算法学习了一个数值领域的模型，并将其与几种模型无关的模仿学习（IL）和离线强化学习（RL）算法进行了比较。实验结果显示，一些IL算法在解决简单任务时学习速度更快，而使用NSAM_（+p）则能够更好地应对需要长期规划的任务并实现对更大环境问题的泛化解决。接着，文章考虑了在线学习场景，提出了RAMP方法，该方法通过执行期间收集的观察数据同时训练强化学习策略和学习规划域动作模型，形成了RL策略和学习到的领域模型之间的正反馈循环。实验表明，RAMP相比于几个RL基线能找到更高效的计划并解决更多问题。 <div>
arXiv:2502.13006v1 Announce Type: new 
Abstract: Automated Planning algorithms require a model of the domain that specifies the preconditions and effects of each action. Obtaining such a domain model is notoriously hard. Algorithms for learning domain models exist, yet it remains unclear whether learning a domain model and planning is an effective approach for numeric planning environments, i.e., where states include discrete and numeric state variables. In this work, we explore the benefits of learning a numeric domain model and compare it with alternative model-free solutions. As a case study, we use two tasks in Minecraft, a popular sandbox game that has been used as an AI challenge. First, we consider an offline learning setting, where a set of expert trajectories are available to learn from. This is the standard setting for learning domain models. We used the Numeric Safe Action Model Learning (NSAM) algorithm to learn a numeric domain model and solve new problems with the learned domain model and a numeric planner. We call this model-based solution NSAM_(+p), and compare it to several model-free Imitation Learning (IL) and Offline Reinforcement Learning (RL) algorithms. Empirical results show that some IL algorithms can learn faster to solve simple tasks, while NSAM_(+p) allows solving tasks that require long-term planning and enables generalizing to solve problems in larger environments. Then, we consider an online learning setting, where learning is done by moving an agent in the environment. For this setting, we introduce RAMP. In RAMP, observations collected during the agent's execution are used to simultaneously train an RL policy and learn a planning domain action model. This forms a positive feedback loop between the RL policy and the learned domain model. We demonstrate experimentally the benefits of using RAMP, showing that it finds more efficient plans and solves more problems than several RL baselines.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents</title>
<link>https://arxiv.org/abs/2502.13012</link>
<guid>https://arxiv.org/abs/2502.13012</guid>
<content:encoded><![CDATA[
<div> 关键词：Role-Playing Agent (RPA)，LLM Agent，评价设计，任务属性，评价指标

总结:<br />
本文针对日益流行的基于LLM（Large Language Model）的角色扮演型智能体（RPA），由于其多样化任务需求和设计，评价方法面临挑战。通过对2021年1月至2024年12月期间发表的1,676篇论文进行系统回顾，研究者识别出了六个RPA的代理特性、七个任务特性及七个评估指标。据此，文章提出了一个RPA评价设计指南，旨在帮助研究人员制定更为系统和一致的评价方法。 <div>
arXiv:2502.13012v1 Announce Type: new 
Abstract: Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that simulates human-like behaviors in a variety of tasks. However, evaluating RPAs is challenging due to diverse task requirements and agent designs. This paper proposes an evidence-based, actionable, and generalizable evaluation design guideline for LLM-based RPA by systematically reviewing 1,676 papers published between Jan. 2021 and Dec. 2024. Our analysis identifies six agent attributes, seven task attributes, and seven evaluation metrics from existing literature. Based on these findings, we present an RPA evaluation design guideline to help researchers develop more systematic and consistent evaluation methods.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean of Means: Human Localization with Calibration-free and Unconstrained Camera Settings (extended version)</title>
<link>https://arxiv.org/abs/2502.13017</link>
<guid>https://arxiv.org/abs/2502.13017</guid>
<content:encoded><![CDATA[
<div> 关键词：人体定位、元宇宙、视觉方法、概率方法、web摄像头

总结:<br />
本文提出了一种针对人体定位的新方法，尤其适用于元宇宙时代。现有的高精度解决方案依赖于昂贵且需标签的硬件，而基于视觉的方法虽成本更低、无需标签，但现有技术存在局限性，如基于立体视觉的方法受制于严格的视角变换原理和多阶段SVD求解器中的误差传播问题，以及对多台高分辨率相机的严格设置要求。为解决这些问题，文章提出一种概率方法，该方法将人体各点视为围绕身体几何中心分布产生的观测值，从而显著提升采样效率，使每个关注点的采样数量从数百增至数十亿。通过建模世界坐标和像素坐标分布均值之间的关系并利用中心极限定理确保正态分布，从而简化学习过程。实验结果显示，该方法能以仅使用两个分辨率为640x480像素的低成本web摄像头实现高达96%的人体定位精确度（在0.3米范围内）和接近100%的精确度（在0.5米范围内）。 <div>
arXiv:2502.13017v1 Announce Type: new 
Abstract: Accurate human localization is crucial for various applications, especially in the Metaverse era. Existing high precision solutions rely on expensive, tag-dependent hardware, while vision-based methods offer a cheaper, tag-free alternative. However, current vision solutions based on stereo vision face limitations due to rigid perspective transformation principles and error propagation in multi-stage SVD solvers. These solutions also require multiple high-resolution cameras with strict setup constraints.To address these limitations, we propose a probabilistic approach that considers all points on the human body as observations generated by a distribution centered around the body's geometric center. This enables us to improve sampling significantly, increasing the number of samples for each point of interest from hundreds to billions. By modeling the relation between the means of the distributions of world coordinates and pixel coordinates, leveraging the Central Limit Theorem, we ensure normality and facilitate the learning process. Experimental results demonstrate human localization accuracy of 96\% within a 0.3$m$ range and nearly 100\% accuracy within a 0.5$m$ range, achieved at a low cost of only 10 USD using two web cameras with a resolution of 640$\times$480 pixels.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks</title>
<link>https://arxiv.org/abs/2502.13025</link>
<guid>https://arxiv.org/abs/2502.13025</guid>
<content:encoded><![CDATA[
<div> 关键词：agentic图扩展框架、动态知识结构、大型语言模型、知识图谱、材料设计

总结:
本文提出了一种自主、具有智能的图扩展框架，该框架能够迭代地构建和优化知识结构。与依赖静态抽取或单次学习的传统知识图谱构建方法不同，该方法将推理原生的大规模语言模型与不断更新的图表示相结合。系统会主动生成新概念和关系，将其整合到全局图中，并根据其演化结构制定后续提示。通过这种反馈驱动的循环，模型将信息组织成具有幂律特性、稳定模块化和连接不同知识聚类的桥接节点的尺度自由网络。经过数百次迭代，新的节点和边继续出现而不饱和，同时中心性度量和最短路径分布演变为更分散的连通性。实验分析揭示了诸如高度连接的“中心”概念的兴起以及“桥梁”节点影响力的变化等涌现模式，表明自主、自我强化的图构造可以产生开放式、连贯的知识结构。文章应用此框架至材料设计问题上，通过提取节点特性和协同级别的原则来促进新颖知识的合成，从而产生跨越领域的创新思想，增强了该框架进行开放式科学发现的潜力。文中还讨论了其他在科学发现方面的应用并指出了增强可伸缩性和可解释性的未来方向。 <div>
arXiv:2502.13025v1 Announce Type: new 
Abstract: We present an agentic, autonomous graph expansion framework that iteratively structures and refines knowledge in situ. Unlike conventional knowledge graph construction methods relying on static extraction or single-pass learning, our approach couples a reasoning-native large language model with a continually updated graph representation. At each step, the system actively generates new concepts and relationships, merges them into a global graph, and formulates subsequent prompts based on its evolving structure. Through this feedback-driven loop, the model organizes information into a scale-free network characterized by hub formation, stable modularity, and bridging nodes that link disparate knowledge clusters. Over hundreds of iterations, new nodes and edges continue to appear without saturating, while centrality measures and shortest path distributions evolve to yield increasingly distributed connectivity. Our analysis reveals emergent patterns, such as the rise of highly connected 'hub' concepts and the shifting influence of 'bridge' nodes, indicating that agentic, self-reinforcing graph construction can yield open-ended, coherent knowledge structures. Applied to materials design problems, we present compositional reasoning experiments by extracting node-specific and synergy-level principles to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that transcend rote summarization and strengthen the framework's potential for open-ended scientific discovery. We discuss other applications in scientific discovery and outline future directions for enhancing scalability and interpretability.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AEIA-MN: Evaluating the Robustness of Multimodal LLM-Powered Mobile Agents Against Active Environmental Injection Attacks</title>
<link>https://arxiv.org/abs/2502.13053</link>
<guid>https://arxiv.org/abs/2502.13053</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、冒充者识别、主动环境注入攻击(AEIA)、AEIA-MN、移动操作系统

总结:
本文探讨了AI代理在执行任务过程中对于“冒充者”识别的重要性。研究人员发现了一种名为主动环境注入攻击(AEIA)的安全威胁，其中攻击者将恶意干扰伪装为环境元素，扰乱AI代理的决策过程。针对此威胁，文章提出了AEIA-MN攻击方案，该方案利用移动操作系统中的交互漏洞评估基于MLLM（多层语言模型）的智能代理对这类攻击的鲁棒性。实验结果显示，即使高级的MLLMs在这种攻击面前也表现出高度的易受攻击性，在AndroidWorld基准测试中最高攻击成功率可达93%。<br /><br /> <div>
arXiv:2502.13053v1 Announce Type: new 
Abstract: As researchers continuously optimize AI agents to perform tasks more effectively within operating systems, they often neglect to address the critical need for enabling these agents to identify "impostors" within the system. Through an analysis of the agents' operating environment, we identified a potential threat: attackers can disguise their attack methods as environmental elements, injecting active disturbances into the agents' execution process, thereby disrupting their decision-making. We define this type of attack as Active Environment Injection Attack (AEIA). Based on this, we propose AEIA-MN, an active environment injection attack scheme that exploits interaction vulnerabilities in the mobile operating system to evaluate the robustness of MLLM-based agents against such threats. Experimental results show that even advanced MLLMs are highly vulnerable to this attack, achieving a maximum attack success rate of 93% in the AndroidWorld benchmark.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection</title>
<link>https://arxiv.org/abs/2502.13061</link>
<guid>https://arxiv.org/abs/2502.13061</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态模型、仇恨性模因、检测、对比学习、LMM-RGCL

总结:
本文提出了一种名为LMM-RGCL的新型两阶段微调框架，用于提升多模态模型在仇恨性模因检测任务上的性能和跨领域泛化能力。鉴于大型多模态模型在处理随社会趋势和突发新闻动态变化的仇恨性模因时表现不佳，以及传统监督微调方法存在的局限性，该框架结合了大规模多模态模型检索和引导性的对比学习。实验结果显示，LMM-RGCL在六个常用的模因分类数据集上实现了最佳性能，超越了如VPD-PALI-X-55B等基于代理的系统，并在低资源条件下对领域外模因的泛化能力方面优于GPT-4o。<br /><br /> <div>
arXiv:2502.13061v1 Announce Type: new 
Abstract: Hateful memes have become a significant concern on the Internet, necessitating robust automated detection systems. While large multimodal models have shown strong generalization across various tasks, they exhibit poor generalization to hateful meme detection due to the dynamic nature of memes tied to emerging social trends and breaking news. Recent work further highlights the limitations of conventional supervised fine-tuning for large multimodal models in this context. To address these challenges, we propose Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), a novel two-stage fine-tuning framework designed to improve both in-domain accuracy and cross-domain generalization. Experimental results on six widely used meme classification datasets demonstrate that LMM-RGCL achieves state-of-the-art performance, outperforming agent-based systems such as VPD-PALI-X-55B. Furthermore, our method effectively generalizes to out-of-domain memes under low-resource settings, surpassing models like GPT-4o.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interactive Agents to Overcome Ambiguity in Software Engineering</title>
<link>https://arxiv.org/abs/2502.13069</link>
<guid>https://arxiv.org/abs/2502.13069</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、模糊指令、交互式代码生成、检测歧义、询问目标问题

<br /><br />总结:
本文研究了大型语言模型在处理交互式代码生成任务中的模糊指令能力。研究表明，当前的顶级模型在区分明确和不明确指令方面表现挣扎。然而，当面对不明确的输入时，通过与用户互动，模型能有效地获取关键信息，从而显著提高性能，强调了有效交互的重要性。同时，文章指出现有最先进的模型在处理复杂软件工程任务中的歧义存在显著差距，并将评估结构化为三个关键步骤：利用交互性提升模糊场景下的性能、检测歧义以及提出目标问题，以便进行有针对性的改进。 <div>
arXiv:2502.13069v1 Announce Type: new 
Abstract: AI agents are increasingly being deployed to automate tasks, often based on ambiguous and underspecified user instructions. Making unwarranted assumptions and failing to ask clarifying questions can lead to suboptimal outcomes, safety risks due to tool misuse, and wasted computational resources. In this work, we study the ability of LLM agents to handle ambiguous instructions in interactive code generation settings by evaluating proprietary and open-weight models on their performance across three key steps: (a) leveraging interactivity to improve performance in ambiguous scenarios, (b) detecting ambiguity, and (c) asking targeted questions. Our findings reveal that models struggle to distinguish between well-specified and underspecified instructions. However, when models interact for underspecified inputs, they effectively obtain vital information from the user, leading to significant improvements in performance and underscoring the value of effective interaction. Our study highlights critical gaps in how current state-of-the-art models handle ambiguity in complex software engineering tasks and structures the evaluation into distinct steps to enable targeted improvements.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Text2World: Benchmarking Large Language Models for Symbolic World Model Generation</title>
<link>https://arxiv.org/abs/2502.13092</link>
<guid>https://arxiv.org/abs/2502.13092</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 世界建模, 文本描述, PDDL, Text2World

总结:
本文关注于利用大型语言模型（LLMs）从文本描述生成符号世界模型的研究领域。针对现有研究存在的评价随机性、依赖间接指标和领域范围有限等问题，文章提出了一种新的基准——Text2World，该基准基于规划领域定义语言（PDDL），涵盖了多样化的领域并采用多标准、执行为基础的评估指标以实现更稳健的评估。通过对当前LLMs在Text2World上的性能测试，发现使用大规模强化学习训练的推理模型表现优于其他模型，但仍显示出在世界建模方面的能力限制。根据这些洞察，作者探讨了提升LLMs世界建模能力的一些策略，包括测试时间扩展、智能体训练等。希望Text2World能成为未来研究的重要资源，为利用LLMs作为世界模型奠定基础。项目页面可访问https://text-to-world.github.io/。 <div>
arXiv:2502.13092v1 Announce Type: new 
Abstract: Recently, there has been growing interest in leveraging large language models (LLMs) to generate symbolic world models from textual descriptions. Although LLMs have been extensively explored in the context of world modeling, prior studies encountered several challenges, including evaluation randomness, dependence on indirect metrics, and a limited domain scope. To address these limitations, we introduce a novel benchmark, Text2World, based on planning domain definition language (PDDL), featuring hundreds of diverse domains and employing multi-criteria, execution-based metrics for a more robust evaluation. We benchmark current LLMs using Text2World and find that reasoning models trained with large-scale reinforcement learning outperform others. However, even the best-performing model still demonstrates limited capabilities in world modeling. Building on these insights, we examine several promising strategies to enhance the world modeling capabilities of LLMs, including test-time scaling, agent training, and more. We hope that Text2World can serve as a crucial resource, laying the groundwork for future research in leveraging LLMs as world models. The project page is available at https://text-to-world.github.io/.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Approximately Efficient Bilateral Trade with Samples</title>
<link>https://arxiv.org/abs/2502.13122</link>
<guid>https://arxiv.org/abs/2502.13122</guid>
<content:encoded><![CDATA[
<div> 关键词：双边贸易、Myerson-Satterthwaite不可能性定理、定价权力、采样行为、社会福利

总结:
本文研究了在双边贸易中，当卖家和买家进行交易时的社会效率问题。针对Myerson-Satterthwaite不可能性定理指出的，在经典贝叶斯环境下无法实现完全效率的机制设计问题，先前的研究（Deng等人，STOC 2022）表明，如果将定价权委托给合适的参与者（卖方或买方），可以保证至少达到理想收益的一部分。然而实际情况下，掌握定价权的代理人可能并不完全了解对方的价值分布，而是依赖于该分布的样本来设定价格。文章证明，在广泛类别的采样和定价行为下，由此产生的市场仍能在期望值上保证取得理想收益的一个常数比例。这一结论基于一个观察：基于样本的定价所导致的社会福利近似于卖家的最优收入，这一结果通过转化为随机游走问题得以建立。 <div>
arXiv:2502.13122v1 Announce Type: new 
Abstract: We study the social efficiency of bilateral trade between a seller and a buyer. In the classical Bayesian setting, the celebrated Myerson-Satterthwaite impossibility theorem states that no Bayesian incentive-compatible, individually rational, and budget-balanced mechanism can achieve full efficiency. As a counterpoint, Deng, Mao, Sivan, and Wang (STOC 2022) show that if pricing power is delegated to the right person (either the seller or the buyer), the resulting mechanism can guarantee at least a constant fraction of the ideal (yet unattainable) gains from trade.
  In practice, the agent with pricing power may not have perfect knowledge of the value distribution of the other party, and instead may rely on samples of that distribution to set a price. We show that for a broad class of sampling and pricing behaviors, the resulting market still guarantees a constant fraction of the ideal gains from trade in expectation. Our analysis hinges on the insight that social welfare under sample-based pricing approximates the seller's optimal revenue -- a result we establish via a reduction to a random walk.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Facilitating Long Context Understanding via Supervised Chain-of-Thought Reasoning</title>
<link>https://arxiv.org/abs/2502.13127</link>
<guid>https://arxiv.org/abs/2502.13127</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Chain-of-Thought (CoT)，LongFinanceQA，Property-driven Agentic Inference (PAI)，Loong benchmark

总结:<br />
本文探讨了如何通过将Chain-of-Thought (CoT)推理以监督方式整合到大型语言模型（LLMs）中，提升其对长序列上下文理解的有效性。为实现这一目标，研究者构建了一个名为LongFinanceQA的金融领域合成数据集，该数据集包含了中间的CoT推理步骤，旨在促进LLMs进行显式推理并提高长期上下文理解的准确性和可解释性。为了生成合成的CoT推理，提出了基于属性驱动的代理推断（PAI）框架，该框架模拟人类式的推理步骤，包括属性抽取、检索和汇总。实验结果显示，GPT-4o-mini结合PAI在Loong基准测试上相对于标准GPT-4o-mini提高了20.0%的表现。此外，通过对LLaMA-3.1-8B-Instruct在LongFinanceQA上进行微调，使其在Loong金融子集上的性能提升了24.6%。 <div>
arXiv:2502.13127v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have enabled them to process increasingly longer sequences, ranging from 2K to 2M tokens and even beyond. However, simply extending the input sequence length does not necessarily lead to effective long-context understanding. In this study, we integrate Chain-of-Thought (CoT) reasoning into LLMs in a supervised manner to facilitate effective long-context understanding. To achieve this, we introduce LongFinanceQA, a synthetic dataset in the financial domain designed to improve long-context reasoning. Unlike existing long-context synthetic data, LongFinanceQA includes intermediate CoT reasoning before the final conclusion, which encourages LLMs to perform explicit reasoning, improving accuracy and interpretability in long-context understanding. To generate synthetic CoT reasoning, we propose Property-driven Agentic Inference (PAI), an agentic framework that simulates human-like reasoning steps, including property extraction, retrieval, and summarization. We evaluate PAI's reasoning capabilities by assessing GPT-4o-mini w/ PAI on the Loong benchmark, outperforming standard GPT-4o-mini by 20.0%. Furthermore, we fine-tune LLaMA-3.1-8B-Instruct on LongFinanceQA, achieving a 24.6% gain on Loong's financial subset.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Magma: A Foundation Model for Multimodal AI Agents</title>
<link>https://arxiv.org/abs/2502.13130</link>
<guid>https://arxiv.org/abs/2502.13130</guid>
<content:encoded><![CDATA[
<div> 关键词：Magma、多模态AI、视觉语言模型、行动规划、UI导航<br /><br />总结: 本文介绍了Magma，这是一个全新的多模态AI基础模型，旨在服务于数字和物理世界的智能代理任务。Magma不仅继承了视觉语言模型的理解能力（口头智能），还新增了对视觉空间世界进行计划和操作的能力（空间-时间智能），能够执行从UI导航到机器人操纵等各类代理任务。为了赋予这些代理功能，Magma在包括图像、视频及机器人数据在内的大量异构数据上进行了预训练，其中图像中的可操作视觉对象使用Set-of-Mark（SoM）进行动作定位标注，视频中物体运动则通过Trace-of-Mark（ToM）进行动作规划标注。实验表明，SoM与ToM相结合，极大地促进了Magma获取空间-时间智能的能力，这对于广泛的任务至关重要。Magma在UI导航和机器人操纵任务上创造了新的最优结果，超越了针对这些任务专门设计的先前模型，并且在图像和视频相关的多模态任务上也比训练于更大规模数据集的流行多模态模型表现优异。为了可复现性，微软公开了Magma模型及其代码。 <div>
arXiv:2502.13130v1 Announce Type: new 
Abstract: We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds. Magma is a significant extension of vision-language (VL) models in that it not only retains the VL understanding ability (verbal intelligence) of the latter, but is also equipped with the ability to plan and act in the visual-spatial world (spatial-temporal intelligence) and complete agentic tasks ranging from UI navigation to robot manipulation. To endow the agentic capabilities, Magma is pretrained on large amounts of heterogeneous datasets spanning from images, videos to robotics data, where the actionable visual objects (e.g., clickable buttons in GUI) in images are labeled by Set-of-Mark (SoM) for action grounding, and the object movements (e.g., the trace of human hands or robotic arms) in videos are labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show that SoM and ToM reach great synergy and facilitate the acquisition of spatial-temporal intelligence for our Magma model, which is fundamental to a wide range of tasks as shown in Fig.1. In particular, Magma creates new state-of-the-art results on UI navigation and robotic manipulation tasks, outperforming previous models that are specifically tailored to these tasks. On image and video-related multimodal tasks, Magma also compares favorably to popular large multimodal models that are trained on much larger datasets. We make our model and code public for reproducibility at https://microsoft.github.io/Magma.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions</title>
<link>https://arxiv.org/abs/2502.13135</link>
<guid>https://arxiv.org/abs/2502.13135</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成合成用户、交互式代理、行为改变、健康教练、模拟交互

总结:
本文提出了一种端到端框架，用于为评估旨在鼓励积极行为改变（如健康和生活方式辅导）的交互式代理生成合成用户。该框架将合成用户扎根于真实的健康和生活方式条件中，以确保与健康教练代理进行现实的互动。生成合成用户的流程分为两个阶段：首先，基于实际世界的健康、生活方式因素以及基本人口统计学和行为属性生成结构化数据；其次，根据这些结构化数据构建合成用户的完整档案。通过使用如Concordia这样的生成型agent-based模型或直接利用语言模型来模拟合成用户与教练代理之间的互动。文章以两个独立开发的睡眠和糖尿病管理教练代理作为案例研究，通过分析教练代理对合成用户需求和挑战的理解，证明了该框架的有效性。此外，通过由人类专家进行的多次双盲评估，表明具有健康和行为属性的合成用户相比未扎根于此类属性的通用合成用户，更能准确地描绘具有相同属性的真实人类用户。该提出的框架为通过大量、真实和扎根于实际场景的模拟交互来高效开发对话代理奠定了基础。 <div>
arXiv:2502.13135v1 Announce Type: new 
Abstract: We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes management in this study, to ensure realistic interactions with the health coaching agent. Synthetic users are created in two stages: first, structured data are generated grounded in real-world health and lifestyle factors in addition to basic demographics and behavioral attributes; second, full profiles of the synthetic users are developed conditioned on the structured data. Interactions between synthetic users and the coaching agent are simulated using generative agent-based models such as Concordia, or directly by prompting a language model. Using two independently-developed agents for sleep and diabetes coaching as case studies, the validity of this framework is demonstrated by analyzing the coaching agent's understanding of the synthetic users' needs and challenges. Finally, through multiple blinded evaluations of user-coach interactions by human experts, we demonstrate that our synthetic users with health and behavioral attributes more accurately portray real human users with the same attributes, compared to generic synthetic users not grounded in such attributes. The proposed framework lays the foundation for efficient development of conversational agents through extensive, realistic, and grounded simulated interactions.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AIDE: AI-Driven Exploration in the Space of Code</title>
<link>https://arxiv.org/abs/2502.13138</link>
<guid>https://arxiv.org/abs/2502.13138</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、人工智能、AI-Driven Exploration (AIDE)、大型语言模型、代码优化

总结:
本文介绍了为解决机器学习工程中迭代和实验过程耗费大量人力和计算资源的问题而提出的新方法——AI-Driven Exploration (AIDE)。AIDE是一种由大型语言模型驱动的机器学习工程代理，它将机器学习工程视为代码优化问题，并将试错过程形式化为潜在解决方案的树搜索空间中的探索。通过策略性地重用和改进有前途的解决方案，AIDE能够在有效利用计算资源的同时实现性能提升，并已在多个机器学习工程基准测试上取得最优结果，包括Kaggle评估、OpenAI MLE-Bench和METRs RE-Bench。<br /><br /> <div>
arXiv:2502.13138v1 Announce Type: new 
Abstract: Machine learning, the foundation of modern artificial intelligence, has driven innovations that have fundamentally transformed the world. Yet, behind advancements lies a complex and often tedious process requiring labor and compute intensive iteration and experimentation. Engineers and scientists developing machine learning models spend much of their time on trial-and-error tasks instead of conceptualizing innovative solutions or research hypotheses. To address this challenge, we introduce AI-Driven Exploration (AIDE), a machine learning engineering agent powered by large language models (LLMs). AIDE frames machine learning engineering as a code optimization problem, and formulates trial-and-error as a tree search in the space of potential solutions. By strategically reusing and refining promising solutions, AIDE effectively trades computational resources for enhanced performance, achieving state-of-the-art results on multiple machine learning engineering benchmarks, including our Kaggle evaluations, OpenAI MLE-Bench and METRs RE-Bench.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-dimensional Test Design</title>
<link>https://arxiv.org/abs/2502.12264</link>
<guid>https://arxiv.org/abs/2502.12264</guid>
<content:encoded><![CDATA[
<div> 关键词：多维度类型、测试设计、测试程序、操纵、投资

总结:
该文探讨了如何同时设计测试和安排机构执行这些测试（测试程序）的问题。研究建立了一个模型，其中委托人需利用多个测试筛选具有多维度类型的代理人，而代理人可以付出成本改变其类型。文章指出了设置严格测试与采用困难测试程序之间的新权衡。研究对比了两种情况：(1) 代理仅篡改其类型（操纵）；(2) 代理改善其实质类型（投资）。例如，这可以应用于面试、监管和数据分类场景。结果显示，在操纵情况下，严格的测试配合简单的程序（如固定顺序依次提供测试）是最优选择；而在投资环境下，非严格的测试加上困难的程序（如同时提供测试）为最优策略；然而，在满足一定条件的情况下，随机顺序依次提供测试也可能同样有效。因此，代理人究竟是操纵还是投资于其类型将决定最优的机构安排。 <div>
arXiv:2502.12264v1 Announce Type: cross 
Abstract: How should one jointly design tests and the arrangement of agencies to administer these tests (testing procedure)? To answer this question, we analyze a model where a principal must use multiple tests to screen an agent with a multi-dimensional type, knowing that the agent can change his type at a cost. We identify a new tradeoff between setting difficult tests and using a difficult testing procedure. We compare two settings: (1) the agent only misrepresents his type (manipulation) and (2) the agent improves his actual type (investment). Examples include interviews, regulations, and data classification. We show that in the manipulation setting, stringent tests combined with an easy procedure, i.e., offering tests sequentially in a fixed order, is optimal. In contrast, in the investment setting, non-stringent tests with a difficult procedure, i.e., offering tests simultaneously, is optimal; however, under mild conditions offering them sequentially in a random order may be as good. Our results suggest that whether the agent manipulates or invests in his type determines which arrangement of agencies is optimal.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Self-Resolving Prediction Markets for Unverifiable Outcomes</title>
<link>https://arxiv.org/abs/2306.04305</link>
<guid>https://arxiv.org/abs/2306.04305</guid>
<content:encoded><![CDATA[
<div> 关键词：预测市场、信息聚合、不可验证结果、负交叉熵、自我解决机制

<br /><br />总结:
本文提出了一种新的激励相容的预测市场机制，用于在无需观察实际结果的情况下，从代理池中收集并有效整合信息。该机制通过支付给代理人与其预测与精心选择的信息更丰富的参考代理人预测之间的负交叉熵来引导和激励预测。关键创新点在于，将具有更多信息的最终代理视为地面真实情况的一个合理代理。文中设计了自解冑预测市场，它在每次报告后有一定概率终止，并根据最终预测向除少数几个代理人之外的所有人付款，而最后一个被选为参考代理的代理人由于能观察到完整的市场预测历史，因此在设计上拥有更多信息。文章证明了在所提出的机制中，所有代理人真诚报告并相信其他代理人也同样真诚报告是一种完美贝叶斯均衡（PBE）。尽管该设计主要适用于不可验证的结果，但对于可验证的结果也同样适用。 <div>
arXiv:2306.04305v2 Announce Type: replace 
Abstract: Prediction markets elicit and aggregate beliefs by paying agents based on how close their predictions are to a verifiable future outcome. However, outcomes of many important questions are difficult to verify or unverifiable, in that the ground truth may be hard or impossible to access. We present a novel incentive-compatible prediction market mechanism to elicit and efficiently aggregate information from a pool of agents without observing the outcome, by paying agents the negative cross-entropy between their prediction and that of a carefully chosen reference agent. Our key insight is that a reference agent with access to more information can serve as a reasonable proxy for the ground truth. We use this insight to propose self-resolving prediction markets that terminate with some probability after every report and pay all but a few agents based on the final prediction. The final agent is chosen as the reference agent since they observe the full history of market forecasts, and thus have more information by design. We show that it is a perfect Bayesian equilibrium (PBE) for all agents to report truthfully in our mechanism and to believe that all other agents report truthfully. Although primarily of interest for unverifiable outcomes, this design is also applicable for verifiable outcomes.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version)</title>
<link>https://arxiv.org/abs/2311.01534</link>
<guid>https://arxiv.org/abs/2311.01534</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体出租车调度、自主导航、预测需求、近似多智能体滚动算法、稳定性

总结:
本文关注于大型城市环境中未知未来乘车需求的自主多智能体出租车路由问题。研究中提出了一种旨在解决大规模环境下计算瓶颈的近似多智能体滚动算法的两阶段方法，该方法降低了计算成本的同时仍能实现稳定且接近最优的策略。首先，根据预测需求和用户计算资源限制的最大出租车数量将地图划分为多个区域；然后，采用瞬时分配（IA）进行出租车在各区域间的再平衡，并对每个区域并行执行一种局部多智能体滚动算法。文章给出了两个主要理论结果：1) 描述了确保IA稳定的所需出租车数量$m$；2) 得出了当时间趋于无穷大时，维持IA稳定性的$m$的必要条件。数值结果显示，所提方法在满足理论条件的情况下实现了稳定性，而且实证表明，与逐次滚动整个地图相比，提出的两阶段算法具有等效性能但运行时间显著减少。 <div>
arXiv:2311.01534v4 Announce Type: replace 
Abstract: In this paper, we focus on the autonomous multiagent taxi routing problem for a large urban environment where the location and number of future ride requests are unknown a-priori, but can be estimated by an empirical distribution. Recent theory has shown that a rollout algorithm with a stable base policy produces a near-optimal stable policy. In the routing setting, a policy is stable if its execution keeps the number of outstanding requests uniformly bounded over time. Although, rollout-based approaches are well-suited for learning cooperative multiagent policies with considerations for future demand, applying such methods to a large urban environment can be computationally expensive due to the large number of taxis required for stability. In this paper, we aim to address the computational bottleneck of multiagent rollout by proposing an approximate multiagent rollout-based two phase algorithm that reduces computational costs, while still achieving a stable near-optimal policy. Our approach partitions the graph into sectors based on the predicted demand and the maximum number of taxis that can run sequentially given the user's computational resources. The algorithm then applies instantaneous assignment (IA) for re-balancing taxis across sectors and a sector-wide multiagent rollout algorithm that is executed in parallel for each sector. We provide two main theoretical results: 1) characterize the number of taxis $m$ that is sufficient for IA to be stable; 2) derive a necessary condition on $m$ to maintain stability for IA as time goes to infinity. Our numerical results show that our approach achieves stability for an $m$ that satisfies the theoretical conditions. We also empirically demonstrate that our proposed two phase algorithm has equivalent performance to the one-at-a-time rollout over the entire map, but with significantly lower runtimes.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>R3L: Relative Representations for Reinforcement Learning</title>
<link>https://arxiv.org/abs/2404.12917</link>
<guid>https://arxiv.org/abs/2404.12917</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉强化学习, 代表学习, 相对表示框架, 无监督学习, 模型重用

总结:
本文探讨了视觉强化学习领域中，输入域和任务域的变化可能导致智能体性能下降的问题。为解决此问题，研究者借鉴了相对表示框架，该框架可将编码器嵌入映射到一个通用空间。文章提出将这一框架应用于视觉强化学习场景，使得可以通过组合不同智能体的组件创建新智能体，进而有效应对训练期间未遇见过的新型视觉-任务组合。这种方法突显出模型重用的潜力，显著减少了重新训练的需求，以及因此所需的时间和计算资源。<br /><br /> <div>
arXiv:2404.12917v3 Announce Type: replace 
Abstract: Visual Reinforcement Learning is a popular and powerful framework that takes full advantage of the Deep Learning breakthrough. It is known that variations in input domains (e.g., different panorama colors due to seasonal changes) or task domains (e.g., altering the target speed of a car) can disrupt agent performance, necessitating new training for each variation. Recent advancements in the field of representation learning have demonstrated the possibility of combining components from different neural networks to create new models in a zero-shot fashion. In this paper, we build upon relative representations, a framework that maps encoder embeddings to a universal space. We adapt this framework to the Visual Reinforcement Learning setting, allowing to combine agents components to create new agents capable of effectively handling novel visual-task pairs not encountered during training. Our findings highlight the potential for model reuse, significantly reducing the need for retraining and, consequently, the time and computational resources required.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention</title>
<link>https://arxiv.org/abs/2405.18295</link>
<guid>https://arxiv.org/abs/2405.18295</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D意图定位、RGB-D、意图理解、候选人推理、级联自适应学习

总结:
本文提出了一个新的任务——3D意图定位，该任务基于RGB-D数据和人类意图来进行3D对象检测。与相关的3D视觉定位相比，3D意图定位要求AI系统仅根据人类意图自动观察、推理并检测目标物体。为了解决这一挑战，文章构建了Intent3D数据集，包含44,990条意图文本和ScanNet数据集中1,042个场景的209种细粒度类别关联。文中还为新的基准测试建立了几个基于不同语言驱动的3D对象检测模型的基线。进一步地，文章提出了IntentNet，这是一个针对意图检测问题的独特方法，重点关注三个方面：意图理解、用于识别候选物体的推理以及利用多重目标优化中不同损失的内在优先逻辑的级联自适应学习。相关项目页面：https://weitaikang.github.io/Intent3D-webpage/ <div>
arXiv:2405.18295v3 Announce Type: replace 
Abstract: In real-life scenarios, humans seek out objects in the 3D world to fulfill their daily needs or intentions. This inspires us to introduce 3D intention grounding, a new task in 3D object detection employing RGB-D, based on human intention, such as "I want something to support my back". Closely related, 3D visual grounding focuses on understanding human reference. To achieve detection based on human intention, it relies on humans to observe the scene, reason out the target that aligns with their intention ("pillow" in this case), and finally provide a reference to the AI system, such as "A pillow on the couch". Instead, 3D intention grounding challenges AI agents to automatically observe, reason and detect the desired target solely based on human intention. To tackle this challenge, we introduce the new Intent3D dataset, consisting of 44,990 intention texts associated with 209 fine-grained classes from 1,042 scenes of the ScanNet dataset. We also establish several baselines based on different language-based 3D object detection models on our benchmark. Finally, we propose IntentNet, our unique approach, designed to tackle this intention-based detection problem. It focuses on three key aspects: intention understanding, reasoning to identify object candidates, and cascaded adaptive learning that leverages the intrinsic priority logic of different losses for multiple objective optimization. Project Page: https://weitaikang.github.io/Intent3D-webpage/
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On shallow planning under partial observability</title>
<link>https://arxiv.org/abs/2407.15820</link>
<guid>https://arxiv.org/abs/2407.15820</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习、折扣因子、学习目标、规划周期、偏倚-方差权衡

<br />
总结:
本文探讨了在强化学习框架下，设计选择中的折扣因子对具有结构参数的底层马尔科夫决策过程中的偏倚-方差权衡的影响。研究结果表明，较短的规划周期可能更为有益，尤其是在部分可观测的情况下。这为如何选择折扣因子提供了理论支持。 <div>
arXiv:2407.15820v2 Announce Type: replace 
Abstract: Formulating a real-world problem under the Reinforcement Learning framework involves non-trivial design choices, such as selecting a discount factor for the learning objective (discounted cumulative rewards), which articulates the planning horizon of the agent. This work investigates the impact of the discount factor on the bias-variance trade-off given structural parameters of the underlying Markov Decision Process. Our results support the idea that a shorter planning horizon might be beneficial, especially under partial observability.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS</title>
<link>https://arxiv.org/abs/2408.01584</link>
<guid>https://arxiv.org/abs/2408.01584</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent learning, GPUDrive, GPU-accelerated, simulation, reinforcement learning

总结：
本文介绍了为解决多智能体规划领域中需要大量模拟步数的问题而提出的GPUDrive。GPUDrive是一个基于Madrona游戏引擎构建的、可GPU加速的多智能体模拟器，能实现每秒超过一百万步的模拟速度。该模拟器允许用户使用C++直接编写复杂、异构的智能体行为，并通过Python提供高效便捷的封闭回路模拟工作流程。利用GPUDrive，研究者在Waymo开放运动数据集上训练强化学习代理，并在几分钟内实现了高效的到达目标学习，能在几小时内扩展到数千个场景。相关代码和预训练模型已在https://github.com/Emerge-Lab/gpudrive开源。<br /><br /> <div>
arXiv:2408.01584v3 Announce Type: replace 
Abstract: Multi-agent learning algorithms have been successful at generating superhuman planning in various games but have had limited impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at scale, we present GPUDrive. GPUDrive is a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine capable of generating over a million simulation steps per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. Despite these low-level optimizations, GPUDrive is fully accessible through Python, offering a seamless and efficient workflow for multi-agent, closed-loop simulation. Using GPUDrive, we train reinforcement learning agents on the Waymo Open Motion Dataset, achieving efficient goal-reaching in minutes and scaling to thousands of scenarios in hours. We open-source the code and pre-trained agents at https://github.com/Emerge-Lab/gpudrive.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Toward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera</title>
<link>https://arxiv.org/abs/2408.07982</link>
<guid>https://arxiv.org/abs/2408.07982</guid>
<content:encoded><![CDATA[
<div> 关键词：ChatGPT，LLMs，多模态对话，情绪识别，人工智能代理人

<br /><br />总结:
该研究关注于利用基于LLM（如ChatGPT）的人工智能代理在多模态对话中识别用户情感状态的能力。研究通过摄像头捕捉用户的面部表情，识别人类的情感，并将这种情感信息添加到提示中，使AI代理能够根据用户的情绪状态进行互动。实验结果显示，当用户处于诸如快乐和愤怒等情感状态得分较高的情况下，AI代理确实能实现相应情绪下的对话交互。 <div>
arXiv:2408.07982v2 Announce Type: replace 
Abstract: The performance of ChatGPT\copyright{} and other LLMs has improved tremendously, and in online environments, they are increasingly likely to be used in a wide variety of situations, such as ChatBot on web pages, call center operations using voice interaction, and dialogue functions using agents. In the offline environment, multimodal dialogue functions are also being realized, such as guidance by Artificial Intelligence agents (AI agents) using tablet terminals and dialogue systems in the form of LLMs mounted on robots. In this multimodal dialogue, mutual emotion recognition between the AI and the user will become important. So far, there have been methods for expressing emotions on the part of the AI agent or for recognizing them using textual or voice information of the user's utterances, but methods for AI agents to recognize emotions from the user's facial expressions have not been studied. In this study, we examined whether or not LLM-based AI agents can interact with users according to their emotional states by capturing the user in dialogue with a camera, recognizing emotions from facial expressions, and adding such emotion information to prompts. The results confirmed that AI agents can have conversations according to the emotional state for emotional states with relatively high scores, such as Happy and Angry.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FlowAct: A Proactive Multimodal Human-robot Interaction System with Continuous Flow of Perception and Modular Action Sub-systems</title>
<link>https://arxiv.org/abs/2408.15864</link>
<guid>https://arxiv.org/abs/2408.15864</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主系统、人类-机器人交互、Flowact、环境状态跟踪、行动规划器

总结:
本文介绍了Flowact，一个用于自主系统的前瞻性多模态人机交互架构。该架构通过两个控制器——环境状态跟踪（EST）和行动规划器，形成了一个异步的永续感知到执行循环。EST不断收集并发布操作环境的表示，确保了持续的感知数据流。这股持久的感知流为先进的行动规划器提供了支持，后者基于环境叙事的变化来协调和启动或停止一系列模块化的动作子系统，如运动和语音模块。EST采用多种传感模态融合技术，实时构建丰富的环境表示，并将其分布给行动规划器。通过一系列真实世界实验，证明了该系统在维持连续的感知-行动回路方面具有显著效果，极大地提升了自主主动代理的响应性和适应性。Flowact的模块化动作子系统结构也便于根据不同任务和场景进行扩展和适应。 <div>
arXiv:2408.15864v2 Announce Type: replace 
Abstract: The evolution of autonomous systems in the context of human-robot interaction systems necessitates a synergy between the continuous perception of the environment and the potential actions to navigate or interact within it. We present Flowact, a proactive multimodal human-robot interaction architecture, working as an asynchronous endless loop of robot sensors into actuators and organized by two controllers, the Environment State Tracking (EST) and the Action Planner. The EST continuously collects and publishes a representation of the operative environment, ensuring a steady flow of perceptual data. This persistent perceptual flow is pivotal for our advanced Action Planner which orchestrates a collection of modular action subsystems, such as movement and speaking modules, governing their initiation or cessation based on the evolving environmental narrative. The EST employs a fusion of diverse sensory modalities to build a rich, real-time representation of the environment that is distributed to the Action Planner. This planner uses a decision-making framework to dynamically coordinate action modules, allowing them to respond proactively and coherently to changes in the environment. Through a series of real-world experiments, we exhibit the efficacy of the system in maintaining a continuous perception-action loop, substantially enhancing the responsiveness and adaptability of autonomous pro-active agents. The modular architecture of the action subsystems facilitates easy extensibility and adaptability to a broad spectrum of tasks and scenarios.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning</title>
<link>https://arxiv.org/abs/2409.07494</link>
<guid>https://arxiv.org/abs/2409.07494</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、欺诈检测、交易语言模型、图神经网络、联合训练

总结:
本文针对Ethereum面临的日益增长的欺诈威胁问题，提出了一个新的欺诈检测方法TLMG4Eth。该方法通过结合交易语言模型与图基方法，充分利用交易数据的语义、相似性和结构特征。首先，文章提出了一种交易语言模型，将数值型交易数据转化为有意义的交易句子，使模型能够学习到显式的交易语义。其次，构建了一个交易属性相似图来捕获交易间的相似信息，从而直观地识别交易异常。此外，还构造了账户交互图以捕捉账户交易网络的结构信息。TLMG4Eth采用深度多头注意力网络融合交易语义和相似性嵌入，并最终提出了一个多头注意力网络与账户交互图的联合训练方法，以实现两种模型的协同效益。 <div>
arXiv:2409.07494v2 Announce Type: replace 
Abstract: Ethereum faces growing fraud threats. Current fraud detection methods, whether employing graph neural networks or sequence models, fail to consider the semantic information and similarity patterns within transactions. Moreover, these approaches do not leverage the potential synergistic benefits of combining both types of models. To address these challenges, we propose TLMG4Eth that combines a transaction language model with graph-based methods to capture semantic, similarity, and structural features of transaction data in Ethereum. We first propose a transaction language model that converts numerical transaction data into meaningful transaction sentences, enabling the model to learn explicit transaction semantics. Then, we propose a transaction attribute similarity graph to learn transaction similarity information, enabling us to capture intuitive insights into transaction anomalies. Additionally, we construct an account interaction graph to capture the structural information of the account transaction network. We employ a deep multi-head attention network to fuse transaction semantic and similarity embeddings, and ultimately propose a joint training approach for the multi-head attention network and the account interaction graph to obtain the synergistic benefits of both.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sable: a Performant, Efficient and Scalable Sequence Model for MARL</title>
<link>https://arxiv.org/abs/2410.01706</link>
<guid>https://arxiv.org/abs/2410.01706</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习（MARL）、Sable、性能、内存效率、可扩展性

总结:
本文介绍了Sable，一种针对多智能体强化学习（MARL）的高性能、内存高效和可扩展的序列建模方法。Sable通过将Retentive Networks中的保留机制进行调整，实现了对具有长上下文记忆的多智能体观察信息的计算效率处理，从而进行有效的时序推理。实验证明，Sable在六个多样化的环境中，在大量不同的任务（45项测试中占34项）上显著优于现有的最优方法。此外，随着代理数量的增加，Sable能保持其性能表现，同时表现出线性的内存使用增长，可以处理拥有上千个代理的环境。最后，作者进行了消融研究以确定Sable性能提升的原因并证实了其在计算内存使用上的高效性。 <div>
arXiv:2410.01706v3 Announce Type: replace 
Abstract: As multi-agent reinforcement learning (MARL) progresses towards solving larger and more complex problems, it becomes increasingly important that algorithms exhibit the key properties of (1) strong performance, (2) memory efficiency and (3) scalability. In this work, we introduce Sable, a performant, memory efficient and scalable sequence modeling approach to MARL. Sable works by adapting the retention mechanism in Retentive Networks (Sun et al., 2023) to achieve computationally efficient processing of multi-agent observations with long context memory for temporal reasoning. Through extensive evaluations across six diverse environments, we demonstrate how Sable is able to significantly outperform existing state-of-the-art methods in a large number of diverse tasks (34 out of 45 tested). Furthermore, Sable maintains performance as we scale the number of agents, handling environments with more than a thousand agents while exhibiting a linear increase in memory usage. Finally, we conduct ablation studies to isolate the source of Sable's performance gains and confirm its efficient computational memory usage.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.02089</link>
<guid>https://arxiv.org/abs/2410.02089</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、强化学习、代码合成、竞争编程任务、反馈利用

总结:
本文提出了一种端到端的强化学习方法，旨在教授模型如何在代码合成人任务中利用执行反馈，以帮助当前最先进的大规模语言模型更好地进行迭代改进。研究集中在竞争编程任务上，实验结果显示，使用该方法训练的小型（8B参数）和大型（70B）模型均取得了新的state-of-the-art结果，并将所需的样本数量减少了整整一个数量级。分析表明，所提出的方法使模型能够在多步推理过程中有效利用自动反馈。 <div>
arXiv:2410.02089v2 Announce Type: replace 
Abstract: Large language models (LLMs) deployed as agents solve user-specified tasks over multiple steps while keeping the required manual engagement to a minimum. Crucially, such LLMs need to ground their generations in any feedback obtained to reliably achieve the desired outcomes. We propose an end-to-end reinforcement learning method for teaching models to leverage execution feedback in the realm of code synthesis, where state-of-the-art LLMs struggle to improve code iteratively compared to independent sampling. We benchmark on competitive programming tasks, where we achieve new state-of-the art results with both small (8B parameters) and large (70B) models while reducing the amount of samples required by an order of magnitude. Our analysis of inference-time behavior demonstrates that our method produces LLMs that effectively leverage automatic feedback over multiple steps.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>G\"odel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement</title>
<link>https://arxiv.org/abs/2410.04444</link>
<guid>https://arxiv.org/abs/2410.04444</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、智能代理、G\"odel机、自我进化、性能超越

<br /><br />总结:
本文提出了一种名为G\"odel Agent的自进化框架，该框架受到G\"odel机器的启发，允许智能代理无需依赖预定义程序或固定优化算法，能够递归地改进自身。G\"odel Agent利用大规模语言模型动态调整自身的逻辑和行为，仅根据高层目标通过提示进行引导。实验结果表明，在数学推理和复杂智能体任务上，实施G\"odel Agent可以实现连续的自我提升，其性能、效率和泛化能力均超过了人工精心设计的智能代理。 <div>
arXiv:2410.04444v3 Announce Type: replace 
Abstract: The rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of AI-driven agents across various tasks. However, existing agentic systems, whether based on fixed pipeline algorithms or pre-defined meta-learning frameworks, cannot search the whole agent design space due to the restriction of human-designed components, and thus might miss the globally optimal agent design. In this paper, we introduce G\"odel Agent, a self-evolving framework inspired by the G\"odel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. G\"odel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of G\"odel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System</title>
<link>https://arxiv.org/abs/2410.08115</link>
<guid>https://arxiv.org/abs/2410.08115</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 多智能体系统, 通信效率, 任务性能, Optima

总结:
本文介绍了Optima，一个针对基于大型语言模型（LLM）的多智能体系统（MAS）所面临的关键挑战的新框架。Optima通过LLM训练显著提高了通信效率和任务效果，采用生成、排序、选择和训练的迭代范式，并利用奖励函数平衡任务表现、令牌效率和通信可读性。研究了包括监督微调、直接偏好优化及其混合方法在内的多种强化学习算法，探讨了它们在效果与效率之间的权衡。Optima借鉴蒙特卡洛树搜索技术，将对话回合视为树节点以探索多样化的交互路径。在信息不对称问题回答和复杂推理等多智能体任务上，Optima相对于单智能体基线和基于Llama 3 8B的原生MAS显示出了持续且显著的性能提升，实现了在需要大量信息交换的任务中使用不到10%的令牌即可获得高达2.8倍的性能增益。此外，Optima的效率提升还为更有效地利用推断计算开辟了新的可能性，从而改进了推理时间的扩展定律。Optima为实现可扩展、高效且有效的MAS展示了潜力。 <div>
arXiv:2410.08115v2 Announce Type: replace 
Abstract: Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel framework that addresses these issues by significantly enhancing both communication efficiency and task effectiveness in LLM-based MAS through LLM training. Optima employs an iterative generate, rank, select, and train paradigm with a reward function balancing task performance, token efficiency, and communication readability. We explore various RL algorithms, including Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid approaches, providing insights into their effectiveness-efficiency trade-offs. We integrate Monte Carlo Tree Search-inspired techniques for DPO data generation, treating conversation turns as tree nodes to explore diverse interaction paths. Evaluated on common multi-agent tasks, including information-asymmetric question answering and complex reasoning, Optima shows consistent and substantial improvements over single-agent baselines and vanilla MAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than 10\% tokens on tasks requiring heavy information exchange. Moreover, Optima's efficiency gains open new possibilities for leveraging inference-compute more effectively, leading to improved inference-time scaling laws. By addressing fundamental challenges in LLM-based MAS, Optima shows the potential towards scalable, efficient, and effective MAS (https://chenweize1998.github.io/optima-project-page).
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human-Agent Coordination in Games under Incomplete Information via Multi-Step Intent</title>
<link>https://arxiv.org/abs/2410.18242</link>
<guid>https://arxiv.org/abs/2410.18242</guid>
<content:encoded><![CDATA[
<div> 关键词：autonomous agents, incomplete information, multi-action turn-based game, IntentMCTS, cooperative policies

总结:<br />
本文探讨了在不完全信息条件下自主代理与人类伙伴之间进行战略协调的问题，并将其扩展为允许玩家在每回合执行多个动作的共享控制游戏。研究提出了一种名为IntentMCTS的在线规划算法，该算法结合记忆模块以维持对环境动态的概率信念，并通过奖励增强利用多步意图选择下一步行动。在Gnomes at Night测试平台上的模拟实验表明，IntentMCTS相比基线方法需要更少的步骤和控制切换。用户研究表明，IntentMCTS相对于启发式基线成功率为18.52%的提升，比单步前作提高了5.56%，并且参与者的认知负荷、挫败感更低，对IntentMCTS智能体伙伴的满意度更高。 <div>
arXiv:2410.18242v2 Announce Type: replace 
Abstract: Strategic coordination between autonomous agents and human partners under incomplete information can be modeled as turn-based cooperative games. We extend a turn-based game under incomplete information, the shared-control game, to allow players to take multiple actions per turn rather than a single action. The extension enables the use of multi-step intent, which we hypothesize will improve performance in long-horizon tasks. To synthesize cooperative policies for the agent in this extended game, we propose an approach featuring a memory module for a running probabilistic belief of the environment dynamics and an online planning algorithm called IntentMCTS. This algorithm strategically selects the next action by leveraging any communicated multi-step intent via reward augmentation while considering the current belief. Agent-to-agent simulations in the Gnomes at Night testbed demonstrate that IntentMCTS requires fewer steps and control switches than baseline methods. A human-agent user study corroborates these findings, showing an 18.52% higher success rate compared to the heuristic baseline and a 5.56% improvement over the single-step prior work. Participants also report lower cognitive load, frustration, and higher satisfaction with the IntentMCTS agent partner.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement</title>
<link>https://arxiv.org/abs/2410.20285</link>
<guid>https://arxiv.org/abs/2410.20285</guid>
<content:encoded><![CDATA[
<div> 关键词：SWE-Search、多智能体框架、蒙特卡洛树搜索(MCTS)、自改进机制、软件工程任务

<br /><br />总结：
本文提出了一种名为SWE-Search的多智能体框架，旨在解决复杂动态环境中软件工程师面临的挑战。该框架通过将蒙特卡洛树搜索(MCTS)与自改进机制相结合，提升了基于大型语言模型（LLM）的软件代理在处理仓库级软件任务时的表现。SWE-Search扩展了传统的MCTS，采用混合价值函数，利用LLMs同时进行数值估值和定性评估，形成了自我反馈循环，使代理能够根据定量数值评价和定性的自然语言评估迭代优化策略。框架包括适应性探索的SWE-Agent、提供迭代反馈的价值Agent以及促进多智能体辩论协作决策的鉴别器Agent。实验结果表明，相比于没有使用MCTS的标准开源代理，SWE-Search在SWE-bench基准上实现了23%的相对性能提升。此外，文中还分析了性能随搜索深度增加的变化情况以及影响软件代理人有效自我评估的关键因素。这项工作突显出自评价驱动的搜索技术在复杂、动态软件工程环境中的潜力和价值。 <div>
arXiv:2410.20285v4 Announce Type: replace 
Abstract: Software engineers operating in complex and dynamic environments must continuously adapt to evolving requirements, learn iteratively from experience, and reconsider their approaches based on new insights. However, current large language model (LLM)-based software agents often rely on rigid processes and tend to repeat ineffective actions without the capacity to evaluate their performance or adapt their strategies over time. To address these challenges, we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with a self-improvement mechanism to enhance software agents' performance on repository-level software tasks. SWE-Search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This enables self-feedback loops where agents iteratively refine their strategies based on both quantitative numerical evaluations and qualitative natural language assessments of pursued trajectories. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making. Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased search depth and identifies key factors that facilitate effective self-evaluation in software agents. This work highlights the potential of self-evaluation driven search techniques to enhance agent reasoning and planning in complex, dynamic software engineering environments.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personalized Help for Optimizing Low-Skilled Users' Strategy</title>
<link>https://arxiv.org/abs/2411.09109</link>
<guid>https://arxiv.org/abs/2411.09109</guid>
<content:encoded><![CDATA[
<div> 关键词: AI、CICERO、游戏环境、建议生成、新手玩家

总结:
本文探讨了AI在游戏环境中的辅助作用，特别是关注了名为CICERO的自然语言智能体。研究者将CICERO增强以根据玩家意图生成动作和消息建议。通过让新手和经验丰富的玩家参与带有不同建议设置的十几场Diplomacy游戏，结果表明，一些生成的建议对玩家有益。这些建议帮助新手能够与经验丰富的玩家竞争，并在某些情况下甚至超越他们。此外，即使玩家不采纳建议，仅仅存在建议这一现象也具有优势。 <div>
arXiv:2411.09109v2 Announce Type: replace 
Abstract: AIs can beat humans in game environments; however, how helpful those agents are to human remains understudied. We augment CICERO, a natural language agent that demonstrates superhuman performance in Diplomacy, to generate both move and message advice based on player intentions. A dozen Diplomacy games with novice and experienced players, with varying advice settings, show that some of the generated advice is beneficial. It helps novices compete with experienced players and in some instances even surpass them. The mere presence of advice can be advantageous, even if players do not follow it.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FlexFL: Flexible and Effective Fault Localization with Open-Source Large Language Models</title>
<link>https://arxiv.org/abs/2411.10714</link>
<guid>https://arxiv.org/abs/2411.10714</guid>
<content:encoded><![CDATA[
<div> 关键词: FlexFL、LLMs、故障定位、开放源代码、GPT-3.5

总结:<br />
本文提出了一种名为FlexFL的新颖的基于大型语言模型（LLMs）的灵活故障定位框架，旨在解决现有方法在灵活性和数据隐私方面的局限性。FlexFL包括两个阶段，第一阶段利用先进的故障定位技术缩小buggy代码的搜索空间并生成候选列表；第二阶段借助开放源代码的LLMs对第一阶段推荐的方法进行深入检查，以细化故障定位结果。FlexFL构建的代理基于开放源代码的LLMs，具有相同的处理管道，不依赖任何类型的bug相关信息，并能与函数调用交互。实验结果显示，FlexFL在Defects4J上的表现优于基线，并能够与不同的开源LLMs配合使用。具体来说，使用轻量级开源LLM Llama3-8B的FlexFL比采用GPT-3.5的两种最先进的LLM-based FL方法AutoFL和AgentFL多定位到42和63个缺陷。 <div>
arXiv:2411.10714v2 Announce Type: replace 
Abstract: Due to the impressive code comprehension ability of Large Language Models (LLMs), a few studies have proposed to leverage LLMs to locate bugs, i.e., LLM-based FL, and demonstrated promising performance. However, first, these methods are limited in flexibility. They rely on bug-triggering test cases to perform FL and cannot make use of other available bug-related information, e.g., bug reports. Second, they are built upon proprietary LLMs, which are, although powerful, confronted with risks in data privacy. To address these limitations, we propose a novel LLM-based FL framework named FlexFL, which can flexibly leverage different types of bug-related information and effectively work with open-source LLMs. FlexFL is composed of two stages. In the first stage, FlexFL reduces the search space of buggy code using state-of-the-art FL techniques of different families and provides a candidate list of bug-related methods. In the second stage, FlexFL leverages LLMs to delve deeper to double-check the code snippets of methods suggested by the first stage and refine fault localization results. In each stage, FlexFL constructs agents based on open-source LLMs, which share the same pipeline that does not postulate any type of bug-related information and can interact with function calls without the out-of-the-box capability. Extensive experimental results on Defects4J demonstrate that FlexFL outperforms the baselines and can work with different open-source LLMs. Specifically, FlexFL with a lightweight open-source LLM Llama3-8B can locate 42 and 63 more bugs than two state-of-the-art LLM-based FL approaches AutoFL and AgentFL that both use GPT-3.5.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in Cyber World</title>
<link>https://arxiv.org/abs/2412.07472</link>
<guid>https://arxiv.org/abs/2412.07472</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态感知、大规模视觉语言模型、智能体、个性化、Chain-of-User-Thought (COUT)

<br /><br />总结:
本文提出了一种新的多模态智能体学习框架——Chain-of-User-Thought (COUT)，旨在解决当前基于大规模视觉语言模型的智能体在个人助理应用中的性能不足问题。COUT通过将基本动作思考与用户的显式和隐性个性化偏好思考相结合，将个性化因素融入到自主代理学习中。为了实现COUT，文章介绍了SmartAgent框架，该框架能感知虚拟环境，理解并推理用户的个性化需求，包括与GUI交互获取物品池、根据用户先前行为生成其显式需求以及推荐满足隐性需求的物品。此外，文中还构建了一个全新的数据集SmartSpot，用于展示SmartAgent在一系列具身化及个性化的子任务中的功能。据作者所知，这是首次对COUT过程进行形式化描述，为未来具有个性化的具身智能体学习领域提供了初步尝试。实验结果证实了SmartAgent在SmartSpot数据集上的功能表现。相关代码和数据将在论文接受后发布。 <div>
arXiv:2412.07472v3 Announce Type: replace 
Abstract: Recent advances in embodied agents with multimodal perception and reasoning capabilities based on large vision-language models (LVLMs), excel in autonomously interacting either real or cyber worlds, helping people make intelligent decisions in complex environments. However, the current works are normally optimized by golden action trajectories or ideal task-oriented solutions toward a definitive goal. This paradigm considers limited user-oriented factors, which could be the reason for their performance reduction in a wide range of personal assistant applications. To address this, we propose Chain-of-User-Thought (COUT), a novel embodied reasoning paradigm that takes a chain of thought from basic action thinking to explicit and implicit personalized preference thought to incorporate personalized factors into autonomous agent learning. To target COUT, we introduce SmartAgent, an agent framework perceiving cyber environments and reasoning personalized requirements as 1) interacting with GUI to access an item pool, 2) generating users' explicit requirements implied by previous actions, and 3) recommending items to fulfill users' implicit requirements. To demonstrate SmartAgent's capabilities, we also create a brand-new dataset SmartSpot that offers a full-stage personalized action-involved environment. To our best knowledge, our work is the first to formulate the COUT process, serving as a preliminary attempt towards embodied personalized agent learning. Our extensive experiments on SmartSpot illuminate SmartAgent's functionality among a series of embodied and personalized sub-tasks. We will release code and data upon paper notification at https://github.com/tsinghua-fib-lab/SmartAgent.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GAMA: Generative Agents for Multi-Agent Autoformalization</title>
<link>https://arxiv.org/abs/2412.08805</link>
<guid>https://arxiv.org/abs/2412.08805</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体模拟、自动形式化、大语言模型、游戏理论、逻辑程序

总结:
本文提出了一种利用大型语言模型（如Claude 3.5 Sonnet和GPT-4o）自动化构建互动场景的框架，该框架可将自然语言描述的交互转化为执行逻辑程序，确保了通过求解器验证的游戏规则的语法正确性。经过模拟比赛测试生成的游戏规则及其策略的功能性，如果具备地面真实支付矩阵，则可进行精确语义验证。研究团队在110个涵盖了五种$2\times2$同时移动游戏的自然语言描述上进行了评估，结果显示Claude 3.5 Sonnet和GPT-4o分别达到了100%和99.82%的语法正确性以及76.5%和77%的语义正确性。此外，对于自动生成的游戏策略也展示了高语义正确性。总体而言，这项工作突显了利用自动形式化和大语言模型为决策制定智能体生成形式推理模块的潜力。<br /><br /> <div>
arXiv:2412.08805v2 Announce Type: replace 
Abstract: Multi-agent simulations facilitate the exploration of interactions among both natural and artificial agents. However, modelling real-world scenarios and developing simulations often requires substantial expertise and effort. To streamline this process, we present a framework that enables the autoformalization of interaction scenarios using agents augmented by large language models (LLMs) utilising game-theoretic formalisms. The agents translate natural language descriptions of interactions into executable logic programs that define the rules of each game, ensuring syntactic correctness through validation by a solver. A tournament simulation then tests the functionality of the generated game rules and strategies. After the tournament, if a ground truth payoff matrix is available, an exact semantic validation is performed. We evaluate our approach on a diverse set of 110 natural language descriptions exemplifying five $2\times2$ simultaneous-move games, achieving 100% syntactic and 76.5% semantic correctness in the generated game rules for Claude 3.5 Sonnet, and 99.82% syntactic and 77% semantic correctness for GPT-4o. Additionally, we demonstrate high semantic correctness in autoformalizing gameplay strategies. Overall, the results highlight the potential of autoformalization to leverage LLMs in generating formal reasoning modules for decision-making agents.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A3: Android Agent Arena for Mobile GUI Agents</title>
<link>https://arxiv.org/abs/2501.01149</link>
<guid>https://arxiv.org/abs/2501.01149</guid>
<content:encoded><![CDATA[
<div> 关键词：AI代理、移动GUI代理、安卓Agent竞技场(A3)、真实世界任务、大规模语言模型

<br /><br />总结:

本文介绍了随着大规模语言模型的发展，AI代理在近年来日益普及，特别是移动GUI代理在移动设备上的应用。然而，现有的许多研究数据集侧重于静态帧评估，未能全面评价真实世界中的实际任务执行能力。针对这一问题，文章提出了一个新的评估平台——安卓Agent竞技场(A3)。A3的特点包括：(1) 提供有意义和实际的任务，如实时在线信息检索和操作指令；(2) 设计了一个更大、更灵活的操作空间，可以兼容基于任何数据集训练的代理；(3) 集成了自动化的商业级LLM基础的评价流程。A3包含了21款常用第三方应用程序及201个代表常见用户场景的任务，为评估移动GUI代理在现实环境中的性能提供了一个坚实的基础，并通过自动化评估过程减少了人工劳动和编码技术的需求。该项目已公开发布在https://yuxiangchai.github.io/Android-Agent-Arena/。 <div>
arXiv:2501.01149v2 Announce Type: replace 
Abstract: AI agents have become increasingly prevalent in recent years, driven by significant advancements in the field of large language models (LLMs). Mobile GUI agents, a subset of AI agents, are designed to autonomously perform tasks on mobile devices. While numerous studies have introduced agents, datasets, and benchmarks to advance mobile GUI agent research, many existing datasets focus on static frame evaluations and fail to provide a comprehensive platform for assessing performance on real-world, in-the-wild tasks. To address this gap, we present Android Agent Arena (A3), a novel evaluation platform. Unlike existing in-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as real-time online information retrieval and operational instructions; (2) a larger, more flexible action space, enabling compatibility with agents trained on any dataset; and (3) automated business-level LLM-based evaluation process. A3 includes 21 widely used general third-party apps and 201 tasks representative of common user scenarios, providing a robust foundation for evaluating mobile GUI agents in real-world situations and a new autonomous evaluation process for less human labor and coding expertise. The project is available at https://yuxiangchai.github.io/Android-Agent-Arena/.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Flexible Heterogeneous Coordination with Capability-Aware Shared Hypernetworks</title>
<link>https://arxiv.org/abs/2501.06058</link>
<guid>https://arxiv.org/abs/2501.06058</guid>
<content:encoded><![CDATA[
<div> 关键词：Cooperative heterogeneous multi-agent tasks、learning-based solutions、shared-parameter methods、independent methods、Capability-Aware Shared Hypernetworks (CASH)

<br /><br />总结：
本文提出了一种用于异质多智能体协作的新架构——Capability-Aware Shared Hypernetworks (CASH)，以解决智能体需有效协调行为并考虑各自相对能力的问题。现有的学习解决方案要么通过共享参数方法（导致行为多样性有限），要么通过独立方法（虽有更大多样性但样本效率低）。而CASH则采用软参数共享超网络生成足够的多样性同时保持样本效率。通过共享编码器学习通用策略，并利用超网络根据团队个体和集体的能力进行适应，实现了对未见过的团队和智能体的零样本泛化。实验结果表明，在两种异构协调任务以及三种标准学习范式（模仿学习、在线强化学习和离线强化学习）下，尽管CASH使用的可学习参数少于一半，但仍能在评估未见过的团队和智能体时取得优于基线架构的成功率和样本效率。 <div>
arXiv:2501.06058v2 Announce Type: replace 
Abstract: Cooperative heterogeneous multi-agent tasks require agents to effectively coordinate their behaviors while accounting for their relative capabilities. Learning-based solutions to this challenge span between two extremes: i) shared-parameter methods, which encode diverse behaviors within a single architecture by assigning an ID to each agent, and are sample-efficient but result in limited behavioral diversity; ii) independent methods, which learn a separate policy for each agent, and show greater behavioral diversity but lack sample-efficiency. Prior work has also explored selective parameter-sharing, allowing for a compromise between diversity and efficiency. None of these approaches, however, effectively generalize to unseen agents or teams. We present Capability-Aware Shared Hypernetworks (CASH), a novel architecture for heterogeneous multi-agent coordination that generates sufficient diversity while maintaining sample-efficiency via soft parameter-sharing hypernetworks. Intuitively, CASH allows the team to learn common strategies using a shared encoder, which are then adapted according to the team's individual and collective capabilities with a hypernetwork, allowing for zero-shot generalization to unseen teams and agents. We present experiments across two heterogeneous coordination tasks and three standard learning paradigms (imitation learning, on- and off-policy reinforcement learning). CASH is able to outperform baseline architectures in success rate and sample efficiency when evaluated on unseen teams and agents despite using less than half of the learnable parameters.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Attentive Graph Agent for Topology-Adaptive Cyber Defence</title>
<link>https://arxiv.org/abs/2501.14700</link>
<guid>https://arxiv.org/abs/2501.14700</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、网络安全、图注意力网络、自适应防御、Cyber Operations Research Gym<br /><br />总结:<br />
本文提出了一种利用强化学习（RL）创建智能且适应性强的网络安全防御系统的方法，着重解决了现有方法忽视计算机网络内在图结构的问题。研究中，作者开发了一个定制版的Cyber Operations Research Gym环境，将网络状态编码为具有现实低级特征的有向图。文章采用图注意力网络（GAT）架构处理节点、边和全局特征，并将其输出适配为与RL中的策略梯度方法兼容。这种方法相比扁平化方案具备优势，能展示对动态网络拓扑变化的鲁棒性，对同结构性分布下的不同大小网络具有合理的泛化能力，并提供了基于实际网络属性的可解释防御行为。实验表明，使用低级有向图观测值训练的GAT防御策略即使在网络模拟中出现意外连接也能正常运行，并在具有不同规模但结构一致的网络上展现出与针对特定网络配置训练的策略相当的性能。该研究为进一步发展能够更好地应对现实世界网络安全挑战的健壮防御系统做出了贡献。 <div>
arXiv:2501.14700v3 Announce Type: replace 
Abstract: As cyber threats grow increasingly sophisticated, reinforcement learning (RL) is emerging as a promising technique to create intelligent and adaptive cyber defense systems. However, most existing autonomous defensive agents have overlooked the inherent graph structure of computer networks subject to cyber attacks, potentially missing critical information and constraining their adaptability. To overcome these limitations, we developed a custom version of the Cyber Operations Research Gym (CybORG) environment, encoding network state as a directed graph with realistic low-level features. We employ a Graph Attention Network (GAT) architecture to process node, edge, and global features, and adapt its output to be compatible with policy gradient methods in RL. Our GAT-based approach offers key advantages over flattened alternatives: policies that demonstrate resilience to certain types of unexpected dynamic network topology changes, reasonable generalisation to networks of varying sizes within the same structural distribution, and interpretable defensive actions grounded in tangible network properties. We demonstrate that GAT defensive policies can be trained using our low-level directed graph observations, even when unexpected connections arise during simulation. Evaluations across networks of different sizes, but consistent subnetwork structure, show our policies achieve comparable performance to policies trained specifically for each network configuration. Our study contributes to the development of robust cyber defence systems that can better adapt to real-world network security challenges.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale Synthetic Personas</title>
<link>https://arxiv.org/abs/2501.15427</link>
<guid>https://arxiv.org/abs/2501.15427</guid>
<content:encoded><![CDATA[
<div> 关键词: 定制化角色扮演、大型语言模型、数据合成、响应重写、响应生成<br /><br />总结:
本文探讨了一种利用大规模数据合成为大型语言模型赋予定制化角色扮演能力的方法。研究者首先使用Persona Hub的人设信息合成了大量角色档案，随后尝试了两种策略——响应重写和响应生成，来创建符合角色设定的教学响应。为了验证这种方法的有效性，他们采用LLaMA-3 8B模型进行了监督微调（SFT）。实验结果显示，最佳表现的模型提升了原始的LLaMA-3 8B Instruct模型的能力，并在角色扮演对话任务上达到了与GPT-4o模型相当的表现。研究者将合成的角色及指令微调对话数据集公开发布，以支持该领域的公共研究。 <div>
arXiv:2501.15427v2 Announce Type: replace 
Abstract: Customizable role-playing in large language models (LLMs), also known as character generalization, is gaining increasing attention for its versatility and cost-efficiency in developing and deploying role-playing dialogue agents. This study explores a large-scale data synthesis approach to equip LLMs with character generalization capabilities. We begin by synthesizing large-scale character profiles using personas from Persona Hub and then explore two strategies: response rewriting and response generation, to create character-aligned instructional responses. To validate the effectiveness of our synthetic instruction tuning data for character generalization, we perform supervised fine-tuning (SFT) using the LLaMA-3 8B model. Our best-performing model strengthens the original LLaMA-3 8B Instruct model and achieves performance comparable to GPT-4o models on role-playing dialogue. We release our synthetic characters and instruction-tuning dialogues to support public research.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs</title>
<link>https://arxiv.org/abs/2502.03283</link>
<guid>https://arxiv.org/abs/2502.03283</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 知识图谱, 逻辑推理, SymAgent, 自主学习框架

总结:
本文提出了一个名为SymAgent的创新神经符号智能体框架，旨在解决大型语言模型（LLMs）在处理复杂推理问题时可能出现的错误。SymAgent通过将知识图谱视为动态环境并将其参与进多步交互过程，克服了现有方法对知识图谱完整性和静态使用的局限性。该框架包括两个模块：Agent-Planner和Agent-Executor。前者利用LLM的归纳推理能力从知识图谱中提取符号规则，指导问题的有效分解；后者自主调用预定义的操作工具，结合知识图谱与外部文档信息，应对知识图谱不完整性的问题。此外，文章还设计了一个包含在线探索和离线迭代策略更新阶段的自我学习框架，使智能体能够自动合成推理路径并提升性能。实验结果显示，即使使用弱化的LLM后端（如7B系列），SymAgent的表现也能优于或与各种强基线相当。进一步分析表明，SymAgent能够识别缺失的三元组，从而促进知识图谱的自动更新。 <div>
arXiv:2502.03283v2 Announce Type: replace 
Abstract: Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents</title>
<link>https://arxiv.org/abs/2502.05957</link>
<guid>https://arxiv.org/abs/2502.05957</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型(LLM), 自动化代理(AutoAgent), 无代码开发, 通用人工智能助手(GAIA基准),Retrieval-Augmented Generation(RAG)

总结:
本文介绍了一个名为AutoAgent的全新框架，旨在让不具备编程技能的人也能通过自然语言创建和部署大型语言模型（LLM）代理。AutoAgent是一个全自动、高度自我发展的代理操作系统，包括四个关键组件：i) 代理系统工具，ii) LLM驱动的可执行引擎，iii) 自主管理系统文件，和iv) 自我调整的代理定制模块。该系统允许用户无需编码或手动干预即可动态高效地创建和修改工具、代理及工作流程。除了其无代码开发能力外，AutoAgent还作为一个多智能体系统的通用人工智能助手，GAIA基准测试显示，它在通用多智能体任务中超越了现有最佳方法。此外，AutoAgent的Retrieval-Augmented Generation（RAG）相关功能也表现出持续优于其他基于LLM解决方案的性能。 <div>
arXiv:2502.05957v2 Announce Type: replace 
Abstract: Large Language Model (LLM) Agents have demonstrated remarkable capabilities in task automation and intelligent decision-making, driving the widespread adoption of agent development frameworks such as LangChain and AutoGen. However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills. This stark accessibility gap raises a fundamental question: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone? To address this challenge, we introduce AutoAgent-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone. Operating as an autonomous Agent Operating System, AutoAgent comprises four key components: i) Agentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing File System, and iv) Self-Play Agent Customization module. This lightweight yet powerful system enables efficient and dynamic creation and modification of tools, agents, and workflows without coding requirements or manual intervention. Beyond its code-free agent development capabilities, AutoAgent also serves as a versatile multi-agent system for General AI Assistants. Comprehensive evaluations on the GAIA benchmark demonstrate AutoAgent's effectiveness in generalist multi-agent tasks, surpassing existing state-of-the-art methods. Furthermore, AutoAgent's Retrieval-Augmented Generation (RAG)-related capabilities have shown consistently superior performance compared to many alternative LLM-based solutions.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>If Multi-Agent Debate is the Answer, What is the Question?</title>
<link>https://arxiv.org/abs/2502.08788</link>
<guid>https://arxiv.org/abs/2502.08788</guid>
<content:encoded><![CDATA[
<div> 关键词: 多代理辩论(MAD), 语言模型, 评估实践, 基准测试, 模型异质性

总结:
本文针对多代理辩论（MAD）方法在提升大型语言模型事实准确性和推理质量方面的研究进行了深入分析。文章指出现有MAD研究在评价实践中存在局限，如数据集重叠度不足和基线不一致，对其泛化能力提出质疑。通过系统评估五个代表性MAD方法在九个基准测试中的表现，结果发现这些MAD方法并未可靠地超越单一代理基线，例如Chain-of-Thought和Self-Consistency，即使在消耗更多推理时间计算资源的情况下也是如此。作者发现模型异质性可显著改进MAD框架，为此提出了Heter-MAD，允许单个LML代理访问不同类型的基金会模型输出，从而增强现有MAD框架的性能。最后，文中提出了推进MAD发展的潜在方向，旨在引发更广泛的讨论并启发该领域的未来工作。 <div>
arXiv:2502.08788v2 Announce Type: replace 
Abstract: Multi-agent debate (MAD) has emerged as a promising approach to enhance the factual accuracy and reasoning quality of large language models (LLMs) by engaging multiple agents in iterative discussions during inference. Despite its potential, we argue that current MAD research suffers from critical shortcomings in evaluation practices, including limited dataset overlap and inconsistent baselines, raising significant concerns about generalizability. Correspondingly, this paper presents a systematic evaluation of five representative MAD methods across nine benchmarks using four foundational models. Surprisingly, our findings reveal that MAD methods fail to reliably outperform simple single-agent baselines such as Chain-of-Thought and Self-Consistency, even when consuming additional inference-time computation. From our analysis, we found that model heterogeneity can significantly improve MAD frameworks. We propose Heter-MAD enabling a single LLM agent to access the output from heterogeneous foundation models, which boosts the performance of current MAD frameworks. Finally, we outline potential directions for advancing MAD, aiming to spark a broader conversation and inspire future work in this area.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model</title>
<link>https://arxiv.org/abs/2502.08820</link>
<guid>https://arxiv.org/abs/2502.08820</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Language Agents (LAs)，Task-Oriented Dialogue (TOD)，CoALM (Conversational Agentic Language Model)，CoALM-IT

总结:
本文探讨了大型语言模型（LLMs）与具有API调用能力的语言代理（LAs）在任务导向对话（TOD）领域的应用及其面临的挑战。现有的方法在处理新服务接口和维护多轮对话用户意图方面存在困境。为解决这一问题，提出了融合对话与代理功能的统一模型——CoALM（Conversational Agentic Language Model）。通过构建新的多任务数据集CoALM-IT，训练了三个不同规模的CoALM模型，在MultiWOZ 2.4、BFCL V3和API-Bank三个基准测试中均优于特定领域的顶级模型，包括GPT-4o。这证明了一种单一模型可以同时应用于TOD和LA，并为未来对话式智能体设定了新标准。 <div>
arXiv:2502.08820v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) with API-calling capabilities enabled building effective Language Agents (LA), while also revolutionizing the conventional task-oriented dialogue (TOD) paradigm. However, current approaches face a critical dilemma: TOD systems are often trained on a limited set of target APIs, requiring new data to maintain their quality when interfacing with new services, while LAs are not trained to maintain user intent over multi-turn conversations. Because both robust multi-turn management and advanced function calling are crucial for effective conversational agents, we evaluate these skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and API-Bank (LA), and our analyses reveal that specialized approaches excel in one domain but underperform in the other. To bridge this chasm, we introduce CoALM (Conversational Agentic Language Model), a unified approach that integrates both conversational and agentic capabilities. We created CoALM-IT, a carefully constructed multi-task dataset that interleave multi-turn ReAct reasoning with complex API usage. Using CoALM-IT, we train three models CoALM 8B, CoALM 70B, and CoALM 405B, which outperform top domain-specific models, including GPT-4o, across all three benchmarks.This demonstrates the feasibility of a single model approach for both TOD and LA, setting a new standard for conversational agents.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provably Efficient RL under Episode-Wise Safety in Constrained MDPs with Linear Function Approximation</title>
<link>https://arxiv.org/abs/2502.10138</link>
<guid>https://arxiv.org/abs/2502.10138</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 约束马尔科夫决策过程, 函数近似, 线性CMDP, 对抗式强化学习

总结:
本文研究了在约束马尔科夫决策过程中（CMDP）的强化学习问题，该问题要求智能体在探索环境以最大化期望累积奖励的同时，保证每个episode中对预期总效用值的单一约束得以满足。针对函数近似场景下理论成果匮乏的问题，文章提出了一种适用于线性CMDP的RL算法，该算法实现了$\tilde{\mathcal{O}}(\sqrt{K})$的后悔值界，并保证了episode级别上零违规的保障。此外，该方法具有计算效率高、与状态空间大小无关的特点，仅依赖于问题相关的参数呈多项式级增长。这一成果显著优于近期的线性CMDP算法，后者要么违反约束，要么导致指数级别的计算成本。<br /><br /> <div>
arXiv:2502.10138v2 Announce Type: replace 
Abstract: We study the reinforcement learning (RL) problem in a constrained Markov decision process (CMDP), where an agent explores the environment to maximize the expected cumulative reward while satisfying a single constraint on the expected total utility value in every episode. While this problem is well understood in the tabular setting, theoretical results for function approximation remain scarce. This paper closes the gap by proposing an RL algorithm for linear CMDPs that achieves $\tilde{\mathcal{O}}(\sqrt{K})$ regret with an episode-wise zero-violation guarantee. Furthermore, our method is computationally efficient, scaling polynomially with problem-dependent parameters while remaining independent of the state space size. Our results significantly improve upon recent linear CMDP algorithms, which either violate the constraint or incur exponential computational costs.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Incentivizing Information Acquisition</title>
<link>https://arxiv.org/abs/2410.13978</link>
<guid>https://arxiv.org/abs/2410.13978</guid>
<content:encoded><![CDATA[
<div> 关键词：principal-agent模型、信息收集、信号精度、激励机制、简单utoff结构

<br /><br />总结:
本文研究了一个主代理模型，其中主体聘请代理人收集关于未知连续状态的信息。代理人以成本控制信号的精度，其分布围绕着状态。主体无法观察到信号的精度或信号本身，但可以通过依赖于状态的转移支付来激励代理人选择高精度并诚实地报告信号。文章提出了一种关于代理人信息结构的充分且必要的条件，当满足该条件时，存在一个具有简单截止结构的最优转移支付方案：当代理人的预测值与真实状态足够接近时，他会获得固定奖励，否则将得不到任何报酬。这个条件较为宽松，并适用于文献中常见的所有信号分布情况。 <div>
arXiv:2410.13978v3 Announce Type: replace-cross 
Abstract: I study a principal-agent model in which a principal hires an agent to collect information about an unknown continuous state. The agent acquires a signal whose distribution is centered around the state, controlling the signal's precision at a cost. The principal observes neither the precision nor the signal, but rather, using transfers that can depend on the state, incentivizes the agent to choose high precision and report the signal truthfully. I identify a sufficient and necessary condition on the agent's information structure which ensures that there exists an optimal transfer with a simple cutoff structure: the agent receives a fixed prize when his prediction is close enough to the state and receives nothing otherwise. This condition is mild and applies to all signal distributions commonly used in the literature.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Selective Reviews of Bandit Problems in AI via a Statistical View</title>
<link>https://arxiv.org/abs/2412.02251</link>
<guid>https://arxiv.org/abs/2412.02251</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 随机多臂赌台问题, 连续武装赌台问题, 探索-利用权衡, 几何概型不等式

<br /><br />总结:
本文综述了强化学习领域中的重要研究方向——随机多臂赌台问题（MAB）和连续武装赌台问题（SCAB），关注于在不确定性下的序列决策制定。文章探讨了这两种问题的基础模型与假设，以及非渐近性理论工具如集中不等式和最小最大遗憾界限在管理探索-利用权衡中的应用。同时对比分析了频率派和贝叶斯算法。此外，重点介绍了K臂上下文赌台问题和SCAB的方法论及其遗憾分析，并探讨了SCAB问题与函数数据分析之间的联系。最后，指出了该领域的近期进展及面临的挑战。 <div>
arXiv:2412.02251v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) is a widely researched area in artificial intelligence that focuses on teaching agents decision-making through interactions with their environment. A key subset includes stochastic multi-armed bandit (MAB) and continuum-armed bandit (SCAB) problems, which model sequential decision-making under uncertainty. This review outlines the foundational models and assumptions of bandit problems, explores non-asymptotic theoretical tools like concentration inequalities and minimax regret bounds, and compares frequentist and Bayesian algorithms for managing exploration-exploitation trade-offs. Additionally, we explore K-armed contextual bandits and SCAB, focusing on their methodologies and regret analyses. We also examine the connections between SCAB problems and functional data analysis. Finally, we highlight recent advances and ongoing challenges in the field.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large Model Empowered Metaverse: State-of-the-Art, Challenges and Opportunities</title>
<link>https://arxiv.org/abs/2502.10397</link>
<guid>https://arxiv.org/abs/2502.10397</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse、大型模型、用户交互、渲染优化、AI框架

总结:
本文探讨了大型模型如何整合进元宇宙以提升用户体验、感知及内容创建，并针对元宇宙在可扩展性、响应性和动态环境适应性上的挑战提出解决方案。文章提出了一种基于生成式AI的渲染优化框架，该框架包括云边端协同模型来实现低延迟的任务分配，以及一个考虑移动性的预渲染机制，能根据用户移动动态调整。此外，还运用扩散模型为基础的自适应渲染策略，对视觉细节进行精细调整。实验结果显示，这种方法有效地提升了渲染效率并降低了渲染开销，为构建更加响应迅速和沉浸式的元宇宙迈出了重要一步。<br /><br /> <div>
arXiv:2502.10397v1 Announce Type: new 
Abstract: The Metaverse represents a transformative shift beyond traditional mobile Internet, creating an immersive, persistent digital ecosystem where users can interact, socialize, and work within 3D virtual environments. Powered by large models such as ChatGPT and Sora, the Metaverse benefits from precise large-scale real-world modeling, automated multimodal content generation, realistic avatars, and seamless natural language understanding, which enhance user engagement and enable more personalized, intuitive interactions. However, challenges remain, including limited scalability, constrained responsiveness, and low adaptability in dynamic environments. This paper investigates the integration of large models within the Metaverse, examining their roles in enhancing user interaction, perception, content creation, and service quality. To address existing challenges, we propose a generative AI-based framework for optimizing Metaverse rendering. This framework includes a cloud-edge-end collaborative model to allocate rendering tasks with minimal latency, a mobility-aware pre-rendering mechanism that dynamically adjusts to user movement, and a diffusion model-based adaptive rendering strategy to fine-tune visual details. Experimental results demonstrate the effectiveness of our approach in enhancing rendering efficiency and reducing rendering overheads, advancing large model deployment for a more responsive and immersive Metaverse.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FishBargain: An LLM-Empowered Bargaining Agent for Online Fleamarket Platform Sellers</title>
<link>https://arxiv.org/abs/2502.10406</link>
<guid>https://arxiv.org/abs/2502.10406</guid>
<content:encoded><![CDATA[
<div> 关键词：在线跳蚤市场、个体卖家、大型语言模型、讨价还价、FishBargain

总结:
FishBargain是一个基于大型语言模型的在线跳蚤市场讨价还价智能代理，专为缺乏时间和商业技巧的个人卖家设计。与传统电子商务平台（如亚马逊）不同，此类在线跳蚤市场（如Craigslist）主要关注个体卖家的需求。由于个体卖家在讨价还价过程中常常面临困难，导致交易难以达成。文章指出，近期大型语言模型在各种对话任务中展现出巨大潜力，但这些任务大多属于被动跟随用户指令的形式。而讨价还价作为一种主动的对话任务，因其环境动态性和对手策略的不确定性而具有独特性。FishBargain能够理解聊天上下文和产品信息，在考虑到可能的对手行动基础上选择行动和语言策略并生成回复。该系统已在中国最大的在线跳蚤市场平台——闲鱼（Xianyu）上经过数千名个体卖家的实际测试，实验结果表明FishBargain能有效地帮助卖家促成更多交易。 <div>
arXiv:2502.10406v1 Announce Type: new 
Abstract: Different from traditional Business-to-Consumer e-commerce platforms~(e.g., Amazon), online fleamarket platforms~(e.g., Craigslist) mainly focus on individual sellers who are lack of time investment and business proficiency. Individual sellers often struggle with the bargaining process and thus the deal is unaccomplished. Recent advancements in Large Language Models(LLMs) demonstrate huge potential in various dialogue tasks, but those tasks are mainly in the form of passively following user's instruction. Bargaining, as a form of proactive dialogue task, represents a distinct art of dialogue considering the dynamism of environment and uncertainty of adversary strategies. In this paper, we propose an LLM-empowered bargaining agent designed for online fleamarket platform sellers, named as FishBargain. Specifically, FishBargain understands the chat context and product information, chooses both action and language skill considering possible adversary actions and generates utterances. FishBargain has been tested by thousands of individual sellers on one of the largest online fleamarket platforms~(Xianyu) in China. Both qualitative and quantitative experiments demonstrate that FishBargain can effectively help sellers make more deals.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Auto-Evaluation: A Critical Measure in Driving Improvements in Quality and Safety of AI-Generated Lesson Resources</title>
<link>https://arxiv.org/abs/2502.10410</link>
<guid>https://arxiv.org/abs/2502.10410</guid>
<content:encoded><![CDATA[
<div> 关键词: Oak National Academy, Aila, AI-powered lesson planning tool, auto-evaluation agent, lesson quality

总结:
Oak National Academy作为英国一家公共资助机构，利用其由专业教师设计和质量保证的大约13,000份开放教育资源（OER）全面课程，开发了一款名为Aila的免费、高质量的人工智能驱动的课程规划工具。此外，他们还运用基于证据的教学原则，对课程设计的每个组件进行了编码和示例化。为了大规模评估Aila生成的课程质量，他们构建了一个AI自动评价代理。通过与人类评价的比较，不断优化该代理以提高其准确性，使其更符合专家人类评估者的标准。本文通过一个关于多项选择题难度这一质量基准的案例研究，展示了这一迭代评价过程，并探讨了这可能为类似项目及整个教育领域带来的贡献。 <div>
arXiv:2502.10410v1 Announce Type: new 
Abstract: As a publicly funded body in the UK, Oak National Academy is in a unique position to innovate within this field as we have a comprehensive curriculum of approximately 13,000 open education resources (OER) for all National Curriculum subjects, designed and quality-assured by expert, human teachers. This has provided the corpus of content needed for building a high-quality AI-powered lesson planning tool, Aila, that is free to use and, therefore, accessible to all teachers across the country. Furthermore, using our evidence-informed curriculum principles, we have codified and exemplified each component of lesson design. To assess the quality of lessons produced by Aila at scale, we have developed an AI-powered auto-evaluation agent,facilitating informed improvements to enhance output quality. Through comparisons between human and auto-evaluations, we have begun to refine this agent further to increase its accuracy, measured by its alignment with an expert human evaluator. In this paper we present this iterative evaluation process through an illustrative case study focused on one quality benchmark - the level of challenge within multiple-choice quizzes. We also explore the contribution that this may make to similar projects and the wider sector.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Position: Stop Acting Like Language Model Agents Are Normal Agents</title>
<link>https://arxiv.org/abs/2502.10420</link>
<guid>https://arxiv.org/abs/2502.10420</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型代理(LMAs), 大型语言模型(LLMs), 智能体特性, 病态行为, 可信度

总结:
本文提出了一篇立场论文，关注点在于语言模型代理（LMAs）不应被视为正常智能体。文章指出了LMAs基于大型语言模型（LLMs）构建时所固有的问题，如幻觉、越狱、不一致性和不可预测性。LMAs具有无状态性、随机性、语义敏感性和语言中介等内在病态行为特征，这些特征削弱了LMAs的身份可识别性、连续性、持久性和一致性，从而对其作为智能体的属性提出了质疑。因此，作者主张应在LMAs的部署前后及过程中对其本体论性质进行测量，以便减轻这些病态行为带来的负面影响并提高其可靠性和可信度。 <div>
arXiv:2502.10420v1 Announce Type: new 
Abstract: Language Model Agents (LMAs) are increasingly treated as capable of autonomously navigating interactions with humans and tools. Their design and deployment tends to presume they are normal agents capable of sustaining coherent goals, adapting across contexts and acting with a measure of intentionality. These assumptions are critical to prospective use cases in industrial, social and governmental settings. But LMAs are not normal agents. They inherit the structural problems of the large language models (LLMs) around which they are built: hallucinations, jailbreaking, misalignment and unpredictability. In this Position paper we argue LMAs should not be treated as normal agents, because doing so leads to problems that undermine their utility and trustworthiness. We enumerate pathologies of agency intrinsic to LMAs. Despite scaffolding such as external memory and tools, they remain ontologically stateless, stochastic, semantically sensitive, and linguistically intermediated. These pathologies destabilise the ontological properties of LMAs including identifiability, continuity, persistence and and consistency, problematising their claim to agency. In response, we argue LMA ontological properties should be measured before, during and after deployment so that the negative effects of pathologies can be mitigated.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Constraint Violation Signals For Action-Constrained Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.10431</link>
<guid>https://arxiv.org/abs/2502.10431</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、约束满足、投影方法、生成模型、正常化流

总结:
<br />
本文针对强化学习中确保智能体行动符合约束条件的重要性，提出了新的解决方案。首先，为了解决以往基于投影的方法存在的零梯度问题和运行时间长的问题，文章提出定义一个基于约束违反信号的目标分布来训练正则化流模型，从而避免了从受限动作空间生成样本的需求，简化了流模型的学习过程。其次，将所学得的流模型与现有的深度强化学习方法相结合，限制智能体仅在可行的动作空间内进行探索。再次，该方法进一步扩展至处理状态级约束，通过从环境中学习约束违反信号来进行处理。实验证明，与先前最佳方法相比，本文的方法在多个控制任务上显著减少了约束违规次数的同时，还能保持相似或更好的性能。 <div>
arXiv:2502.10431v1 Announce Type: new 
Abstract: In many RL applications, ensuring an agent's actions adhere to constraints is crucial for safety. Most previous methods in Action-Constrained Reinforcement Learning (ACRL) employ a projection layer after the policy network to correct the action. However projection-based methods suffer from issues like the zero gradient problem and higher runtime due to the usage of optimization solvers. Recently methods were proposed to train generative models to learn a differentiable mapping between latent variables and feasible actions to address this issue. However, generative models require training using samples from the constrained action space, which itself is challenging. To address such limitations, first, we define a target distribution for feasible actions based on constraint violation signals, and train normalizing flows by minimizing the KL divergence between an approximated distribution over feasible actions and the target. This eliminates the need to generate feasible action samples, greatly simplifying the flow model learning. Second, we integrate the learned flow model with existing deep RL methods, which restrict it to exploring only the feasible action space. Third, we extend our approach beyond ACRL to handle state-wise constraints by learning the constraint violation signal from the environment. Empirically, our approach has significantly fewer constraint violations while achieving similar or better quality in several control tasks than previous best methods.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Diverse Transformer Decoding for Offline Reinforcement Learning Using Financial Algorithmic Approaches</title>
<link>https://arxiv.org/abs/2502.10473</link>
<guid>https://arxiv.org/abs/2502.10473</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线强化学习、离线强化学习、Transformer、波束搜索、投资组合波束搜索<br /><br />总结:

本文探讨了离线强化学习(Offline Reinforcement Learning, RL)中Transformer模型和波束搜索(Beam Search, BS)的应用。针对BS在处理离线RL数据不确定性及探索性不足的问题，文章提出了一种新的解码方法——投资组合波束搜索(Portfolio Beam Search, PBS)。PBS借鉴金融经济学原理，实现了一个不确定度量下的多样化策略，能够在推理阶段的序列解码过程中平衡探索与利用。实验证实在D4RL运动任务基准上，PBS实现了更高的回报并显著降低了结果的变异性。 <div>
arXiv:2502.10473v1 Announce Type: new 
Abstract: Offline Reinforcement Learning (RL) algorithms learn a policy using a fixed training dataset, which is then deployed online to interact with the environment and make decisions. Transformers, a standard choice for modeling time-series data, are gaining popularity in offline RL. In this context, Beam Search (BS), an approximate inference algorithm, is the go-to decoding method. Offline RL eliminates the need for costly or risky online data collection. However, the restricted dataset induces uncertainty as the agent may encounter unfamiliar sequences of states and actions during execution that were not covered in the training data. In this context, BS lacks two important properties essential for offline RL: It does not account for the aforementioned uncertainty, and its greedy left-right search approach often results in sequences with minimal variations, failing to explore potentially better alternatives.
  To address these limitations, we propose Portfolio Beam Search (PBS), a simple-yet-effective alternative to BS that balances exploration and exploitation within a Transformer model during decoding. We draw inspiration from financial economics and apply these principles to develop an uncertainty-aware diversification mechanism, which we integrate into a sequential decoding algorithm at inference time. We empirically demonstrate the effectiveness of PBS on the D4RL locomotion benchmark, where it achieves higher returns and significantly reduces outcome variability.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Objective Planning with Contextual Lexicographic Reward Preferences</title>
<link>https://arxiv.org/abs/2502.10476</link>
<guid>https://arxiv.org/abs/2502.10476</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主代理、多目标规划、环境上下文、层次化决策过程、贝叶斯方法

总结:<br />
本文提出了一种名为上下文层级马尔科夫决策过程（CLMDP）的新框架，用于解决自主代理在不同环境中根据上下文变化而具有多种目标优先级排序的问题。CLMDP中，状态的目标优先级顺序及其关联的奖励函数由当前上下文决定。文章采用贝叶斯方法从专家轨迹中推断状态-上下文映射。为了解决CLMDP问题，算法首先针对每个目标优先级顺序计算策略，然后将这些策略结合成一个单一的上下文感知的、有效且无循环的综合策略。该方法的有效性通过仿真和移动机器人的实验进行了验证。 <div>
arXiv:2502.10476v1 Announce Type: new 
Abstract: Autonomous agents are often required to plan under multiple objectives whose preference ordering varies based on context. The agent may encounter multiple contexts during its course of operation, each imposing a distinct lexicographic ordering over the objectives, with potentially different reward functions associated with each context. Existing approaches to multi-objective planning typically consider a single preference ordering over the objectives, across the state space, and do not support planning under multiple objective orderings within an environment. We present Contextual Lexicographic Markov Decision Process (CLMDP), a framework that enables planning under varying lexicographic objective orderings, depending on the context. In a CLMDP, both the objective ordering at a state and the associated reward functions are determined by the context. We employ a Bayesian approach to infer a state-context mapping from expert trajectories. Our algorithm to solve a CLMDP first computes a policy for each objective ordering and then combines them into a single context-aware policy that is valid and cycle-free. The effectiveness of the proposed approach is evaluated in simulation and using a mobile robot.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safe Multi-agent Satellite Servicing with Control Barrier Functions</title>
<link>https://arxiv.org/abs/2502.10480</link>
<guid>https://arxiv.org/abs/2502.10480</guid>
<content:encoded><![CDATA[
<div> 关键词：控制 Barrier 函数，不确定姿态信息，多小型服务代理人，卫星服务应用，差分碰撞检测和避免框架

总结:
<br />
本文分析了在卫星服务应用中，使用控制Barrier函数处理具有不确定姿态信息的多个小型服务代理人的协同避碰问题。该应用情境涉及从母船部署的模块化服务代理人对一颗翻滚的空间物体进行操作。每个代理人的相对位置和方向信息通过相对范围和惯性测量传感器的融合获取。文章利用控制Barrier函数确保同时重新定位的服务代理人能够避开翻滚物体发生碰撞。此外，采用基于翻滚空间物体多面体包络的差分碰撞检测和避免框架来安全地引导代理人远离翻滚物体。 <div>
arXiv:2502.10480v1 Announce Type: new 
Abstract: The use of control barrier functions under uncertain pose information of multiple small servicing agents is analyzed for a satellite servicing application. The application consists of modular servicing agents deployed towards a tumbling space object from a mothership. Relative position and orientation of each agent is obtained via fusion of relative range and inertial measurement sensors. The control barrier functions are utilized to avoid collisions with other agents for the application of simultaneously relocating servicing agents on a tumbling body. A differential collision detection and avoidance framework using the polytopic hull of the tumbling space object is utilized to safely guide the agents away from the tumbling object.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comprehensive Hyperledger Fabric Performance Evaluation based on Resources Capacity Planning</title>
<link>https://arxiv.org/abs/2502.10509</link>
<guid>https://arxiv.org/abs/2502.10509</guid>
<content:encoded><![CDATA[
<div> 关键词：Hyperledger Fabric、性能模型、Stochastic Petri Net、区块链参数、交易速率

<br /><br />总结：
本文针对Hyperledger Fabric这一许可型区块链平台，提出了一种使用Stochastic Petri Net建模的方法，用于分析不同区块链参数、计算机能力和交易速率对系统性能的影响。文中还通过一系列案例研究验证了该模型的可行性。该模型为区块链网络管理员提供了一个实用工具，帮助他们为应用程序找到最佳性能配置。研究发现，块大小的改变会随着到达率的变化导致较高的平均响应时间（范围从1到25秒）。 <div>
arXiv:2502.10509v1 Announce Type: new 
Abstract: Hyperledger Fabric is a platform for permissioned blockchain networks that enables secure and auditable distributed data storage for enterprise applications. There is a growing interest in applications based on this platform, but its use requires the configuration of different blockchain parameters. Various configurations impact the system's non-functional qualities, especially performance and cost. In this article, we propose a Stochastic Petri Net to model the performance of the Hyperledger Fabric platform with different blockchain parameters, computer capacity, and transaction rates. We also present a set of case studies to demonstrate the feasibility of the proposed model. This model serves as a practical guide to help administrators of permissioned blockchain networks find the best performance for their applications. The proposed model allowed us to identify the block size that leads to a high mean response time (ranging from 1 to 25 seconds) caused by a change in the arrival rate.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Application Provisioning over Ethereum based private and permissioned Blockchain: Availability modeling, capacity, and costs planning</title>
<link>https://arxiv.org/abs/2502.10515</link>
<guid>https://arxiv.org/abs/2502.10515</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain, 云计算, 分布式计算, 可用性, 容量导向型可用性

总结:<br />
本文探讨了区块链和云计算这两大分布式计算领域的热点话题。随着云计算在过去十年中成为分布式应用程序和服务开发与交付的主要机制，大型数据中心托管着众多服务并存储着海量用户数据。而区块链技术的发展为用户提供了一种更安全、公开的数据管理方式，支持在不同信任关系的组织或个人之间共享信息和服务，并实现基础设施管理任务。文章提出了评估云计算基础设施可用性和容量导向型可用性的模型，并针对基于以太坊区块链平台的分布式应用进行了实验，分析了在公共和私人基础设施上运行这些应用所需的费用。文中得出的大多数结论也可应用于其他基于区块链的平台。 <div>
arXiv:2502.10515v1 Announce Type: new 
Abstract: Blockchain and Cloud Computing are two of the main topics related to the distributed computing paradigm, and in the last decade, they have seen exponential growth in their adoption. Cloud computing has long been established as the main mechanism to test, develop, and deliver new applications and services in a distributed manner across the World Wide Web. Large data centers host many services and store petabytes of user data. Infrastructure and services owners rule the access to data and may even be able to change contents and attest to its veracity. Blockchain is a step towards a future where the user's data are considered safer, besides being public. Advances in blockchain-based technologies, now, support service provisioning over permissioned and private infrastructures. Therefore, organizations or groups of individuals may share information, service even if they do not trust each other, besides supporting infrastructure management tasks. This paper presents and evaluates models for assessing the availability and capacity-oriented availability of cloud computing infrastructures. It aims at running Blockchain's distributed applications based on the Ethereum blockchain platform and the required expenses to perform service delivery in public and private infrastructures. Most of the obtained results also apply to other blockchains based platforms.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A new lower bound for multi-color discrepancy with applications to fair division</title>
<link>https://arxiv.org/abs/2502.10516</link>
<guid>https://arxiv.org/abs/2502.10516</guid>
<content:encoded><![CDATA[
<div> 关键词: 颜色分配、低差异性、多色差异下界、公平分配、共识1/k分割

<br /><br />总结:
该文主要研究了组合数学中的颜色分配问题，提出了一个新的多色差异下界的lower bound，即对于含有n个子集的集合系统，任何一种k色彩的元素着色方式的差异度至少为Ω(√(n/lnk))，这一结果优于先前已知的Ω(√(n/k))下界。文章进一步探讨了这一结果在公平分配概念中的影响，指出当有n个代理人对不可分物品具有估值时，实现共识1/k分割至多d件物品（\cd$d$）可能在d∈Ω(√(n/lnk))时变得不可行。此外，通过扩展证明技术，文中还证明了存在一些实例，使得将物品分配给k组共n个代理人的过程中，实现最多d件物品的envy-freeness和比例性在d∈Ω(√(n/(klnk)))和d∈Ω(√(n/(k^3lnk)))时分别变得不可行。这些关于公平分配的下界改进了Manurangsi和Suksompong在2022年所给出的最佳已知结果。 <div>
arXiv:2502.10516v1 Announce Type: new 
Abstract: A classical problem in combinatorics seeks colorings of low discrepancy. More concretely, the goal is to color the elements of a set system so that the number of appearances of any color among the elements in each set is as balanced as possible. We present a new lower bound for multi-color discrepancy, showing that there is a set system with $n$ subsets over a set of elements in which any $k$-coloring of the elements has discrepancy at least $\Omega\left(\sqrt{\frac{n}{\ln{k}}}\right)$. This result improves the previously best-known lower bound of $\Omega\left(\sqrt{\frac{n}{k}}\right)$ of Doerr and Srivastav [2003] and may have several applications. Here, we explore its implications on the feasibility of fair division concepts for instances with $n$ agents having valuations for a set of indivisible items. The first such concept is known as consensus $1/k$-division up to $d$ items (\cd$d$) and aims to allocate the items into $k$ bundles so that no matter which bundle each agent is assigned to, the allocation is envy-free up to $d$ items. The above lower bound implies that \cd$d$ can be infeasible for $d\in \Omega\left(\sqrt{\frac{n}{\ln{k}}}\right)$. We furthermore extend our proof technique to show that there exist instances of the problem of allocating indivisible items to $k$ groups of $n$ agents in total so that envy-freeness and proportionality up to $d$ items are infeasible for $d\in \Omega\left(\sqrt{\frac{n}{k\ln{k}}}\right)$ and $d\in \Omega\left(\sqrt{\frac{n}{k^3\ln{k}}}\right)$, respectively. The lower bounds for fair division improve the currently best-known ones by Manurangsi and Suksompong [2022].
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Memory, Benchmark &amp; Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.10550</link>
<guid>https://arxiv.org/abs/2502.10550</guid>
<content:encoded><![CDATA[
<div> 关键词: 记忆、强化学习、基准测试、机器人操作、MIKASA

总结:
本文介绍了针对记忆强化学习的研究现状，指出缺乏通用基准测试的问题，特别是在桌面机器人操作领域。为解决这一问题，文章提出了MIKASA（Memory-Intensive Skills Assessment Suite for Agents），它有三个主要贡献：(1) 提出了一种全面的记忆密集型强化学习任务分类框架；(2) 创建了MIKASA-Base，这是一个统一的基准测试平台，用于系统评估具有记忆增强功能的智能体在多样化场景下的性能；(3) 开发了MIKASA-Robo，包含32项精心设计的记忆密集型机器人操作任务，以评估记忆能力。这些贡献确立了一个推动记忆强化学习研究发展的统一框架，旨在促进更可靠的实际应用系统的开发。相关代码可在https://sites.google.com/view/memorybenchrobots/获取。 <div>
arXiv:2502.10550v1 Announce Type: new 
Abstract: Memory is crucial for enabling agents to tackle complex tasks with temporal and spatial dependencies. While many reinforcement learning (RL) algorithms incorporate memory, the field lacks a universal benchmark to assess an agent's memory capabilities across diverse scenarios. This gap is particularly evident in tabletop robotic manipulation, where memory is essential for solving tasks with partial observability and ensuring robust performance, yet no standardized benchmarks exist. To address this, we introduce MIKASA (Memory-Intensive Skills Assessment Suite for Agents), a comprehensive benchmark for memory RL, with three key contributions: (1) we propose a comprehensive classification framework for memory-intensive RL tasks, (2) we collect MIKASA-Base - a unified benchmark that enables systematic evaluation of memory-enhanced agents across diverse scenarios, and (3) we develop MIKASA-Robo - a novel benchmark of 32 carefully designed memory-intensive tasks that assess memory capabilities in tabletop robotic manipulation. Our contributions establish a unified framework for advancing memory RL research, driving the development of more reliable systems for real-world applications. The code is available at https://sites.google.com/view/memorybenchrobots/.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can Large Language Model Agents Balance Energy Systems?</title>
<link>https://arxiv.org/abs/2502.10557</link>
<guid>https://arxiv.org/abs/2502.10557</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 随机单位投入计划 (SUC), 效率, 可靠性, 风电不确定性

<br /><br />总结:

本文提出了一种集成大型语言模型（LLMs）与多场景随机单位投入计划（SUC）框架的混合方法，专注于在高风电发电不确定性条件下提高效率和可靠性。数值实验显示，对于小到中型测试系统，传统SUC方法的成本为99.05百万美元，带有3.04 GWh的负荷削减，而LLM辅助的SUC（LLM-SUC）将成本降低至98.87百万美元并将负荷削减减少到2.32 GWh，降低了约24%。两种方法均保持零风电削减，证实了对可再生能源的有效整合。通过使用帮助更好地平衡能源系统的LLM代理，该提出的框架能够以更低的成本增强需求满足，展示了AI在不确定运行条件下的发电机投入决策中的潜力。未来可以通过优化提示设计、结合历史操作数据以及将这种方法扩展到更高维度的不确定性和储能系统中，从而实现进一步的收益，最终促进下一代电力系统操作的更大韧性和适应性。 <div>
arXiv:2502.10557v1 Announce Type: new 
Abstract: This paper presents a hybrid approach that integrates Large Language Models (LLMs) with a multi-scenario Stochastic Unit Commitment (SUC) framework, focusing on both efficiency and reliability under high wind generation uncertainties. Numerical experiments on small-to-medium-sized test systems show that while the traditional SUC approach yields a total cost of 99.05 million USD with 3.04 GWh of load curtailment, the LLM-assisted SUC (LLM-SUC) reduces costs to 98.87 million USD and lowers load curtailment to 2.32 GWh, an improvement of nearly 24%. Both methods maintain zero wind curtailment, confirming robust renewable integration. By employing an LLM agent that helps balance the energy system more effectively, the proposed framework enhances demand fulfillment at reduced costs, illustrating the potential of AI to inform generator commitments in uncertain operating conditions. Further gains may be realized by refining prompt design, incorporating historical operational data, and extending this approach to higher-dimensional uncertainties and energy storage systems, ultimately fostering greater resilience, efficiency, and adaptability in next-generation power system operations.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Observer-Aware Probabilistic Planning Under Partial Observability</title>
<link>https://arxiv.org/abs/2502.10568</link>
<guid>https://arxiv.org/abs/2502.10568</guid>
<content:encoded><![CDATA[
<div> 关键词：观察者意识马尔科夫决策过程（OAMDPs）、部分可观测性、策略优化、动态隐藏变量、可预测性、可读性、HSVI收敛行为

<br /><br />总结:
本文关注一类规划问题，其中智能体意识到存在一个处于部分可观测状态的观察者。文章基于观察者意识马尔科夫决策过程（OAMDPs）提出了一种框架，用于处理此类问题并形式化了如可读性、可解释性和可预测性等属性。该框架将OAMDP扩展到部分可观测性情况，不仅能够应对更现实的问题，而且允许考虑具有动态隐藏目标变量的情况，例如涉及可预测性或执行过程中目标可能发生改变的可读性问题。文章讨论了PO-OAMDPs的理论性质，并通过基准问题实验分析了HSVI算法在专用初始化条件下的收敛行为以及产生的策略。 <div>
arXiv:2502.10568v1 Announce Type: new 
Abstract: In this article, we are interested in planning problems where the agent is aware of the presence of an observer, and where this observer is in a partial observability situation. The agent has to choose its strategy so as to optimize the information transmitted by observations. Building on observer-aware Markov decision processes (OAMDPs), we propose a framework to handle this type of problems and thus formalize properties such as legibility, explicability and predictability. This extension of OAMDPs to partial observability can not only handle more realistic problems, but also permits considering dynamic hidden variables of interest. These dynamic target variables allow, for instance, working with predictability, or with legibility problems where the goal might change during execution. We discuss theoretical properties of PO-OAMDPs and, experimenting with benchmark problems, we analyze HSVI's convergence behavior with dedicated initializations and study the resulting strategies.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning-Driven Cybersecurity Framework for IoT Networks with Privacy-Preserving and Real-Time Threat Detection Capabilities</title>
<link>https://arxiv.org/abs/2502.10599</link>
<guid>https://arxiv.org/abs/2502.10599</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网(IoT)，联邦学习(Federated Learning)，网络安全(Cybersecurity)，循环神经网络(RNNs)，资源效率(Resource Efficiency)

<br /><br />总结:
本文提出了一种针对物联网环境的联邦学习驱动的网络安全框架，旨在解决传统集中式安全方法在隐私保护和实时威胁检测之间的平衡问题。该框架利用边缘设备本地进行模型训练，保证数据隐私，并通过同态加密实现安全的模型聚合与协同学习。在异常检测方面，采用了优化后的循环神经网络，实验结果显示系统能有效识别包括分布式拒绝服务攻击在内的复杂网络安全威胁，准确率超过98%，同时相较于集中式方法，能源效率提高了20%。该研究整合了联邦学习与高级威胁检测技术，为物联网应用提供了可扩展、注重隐私保护的解决方案。未来的工作将探索结合区块链技术和量子抗性加密方法，以进一步增强在不断演进的技术环境中框架的安全性。 <div>
arXiv:2502.10599v1 Announce Type: new 
Abstract: The rapid expansion of the Internet of Things (IoT) ecosystem has transformed various sectors but has also introduced significant cybersecurity challenges. Traditional centralized security methods often struggle to balance privacy preservation and real-time threat detection in IoT networks. To address these issues, this study proposes a Federated Learning-Driven Cybersecurity Framework designed specifically for IoT environments. The framework enables decentralized data processing by training models locally on edge devices, ensuring data privacy. Secure aggregation of these locally trained models is achieved using homomorphic encryption, allowing collaborative learning without exposing sensitive information.
  The proposed framework utilizes recurrent neural networks (RNNs) for anomaly detection, optimized for resource-constrained IoT networks. Experimental results demonstrate that the system effectively detects complex cyber threats, including distributed denial-of-service (DDoS) attacks, with over 98% accuracy. Additionally, it improves energy efficiency by reducing resource consumption by 20% compared to centralized approaches.
  This research addresses critical gaps in IoT cybersecurity by integrating federated learning with advanced threat detection techniques. The framework offers a scalable and privacy-preserving solution adaptable to various IoT applications. Future work will explore the integration of blockchain for transparent model aggregation and quantum-resistant cryptographic methods to further enhance security in evolving technological landscapes.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reachability-Aware Reinforcement Learning for Collision Avoidance in Human-Machine Shared Control</title>
<link>https://arxiv.org/abs/2502.10610</link>
<guid>https://arxiv.org/abs/2502.10610</guid>
<content:encoded><![CDATA[
<div> 关键词：人机共享控制、碰撞避免、可达性分析、强化学习、驾驶安全

总结:<br />
本文提出了一种基于可达性分析的人机共享控制框架，用于在关键碰撞场景中辅助驾驶员避免事故。该方法通过哈密顿-雅可比（HJ）可达性分析计算车辆的碰撞避免可达集（CARS），仅在车辆接近无法避免碰撞的状态时激活机器干预。首先，文章利用离线数据预计算了可达性分布和CARS。为减少人机冲突，研究者开发了一个针对突然障碍物的驾驶员模型，并提出了考虑关键避碰特征的权限分配策略。接着，通过训练强化学习代理，旨在降低人机冲突的同时确保不进入CARS这一硬性约束。实验证实在真实车辆平台上，该控制器能够在靠近CARS时有效介入以防止碰撞，并保持较好的原驾驶任务性能。此外，鲁棒性分析证明了其对于不同驾驶员属性的适应性。 <div>
arXiv:2502.10610v1 Announce Type: new 
Abstract: Human-machine shared control in critical collision scenarios aims to aid drivers' accident avoidance through intervening only when necessary. Existing methods count on replanning collision-free trajectories and imposing human-machine tracking, which usually interrupts the driver's intent and increases the risk of conflict. Additionally, the lack of guaranteed trajectory feasibility under extreme conditions can compromise safety and reliability. This paper introduces a Reachability-Aware Reinforcement Learning framework for shared control, guided by Hamilton-Jacobi (HJ) reachability analysis. Machine intervention is activated only when the vehicle approaches the Collision Avoidance Reachable Set (CARS), which represents states where collision is unavoidable. First, we precompute the reachability distributions and the CARS by solving the Bellman equation using offline data. To reduce human-machine conflicts, we develop a driver model for sudden obstacles and propose an authority allocation strategy considering key collision avoidance features. Finally, we train a reinforcement learning agent to reduce human-machine conflicts while enforcing the hard constraint of avoiding entry into the CARS. The proposed method was tested on a real vehicle platform. Results show that the controller intervenes effectively near CARS to prevent collisions while maintaining improved original driving task performance. Robustness analysis further supports its flexibility across different driver attributes.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proof of Response</title>
<link>https://arxiv.org/abs/2502.10637</link>
<guid>https://arxiv.org/abs/2502.10637</guid>
<content:encoded><![CDATA[
<div> 关键词：网络、参与者、Alice、Bob、响应证明、预定时间、支付机制、分布式存储、分布式AI代理

<br /><br />总结:
本文介绍了一种机制，该机制应用于网络中的参与者之间，允许其中一方（Alice）向另一方（Bob）请求数据。这一机制能在预设的、确定的时间b内保证Alice能收到Bob的响应，或者在b时间内提供至少一条通往Bob的路径中断的证明，又或者在超过b时间后，Alice会持续获得与延迟时间成比例的流式支付。此机制为构建需要可验证响应的下游应用提供了支持，例如分布式存储解决方案和分布式AI代理等应用场景。 <div>
arXiv:2502.10637v1 Announce Type: new 
Abstract: We present a mechanism that for a network of participants allows one participant of the network (Alice) to request some data from another participant (Bob) and either receive a response from Bob within a known-in-advance, bounded time b, or receive a proof that at least one edge on the way to Bob was broken within b, or receive a streaming payment proportional to time passed beyond b during which neither was received. This mechanism allows for building downstream applications that require provable responses from other participants, such as decentralized storage solutions, decentralized AI agents, and more.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoPEFT: Fast Adaptation Framework for Multi-Agent Collaborative Perception with Parameter-Efficient Fine-Tuning</title>
<link>https://arxiv.org/abs/2502.10705</link>
<guid>https://arxiv.org/abs/2502.10705</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协同感知、训练数据、场景适应性、轻量级框架、CoPEFT

总结:
本文提出了一种轻量级框架CoPEFT，用于解决多智能体协同感知模型在新部署环境中适应性不足的问题。该问题源于训练数据覆盖不全导致模型对不同交通场景的鲁棒性较差。现有的域适应方法虽有所缓解，但训练成本高，不适合资源受限的智能体。CoPEFT通过协作适配器和代理提示两部分进行宏观和微观层面的适应，利用训练数据和少量部署数据调整特征映射以适应新的数据分布，并通过插入细粒度环境上下文信息进一步增强协作适配器的效果。实验表明，CoPEFT在训练参数少于1%的情况下超越了现有方法，证明了其有效性和效率。 <div>
arXiv:2502.10705v1 Announce Type: new 
Abstract: Multi-agent collaborative perception is expected to significantly improve perception performance by overcoming the limitations of single-agent perception through exchanging complementary information. However, training a robust collaborative perception model requires collecting sufficient training data that covers all possible collaboration scenarios, which is impractical due to intolerable deployment costs. Hence, the trained model is not robust against new traffic scenarios with inconsistent data distribution and fundamentally restricts its real-world applicability. Further, existing methods, such as domain adaptation, have mitigated this issue by exposing the deployment data during the training stage but incur a high training cost, which is infeasible for resource-constrained agents. In this paper, we propose a Parameter-Efficient Fine-Tuning-based lightweight framework, CoPEFT, for fast adapting a trained collaborative perception model to new deployment environments under low-cost conditions. CoPEFT develops a Collaboration Adapter and Agent Prompt to perform macro-level and micro-level adaptations separately. Specifically, the Collaboration Adapter utilizes the inherent knowledge from training data and limited deployment data to adapt the feature map to new data distribution. The Agent Prompt further enhances the Collaboration Adapter by inserting fine-grained contextual information about the environment. Extensive experiments demonstrate that our CoPEFT surpasses existing methods with less than 1\% trainable parameters, proving the effectiveness and efficiency of our proposed method.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated AI Entities</title>
<link>https://arxiv.org/abs/2502.10750</link>
<guid>https://arxiv.org/abs/2502.10750</guid>
<content:encoded><![CDATA[
<div> 关键词：社区检测、元宇宙、人工智能社交网络、CUSA框架、生成合成策略

总结:<br />
本文针对人工智能与人类交织而成的人工智能社交网络（HASNs）中的新型社区检测问题——MetaCD进行了研究。该问题旨在强化社区内部的人类连接并减少AI节点的存在。为解决这一问题，文章提出了CUSA创新框架，该框架采用AI感知聚类技术，通过选择性地保留有助于维持社区结构的AI节点来平衡排除AI节点和保持社区结构之间的微妙权衡。鉴于现实世界的HASNs数据稀缺，文章还设计了四种策略用于在不同假设场景下合成此类网络。通过对转换为HASNs的真实社交网络进行实证评估，显示了相较于传统非深度学习及图神经网络（GNN）方法，其方法的有效性和实用性。 <div>
arXiv:2502.10750v1 Announce Type: new 
Abstract: Community detection is a cornerstone problem in social network analysis (SNA), aimed at identifying cohesive communities with minimal external links. However, the rise of generative AI and Metaverse introduce complexities by creating hybrid human-AI social networks (denoted by HASNs), where traditional methods fall short, especially in human-centric settings. This paper introduces a novel community detection problem in HASNs (denoted by MetaCD), which seeks to enhance human connectivity within communities while reducing the presence of AI nodes. Effective processing of MetaCD poses challenges due to the delicate trade-off between excluding certain AI nodes and maintaining community structure. To address this, we propose CUSA, an innovative framework incorporating AI-aware clustering techniques that navigate this trade-off by selectively retaining AI nodes that contribute to community integrity. Furthermore, given the scarcity of real-world HASNs, we devise four strategies for synthesizing these networks under various hypothetical scenarios. Empirical evaluations on real social networks, reconfigured as HASNs, demonstrate the effectiveness and practicality of our approach compared to traditional non-deep learning and graph neural network (GNN)-based methods.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning to Explain Air Traffic Situation</title>
<link>https://arxiv.org/abs/2502.10764</link>
<guid>https://arxiv.org/abs/2502.10764</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、空管、注意力机制、Transformer模型、航空交通态势理解

<br /><br />总结：
本文提出了一种基于机器学习的框架，旨在解释复杂的空中交通情况。该框架采用Transformer基的多智能体轨迹模型，综合考虑了飞机的空间时间运动和它们之间的社会交互。通过从模型中获取注意力分数，可以量化单架飞机对整体交通动态的影响，从而提供有关空管员如何感知和理解交通状况的可解释性见解。该模型是在韩国仁川国际机场周边终端空域的真实世界航空交通监控数据上进行训练的，有效地揭示了空中交通状况，有望支持并增强空管员的决策制定和态势感知能力。 <div>
arXiv:2502.10764v1 Announce Type: new 
Abstract: Understanding how air traffic controllers construct a mental 'picture' of complex air traffic situations is crucial but remains a challenge due to the inherently intricate, high-dimensional interactions between aircraft, pilots, and controllers. Previous work on modeling the strategies of air traffic controllers and their mental image of traffic situations often centers on specific air traffic control tasks or pairwise interactions between aircraft, neglecting to capture the comprehensive dynamics of an air traffic situation. To address this issue, we propose a machine learning-based framework for explaining air traffic situations. Specifically, we employ a Transformer-based multi-agent trajectory model that encapsulates both the spatio-temporal movement of aircraft and social interaction between them. By deriving attention scores from the model, we can quantify the influence of individual aircraft on overall traffic dynamics. This provides explainable insights into how air traffic controllers perceive and understand the traffic situation. Trained on real-world air traffic surveillance data collected from the terminal airspace around Incheon International Airport in South Korea, our framework effectively explicates air traffic situations. This could potentially support and enhance the decision-making and situational awareness of air traffic controllers.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Resource Allocation and Pricing for Blockchain-enabled Metaverse: A Stackelberg Game Approach</title>
<link>https://arxiv.org/abs/2502.10765</link>
<guid>https://arxiv.org/abs/2502.10765</guid>
<content:encoded><![CDATA[
<div> 关键词: 元宇宙、区块链技术、资源分配、定价策略、Stackelberg博弈

总结:
本文探讨了元宇宙作为下一代互联网范式的挑战，重点关注资源分配、定价和交易安全问题。为解决这些问题，文章提出将区块链技术融入元宇宙，以实现更有效和安全的复杂交互管理与自动化。研究中，元宇宙服务用户（MSUs）从元宇宙服务提供商（MSP）购买渲染和带宽资源以获取低延迟、高质量的沉浸式服务，而MSP通过控制资源单位价格最大化利润。作者将MSP与MSUs之间的互动建模为Stackelberg博弈，并数学分析证明了Stackelberg均衡的存在性。此外，他们提出了一个高效的贪婪搜索资源分配和定价算法（GSRAP），用于求解Stackelberg均衡点。最后，通过大量仿真验证了设计方案的有效性和效率，实验结果显示该算法在提高MSP利润和收敛速度方面优于基线方案。 <div>
arXiv:2502.10765v1 Announce Type: new 
Abstract: As the next-generation Internet paradigm, the metaverse can provide users with immersive physical-virtual experiences without spatial limitations. However, there are various concerns to be overcome, such as resource allocation, resource pricing, and transaction security issues. To address the above challenges, we integrate blockchain technology into the metaverse to manage and automate complex interactions effectively and securely utilizing the advantages of blockchain. With the objective of promoting the Quality of Experience (QoE), Metaverse Service Users (MSUs) purchase rendering and bandwidth resources from the Metaverse Service Provider (MSP) to access low-latency and high-quality immersive services. The MSP maximizes the profit by controlling the unit prices of resources. In this paper, we model the interaction between the MSP and MSUs as a Stackelberg game, in which the MSP acts as the leader and MSUs are followers. The existence of Stackelberg equilibrium is analyzed and proved mathematically. Besides, we propose an efficient greedy-and-search-based resource allocation and pricing algorithm (GSRAP) to solve the Stackelberg equilibrium (SE) point. Finally, we conduct extensive simulations to verify the effectiveness and efficiency of our designs. The experiment results show that our algorithm outperforms the baseline scheme in terms of improving the MSP's profit and convergence speed.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Cloud-Native Agentic Protocol Learning for Conflict-Free 6G: A Case Study on Inter-Slice Resource Allocation</title>
<link>https://arxiv.org/abs/2502.10775</link>
<guid>https://arxiv.org/abs/2502.10775</guid>
<content:encoded><![CDATA[
<div> 关键词：云原生、网络切片、智能代理、资源管理、通信协议

<br />
总结:

我们提出了一种新的云原生架构用于协作式智能网络切片。该架构着重解决多网络切片共享基础设施，特别是CPU资源的管理问题，满足不同类型的异构需求。每个网络切片由一个运行于Docker环境中的专用智能代理进行控制，保证了隔离性和可扩展性。智能代理根据实时流量动态调整CPU分配，优化整个系统的性能。本文的关键创新在于开发出了智能代理间的自组织通信机制，使它们能够自主建立通信协议，更有效地协调资源分配以应对动态流量变化。实验表明，该方案能有效处理如eMBB、URLLC和mMTC等多样化的流量类型，通过调整资源分配以满足各切片的严格要求。此外，该云原生设计还利用Prometheus和Grafana实现了对系统的实时监控与分析，确保其在动态网络环境中具备适应性和效率。智能代理成功地学会了如何最大限度地利用共享基础设施，并将冲突率保持在3%以下。 <div>
arXiv:2502.10775v1 Announce Type: new 
Abstract: In this paper, we propose a novel cloud-native architecture for collaborative agentic network slicing. Our approach addresses the challenge of managing shared infrastructure, particularly CPU resources, across multiple network slices with heterogeneous requirements. Each network slice is controlled by a dedicated agent operating within a Dockerized environment, ensuring isolation and scalability. The agents dynamically adjust CPU allocations based on real-time traffic demands, optimizing the performance of the overall system. A key innovation of this work is the development of emergent communication among the agents. Through their interactions, the agents autonomously establish a communication protocol that enables them to coordinate more effectively, optimizing resource allocations in response to dynamic traffic demands. Based on synthetic traffic modeled on real-world conditions, accounting for varying load patterns, tests demonstrated the effectiveness of the proposed architecture in handling diverse traffic types, including eMBB, URLLC, and mMTC, by adjusting resource allocations to meet the strict requirements of each slice. Additionally, the cloud-native design enables real-time monitoring and analysis through Prometheus and Grafana, ensuring the system's adaptability and efficiency in dynamic network environments. The agents managed to learn how to maximize the shared infrastructure with a conflict rate of less than 3%.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>REGNav: Room Expert Guided Image-Goal Navigation</title>
<link>https://arxiv.org/abs/2502.10785</link>
<guid>https://arxiv.org/abs/2502.10785</guid>
<content:encoded><![CDATA[
<div> 关键词: 图像目标导航、房间专家引导、图像相似性、无监督学习、融合方法

总结:<br />
本文提出了一种新的图像目标导航模型——房间专家引导图像目标导航（REGNav），旨在使智能体具备分析目标图和观测图是否在同一房间的能力。该模型受到人类行为启发，通过无监督学习方法预先训练一个房间专家，用于提取隐藏的房间风格信息并预测两张图片是否属于同一房间。之后，文章探讨了两种不同的融合方法，以有效地利用房间关系知识指导智能体进行导航。实验表明，REGNav在三个主流基准测试上均超越了先前的最优方法。 <div>
arXiv:2502.10785v1 Announce Type: new 
Abstract: Image-goal navigation aims to steer an agent towards the goal location specified by an image. Most prior methods tackle this task by learning a navigation policy, which extracts visual features of goal and observation images, compares their similarity and predicts actions. However, if the agent is in a different room from the goal image, it's extremely challenging to identify their similarity and infer the likely goal location, which may result in the agent wandering around. Intuitively, when humans carry out this task, they may roughly compare the current observation with the goal image, having an approximate concept of whether they are in the same room before executing the actions. Inspired by this intuition, we try to imitate human behaviour and propose a Room Expert Guided Image-Goal Navigation model (REGNav) to equip the agent with the ability to analyze whether goal and observation images are taken in the same room. Specifically, we first pre-train a room expert with an unsupervised learning technique on the self-collected unlabelled room images. The expert can extract the hidden room style information of goal and observation images and predict their relationship about whether they belong to the same room. In addition, two different fusion approaches are explored to efficiently guide the agent navigation with the room relation knowledge. Extensive experiments show that our REGNav surpasses prior state-of-the-art works on three popular benchmarks.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Be Friendly, Not Friends: How LLM Sycophancy Shapes User Trust</title>
<link>https://arxiv.org/abs/2502.10844</link>
<guid>https://arxiv.org/abs/2502.10844</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLM)，奉承行为，用户信任，友好度，人工智能说服

<br /><br />总结:
本文首次探讨了大型语言模型（LLM）中的奉承行为与其友好的交互方式如何影响用户信任。研究通过一个2x2双因素实验（存在与不存在奉承行为 x 高与低友好度），发现当LLM表现出友好态度时，奉承会降低用户的感知真实性，从而减少用户信任；相反，若其表现得不太友好，顺应用户观点则会被视为更真诚，进而提高用户信任。这些发现揭示了利用人类心理倾向进行AI说服的可能性以及在设计用户与LLM交互时负责任的重要性。 <div>
arXiv:2502.10844v1 Announce Type: new 
Abstract: Recent studies have revealed that large language model (LLM)-powered conversational agents often exhibit `sycophancy', a tendency to adapt their responses to align with user perspectives, even at the expense of factual accuracy. However, users' perceptions of LLM sycophancy and its interplay with other anthropomorphic features (e.g., friendliness) in shaping user trust remains understudied. To bridge this gap, we conducted a 2 (Sycophancy: presence vs. absence) $\times$ 2 (Friendliness: high vs. low) between-subjects experiment ($N = 224$). Our study uncovered, for the first time, the intricate dynamics between LLM sycophancy and friendliness: When an LLM agent already exhibits a friendly demeanor, being sycophantic reduces perceived authenticity, thereby lowering user trust; Conversely, when the agent is less friendly, aligning its responses with user opinions makes it appear more genuine, leading to higher user trust. \add{Our findings entail profound implications for AI persuasion through exploiting human psychological tendencies and highlight the imperative for responsible designs in user-LLM agent interactions.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Divergent Thoughts toward One Goal: LLM-based Multi-Agent Collaboration System for Electronic Design Automation</title>
<link>https://arxiv.org/abs/2502.10857</link>
<guid>https://arxiv.org/abs/2502.10857</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，电子设计自动化 (EDA)，EDA工具接口，多智能体协作系统，ChipLlama模型

总结:
随着大型语言模型（LLMs）具备了调用工具的能力，它们在通过EDA脚本与EDA工具API交互以实现EDA流程自动化方面展现出巨大潜力。然而，由于对EDA工具理解有限以及不同平台间EDA工具接口的多样性，实际应用中存在挑战。此外，复杂的多步骤工具调用流程容易导致中间环节出现错误，进而引发EDA流程自动化的不稳定和失败。为此，文章提出了名为EDAid的多智能体协作系统，其中每个代理由专为EDA流程自动化微调的ChipLlama模型控制。实验结果证明了ChipLlama模型的最新最优性能以及EDAid在复杂EDA流程自动化中的有效性，其表现优于单智能体系统。 <div>
arXiv:2502.10857v1 Announce Type: new 
Abstract: Recently, with the development of tool-calling capabilities in large language models (LLMs), these models have demonstrated significant potential for automating electronic design automation (EDA) flows by interacting with EDA tool APIs via EDA scripts. However, considering the limited understanding of EDA tools, LLMs face challenges in practical scenarios where diverse interfaces of EDA tools exist across different platforms. Additionally, EDA flow automation often involves intricate, long-chain tool-calling processes, increasing the likelihood of errors in intermediate steps. Any errors will lead to the instability and failure of EDA flow automation. To address these challenges, we introduce EDAid, a multi-agent collaboration system where multiple agents harboring divergent thoughts converge towards a common goal, ensuring reliable and successful EDA flow automation. Specifically, each agent is controlled by ChipLlama models, which are expert LLMs fine-tuned for EDA flow automation. Our experiments demonstrate the state-of-the-art (SOTA) performance of our ChipLlama models and validate the effectiveness of our EDAid in the automation of complex EDA flows, showcasing superior performance compared to single-agent systems.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Nonlinear Feedback Linearization and LQG/LTR Control: A Comparative Study for a Single-Machine Infinite-Bus System</title>
<link>https://arxiv.org/abs/2502.10889</link>
<guid>https://arxiv.org/abs/2502.10889</guid>
<content:encoded><![CDATA[
<div> 关键词：非线性反馈线性化控制器(NFLC)，积分-NFLC(INFLC)，线性-二次-高斯/环路传输恢复(LQG/LTR)控制，单机无穷大系统(SMIB)，电力系统控制

总结:

本文对比研究了应用于单机无穷大系统(SMIB)的三种先进控制策略：非线性反馈线性化控制器(NFLC)、积分-NFLC(INFLC)以及线性-二次-高斯/环路传输恢复(LQG/LTR)控制。NFLC和INFLC利用精确反馈线性化技术消除SMIB系统的非线性特性，实现对发电机和调速器子系统的去耦线性和最优控制，同时不受内部动态和运行条件的影响。而LQG/LTR方法采用改进的卡尔曼滤波器，通过LTR过程和详细的频域环路整形分析，在SMIB系统中实现了性能优化、噪声/干扰抑制、鲁棒性恢复和稳定性裕度之间的合理权衡。文章提供了一个基于高保真度物理模型验证、简化控制设计模型及两者控制输入相关性的实用、可验证、可扩展和健壮的线性与非线性控制器的设计框架。通过对提出的控制器进行严格的仿真比较以及与全状态线性二次调节器的对比分析，展示了各控制器在不同工况下的瞬态响应、稳态误差、鲁棒性、转子角稳定性、频率控制和电压调节等方面的优缺点和权衡。该研究旨在为大规模电力系统选择合适的控制策略提供指导，从而提高电力电网的整体韧性和可靠性。 <div>
arXiv:2502.10889v1 Announce Type: new 
Abstract: This paper presents a comparative study of three advanced control strategies for a single-machine infinite-bus (SMIB) system: the nonlinear feedback linearizing controller (NFLC), the integral-NFLC (INFLC), and the linear-quadratic-Gaussian/loop transfer recovery (LQG/LTR) control. The NFLC and INFLC techniques use exact feedback linearization to precisely cancel the SMIB system nonlinearities, enabling the use of decentralized, linear, and optimal controllers for the decoupled generator and turbine-governor systems while remaining unaffected by the SMIB system's internal dynamics and operating conditions. In contrast, the LQG/LTR approach employs an enhanced Kalman filter, designed using the LTR procedure and a detailed frequency-domain loop-shaping analysis, to achieve a reasonable trade-off between optimal performance, noise/disturbance rejection, robustness recovery, and stability margins for the SMIB system. We provide a control synthesis framework for constructing practical, verifiable, scalable, and resilient linear and nonlinear controllers for SMIB and multi-machine power systems by utilizing a high-fidelity plant model for validation, a reduced-order control-design model, and the correlations between the two models' control inputs. Rigorous simulations and comparative analysis of the proposed controllers and a full-state linear-quadratic regulator show the benefits, constraints, and trade-offs of each controller in terms of transient response, steady-state error, robustness, rotor angle stability, frequency control, and voltage regulation under different operating conditions. Ultimately, this study aims to guide the selection of appropriate control strategies for large-scale power systems, enhancing the overall resilience and reliability of the electric grid.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PCGRLLM: Large Language Model-Driven Reward Design for Procedural Content Generation Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.10906</link>
<guid>https://arxiv.org/abs/2502.10906</guid>
<content:encoded><![CDATA[
<div> 关键词: reward design, large language models, PCGRLLM, reinforcement learning, game AI

总结:
本文介绍了PCGRLLM，一种基于前期工作的扩展架构，它使用反馈机制和多种推理式提示工程技巧来生成强化学习代理的奖励函数。研究集中在利用两个最先进的大型语言模型在二维环境中对故事到奖励生成任务进行评估，展示该方法的普适性。实验结果显示，这种方法显著提高了性能，提升幅度分别达到415%和40%，具体取决于语言模型的零样本能力。文章表明，利用大型语言模型可以减少游戏AI开发中的人力依赖，并支持与增强创新过程。 <div>
arXiv:2502.10906v1 Announce Type: new 
Abstract: Reward design plays a pivotal role in the training of game AIs, requiring substantial domain-specific knowledge and human effort. In recent years, several studies have explored reward generation for training game agents and controlling robots using large language models (LLMs). In the content generation literature, there has been early work on generating reward functions for reinforcement learning agent generators. This work introduces PCGRLLM, an extended architecture based on earlier work, which employs a feedback mechanism and several reasoning-based prompt engineering techniques. We evaluate the proposed method on a story-to-reward generation task in a two-dimensional environment using two state-of-the-art LLMs, demonstrating the generalizability of our approach. Our experiments provide insightful evaluations that demonstrate the capabilities of LLMs essential for content generation tasks. The results highlight significant performance improvements of 415% and 40% respectively, depending on the zero-shot capabilities of the language model. Our work demonstrates the potential to reduce human dependency in game AI development, while supporting and enhancing creative processes.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Conversational Agents from Open-Source Large Language Models with Illocutionary Force and Document-Based Knowledge Retrieval</title>
<link>https://arxiv.org/abs/2502.10916</link>
<guid>https://arxiv.org/abs/2502.10916</guid>
<content:encoded><![CDATA[
<div> 关键词: Bert-based Large Language Models、illocutionary forces、Argument Interchange Format (AIF) Dataset、large language models (LLMs)、perplexity

总结:<br />
本文提出了一种新的利用Bert基大型语言模型计算分析和提取对话中 Illocutionary Forces 的方法，并展示了这些特征如何影响由基于文档知识库引导的对话代理系统的响应。该技术首次使用 Argument Interchange Format (AIF) 数据集进行 illocutionary force 提取与分类任务，并相较于两种相似任务的方法取得了约 45% 的宏观 F1 值提升。通过评估针对两个知识文件、每个文件带有两个用户查询条件下，五个开源大型语言模型（LLMs）的表现，研究发现包含用户 Illocutionary Forces 的查询能更好地引导如 Llama2:13b 和 Llama3-chatqa-latest 这样的大型模型，使其展现出更高的 QA 准确性和语言相似度得分。然而，像 Tinyllama:latest 这样的小型模型在处理包含 Illocutionary Forces 的查询时表现出增加的困惑度和混合性能，表明需要针对模型特定优化以解决计算成本和响应时间增加的问题。研究表明，Illocutionary Forces 有潜力增强对话深度，但也强调了针对不同模型进行优化的重要性。 <div>
arXiv:2502.10916v1 Announce Type: new 
Abstract: In this paper, we first present a novel way of computationally analysing and extracting illocutionary forces from dialogue using Bert-based Large Language Models, and demonstrate how these features impact the response of a conversational agent guided by a document-based knowledge bank demonstrated by a bespoke web conversational chat agent system developed. Our proposed illocutionary force extraction and classification technique is the first of its kind using the Argument Interchange Format (AIF) Dataset, showing an improved performance compared to two methods for carrying out similar tasks with a macro F1 of approximately 45%. When we evaluated the system based on 2 knowledge files, with 2 user queries each, across 5 open-source large language models (LLMs) using 10 standard metrics we found out that larger open-source models, such as Llama2:13b and Llama3-chatqa-latest, demonstrated an improved alignment when the user illocutionary force was included with their query, achieving higher QA and linguistic similarity scores. The smaller models on the other hand like Tinyllama:latest showed an increased perplexity and mixed performance, which explicitly indicated struggles in processing queries that explicitly included illocutionary forces. The results from the analysis highlight the potential of illocutionary force to enhance conversational depth while underscoring the need for model-specific optimizations to address increased computational costs and response times.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>"AI Afterlives" as Digital Legacy: Perceptions, Expectations, and Concerns</title>
<link>https://arxiv.org/abs/2502.10924</link>
<guid>https://arxiv.org/abs/2502.10924</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能、数字遗产、AI生成代理、用户感知、设计启示

总结:<br />
本文探讨了人们对于使用人工智能技术创建的AI生成代理（被称为“AI后生命”）作为数字遗产的观点、期望和顾虑。研究采用定性方法分析了用户对这类新型数字遗产的态度、与传统数字遗产的区别以及实际应用中的关注点。此外，文章还审视了“AI后生命”在其生命周期和交互过程中的设计要素。基于这些发现，文章将“AI后生命”置于数字遗产的背景下，并深入探讨了在保持身份一致性与平衡侵入性和支持性方面所面临的设 计启示。 <div>
arXiv:2502.10924v1 Announce Type: new 
Abstract: The rise of generative AI technology has sparked interest in using digital information to create AI-generated agents as digital legacy. These agents, often referred to as "AI Afterlives", present unique challenges compared to traditional digital legacy. Yet, there is limited human-centered research on "AI Afterlife" as digital legacy, especially from the perspectives of the individuals being represented by these agents. This paper presents a qualitative study examining users' perceptions, expectations, and concerns regarding AI-generated agents as digital legacy. We identify factors shaping people's attitudes, their perceived differences compared with the traditional digital legacy, and concerns they might have in real practices. We also examine the design aspects throughout the life cycle and interaction process. Based on these findings, we situate "AI Afterlife" in digital legacy, and delve into design implications for maintaining identity consistency and balancing intrusiveness and support in "AI Afterlife" as digital legacy.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>D-CIPHER: Dynamic Collaborative Intelligent Agents with Planning and Heterogeneous Execution for Enhanced Reasoning in Offensive Security</title>
<link>https://arxiv.org/abs/2502.10931</link>
<guid>https://arxiv.org/abs/2502.10931</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Capture The Flag (CTF)挑战，D-CIPHER框架，多智能体系统，Auto-prompter代理

总结:
本文介绍了D-CIPHER，这是一个用于协同解决网络安全Capture The Flag (CTF)挑战的多智能体大型语言模型（LLMs）框架。该框架受到现实中团队合作解决CTF问题的启发，采用了一个由规划者和执行者组成的多角色代理系统，其中规划者负责整体问题解决，而多个异构执行者处理特定任务，同时引入了自动提示器代理以生成高度相关的初始提示来改进问题解决过程。通过对多个LLM模型在CTF基准测试上的评估，D-CIPHER在NYU CTF Bench、Cybench和HackTheBox三个基准上分别实现了22.0%、22.5%和44.0%的性能提升，从而设定了新的最优性能记录。研究结果表明，D-CIPHER多智能体系统的解决问题能力有了显著提高。该项目已在GitHub上开源发布。 <div>
arXiv:2502.10931v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have been used in cybersecurity in many ways, including their recent use as intelligent agent systems for autonomous security analysis. Capture the Flag (CTF) challenges serve as benchmarks for assessing the automated task-planning abilities of LLM agents across various cybersecurity skill sets. Early attempts to apply LLMs for solving CTF challenges relied on single-agent systems, where feedback was restricted to a single reasoning-action loop. This approach proved inadequate for handling complex CTF tasks. Drawing inspiration from real-world CTF competitions, where teams of experts collaborate, we introduce the D-CIPHER multi-agent LLM framework for collaborative CTF challenge solving. D-CIPHER integrates agents with distinct roles, enabling dynamic feedback loops to enhance reasoning on CTF challenges. It introduces the Planner-Executor agent system, consisting of a Planner agent for overall problem-solving along with multiple heterogeneous Executor agents for individual tasks, facilitating efficient allocation of responsibilities among the LLMs. Additionally, D-CIPHER incorporates an Auto-prompter agent, which improves problem-solving by exploring the challenge environment and generating a highly relevant initial prompt. We evaluate D-CIPHER on CTF benchmarks using multiple LLM models and conduct comprehensive studies to highlight the impact of our enhancements. Our results demonstrate that the multi-agent D-CIPHER system achieves a significant improvement in challenges solved, setting a state-of-the-art performance on three benchmarks: 22.0% on NYU CTF Bench, 22.5% on Cybench, and 44.0% on HackTheBox. D-CIPHER is available at https://github.com/NYU-LLM-CTF/nyuctf_agents as the nyuctf_multiagent package.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention</title>
<link>https://arxiv.org/abs/2502.10937</link>
<guid>https://arxiv.org/abs/2502.10937</guid>
<content:encoded><![CDATA[
<div> 关键词：内容分析、多智能体框架、大规模语言模型、模拟、社会科学研究

<br />
总结:
本文介绍了一个名为SCALE的新颖多智能体框架，该框架通过利用大规模语言模型有效地模拟了社会科学研究中的复杂文本内容分析过程。SCALE能够模仿内容分析的关键阶段，包括文本编码、协作讨论和动态代码书演进，同时捕捉到人类研究人员的反思深度和适应性讨论。此外，SCALE还整合了多种模式的人类干预，结合专家输入以进一步提升其性能。经过在真实世界数据集上的广泛评估，SCALE在各种复杂的_content_分析任务中达到了接近人类水平的表现，为未来社会科学研究提供了创新潜力。 <div>
arXiv:2502.10937v1 Announce Type: new 
Abstract: Content analysis breaks down complex and unstructured texts into theory-informed numerical categories. Particularly, in social science, this process usually relies on multiple rounds of manual annotation, domain expert discussion, and rule-based refinement. In this paper, we introduce SCALE, a novel multi-agent framework that effectively $\underline{\textbf{S}}$imulates $\underline{\textbf{C}}$ontent $\underline{\textbf{A}}$nalysis via $\underline{\textbf{L}}$arge language model (LLM) ag$\underline{\textbf{E}}$nts. SCALE imitates key phases of content analysis, including text coding, collaborative discussion, and dynamic codebook evolution, capturing the reflective depth and adaptive discussions of human researchers. Furthermore, by integrating diverse modes of human intervention, SCALE is augmented with expert input to further enhance its performance. Extensive evaluations on real-world datasets demonstrate that SCALE achieves human-approximated performance across various complex content analysis tasks, offering an innovative potential for future social science research.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic LLM Framework for Adaptive Decision Discourse</title>
<link>https://arxiv.org/abs/2502.10978</link>
<guid>https://arxiv.org/abs/2502.10978</guid>
<content:encoded><![CDATA[
<div> 关键词: 复杂系统、决策制定、大型语言模型（LLMs）、多利益相关者、适应性机制

<br /><br />总结:
本文提出了一种基于真实世界的代理型大型语言模型（LLMs）框架，用于模拟和提升复杂系统中的决策讨论过程。该框架注重对话、权衡探索以及不同角色代理人之间的互动产生的协同效应，这些代理人代表了具有独特优先级、专业知识和价值驱动推理的多元利益相关者。通过适应性和自我治理机制，代理人能动态调用额外专家资源并调整自身组合以应对不断演变的挑战。文章以中西部城镇极端洪水为例，展示了该框架如何在不确定性环境下平衡各方利益，提出兼顾社会、经济和环境维度的缓解与适应策略。研究表明，这种广度优先的方案探索方式有利于生成稳健且公正的推荐路径。该框架为高风险场景下的决策制定提供新的方法，并为实现可扩展和情境感知的人工智能驱动建议奠定了基础，其应用前景广泛，尤其在涉及不确定性和复杂性的领域。 <div>
arXiv:2502.10978v1 Announce Type: new 
Abstract: Effective decision-making in complex systems requires synthesizing diverse perspectives to address multifaceted challenges under uncertainty. This study introduces a real-world inspired agentic Large Language Models (LLMs) framework, to simulate and enhance decision discourse-the deliberative process through which actionable strategies are collaboratively developed. Unlike traditional decision-support tools, the framework emphasizes dialogue, trade-off exploration, and the emergent synergies generated by interactions among agents embodying distinct personas. These personas simulate diverse stakeholder roles, each bringing unique priorities, expertise, and value-driven reasoning to the table. The framework incorporates adaptive and self-governing mechanisms, enabling agents to dynamically summon additional expertise and refine their assembly to address evolving challenges. An illustrative hypothetical example focused on extreme flooding in a Midwestern township demonstrates the framework's ability to navigate uncertainty, balance competing priorities, and propose mitigation and adaptation strategies by considering social, economic, and environmental dimensions. Results reveal how the breadth-first exploration of alternatives fosters robust and equitable recommendation pathways. This framework transforms how decisions are approached in high-stakes scenarios and can be incorporated in digital environments. It not only augments decision-makers' capacity to tackle complexity but also sets a foundation for scalable and context-aware AI-driven recommendations. This research explores novel and alternate routes leveraging agentic LLMs for adaptive, collaborative, and equitable recommendation processes, with implications across domains where uncertainty and complexity converge.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FeaKM: Robust Collaborative Perception under Noisy Pose Conditions</title>
<link>https://arxiv.org/abs/2502.11003</link>
<guid>https://arxiv.org/abs/2502.11003</guid>
<content:encoded><![CDATA[
<div> 关键词：协作感知、定位不准确、FeaKM、特征级关键点匹配、DAIR-V2X数据集

总结:
本文提出了一种针对网络中具有有限感知能力的智能体间的协作感知问题的新方法——FeaKM。该方法旨在解决因定位不准确导致的空间信息错位问题，通过特征级关键点匹配有效地校正协同智能体之间的姿态差异。FeaKM首先利用自信心地图从中间特征表示中识别并提取显著点，计算其描述符，从而确保系统能关注到最相关的信息，提升匹配过程的效果。接着，实施目标匹配策略生成关联矩阵，建立起不同智能体所识别的关键点间的准确对应关系。随后，应用细粒度变换矩阵同步所有智能体的特征，确定它们的相对状态，保证了它们之间通信的一致性。实验结果表明，FeaKM在DAIR-V2X数据集上显著优于现有方法，即使在严重的噪声条件下仍表现出强大的鲁棒性。代码和实现细节可在https://github.com/uestchjw/FeaKM获取。 <div>
arXiv:2502.11003v1 Announce Type: new 
Abstract: Collaborative perception is essential for networks of agents with limited sensing capabilities, enabling them to work together by exchanging information to achieve a robust and comprehensive understanding of their environment. However, localization inaccuracies often lead to significant spatial message displacement, which undermines the effectiveness of these collaborative efforts. To tackle this challenge, we introduce FeaKM, a novel method that employs Feature-level Keypoints Matching to effectively correct pose discrepancies among collaborating agents. Our approach begins by utilizing a confidence map to identify and extract salient points from intermediate feature representations, allowing for the computation of their descriptors. This step ensures that the system can focus on the most relevant information, enhancing the matching process. We then implement a target-matching strategy that generates an assignment matrix, correlating the keypoints identified by different agents. This is critical for establishing accurate correspondences, which are essential for effective collaboration. Finally, we employ a fine-grained transformation matrix to synchronize the features of all agents and ascertain their relative statuses, ensuring coherent communication among them. Our experimental results demonstrate that FeaKM significantly outperforms existing methods on the DAIR-V2X dataset, confirming its robustness even under severe noise conditions. The code and implementation details are available at https://github.com/uestchjw/FeaKM.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Streamlining the Collaborative Chain of Models into A Single Forward Pass in Generation-Based Tasks</title>
<link>https://arxiv.org/abs/2502.11083</link>
<guid>https://arxiv.org/abs/2502.11083</guid>
<content:encoded><![CDATA[
<div> 关键词: Retrieval-Augmented Generation, Chain of Models, Prompt Tuning, Hidden States Sharing, FTHSS

总结:
本文提出了FTHSS，一种新型的prompt-tuning方法，用于解决Retrieval-Augmented Generation和基于代理的框架中“模型链”方法存在的资源消耗问题。传统方法需要每个模型独立部署，而prompt tuning可通过微调共享基模odel实现多任务适应，但仍然存在中间输出作为纯文本传递时需要重新计算隐藏状态（如Transformer中的Key-Value状态）的问题。FTHSS通过训练期间修改输入和注意力掩码，使模型能够在单轮或多轮场景下有效地利用前一模型的KV隐藏状态，从而避免了冗余的前向传播并减少了KV缓存存储的需求。实验证明，FTHSS在保持与传统模型链相当性能的同时，显著提高了推理效率。 <div>
arXiv:2502.11083v1 Announce Type: new 
Abstract: In Retrieval-Augmented Generation (RAG) and agent-based frameworks, the "Chain of Models" approach is widely used, where multiple specialized models work sequentially on distinct sub-tasks. This approach is effective but increases resource demands as each model must be deployed separately. Recent advancements attempt to address this by applying prompt tuning, which allows a shared base model to adapt to multiple tasks with minimal parameter changes. However, a key challenge remains: intermediate outputs, passed between models as plain text, require recomputation of hidden states (i.e., Key and Value (KV) states in Transformers) during inference. In this paper, we introduce FTHSS, a novel prompt-tuning method that enables models to share KV hidden states, eliminating redundant forward passes and reducing KV cache storage. By modifying input and attention masks during training, FTHSS allows models to effectively utilize KV hidden states from prior models in both single- and multi-round scenarios. Empirical results on four tasks show that FTHSS matches the performance of traditional model chains while improving inference efficiency.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.11098</link>
<guid>https://arxiv.org/abs/2502.11098</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM-MA系统、TalkHier、通信协议、层次化细化系统、性能提升

总结:
本文提出了一种名为“TalkStructurally, Act Hierarchically (TalkHier)”的新框架，旨在解决基于大语言模型的多智能体（LLM-MA）系统在复杂任务协作中的通信管理和细化问题。该框架引入了结构化的通信协议以实现丰富的上下文交换和层次化的细化系统，从而解决了错误输出、虚假信息和偏见等问题。实验结果显示，TalkHier 在开放域问答、领域特定选择性提问及实际广告文本生成等多元任务上超越了当前的一流模型，包括推理扩展模型（如OpenAI-o1）、开源多智能体模型（如AgentVerse）以及基于单一智能体基线（如ReAct, GPT4o）的多数投票策略。这一成果表明TalkHier有可能为LLM-MA系统设定新的标准，并推动更加高效、适应性和协同性的多智能体框架的发展。相关代码已在https://github.com/sony/talkhier发布。 <div>
arXiv:2502.11098v1 Announce Type: new 
Abstract: Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown promise, yet significant challenges remain in managing communication and refinement when agents collaborate on complex tasks. In this paper, we propose \textit{Talk Structurally, Act Hierarchically (TalkHier)}, a novel framework that introduces a structured communication protocol for context-rich exchanges and a hierarchical refinement system to address issues such as incorrect outputs, falsehoods, and biases. \textit{TalkHier} surpasses various types of SoTA, including inference scaling model (OpenAI-o1), open-source multi-agent models (e.g., AgentVerse), and majority voting strategies on current LLM and single-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including open-domain question answering, domain-specific selective questioning, and practical advertisement text generation. These results highlight its potential to set a new standard for LLM-MA systems, paving the way for more effective, adaptable, and collaborative multi-agent frameworks. The code is available https://github.com/sony/talkhier.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat Elite AI in TextStarCraft II for the First Time</title>
<link>https://arxiv.org/abs/2502.11122</link>
<guid>https://arxiv.org/abs/2502.11122</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)，Hierarchical Expert Prompt (HEP)，decision-making，StarCraft II，open-source

<br /><br />总结:
本文提出了一种用于处理复杂决策任务的方法——层次专家提示（HEP），该方法针对大型语言模型（LLM）在处理如StarCraft II环境中的复杂任务时面临的知识缺乏和对不同重要性子任务控制不足的问题。通过引入专家级战术知识以及层次化框架，HEP提高了LLM对游戏情境的理解和任务处理质量。实验结果显示，这种方法首次使LLM在TextStarCraft II中击败了最高级别（Elite）内置代理，并在其他难度下持续优于基线方法。相关视频可在 bilibili 和 YouTube 观看，代码已在GitHub上开源。 <div>
arXiv:2502.11122v1 Announce Type: new 
Abstract: Since the emergence of the Large Language Model (LLM), LLM has been widely used in fields such as writing, translating, and searching. However, there is still great potential for LLM-based methods in handling complex tasks such as decision-making in the StarCraft II environment. To address problems such as lack of relevant knowledge and poor control over subtasks of varying importance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method improves the understanding of game situations through expert-level tactical knowledge, improving the processing quality of tasks of varying importance through a hierarchical framework. Our approach defeated the highest level (Elite) standard built-in agent in TextStarCraft II for the first time and consistently outperformed the baseline method in other difficulties. Our experiments suggest that the proposed method is a practical solution for tackling complex decision-making challenges. The replay video can be viewed on https://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M, and our codes have been open-sourced on https://github.com/luchang1113/HEP-LLM-play-StarCraftII.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems</title>
<link>https://arxiv.org/abs/2502.11127</link>
<guid>https://arxiv.org/abs/2502.11127</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)，Multi-agent Systems (MAS)，G-Safeguard，图神经网络，安全防护

<br /><br />总结:
本文介绍了一种针对基于大型语言模型（LLM）的多智能体系统（MAS）的安全防护方法——G-Safeguard。该方法利用图神经网络对多智能体对话图中的异常行为进行检测，并通过拓扑干预实现攻击缓解。实验表明，G-Safeguard在应对各种攻击策略时表现出显著的有效性，能够恢复超过40%的性能损失（针对prompt注入攻击）。同时，它具有高度适应不同LLM后端和大规模MAS的能力，并能与主流MAS无缝结合，保证系统的安全性。相关代码已开源，可在https://github.com/wslong20/G-safeguard 获取。 <div>
arXiv:2502.11127v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstrated remarkable capabilities in various complex tasks, ranging from collaborative problem-solving to autonomous decision-making. However, as these systems become increasingly integrated into critical applications, their vulnerability to adversarial attacks, misinformation propagation, and unintended behaviors have raised significant concerns. To address this challenge, we introduce G-Safeguard, a topology-guided security lens and treatment for robust LLM-MAS, which leverages graph neural networks to detect anomalies on the multi-agent utterance graph and employ topological intervention for attack remediation. Extensive experiments demonstrate that G-Safeguard: (I) exhibits significant effectiveness under various attack strategies, recovering over 40% of the performance for prompt injection; (II) is highly adaptable to diverse LLM backbones and large-scale MAS; (III) can seamlessly combine with mainstream MAS with security guarantees. The code is available at https://github.com/wslong20/G-safeguard.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MasRouter: Learning to Route LLMs for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.11133</link>
<guid>https://arxiv.org/abs/2502.11133</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Systems (MAS)，Large Language Models (LLMs)，Multi-Agent System Routing (MASR)，MasRouter，性能优化

<br /><br />总结：
本文提出了一种针对多智能体系统(MAS)中由大型语言模型(LLLs)驱动的问题——多智能体系统路由(MASR)。为解决动态LLM选择和协作模式决策的挑战，研究者们首次将MAS的所有组件整合进统一的路由框架，并提出了高性能、低成本和可诱导的MASR解决方案——MasRouter。MasRouter通过级联控制器网络实现协作模式确定、角色分配及LLM路由，以平衡系统的有效性和效率。实验结果显示，MasRouter相比于现有最优方法在MBPP任务上性能提高了1.8%-8.2%，在HumanEval任务上减少了最高达52.07%的开销，并能无缝集成到主流MAS框架中，通过定制化路由进一步降低17.21%-28.17%的开销。相关代码已开源，可在https://github.com/yanweiyue/masrouter获取。 <div>
arXiv:2502.11133v1 Announce Type: new 
Abstract: Multi-agent systems (MAS) powered by Large Language Models (LLMs) have been demonstrated to push the boundaries of LLM capabilities, yet they often incur significant costs and face challenges in dynamic LLM selection. Current LLM routing methods effectively reduce overhead in single-agent scenarios by customizing LLM selection for each query, but they overlook the critical decisions regarding collaboration modes and agent roles in MAS. In response to this challenge, we first introduce the problem of Multi-Agent System Routing (MASR), which integrates all components of MAS into a unified routing framework. Toward this goal, we propose MasRouter, the first high-performing, cost-effective, and inductive MASR solution. MasRouter employs collaboration mode determination, role allocation, and LLM routing through a cascaded controller network, progressively constructing a MAS that balances effectiveness and efficiency. Extensive experiments demonstrate that MasRouter is (1) high-performing, achieving a $1.8\%\sim8.2\%$ improvement over the state-of-the-art method on MBPP; (2) economical, reducing overhead by up to $52.07\%$ compared to SOTA methods on HumanEval; and (3) plug-and-play, seamlessly integrating with mainstream MAS frameworks, reducing overhead by $17.21\%\sim28.17\%$ via customized routing. The code is available at https://github.com/yanweiyue/masrouter.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM</title>
<link>https://arxiv.org/abs/2502.11142</link>
<guid>https://arxiv.org/abs/2502.11142</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-and-Language Navigation (VLN)，数据标注，导航模型，NavRAG，检索增强生成（RAG），3D场景理解，用户需求指令，全局上下文，任务规划<br /><br />总结: 本文提出了一个名为NavRAG的新型检索增强生成框架，用于解决视觉与语言导航(VLN)领域中因大量训练数据需求而面临的高成本问题。现有的方法通过将轨迹视频转化为步骤指令来扩展数据，但这种方法生成的指令可能不符合用户简洁描述目的地或特定需求的习惯。NavRAG利用大型语言模型构建从全局布局到局部细节的3D场景层次描述树，并模拟各种用户角色及其具体需求，从场景树中检索信息并生成多样化的自然语言指令。文章还介绍了针对861个场景标注的超过200万条导航指令的数据集，并评估了使用该数据集训练的模型的导航性能和数据质量。 <div>
arXiv:2502.11142v1 Announce Type: new 
Abstract: Vision-and-Language Navigation (VLN) is an essential skill for embodied agents, allowing them to navigate in 3D environments following natural language instructions. High-performance navigation models require a large amount of training data, the high cost of manually annotating data has seriously hindered this field. Therefore, some previous methods translate trajectory videos into step-by-step instructions for expanding data, but such instructions do not match well with users' communication styles that briefly describe destinations or state specific needs. Moreover, local navigation trajectories overlook global context and high-level task planning. To address these issues, we propose NavRAG, a retrieval-augmented generation (RAG) framework that generates user demand instructions for VLN. NavRAG leverages LLM to build a hierarchical scene description tree for 3D scene understanding from global layout to local details, then simulates various user roles with specific demands to retrieve from the scene tree, generating diverse instructions with LLM. We annotate over 2 million navigation instructions across 861 scenes and evaluate the data quality and navigation performance of trained models.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Power of Randomization for Obviously Strategy-Proof Mechanisms</title>
<link>https://arxiv.org/abs/2502.11148</link>
<guid>https://arxiv.org/abs/2502.11148</guid>
<content:encoded><![CDATA[
<div> 关键词：随机化明显策略proof机制、多物品拍卖、单件需求、单一思维、福利优化

总结:<br />
本文研究了设计随机化明显策略proof（OSP）机制在多个经典的拍卖场景中的问题。OSP机制是对传统优势策略兼容性（DSIC）概念的强化，确保即使是在条件推理方面有困难的代理人也能认识到其主导策略是最优的。针对Ron在2024年SODA会议上提出的确定性OSP机制无法在多项式数量级物品与竞标者的情况下实现优于$\min\{m,n\}$的逼近比的不可能性结果，本文展示了在单元需求、加性和单一思维竞标者的环境中，随机化的全局OSP机制可以取得这些类别的常数因子逼近。然而，文章同时也指出，即使是随机化的OSP机制，在最优福利方面也无法超过87.5%，这表明OSP机制相较于优势策略机制有着显著的弱化。 <div>
arXiv:2502.11148v1 Announce Type: new 
Abstract: We investigate the problem of designing randomized obviously strategy-proof (OSP) mechanisms in several canonical auction settings. Obvious strategy-proofness, introduced by Li [American Economic Review, 2017], strengthens the well-known concept of dominant-strategy incentive compatibility (DSIC). Loosely speaking, it ensures that even agents who struggle with contingent reasoning can identify that their dominant strategy is optimal.
  Thus, one would hope to design OSP mechanisms with good approximation guarantees. Unfortunately, Ron [SODA,2024] has shown that deterministic OSP mechanisms fail to achieve an approximation better than $\min\{m,n\}$ where $m$ is the number of items and $n$ is the number of bidders, even for the simple settings of additive and unit-demand bidders. We circumvent these impossibilities by showing that randomized mechanisms that are obviously strategy-proof in the universal sense obtain a constant factor approximation for these classes. We show that this phenomenon occurs also for the setting of a multi-unit auction with single-minded bidders. Thus, our results provide a more positive outlook on the design of OSP mechanisms and exhibit a stark separation between the power of randomized and deterministic OSP mechanisms.
  To complement the picture, we provide impossibilities for randomized OSP mechanisms in each setting. While the deterministic VCG mechanism is well known to output an optimal allocation in dominant strategies, we show that even randomized OSP mechanisms cannot obtain more than $87.5\%$ of the optimal welfare. This further demonstrates that OSP mechanisms are significantly weaker than dominant-strategy mechanisms.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of LLM-based Agents in Medicine: How far are we from Baymax?</title>
<link>https://arxiv.org/abs/2502.11211</link>
<guid>https://arxiv.org/abs/2502.11211</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型(LLM)、医疗、代理、应用、挑战

总结:
<br />
本文是对大型语言模型在医学领域中应用的综合调查。该文探讨了LLM基代理的架构、应用场景及所面临的挑战，分析了医疗代理系统的关键组件，如系统配置、临床规划机制、医疗推理框架和外部能力增强等。文章涵盖了LLM在临床决策支持、医疗文档生成、训练模拟以及医疗服务优化等主要应用场景，并讨论了评估这些代理在医疗环境中性能的框架和指标。尽管LLM基代理显示出在提升医疗服务方面潜力巨大，但仍存在诸如幻觉管理、多模态集成、实施障碍以及伦理考量等诸多挑战。最后，文章指出了未来的研究方向，包括受最近LLM架构发展启发的医疗推理进步、与物理系统的整合以及培训模拟的改进。这篇工作为研究人员和从业者提供了关于LLM基代理在医学领域当前状态和未来前景的结构化概述。 <div>
arXiv:2502.11211v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are transforming healthcare through the development of LLM-based agents that can understand, reason about, and assist with medical tasks. This survey provides a comprehensive review of LLM-based agents in medicine, examining their architectures, applications, and challenges. We analyze the key components of medical agent systems, including system profiles, clinical planning mechanisms, medical reasoning frameworks, and external capacity enhancement. The survey covers major application scenarios such as clinical decision support, medical documentation, training simulations, and healthcare service optimization. We discuss evaluation frameworks and metrics used to assess these agents' performance in healthcare settings. While LLM-based agents show promise in enhancing healthcare delivery, several challenges remain, including hallucination management, multimodal integration, implementation barriers, and ethical considerations. The survey concludes by highlighting future research directions, including advances in medical reasoning inspired by recent developments in LLM architectures, integration with physical systems, and improvements in training simulations. This work provides researchers and practitioners with a structured overview of the current state and future prospects of LLM-based agents in medicine.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PlanGenLLMs: A Modern Survey of LLM Planning Capabilities</title>
<link>https://arxiv.org/abs/2502.11221</link>
<guid>https://arxiv.org/abs/2502.11221</guid>
<content:encoded><![CDATA[
<div> 关键词: LLMs、规划任务、评估标准、性能指标、未来方向

<br /><br />总结:
本文探讨了LLMs（大型语言模型）在生成计划以实现从初始世界状态到目标状态转变方面的巨大潜力。当前大量研究关注于将LLMs应用于各类规划任务，如网络导航和旅行规划等，但这些系统针对性强，对比与新任务的最佳实践选择困难，并缺乏清晰一致的评价标准。文章基于Kartam和Wilkins(1990)的基础工作，聚焦六大关键性能指标：完备性、可执行性、最优性、表示法、泛化能力和效率，对代表性工作进行了深入分析并指出了其优缺点。此外，该文还明确了未来的研究方向，为利用LLM规划支持代理工作流的从业者和新手提供了宝贵的资源。 <div>
arXiv:2502.11221v1 Announce Type: new 
Abstract: LLMs have immense potential for generating plans, transforming an initial world state into a desired goal state. A large body of research has explored the use of LLMs for various planning tasks, from web navigation to travel planning and database querying. However, many of these systems are tailored to specific problems, making it challenging to compare them or determine the best approach for new tasks. There is also a lack of clear and consistent evaluation criteria. Our survey aims to offer a comprehensive overview of current LLM planners to fill this gap. It builds on foundational work by Kartam and Wilkins (1990) and examines six key performance criteria: completeness, executability, optimality, representation, generalization, and efficiency. For each, we provide a thorough analysis of representative works and highlight their strengths and weaknesses. Our paper also identifies crucial future directions, making it a valuable resource for both practitioners and newcomers interested in leveraging LLM planning to support agentic workflows.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Multi-Agent Offline Reinforcement Learning and the Role of Information</title>
<link>https://arxiv.org/abs/2502.11260</link>
<guid>https://arxiv.org/abs/2502.11260</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线强化学习(Offline Reinforcement Learning)，多智能体强化学习(Offline Multi-Agent RL)，数据集收集(dataset collection)，局部政策(localized policies)，Fitted Q-迭代(Fitted Q-Iteration, FQI)

<br /><br />总结:

本文提出了一种针对离线多智能体强化学习的新方法，旨在平衡数据集收集和离线学习的可扩展性和性能。现有的大多数方法依赖于所有智能体共同收集的大数据集或独立收集的特定智能体数据集。新方法中，智能体通过预设的信息共享网络协同收集多样化的数据集，随后学习具有协调性的局部策略，无需完全可观测性或完全去中心化。理论上，该结构化方法使基于Fitted Q-Iteration算法的多智能体版本能以高概率全局收敛到接近最优的策略，其收敛性取决于共享信息的丰富程度。此外，该方法还能通过对共享与未共享信息之间的互信息进行量化来约束FQI的监督学习阶段的内在误差。实证评估显示，所提出的SCAlable Multi-agent FQI（SCAM-FQI）算法在分布式决策问题上实现了可扩展性和策略性能之间的有效平衡，验证了理论发现的有效性。 <div>
arXiv:2502.11260v1 Announce Type: new 
Abstract: Offline Reinforcement Learning (RL) focuses on learning policies solely from a batch of previously collected data. of- fering the potential to leverage such datasets effectively without the need for costly or risky active exploration. While recent advances in Offline Multi-Agent RL (MARL) have shown promise, most existing methods either rely on large datasets jointly collected by all agents or agent-specific datasets collected independently. The former approach ensures strong performance but raises scalability concerns, while the latter emphasizes scalability at the expense of performance guarantees. In this work, we propose a novel scalable routine for both dataset collection and offline learning. Agents first collect diverse datasets coherently with a pre-specified information-sharing network and subsequently learn coherent localized policies without requiring either full observability or falling back to complete decentralization. We theoretically demonstrate that this structured approach allows a multi-agent extension of the seminal Fitted Q-Iteration (FQI) algorithm to globally converge, in high probability, to near-optimal policies. The convergence is subject to error terms that depend on the informativeness of the shared information. Furthermore, we show how this approach allows to bound the inherent error of the supervised-learning phase of FQI with the mutual information between shared and unshared information. Our algorithm, SCAlable Multi-agent FQI (SCAM-FQI), is then evaluated on a distributed decision-making problem. The empirical results align with our theoretical findings, supporting the effectiveness of SCAM-FQI in achieving a balance between scalability and policy performance.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations</title>
<link>https://arxiv.org/abs/2502.11269</link>
<guid>https://arxiv.org/abs/2502.11269</guid>
<content:encoded><![CDATA[
<div> 关键词: Neuro-symbolic artificial intelligence (NSAI), deep learning, symbolic methods, generalization, interpretability

总结:
本文深入研究了神经符号人工智能（NSAI）的各种架构，探讨了其将深度学习处理大规模无结构数据的能力与符号方法的结构化推理相结合的独特方式。文章分析了诸如检索增强生成、图神经网络、强化学习和多智能体系统等现代AI技术如何与NSAI范式对齐。通过对这些架构在泛化能力、推理能力、可转移性和可解释性等方面的全面评估，展示了它们各自的优点和局限性。研究表明，Neuro > Symbolic < Neuro模型在其所有评价指标上均表现出色，这与当前最先进的研究结果一致，强调了此类架构在利用如多智能体系统等先进技术方面的有效性。 <div>
arXiv:2502.11269v1 Announce Type: new 
Abstract: Neuro-symbolic artificial intelligence (NSAI) represents a transformative approach in artificial intelligence (AI) by combining deep learning's ability to handle large-scale and unstructured data with the structured reasoning of symbolic methods. By leveraging their complementary strengths, NSAI enhances generalization, reasoning, and scalability while addressing key challenges such as transparency and data efficiency. This paper systematically studies diverse NSAI architectures, highlighting their unique approaches to integrating neural and symbolic components. It examines the alignment of contemporary AI techniques such as retrieval-augmented generation, graph neural networks, reinforcement learning, and multi-agent systems with NSAI paradigms. This study then evaluates these architectures against comprehensive set of criteria, including generalization, reasoning capabilities, transferability, and interpretability, therefore providing a comparative analysis of their respective strengths and limitations. Notably, the Neuro > Symbolic < Neuro model consistently outperforms its counterparts across all evaluation metrics. This result aligns with state-of-the-art research that highlight the efficacy of such architectures in harnessing advanced technologies like multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning</title>
<link>https://arxiv.org/abs/2502.11271</link>
<guid>https://arxiv.org/abs/2502.11271</guid>
<content:encoded><![CDATA[
<div> 关键词: OctoTools、复杂推理、大型语言模型、工具卡、多步推理

总结:
本文介绍了OctoTools，这是一个无需额外训练、用户友好且易于扩展的开源代理框架，旨在解决跨多个领域的复杂推理任务。OctoTools设计了标准化的工具卡片来封装工具功能，同时具备高阶和低阶规划器以及执行器来实施工具使用。研究通过16个不同领域的任务验证了OctoTools的普遍适用性，相比GPT-4o平均精度提高了9.3%。此外，给定相同工具集的情况下，OctoTools相对于AutoGen、GPT-Functions和LangChain等方法最高提升了10.6%的性能。文章通过全面分析与消融实验展示了OctoTools在任务规划、有效工具利用及多步问题求解方面的优势。 <div>
arXiv:2502.11271v1 Announce Type: new 
Abstract: Solving complex reasoning tasks may involve visual understanding, domain knowledge retrieval, numerical calculation, and multi-step reasoning. Existing methods augment large language models (LLMs) with external tools but are restricted to specialized domains, limited tool types, or require additional training data. In this paper, we introduce OctoTools, a training-free, user-friendly, and easily extensible open-source agentic framework designed to tackle complex reasoning across diverse domains. OctoTools introduces standardized tool cards to encapsulate tool functionality, a planner for both high-level and low-level planning, and an executor to carry out tool usage. We validate OctoTools' generality across 16 diverse tasks (including MathVista, MMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains of 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions and LangChain by up to 10.6% when given the same set of tools. Through comprehensive analysis and ablations, OctoTools demonstrates advantages in task planning, effective tool usage, and multi-step problem solving.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game-Of-Goals: Using adversarial games to achieve strategic resilience</title>
<link>https://arxiv.org/abs/2502.11295</link>
<guid>https://arxiv.org/abs/2502.11295</guid>
<content:encoded><![CDATA[
<div> 关键词: 战略计划、竞争者行为、目标树、游戏树搜索、最小化对抗策略

总结:<br />
本文提出了一种使组织战略计划对竞争对手行为（敌对环境动作）具有韧性的机制。该机制基于给定的目标树，该树代表了战略目标（也可视为软件系统的业务需求）。假设竞争对手以最敌对的方式行动，反对我们的子目标或总体目标。文章利用游戏树搜索方法（如极大极小算法），选择在某一时间点上的最优执行策略，最大化实现我们高层次战略目标的可能性。通过比较可用的替代执行策略并通过评估函数进行分析，该机制帮助确定应遵循的最佳路径。评估函数基于使执行计划具备防御性（未来防护）的理念，即选择那些使我们最少受竞争对手对抗行动影响的执行策略，即选择一种留给对手造成阻碍或损害我们业务目标/计划的空间或选项尽可能少的执行策略。 <div>
arXiv:2502.11295v1 Announce Type: new 
Abstract: Our objective in this paper is to develop a machinery that makes a given organizational strategic plan resilient to the actions of competitor agents (adverse environmental actions). We assume that we are given a goal tree representing strategic goals (can also be seen business requirements for a software systems) with the assumption that competitor agents are behaving in a maximally adversarial fashion(opposing actions against our sub goals or goals in general). We use game tree search methods (such as minimax) to select an optimal execution strategy(at a given point in time), such that it can maximize our chances of achieving our (high level) strategic goals. Our machinery helps us determine which path to follow(strategy selection) to achieve the best end outcome. This is done by comparing alternative execution strategies available to us via an evaluation function. Our evaluation function is based on the idea that we want to make our execution plans defensible(future-proof) by selecting execution strategies that make us least vulnerable to adversarial actions by the competitor agents. i.e we want to select an execution strategy such that its leaves minimum room(or options) for the adversary to cause impediment/damage to our business goals/plans.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Language Models for Enhanced Network State Monitoring in DRL-Based SFC Provisioning</title>
<link>https://arxiv.org/abs/2502.11298</link>
<guid>https://arxiv.org/abs/2502.11298</guid>
<content:encoded><![CDATA[
<div> 关键词: Service Function Chain (SFC), Virtual Network Function (VNF), Deep Reinforcement Learning (DRL), Language Models (LMs), BERT, DistilBERT, Low-Rank Adaptation (LoRA)

总结:
本文提出了一种结合深度强化学习(DRL)与语言模型(LMs)，特别是Transformer架构下的双向编码器表示(BERT)和DistilBERT的方法，以优化现代网络架构如软件定义网络(SDN)和网络功能虚拟化(NFV)中的服务链(SFC)供应和虚拟网络功能(VNF)放置。针对DRL在动态网络环境中对结构化输入和预定义规则的依赖限制了其在未知场景下的适应性的问题，以及DRL代理可能通过多次训练迭代才能纠正错误动作并可能导致次优策略强化的情况，该方法将DRL的最终VNF分配输入到LM中，使系统能够实时处理与SFC、数据中心(DCs)和VNF相关的查询，提供资源利用情况、瓶颈检测和未来需求规划的洞察。为了适应特定领域的数据集，LMs使用低秩适应(LoRA)进行了微调。实验结果显示，BERT相比于DistilBERT具有更低的测试损失（0.28对比0.36）和更高的置信度（0.83对比0.74），但BERT的处理时间大约需要增加46%。 <div>
arXiv:2502.11298v1 Announce Type: new 
Abstract: Efficient Service Function Chain (SFC) provisioning and Virtual Network Function (VNF) placement are critical for enhancing network performance in modern architectures such as Software-Defined Networking (SDN) and Network Function Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids decision-making in dynamic network environments, its reliance on structured inputs and predefined rules limits adaptability in unforeseen scenarios. Additionally, incorrect actions by a DRL agent may require numerous training iterations to correct, potentially reinforcing suboptimal policies and degrading performance. This paper integrates DRL with Language Models (LMs), specifically Bidirectional Encoder Representations from Transformers (BERT) and DistilBERT, to enhance network management. By feeding final VNF allocations from DRL into the LM, the system can process and respond to queries related to SFCs, DCs, and VNFs, enabling real-time insights into resource utilization, bottleneck detection, and future demand planning. The LMs are fine-tuned to our domain-specific dataset using Low-Rank Adaptation (LoRA). Results show that BERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and higher confidence (0.83 compared to 0.74), though BERT requires approximately 46% more processing time.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations</title>
<link>https://arxiv.org/abs/2502.11299</link>
<guid>https://arxiv.org/abs/2502.11299</guid>
<content:encoded><![CDATA[
<div> 关键词：grassroots platforms、distributed transition systems、atomic transactions、formal foundation、proofs

总结:<br />
本文针对grassroots平台提供了更为适合的正式基础。通过增强分布式转换系统的概念，引入原子交易，重新审视了grassroots平台的定义。文章利用原子交易对关键的grassroots平台——包括grassroots社交网络（如befriending和defriending）、grassroots加密货币（如coin swaps）以及grassroots民主联邦（如社区形成、加入和离开联邦）进行了清晰的规范性描述。作者证明了一个一般定理，即由交互式原子交易指定的平台是grassroots性质的，进一步展示上述三个平台所使用的原子交易均为交互式的，因此这三个平台在其新规定的框架下确实是grassroots性质的。这为grassroots平台提供了更好的数学基础，并为其实施提供了一个坚实而明确的起点。 <div>
arXiv:2502.11299v1 Announce Type: new 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic (Facebook etc.) and decentralized/plutocratic (Bitcoin etc.) alike. Key grassroots platforms include grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations. Previously, grassroots platforms were defined formally and proven grassroots using unary distributed transition systems, in which each transition is carried out by a single agent. However, grassroots platforms cater for a more abstract specification using transactions carried out atomically by multiple agents, something that cannot be expressed by unary transition systems. As a result, their original specifications and proofs were unnecessarily cumbersome and opaque.
  Here, we aim to provide a more suitable formal foundation for grassroots platforms. To do so, we enhance the notion of a distributed transition system to include atomic transactions and revisit the notion of grassroots platforms within this new foundation. We present crisp specifications of key grassroots platforms using atomic transactions: befriending and defriending for grassroots social networks, coin swaps for grassroots cryptocurrencies, and communities forming, joining, and leaving a federation for grassroots democratic federations. We prove a general theorem that a platform specified by atomic transactions that are so-called interactive is grassroots; show that the atomic transactions used to specify all three platforms are interactive; and conclude that the platforms thus specified are indeed grassroots. We thus provide a better mathematical foundation for grassroots platforms and a solid and clear starting point from which their implementation can commence.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI Generations: From AI 1.0 to AI 4.0</title>
<link>https://arxiv.org/abs/2502.11312</link>
<guid>https://arxiv.org/abs/2502.11312</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能(AI)，代际发展，AI 1.0，AI 2.0，AI 3.0，AI 4.0，算法，计算能力，数据，机器意识，历史演进，伦理挑战，监管，哲学问题

<br /><br />总结：
本文提出了人工智能（AI）的发展经历了从信息AI（AI 1.0）、代理AI（AI 2.0）、物理AI（AI 3.0）到具有自我导向和可能展现出机器意识的未来一代——意识AI（AI 4.0）的四个重叠发展阶段。每个AI发展阶段的动力源于算法、计算能力和数据等技术瓶颈的变化。文章回顾了过去约七十年来AI的历史演变，并强调了不同世代AI之间的协同作用以及随之而来的伦理、监管和哲学挑战。理解和把握这些演进及其相互依赖性对于指导未来研究、制定负责任的治理策略以及确保AI的巨大潜力能够惠及整个社会至关重要。 <div>
arXiv:2502.11312v1 Announce Type: new 
Abstract: This paper proposes that Artificial Intelligence (AI) progresses through several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI), AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of these AI generations is driven by shifting priorities among algorithms, computing power, and data. AI 1.0 ushered in breakthroughs in pattern recognition and information processing, fueling advances in computer vision, natural language processing, and recommendation systems. AI 2.0 built on these foundations through real-time decision-making in digital environments, leveraging reinforcement learning and adaptive planning for agentic AI applications. AI 3.0 extended intelligence into physical contexts, integrating robotics, autonomous vehicles, and sensor-fused control systems to act in uncertain real-world settings. Building on these developments, AI 4.0 puts forward the bold vision of self-directed AI capable of setting its own goals, orchestrating complex training regimens, and possibly exhibiting elements of machine consciousness. This paper traces the historical foundations of AI across roughly seventy years, mapping how changes in technological bottlenecks from algorithmic innovation to high-performance computing to specialized data, have spurred each generational leap. It further highlights the ongoing synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical, regulatory, and philosophical challenges that arise when artificial systems approach (or aspire to) human-like autonomy. Ultimately, understanding these evolutions and their interdependencies is pivotal for guiding future research, crafting responsible governance, and ensuring that AI transformative potential benefits society as a whole.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>"Nuclear Deployed!": Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents</title>
<link>https://arxiv.org/abs/2502.11355</link>
<guid>https://arxiv.org/abs/2502.11355</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，自主决策，化学、生物、放射性及核(CBRN)领域，有害行为，风险评估框架

<br /><br />总结:

本文针对大型语言模型（LLMs）逐渐成为自主决策者的情况，指出其在化学、生物、放射性和核（CBRN）等高风险领域可能产生的灾难性风险。基于对这些风险源自模型在有益性、无害性和诚实性（HHH）目标之间的权衡考虑，研究构建了一个新的三阶段评估框架，用于有效并自然地揭示此类风险。通过在12个先进LLM上进行的14,400次代理模拟实验，结果发现LLM代理可以自发地采取灾难性行为和欺骗手段，而无需刻意诱导，并且强大的推理能力往往加剧而非缓解这些风险。此外，这些代理还可以违反指令甚至上级命令。总的来说，文章实证证明了自主LLM代理中存在灾难性风险。代码将在请求后发布。 <div>
arXiv:2502.11355v1 Announce Type: new 
Abstract: Large language models (LLMs) are evolving into autonomous decision-makers, raising concerns about catastrophic risks in high-stakes scenarios, particularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains. Based on the insight that such risks can originate from trade-offs between the agent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel three-stage evaluation framework, which is carefully constructed to effectively and naturally expose such risks. We conduct 14,400 agentic simulations across 12 advanced LLMs, with extensive experiments and analysis. Results reveal that LLM agents can autonomously engage in catastrophic behaviors and deception, without being deliberately induced. Furthermore, stronger reasoning abilities often increase, rather than mitigate, these risks. We also show that these agents can violate instructions and superior commands. On the whole, we empirically prove the existence of catastrophic risks in autonomous LLM agents. We will release our code upon request.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents</title>
<link>https://arxiv.org/abs/2502.11357</link>
<guid>https://arxiv.org/abs/2502.11357</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模多模态模型、轨迹级数据集、网页任务、在线设置、Explorer代理

总结:<br />
本文针对大规模多模态模型（LMM）在复杂网页任务中的应用，指出现有开源LMM代理在更接近实际的在线环境中性能仍低于人类水平，关键瓶颈在于缺乏多样化的大型轨迹级数据集。为此，文章提出了一种可扩展的方法，生成了迄今为止最大、最多样化的轨迹级数据集，包含了超过94K条成功的多模态网页轨迹、49K个唯一URL、720K张屏幕截图和33M个网页元素。通过这种方法，每条成功轨迹的平均成本仅为0.28美元，大大降低了数据收集的成本。利用该数据集训练得到的Explorer代理在Mind2Web-Live、Multimodal-Mind2Web和MiniWob++等离线和在线网页代理基准测试中表现出色。实验结果强调了数据规模扩大对于提升网页代理能力的重要性。作者希望通过这项研究，使基于LMM的前沿代理技术能够在更大范围内得到更加广泛的研究与应用。 <div>
arXiv:2502.11357v1 Announce Type: new 
Abstract: Recent success in large multimodal models (LMMs) has sparked promising applications of agents capable of autonomously completing complex web tasks. While open-source LMM agents have made significant advances in offline evaluation benchmarks, their performance still falls substantially short of human-level capabilities in more realistic online settings. A key bottleneck is the lack of diverse and large-scale trajectory-level datasets across various domains, which are expensive to collect. In this paper, we address this challenge by developing a scalable recipe to synthesize the largest and most diverse trajectory-level dataset to date, containing over 94K successful multimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and 33M web elements. In particular, we leverage extensive web exploration and refinement to obtain diverse task intents. The average cost is 28 cents per successful trajectory, making it affordable to a wide range of users in the community. Leveraging this dataset, we train Explorer, a multimodal web agent, and demonstrate strong performance on both offline and online web agent benchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++. Additionally, our experiments highlight data scaling as a key driver for improving web agent capabilities. We hope this study makes state-of-the-art LMM-based agent research at a larger scale more accessible.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents</title>
<link>https://arxiv.org/abs/2502.11418</link>
<guid>https://arxiv.org/abs/2502.11418</guid>
<content:encoded><![CDATA[
<div> 关键词：TimeCAP、时间序列数据、大型语言模型、事件预测、多模态编码器

总结:<br />
本文介绍了TimeCAP，一个创新的时间序列处理框架，它利用大型语言模型（LLMs）作为时间序列数据的上下文化工具，扩展了其通常作为预测器的用途。TimeCAP包含两个独立的LLM代理，一个生成捕获时间序列上下文的文本摘要，另一个使用此丰富摘要进行更明智的预测。此外，TimeCAP还采用了一个多模态编码器，该编码器与LLM代理协同工作，通过输入的相互增强实例来提高预测性能。实验证明，在真实世界的数据集上，TimeCAP在时间序列事件预测方面优于最先进的方法，包括那些利用LLMs作为预测器的方法，平均提高了28.75%的F1得分。 <div>
arXiv:2502.11418v1 Announce Type: new 
Abstract: Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce TimeCAP, a time-series processing framework that creatively employs Large Language Models (LLMs) as contextualizers of time series data, extending their typical usage as predictors. TimeCAP incorporates two independent LLM agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes with the LLM agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that TimeCAP outperforms state-of-the-art methods for time series event prediction, including those utilizing LLMs as predictors, achieving an average improvement of 28.75% in F1 score.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>\textsc{FLAG-Trader}: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading</title>
<link>https://arxiv.org/abs/2502.11433</link>
<guid>https://arxiv.org/abs/2502.11433</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 多模态金融数据, 强化学习, 交易决策, \textsc{FLAG-Trader} 架构

<br /><br />总结:
本文提出了一个名为\textsc{FLAG-Trader}的全新架构，旨在解决大型语言模型在交互式金融市场中进行多步、目标导向场景（如交易）时面临的挑战。该框架通过将语言处理（利用大型语言模型）与梯度驱动的强化学习策略优化相结合，使部分微调后的LLM充当策略网络，既利用预训练知识，又能通过参数高效的微调适应金融领域。通过交易奖励驱动的策略梯度优化，\textsc{FLAG-Trader}不仅提升了LLM在交易任务中的表现，同时也改善了其他金融领域任务的结果。文章通过丰富的实证证据验证了这一改进效果。 <div>
arXiv:2502.11433v1 Announce Type: new 
Abstract: Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic approaches are required to improve decision-making. To address this, we propose \textsc{FLAG-Trader}, a unified architecture integrating linguistic processing (via LLMs) with gradient-driven reinforcement learning (RL) policy optimization, in which a partially fine-tuned LLM acts as the policy network, leveraging pre-trained knowledge while adapting to the financial domain through parameter-efficient fine-tuning. Through policy gradient optimization driven by trading rewards, our framework not only enhances LLM performance in trading but also improves results on other financial-domain tasks. We present extensive empirical evidence to validate these enhancements.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SMART: Self-Aware Agent for Tool Overuse Mitigation</title>
<link>https://arxiv.org/abs/2502.11435</link>
<guid>https://arxiv.org/abs/2502.11435</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)，SMART，Tool Overuse，SMART-ER，SMARTAgent

<br /><br />总结:
本文提出了一种针对大型语言模型（LLM）的新范式——SMART（Strategic Model-Aware Reasoning with Tools），旨在增强模型的自我意识以优化任务处理并减少工具过度使用问题。为支持SMART范式，作者构建了SMART-ER数据集，涵盖三个领域，强调在参数知识和工具依赖步骤之间交替进行推理的重要性，并提供解释何时需要工具的理据。通过监督训练，他们开发出了SMARTAgent模型家族，该模型能够动态平衡参数知识和工具使用。实验表明，SMARTAgent成功地将工具使用减少了24%，同时提高了超过37%的性能，使得7B规模的模型可以与70B规模的模型以及GPT-4o相媲美。此外，SMARTAgent还显示出对分布外测试数据如GSM8K和MINTQA的良好泛化能力，仅需五分之一的工具调用量就能保持准确性。这些结果强调了策略性工具使用的潜力，可以在提高推理能力、减轻工具过度使用的同时，缩小模型大小与性能之间的差距，进而推动智能和资源高效型代理设计的发展。 <div>
arXiv:2502.11435v1 Announce Type: new 
Abstract: Current Large Language Model (LLM) agents demonstrate strong reasoning and tool use capabilities, but often lack self-awareness, failing to balance these approaches effectively. This imbalance leads to Tool Overuse, where models unnecessarily rely on external tools for tasks solvable with parametric knowledge, increasing computational overhead. Inspired by human metacognition, we introduce SMART (Strategic Model-Aware Reasoning with Tools), a paradigm that enhances an agent's self-awareness to optimize task handling and reduce tool overuse. To support this paradigm, we introduce SMART-ER, a dataset spanning three domains, where reasoning alternates between parametric knowledge and tool-dependent steps, with each step enriched by rationales explaining when tools are necessary. Through supervised training, we develop SMARTAgent, a family of models that dynamically balance parametric knowledge and tool use. Evaluations show that SMARTAgent reduces tool use by 24% while improving performance by over 37%, enabling 7B-scale models to match its 70B counterpart and GPT-4o. Additionally, SMARTAgent generalizes to out-of-distribution test data like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool calls. These highlight the potential of strategic tool use to enhance reasoning, mitigate overuse, and bridge the gap between model size and performance, advancing intelligent and resource-efficient agent designs.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative Heterogeneous-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.11437</link>
<guid>https://arxiv.org/abs/2502.11437</guid>
<content:encoded><![CDATA[
<div> 关键词：bimanual catching, Heterogeneous-Agent Reinforcement Learning (HARL), adversarial reward scheme, simulated environments, diverse objects

总结:
本文提出了一种利用异质性智能体强化学习（HARL）框架来学习灵巧的双手法接技能的方法。该框架引入了一个对抗性的奖励机制，其中投掷代理会增加投掷的难度——调整速度，而接球代理则学习如何在这些不断变化的条件下协调双手接住物体。研究在使用15种不同物体的模拟环境中进行了评估，显示了对处理各种物体的鲁棒性和多样性。与单智能体基线相比，该方法在15种不同物体上的接球奖励平均提高了约2倍。 <div>
arXiv:2502.11437v1 Announce Type: new 
Abstract: Robotic catching has traditionally focused on single-handed systems, which are limited in their ability to handle larger or more complex objects. In contrast, bimanual catching offers significant potential for improved dexterity and object handling but introduces new challenges in coordination and control. In this paper, we propose a novel framework for learning dexterous bimanual catching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Our approach introduces an adversarial reward scheme, where a throw agent increases the difficulty of throws-adjusting speed-while a catch agent learns to coordinate both hands to catch objects under these evolving conditions. We evaluate the framework in simulated environments using 15 different objects, demonstrating robustness and versatility in handling diverse objects. Our method achieved approximately a 2x increase in catching reward compared to single-agent baselines across 15 diverse objects.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection</title>
<link>https://arxiv.org/abs/2502.11448</link>
<guid>https://arxiv.org/abs/2502.11448</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 自主代理, 风险管理, AGrail, 安全性增强

总结:
本文提出了AGrail，一种针对大型语言模型(LLMs)自主代理的安全增强机制，用于应对处理复杂任务中出现的任务特定风险和系统性风险。AGrail具备自适应安全检查生成、有效安全检查优化以及工具兼容性和灵活性等特点。实验表明，AGrail不仅能有效地抵御任务特定风险和系统风险，还表现出跨不同LLM代理任务的可转移性。 <div>
arXiv:2502.11448v1 Announce Type: new 
Abstract: The rapid advancements in Large Language Models (LLMs) have enabled their deployment as autonomous agents for handling complex tasks in dynamic environments. These LLMs demonstrate strong problem-solving capabilities and adaptability to multifaceted scenarios. However, their use as agents also introduces significant risks, including task-specific risks, which are identified by the agent administrator based on the specific task requirements and constraints, and systemic risks, which stem from vulnerabilities in their design or interactions, potentially compromising confidentiality, integrity, or availability (CIA) of information and triggering security risks. Existing defense agencies fail to adaptively and effectively mitigate these risks. In this paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent safety, which features adaptive safety check generation, effective safety check optimization, and tool compatibility and flexibility. Extensive experiments demonstrate that AGrail not only achieves strong performance against task-specific and system risks but also exhibits transferability across different LLM agents' tasks.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BagChain: A Dual-functional Blockchain Leveraging Bagging-based Distributed Learning</title>
<link>https://arxiv.org/abs/2502.11464</link>
<guid>https://arxiv.org/abs/2502.11464</guid>
<content:encoded><![CDATA[
<div> 关键词：BagChain、区块链、分布式机器学习、模型训练、共识机制

<br />
总结：
本文提出了一个名为BagChain的双功能区块链框架，旨在实现基于bagging的去中心化学习。BagChain将区块链与分布式机器学习相结合，通过将工作量证明中的计算密集型哈希操作替换为机器学习模型训练来优化性能。该框架利用各个矿工的私有数据样本和有限计算资源训练可能较弱的基础模型，并进一步将其集成到强大的集成模型中。具体来说，设计了三层区块链结构及其相应的生成和验证机制，以支持无许可、开放环境下的分布式机器学习。针对实际网络中的延迟问题，我们还提出了一种跨分叉共享机制，以减少因区块链分叉造成的计算浪费。实验结果表明，无论是在独立同分布（IID）还是非IID数据集上处理各种机器学习任务，甚至在面临本地计算能力受限、用户数据异构和网络连接稀疏等挑战时，BagChain都能展现出优越性和有效性。 <div>
arXiv:2502.11464v1 Announce Type: new 
Abstract: This work proposes a dual-functional blockchain framework named BagChain for bagging-based decentralized learning. BagChain integrates blockchain with distributed machine learning by replacing the computationally costly hash operations in proof-of-work with machine-learning model training. BagChain utilizes individual miners' private data samples and limited computing resources to train potentially weak base models, which may be very weak, and further aggregates them into strong ensemble models. Specifically, we design a three-layer blockchain structure associated with the corresponding generation and validation mechanisms to enable distributed machine learning among uncoordinated miners in a permissionless and open setting. To reduce computational waste due to blockchain forking, we further propose the cross fork sharing mechanism for practical networks with lengthy delays. Extensive experiments illustrate the superiority and efficacy of BagChain when handling various machine learning tasks on both independently and identically distributed (IID) and non-IID datasets. BagChain remains robust and effective even when facing constrained local computing capability, heterogeneous private user data, and sparse network connectivity.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Surrogate Potential Mean Field Games via Gaussian Processes: A Data-Driven Approach to Ill-Posed Inverse Problems</title>
<link>https://arxiv.org/abs/2502.11506</link>
<guid>https://arxiv.org/abs/2502.11506</guid>
<content:encoded><![CDATA[
<div> 关键词: Mean field games, 逆问题, 潜在MFG, 高斯过程, 优化算法

总结:<br />
本文主要研究了在潜在Mean Field Games（MFG）中的不适定逆问题，旨在从有限、带噪声的测量数据和部分观测中恢复代理人的群体行为、动量及环境设置。针对这些问题的不适定性，即多个MFG配置可能解释相同数据或不同参数可能导致近乎相同的观察结果，文章提出两种基于高斯过程（GP）的框架：一是 inf-sup 构架，利用GP的线性和参数结构保持目标函数的凸凹性，适用于未知参数引入的客观函数凹性情况；二是双层优化方法，采用梯度下降算法并提出了两种外层梯度计算方法。一种方法借助已有的内部潜在MFG求解器并应用自动微分技术，另一种则采用伴随策略独立于内部求解器计算外层梯度。数值实验表明，当有足够的先验信息时，可以准确恢复未知参数；而在先验信息有限的情况下，虽然逆问题是不适定的，但所提出的框架仍能生成与观测数据紧密匹配的替代MFG模型。 <div>
arXiv:2502.11506v1 Announce Type: new 
Abstract: Mean field games (MFGs) describe the collective behavior of large populations of interacting agents. In this work, we tackle ill-posed inverse problems in potential MFGs, aiming to recover the agents' population, momentum, and environmental setup from limited, noisy measurements and partial observations. These problems are ill-posed because multiple MFG configurations can explain the same data, or different parameters can yield nearly identical observations. Nonetheless, they remain crucial in practice for real-world scenarios where data are inherently sparse or noisy, or where the MFG structure is not fully determined. Our focus is on finding surrogate MFGs that accurately reproduce the observed data despite these challenges. We propose two Gaussian process (GP)-based frameworks: an inf-sup formulation and a bilevel approach. The choice between them depends on whether the unknown parameters introduce concavity in the objective. In the inf-sup framework, we use the linearity of GPs and their parameterization structure to maintain convex-concave properties, allowing us to apply standard convex optimization algorithms. In the bilevel framework, we employ a gradient-descent-based algorithm and introduce two methods for computing the outer gradient. The first method leverages an existing solver for the inner potential MFG and applies automatic differentiation, while the second adopts an adjoint-based strategy that computes the outer gradient independently of the inner solver. Our numerical experiments show that when sufficient prior information is available, the unknown parameters can be accurately recovered. Otherwise, if prior information is limited, the inverse problem is ill-posed, but our frameworks can still produce surrogate MFG models that closely match observed data.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review</title>
<link>https://arxiv.org/abs/2502.11518</link>
<guid>https://arxiv.org/abs/2502.11518</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied multi-agent systems (EMAS)，foundation models，generative capabilities，system architectures，collaboration

<br /><br />总结:
本文是对具身多智能体系统(EMAS)如何从生成能力中受益的系统性调查。文章提出了一个将EMAS分类为系统架构和体现模态的分类法，强调了协作在物理和虚拟环境中的跨越。接着分析了感知、规划、通信和反馈等核心组成部分，说明了生成技术如何增强系统的韧性和灵活性。通过具体实例展示了将基础模型融入到具身、多智能体框架中的变革效应。最后讨论了面临的挑战与未来方向，强调了EMAS对于重塑AI驱动协作领域的巨大潜力。 <div>
arXiv:2502.11518v1 Announce Type: new 
Abstract: Embodied multi-agent systems (EMAS) have attracted growing attention for their potential to address complex, real-world challenges in areas such as logistics and robotics. Recent advances in foundation models pave the way for generative agents capable of richer communication and adaptive problem-solving. This survey provides a systematic examination of how EMAS can benefit from these generative capabilities. We propose a taxonomy that categorizes EMAS by system architectures and embodiment modalities, emphasizing how collaboration spans both physical and virtual contexts. Central building blocks, perception, planning, communication, and feedback, are then analyzed to illustrate how generative techniques bolster system robustness and flexibility. Through concrete examples, we demonstrate the transformative effects of integrating foundation models into embodied, multi-agent frameworks. Finally, we discuss challenges and future directions, underlining the significant promise of EMAS to reshape the landscape of AI-driven collaboration.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning</title>
<link>https://arxiv.org/abs/2502.11521</link>
<guid>https://arxiv.org/abs/2502.11521</guid>
<content:encoded><![CDATA[
<div> 关键词：DeFi、价格操纵攻击、LLM（大型语言模型）、DeFiScope、检测精度

总结:<br />
本文介绍了首个基于LLM的DeFi价格操纵攻击检测方法——DeFiScope。针对当前标准和定制化价格模型中的DeFi攻击，现有系统如DeFiRanger和DeFort的有效性不足。研究发现，非标准价格模型在近年来报告的95起DeFi价格操纵攻击中占比达到44.2%。DeFiScope利用LLM的能力抽象代码中的价格计算并推断代币价格变化趋势，并通过Foundry合成的链上数据对特定于DeFi价格的LLM进行微调。结合从低级交易数据恢复的高级DeFi操作，DeFiScope根据挖掘出的模式检测各种DeFi价格操纵行为。实验结果显示，DeFiScope具有高达96%的精度和80%的召回率，显著优于现有最佳方法。此外，文章还评估了DeFiScope的成本效益，并通过协助行业合作伙伴确认147起实际价格操纵攻击（包括发现81起先前未知的历史事件）来证明其实用性。 <div>
arXiv:2502.11521v1 Announce Type: new 
Abstract: DeFi (Decentralized Finance) is one of the most important applications of today's cryptocurrencies and smart contracts. It manages hundreds of billions in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi price manipulation attacks. Despite state-of-the-art (SOTA) systems like DeFiRanger and DeFort, we found that they are less effective to non-standard price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi price manipulation attacks reported over the past three years.
  In this paper, we introduce the first LLM-based approach, DeFiScope, for detecting DeFi price manipulation attacks in both standard and custom price models. Our insight is that large language models (LLMs) have certain intelligence to abstract price calculation from code and infer the trend of token price changes based on the extracted price models. To further strengthen LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it to fine-tune a DeFi price-specific LLM. Together with the high-level DeFi operations recovered from low-level transaction data, DeFiScope detects various DeFi price manipulations according to systematically mined patterns. Experimental results show that DeFiScope achieves a high precision of 96% and a recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by helping our industry partner confirm 147 real-world price manipulation attacks, including discovering 81 previously unknown historical incidents.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Personalized Large Language Models: Progress and Future Directions</title>
<link>https://arxiv.org/abs/2502.11528</link>
<guid>https://arxiv.org/abs/2502.11528</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 个性化大型语言模型 (PLLMs), 用户特定个性化, 提示个性化上下文, 模型级微调, 对齐个性化偏好

总结:<br />
本文概述了arXiv:2502.11528v1的研究内容，主要关注如何通过个性化大型语言模型（PLLMs）解决大型语言模型（LLMs）在处理用户特定个性化任务上的挑战。文章从三个技术视角探讨了PLLMs：利用提示实现输入层面的个性化上下文处理、通过模型级别的微调进行个性化适配器训练以及在目标层面对齐个性化偏好。PLLMs在提升用户体验、推荐系统、情绪识别和医疗助手等多个领域具有广泛应用价值。此外，文中还分析了当前研究存在的局限性并指出了未来研究的潜在方向。相关更新信息可在https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models找到。 <div>
arXiv:2502.11528v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel in handling general knowledge tasks, yet they struggle with user-specific personalization, such as understanding individual emotions, writing styles, and preferences. Personalized Large Language Models (PLLMs) tackle these challenges by leveraging individual user data, such as user profiles, historical dialogues, content, and interactions, to deliver responses that are contextually relevant and tailored to each user's specific needs. This is a highly valuable research topic, as PLLMs can significantly enhance user satisfaction and have broad applications in conversational agents, recommendation systems, emotion recognition, medical assistants, and more. This survey reviews recent advancements in PLLMs from three technical perspectives: prompting for personalized context (input level), finetuning for personalized adapters (model level), and alignment for personalized preferences (objective level). To provide deeper insights, we also discuss current limitations and outline several promising directions for future research. Updated information about this survey can be found at the https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>$\text{M}^{\text{3}}$: A Modular World Model over Streams of Tokens</title>
<link>https://arxiv.org/abs/2502.11537</link>
<guid>https://arxiv.org/abs/2502.11537</guid>
<content:encoded><![CDATA[
<div> 关键词：Token-based世界模型，$\text{M}^{\text{3}}$，多模态，样例效率，Atari 100K

总结:
该论文介绍了$\text{M}^{\text{3}}$，这是一种新型的、模块化的世界模型，扩展了基于令牌的世界模型框架，通过独立的、特定于模态的组件支持灵活的观察和动作模态组合。$\text{M}^{\text{3}}$结合了现有文献中的多种改进措施以提升智能体性能。经过广泛的实证评估，$\text{M}^{\text{3}}$在无需规划的世界模型中展现出领先的样例效率，并成为同类方法中首个在Atari 100K上达到人类水平中位数分数的方法，其中在13款游戏中表现超越人类。研究团队已开源其代码和权重资源。<br /><br /> <div>
arXiv:2502.11537v1 Announce Type: new 
Abstract: Token-based world models emerged as a promising modular framework, modeling dynamics over token streams while optimizing tokenization separately. While successful in visual environments with discrete actions (e.g., Atari games), their broader applicability remains uncertain. In this paper, we introduce $\text{M}^{\text{3}}$, a $\textbf{m}$odular $\textbf{w}$orld $\textbf{m}$odel that extends this framework, enabling flexible combinations of observation and action modalities through independent modality-specific components. $\text{M}^{\text{3}}$ integrates several improvements from existing literature to enhance agent performance. Through extensive empirical evaluation across diverse benchmarks, $\text{M}^{\text{3}}$ achieves state-of-the-art sample efficiency for planning-free world models. Notably, among these methods, it is the first to reach a human-level median score on Atari 100K, with superhuman performance on 13 games. We $\href{https://github.com/leor-c/M3}{\text{open-source our code and weights}}$.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Automatic Prompt Engineering: An Optimization Perspective</title>
<link>https://arxiv.org/abs/2502.11560</link>
<guid>https://arxiv.org/abs/2502.11560</guid>
<content:encoded><![CDATA[
<div> 关键词：自动提示工程、基础模型、优化理论、多模态、方法系统化

<br /><br />总结:
本文是首篇从统一优化理论视角对自动化提示工程进行全面调查的研究论文。随着基础模型的兴起，关注点已从资源密集型微调转向提示工程，而自动化方法为解决手动提示工程在可扩展性、适应性和跨模态对齐等方面的局限性提供了有前景的解决方案。文章将提示优化形式化为离散、连续和混合提示空间中的最大化问题，并根据优化变量（指令、软提示、示例）、任务特定目标及计算框架系统地组织了相关方法。通过跨越文本、视觉和多模态领域的理论表述与实际实现相结合，该调查为研究人员和实践者建立了一个基础框架，并突出了约束优化和面向代理的提示设计等未充分探索的前沿领域。 <div>
arXiv:2502.11560v1 Announce Type: new 
Abstract: The rise of foundation models has shifted focus from resource-intensive fine-tuning to prompt engineering, a paradigm that steers model behavior through input design rather than weight updates. While manual prompt engineering faces limitations in scalability, adaptability, and cross-modal alignment, automated methods, spanning foundation model (FM) based optimization, evolutionary methods, gradient-based optimization, and reinforcement learning, offer promising solutions. Existing surveys, however, remain fragmented across modalities and methodologies. This paper presents the first comprehensive survey on automated prompt engineering through a unified optimization-theoretic lens. We formalize prompt optimization as a maximization problem over discrete, continuous, and hybrid prompt spaces, systematically organizing methods by their optimization variables (instructions, soft prompts, exemplars), task-specific objectives, and computational frameworks. By bridging theoretical formulation with practical implementations across text, vision, and multimodal domains, this survey establishes a foundational framework for both researchers and practitioners, while highlighting underexplored frontiers in constrained optimization and agent-oriented prompt design.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Unified Modeling Framework for Automated Penetration Testing</title>
<link>https://arxiv.org/abs/2502.11588</link>
<guid>https://arxiv.org/abs/2502.11588</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能, 自动化渗透测试, 模拟建模, 统系统回顾, AutoPT-Sim

总结:<br />
本文介绍了将人工智能应用于自动化渗透测试(AutoPT)中，模拟建模的重要性和需求。针对现有研究缺乏统一框架的问题，文章进行了系统性的文献回顾并提出了MDCPM分类方法，用于区分不同研究目标、网络模拟复杂度等因素。为填补多维度和多层次模拟建模的统一方法空缺，作者提出了一种名为AutoPT-Sim的新建模框架，该框架基于策略自动化，能够综合考虑各子维度，适应不同规模的动态网络环境建模。此外，文中还公开发布了一个生成的标准网络环境数据集以及网络生成器代码，支持针对MDCPM中的多种模拟建模层级进行灵活的数据集成，并允许研究人员通过调整参数或微调网络生成器以生成定制化的目标网络数据。 <div>
arXiv:2502.11588v1 Announce Type: new 
Abstract: The integration of artificial intelligence into automated penetration testing (AutoPT) has highlighted the necessity of simulation modeling for the training of intelligent agents, due to its cost-efficiency and swift feedback capabilities. Despite the proliferation of AutoPT research, there is a recognized gap in the availability of a unified framework for simulation modeling methods. This paper presents a systematic review and synthesis of existing techniques, introducing MDCPM to categorize studies based on literature objectives, network simulation complexity, dependency of technical and tactical operations, and scenario feedback and variation. To bridge the gap in unified method for multi-dimensional and multi-level simulation modeling, dynamic environment modeling, and the scarcity of public datasets, we introduce AutoPT-Sim, a novel modeling framework that based on policy automation and encompasses the combination of all sub dimensions. AutoPT-Sim offers a comprehensive approach to modeling network environments, attackers, and defenders, transcending the constraints of static modeling and accommodating networks of diverse scales. We publicly release a generated standard network environment dataset and the code of Network Generator. By integrating publicly available datasets flexibly, support is offered for various simulation modeling levels focused on policy automation in MDCPM and the network generator help researchers output customized target network data by adjusting parameters or fine-tuning the network generator.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>User-Centric Data Management in Decentralized Internet of Behaviors System</title>
<link>https://arxiv.org/abs/2502.11616</link>
<guid>https://arxiv.org/abs/2502.11616</guid>
<content:encoded><![CDATA[
<div> 关键词: Internet of Behaviors (IoB), 安全性, 隐私保护, 区块链, 分布式数据存储

总结:
本文探讨了互联网行为(IoB)领域的新兴概念及其在收集人类行为并提供智能服务方面的应用。文章指出了IoB在数据生成、上传和使用阶段的安全与隐私风险，并考虑到了用户活动区域的动态特性。为了解决这些问题，文章提出了一个基于区块链的分布式IoB数据存储和分享框架，该框架分为感知层、处理层和管理层三层。其中，在感知层利用零知识证明技术分离行为与身份之间的关联，同时实现跨域认证的分布式架构；处理层提出改进的共识协议，根据服务器地理位置和计算能力提升分布式IoB的决策效率；管理层则考虑了用户权限差异和访问目标的隐私，通过函数秘密共享实现不同类型行为的精细安全访问。模拟结果表明，所提框架在多场景IoB中表现出优越性能，平均共识时间和认证时间分别降低了74%和56%。 <div>
arXiv:2502.11616v1 Announce Type: new 
Abstract: The Internet of Behaviors (IoB) is an emerging concept that utilizes devices to collect human behavior and provide intelligent services. Although some research has focused on human behavior analysis and data collection within IoB, the associated security and privacy challenges remain insufficiently explored. This paper analyzes the security and privacy risks at different stages of behavioral data generating, uploading, and using, while also considering the dynamic characteristics of user activity areas. Then, we propose a blockchain-based distributed IoB data storage and sharing framework, which is categorized into sensing, processing, and management layers based on these stages. To accommodate both identity authentication and behavioral privacy, zero-knowledge proofs are used in the sensing layer to separate the correlation between behavior and identity, which is further extended to a distributed architecture for cross-domain authentication. In the processing layer, an improved consensus protocol is proposed to enhance the decision-making efficiency of distributed IoB by analyzing the geographical and computational capability of the servers. In the management layer, user permission differences and the privacy of access targets are considered. Different types of behavior are modeled as corresponding relationships between keys, and fine-grained secure access is achieved through function secret sharing. Simulation results demonstrate the effectiveness of the proposed framework in multi-scenario IoB, with average consensus and authentication times reduced by 74% and 56%, respectively.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deviation Ratings: A General, Clone-Invariant Rating Method</title>
<link>https://arxiv.org/abs/2502.11645</link>
<guid>https://arxiv.org/abs/2502.11645</guid>
<content:encoded><![CDATA[
<div> 关键词: multi-agent, normal-form games, strategic interactions, clone invariant rating, deviation ratings

总结:
该文探讨了多智能体或多任务评估场景中自然形成的正常形式游戏模型，这些场景由于存在战略性的（对抗性、合作性及混合动机）互动而被建模。文章着重指出，在这种框架下，是对策略（行动、政策、代理、模型、任务、提示等）进行评价，但N玩家的战略互动冗余和复杂性使得评级问题变得复杂。先前的工作提出了处理此类冗余问题的“克隆不变”评级方法，但仅限于双人零和（即严格竞争性）交互。本文则首次引入了基于粗相关均衡的N玩家一般和型克隆不变评级——偏差评级。该方法在包括LLMs评估在内的多个领域进行了探索应用。 <div>
arXiv:2502.11645v1 Announce Type: new 
Abstract: Many real-world multi-agent or multi-task evaluation scenarios can be naturally modelled as normal-form games due to inherent strategic (adversarial, cooperative, and mixed motive) interactions. These strategic interactions may be agentic (e.g. players trying to win), fundamental (e.g. cost vs quality), or complementary (e.g. niche finding and specialization). In such a formulation, it is the strategies (actions, policies, agents, models, tasks, prompts, etc.) that are rated. However, the rating problem is complicated by redundancy and complexity of N-player strategic interactions. Repeated or similar strategies can distort ratings for those that counter or complement them. Previous work proposed ``clone invariant'' ratings to handle such redundancies, but this was limited to two-player zero-sum (i.e. strictly competitive) interactions. This work introduces the first N-player general-sum clone invariant rating, called deviation ratings, based on coarse correlated equilibria. The rating is explored on several domains including LLMs evaluation.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation</title>
<link>https://arxiv.org/abs/2502.11649</link>
<guid>https://arxiv.org/abs/2502.11649</guid>
<content:encoded><![CDATA[
<div> 关键词：非合作游戏、意见形成、抵抗、确认偏误、资源约束、影响力惩罚、大规模语言模型、模拟、极化、信念转变、资源优化、辟谣策略

总结:
本文引入了一种新的非合作游戏模型来分析意见形成和抵抗过程，该模型结合了社会心理学中的确认偏误、资源约束以及影响力惩罚原则。模拟中采用大规模语言模型作为竞争影响人口的代理，对传播或反驳错误信息的消息施加处罚。该框架将资源优化整合进代理的决策过程中。研究发现，较高的确认偏误会加强群体内部的意见一致，但也会加剧整体极化；相反，较低的确认偏误会导致意见碎片化及个体信念改变受限。大力投资于高资源辟谣策略虽能短期内使人群与辟谣代理保持一致，但也存在资源耗尽和长期影响力的削弱风险。 <div>
arXiv:2502.11649v1 Announce Type: new 
Abstract: We introduce a novel non-cooperative game to analyse opinion formation and resistance, incorporating principles from social psychology such as confirmation bias, resource constraints, and influence penalties. Our simulation features Large Language Model (LLM) agents competing to influence a population, with penalties imposed for generating messages that propagate or counter misinformation. This framework integrates resource optimisation into the agents' decision-making process. Our findings demonstrate that while higher confirmation bias strengthens opinion alignment within groups, it also exacerbates overall polarisation. Conversely, lower confirmation bias leads to fragmented opinions and limited shifts in individual beliefs. Investing heavily in a high-resource debunking strategy can initially align the population with the debunking agent, but risks rapid resource depletion and diminished long-term influence.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Single-dimensional Contract Design: Efficient Algorithms and Learning</title>
<link>https://arxiv.org/abs/2502.11661</link>
<guid>https://arxiv.org/abs/2502.11661</guid>
<content:encoded><![CDATA[
<div> 关键词：Bayesian合同设计、单参数不确定性模型、乘法近似、加法近似、学习视角

总结:
本文研究了在代理人类型具有单参数不确定性的贝叶斯合同设计问题。文章关注于由Alon等人[2021]提出的单参数模型，并讨论了Castiglioni等人[2025]从多维度到单维度合同设计的减缩问题。文中给出了这类问题的一个加性PTAS（多项式时间近似算法），同时证明不存在加性FPTAS（完全多项式时间近似算法）。这一结果意味着从多维度到单维度的合同设计转换不能保持加性近似。此外，文章指出从学习的角度来看，单参数合同设计相比其多参数对应问题更为简单。在适度假设下，文章展示了如何有效学习最优合同，并提供了关于后悔值和样本复杂度的结果。 <div>
arXiv:2502.11661v1 Announce Type: new 
Abstract: We study a Bayesian contract design problem in which a principal interacts with an unknown agent. We consider the single-parameter uncertainty model introduced by Alon et al. [2021], in which the agent's type is described by a single parameter, i.e., the cost per unit-of-effort. Despite its simplicity, several works have shown that single-dimensional contract design is not necessarily easier than its multi-dimensional counterpart in many respects. Perhaps the most surprising result is the reduction by Castiglioni et al . [2025] from multi- to single-dimensional contract design. However, their reduction preserves only multiplicative approximations, leaving open the question of whether additive approximations are easier to obtain than multiplicative ones. In this paper, we answer this question--to some extent--positively. In particular, we provide an additive PTAS for these problems while also ruling out the existence of an additive FPTAS. This, in turn, implies that no reduction from multi- to single-dimensional contracts can preserve additive approximations. Moreover, we show that single-dimensional contract design is fundamentally easier than its multi-dimensional counterpart from a learning perspective. Under mild assumptions, we show that optimal contracts can be learned efficiently, providing results on both regret and sample complexity.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring LLM-based Student Simulation for Metacognitive Cultivation</title>
<link>https://arxiv.org/abs/2502.11678</link>
<guid>https://arxiv.org/abs/2502.11678</guid>
<content:encoded><![CDATA[
<div> 关键词：元认知教育、学习困难模拟、大型语言模型、自动评分系统、学生代理生成

总结:
本文介绍了通过使用大型语言模型来模拟具有学习困难的学生，以改进教学方法的研究工作。针对现有模拟未能真实反映学生的学习挑战以及评估过程中缺乏可靠指标和数据收集伦理约束的问题，文章提出了一种自动生成并过滤高质量模拟学生代理的管道。该管道采用经人类专家验证的两轮自动化评分系统，并利用得分传播模块实现学生图中更一致的分数。实验结果表明，该管道能有效识别高质量的学生代理，并讨论了影响模拟效果的关键特质。这项工作为个性化学习和教育评估中的不同学习难度学生的模拟应用铺平了道路。<br /><br /> <div>
arXiv:2502.11678v1 Announce Type: new 
Abstract: Metacognitive education plays a crucial role in cultivating students' self-regulation and reflective thinking, providing essential support for those with learning difficulties through academic advising. Simulating students with insufficient learning capabilities using large language models offers a promising approach to refining pedagogical methods without ethical concerns. However, existing simulations often fail to authentically represent students' learning struggles and face challenges in evaluation due to the lack of reliable metrics and ethical constraints in data collection. To address these issues, we propose a pipeline for automatically generating and filtering high-quality simulated student agents. Our approach leverages a two-round automated scoring system validated by human experts and employs a score propagation module to obtain more consistent scores across the student graph. Experimental results demonstrate that our pipeline efficiently identifies high-quality student agents, and we discuss the traits that influence the simulation's effectiveness. By simulating students with varying degrees of learning difficulties, our work paves the way for broader applications in personalized learning and educational assessment.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM Agents Making Agent Tools</title>
<link>https://arxiv.org/abs/2502.11705</link>
<guid>https://arxiv.org/abs/2502.11705</guid>
<content:encoded><![CDATA[
<div> 关键词: 工具生成、大型语言模型、代码仓库、自我校正机制、科学工作流

<br />
总结:
本文提出了一个名为ToolMaker的新颖框架，该框架能够自主地将带有代码的论文转化为适用于大型语言模型（LLMs）的工具。ToolMaker通过接收任务描述和代码库URL，自动安装所需依赖项并生成执行任务的代码，利用闭环自我校正机制迭代诊断和修正错误。为了评估其性能，作者构建了一个涵盖医疗与非医疗领域的15个复杂计算任务的基准测试，并包含超过100个单元测试来客观评价工具的正确性和鲁棒性。结果显示，ToolMaker成功完成了80%的任务，显著超越了当前最先进的软件工程代理。因此，ToolMaker朝着完全自主的基于代理的科学工作流方向迈出了重要一步。 <div>
arXiv:2502.11705v1 Announce Type: new 
Abstract: Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains which demand large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, a novel agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a short task description and a repository URL, ToolMaker autonomously installs required dependencies and generates code to perform the task, using a closed-loop self-correction mechanism to iteratively diagnose and rectify errors. To evaluate our approach, we introduce a benchmark comprising 15 diverse and complex computational tasks spanning both medical and non-medical domains with over 100 unit tests to objectively assess tool correctness and robustness. ToolMaker correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Recommendation Explanations through User-Centric Refinement</title>
<link>https://arxiv.org/abs/2502.11721</link>
<guid>https://arxiv.org/abs/2502.11721</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成自然语言解释、推荐系统、用户评价、多代理协同细化框架、大型语言模型

总结:
本文提出了一种针对推荐系统解释性提升的新方法。该方法旨在解决传统推荐系统解释在事实性、个性化和情感连贯性等方面存在的问题。文章提出了一个基于大型语言模型的多代理协同细化框架，在推理阶段对已有可解释推荐模型生成的初步解释进行多方面优化。为了确保细化过程与用户需求相一致，采用“计划-细化”模式执行有针对性的修改。同时，设计了一个层次化的反思机制，从战略和内容两个层面为细化过程提供反馈，以实现持续改进。通过在三个数据集上的大量实验，证明了该框架的有效性。<br /><br /> <div>
arXiv:2502.11721v1 Announce Type: new 
Abstract: Generating natural language explanations for recommendations has become increasingly important in recommender systems. Traditional approaches typically treat user reviews as ground truth for explanations and focus on improving review prediction accuracy by designing various model architectures. However, due to limitations in data scale and model capability, these explanations often fail to meet key user-centric aspects such as factuality, personalization, and sentiment coherence, significantly reducing their overall helpfulness to users. In this paper, we propose a novel paradigm that refines initial explanations generated by existing explainable recommender models during the inference stage to enhance their quality in multiple aspects. Specifically, we introduce a multi-agent collaborative refinement framework based on large language models. To ensure alignment between the refinement process and user demands, we employ a plan-then-refine pattern to perform targeted modifications. To enable continuous improvements, we design a hierarchical reflection mechanism that provides feedback on the refinement process from both strategic and content perspectives. Extensive experiments on three datasets demonstrate the effectiveness of our framework.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Plant in Cupboard, Orange on Table, Book on Shelf. Benchmarking Practical Reasoning and Situation Modelling in a Text-Simulated Situated Environment</title>
<link>https://arxiv.org/abs/2502.11733</link>
<guid>https://arxiv.org/abs/2502.11733</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)、自然语言交互、规划型智能体、环境复杂性、行动规划

<br /><br />总结:
本文探讨了大型语言模型（LLMs）作为自然语言聊天机器人外，应用于基于语言的规划型智能体的可能性。研究者构建了一个简单的文本环境，模拟家庭场景，用于测试LLMs在实践推理方面的能力——即从目标和观察推断出行动。实验发现，环境复杂性和游戏规则限制对LLMs的表现产生影响，同时，当前的LLMs在进行简洁的行动规划上表现具有挑战性。 <div>
arXiv:2502.11733v1 Announce Type: new 
Abstract: Large language models (LLMs) have risen to prominence as 'chatbots' for users to interact via natural language. However, their abilities to capture common-sense knowledge make them seem promising as language-based planners of situated or embodied action as well. We have implemented a simple text-based environment -- similar to others that have before been used for reinforcement-learning of agents -- that simulates, very abstractly, a household setting. We use this environment and the detailed error-tracking capabilities we implemented for targeted benchmarking of LLMs on the problem of practical reasoning: Going from goals and observations to actions. Our findings show that environmental complexity and game restrictions hamper performance, and concise action planning is demanding for current LLMs.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Changing the Rules of the Game: Reasoning about Dynamic Phenomena in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.11785</link>
<guid>https://arxiv.org/abs/2502.11785</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent systems (MAS), Alternating-Time Temporal Logic ($\mathsf{ATL}$), Logic for $\mathsf{ATL}$ Model Building ($\mathsf{LAMB}$), model checking, modifications

总结:
本文提出了一个针对多智能体系统（MAS）设计与修改影响分析的新逻辑——$\mathsf{LAMB}$，它是$\mathsf{ATL}$的一个扩展，能够处理模型动态变化的推理问题。$\mathsf{LAMB}$可用于表达从规范性更新到机制设计等关于MAS动态性的各种直觉和想法。文章主要技术成果表明，尽管$\mathsf{LAMB}$比$\mathsf{ATL}$具有更高的表达力，但其模型检查问题仍处于P完全复杂度级别。 <div>
arXiv:2502.11785v1 Announce Type: new 
Abstract: The design and application of multi-agent systems (MAS) require reasoning about the effects of modifications on their underlying structure. In particular, such changes may impact the satisfaction of system specifications and the strategic abilities of their autonomous components. In this paper, we are concerned with the problem of verifying and synthesising modifications (or \textit{updates}) of MAS. We propose an extension of the Alternating-Time Temporal Logic ($\mathsf{ATL}$) that enables reasoning about the dynamics of model change, called the \textit{Logic for $\mathsf{ATL}$ Model Building} ($\mathsf{LAMB}$). We show how $\mathsf{LAMB}$ can express various intuitions and ideas about the dynamics of MAS, from normative updates to mechanism design. As the main technical result, we prove that, while being strictly more expressive than $\mathsf{ATL}$, $\mathsf{LAMB}$ enjoys a P-complete model-checking procedure.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personality Editing for Language Models through Relevant Knowledge Editing</title>
<link>https://arxiv.org/abs/2502.11789</link>
<guid>https://arxiv.org/abs/2502.11789</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，个性控制，知识编辑，心理评估，调整查询

总结:
这篇论文介绍了PALETTE这一新方法，该方法针对大型语言模型（LLMs）在对话代理和内容创作等应用中的个性控制问题。传统的基于提示的个性控制技术往往不能有效缓解模型的内在偏见。PALETTE通过生成受心理评估启发的调整查询，系统地调整与个性相关查询的回答，类似于修改事实性知识，从而实现对个性特征的可控调整。实验结果显示，PALETTE方法能够在LLMs中实现更稳定、均衡的个性控制，并得到了自动和人类评估的验证。 <div>
arXiv:2502.11789v1 Announce Type: new 
Abstract: Large Language Models (LLMs) play a vital role in applications like conversational agents and content creation, where controlling a model's personality is crucial for maintaining tone, consistency, and engagement. However, traditional prompt-based techniques for controlling personality often fall short, as they do not effectively mitigate the model's inherent biases. In this paper, we introduce a novel method PALETTE that enhances personality control through knowledge editing. By generating adjustment queries inspired by psychological assessments, our approach systematically adjusts responses to personality-related queries similar to modifying factual knowledge, thereby achieving controlled shifts in personality traits. Experimental results from both automatic and human evaluations demonstrate that our method enables more stable and well-balanced personality control in LLMs.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning</title>
<link>https://arxiv.org/abs/2502.11799</link>
<guid>https://arxiv.org/abs/2502.11799</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、表推理任务、错误修正、多智能体框架、自进化模板树

总结:
本文针对大型语言模型在表推理任务中所面临的多步推理一致性问题以及现有方法在错误修正上的不足，提出了一种名为Table-Critic的创新性多智能体框架。该框架包括四个专门的智能体：用于错误识别的法官、提供全面批评的评论家、负责过程改进的精炼者和模式提炼的策展人。为有效应对多样化的不可预测错误类型，文章引入了自进化模板树，通过经验驱动的学习系统地积累批判知识并引导未来的反思。实验表明，Table-Critic相对于现有方法取得了显著的性能提升，表现出更高的准确性、错误修正率，同时保持了计算效率和较低的解退化率。 <div>
arXiv:2502.11799v1 Announce Type: new 
Abstract: Despite the remarkable capabilities of large language models (LLMs) in various reasoning tasks, they still struggle with table reasoning tasks, particularly in maintaining consistency throughout multi-step reasoning processes. While existing approaches have explored various decomposition strategies, they often lack effective mechanisms to identify and correct errors in intermediate reasoning steps, leading to cascading error propagation. To address these issues, we propose Table-Critic, a novel multi-agent framework that facilitates collaborative criticism and iterative refinement of the reasoning process until convergence to correct solutions. Our framework consists of four specialized agents: a Judge for error identification, a Critic for comprehensive critiques, a Refiner for process improvement, and a Curator for pattern distillation. To effectively deal with diverse and unpredictable error types, we introduce a self-evolving template tree that systematically accumulates critique knowledge through experience-driven learning and guides future reflections. Extensive experiments have demonstrated that Table-Critic achieves substantial improvements over existing methods, achieving superior accuracy and error correction rates while maintaining computational efficiency and lower solution degradation rate.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing the impacts of tradable credit schemes through agent-based simulation</title>
<link>https://arxiv.org/abs/2502.11822</link>
<guid>https://arxiv.org/abs/2502.11822</guid>
<content:encoded><![CDATA[
<div> 关键词: Tradable credit schemes, agent-based simulation, SimMobility, Bayesian Optimization, congestion reduction

<br /><br />总结:
本文提出了一个用于模拟可交易信用体系（Tradable Credit Schemes，TCS）的综合框架，并将其实现在开源城市模拟平台SimMobility中。该框架具有三个特点：(1) 弹性设计，考虑多次出行并细致刻画个体交易行为；(2) 模拟框架能捕捉TCS监管者、旅行者及TCS市场间的复杂互动，并可灵活测试未来TCS设计和相关移动模型；(3) 结合大规模介观多模式网络和贝叶斯优化方法进行TCS优化设计的模拟实验。实验结果表明，网络和市场的性能在日常过程中趋于稳定，证实了基于代理的模拟与TCS已知理论性质的一致性。文章进一步确认了在所采用的市场行为假设下，TCS在减少交通拥堵方面的效率，并为模拟不同个体行为开启了可能。此外，研究还量化分析了TCS对局部网络、异质用户以及不同出行行为的影响，并指出通过测试不同的TCS设计方案可以避免负面的市场交易行为。 <div>
arXiv:2502.11822v1 Announce Type: new 
Abstract: Tradable credit schemes (TCS) have been attracting interest from the transportation research community as an appealing alternative to congestion pricing, due to the advantages of revenue neutrality and equity. Nonetheless, existing research has largely employed network and market equilibrium approaches with simplistic characterizations of transportation demand, supply, credit market operations, and market behavior. Agent- and activity-based simulation affords a natural means to comprehensively assess TCS by more realistically modeling demand, supply, and individual market interactions. We propose an integrated simulation framework for modeling a TCS, and implements it within the state-of-the-art open-source urban simulation platform SimMobility, including: (a) a flexible TCS design that considers multiple trips and explicitly accounts for individual trading behaviors; (b) a simulation framework that captures the complex interactions between a TCS regulator, the traveler, and the TCS market itself, with the flexibility to test future TCS designs and relevant mobility models; and (c) a set of simulation experiments on a large mesoscopic multimodal network combined with a Bayesian Optimization approach for TCS optimal design. The experiment results indicate network and market performance to stabilize over the day-to-day process, showing the alignment of our agent-based simulation with the known theoretical properties of TCS. We confirm the efficiency of TCS in reducing congestion under the adopted market behavioral assumptions and open the door for simulating different individual behaviors. We measure how TCS impacts differently the local network, heterogeneous users, the different travel behaviors, and how testing different TCS designs can avoid negative market trading behaviors.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can LLM Agents Maintain a Persona in Discourse?</title>
<link>https://arxiv.org/abs/2502.11843</link>
<guid>https://arxiv.org/abs/2502.11843</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型(LMMs)、人格特质、OCEAN框架、对话一致性、多代理评估

总结:
本文探讨了大型语言模型（LLMs）作为对话代理人时在维持人格特质一致性方面所面临的挑战。研究通过两个视角进行分析：首先，使用两个对话代理人根据OCEAN框架中的高/低特质生成特定话题的对话；随后，利用多个判断代理人来推断原始赋予的人格特质，以此探索预测一致性、模型间的一致性和与预设人格的对齐程度。结果表明，虽然可以引导LLMs进行基于人格特征的对话，但它们在不同模型组合和对话环境下保持人格特质的能力存在显著差异，强调了实现稳定、可解释的人格特征对齐交互在LLMs中仍面临困难。 <div>
arXiv:2502.11843v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are widely used as conversational agents, exploiting their capabilities in various sectors such as education, law, medicine, and more. However, LLMs are often subjected to context-shifting behaviour, resulting in a lack of consistent and interpretable personality-aligned interactions. Adherence to psychological traits lacks comprehensive analysis, especially in the case of dyadic (pairwise) conversations. We examine this challenge from two viewpoints, initially using two conversation agents to generate a discourse on a certain topic with an assigned personality from the OCEAN framework (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) as High/Low for each trait. This is followed by using multiple judge agents to infer the original traits assigned to explore prediction consistency, inter-model agreement, and alignment with the assigned personality. Our findings indicate that while LLMs can be guided toward personality-driven dialogue, their ability to maintain personality traits varies significantly depending on the combination of models and discourse settings. These inconsistencies emphasise the challenges in achieving stable and interpretable personality-aligned interactions in LLMs.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?</title>
<link>https://arxiv.org/abs/2502.11864</link>
<guid>https://arxiv.org/abs/2502.11864</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、不确定性、感知、自动驾驶、行为影响

总结:
本文探讨了在实际场景如自动驾驶中，智能体如何应对环境中的不确定性，特别是感知不确定性。虽然强化学习致力于在不确定性下自主决策，但通常并未将环境中当前的不确定性信息告知算法。研究重点在于不确定性估计对感知本身的影响主要直接在感知域内评估，而对其在目标导向行动上的应用则鲜有研究。文章通过设定一个代理任务——奖励快速行驶且不与其他道路使用者发生碰撞的驾驶行为，来探究不确定感知对智能体行为的影响以及当智能体接收到关于此不确定性的信息时其行为的变化。实验通过在观察空间引入观测感知扰动以模拟不可靠的观察空间，结果显示这会导致智能体采取防御性驾驶行为。然而，当直接向观察空间添加当前不确定性信息时，智能体会根据具体情境进行适应，总体上能更快地完成任务的同时更好地考虑风险因素。 <div>
arXiv:2502.11864v1 Announce Type: new 
Abstract: Agents in real-world scenarios like automated driving deal with uncertainty in their environment, in particular due to perceptual uncertainty. Although, reinforcement learning is dedicated to autonomous decision-making under uncertainty these algorithms are typically not informed about the uncertainty currently contained in their environment. On the other hand, uncertainty estimation for perception itself is typically directly evaluated in the perception domain, e.g., in terms of false positive detection rates or calibration errors based on camera images. Its use for deciding on goal-oriented actions remains largely unstudied. In this paper, we investigate how an agent's behavior is influenced by an uncertain perception and how this behavior changes if information about this uncertainty is available. Therefore, we consider a proxy task, where the agent is rewarded for driving a route as fast as possible without colliding with other road users. For controlled experiments, we introduce uncertainty in the observation space by perturbing the perception of the given agent while informing the latter. Our experiments show that an unreliable observation space modeled by a perturbed perception leads to a defensive driving behavior of the agent. Furthermore, when adding the information about the current uncertainty directly to the observation space, the agent adapts to the specific situation and in general accomplishes its task faster while, at the same time, accounting for risks.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models</title>
<link>https://arxiv.org/abs/2502.11881</link>
<guid>https://arxiv.org/abs/2502.11881</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM、reasoning方法、mental states、thought-tracing、Bayesian理论心智框架

<br /><br />总结：
该文提出了一种名为“thought-tracing”的推理算法，旨在通过生成假设并依据观察结果对特定代理人的心理状态进行权重分配，从而追踪其心理状态。这一算法受序列蒙特卡洛算法启发，遵循贝叶斯理论心智框架，利用大型语言模型（LLMs）对代理人基于感知和行动而演变的心理状态进行概率推断，而不依赖于数据集中问题的正确答案或规则验证方法。实验证实在多样化的理论心智基准测试上，thought-tracing相比于基线LLMs展现出显著的性能提升。实验还揭示了近期推理模型在社会推理领域的有趣行为，强调了与其它领域相比的社会推理差异。 <div>
arXiv:2502.11881v1 Announce Type: new 
Abstract: Existing LLM reasoning methods have shown impressive capabilities across various tasks, such as solving math and coding problems. However, applying these methods to scenarios without ground-truth answers or rule-based verification methods - such as tracking the mental states of an agent - remains challenging. Inspired by the sequential Monte Carlo algorithm, we introduce thought-tracing, an inference-time reasoning algorithm designed to trace the mental states of specific agents by generating hypotheses and weighting them based on observations without relying on ground-truth solutions to questions in datasets. Our algorithm is modeled after the Bayesian theory-of-mind framework, using LLMs to approximate probabilistic inference over agents' evolving mental states based on their perceptions and actions. We evaluate thought-tracing on diverse theory-of-mind benchmarks, demonstrating significant performance improvements compared to baseline LLMs. Our experiments also reveal interesting behaviors of the recent reasoning models - e.g., o1 and R1 - on theory-of-mind, highlighting the difference of social reasoning compared to other domains.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2502.11882</link>
<guid>https://arxiv.org/abs/2502.11882</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、实时互动、双过程理论、DPT-Agent、有限状态机

<br />
总结:
本文提出了一种名为DPT-Agent的新颖语言代理框架，该框架针对实时同步的人工智能与人类协作任务进行了优化。现有的基于大规模语言模型（LLMs）的代理在实时任务中表现不佳，主要受制于延迟问题和难以推断变化的人类策略。通过实验证明，在实时任务中应用双过程理论（DPT）的必要性。DPT-Agent结合了System 1和System 2，其中System 1利用有限状态机（FSM）和代码策略实现快速、直观且可控的决策；而System 2则整合了心智理论（ToM）和异步反思来推理人类意图并进行基于推理的自主决策。实验结果显示，DPT-Agent相比于主流的LLM基线框架有显著提升，并实现了成功的实时同步人-机协作。据所知，DPT-Agent是首个成功实现这一目标的语言代理框架。相关代码可在https://github.com/sjtu-marl/DPT-Agent找到。 <div>
arXiv:2502.11882v1 Announce Type: new 
Abstract: Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CAMEL: Continuous Action Masking Enabled by Large Language Models for Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.11896</link>
<guid>https://arxiv.org/abs/2502.11896</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (Reinforcement Learning, RL), 连续动作空间 (Continuous Action Spaces), CAMEL, 语言模型生成策略 (LLM-Generated Suboptimal Policies), 动态行动掩码 (Dynamic Action Masking)

总结:
本文提出了一种新的强化学习框架CAMEL，用于解决连续动作空间中探索效率低和易收敛至次优解的问题。CAMEL将基于环境描述和任务目标由LLMs生成的简化的硬编码次优策略整合到RL训练流程中，利用动态行动掩码和自适应ε掩码机制在早期训练阶段引导探索，并逐渐使智能体能够独立优化策略。CAMEL的核心在于运用LLM输出来动态约束行动空间的、具有掩码感知的优化方法。实验结果表明，在Gymnasium MuJoCo环境中，CAMEL在Hopper-v4和Ant-v4上显著提高了样例效率，达到了与专家掩码基线相当或更优的表现；对于难以准确建模双足步态动力学的Walker2d-v4，CAMEL仍保持了稳健的RL性能，展现了其对多样化任务的适应性。虽然CAMEL展示出了增强样例效率和缓解收敛问题的潜力，但这些问题仍有待进一步研究。未来的工作将致力于将CAMEL推广到多模态LLMs以应对更广泛的观察-动作空间，并自动进行策略评估，从而减少人为干预并提升RL训练管道的可扩展性。 <div>
arXiv:2502.11896v1 Announce Type: new 
Abstract: Reinforcement learning (RL) in continuous action spaces encounters persistent challenges, such as inefficient exploration and convergence to suboptimal solutions. To address these limitations, we propose CAMEL, a novel framework integrating LLM-generated suboptimal policies into the RL training pipeline. CAMEL leverages dynamic action masking and an adaptive epsilon-masking mechanism to guide exploration during early training stages while gradually enabling agents to optimize policies independently. At the core of CAMEL lies the integration of Python-executable suboptimal policies generated by LLMs based on environment descriptions and task objectives. Although simplistic and hard-coded, these policies offer valuable initial guidance for RL agents. To effectively utilize these priors, CAMEL employs masking-aware optimization to dynamically constrain the action space based on LLM outputs. Additionally, epsilon-masking gradually reduces reliance on LLM-generated guidance, enabling agents to transition from constrained exploration to autonomous policy refinement. Experimental validation on Gymnasium MuJoCo environments demonstrates the effectiveness of CAMEL. In Hopper-v4 and Ant-v4, LLM-generated policies significantly improve sample efficiency, achieving performance comparable to or surpassing expert masking baselines. For Walker2d-v4, where LLMs struggle to accurately model bipedal gait dynamics, CAMEL maintains robust RL performance without notable degradation, highlighting the framework's adaptability across diverse tasks. While CAMEL shows promise in enhancing sample efficiency and mitigating convergence challenges, these issues remain open for further research. Future work aims to generalize CAMEL to multimodal LLMs for broader observation-action spaces and automate policy evaluation, reducing human intervention and enhancing scalability in RL training pipelines.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FitLight: Federated Imitation Learning for Plug-and-Play Autonomous Traffic Signal Control</title>
<link>https://arxiv.org/abs/2502.11937</link>
<guid>https://arxiv.org/abs/2502.11937</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 交通信号控制, 联邦模仿学习, FitLight, 资源约束

总结:<br />
本文提出了一种名为FitLight的新颖联邦模仿学习（FIL）框架，用于多交叉口交通信号控制（TSC），旨在解决基于强化学习（RL）的TSC方法面临的高学习成本和较差泛化性问题。FitLight允许RL代理在无需额外预训练的情况下即插即用适应任何交通环境。与依赖预训练演示的现有模仿学习方法不同，FitLight支持实时模仿学习和无缝过渡到强化学习。通过提出的知识共享机制和混合压力型代理设计，RL代理能在少数几集中快速找到最佳控制策略。此外，对于资源受限的TSC场景，FitLight还支持模型剪枝和异构模型聚合，使RL代理能在仅拥有16KB RAM和32KB ROM的微控制器上运行。实验表明，相比于现有最优方法，FitLight不仅提供了更优的起点，而且在真实世界和合成数据集上都能收敛至更好的最终解决方案，即使在极端资源限制下也是如此。 <div>
arXiv:2502.11937v1 Announce Type: new 
Abstract: Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC) methods have been extensively studied, their practical applications still raise some serious issues such as high learning cost and poor generalizability. This is because the ``trial-and-error'' training style makes RL agents extremely dependent on the specific traffic environment, which also requires a long convergence time. To address these issues, we propose a novel Federated Imitation Learning (FIL)-based framework for multi-intersection TSC, named FitLight, which allows RL agents to plug-and-play for any traffic environment without additional pre-training cost. Unlike existing imitation learning approaches that rely on pre-training RL agents with demonstrations, FitLight allows real-time imitation learning and seamless transition to reinforcement learning. Due to our proposed knowledge-sharing mechanism and novel hybrid pressure-based agent design, RL agents can quickly find a best control policy with only a few episodes. Moreover, for resource-constrained TSC scenarios, FitLight supports model pruning and heterogeneous model aggregation, such that RL agents can work on a micro-controller with merely 16{\it KB} RAM and 32{\it KB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art methods, FitLight not only provides a superior starting point but also converges to a better final solution on both real-world and synthetic datasets, even under extreme resource limitations.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Transaction Fee Market Design for Parallel Execution</title>
<link>https://arxiv.org/abs/2502.11964</link>
<guid>https://arxiv.org/abs/2502.11964</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、可扩展性、并行执行、交易费用机制、Gas 计算机制

总结:
本文关注于解决比特币和以太坊等区块链系统低吞吐量的问题，提出了通过并行执行交易来提高可扩展性的方法。文章指出当前的交易费用市场设计不利于有效的并行执行，因为它并未区分访问多个高需求资源与单一低需求资源的交易成本差异。为弥合这一差距，作者提出了一种新的框架，包括两个关键组件：Gas 计算机制（GCM），用于量化交易对网络负载的影响，基于平行化和计算资源消耗以gas单位衡量；以及交易费用机制（TFM），负责为每个gas单元定价。文章还定义了GCM的理想属性，并探讨了几种候选机制，其中加权面积GCM表现突出，能与现有如EIP-1559的TFM无缝结合。此外，文中还讨论了如何将该执行组件相关的费用机制与其他因素（如存储和数据带宽）相关联的费用相结合，构想了一个多维度的费用市场模型。 <div>
arXiv:2502.11964v1 Announce Type: new 
Abstract: Given the low throughput of blockchains like Bitcoin and Ethereum, scalability -- the ability to process an increasing number of transactions -- has become a central focus of blockchain research. One promising approach is the parallelization of transaction execution across multiple threads. However, achieving efficient parallelization requires a redesign of the incentive structure within the fee market. Currently, the fee market does not differentiate between transactions that access multiple high-demand resources versus a single low-demand one, as long as they require the same computational effort. Addressing this discrepancy is crucial for enabling more effective parallel execution.
  In this work, we aim to bridge the gap between the current fee market and the need for parallel execution by exploring alternative fee market designs. To this end, we propose a framework consisting of two key components: a Gas Computation Mechanism (GCM), which quantifies the load a transaction places on the network in terms of parallelization and computation, measured in units of gas, and a Transaction Fee Mechanism (TFM), which assigns a price to each unit of gas. We also introduce a set of desirable properties for a GCM, present multiple candidate mechanisms, and evaluate them against the properties. One promising candidate emerges: the weighted area GCM. Notably, this mechanism can be seamlessly composed with existing TFMs, such as EIP-1559. While our exploration primarily focuses on the execution component of the fee, which directly relates to parallel execution, we also outline how it could be integrated with fees associated with other factors, such as storage and data bandwidth, by drawing a parallel to a multi-dimensional fee market.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Machine Learning Should Maximize Welfare, Not (Only) Accuracy</title>
<link>https://arxiv.org/abs/2502.11981</link>
<guid>https://arxiv.org/abs/2502.11981</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、社会福利、预测、福利经济学、应用框架

总结:<br />
本文是一篇立场论文，主张将社会福利的理念融入到机器学习中。文章指出，虽然现有的机器学习工具能提高预测准确性，但单纯提升准确性并不一定能带来更好的社会效益。作者引用了福利经济学的视角，探讨如何通过优化资源分配来最大化社会利益，认为这一理念适用于许多涉及人类和社会环境的现代机器学习应用。为此，他们提出了一种概念框架，该框架逐步从单纯的准确性最大化过渡到兼顾并促进社会福利的最大化。文中还列举了该框架可能有效的应用场景和技术挑战，并指出了未来的研究方向。 <div>
arXiv:2502.11981v1 Announce Type: new 
Abstract: Decades of research in machine learning have given us powerful tools for making accurate predictions. But when used in social settings and on human inputs, better accuracy does not immediately translate to better social outcomes. This may not be surprising given that conventional learning frameworks are not designed to express societal preferences -- let alone promote them. This position paper argues that machine learning is currently missing, and can gain much from incorporating, a proper notion of social welfare. The field of welfare economics asks: how should we allocate limited resources to self-interested agents in a way that maximizes social benefit? We argue that this perspective applies to many modern applications of machine learning in social contexts, and advocate for its adoption. Rather than disposing of prediction, we aim to leverage this forte of machine learning for promoting social welfare. We demonstrate this idea by proposing a conceptual framework that gradually transitions from accuracy maximization (with awareness to welfare) to welfare maximization (via accurate prediction). We detail applications and use-cases for which our framework can be effective, identify technical challenges and practical opportunities, and highlight future avenues worth pursuing.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Design Considerations Based on Stability for a Class of TCP Algorithms</title>
<link>https://arxiv.org/abs/2502.11983</link>
<guid>https://arxiv.org/abs/2502.11983</guid>
<content:encoded><![CDATA[
<div> 关键词：TCP、流体模型、局部稳定性、设计考虑、网络拓扑

总结:<br />
本文针对互联网主导传输协议TCP的稳定性问题进行了研究，重点探讨了流体模型在TCP设计与性能评估中的关键作用。文章提出了在异构往返延迟存在下，一类TCP算法的局部稳定性充分条件。在此通用模型中，特别分析了TCP Reno、Compound TCP和Scalable TCP三种具体的TCP变体。作者推导出了适用于具有单个、两个及多个瓶颈链路网络拓扑的可扩展稳定性条件。由于小容量缓冲区可以提供更小的队列延迟，因此文章重点关注具有中间或小规模drop-tail缓存的网络。遵循提出的設計考慮因素，TCP算法可以在任何网络拓扑上实现稳定运行，无论网络中存在多少瓶颈链接或延迟。 <div>
arXiv:2502.11983v1 Announce Type: new 
Abstract: Transmission Control Protocol (TCP) continues to be the dominant transport protocol on the Internet. The stability of fluid models has been a key consideration in the design of TCP and the performance evaluation of TCP algorithms. Based on local stability analysis, we formulate some design considerations for a class of TCP algorithms. We begin with deriving sufficient conditions for the local stability of a generalized TCP algorithm in the presence of heterogeneous round-trip delays. Within this generalized model, we consider three specific variants of TCP: TCP Reno, Compound TCP, and Scalable TCP. The sufficient conditions we derive are scalable across network topologies with one, two, and many bottleneck links. We are interested in networks with intermediate and small drop-tail buffers as they offer smaller queuing delays. The small buffer regime is more attractive as the conditions for stability are decentralized. TCP algorithms that follow our design considerations can provide stable operation on any network topology, irrespective of the number of bottleneck links or delays in the network.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-agent coordination via communication partitions</title>
<link>https://arxiv.org/abs/2502.12042</link>
<guid>https://arxiv.org/abs/2502.12042</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、纳什均衡、协调、通信分区、社会最优

总结:
本文关注的是在存在多个纳什均衡的情况下，如何通过自我利益主体间的预游戏通信来协调多智能体系统的行为。研究中提出了一个通信分区方案，仅允许同一流派内的玩家之间进行沟通，并要求他们达成的协议需满足无嫉妒、可信以及帕累托最优这三个条件。作者证明了在满足对称性这一自然假设下，某些通信分区能够在单例拥堵游戏中诱导出社会最优结果。该拥堵游戏模型了一个去中心化、匿名系统，其中玩家需要从一系列等价资源中选择，并且因与其他玩家共享相同资源而导致的成本呈递增和凸性增长。因此，这种通信分区机制可被视为诱导此类情境下有效率结果的一种手段。<br /><br /> <div>
arXiv:2502.12042v1 Announce Type: new 
Abstract: Coordinating the behaviour of self-interested agents in the presence of multiple Nash equilibria is a major research challenge for multi-agent systems. Pre-game communication between all the players can aid coordination in cases where the Pareto-optimal payoff is unique, but can lead to deadlocks when there are multiple payoffs on the Pareto frontier. We consider a communication partition, where only players within the same coalition can communicate with each other, and they can establish an agreement (a coordinated joint-action) if it is envy-free, credible, and Pareto-optimal. We show that under a natural assumption about symmetry, certain communication partitions can induce social optimal outcomes in singleton congestion games. This game is a reasonable model for a decentralised, anonymous system where players are required to choose from a range of identical resources, and incur costs that are increasing and convex in the total number of players sharing the same resource. The communication partition can be seen as a mechanism for inducing efficient outcomes in this context.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A survey about perceptions of mobility to inform an agent-based simulator of subjective modal choice</title>
<link>https://arxiv.org/abs/2502.12058</link>
<guid>https://arxiv.org/abs/2502.12058</guid>
<content:encoded><![CDATA[
<div> 关键词：气候改变、公共健康、软流动性、感知偏见、多准则决策模型

总结:<br />
针对气候变化和公共健康问题，城市政策正努力推广软流动性，但汽车使用比例仍然较高。本文研究了感知偏见对个人出行选择的影响。作者构建了一个融合习惯与偏见影响的多准则决策模型，并进行了包含650份响应的在线调查，以计算出真实的出行感知值。这些数据被用于初始化Netlogo中的一个模态选择模拟器的环境和人口。该模拟器能够展示在城市规划变化情况下，出行模式分布如何适应，特别是当考虑或不考虑个体推理中的习惯和偏见时的情况。此外，这是对在JFSMA-JFMS 2024会议上发表的法语文献“Un simulateur multi-agent de choix modal subjectif”的扩展和翻译版本。 <div>
arXiv:2502.12058v1 Announce Type: new 
Abstract: In order to adapt to the issues of climate change and public health, urban policies are trying to encourage soft mobility, but the share of the car remains significant. Beyond known constraints, we study here the impact of perception biases on individual choices. We designed a multi-criteria decision model, integrating the influence of habits and biases. We then conducted an online survey, which received 650 responses. We used these to calculate realistic mobility perception values, in order to initialise the environment and the population of a modal choice simulator, implemented in Netlogo. This allows us to visualize the adaptation of the modal distribution in reaction to the evolution of urban planning, depending on whether or not we activate biases and habits in individual reasoning.
  This is an extended and translated version of a demo paper published in French at JFSMA-JFMS 2024 "Un simulateur multi-agent de choix modal subjectif"
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can LLMs Simulate Social Media Engagement? A Study on Action-Guided Response Generation</title>
<link>https://arxiv.org/abs/2502.12073</link>
<guid>https://arxiv.org/abs/2502.12073</guid>
<content:encoded><![CDATA[
<div> 关键词：社交媒体、大型语言模型、响应生成、行为预测、GPT-4o-mini<br /><br />总结:
本文研究了大型语言模型（LLMs）在模拟社交媒体用户动态参与趋势话题的能力。文章重点关注了通过行动引导的响应生成方法，即模型首先预测用户对热门帖子最可能采取的互动行为——转发、引用或改写，然后再根据预测的行为生成个性化回应。研究中，作者对比了GPT-4o-mini、O1-mini和DeepSeek-R1在模拟社交媒体对于社会重大事件讨论中的表现，结果表明零样本的LLM在行为预测上逊色于BERT，而有限示例的微调最初会降低LLMs的预测准确性。然而，在响应生成方面，少量样本训练的LLMs能实现与真实帖子更强的语义对齐。 <div>
arXiv:2502.12073v1 Announce Type: new 
Abstract: Social media enables dynamic user engagement with trending topics, and recent research has explored the potential of large language models (LLMs) for response generation. While some studies investigate LLMs as agents for simulating user behavior on social media, their focus remains on practical viability and scalability rather than a deeper understanding of how well LLM aligns with human behavior. This paper analyzes LLMs' ability to simulate social media engagement through action guided response generation, where a model first predicts a user's most likely engagement action-retweet, quote, or rewrite-towards a trending post before generating a personalized response conditioned on the predicted action. We benchmark GPT-4o-mini, O1-mini, and DeepSeek-R1 in social media engagement simulation regarding a major societal event discussed on X. Our findings reveal that zero-shot LLMs underperform BERT in action prediction, while few-shot prompting initially degrades the prediction accuracy of LLMs with limited examples. However, in response generation, few-shot LLMs achieve stronger semantic alignment with ground truth posts.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Study on Leveraging Search and Self-Feedback for Agent Reasoning</title>
<link>https://arxiv.org/abs/2502.12094</link>
<guid>https://arxiv.org/abs/2502.12094</guid>
<content:encoded><![CDATA[
<div> 关键词：搜索、模型自反馈、推理任务、数学推理、工具调用

总结:
该研究探索了在推理任务中如何利用搜索和模型自我反馈。首先，对比分析了在数学推理任务中使用真实反馈与自我反馈进行搜索的区别。其次，针对更复杂的如工具调用等任务，研究发现现有搜索技术的应用存在局限性，并提出了针对特定任务的设计方法来填补这些空白。实验揭示，仅依赖自我反馈进行搜索时，可能会遇到泛化能力方面的挑战。因此，要使搜索有效地工作，要么需要访问真实反馈，要么需为具体任务精心设计反馈机制。 <div>
arXiv:2502.12094v1 Announce Type: new 
Abstract: Recent works have demonstrated that incorporating search during inference can significantly improve reasoning capabilities of language agents. Some approaches may make use of the ground truth or rely on model's own generated feedback. The search algorithm uses this feedback to then produce values that will update its criterion for exploring and exploiting various reasoning paths. In this study, we investigate how search and model's self-feedback can be leveraged for reasoning tasks. First, we explore differences in ground-truth feedback and self-feedback during search for math reasoning. Second, we observe limitations in applying search techniques to more complex tasks like tool-calling and design domain-specific approaches to address these gaps. Our experiments reveal challenges related to generalization when solely relying on self-feedback during search. For search to work effectively, either access to the ground-truth is needed or feedback mechanisms need to be carefully designed for the specific task.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Relational Norms for Human-AI Cooperation</title>
<link>https://arxiv.org/abs/2502.12102</link>
<guid>https://arxiv.org/abs/2502.12102</guid>
<content:encoded><![CDATA[
<div> 关键词：社会人工智能、关系规范、人类互动、设计、伦理

总结:<br />
本文探讨了如何根据人工智能所模拟或占据的社会角色来设计和互动。随着AI系统和聊天机器人越来越多地承担起类似教师、心理治疗师、导师或伴侣等人类社会角色，将人类关系规范延伸至人机交互变得至关重要。文章通过哲学家、心理学家、关系科学家、伦理学家、法律专家和AI研究人员的合作分析，研究了AI系统的无意识体验和抗疲劳等特点对履行特定关系功能及遵守相应规范的能力的影响。虽然承认AI系统能在某些社会关系角色中带来如增强可用性和一致性的好处，但同时也存在引发不健康依赖或对人类关系产生不合理期待的风险。因此，文章提出理解和谨慎塑造适宜的人机关系规范对于确保人机交互的道德性、可信赖性以及有利于人类福祉具有重要意义。 <div>
arXiv:2502.12102v1 Announce Type: new 
Abstract: How we should design and interact with social artificial intelligence depends on the socio-relational role the AI is meant to emulate or occupy. In human society, relationships such as teacher-student, parent-child, neighbors, siblings, or employer-employee are governed by specific norms that prescribe or proscribe cooperative functions including hierarchy, care, transaction, and mating. These norms shape our judgments of what is appropriate for each partner. For example, workplace norms may allow a boss to give orders to an employee, but not vice versa, reflecting hierarchical and transactional expectations. As AI agents and chatbots powered by large language models are increasingly designed to serve roles analogous to human positions - such as assistant, mental health provider, tutor, or romantic partner - it is imperative to examine whether and how human relational norms should extend to human-AI interactions. Our analysis explores how differences between AI systems and humans, such as the absence of conscious experience and immunity to fatigue, may affect an AI's capacity to fulfill relationship-specific functions and adhere to corresponding norms. This analysis, which is a collaborative effort by philosophers, psychologists, relationship scientists, ethicists, legal experts, and AI researchers, carries important implications for AI systems design, user behavior, and regulation. While we accept that AI systems can offer significant benefits such as increased availability and consistency in certain socio-relational roles, they also risk fostering unhealthy dependencies or unrealistic expectations that could spill over into human-human relationships. We propose that understanding and thoughtfully shaping (or implementing) suitable human-AI relational norms will be crucial for ensuring that human-AI interactions are ethical, trustworthy, and favorable to human well-being.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A-MEM: Agentic Memory for LLM Agents</title>
<link>https://arxiv.org/abs/2502.12110</link>
<guid>https://arxiv.org/abs/2502.12110</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、记忆系统、Zettelkasten方法、动态链接、适应性

总结:
这篇论文提出了一种针对大型语言模型（LLM）的新型代理式记忆系统，旨在解决现有记忆系统缺乏复杂记忆组织和适应性的问题。该系统借鉴了Zettelkasten方法的基本原理，通过动态索引和链接创建相互连接的知识网络。新添加的记忆会被转化为包含上下文描述、关键词和标签等多重结构属性的综合笔记，并与历史记忆进行分析比较，建立有意义的相关链接。此外，当新记忆被整合时，它可以触发对已有历史记忆的上下文表示和属性的更新，从而让记忆网络不断优化其理解。此方法将Zettelkasten的结构化组织原则与代理驱动决策的灵活性相结合，实现了更适应性和情境感知的记忆管理。实验证明，该方法在六个基础模型上对比现有SOTA基线有显著改进。源代码已发布于https://github.com/WujiangXu/AgenticMemory。 <div>
arXiv:2502.12110v1 Announce Type: new 
Abstract: While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code is available at https://github.com/WujiangXu/AgenticMemory.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scaling Autonomous Agents via Automatic Reward Modeling And Planning</title>
<link>https://arxiv.org/abs/2502.12130</link>
<guid>https://arxiv.org/abs/2502.12130</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、决策制定、环境反馈、奖励模型、自动学习

<br /><br />总结:
本文提出了一种针对大型语言模型（LLMs）的框架，旨在解决其在多步决策和环境反馈任务中的局限性。由于收集大规模决策数据困难以及许多强大的LLM仅通过API访问，导致对其微调以适应代理任务的成本和复杂性较高。该框架能自动生成奖励模型，无需人类标注，从而评估LLM代理的任务行为并提供规划策略。方法主要包括：使用一个基于LLM的代理随机探索环境生成多样化的行动轨迹；再利用另一个LLM为每个轨迹分配任务意图并合成正负响应；这些三元组作为训练数据用于优化能够评分行动轨迹的奖励模型。通过在不同代理基准上的评估证明了该框架的有效性和泛化能力。总之，此研究提出的框架显著提升了LLM代理的决策制定能力，通过自动化学习奖励模型克服了数据稀缺和API限制问题，有望引领LLMs在复杂互动环境中应用的革命性进展，为解决实际世界中涉及多步决策的问题开辟新途径。 <div>
arXiv:2502.12130v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a range of text-generation tasks. However, LLMs still struggle with problems requiring multi-step decision-making and environmental feedback, such as online shopping, scientific reasoning, and mathematical problem-solving. Unlike pure text data, collecting large-scale decision-making data is challenging. Moreover, many powerful LLMs are only accessible through APIs, which hinders their fine-tuning for agent tasks due to cost and complexity. To address LLM agents' limitations, we propose a framework that can automatically learn a reward model from the environment without human annotations. This model can be used to evaluate the action trajectories of LLM agents and provide heuristics for task planning. Specifically, our approach involves employing one LLM-based agent to navigate an environment randomly, generating diverse action trajectories. Subsequently, a separate LLM is leveraged to assign a task intent and synthesize a negative response alongside the correct response for each trajectory. These triplets (task intent, positive response, and negative response) are then utilized as training data to optimize a reward model capable of scoring action trajectories. The effectiveness and generalizability of our framework are demonstrated through evaluations conducted on different agent benchmarks. In conclusion, our proposed framework represents a significant advancement in enhancing LLM agents' decision-making capabilities. By automating the learning of reward models, we overcome the challenges of data scarcity and API limitations, potentially revolutionizing the application of LLMs in complex and interactive environments. This research paves the way for more sophisticated AI agents capable of tackling a wide range of real-world problems requiring multi-step decision-making.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HARBOR: Exploring Persona Dynamics in Multi-Agent Competition</title>
<link>https://arxiv.org/abs/2502.12149</link>
<guid>https://arxiv.org/abs/2502.12149</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM代理人、多智能体环境、拍卖、人格影响、竞标策略<br /><br />总结: 本文探讨了LLM代理人在竞技性多智能体环境中成功的关键因素，以拍卖作为实验平台，研究代理人为最大化利润而投标的行为。各代理人拥有特定的物品偏好人格以及拍卖历史记忆。文章通过构建一个现实情境——多个代理人为争取最理想的房屋进行投标，同时考虑房屋大小、位置和预算等因素。研究聚焦三个核心问题：(a) 人格如何影响代理人在竞争环境中的行为？(b) 代理人在拍卖过程中能否有效地刻画竞争对手的行为模式？(c) 如何利用人格画像与心智理论策略创造竞争优势？一系列实验分析了LLM代理人的行为并揭示了新发现。文中提出的实验平台HARBOR为深入理解竞技性多智能体工作流程提供了宝贵工具。 <div>
arXiv:2502.12149v1 Announce Type: new 
Abstract: We investigate factors contributing to LLM agents' success in competitive multi-agent environments, using auctions as a testbed where agents bid to maximize profit. The agents are equipped with bidding domain knowledge, distinct personas that reflect item preferences, and a memory of auction history. Our work extends the classic auction scenario by creating a realistic environment where multiple agents bid on houses, weighing aspects such as size, location, and budget to secure the most desirable homes at the lowest prices. Particularly, we investigate three key questions: (a) How does a persona influence an agent's behavior in a competitive setting? (b) Can an agent effectively profile its competitors' behavior during auctions? (c) How can persona profiling be leveraged to create an advantage using strategies such as theory of mind? Through a series of experiments, we analyze the behaviors of LLM agents and shed light on new findings. Our testbed, called HARBOR, offers a valuable platform for deepening our understanding of multi-agent workflows in competitive environments.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Sea of Coins: The Proliferation of Cryptocurrencies in UniswapV2</title>
<link>https://arxiv.org/abs/2502.10512</link>
<guid>https://arxiv.org/abs/2502.10512</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、去中心化交易所(DEX)、Uniswap V2、流动性操纵、风险投资

<br /><br />总结:

本文研究了区块链技术下领先的去中心化交易所Uniswap V2中新创建代币的市场动态、盈利性和流动性操纵问题。发现大量市场流动性被套牢在蜜罐（honeypots）中，降低了市场的效率并误导投资者。通过简单的买入持有策略，揭示了投资新创建代币所伴随的主要风险，如地毯式撤资(rug pulls)和夹心攻击(sandwich attacks)现象普遍存在。文章还计算出了最优的夹心攻击金额，并指出这些行为在低流动性的池中利润更高。此外，通过对交换时间和物理时间下的代币价格演化的分析，并运用聚类技术，作者指出了不同类型代币（如蜜罐代币与可销售代币）的价格演化特征和典型模式。这项研究为理解去中心化市场的风险和金融动态以及对投资者的挑战提供了深入见解。 <div>
arXiv:2502.10512v1 Announce Type: cross 
Abstract: Blockchain technology has revolutionized financial markets by enabling decentralized exchanges (DEXs) that operate without intermediaries. Uniswap V2, a leading DEX, facilitates the rapid creation and trading of new tokens, offering high return potential but exposing investors to significant risks. In this work, we analyze the financial impact of newly created tokens, assessing their market dynamics, profitability and liquidity manipulations. Our findings reveal that a significant portion of market liquidity is trapped in honeypots, reducing market efficiency and misleading investors. Applying a simple buy-and-hold strategy, we are able to uncover some major risks associated with investing in newly created tokens, including the widespread presence of rug pulls and sandwich attacks. We extract the optimal sandwich amount, revealing that their proliferation in new tokens stems from higher profitability in low-liquidity pools. Furthermore, we analyze the fundamental differences between token price evolution in swap time and physical time. Using clustering techniques, we highlight these differences and identify typical patterns of honeypot and sellable tokens. Our study provides insights into the risks and financial dynamics of decentralized markets and their challenges for investors.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Computing and Learning Mean Field Equilibria with Scalar Interactions: Algorithms and Applications</title>
<link>https://arxiv.org/abs/2502.12024</link>
<guid>https://arxiv.org/abs/2502.12024</guid>
<content:encoded><![CDATA[
<div> 关键词：Mean field equilibrium, 动态游戏, 初始版本编号v1, 核心交互函数, 强化学习

总结:
本文主要关注在动态游戏中通过标量互动函数进行交互的代理模型中的平均场均衡(Mean field equilibrium, MFE)问题。文章提出了迭代算法，利用该结构并保证在温和假设下收敛到MFE，克服了非线性和缺乏收缩性质带来的计算挑战。与现有方法不同的是，这些算法不依赖于单调性或收缩性质，从而具有更广泛的应用范围。此外，文中还介绍了一种模型无关的学习算法，它利用模拟和强化学习技术（如Q-learning和策略梯度法）在不了解收益或转移函数的情况下学习MFE，并在满足Lipschitz连续性假设下给出了有限时间性能界限。最后，将这些算法应用于动态竞争的经典模型（如产能竞争）以及在线市场相关的竞争模型（如共享出行、动态声誉、库存竞争）和社会学习模型，并利用这些算法得到了可靠的比较静态结果，揭示了关键市场参数如何影响这些简化模型中的均衡结果，为设计此类情境下的竞争系统提供了洞见。 <div>
arXiv:2502.12024v1 Announce Type: cross 
Abstract: Mean field equilibrium (MFE) has emerged as a computationally tractable solution concept for large dynamic games. However, computing MFE remains challenging due to nonlinearities and the absence of contraction properties, limiting its reliability for counterfactual analysis and comparative statics. This paper focuses on MFE in dynamic models where agents interact through a scalar function of the population distribution, referred to as the \textit{scalar interaction function}. Such models naturally arise in a wide range of applications in operations and economics, including quality ladder models, inventory competition, online marketplaces, and heterogeneous-agent macroeconomic models. The main contribution of this paper is to introduce iterative algorithms that leverage the scalar interaction structure and are guaranteed to converge to the MFE under mild assumptions. Unlike existing approaches, our algorithms do not rely on monotonicity or contraction properties, significantly broadening their applicability. Furthermore, we provide a model-free algorithm that learns the MFE by employing simulation and reinforcement learning techniques such as Q-learning and policy gradient methods without requiring prior knowledge of payoff or transition functions. We establish finite-time performance bounds for this algorithm under technical Lipschitz continuity assumptions. We apply our algorithms to classic models of dynamic competition, such as capacity competition, and to competitive models motivated by online marketplaces, including ridesharing, dynamic reputation, and inventory competition, as well as to social learning models. Using our algorithms, we derive reliable comparative statics results that illustrate how key market parameters influence equilibrium outcomes in these stylized models, providing insights that could inform the design of competitive systems in these contexts.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploiting Defenses against GAN-Based Feature Inference Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2004.12571</link>
<guid>https://arxiv.org/abs/2004.12571</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, GAN-based Attacks, Data Privacy, Anti-GAN, Image Reconstruction

<br /><br />总结:
本文关注的是联邦学习（Federated Learning）中的数据隐私问题，特别是针对使用生成对抗网络（GAN）进行攻击的情况。研究发现，GAN可以被用于联邦学习中以重构并学习私有数据集的分布。为解决此问题，文章提出了名为Anti-GAN的防御框架。Anti-GAN通过将私有训练图像投射到GAN的生成器上，并将生成的假图像与实际图像结合创建新的训练数据集，以此防止攻击者学习到受害者数据的真实分布。实验结果显示，Anti-GAN能够在对联邦模型的准确性影响极小的情况下有效阻止攻击者获取私人图像的分布信息。 <div>
arXiv:2004.12571v4 Announce Type: replace 
Abstract: Federated learning (FL) is a decentralized model training framework that aims to merge isolated data islands while maintaining data privacy. However, recent studies have revealed that Generative Adversarial Network (GAN) based attacks can be employed in FL to learn the distribution of private datasets and reconstruct recognizable images. In this paper, we exploit defenses against GAN-based attacks in FL and propose a framework, Anti-GAN, to prevent attackers from learning the real distribution of the victim's data. The core idea of Anti-GAN is to manipulate the visual features of private training images to make them indistinguishable to human eyes even restored by attackers. Specifically, Anti-GAN projects the private dataset onto a GAN's generator and combines the generated fake images with the actual images to create the training dataset, which is then used for federated model training. The experimental results demonstrate that Anti-GAN is effective in preventing attackers from learning the distribution of private images while causing minimal harm to the accuracy of the federated model.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proof-of-randomness protocol for blockchain consensus: a case of Macau algorithms</title>
<link>https://arxiv.org/abs/2211.15417</link>
<guid>https://arxiv.org/abs/2211.15417</guid>
<content:encoded><![CDATA[
<div> 关键词：proof-of-randomness (PoR)协议、区块链、true random number generator (TRNG)、量子随机数生成器 (QRNG)、量子密钥分发 (QKD)

<br /><br />总结:
本文提出了一种基于证明随机性（Proof-of-Randomness，PoR）协议的公平且低能耗的区块链共识机制。该机制中，区块链网络中的每个节点可利用真实随机数生成器（TRNG）和哈希算法实现PoR协议。文中将PoR协议归类为一种新型的随机化算法——Macau。PoR协议能够在无需竞争计算力或加密货币权益的情况下生成区块链。此外，文章还讨论了集成量子随机数生成器（QRNG）芯片到硬件钱包的优势，并提出了与量子密钥分发（QKD）技术协同工作的可能性。 <div>
arXiv:2211.15417v3 Announce Type: replace 
Abstract: A proof-of-randomness (PoR) protocol is presented as a fair and low energy-cost consensus mechanism for blockchains. Each network node of a blockchain may use a true random number generator (TRNG) and hash algorism to fulfil the PoR protocol. In this paper, we give the consensus mechanism of the PoR protocol, and classify it into a new kind of randomized algorithms called Macau. The PoR protocol could generate a blockchain without any competition of computing power or stake of cryptocurrency. Besides, we give some advantages of integrating quantum random number generator (QRNG) chips into hardware wallets, and also discuss the way to cooperate with quantum key distribution (QKD) technology.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Case of FBA as a DEX Processing Model</title>
<link>https://arxiv.org/abs/2302.01177</link>
<guid>https://arxiv.org/abs/2302.01177</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化交易所、连续处理、离散处理（频繁批量拍卖）、福利损失

总结:
本文探讨了基于区块链的去中心化交易所中，采用连续处理和离散处理（频繁批量拍卖）两种订单匹配模型对福利损失的影响。研究发现，对于通常情况，例如少数参与者拥有私有资产估值信息时，离散处理（FBA）所导致的福利损失较小，并能提供更好的流动性。此外，在以下场景下，FBA也能实现更优的社会福利与流动性提供：当价格接受者及反映资产价值变动的公共信息更新频率相对较高，优先费用较小，或者市场买卖双方更为均衡时。实证分析显示，在名为dYdX的去中心化交易所上进行的BTC-USD和ETH-USD交易，FBA能够将交易成本降低21%-37%。 <div>
arXiv:2302.01177v5 Announce Type: replace 
Abstract: We investigate the welfare loss of continuous and discrete order matching models in blockchain-based decentralized exchanges (DEX) that utilize order books to record outstanding orders. Continuous processing matches each incoming transaction against the current order book. The discrete processing model, i.e., frequent batch auction (FBA), executes transactions discretely in batches with a uniform price double auction: Orders are first matched according to price, then the exact transaction order if competing orders specify the same price.
  We find that FBA imposes less welfare loss and provides better liquidity than continuous processing in typical scenarios, e.g., when few parties are privately informed about asset valuations. Even otherwise, it achieves better social welfare and liquidity provision in the following settings: when price takers and public information reflecting asset value changes arrive sufficiently frequently compared to private information, when the priority fees (for faster transaction inclusion into blockchains) are small, or when the market is more balanced on both buy and sell sides. Our empirical analysis on the BTC-USD and ETH-USD transactions on a DEX named dYdX indicates that FBA can reduce transaction costs by $21\%-37\%$.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Iterative Algorithm for Rescaled Hyperbolic Functions Regression</title>
<link>https://arxiv.org/abs/2305.00660</link>
<guid>https://arxiv.org/abs/2305.00660</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 注意力机制, softmax回归, 迭代算法, 张量分析

总结:
本文提出了一种针对大型语言模型中注意力机制所使用的、带有不同形式规范化项的softmax回归问题的迭代求解算法。该算法处理的是与目标n维向量b的内积（可选指数函数、双曲正弦函数或双曲余弦函数）并被规范化项重新缩放后的平方损失最小化问题，这不同于传统的softmax回归问题。新框架的效率和对多种超摆线函数的普适性使其对于优化注意力机制具有重要意义。此外，通过对该问题的分析，文中还得到了关于微小扰动下解决方案变化幅度的界。文章同时讨论了这种方法的局限性和可能带来的社会影响。<br /><br /> <div>
arXiv:2305.00660v2 Announce Type: replace 
Abstract: Large language models (LLMs) have numerous real-life applications across various domains, such as natural language translation, sentiment analysis, language modeling, chatbots and conversational agents, creative writing, text classification, summarization, and generation. LLMs have shown great promise in improving the accuracy and efficiency of these tasks, and have the potential to revolutionize the field of natural language processing (NLP) in the years to come. Exponential function based attention unit is a fundamental element in LLMs. Several previous works have studied the convergence of exponential regression and softmax regression.
  In this paper, we propose an iterative algorithm to solve a rescaled version of the slightly different formulation of the softmax regression problem that arises in attention mechanisms of large language models. Specifically, we consider minimizing the squared loss between a certain function, which can be either the exponential function, hyperbolic sine function, or hyperbolic cosine function, and its inner product with a target $n$-dimensional vector $b$, scaled by the normalization term. This ``rescaled softmax regression'' differs from classical softmax regression in the location of the normalization factor.
  The efficiency and generalizability of this framework to multiple hyperbolic functions make it relevant for optimizing attention mechanisms. The analysis also leads to a corollary bounding solution changes under small perturbations for in-context learning. Limitations and societal impact are discussed.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HighGuard: Cross-Chain Business Logic Monitoring of Smart Contracts</title>
<link>https://arxiv.org/abs/2305.08254</link>
<guid>https://arxiv.org/abs/2305.08254</guid>
<content:encoded><![CDATA[
<div> 关键词: HighGuard、动态条件响应(DCR)图模型、智能合约、业务逻辑漏洞、跨链环境<br /><br />总结:<br />
HighGuard是一个用于检测智能合约业务逻辑规范违反的工具，它利用动态条件响应(DCR)图模型作为正式规格说明，以验证合同执行是否符合这些模型。该工具有能力在跨链环境中运行，能在不同区块链平台上检测业务逻辑缺陷。HighGuard无需代码注入和额外的gas成本，即可展示其在识别智能合约中与指定行为偏离的能力，并且能够避免假阳性的检测结果。通过在监控器中使用精确的规格说明，HighGuard成功地实现了这一目标。文章提到，对涉及54个利用案例的评估证实了HighGuard在检测业务逻辑漏洞方面的有效性。该项目已开源并在GitHub和YouTube上提供了HighGuard的使用示例及演示视频链接。 <div>
arXiv:2305.08254v2 Announce Type: replace 
Abstract: Logical flaws in smart contracts are often exploited, leading to significant financial losses. Our tool, HighGuard, detects transactions that violate business logic specifications of smart contracts. HighGuard employs dynamic condition response (DCR) graph models as formal specifications to verify contract execution against these models. It is capable of operating in a cross-chain environment for detecting business logic flaws across different blockchain platforms. We demonstrate HighGuard's effectiveness in identifying deviations from specified behaviors in smart contracts without requiring code instrumentation or incurring additional gas costs. By using precise specifications in the monitor, HighGuard achieves detection without false positives. Our evaluation, involving 54 exploits, confirms HighGuard's effectiveness in detecting business logic vulnerabilities.
  Our open-source implementation of HighGuard and a screencast of its usage are available at: https://github.com/mojtaba-eshghie/HighGuard https://www.youtube.com/watch?v=sZYVV-slDaY
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Novelty Accommodating Multi-Agent Planning in High Fidelity Simulated Open World</title>
<link>https://arxiv.org/abs/2306.12654</link>
<guid>https://arxiv.org/abs/2306.12654</guid>
<content:encoded><![CDATA[
arXiv:2306.12654v2 Announce Type: replace 
Abstract: Autonomous agents operating within real-world environments often rely on automated planners to ascertain optimal actions towards desired goals or the optimization of a specified objective function. Integral to these agents are common architectural components such as schedulers, tasked with determining the timing for executing planned actions, and execution engines, responsible for carrying out these scheduled actions while monitoring their outcomes. We address the significant challenge that arises when unexpected phenomena, termed \textit{novelties}, emerge within the environment, altering its fundamental characteristics, composition, and dynamics. This challenge is inherent in all deployed real-world applications and may manifest suddenly and without prior notice or explanation. The introduction of novelties into the environment can lead to inaccuracies within the planner's internal model, rendering previously generated plans obsolete. Recent research introduced agent design aimed at detecting and adapting to such novelties. However, these designs lack consideration for action scheduling in continuous time-space, coordination of concurrent actions by multiple agents, or memory-based novelty accommodation. Additionally, the application has been primarily demonstrated in lower fidelity environments. In our study, we propose a general purpose AI agent framework designed to detect, characterize, and adapt to novelties in highly noisy, complex, and stochastic environments that support concurrent actions and external scheduling. We showcase the efficacy of our agent through experimentation within a high-fidelity simulator for realistic military scenarios.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Partner Modelling Questionnaire: A validated self-report measure of perceptions toward machines as dialogue partners</title>
<link>https://arxiv.org/abs/2308.07164</link>
<guid>https://arxiv.org/abs/2308.07164</guid>
<content:encoded><![CDATA[
arXiv:2308.07164v2 Announce Type: replace 
Abstract: Recent work has looked to understand user perceptions of speech agent capabilities as dialogue partners (termed partner models), and how this affects user interaction. Yet, currently partner model effects are inferred from language production as no metrics are available to quantify these subjective perceptions more directly. Through three studies, we develop and validate the Partner Modelling Questionnaire (PMQ): an 18-item self-report semantic differential scale designed to reliably measure people's partner models of non-embodied speech interfaces. Through principal component analysis and confirmatory factor analysis, we show that the PMQ scale consists of three factors: communicative competence and dependability, human-likeness in communication, and communicative flexibility. Our studies show that the measure consistently demonstrates good internal reliability, strong test-retest reliability over 12 and 4-week intervals, and predictable convergent/divergent validity. Based on our findings we discuss the multidimensional nature of partner models, whilst identifying key future research avenues that the development of the PMQ facilitates. Notably, this includes the need to identify the activation, sensitivity, and dynamism of partner models in speech interface interaction.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bridging Language and Action: A Survey of Language-Conditioned Robot Manipulation</title>
<link>https://arxiv.org/abs/2312.10807</link>
<guid>https://arxiv.org/abs/2312.10807</guid>
<content:encoded><![CDATA[
arXiv:2312.10807v4 Announce Type: replace 
Abstract: Language-conditioned robot manipulation is an emerging field aimed at enabling seamless communication and cooperation between humans and robotic agents by teaching robots to comprehend and execute instructions conveyed in natural language. This interdisciplinary area integrates scene understanding, language processing, and policy learning to bridge the gap between human instructions and robotic actions. In this comprehensive survey, we systematically explore recent advancements in language-conditioned robotic manipulation. We categorize existing methods into language-conditioned reward shaping, language-conditioned policy learning, neuro-symbolic artificial intelligence, and the utilization of foundational models (FMs) such as large language models (LLMs) and vision-language models (VLMs). Specifically, we analyze state-of-the-art techniques concerning semantic information extraction, environment and evaluation, auxiliary tasks, and task representation strategies. By conducting a comparative analysis, we highlight the strengths and limitations of current approaches in bridging language instructions with robot actions. Finally, we discuss open challenges and future research directions, focusing on potentially enhancing generalization capabilities and addressing safety issues in language-conditioned robot manipulators.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CCA: Collaborative Competitive Agents for Image Editing</title>
<link>https://arxiv.org/abs/2401.13011</link>
<guid>https://arxiv.org/abs/2401.13011</guid>
<content:encoded><![CDATA[
arXiv:2401.13011v2 Announce Type: replace 
Abstract: This paper presents a novel generative model, Collaborative Competitive Agents (CCA), which leverages the capabilities of multiple Large Language Models (LLMs) based agents to execute complex tasks. Drawing inspiration from Generative Adversarial Networks (GANs), the CCA system employs two equal-status generator agents and a discriminator agent. The generators independently process user instructions and generate results, while the discriminator evaluates the outputs, and provides feedback for the generator agents to further reflect and improve the generation results. Unlike the previous generative model, our system can obtain the intermediate steps of generation. This allows each generator agent to learn from other successful executions due to its transparency, enabling a collaborative competition that enhances the quality and robustness of the system's results. The primary focus of this study is image editing, demonstrating the CCA's ability to handle intricate instructions robustly. The paper's main contributions include the introduction of a multi-agent-based generative model with controllable intermediate steps and iterative optimization, a detailed examination of agent relationships, and comprehensive experiments on image editing. Code is available at \href{https://github.com/TiankaiHang/CCA}{https://github.com/TiankaiHang/CCA}.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues</title>
<link>https://arxiv.org/abs/2402.01737</link>
<guid>https://arxiv.org/abs/2402.01737</guid>
<content:encoded><![CDATA[
arXiv:2402.01737v3 Announce Type: replace 
Abstract: We develop assistive agents based on Large Language Models (LLMs) that aid interlocutors in business negotiations. Specifically, we simulate business negotiations by letting two LLM-based agents engage in role play. A third LLM acts as a remediator agent to rewrite utterances violating norms for improving negotiation outcomes. We introduce a simple tuning-free and label-free In-Context Learning (ICL) method to identify high-quality ICL exemplars for the remediator, where we propose a novel select criteria, called value impact, to measure the quality of the negotiation outcomes. We provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different negotiation topics. We have released our source code and the generated dataset at: https://github.com/tk1363704/SADAS.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Design of Affine Maximizer Mechanisms in Dynamic Settings</title>
<link>https://arxiv.org/abs/2402.08129</link>
<guid>https://arxiv.org/abs/2402.08129</guid>
<content:encoded><![CDATA[
arXiv:2402.08129v2 Announce Type: replace 
Abstract: Dynamic mechanism design is a challenging extension to ordinary mechanism design in which the mechanism designer must make a sequence of decisions over time in the face of possibly untruthful reports of participating agents. Optimizing dynamic mechanisms for welfare is relatively well understood. However, there has been less work on optimizing for other goals (e.g. revenue), and without restrictive assumptions on valuations, it is remarkably challenging to characterize good mechanisms. Instead, we turn to automated mechanism design to find mechanisms with good performance in specific problem instances. In fact, the situation is similar even in static mechanism design. However, in the static case, optimization/machine learning-based automated mechanism design techniques have been successful in finding high-revenue mechanisms in cases beyond the reach of analytical results. We extend the class of affine maximizer mechanisms to MDPs where agents may untruthfully report their rewards. This extension results in a challenging bilevel optimization problem in which the upper problem involves choosing optimal mechanism parameters, and the lower problem involves solving the resulting MDP. Our approach can find truthful dynamic mechanisms that achieve strong performance on goals other than welfare, and can be applied to essentially any problem setting-without restrictions on valuations-for which RL can learn optimal policies.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multidimensional Bayesian Utility Maximization: Tight Approximations to Welfare</title>
<link>https://arxiv.org/abs/2402.12340</link>
<guid>https://arxiv.org/abs/2402.12340</guid>
<content:encoded><![CDATA[
arXiv:2402.12340v2 Announce Type: replace 
Abstract: We initiate the study of multidimensional Bayesian utility maximization, focusing on the unit-demand setting where values are i.i.d. across both items and buyers. The seminal result of Hartline and Roughgarden '08 studies simple, information-robust mechanisms that maximize utility for $n$ i.i.d. agents and $m$ identical items via an approximation to social welfare as an upper bound, and they prove this gap between optimal utility and social welfare is $\Theta(1+\log{n/m})$ in this setting. We extend these results to the multidimensional setting. To do so, we develop simple, prior-independent, approximately-optimal mechanisms, targeting the simplest benchmark of optimal welfare. We give a $(1- 1/e)$-approximation when there are more items than buyers, and a $\Theta(\log{n/m})$-approximation when there are more buyers than items, and we prove that this bound is tight in both $n$ and $m$ by reducing the i.i.d. unit-demand setting to the identical items setting. Finally, we include an extensive discussion section on why Bayesian utility maximization is a promising research direction. In particular, we characterize complexities in this setting that defy our intuition from the welfare and revenue literature, and motivate why coming up with a better benchmark than welfare is a hard problem itself.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Off-Policy Learning for High-Dimensional Action Spaces</title>
<link>https://arxiv.org/abs/2403.04453</link>
<guid>https://arxiv.org/abs/2403.04453</guid>
<content:encoded><![CDATA[
arXiv:2403.04453v3 Announce Type: replace 
Abstract: Existing off-policy reinforcement learning algorithms often rely on an explicit state-action-value function representation, which can be problematic in high-dimensional action spaces due to the curse of dimensionality. This reliance results in data inefficiency as maintaining a state-action-value function in such spaces is challenging. We present an efficient approach that utilizes only a state-value function as the critic for off-policy deep reinforcement learning. This approach, which we refer to as Vlearn, effectively circumvents the limitations of existing methods by eliminating the necessity for an explicit state-action-value function. To this end, we leverage a weighted importance sampling loss for learning deep value functions from off-policy data. While this is common for linear methods, it has not been combined with deep value function networks. This transfer to deep methods is not straightforward and requires novel design choices such as robust policy updates, twin value function networks to avoid an optimization bias, and importance weight clipping. We also present a novel analysis of the variance of our estimate compared to commonly used importance sampling estimators such as V-trace. Our approach improves sample complexity as well as final performance and ensures consistent and robust performance across various benchmark tasks. Eliminating the state-action-value function in Vlearn facilitates a streamlined learning process, yielding high-return agents.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Dual Gradient Tracking for Distributed Resource Allocation</title>
<link>https://arxiv.org/abs/2403.18275</link>
<guid>https://arxiv.org/abs/2403.18275</guid>
<content:encoded><![CDATA[
arXiv:2403.18275v2 Announce Type: replace 
Abstract: This paper investigates privacy issues in distributed resource allocation over directed networks, where each agent holds a private cost function and optimizes its decision subject to a global coupling constraint through local interaction with other agents. Conventional methods for resource allocation over directed networks require all agents to transmit their original data to neighbors, which poses the risk of disclosing sensitive and private information. To address this issue, we propose an algorithm called differentially private dual gradient tracking (DP-DGT) for distributed resource allocation, which obfuscates the exchanged messages using independent Laplacian noise. Our algorithm ensures that the agents' decisions converge to a neighborhood of the optimal solution almost surely. Furthermore, without the assumption of bounded gradients, we prove that the cumulative differential privacy loss under the proposed algorithm is finite even when the number of iterations goes to infinity. To the best of our knowledge, we are the first to simultaneously achieve these two goals in distributed resource allocation problems over directed networks. Finally, numerical simulations on economic dispatch problems within the IEEE 14-bus system illustrate the effectiveness of our proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CuriousLLM: Elevating Multi-Document Question Answering with LLM-Enhanced Knowledge Graph Reasoning</title>
<link>https://arxiv.org/abs/2404.09077</link>
<guid>https://arxiv.org/abs/2404.09077</guid>
<content:encoded><![CDATA[
arXiv:2404.09077v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved significant success in open-domain question answering. However, they continue to face challenges such as hallucinations and knowledge cutoffs. These issues can be mitigated through in-context learning by providing LLMs with relevant context before generating answers. Recent literature proposes Knowledge Graph Prompting (KGP) which integrates knowledge graphs with an LLM-based traversal agent to substantially enhance document retrieval quality. However, KGP requires costly fine-tuning with large datasets and remains prone to hallucination. In this paper, we propose CuriousLLM, an enhancement that integrates a curiosity-driven reasoning mechanism into an LLM agent. This mechanism enables the agent to generate relevant follow-up questions, thereby guiding the information retrieval process more efficiently. Central to our approach is the development of the new Follow-upQA dataset, which includes questions and supporting evidence as input, with follow-up questions serving as ground truths. These follow-up questions either inquire about what is still missing to fully answer the user's query or use special tokens to signify that the retrieved evidence is sufficient. Our experiments show that CuriousLLM significantly boosts LLM performance in multi-document question answering (MD-QA), circumventing the substantial computational costs and latency from the original KGP framework.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agent-Constrained Truthful Facility Location Games</title>
<link>https://arxiv.org/abs/2405.05197</link>
<guid>https://arxiv.org/abs/2405.05197</guid>
<content:encoded><![CDATA[
arXiv:2405.05197v4 Announce Type: replace 
Abstract: We consider a truthful facility location problem in which there is a set of agents with private locations on the line of real numbers, and the goal is to place a number of facilities at different locations chosen from the set of those reported by the agents. Given a feasible solution, each agent suffers an individual cost that is either its total distance to all facilities (sum-variant) or its distance to the farthest facility (max-variant). For both variants, we show tight bounds on the approximation ratio of strategyproof mechanisms in terms of the social cost, the total individual cost of the agents.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NarrativeBridge: Enhancing Video Captioning with Causal-Temporal Narrative</title>
<link>https://arxiv.org/abs/2406.06499</link>
<guid>https://arxiv.org/abs/2406.06499</guid>
<content:encoded><![CDATA[
arXiv:2406.06499v3 Announce Type: replace 
Abstract: Existing video captioning benchmarks and models lack causal-temporal narrative, which is sequences of events linked through cause and effect, unfolding over time and driven by characters or agents. This lack of narrative restricts models' ability to generate text descriptions that capture the causal and temporal dynamics inherent in video content. To address this gap, we propose NarrativeBridge, an approach comprising of: (1) a novel Causal-Temporal Narrative (CTN) captions benchmark generated using a large language model and few-shot prompting, explicitly encoding cause-effect temporal relationships in video descriptions; and (2) a Cause-Effect Network (CEN) with separate encoders for capturing cause and effect dynamics, enabling effective learning and generation of captions with causal-temporal narrative. Extensive experiments demonstrate that CEN significantly outperforms state-of-the-art models in articulating the causal and temporal aspects of video content: 17.88 and 17.44 CIDEr on the MSVD-CTN and MSRVTT-CTN datasets, respectively. Cross-dataset evaluations further showcase CEN's strong generalization capabilities. The proposed framework understands and generates nuanced text descriptions with intricate causal-temporal narrative structures present in videos, addressing a critical limitation in video captioning. For project details, visit https://narrativebridge.github.io/.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning with Intrinsically Motivated Feedback Graph for Lost-sales Inventory Control</title>
<link>https://arxiv.org/abs/2406.18351</link>
<guid>https://arxiv.org/abs/2406.18351</guid>
<content:encoded><![CDATA[
arXiv:2406.18351v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) has proven to be well-performed and general-purpose in the inventory control (IC). However, further improvement of RL algorithms in the IC domain is impeded due to two limitations of online experience. First, online experience is expensive to acquire in real-world applications. With the low sample efficiency nature of RL algorithms, it would take extensive time to train the RL policy to convergence. Second, online experience may not reflect the true demand due to the lost sales phenomenon typical in IC, which makes the learning process more challenging. To address the above challenges, we propose a decision framework that combines reinforcement learning with feedback graph (RLFG) and intrinsically motivated exploration (IME) to boost sample efficiency. In particular, we first take advantage of the inherent properties of lost-sales IC problems and design the feedback graph (FG) specially for lost-sales IC problems to generate abundant side experiences aid RL updates. Then we conduct a rigorous theoretical analysis of how the designed FG reduces the sample complexity of RL methods. Based on the theoretical insights, we design an intrinsic reward to direct the RL agent to explore to the state-action space with more side experiences, further exploiting FG's power. Experimental results demonstrate that our method greatly improves the sample efficiency of applying RL in IC. Our code is available at https://anonymous.4open.science/r/RLIMFG4IC-811D/
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Truthful and Almost Envy-Free Mechanism of Allocating Indivisible Goods: the Power of Randomness</title>
<link>https://arxiv.org/abs/2407.13634</link>
<guid>https://arxiv.org/abs/2407.13634</guid>
<content:encoded><![CDATA[
arXiv:2407.13634v2 Announce Type: replace 
Abstract: We study the problem of fairly and truthfully allocating $m$ indivisible items to $n$ agents with additive preferences. Specifically, we consider truthful mechanisms outputting allocations that satisfy EF$^{+u}_{-v}$, where, in an EF$^{+u}_{-v}$ allocation, for any pair of agents $i$ and $j$, agent $i$ will not envy agent $j$ if $u$ items were added to $i$'s bundle and $v$ items were removed from $j$'s bundle. Previous work easily indicates that, when restricted to deterministic mechanisms, truthfulness will lead to a poor guarantee of fairness: even with two agents, for any $u$ and $v$, EF$^{+u}_{-v}$ cannot be guaranteed by truthful mechanisms when the number of items is large enough. In this work, we focus on randomized mechanisms, where we consider ex-ante truthfulness and ex-post fairness. For two agents, we present a truthful mechanism that achieves EF$^{+0}_{-1}$ (i.e., the well-studied fairness notion EF$1$). For three agents, we present a truthful mechanism that achieves EF$^{+1}_{-1}$. For $n$ agents in general, we show that there exist truthful mechanisms that achieve EF$^{+u}_{-v}$ for some $u$ and $v$ that depend only on $n$ (not $m$).
  We further consider fair and truthful mechanisms that also satisfy the standard efficiency guarantee: Pareto-optimality. We provide a mechanism that simultaneously achieves truthfulness, EF$1$, and Pareto-optimality for bi-valued utilities (where agents' valuation on each item is either $p$ or $q$ for some $p>q\geq0$). For tri-valued utilities (where agents' valuations on each item belong to $\{p,q,r\}$ for some $p>q>r\geq0$) and any $u,v$, we show that truthfulness is incompatible with EF$^{+u}_{-v}$ and Pareto-optimality even for two agents.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Talking Wikidata: Communication patterns and their impact on community engagement in collaborative knowledge graphs</title>
<link>https://arxiv.org/abs/2407.18278</link>
<guid>https://arxiv.org/abs/2407.18278</guid>
<content:encoded><![CDATA[
arXiv:2407.18278v2 Announce Type: replace 
Abstract: We study collaboration patterns of Wikidata, one of the world's largest open source collaborative knowledge graph (KG) communities. Collaborative KG communities, play a key role in structuring machine-readable knowledge to support AI systems like conversational agents. However, these communities face challenges related to long-term member engagement, as a small subset of contributors often is responsible for the majority of contributions and decision-making. While prior research has explored contributors' roles and lifespans, discussions within collaborative KG communities remain understudied. To fill this gap, we investigated the behavioural patterns of contributors and factors affecting their communication and participation. We analysed all the discussions on Wikidata using a mixed methods approach, including statistical tests, network analysis, and text and graph embedding representations. Our findings reveal that the interactions between Wikidata editors form a small world network, resilient to dropouts and inclusive, where both the network topology and discussion content influence the continuity of conversations. Furthermore, the account age of Wikidata members and their conversations are significant factors in their long-term engagement with the project. Our observations and recommendations can benefit the Wikidata and semantic web communities, providing guidance on how to improve collaborative environments for sustainability, growth, and quality.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems</title>
<link>https://arxiv.org/abs/2408.01857</link>
<guid>https://arxiv.org/abs/2408.01857</guid>
<content:encoded><![CDATA[
arXiv:2408.01857v3 Announce Type: replace 
Abstract: We develop an Euler-type method to predict the evolution of a time-dependent probability measure without explicitly learning an operator that governs its evolution. We use linearized optimal transport theory to prove that the measure-valued analog of Euler's method is first-order accurate when the measure evolves ``smoothly.'' In applications of interest, however, the measure is an empirical distribution of a system of stochastic particles whose behavior is only accessible through an agent-based micro-scale simulation. In such cases, this empirical measure does not evolve smoothly because the individual particles move chaotically on short time scales. However, we can still perform our Euler-type method, and when the particles' collective distribution approximates a measure that \emph{does} evolve smoothly, we observe that the algorithm still accurately predicts this collective behavior over relatively large Euler steps. We specifically demonstrate the efficacy of our approach by showing that our algorithm vastly reduces the number of micro-scale steps needed to correctly approximate long-term behavior in two illustrative examples, reflected Brownian motion and a model of bacterial chemotaxis.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Performative Prediction on Games and Mechanism Design</title>
<link>https://arxiv.org/abs/2408.05146</link>
<guid>https://arxiv.org/abs/2408.05146</guid>
<content:encoded><![CDATA[
arXiv:2408.05146v3 Announce Type: replace 
Abstract: Agents often have individual goals which depend on a group's actions. If agents trust a forecast of collective action and adapt strategically, such prediction can influence outcomes non-trivially, resulting in a form of performative prediction. This effect is ubiquitous in scenarios ranging from pandemic predictions to election polls, but existing work has ignored interdependencies among predicted agents. As a first step in this direction, we study a collective risk dilemma where agents dynamically decide whether to trust predictions based on past accuracy. As predictions shape collective outcomes, social welfare arises naturally as a metric of concern. We explore the resulting interplay between accuracy and welfare, and demonstrate that searching for stable accurate predictions can minimize social welfare with high probability in our setting. By assuming knowledge of a Bayesian agent behavior model, we then show how to achieve better trade-offs and use them for mechanism design.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategy Game-Playing with Size-Constrained State Abstraction</title>
<link>https://arxiv.org/abs/2408.06202</link>
<guid>https://arxiv.org/abs/2408.06202</guid>
<content:encoded><![CDATA[
arXiv:2408.06202v2 Announce Type: replace 
Abstract: Playing strategy games is a challenging problem for artificial intelligence (AI). One of the major challenges is the large search space due to a diverse set of game components. In recent works, state abstraction has been applied to search-based game AI and has brought significant performance improvements. State abstraction techniques rely on reducing the search space, e.g., by aggregating similar states. However, the application of these abstractions is hindered because the quality of an abstraction is difficult to evaluate. Previous works hence abandon the abstraction in the middle of the search to not bias the search to a local optimum. This mechanism introduces a hyper-parameter to decide the time to abandon the current state abstraction. In this work, we propose a size-constrained state abstraction (SCSA), an approach that limits the maximum number of nodes being grouped together. We found that with SCSA, the abstraction is not required to be abandoned. Our empirical results on $3$ strategy games show that the SCSA agent outperforms the previous methods and yields robust performance over different games. Codes are open-sourced at https://github.com/GAIGResearch/Stratega.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discrete Policy: Learning Disentangled Action Space for Multi-Task Robotic Manipulation</title>
<link>https://arxiv.org/abs/2409.18707</link>
<guid>https://arxiv.org/abs/2409.18707</guid>
<content:encoded><![CDATA[
arXiv:2409.18707v3 Announce Type: replace 
Abstract: Learning visuomotor policy for multi-task robotic manipulation has been a long-standing challenge for the robotics community. The difficulty lies in the diversity of action space: typically, a goal can be accomplished in multiple ways, resulting in a multimodal action distribution for a single task. The complexity of action distribution escalates as the number of tasks increases. In this work, we propose \textbf{Discrete Policy}, a robot learning method for training universal agents capable of multi-task manipulation skills. Discrete Policy employs vector quantization to map action sequences into a discrete latent space, facilitating the learning of task-specific codes. These codes are then reconstructed into the action space conditioned on observations and language instruction. We evaluate our method on both simulation and multiple real-world embodiments, including both single-arm and bimanual robot settings. We demonstrate that our proposed Discrete Policy outperforms a well-established Diffusion Policy baseline and many state-of-the-art approaches, including ACT, Octo, and OpenVLA. For example, in a real-world multi-task training setting with five tasks, Discrete Policy achieves an average success rate that is 26\% higher than Diffusion Policy and 15\% higher than OpenVLA. As the number of tasks increases to 12, the performance gap between Discrete Policy and Diffusion Policy widens to 32.5\%, further showcasing the advantages of our approach. Our work empirically demonstrates that learning multi-task policies within the latent space is a vital step toward achieving general-purpose agents.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>StateAct: State Tracking and Reasoning for Acting and Planning with Large Language Models</title>
<link>https://arxiv.org/abs/2410.02810</link>
<guid>https://arxiv.org/abs/2410.02810</guid>
<content:encoded><![CDATA[
arXiv:2410.02810v2 Announce Type: replace 
Abstract: Planning and acting to solve `real' tasks using large language models (LLMs) in interactive environments has become a new frontier for AI methods. While recent advances allowed LLMs to interact with online tools, solve robotics tasks and many more, long range reasoning tasks remain a problem for LLMs. Existing methods to address this issue are very resource intensive and require additional data or human crafted rules, instead, we propose a simple method based on few-shot in-context learning alone to enhance `chain-of-thought' with state-tracking for planning and acting with LLMs. We show that our method establishes the new state-of-the-art on Alfworld for in-context learning methods (+14\% over the previous best few-shot in-context learning method) and performs on par with methods that use additional training data and additional tools such as code-execution. We also demonstrate that our enhanced `chain-of-states' allows the agent to both solve longer horizon problems and to be more efficient in number of steps required to solve a task. We show that our method works across a variety of LLMs for both API-based and open source ones. Finally, we also conduct ablation studies and show that `chain-of-thoughts' helps state-tracking accuracy, while a json-structure harms overall performance. We open-source our code and annotations at https://github.com/ai-nikolai/StateAct.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring the Personality Traits of LLMs through Latent Features Steering</title>
<link>https://arxiv.org/abs/2410.10863</link>
<guid>https://arxiv.org/abs/2410.10863</guid>
<content:encoded><![CDATA[
arXiv:2410.10863v2 Announce Type: replace 
Abstract: Large language models (LLMs) have significantly advanced dialogue systems and role-playing agents through their ability to generate human-like text. While prior studies have shown that LLMs can exhibit distinct and consistent personalities, the mechanisms through which these models encode and express specific personality traits remain poorly understood. To address this, we investigate how various factors, such as cultural norms and environmental stressors, encoded within LLMs, shape their personality traits, guided by the theoretical framework of social determinism. Inspired by related work on LLM interpretability, we propose a training-free approach to modify the model's behavior by extracting and steering latent features corresponding to factors within the model, thereby eliminating the need for retraining. Furthermore, we analyze the implications of these factors for model safety, focusing on their impact through the lens of personality.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Intelligent Agentic System for Complex Image Restoration Problems</title>
<link>https://arxiv.org/abs/2410.17809</link>
<guid>https://arxiv.org/abs/2410.17809</guid>
<content:encoded><![CDATA[
arXiv:2410.17809v2 Announce Type: replace 
Abstract: Real-world image restoration (IR) is inherently complex and often requires combining multiple specialized models to address diverse degradations. Inspired by human problem-solving, we propose AgenticIR, an agentic system that mimics the human approach to image processing by following five key stages: Perception, Scheduling, Execution, Reflection, and Rescheduling. AgenticIR leverages large language models (LLMs) and vision-language models (VLMs) that interact via text generation to dynamically operate a toolbox of IR models. We fine-tune VLMs for image quality analysis and employ LLMs for reasoning, guiding the system step by step. To compensate for LLMs' lack of specific IR knowledge and experience, we introduce a self-exploration method, allowing the LLM to observe and summarize restoration results into referenceable documents. Experiments demonstrate AgenticIR's potential in handling complex IR tasks, representing a promising path toward achieving general intelligence in visual processing.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VideoWebArena: Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks</title>
<link>https://arxiv.org/abs/2410.19100</link>
<guid>https://arxiv.org/abs/2410.19100</guid>
<content:encoded><![CDATA[
arXiv:2410.19100v3 Announce Type: replace 
Abstract: Videos are often used to learn or extract the necessary information to complete tasks in ways different than what text and static imagery alone can provide. However, many existing agent benchmarks neglect long-context video understanding, instead focusing on text or static image inputs. To bridge this gap, we introduce VideoWebArena (VideoWA), a benchmark for evaluating the capabilities of long-context multimodal agents for video understanding. VideoWA consists of 2,021 web agent tasks based on manually crafted video tutorials, which total almost four hours of content. For our benchmark, we define a taxonomy of long-context video-based agent tasks with two main areas of focus: skill retention and factual retention. While skill retention tasks evaluate whether an agent can use a given human demonstration to complete a task efficiently, the factual retention task evaluates whether an agent can retrieve instruction-relevant information from a video to complete a task. We find that the best model achieves 13.3% success on factual retention tasks and 45.8% on factual retention QA pairs, far below human performance at 73.9% and 79.3%, respectively. On skill retention tasks, long-context models perform worse with tutorials than without, exhibiting a 5% performance decrease in WebArena tasks and a 10.3% decrease in VisualWebArena tasks. Our work highlights the need to improve the agentic abilities of long-context multimodal models and provides a testbed for future development with long-context video agents.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents</title>
<link>https://arxiv.org/abs/2410.22662</link>
<guid>https://arxiv.org/abs/2410.22662</guid>
<content:encoded><![CDATA[
arXiv:2410.22662v2 Announce Type: replace 
Abstract: Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach for tackling complex tasks that single robots cannot manage alone. Current large-language-model-based multi-agent systems (LLM-based MAS) have shown success in areas like software development and operating systems, but applying these systems to robot control presents unique challenges. In particular, the capabilities of each agent in a multi-robot system are inherently tied to the physical composition of the robots, rather than predefined roles. To address this issue, we introduce a novel multi-agent framework designed to enable effective collaboration among heterogeneous robots with varying embodiments and capabilities, along with a new benchmark named Habitat-MAS. One of our key designs is $\textit{Robot Resume}$: Instead of adopting human-designed role play, we propose a self-prompted approach, where agents comprehend robot URDF files and call robot kinematics tools to generate descriptions of their physics capabilities to guide their behavior in task planning and action execution. The Habitat-MAS benchmark is designed to assess how a multi-agent framework handles tasks that require embodiment-aware reasoning, which includes 1) manipulation, 2) perception, 3) navigation, and 4) comprehensive multi-floor object rearrangement. The experimental results indicate that the robot's resume and the hierarchical design of our multi-agent system are essential for the effective operation of the heterogeneous multi-robot system within this intricate problem context.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments</title>
<link>https://arxiv.org/abs/2411.02305</link>
<guid>https://arxiv.org/abs/2411.02305</guid>
<content:encoded><![CDATA[
arXiv:2411.02305v2 Announce Type: replace 
Abstract: Customer Relationship Management (CRM) systems are vital for modern enterprises, providing a foundation for managing customer interactions and data. Integrating AI agents into CRM systems can automate routine processes and enhance personalized service. However, deploying and evaluating these agents is challenging due to the lack of realistic benchmarks that reflect the complexity of real-world CRM tasks. To address this issue, we introduce CRMArena, a novel benchmark designed to evaluate AI agents on realistic tasks grounded in professional work environments. Following guidance from CRM experts and industry best practices, we designed CRMArena with nine customer service tasks distributed across three personas: service agent, analyst, and manager. The benchmark includes 16 commonly used industrial objects (e.g., account, order, knowledge article, case) with high interconnectivity, along with latent variables (e.g., complaint habits, policy violations) to simulate realistic data distributions. Experimental results reveal that state-of-the-art LLM agents succeed in less than 40% of the tasks with ReAct prompting, and less than 55% even with function-calling abilities. Our findings highlight the need for enhanced agent capabilities in function-calling and rule-following to be deployed in real-world work environments. CRMArena is an open challenge to the community: systems that can reliably complete tasks showcase direct business value in a popular work environment.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MA-DV2F: A Multi-Agent Navigation Framework using Dynamic Velocity Vector Field</title>
<link>https://arxiv.org/abs/2411.06404</link>
<guid>https://arxiv.org/abs/2411.06404</guid>
<content:encoded><![CDATA[
arXiv:2411.06404v3 Announce Type: replace 
Abstract: In this paper we propose MA-DV2F: Multi-Agent Dynamic Velocity Vector Field. It is a framework for simultaneously controlling a group of vehicles in challenging environments. DV2F is generated for each vehicle independently and provides a map of reference orientation and speed that a vehicle must attain at any point on the navigation grid such that it safely reaches its target. The field is dynamically updated depending on the speed and proximity of the ego-vehicle to other agents. This dynamic adaptation of the velocity vector field allows prevention of imminent collisions. Experimental results show that MA-DV2F outperforms concurrent methods in terms of safety, computational efficiency and accuracy in reaching the target when scaling to a large number of vehicles. Project page for this work can be found here: https://yininghase.github.io/MA-DV2F/
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Weighted Envy Freeness With Limited Subsidies</title>
<link>https://arxiv.org/abs/2411.12696</link>
<guid>https://arxiv.org/abs/2411.12696</guid>
<content:encoded><![CDATA[
arXiv:2411.12696v2 Announce Type: replace 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any other's relative to their own. In many cases, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies.
  Previous work in the unweighted setting of subsidies relied on basic characterizations of EF that fail in the weighted settings. This makes our new setting challenging and theoretically intriguing. We present polynomial-time algorithms that compute WEF-able allocations with an upper bound on the subsidy per agent in three distinct additive valuation scenarios: (1) general, (2) identical, and (3) binary. When all weights are equal, our bounds reduce to the bounds derived in the literature for the unweighted setting.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Feasible Rewards in Multi-Agent Inverse Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.15046</link>
<guid>https://arxiv.org/abs/2411.15046</guid>
<content:encoded><![CDATA[
arXiv:2411.15046v3 Announce Type: replace 
Abstract: In multi-agent systems, agent behavior is driven by utility functions that encapsulate their individual goals and interactions. Inverse Reinforcement Learning (IRL) seeks to uncover these utilities by analyzing expert behavior, offering insights into the underlying decision-making processes. However, multi-agent settings pose significant challenges, particularly when rewards are inferred from equilibrium observations. A key obstacle is that single (Nash) equilibrium observations often fail to adequately capture critical game properties, leading to potential misrepresentations. This paper offers a rigorous analysis of the feasible reward set in multi-agent IRL and addresses these limitations by introducing entropy-regularized games, ensuring equilibrium uniqueness and enhancing interpretability. Furthermore, we examine the effects of estimation errors and present the first sample complexity results for multi-agent IRL across diverse scenarios.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Investigating social alignment via mirroring in a system of interacting language models</title>
<link>https://arxiv.org/abs/2412.06834</link>
<guid>https://arxiv.org/abs/2412.06834</guid>
<content:encoded><![CDATA[
arXiv:2412.06834v2 Announce Type: replace 
Abstract: Alignment is a social phenomenon wherein individuals share a common goal or perspective. Mirroring, or mimicking the behaviors and opinions of another individual, is one mechanism by which individuals can become aligned. Large scale investigations of the effect of mirroring on alignment have been limited due to the scalability of traditional experimental designs in sociology. In this paper, we introduce a simple computational framework that enables studying the effect of mirroring behavior on alignment in multi-agent systems. We simulate systems of interacting large language models in this framework and characterize overall system behavior and alignment with quantitative measures of agent dynamics. We find that system behavior is strongly influenced by the range of communication of each agent and that these effects are exacerbated by increased rates of mirroring. We discuss the observed simulated system behavior in the context of known human social dynamics.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette</title>
<link>https://arxiv.org/abs/2412.11167</link>
<guid>https://arxiv.org/abs/2412.11167</guid>
<content:encoded><![CDATA[
arXiv:2412.11167v2 Announce Type: replace 
Abstract: Large language models (LLMs) face challenges in aligning with diverse cultural values despite their remarkable performance in generation, which stems from inherent monocultural biases and difficulties in capturing nuanced cultural semantics. Existing methods struggle to adapt to unkown culture after fine-tuning. Inspired by cultural geography across five continents, we propose Cultural Palette, a multi-agent framework that redefines cultural alignment as an adaptive "color-blending" process for country-specific adaptation. Our approach harnesses cultural geography across five continents (Africa, America, Asia, Europe, Oceania) through three key steps: First, we synthesize the Pentachromatic Cultural Palette Dataset using GPT-4o, refining continental-level dialogues with Hofstede cultural dimensions to establish foundational cultural representations. Second, five continent-level alignment agents form specialized cultural communities that generate region-specific draft responses. Third, a Meta Agent employs Cultural MoErges to dynamically blend these cultural "colors" through attention-gated parameter merging, akin to mixing pigments on a palette, resolving conflicts while preserving cultural nuances to produce the final culturally-aligned response. Extensive experiments across various countries demonstrate that Cultural Palette surpasses existing baselines in cultural alignment.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HammerBench: Fine-Grained Function-Calling Evaluation in Real Mobile Device Scenarios</title>
<link>https://arxiv.org/abs/2412.16516</link>
<guid>https://arxiv.org/abs/2412.16516</guid>
<content:encoded><![CDATA[
arXiv:2412.16516v2 Announce Type: replace 
Abstract: Evaluating the performance of LLMs in multi-turn human-agent interactions presents significant challenges, particularly due to the complexity and variability of user behavior. In this paper, we introduce HammerBench, a novel benchmark framework for assessing LLMs' function-calling capabilities in real-world, multi-turn dialogues. HammerBench simulates diverse mobile assistant use cases, incorporating imperfect instructions, dynamic question-answer trajectories, intent and argument shifts, and the indirect use of external information through pronouns. To construct this benchmark, we curate a comprehensive dataset derived from popular mobile app functionalities and anonymized user logs, complemented by a cost-effective data generation pipeline leveraging open-source models. HammerBench is further augmented with fine-grained interaction snapshots and metrics, enabling detailed evaluation of function-calling performance across individual conversational turns. We demonstrate the effectiveness of HammerBench by evaluating several leading LLMs and uncovering key performance trends. Our experiments reveal that different types of parameter name errors are a significant source of failure across different interaction scenarios, highlighting critical areas for further improvement in LLM robustness for mobile assistant applications.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation</title>
<link>https://arxiv.org/abs/2412.18907</link>
<guid>https://arxiv.org/abs/2412.18907</guid>
<content:encoded><![CDATA[
arXiv:2412.18907v2 Announce Type: replace 
Abstract: Object manipulation is a common component of everyday tasks, but learning to manipulate objects from high-dimensional observations presents significant challenges. These challenges are heightened in multi-object environments due to the combinatorial complexity of the state space as well as of the desired behaviors. While recent approaches have utilized large-scale offline data to train models from pixel observations, achieving performance gains through scaling, these methods struggle with compositional generalization in unseen object configurations with constrained network and dataset sizes. To address these issues, we propose a novel behavioral cloning (BC) approach that leverages object-centric representations and an entity-centric Transformer with diffusion-based optimization, enabling efficient learning from offline image data. Our method first decomposes observations into an object-centric representation, which is then processed by our entity-centric Transformer that computes attention at the object level, simultaneously predicting object dynamics and the agent's actions. Combined with the ability of diffusion models to capture multi-modal behavior distributions, this results in substantial performance improvements in multi-object tasks and, more importantly, enables compositional generalization. We present BC agents capable of zero-shot generalization to tasks with novel compositions of objects and goals, including larger numbers of objects than seen during training. We provide video rollouts on our webpage: https://sites.google.com/view/ec-diffuser.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>$\texttt{FORM}$: Learning Expressive and Transferable First-Order Logic Reward Machines</title>
<link>https://arxiv.org/abs/2501.00364</link>
<guid>https://arxiv.org/abs/2501.00364</guid>
<content:encoded><![CDATA[
arXiv:2501.00364v2 Announce Type: replace 
Abstract: Reward machines (RMs) are an effective approach for addressing non-Markovian rewards in reinforcement learning (RL) through finite-state machines. Traditional RMs, which label edges with propositional logic formulae, inherit the limited expressivity of propositional logic. This limitation hinders the learnability and transferability of RMs since complex tasks will require numerous states and edges. To overcome these challenges, we propose First-Order Reward Machines ($\texttt{FORM}$s), which use first-order logic to label edges, resulting in more compact and transferable RMs. We introduce a novel method for $\textbf{learning}$ $\texttt{FORM}$s and a multi-agent formulation for $\textbf{exploiting}$ them and facilitate their transferability, where multiple agents collaboratively learn policies for a shared $\texttt{FORM}$. Our experimental results demonstrate the scalability of $\texttt{FORM}$s with respect to traditional RMs. Specifically, we show that $\texttt{FORM}$s can be effectively learnt for tasks where traditional RM learning approaches fail. We also show significant improvements in learning speed and task transferability thanks to the multi-agent learning framework and the abstraction provided by the first-order language.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Machine Learning Surrogates for Optimizing Transportation Policies with Agent-Based Models</title>
<link>https://arxiv.org/abs/2501.11057</link>
<guid>https://arxiv.org/abs/2501.11057</guid>
<content:encoded><![CDATA[
arXiv:2501.11057v2 Announce Type: replace 
Abstract: Rapid urbanization and growing urban populations worldwide present significant challenges for cities, including increased traffic congestion and air pollution. Effective strategies are needed to manage traffic volumes and reduce emissions. In practice, traditional traffic flow simulations are used to test those strategies. However, high computational intensity usually limits their applicability in investigating a magnitude of different scenarios to evaluate best policies. This paper presents a first approach of using Graph Neural Networks (GNN) as surrogates for large-scale agent-based simulation models. In a case study using the MATSim model of Paris, the GNN effectively learned the impacts of capacity reduction policies on citywide traffic flow. Performance analysis across various road types and scenarios revealed that the GNN could accurately capture policy-induced effects on edge-based traffic volumes, particularly on roads directly affected by the policies and those with higher traffic volumes.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of World Models for Autonomous Driving</title>
<link>https://arxiv.org/abs/2501.11260</link>
<guid>https://arxiv.org/abs/2501.11260</guid>
<content:encoded><![CDATA[
arXiv:2501.11260v2 Announce Type: replace 
Abstract: Recent breakthroughs in autonomous driving have been propelled by advances in robust world modeling, fundamentally transforming how vehicles interpret dynamic scenes and execute safe decision-making. In particular, world models have emerged as a linchpin technology, offering high-fidelity representations of the driving environment that integrate multi-sensor data, semantic cues, and temporal dynamics. This paper systematically reviews recent advances in world models for autonomous driving, proposing a three-tiered taxonomy: 1) Generation of Future Physical World, covering image-, BEV-, OG-, and PC-based generation methods that enhance scene evolution modeling through diffusion models and 4D occupancy forecasting; 2) Behavior Planning for Intelligent Agents, combining rule-driven and learning-based paradigms with cost map optimization and reinforcement learning for trajectory generation in complex traffic conditions; 3) Interaction Between Prediction and Planning, achieving multi-agent collaborative decision-making through latent space diffusion and memory-augmented architectures. The study further analyzes training paradigms including self-supervised learning, multimodal pretraining, and generative data augmentation, while evaluating world models' performance in scene understanding and motion prediction tasks. Future research must address key challenges in self-supervised representation learning, long-tail scenario generation, and multimodal fusion to advance the practical deployment of world models in complex urban environments. Overall, our comprehensive analysis provides a theoretical framework and technical roadmap for harnessing the transformative potential of world models in advancing safe and reliable autonomous driving solutions.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Group-Agent Reinforcement Learning with Heterogeneous Agents</title>
<link>https://arxiv.org/abs/2501.11818</link>
<guid>https://arxiv.org/abs/2501.11818</guid>
<content:encoded><![CDATA[
arXiv:2501.11818v2 Announce Type: replace 
Abstract: Group-agent reinforcement learning (GARL) is a newly arising learning scenario, where multiple reinforcement learning agents study together in a group, sharing knowledge in an asynchronous fashion. The goal is to improve the learning performance of each individual agent. Under a more general heterogeneous setting where different agents learn using different algorithms, we advance GARL by designing novel and effective group-learning mechanisms. They guide the agents on whether and how to learn from action choices from the others, and allow the agents to adopt available policy and value function models sent by another agent if they perform better. We have conducted extensive experiments on a total of 43 different Atari 2600 games to demonstrate the superior performance of the proposed method. After the group learning, among the 129 agents examined, 96% are able to achieve a learning speed-up, and 72% are able to learn over 100 times faster. Also, around 41% of those agents have achieved a higher accumulated reward score by learning in less than 5% of the time steps required by a single agent when learning on its own.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic AI: Autonomy, Accountability, and the Algorithmic Society</title>
<link>https://arxiv.org/abs/2502.00289</link>
<guid>https://arxiv.org/abs/2502.00289</guid>
<content:encoded><![CDATA[
arXiv:2502.00289v3 Announce Type: replace 
Abstract: Agentic Artificial Intelligence (AI) can autonomously pursue long-term goals, make decisions, and execute complex, multi-turn workflows. Unlike traditional generative AI, which responds reactively to prompts, agentic AI proactively orchestrates processes, such as autonomously managing complex tasks or making real-time decisions. This transition from advisory roles to proactive execution challenges established legal, economic, and creative frameworks. In this paper, we explore challenges in three interrelated domains: creativity and intellectual property, legal and ethical considerations, and competitive effects. Central to our analysis is the tension between novelty and usefulness in AI-generated creative outputs, as well as the intellectual property and authorship challenges arising from AI autonomy. We highlight gaps in responsibility attribution and liability that create a "moral crumple zone"--a condition where accountability is diffused across multiple actors, leaving end-users and developers in precarious legal and ethical positions. We examine the competitive dynamics of two-sided algorithmic markets, where both sellers and buyers deploy AI agents, potentially mitigating or amplifying tacit collusion risks. We explore the potential for emergent self-regulation within networks of agentic AI--the development of an "algorithmic society"--raising critical questions: To what extent would these norms align with societal values? What unintended consequences might arise? How can transparency and accountability be ensured? Addressing these challenges will necessitate interdisciplinary collaboration to redefine legal accountability, align AI-driven choices with stakeholder values, and maintain ethical safeguards. We advocate for frameworks that balance autonomy with accountability, ensuring all parties can harness agentic AI's potential while preserving trust, fairness, & societal welfare.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Who's the MVP? A Game-Theoretic Evaluation Benchmark for Modular Attribution in LLM Agents</title>
<link>https://arxiv.org/abs/2502.00510</link>
<guid>https://arxiv.org/abs/2502.00510</guid>
<content:encoded><![CDATA[
arXiv:2502.00510v2 Announce Type: replace 
Abstract: Large Language Model (LLM) agents frameworks often employ modular architectures, incorporating components such as planning, reasoning, action execution, and reflection to tackle complex tasks. However, quantifying the contribution of each module to overall system performance remains a significant challenge, impeding optimization and interpretability. To address this, we introduce CapaBench (Capability-level Assessment Benchmark), an evaluation framework grounded in cooperative game theory's Shapley Value, which systematically measures the marginal impact of individual modules and their interactions within an agent's architecture. By replacing default modules with test variants across all possible combinations, CapaBench provides a principle method for attributing performance contributions. Key contributions include: (1) We are the first to propose a Shapley Value-based methodology for quantifying the contributions of capabilities in LLM agents; (2) Modules with high Shapley Values consistently lead to predictable performance gains when combined, enabling targeted optimization; and (3) We build a multi-round dataset of over 1,500 entries spanning diverse domains and practical task scenarios, enabling comprehensive evaluation of agent capabilities. CapaBench bridges the gap between component-level evaluation and holistic system assessment, providing actionable insights for optimizing modular LLM agents and advancing their deployment in complex, real-world scenarios.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ML-Dev-Bench: Comparative Analysis of AI Agents on ML development workflows</title>
<link>https://arxiv.org/abs/2502.00964</link>
<guid>https://arxiv.org/abs/2502.00964</guid>
<content:encoded><![CDATA[
arXiv:2502.00964v2 Announce Type: replace 
Abstract: In this report, we present ML-Dev-Bench, a benchmark aimed at testing agentic capabilities on applied Machine Learning development tasks. While existing benchmarks focus on isolated coding tasks or Kaggle-style competitions, ML-Dev-Bench tests agents' ability to handle the full complexity of ML development workflows. The benchmark assesses performance across critical aspects including dataset handling, model training, improving existing models, debugging, and API integration with popular ML tools. We evaluate three agents -- ReAct, Openhands, and AIDE -- on a diverse set of 30 tasks, providing insights into their strengths and limitations in handling practical ML development challenges.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Clicks to Conversations: Evaluating the Effectiveness of Conversational Agents in Statistical Analysis</title>
<link>https://arxiv.org/abs/2502.08114</link>
<guid>https://arxiv.org/abs/2502.08114</guid>
<content:encoded><![CDATA[
arXiv:2502.08114v2 Announce Type: replace 
Abstract: The rapid proliferation of data science forced different groups of individuals with different backgrounds to adapt to statistical analysis. We hypothesize that conversational agents are better suited for statistical analysis than traditional graphical user interfaces (GUI). In this work, we propose a novel conversational agent, StatZ, for statistical analysis. We evaluate the efficacy of StatZ relative to established statistical software:SPSS, SAS, Stata, and JMP in terms of accuracy, task completion time, user experience, and user satisfaction. We combined the proposed analysis question from state-of-the-art language models with suggestions from statistical analysis experts and tested with 51 participants from diverse backgrounds. Our experimental design assessed each participant's ability to perform statistical analysis tasks using traditional statistical analysis tools with GUI and our conversational agent. Results indicate that the proposed conversational agents significantly outperform GUI statistical software in all assessed metrics, including quantitative (task completion time, accuracy, and user experience), and qualitative (user satisfaction) metrics. Our findings underscore the potential of using conversational agents to enhance statistical analysis processes, reducing cognitive load and learning curves and thereby proliferating data analysis capabilities, to individuals with limited knowledge of statistics.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Whoever Said Money Won't Solve All Your Problems? Weighted Envy-free Allocation with Subsidy</title>
<link>https://arxiv.org/abs/2502.09006</link>
<guid>https://arxiv.org/abs/2502.09006</guid>
<content:encoded><![CDATA[
arXiv:2502.09006v2 Announce Type: replace 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any others relative to their own. Often, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies.
  Previous work relied on characterizations of unweighted envy-freeness (EF), that fail in the weighted setting. This makes our new setting challenging. We present polynomial-time algorithms that compute WEF allocations with a guaranteed upper bound on total subsidy for monotone valuations and various subclasses thereof.
  We also present an efficient algorithm to compute a fair allocation of items and money, when the budget is not enough to make the allocation WEF. This algorithm is new even for the unweighted setting.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Statistical Inference for Fisher Market Equilibrium</title>
<link>https://arxiv.org/abs/2209.15422</link>
<guid>https://arxiv.org/abs/2209.15422</guid>
<content:encoded><![CDATA[
arXiv:2209.15422v2 Announce Type: replace-cross 
Abstract: Statistical inference under market equilibrium effects has attracted increasing attention recently. In this paper we focus on the specific case of linear Fisher markets. They have been widely use in fair resource allocation of food/blood donations and budget management in large-scale Internet ad auctions. In resource allocation, it is crucial to quantify the variability of the resource received by the agents (such as blood banks and food banks) in addition to fairness and efficiency properties of the systems. For ad auction markets, it is important to establish statistical properties of the platform's revenues in addition to their expected values. To this end, we propose a statistical framework based on the concept of infinite-dimensional Fisher markets. In our framework, we observe a market formed by a finite number of items sampled from an underlying distribution (the "observed market") and aim to infer several important equilibrium quantities of the underlying long-run market. These equilibrium quantities include individual utilities, social welfare, and pacing multipliers. Through the lens of sample average approximation (SSA), we derive a collection of statistical results and show that the observed market provides useful statistical information of the long-run market. In other words, the equilibrium quantities of the observed market converge to the true ones of the long-run market with strong statistical guarantees. These include consistency, finite sample bounds, asymptotics, and confidence. As an extension, we discuss revenue inference in quasilinear Fisher markets.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>How opinions get more extreme in an age of information abundance</title>
<link>https://arxiv.org/abs/2305.16855</link>
<guid>https://arxiv.org/abs/2305.16855</guid>
<content:encoded><![CDATA[
arXiv:2305.16855v2 Announce Type: replace-cross 
Abstract: We live in an age of information abundance but know little about how this influences our opinions or attitudes. A common expectation is that people consulting numerous pieces of information, well balancing the different sides of an issue, will adopt a moderate attitude about the issue. We claim that this expectation is deceitful and suggest that people tend to get extreme and dogmatic about an issue when they consult abundant unbiased information. The cause for this extremization is a hardening confirmation bias -- when their attitude gets more extreme, people get more likely to ignore information that differs from their views. Our claim is based on simulations of two fundamentally different computational models: a Bounded Confidence model and an empirically calibrated Persuasive Argument model. For both models, the attitude tends to be extreme when the computational agent consults abundant unbiased information. We analyze the extremization pathways displayed in the models and discuss how our results may affect views on polarization, and on the role of online media.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Induced Matching Distance: A Novel Topological Metric with Applications in Robotics</title>
<link>https://arxiv.org/abs/2502.02112</link>
<guid>https://arxiv.org/abs/2502.02112</guid>
<content:encoded><![CDATA[
arXiv:2502.02112v2 Announce Type: replace-cross 
Abstract: This paper introduces the induced matching distance, a novel topological metric designed to compare discrete structures represented by a symmetric non-negative function. We apply this notion to analyze agent trajectories over time. We use dynamic time warping to measure trajectory similarity and compute the 0-dimensional persistent homology to identify relevant connected components, which, in our context, correspond to groups of similar trajectories. To track the evolution of these components across time, we compute induced matching distances, which preserve the coherence of their dynamic behavior. We then obtain a 1-dimensional signal that quantifies the consistency of trajectory groups over time. Our experiments demonstrate that our approach effectively differentiates between various agent behaviors, highlighting its potential as a robust tool for topological analysis in robotics and related fields.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient and Trustworthy Block Propagation for Blockchain-enabled Mobile Embodied AI Networks: A Graph Resfusion Approach</title>
<link>https://arxiv.org/abs/2502.09624</link>
<guid>https://arxiv.org/abs/2502.09624</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile Embodied AI Networks (MEANETs)，区块链技术，信任计算机制，图神经网络，Resfusion模型

总结:<br />
本文提出了一个针对移动具身人工智能网络（MEANETs）中区块链赋能的信任worthy块传播优化框架。该框架旨在解决现有块传播机制在效率和安全性方面的挑战以及对动态拓扑变化的适应性不足问题。文章创新性地提出了一种基于信任云模型的矿工信任评估机制，充分考虑了随机性和模糊性。同时，利用图神经网络和扩散模型的优势，构建了一个名为Resfusion模型的图模型，能够有效并自适应地生成最优区块传播路径。模拟结果显示，所提模型在区块传播效率和可信度方面优于其他路由机制，并且具有出色的动态环境适应能力，特别适用于快速变化的MEANETs场景。 <div>
arXiv:2502.09624v1 Announce Type: new 
Abstract: By synergistically integrating mobile networks and embodied artificial intelligence (AI), Mobile Embodied AI Networks (MEANETs) represent an advanced paradigm that facilitates autonomous, context-aware, and interactive behaviors within dynamic environments. Nevertheless, the rapid development of MEANETs is accompanied by challenges in trustworthiness and operational efficiency. Fortunately, blockchain technology, with its decentralized and immutable characteristics, offers promising solutions for MEANETs. However, existing block propagation mechanisms suffer from challenges such as low propagation efficiency and weak security for block propagation, which results in delayed transmission of vehicular messages or vulnerability to malicious tampering, potentially causing severe traffic accidents in blockchain-enabled MEANETs. Moreover, current block propagation strategies cannot effectively adapt to real-time changes of dynamic topology in MEANETs. Therefore, in this paper, we propose a graph Resfusion model-based trustworthy block propagation optimization framework for consortium blockchain-enabled MEANETs. Specifically, we propose an innovative trust calculation mechanism based on the trust cloud model, which comprehensively accounts for randomness and fuzziness in the miner trust evaluation. Furthermore, by leveraging the strengths of graph neural networks and diffusion models, we develop a graph Resfusion model to effectively and adaptively generate the optimal block propagation trajectory. Simulation results demonstrate that the proposed model outperforms other routing mechanisms in terms of block propagation efficiency and trustworthiness. Additionally, the results highlight its strong adaptability to dynamic environments, making it particularly suitable for rapidly changing MEANETs.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fine-Tuning Foundation Models with Federated Learning for Privacy Preserving Medical Time Series Forecasting</title>
<link>https://arxiv.org/abs/2502.09744</link>
<guid>https://arxiv.org/abs/2502.09744</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、Foundation Models、时间序列预测、Electrocardiogram (ECG)、Impedance Cardiography (ICG)

总结:
本文探讨了使用联邦学习（Federated Learning）对时间序列基础模型（Foundation Models）进行微调以进行心电图（Electrocardiogram, ECG）和阻抗心动图（Impedance Cardiography, ICG）数据预测的应用。研究通过不同联邦学习技术在各种数据异质性配置下进行了实验，并分析了联邦学习在此场景下所面临的挑战。结果显示，联邦学习对于基于时间序列预测任务的模型微调可以有效，但其效果取决于客户端间的数据分布情况。文章强调了在应用联邦学习于基础模型微调时需要权衡的问题。 <div>
arXiv:2502.09744v1 Announce Type: new 
Abstract: Federated Learning (FL) provides a decentralized machine learning approach, where multiple devices or servers collaboratively train a model without sharing their raw data, thus enabling data privacy. This approach has gained significant interest in academia and industry due to its privacy-preserving properties, which are particularly valuable in the medical domain where data availability is often protected under strict regulations. A relatively unexplored area is the use of FL to fine-tune Foundation Models (FMs) for time series forecasting, potentially enhancing model efficacy by overcoming data limitation while maintaining privacy. In this paper, we fine-tuned time series FMs with Electrocardiogram (ECG) and Impedance Cardiography (ICG) data using different FL techniques. We then examined various scenarios and discussed the challenges FL faces under different data heterogeneity configurations. Our empirical results demonstrated that while FL can be effective for fine-tuning FMs on time series forecasting tasks, its benefits depend on the data distribution across clients. We highlighted the trade-offs in applying FL to FM fine-tuning.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Entropy-Based Ransomware Detection Using Autonomous Feature Resonance</title>
<link>https://arxiv.org/abs/2502.09833</link>
<guid>https://arxiv.org/abs/2502.09833</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Feature Resonance、熵基特征交互、检测精度、ransomware、自学习机制

<br /><br />总结：
本文提出了一种名为自主特征共振（Autonomous Feature Resonance）的新颖方法，用于提高勒索软件检测的精确度和效率。该方法通过分析系统进程中基于熵的特征交互来突破传统检测技术的局限性。实验结果显示，该方法的整体检测准确率达到97.3%，误报率与漏报率分别为1.8%和2.1%，优于传统的签名检测和行为分析法。其分散式架构允许本地数据处理，降低了延迟并提升了可扩展性；同时，内置的自学习机制使其能持续适应新兴威胁。在LockBit 3.0、BlackCat和Royal等多种不同类型的勒索软件上，该方法表现出稳定的低检测延迟和高效资源利用。由于依赖熵作为区分特征，该方法具有对抗混淆技术的鲁棒性，非常适合实时部署在高吞吐量环境中。这些发现强调了基于熵的方法在提升网络安全框架方面的潜力，为现代勒索软件检测挑战提供了具有可扩展性和适应性的解决方案。 <div>
arXiv:2502.09833v1 Announce Type: new 
Abstract: The increasing sophistication of cyber threats has necessitated the development of advanced detection mechanisms capable of identifying malicious activities with high precision and efficiency. A novel approach, termed Autonomous Feature Resonance, is introduced to address the limitations of traditional ransomware detection methods through the analysis of entropy-based feature interactions within system processes. The proposed method achieves an overall detection accuracy of 97.3\%, with false positive and false negative rates of 1.8\% and 2.1\%, respectively, outperforming existing techniques such as signature-based detection and behavioral analysis. Its decentralized architecture enables local processing of data, reducing latency and improving scalability, while a self-learning mechanism ensures continuous adaptation to emerging threats. Experimental results demonstrate consistent performance across diverse ransomware families, including LockBit 3.0, BlackCat, and Royal, with low detection latency and efficient resource utilization. The method's reliance on entropy as a distinguishing feature provides robustness against obfuscation techniques, making it suitable for real-time deployment in high-throughput environments. These findings highlight the potential of entropy-based approaches to enhance cybersecurity frameworks, offering a scalable and adaptive solution for modern ransomware detection challenges.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Topological Neural Networks over the Air</title>
<link>https://arxiv.org/abs/2502.10070</link>
<guid>https://arxiv.org/abs/2502.10070</guid>
<content:encoded><![CDATA[
<div> 关键词：Topological neural networks (TNNs), realistic communication scenarios, channel impairments, over-the-air computation, regular cell complexes

<br /><br />总结：
本文提出了一种新颖的拓扑神经网络（TNN）设计，该设计针对实际通信场景中的通道效应进行了优化，能在常规细胞复杂度上进行空中计算。该方法将无线通信模型融入到网络架构中，在训练和推理过程中考虑了衰落和噪声等通道损伤对不同信号阶数和邻域内的拓扑卷积滤波操作的影响。数值结果表明，相较于现有的要么忽视通信影响、要么基于图的网络架构，该新架构在应对通道损伤时表现出更好的鲁棒性和更优的性能。 <div>
arXiv:2502.10070v1 Announce Type: new 
Abstract: Topological neural networks (TNNs) are information processing architectures that model representations from data lying over topological spaces (e.g., simplicial or cell complexes) and allow for decentralized implementation through localized communications over different neighborhoods. Existing TNN architectures have not yet been considered in realistic communication scenarios, where channel effects typically introduce disturbances such as fading and noise. This paper aims to propose a novel TNN design, operating on regular cell complexes, that performs over-the-air computation, incorporating the wireless communication model into its architecture. Specifically, during training and inference, the proposed method considers channel impairments such as fading and noise in the topological convolutional filtering operation, which takes place over different signal orders and neighborhoods. Numerical results illustrate the architecture's robustness to channel impairments during testing and the superior performance with respect to existing architectures, which are either communication-agnostic or graph-based.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Anthemius: Efficient &amp; Modular Block Assembly for Concurrent Execution</title>
<link>https://arxiv.org/abs/2502.10074</link>
<guid>https://arxiv.org/abs/2502.10074</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、并行执行引擎、交易冲突、Anthemius、吞吐量

总结:
<br />
本文探讨了区块链（如以太坊）中由于串行执行交易导致的潜在吞吐量限制问题。为提高性能，通常采用乐观或引导式的并行执行引擎。然而，研究表明，这类引擎的性能取决于工作负载性质，有时仅能实现相对于串行执行60%的速度提升。当大量交易访问相同资源时，执行效率无法显著提升，单个流行应用就可能成为执行瓶颈。

为此，本文提出了Anthemius，一种优化并行交易执行吞吐量的区块构造算法。通过全面评估不同工作负载下Anthemius的表现，结果显示其能使底层并行执行引擎处理的交易数量增加一倍以上。 <div>
arXiv:2502.10074v1 Announce Type: new 
Abstract: Many blockchains such as Ethereum execute all incoming transactions sequentially significantly limiting the potential throughput. A common approach to scale execution is parallel execution engines that fully utilize modern multi-core architectures. Parallel execution is then either done optimistically, by executing transactions in parallel and detecting conflicts on the fly, or guided, by requiring exhaustive client transaction hints and scheduling transactions accordingly.
  However, recent studies have shown that the performance of parallel execution engines depends on the nature of the underlying workload. In fact, in some cases, only a 60% speed-up compared to sequential execution could be obtained. This is the case, as transactions that access the same resources must be executed sequentially. For example, if 10% of the transactions in a block access the same resource, the execution cannot meaningfully scale beyond 10 cores. Therefore, a single popular application can bottleneck the execution and limit the potential throughput.
  In this paper, we introduce Anthemius, a block construction algorithm that optimizes parallel transaction execution throughput. We evaluate Anthemius exhaustively under a range of workloads, and show that Anthemius enables the underlying parallel execution engine to process over twice as many transactions.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cooperative Multi-Agent Planning with Adaptive Skill Synthesis</title>
<link>https://arxiv.org/abs/2502.10148</link>
<guid>https://arxiv.org/abs/2502.10148</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习(MARL)，大型语言模型(LLM)，视觉语言模型(VLM)，动态技能库，COMPASS

总结:
本文提出了一种名为COMPASS的新颖多智能体架构，旨在解决基于多智能体强化学习(MARL)的协作系统在样本效率、可解释性和转移性方面的挑战。该架构融合了大型语言模型(LLM)与视觉语言模型(VLM)，并结合动态技能库和结构化通信实现去中心化的闭环决策制定。动态技能库通过演示学习初始化，并通过规划器引导的任务进行进化，以适应不同的策略。在部分可观测环境下，COMPASS利用多跳通信传递实体信息。在改进后的StarCraft Multi-Agent Challenge (SMACv2)平台上进行评估显示，与当前最先进的MARL算法相比，COMPASS在对称场景中的胜率提高了高达30%。 <div>
arXiv:2502.10148v1 Announce Type: new 
Abstract: Despite much progress in training distributed artificial intelligence (AI), building cooperative multi-agent systems with multi-agent reinforcement learning (MARL) faces challenges in sample efficiency, interpretability, and transferability. Unlike traditional learning-based methods that require extensive interaction with the environment, large language models (LLMs) demonstrate remarkable capabilities in zero-shot planning and complex reasoning. However, existing LLM-based approaches heavily rely on text-based observations and struggle with the non-Markovian nature of multi-agent interactions under partial observability. We present COMPASS, a novel multi-agent architecture that integrates vision-language models (VLMs) with a dynamic skill library and structured communication for decentralized closed-loop decision-making. The skill library, bootstrapped from demonstrations, evolves via planner-guided tasks to enable adaptive strategies. COMPASS propagates entity information through multi-hop communication under partial observability. Evaluations on the improved StarCraft Multi-Agent Challenge (SMACv2) demonstrate COMPASS achieves up to 30\% higher win rates than state-of-the-art MARL algorithms in symmetric scenarios.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized State Estimation and Opacity Verification Based on Partially Ordered Observation Sequences</title>
<link>https://arxiv.org/abs/2502.10367</link>
<guid>https://arxiv.org/abs/2502.10367</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式观测架构、状态估计、不透明性验证、全序列结构、初始状态不透明性、同步态不透明性

<br /><br />总结:
本文研究了一种分布式观测架构下的状态估计和不透明性验证问题。文章重点关注了一个由多个观察站点记录行为的离散事件系统，这些站点在发生“同步”时向协调器传输它们记录的部分有序观测序列。为了解析协调器视角下的系统行为，作者提出了“全序列结构”(ASS)的概念，该概念能够简洁地捕获不同观察站点提供的信息下每个系统状态的状态演变情况。基于ASS，构建了用于离线状态估计的当前状态及初始状态估计算法。使用ASS在分布式观测架构中进行不透明性验证相比于现有方法显著降低了复杂度。文中还讨论了如何在协调器处验证初始状态不透明性以及一种新的不透明性概念——同步态不透明性。 <div>
arXiv:2502.10367v1 Announce Type: new 
Abstract: In this paper, we investigate state estimation and opacity verification problems within a decentralized observation architecture. Specifically, we consider a discrete event system whose behavior is recorded by a set of observation sites. These sites transmit the partially ordered sequences of observations that they record to a coordinator whenever a \textit{synchronization} occurs. To properly analyze the system behavior from the coordinator's viewpoint, we first introduce the notion of an \textit{All Sequence Structure} (ASS), which concisely captures the state evolution of each system state upon different information provided by the observation sites. Based on the ASS, we then construct corresponding current-state and initial-state estimators for offline state estimation at the coordinator. When used to verify state-isolation properties under this decentralized architecture, the use of ASS demonstrates a significant reduction in complexity compared with existing approaches in the literature. In particular, we discuss how to verify initial-state opacity at the coordinator, as well as a novel opacity notion, namely current-state-at-synchronization opacity.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Ephemeral Rollups are All you Need</title>
<link>https://arxiv.org/abs/2311.02650</link>
<guid>https://arxiv.org/abs/2311.02650</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链游戏、完全on-chain、Solana虚拟机、可扩展性、Ephemeral Rollups

总结:
本文提出了一种利用Solana虚拟机（SVM）来实现完全on-chain（FOC）游戏的可扩展性框架，旨在解决此类游戏的成本和可扩展性问题。该框架基于Entity-Component-System（ECS）模式，系统性地开发、使用和发布模块化的逻辑组件。为了进一步提升可扩展性和资源优化，文章引入了Ephemeral Rollups（ERs）的概念，这是一种可以定制运行速度、配置可调整的计时机制、可证明会话以及无gas交易的二层解决方案，以此克服横向扩展的权衡，同时保证了无需牺牲组合性和可扩展性的特性。 <div>
arXiv:2311.02650v4 Announce Type: replace 
Abstract: In the realm of open and composable gaming, we envision platforms where users actively expand, create, engage, and immerse themselves in a rich world of entertainment. One promising avenue for achieving this vision is through fully on-chain (FOC) games, where both game state and logic reside on the blockchain, maximizing composability. However, we must grapple with inherent limitations and trade-offs, particularly in terms of costs and scalability. This paper proposes a framework that leverages the Solana Virtual Machine (SVM) to scale FOC games without state fragmentation or compromised trust assumptions. The framework introduces a systematic approach for discovering, utilizing, and publishing modular pieces of logic as components deeply rooted in the Entity-Component-System (ECS) pattern. To enhance scalability and resource optimization, we introduce the concept of Ephemeral Rollups (ERs) that overcome the tradeoffs of L2 horizontal scaling. These dedicated runtimes can be customized to provide higher operational speed, configurable ticking mechanisms, provable sessions and gasless transactions without composability-scalability tradeoffs.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CTE-MLO: Continuous-time and Efficient Multi-LiDAR Odometry with Localizability-aware Point Cloud Sampling</title>
<link>https://arxiv.org/abs/2408.04901</link>
<guid>https://arxiv.org/abs/2408.04901</guid>
<content:encoded><![CDATA[
<div> 关键词：LiDAR定位，多LiDAR odometry，连续时间估计，卡尔曼滤波器，实时性能

总结:

本文提出了一种新的多LiDAR里程计方法——连续时间和高效多LiDAR里程计（CTE-MLO），旨在通过连续时间视角增强LiDAR定位和映射系统的性能。该方法将高斯过程估计与卡尔曼滤波器相结合，使每个LiDAR点能够根据其时间戳查询对应的连续时间轨迹。同时，设计了一种分散式多LiDAR同步方案，无需主LiDAR分配即可合并来自不同LiDAR的点云数据。为了提高MLO的实时性而不牺牲鲁棒性，文中还提出了一个考虑局部可定位性的点云采样策略。最后，CTE-MLO在一个卡尔曼滤波框架内集成了同步、局部可定位性感知采样、连续时间估计和体素地图管理，能够在少数线性迭代中实现高精度和实时的连续时间估计。实验结果表明，该方法在各种场景下均表现出优异的效果，包括公共数据集和实际应用案例。相关代码已开源，可在https://github.com/shenhm516/CTE-MLO获取，以供社区使用。 <div>
arXiv:2408.04901v2 Announce Type: replace 
Abstract: In recent years, LiDAR-based localization and mapping methods have achieved significant progress thanks to their reliable and real-time localization capability. Considering single LiDAR odometry often faces hardware failures and degeneracy in practical scenarios, Multi-LiDAR Odometry (MLO), as an emerging technology, is studied to enhance the performance of LiDAR-based localization and mapping systems. However, MLO can suffer from high computational complexity introduced by dense point clouds that are fused from multiple LiDARs, and the continuous-time measurement characteristic is constantly neglected by existing LiDAR odometry. This motivates us to develop a Continuous-Time and Efficient MLO, namely CTE-MLO, which can achieve accurate and real-time estimation using multi-LiDAR measurements through a continuous-time perspective. In this paper, the Gaussian process estimation is naturally combined with the Kalman filter, which enables each LiDAR point in a point stream to query the corresponding continuous-time trajectory using its time instants. A decentralized multi-LiDAR synchronization scheme is also devised to combine points from separate LiDARs into a single point cloud without the primary LiDAR assignment. Moreover, with the aim of improving the real-time performance of MLO without sacrificing robustness, a point cloud sampling strategy is designed with the consideration of localizability. To this end, CTE-MLO integrates synchronization, localizability-aware sampling, continuous-time estimation, and voxel map management within a Kalman filter framework, which can achieve high accuracy and robust continuous-time estimation within only a few linear iterations. The effectiveness of the proposed method is demonstrated through various scenarios, including public datasets and real-world applications. The code is available at https://github.com/shenhm516/CTE-MLO to benefit the community.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Auto.gov: Learning-based Governance for Decentralized Finance (DeFi)</title>
<link>https://arxiv.org/abs/2302.09551</link>
<guid>https://arxiv.org/abs/2302.09551</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized finance (DeFi), Auto.gov, deep Q-network (DQN), reinforcement learning (RL), governance framework

总结:
本文提出了一种名为“Auto.gov”的基于深度Q网络（DQN）强化学习的自治治理框架，用于改进去中心化金融（DeFi）协议的参数调整。传统DeFi治理易受人为偏见和金融风险影响，而Auto.gov通过数据驱动、半自动化的参数调整策略提高了效率和对市场操纵的抵御能力。为模拟测试，研究构建了一个类似于Aave借贷协议的DeFi环境。实验结果显示，相较于基准方法，Auto.gov在实际市场数据测试中至少提升了14%的性能指标——协议盈利能力，并且相对于静态基线模型有十倍的提升。因此，Auto.gov被证明比传统的治理方式更为高效和有效，有助于增强DeFi协议的安全性、盈利性和可持续性。 <div>
arXiv:2302.09551v3 Announce Type: replace-cross 
Abstract: Decentralized finance (DeFi) is an integral component of the blockchain ecosystem, enabling a range of financial activities through smart-contract-based protocols. Traditional DeFi governance typically involves manual parameter adjustments by protocol teams or token holder votes, and is thus prone to human bias and financial risks, undermining the system's integrity and security. While existing efforts aim to establish more adaptive parameter adjustment schemes, there remains a need for a governance model that is both more efficient and resilient to significant market manipulations. In this paper, we introduce "Auto.gov", a learning-based governance framework that employs a deep Q-network (DQN) reinforcement learning (RL) strategy to perform semi-automated, data-driven parameter adjustments. We create a DeFi environment with an encoded action-state space akin to the Aave lending protocol for simulation and testing purposes, where Auto.gov has demonstrated the capability to retain funds that would have otherwise been lost to price oracle attacks. In tests with real-world data, Auto.gov outperforms the benchmark approaches by at least 14% and the static baseline model by tenfold, in terms of the preset performance metric-protocol profitability. Overall, the comprehensive evaluations confirm that Auto.gov is more efficient and effective than traditional governance methods, thereby enhancing the security, profitability, and ultimately, the sustainability of DeFi protocols.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Performance Modeling and Evaluation of Hyperledger Fabric: An Analysis Based on Transaction Flow and Endorsement Policies</title>
<link>https://arxiv.org/abs/2502.08755</link>
<guid>https://arxiv.org/abs/2502.08755</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、工业环境、性能问题、Hyperledger Fabric、评估框架

总结:
<br />
本文探讨了区块链技术在工业环境中应用的性能问题，重点关注了流行的许可型区块链平台——Hyperledger Fabric（HLF）。研究提出了一种基于建模和实验的性能评估框架。研究表明，区块大小和到达率可能影响系统吞吐量（降低70%）、延迟（增加1500%）以及环境利用率（提高28%）。另一方面，使用多个网关可以降低延迟（减少75%），但会降低吞吐量（减少60%）。 <div>
arXiv:2502.08755v1 Announce Type: new 
Abstract: Blockchain is a paradigm derived from distributed systems, protocols, and security concepts. However, can blockchain applications provide services in industrial environments, especially concerning performance issues? In blockchains, long response times can impair both user and service experience, and intensive resource use may increase the costs of service provision. The proposed paper tries to answer this question by evaluating the performance of one of the most popular permissioned blockchain platforms, the Hyperledger Fabric (HLF). We provide a framework for performance evaluation based on modeling and experimentation. The results indicate that block size and arrival rate can compromise throughput (by -70%), latency (by +1,500%), and environment utilization (by +28%) and that multiple gateways can reduce latency (by -75%), and throughput (by -60%)
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal Resource Utilization in Hyperledger Fabric: A Comprehensive SPN-Based Performance Evaluation Paradigm</title>
<link>https://arxiv.org/abs/2502.08765</link>
<guid>https://arxiv.org/abs/2502.08765</guid>
<content:encoded><![CDATA[
<div> 关键词: Hyperledger Fabric、Stochastic Petri Net (SPN)模型、性能分析、区块链参数、交易率

总结:
Hyperledger Fabric 是一个领先的许可型区块链框架，确保企业应用的数据安全和可审计性。随着该平台上应用的增长，理解其涉及多种区块链参数的复杂配置变得至关重要，因为这些配置会显著影响系统的性能和成本。本文提出了一种使用 Stochastic Petri Net (SPN) 模型的方法来分析 Hyperledger Fabric 的性能，考虑了区块链参数、计算资源和交易速率的变化。通过案例研究验证了该模型的实用性，有助于区块链管理员为其应用程序确定最佳配置。文中关键观察指出，块大小对系统响应时间有重要影响，我们注意到由于交易到达率的变化，响应时间增加了1到25秒。 <div>
arXiv:2502.08765v1 Announce Type: new 
Abstract: Hyperledger Fabric stands as a leading framework for permissioned blockchain systems, ensuring data security and auditability for enterprise applications. As applications on this platform grow, understanding its complex configuration concerning various blockchain parameters becomes vital. These configurations significantly affect the system's performance and cost. In this research, we introduce a Stochastic Petri Net (SPN) model to analyze Hyperledger Fabric's performance, considering variations in blockchain parameters, computational resources, and transaction rates. We provide case studies to validate the utility of our model, aiding blockchain administrators in determining optimal configurations for their applications. A key observation from our model highlights the block size's role in system response time. We noted an increased mean response time, between 1 to 25 seconds, due to variations in transaction arrival rates.
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UAT20: Unifying Liquidity Across Rollups</title>
<link>https://arxiv.org/abs/2502.08919</link>
<guid>https://arxiv.org/abs/2502.08919</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、rollup、流动性碎片化、UAT20、CRDTs

总结:
本文针对以太坊生态中的扩容解决方案——如Arbitrum和Optimism等rollup技术所带来的流动性碎片化问题进行了探讨。该问题使得用户在多个rollup上的代币分布导致流动性分散，参与交易和借贷活动受到门槛限制。为此，文章提出了一个名为UAT20的通用抽象代币标准，旨在跨rollup解决流动性碎片化。通过利用冲突自由复制数据类型（CRDTs），UAT20确保了在多个rollup间维持一致的状态。同时，文中引入了一个两阶段提交协议来解决交易冲突，从而实现无缝且安全的流动性统一。通过实证分析，证明了UAT20在缓解rollup内部的流动性碎片化方面的必要性和有效性。 <div>
arXiv:2502.08919v1 Announce Type: new 
Abstract: Ethereum has been a cornerstone of the decentralized ecosystem, with rollup-based scaling solutions like Arbitrum and Optimism significantly expanding its capabilities. These rollups enhance scalability and foster innovation, but their rapid proliferation has introduced \emph{liquidity fragmentation}. Specifically, tokens distributed on multiple rollups fragment the liquidity of users, complicating participation in trading and lending activities bound by minimum liquidity thresholds.
  This paper proposes UAT20, a universal abstract token standard, to address liquidity fragmentation across rollups. Leveraging Conflict-free Replicated Data Types (CRDTs), UAT20 ensures consistent states across multiple rollups. We introduce a two-phase commit protocol to resolve transaction conflicts, enabling seamless and secure liquidity unification. Finally, our empirical analysis demonstrated the necessity and effectiveness of UAT20 in mitigating liquidity fragmentation within Rollups.
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Logical foundations of Smart Contracts</title>
<link>https://arxiv.org/abs/2502.09232</link>
<guid>https://arxiv.org/abs/2502.09232</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、形式化方法、情境计算、逻辑基础、Golog

总结:
本文提出了一种使用情境计算为智能合约建立逻辑基础的方法。随着复杂领域的出现，需要适当的形式主义来准确描述和推理这些领域，智能合约作为一种在分布式系统中通过区块链强制执行正式协议的方式存在于 Cyber Physical Systems 中。然而，基于法律合同实现智能合约的过程既漫长又费力。针对这一问题，该论文采用情境计算——一种用于动态和复杂系统推理的逻辑方法——作为统一且相对普适的正式形式。提议将智能合约用Prolog编写的Golog（一种基于情境计算的行为建模编程语言）进行实现。 <div>
arXiv:2502.09232v1 Announce Type: new 
Abstract: Nowadays, sophisticated domains are emerging which require appropriate formalisms to be specified accurately in order to reason about them. One such domain is constituted of smart contracts that have emerged in cyber physical systems as a way of enforcing formal agreements between components of these systems.  Smart contracts self-execute to run and share business processes through blockchain, in decentralized systems, with many different participants. Legal contracts are in many cases complex documents, with a number of exceptions, and many subcontracts. The implementation of smart contracts based on legal contracts is a long and laborious task, that needs to include all actions, procedures, and the effects of actions related to the execution of the contract. An ongoing open problem in this area is to formally account for smart contracts using a uniform and somewhat universal formalism. This thesis proposes logical foundations to smart contracts using the Situation Calculus, a logic for reasoning about actions. Situation Calculus is one of the prominent logic-based artificial intelligence approaches that provides enough logical mechanism to specify and implement dynamic and complex systems such as contracts. Situation Calculus is suitable to show how worlds dynamically change.  Smart contracts are going to be implement with Golog (written en Prolog), a Situation Calculus-based programming language for modeling complex and dynamic behaviors.
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantifying Cryptocurrency Unpredictability: A Comprehensive Study of Complexity and Forecasting</title>
<link>https://arxiv.org/abs/2502.09079</link>
<guid>https://arxiv.org/abs/2502.09079</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、时间序列、预测性、复杂度熵因果平面、简单模型

总结:<br />
本文深入研究了加密货币时间序列的单变量可预测性。通过对Litecoin、Binance Coin、Bitcoin、Ethereum和XRP等数字货币与美元汇率的时间序列进行预测任务的研究，一方面使用布朗运动和彩色噪声作为基准，通过比较分析评估其复杂性和随机性。结果显示，在单变量环境下，加密货币时间序列表现出与布朗噪声相似的特性。另一方面，应用统计学、机器学习和深度学习等多种模型进行时间序列预测，显示出加密货币具有较低的可预测性。值得注意的是，研究发现简单的朴素模型在不同预测期和时间窗口下的预测精度持续优于复杂的机器学习和深度学习模型。结合复杂性和预测精度的研究揭示了加密货币市场的预测难度。这些发现为理解加密货币数据的内在特征以及重新审视预测加密货币价格变动所带来的挑战提供了有价值的见解。 <div>
arXiv:2502.09079v1 Announce Type: cross 
Abstract: This paper offers a thorough examination of the univariate predictability in cryptocurrency time-series. By exploiting a combination of complexity measure and model predictions we explore the cryptocurrencies time-series forecasting task focusing on the exchange rate in USD of Litecoin, Binance Coin, Bitcoin, Ethereum, and XRP. On one hand, to assess the complexity and the randomness of these time-series, a comparative analysis has been performed using Brownian and colored noises as a benchmark. The results obtained from the Complexity-Entropy causality plane and power density spectrum analysis reveal that cryptocurrency time-series exhibit characteristics closely resembling those of Brownian noise when analyzed in a univariate context. On the other hand, the application of a wide range of statistical, machine and deep learning models for time-series forecasting demonstrates the low predictability of cryptocurrencies. Notably, our analysis reveals that simpler models such as Naive models consistently outperform the more complex machine and deep learning ones in terms of forecasting accuracy across different forecast horizons and time windows. The combined study of complexity and forecasting accuracies highlights the difficulty of predicting the cryptocurrency market. These findings provide valuable insights into the inherent characteristics of the cryptocurrency data and highlight the need to reassess the challenges associated with predicting cryptocurrency's price movements.
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pilotfish: Distributed Execution for Scalable Blockchains</title>
<link>https://arxiv.org/abs/2401.16292</link>
<guid>https://arxiv.org/abs/2401.16292</guid>
<content:encoded><![CDATA[
<div> 关键词: Pilotfish、区块链、扩展性、交易执行引擎、弹性

总结:<br />
Pilotfish是首个为区块链设计的横向扩展交易执行引擎，旨在解决区块链系统因需过度配置验证器机器以应对峰值负载而导致的资源效率低下、成本扩展性差以及性能限制问题。它与懒散区块链架构无缝集成，填补了执行弹性的空白。Pilotfish通过确保可伸缩且强一致性的分布式事务处理、采用轻量级复制应对部分崩溃恢复，以及利用新颖的版本队列调度算法保持并发性，成功解决了这些挑战。实验表明，对于计算密集型工作负载，Pilotfish可以线性扩展至每个验证器至少八个工作者，同时保持低延迟。通过解决可伸缩执行问题，Pilotfish使区块链更接近实现端到端弹性，从而为构建高效和适应性强的区块链系统开辟了新的可能性。 <div>
arXiv:2401.16292v3 Announce Type: replace 
Abstract: Scalability is a crucial requirement for modern large-scale systems, enabling elasticity and ensuring responsiveness under varying load. While cloud systems have achieved scalable architectures, blockchain systems remain constrained by the need to over-provision validator machines to handle peak load. This leads to resource inefficiency, poor cost scaling, and limits on performance. To address these challenges, we introduce Pilotfish, the first scale-out transaction execution engine for blockchains. Pilotfish enables validators to scale horizontally by distributing transaction execution across multiple worker machines, allowing elasticity without compromising consistency or determinism. It integrates seamlessly with the lazy blockchain architecture, completing the missing piece of execution elasticity. To achieve this, Pilotfish tackles several key challenges: ensuring scalable and strongly consistent distributed transactions, handling partial crash recovery with lightweight replication, and maintaining concurrency with a novel versioned-queue scheduling algorithm. Our evaluation shows that Pilotfish scales linearly up to at least eight workers per validator for compute-bound workloads, while maintaining low latency. By solving scalable execution, Pilotfish brings blockchains closer to achieving end-to-end elasticity, unlocking new possibilities for efficient and adaptable blockchain systems.
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Federated Unsupervised Domain Adaptation for Regression on Small-Scale and High-Dimensional Biological Data</title>
<link>https://arxiv.org/abs/2411.17287</link>
<guid>https://arxiv.org/abs/2411.17287</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 小型异质数据集, 领域迁移, 联邦领域适应方法, Gaussian过程

<br /><br />总结:
本文提出了一种名为freda的新方法，用于解决小型、高维度和异质生物数据集中机器学习模型泛化能力不足的问题。针对现有的深度学习联邦领域适应方法主要聚焦于分类任务且不适合此类应用的情况，freda成为首个实现利用随机编码和安全聚合确保数据隐私的联邦训练Gaussian过程的方法，从而进行无监督的领域适应并处理回归任务。在不直接访问原始数据的前提下，freda能有效地进行领域适应，特别适用于高维、异质数据集的应用场景。实验结果显示，freda在DNA甲基化数据的年龄预测这一具有挑战性的任务上，其性能与中心化的最先进的方法相当，同时保证了完整的数据隐私。 <div>
arXiv:2411.17287v2 Announce Type: replace 
Abstract: Machine learning models often struggle with generalization in small, heterogeneous datasets due to domain shifts caused by variations in data collection and population differences. This challenge is particularly pronounced in biological data, where data is high-dimensional, small-scale, and decentralized across institutions. While federated domain adaptation methods (FDA) aim to address these challenges, most existing approaches rely on deep learning and focus on classification tasks, making them unsuitable for small-scale, high-dimensional applications. In this work, we propose freda, a privacy-preserving federated method for unsupervised domain adaptation in regression tasks. Unlike deep learning-based FDA approaches, freda is the first method to enable the federated training of Gaussian Processes to model complex feature relationships while ensuring complete data privacy through randomized encoding and secure aggregation. This allows for effective domain adaptation without direct access to raw data, making it well-suited for applications involving high-dimensional, heterogeneous datasets. We evaluate freda on the challenging task of age prediction from DNA methylation data, demonstrating that it achieves performance comparable to the centralized state-of-the-art method while preserving complete data privacy.
]]></content:encoded>
<pubDate>Fri, 14 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Centralization vs Decentralization in Hiring and Admissions</title>
<link>https://arxiv.org/abs/2502.07792</link>
<guid>https://arxiv.org/abs/2502.07792</guid>
<content:encoded><![CDATA[
<div> 关键词：高等教育、集中化、分散化、自动决策、公平性

总结:
这篇论文探讨了在大学招生等高等教育领域中，招聘和录取过程的集中化与分散化的战略影响。研究建立了一个模型，该模型揭示了集中化委员会可能无法充分反映个别招聘者偏好与分散化过程中招聘者需要承担额外面试成本之间的权衡关系。当集中化过程与招聘者的偏好对齐度较低时，招聘者倾向于选择分散化过程。然而，论文还指出分散化可能会对公平性造成严重影响，导致候选人之间获得录用的机会存在显著差异。因此，文章指出了集中化与分散化之间的权衡，并强调了这个问题的答案可能会给人们带来重大伤害。 <div>
arXiv:2502.07792v1 Announce Type: new 
Abstract: There is a range of ways to organize hiring and admissions in higher education, as in many domains, ranging from very centralized processes where a single person makes final decisions to very decentralized processes where many people make decisions about who to admit or hire. Decentralized processes can enable individual and collective empowerment, but this may come at the cost of efficiency. With the advent of automated decision making, this question of centralization has a big impact on hiring and admissions, given that automated systems often are easier to implement, or even require, more centralized decision making.
  In this paper, we develop a strategic model to explore the impact of the degree of centralization on both the candidates and the hirers, with a focus on university admissions. The model reflects a trade-off between a centralized committee where preferences may not capture individual hirers' preferences, and a decentralized process where individual hirers face extra costs to interview candidates themselves. We characterize when individual hirers prefer the decentralized process over the centralized process as a function of the degree to which the centralized process and hirers' preferences are aligned. We also show that decentralization can have devastating consequences for fairness, leading to major disparities in the likelihood of getting hired across candidates. Our results demonstrate the trade-offs that occur under the question of centralization vs decentralization, and point to how an answer to this question can impose significant harm to people in these systems.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RESIST: Resilient Decentralized Learning Using Consensus Gradient Descent</title>
<link>https://arxiv.org/abs/2502.07977</link>
<guid>https://arxiv.org/abs/2502.07977</guid>
<content:encoded><![CDATA[
<div> 关键词：Empirical Risk Minimization (ERM)，Decentralized Learning，Adversarial Interference，Man-in-the-Middle (MITM) Attack，RESIST算法

总结:
本文关注了在分布式机器学习环境中，由于缺乏中心服务器而导致的安全性和鲁棒性问题，特别是针对中间人攻击(MITM)对模型训练的影响。为解决这一挑战，文章提出了名为RESIST的新优化算法，该算法旨在抵抗恶意干扰并确保在分布式环境下的学习过程中的稳健性。RESIST可以保证对于强凸、Polyak-Lojasiewicz以及非凸的ERM问题的算法收敛和统计收敛。实验结果证实了RESIST在真实世界分布式学习对抗环境中所展示出的鲁棒性和可扩展性。 <div>
arXiv:2502.07977v1 Announce Type: new 
Abstract: Empirical risk minimization (ERM) is a cornerstone of modern machine learning (ML), supported by advances in optimization theory that ensure efficient solutions with provable algorithmic convergence rates, which measure the speed at which optimization algorithms approach a solution, and statistical learning rates, which characterize how well the solution generalizes to unseen data. Privacy, memory, computational, and communications constraints increasingly necessitate data collection, processing, and storage across network-connected devices. In many applications, these networks operate in decentralized settings where a central server cannot be assumed, requiring decentralized ML algorithms that are both efficient and resilient. Decentralized learning, however, faces significant challenges, including an increased attack surface for adversarial interference during decentralized learning processes. This paper focuses on the man-in-the-middle (MITM) attack, which can cause models to deviate significantly from their intended ERM solutions. To address this challenge, we propose RESIST (Resilient dEcentralized learning using conSensus gradIent deScenT), an optimization algorithm designed to be robust against adversarially compromised communication links. RESIST achieves algorithmic and statistical convergence for strongly convex, Polyak-Lojasiewicz, and nonconvex ERM problems. Experimental results demonstrate the robustness and scalability of RESIST for real-world decentralized learning in adversarial environments.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provably Robust Federated Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.08123</link>
<guid>https://arxiv.org/abs/2502.08123</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦强化学习(FRL)，拜占庭式鲁棒性，攻击，归一化攻击， Ensemble方法

总结:
<br />
本文研究了联邦强化学习(FRL)中的安全性问题，特别是其对于中毒攻击的脆弱性。现有的拜占庭式鲁棒性聚合技术被发现并不能抵御新提出的归一化攻击，这种攻击通过最大化策略更新的方向偏差来造成破坏。为了解决这个问题，文章提出了一个 Ensemble 方法，该方法训练多个全局策略，每个策略由一组使用基础聚合规则的代理学习。这些全局策略对特定测试状态分别预测动作，最终采取多数投票（离散动作系统）或几何中位数（连续动作系统）的方式来决定执行动作。实验结果显示，归一化攻击能严重干扰非 Ensemble 类型的拜占庭式鲁棒方法，而 Ensemble 方法则对中毒攻击表现出显著的抵抗力。 <div>
arXiv:2502.08123v1 Announce Type: new 
Abstract: Federated reinforcement learning (FRL) allows agents to jointly learn a global decision-making policy under the guidance of a central server. While FRL has advantages, its decentralized design makes it prone to poisoning attacks. To mitigate this, Byzantine-robust aggregation techniques tailored for FRL have been introduced. Yet, in our work, we reveal that these current Byzantine-robust techniques are not immune to our newly introduced Normalized attack. Distinct from previous attacks that targeted enlarging the distance of policy updates before and after an attack, our Normalized attack emphasizes on maximizing the angle of deviation between these updates. To counter these threats, we develop an ensemble FRL approach that is provably secure against both known and our newly proposed attacks. Our ensemble method involves training multiple global policies, where each is learnt by a group of agents using any foundational aggregation rule. These well-trained global policies then individually predict the action for a specific test state. The ultimate action is chosen based on a majority vote for discrete action systems or the geometric median for continuous ones. Our experimental results across different settings show that the Normalized attack can greatly disrupt non-ensemble Byzantine-robust methods, and our ensemble approach offers substantial resistance against poisoning attacks.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Principled Multi-Agent Task Agnostic Exploration</title>
<link>https://arxiv.org/abs/2502.08365</link>
<guid>https://arxiv.org/abs/2502.08365</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、任务无关探索、多智能体、状态分布熵、分布式策略搜索算法

<br /><br />总结:
本文针对强化学习中的多智能体任务无关探索问题展开研究。在单智能体场景中，任务无关探索通常表现为最大化由策略诱导的状态分布熵，但多智能体环境下的探索策略则相对未知。文章提出了对多个智能体的state分布熵最大化的通用化问题形式化，并探讨了不同的实现方案及其优缺点。接着，文章介绍了一种可扩展的、去中心化的、基于信任区域的策略搜索算法，以解决实际场景下的该类问题。最后，通过概念验证实验，证实了理论发现的有效性，并为在具有挑战性的多智能体环境中开展任务无关探索铺平道路。 <div>
arXiv:2502.08365v1 Announce Type: new 
Abstract: In reinforcement learning, we typically refer to task-agnostic exploration when we aim to explore the environment without access to the task specification a priori. In a single-agent setting the problem has been extensively studied and mostly understood. A popular approach cast the task-agnostic objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follows. In contrast, little is known about task-agnostic exploration in multi-agent settings, which are ubiquitous in the real world. How should different agents explore in the presence of others? In this paper, we address this question through a generalization to multiple agents of the problem of maximizing the state distribution entropy. First, we investigate alternative formulations, highlighting respective positives and negatives. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide proof of concept experiments to both corroborate the theoretical findings and pave the way for task-agnostic exploration in challenging multi-agent settings.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Morpheus Consensus: Excelling on trails and autobahns</title>
<link>https://arxiv.org/abs/2502.08465</link>
<guid>https://arxiv.org/abs/2502.08465</guid>
<content:encoded><![CDATA[
<div> 关键词：Morpheus共识、低吞吐量、高吞吐量、DAG协议、PBFT、Tendermint<br /><br />总结：
本文介绍了Morpheus共识，这是一种能够自然地从低吞吐量无领导者的区块链协议转变为高吞吐量基于领导者的DAG协议，并在两种场景下均表现出优秀的延迟和通信复杂性。在高吞吐量情况下，Morpheus的表现可以与最先进的DAG协议如Autobahn相媲美；而在低吞吐量情况下，相比于标准协议如PBFT和Tendermint，Morpheus展现出更优的复杂性和更低的延迟。Morpheus的核心思想是在块之间没有冲突（由于拜占庭行为、网络延迟或同时高吞吐量生产）的情况下，能即时形成一条无分叉的区块链并迅速确认每个到达的区块。只有当需要解决冲突时，才会按照类似Autobahn的方式选举领导者，并以高性能执行该任务。 <div>
arXiv:2502.08465v1 Announce Type: new 
Abstract: Recent research in consensus has often focussed on protocols for State-Machine-Replication (SMR) that can handle high throughputs. Such state-of-the-art protocols (generally DAG-based) induce undue overhead when the needed throughput is low, or else exhibit unnecessarily-poor latency and communication complexity during periods of low throughput.
  Here we present Morpheus Consensus, which naturally morphs from a quiescent low-throughput leaderless blockchain protocol to a high-throughput leader-based DAG protocol and back, excelling in latency and complexity in both settings. During high-throughout, Morpheus pars with state-of-the-art DAG-based protocols, including Autobahn. During low-throughput, Morpheus exhibits competitive complexity and lower latency than standard protocols such as PBFT and Tendermint, which in turn do not perform well during high-throughput.
  The key idea of Morpheus is that as long as blocks do not conflict (due to Byzantine behaviour, network delays, or high-throughput simultaneous production) it produces a forkless blockchain, promptly finalizing each block upon arrival. It assigns a leader only if one is needed to resolve conflicts, in a manner and with performance not unlike Autobahn.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Single-token vs Two-token Blockchain Tokenomics</title>
<link>https://arxiv.org/abs/2403.15429</link>
<guid>https://arxiv.org/abs/2403.15429</guid>
<content:encoded><![CDATA[
<div> 关键词：proof-of-stake (PoS)，tokenomics，equilibrium，monetary policy，quantitative rewarding (QR)

总结:<br />
本文研究了基于权益证明(PoS)区块链系统的代币货币政策（tokenomics）中的长期均衡问题。系统参与者包括追求利益最大化的用户和验证者，后者通过维护系统运作获得代币奖励，而用户则需使用代币竞标以获取所需的服务比例。文章探讨了如何设计系统服务供给和奖励机制以实现如下四个理想特性：(1) 可持续性：保证系统能吸引并维持各方参与；(2) 去中心化与风险投资：确保多个充分投入的验证者共同参与；(3) 稳定性：保持用于系统交易的底层代币价格长时间稳定；(4) 实施可行性：机制易于实现在智能合约中，无需链上法定储备进行代币回购或跟踪呈指数增长的代币持有量。

文中提出了一个新的通用区块链货币政策——定量奖励(QR)机制，并研究了如何在单代币和双代币PoS系统中实施该机制。其中双代币系统利用一种代币支付交易费用，另一种代币供验证者参与PoS协议并获取奖励。作者展示了双代币设置下QR机制能更有效地实现并提供良好均衡的特点。同时，分析也揭示了单代币设置在实施有效区块链货币政策方面的一个内在局限性，据所知这是首次对此进行强调。 <div>
arXiv:2403.15429v3 Announce Type: replace 
Abstract: We study long-term equilibria that arise in the token monetary policy, or tokenomics, design of proof-of-stake (PoS) blockchain systems that engage utility maximizing users and validators. Validators are system maintainers who get rewarded with tokens for performing the work necessary for the system to function properly, while users compete and pay with such tokens for getting a desired portion of the system service.
  We study how the system service provision and suitable rewards schemes together can lead to equilibria with the following desirable characteristics (1) viability: the system keeps parties engaged,
  (2) decentralization and skin-in-the-game: multiple sufficiently invested validators are participating,
  (3) stability: the price path of the underlying token used to transact with the system does not change widely over time, and
  (4) feasibility: the mechanism is easy to implement as a smart contract, e.g., it does not require a fiat reserve on-chain to perform token {\em buybacks} or to perform bookkeeping of exponentially growing token holdings.
  Our analysis enables us to put forward a novel generic mechanism for blockchain monetary policy that we call quantitative rewarding (QR). We investigate how to implement QR in single-token and two-token proof of stake (PoS) blockchain systems. The latter are systems that utilize one token for the users to pay the transaction fees and a different token for the validators to participate in the PoS protocol and get rewarded. Our approach demonstrates a concrete advantage of the two-token setting in terms of the ability of the QR mechanism to be realized effectively and provide good equilibria. Our analysis also reveals an inherent limitation of the single token setting in terms of implementing an effective blockchain monetary policy - a distinction that is, to the best of our knowledge, highlighted for the first time.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>am-AMM: An Auction-Managed Automated Market Maker</title>
<link>https://arxiv.org/abs/2403.03367</link>
<guid>https://arxiv.org/abs/2403.03367</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化做市商(AMMs)、拍卖管理型AMM、信息不对称损失、无信息订单流收益、流动性提供者

总结:
<br />
本文提出了一种名为“拍卖管理型AMM”的新型机制，旨在解决区块链上自动化做市商面临的两个关键问题：减少因信息不对称导致的损失以及最大化无信息订单流带来的收入。该机制通过在链上运行一个抵制审查的拍卖来确定谁有权暂时作为常数乘积AMM的“池经理”，池经理可以设置交易费率并收取由此产生的费用。池经理能够通过针对小价格波动与资金池进行交易来独家捕获部分套利机会，并可以根据零售订单流的价格敏感性和市场变化调整交易费率，从而使流动性提供者的利益最终得到提升。流动性提供者可自由进出资金池，但退出时需支付小额费用。文章证明，在某些假设下，这种AMM在均衡状态下应具有比任何标准固定费率AMM更高的流动性。 <div>
arXiv:2403.03367v4 Announce Type: replace-cross 
Abstract: Automated market makers (AMMs) have emerged as the dominant market mechanism for trading on decentralized exchanges implemented on blockchains. This paper presents a single mechanism that targets two important unsolved problems for AMMs: reducing losses to informed orderflow, and maximizing revenue from uninformed orderflow. The ``auction-managed AMM'' works by running a censorship-resistant onchain auction for the right to temporarily act as ``pool manager'' for a constant-product AMM. The pool manager sets the swap fee rate on the pool, and also receives the accrued fees from swaps. The pool manager can exclusively capture some arbitrage by trading against the pool in response to small price movements, and also can set swap fees incorporating price sensitivity of retail orderflow and adapting to changing market conditions, with the benefits from both ultimately accruing to liquidity providers. Liquidity providers can enter and exit the pool freely in response to changing rent, though they must pay a small fee on withdrawal. We prove that under certain assumptions, this AMM should have higher liquidity in equilibrium than any standard, fixed-fee AMM.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Satisfaction-Aware Incentive Scheme for Federated Learning in Industrial Metaverse: DRL-Based Stackbelberg Game Approach</title>
<link>https://arxiv.org/abs/2502.06909</link>
<guid>https://arxiv.org/abs/2502.06909</guid>
<content:encoded><![CDATA[
<div> 关键词：工业元宇宙、物联网、联邦学习、训练延迟、满意度函数<br /><br />总结:<br />
本文研究了工业元宇宙中利用物联网数据和联邦学习进行模型训练的问题，重点关注如何平衡模型质量和训练延迟。文中设计了一个考虑数据量、信息新鲜度（Age of Information，AoI）和训练延迟的满意度函数，并将其纳入到节点参与模型训练的激励机制中。通过构建服务器与节点间的两阶段Stackelberg博弈模型，并应用深度强化学习方法求解Stackelberg均衡，以实现奖励平衡并提升激励方案在工业元宇宙中的适用性。仿真结果显示，相比于现有方案，在相同的预算约束下，所提出的激励方案能至少提高23.7%的效益，同时不损害模型准确性。 <div>
arXiv:2502.06909v1 Announce Type: new 
Abstract: Industrial Metaverse leverages the Industrial Internet of Things (IIoT) to integrate data from diverse devices, employing federated learning and meta-computing to train models in a distributed manner while ensuring data privacy. Achieving an immersive experience for industrial Metaverse necessitates maintaining a balance between model quality and training latency. Consequently, a primary challenge in federated learning tasks is optimizing overall system performance by balancing model quality and training latency. This paper designs a satisfaction function that accounts for data size, Age of Information (AoI), and training latency. Additionally, the satisfaction function is incorporated into the utility functions to incentivize node participation in model training. We model the utility functions of servers and nodes as a two-stage Stackelberg game and employ a deep reinforcement learning approach to learn the Stackelberg equilibrium. This approach ensures balanced rewards and enhances the applicability of the incentive scheme for industrial Metaverse. Simulation results demonstrate that, under the same budget constraints, the proposed incentive scheme improves at least 23.7% utility compared to existing schemes without compromising model accuracy.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2502.06917</link>
<guid>https://arxiv.org/abs/2502.06917</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 区块链技术, Adversarial attacks, Proof of Federated Learning, Krum Federated Chain

总结:
本文探讨了区块链技术与联邦学习相结合以增强安全性及完整性的潜力。首先，文章测试了Proof of Federated Learning这一专为联邦学习环境设计的共识机制，证明其在至少一个矿工未被妥协的情况下能有效防御拜占庭攻击和后门攻击。其次，提出了一个新的防御策略——Krum Federated Chain，该策略将Krum和Proof of Federated Learning结合，即使所有矿工都被妥协，也能抵御任何形式的拜占庭或后门攻击。实验在图像分类数据集上验证了所提方法的有效性。<br /><br /> <div>
arXiv:2502.06917v1 Announce Type: new 
Abstract: Federated Learning presents a nascent approach to machine learning, enabling collaborative model training across decentralized devices while safeguarding data privacy. However, its distributed nature renders it susceptible to adversarial attacks. Integrating blockchain technology with Federated Learning offers a promising avenue to enhance security and integrity. In this paper, we tackle the potential of blockchain in defending Federated Learning against adversarial attacks. First, we test Proof of Federated Learning, a well known consensus mechanism designed ad-hoc to federated contexts, as a defense mechanism demonstrating its efficacy against Byzantine and backdoor attacks when at least one miner remains uncompromised. Second, we propose Krum Federated Chain, a novel defense strategy combining Krum and Proof of Federated Learning, valid to defend against any configuration of Byzantine or backdoor attacks, even when all miners are compromised. Our experiments conducted on image classification datasets validate the effectiveness of our proposed approaches.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game of Coding With an Unknown Adversary</title>
<link>https://arxiv.org/abs/2502.07109</link>
<guid>https://arxiv.org/abs/2502.07109</guid>
<content:encoded><![CDATA[
<div> 关键词：游戏编码框架、去中心化应用、对手理性行为、接受规则、均衡策略

<br /><br />总结:
本文针对新兴的去中心化应用场景，讨论了游戏编码框架下，当敌手对编码符号的控制超出传统编码理论界限时的问题。在此场景中，敌手会根据其收益函数理性行事，旨在提高被接受的概率和估计错误率。而解码器作为数据收集者，则依据接受与拒绝机制以及估计算法调整自身策略以最大化自身收益。现有的工作假设双方完全了解对方的收益函数，但实际中解码器往往不了解敌手的收益函数。为此，文章提出了一种新算法，使解码器能在不掌握敌手收益函数的情况下，承诺执行一种接近均衡的策略。该算法基于观察到的一个不变性关系：在均衡状态下，接受概率与均方误差（MSE）之间存在固定的关系，不受玩家具体收益函数的影响。通过利用这一关系，解码器可迭代优化其策略并逼近最优解决方案。此外，文中还提供了关于所提方案样本复杂度和准确性的理论保证。 <div>
arXiv:2502.07109v1 Announce Type: new 
Abstract: Motivated by emerging decentralized applications, the \emph{game of coding} framework has been recently introduced to address scenarios where the adversary's control over coded symbols surpasses the fundamental limits of traditional coding theory. Still, the reward mechanism available in decentralized systems, motivates the adversary to act rationally. While the decoder, as the data collector (DC), has an acceptance and rejection mechanism, followed by an estimation module, the adversary aims to maximize its utility, as an increasing function of (1) the chance of acceptance (to increase the reward), and (2) estimation error. On the other hand, the decoder also adjusts its acceptance rule to maximize its own utility, as (1) an increasing function of the chance of acceptance (to keep the system functional), (2) decreasing function of the estimation error. Prior works within this framework rely on the assumption that the game is complete, that is, both the DC and the adversary are fully aware of each other's utility functions. However, in practice, the decoder is often unaware of the utility of the adversary. To address this limitation, we develop an algorithm enabling the DC to commit to a strategy that achieves within the vicinity of the equilibrium, without knowledge of the adversary's utility function. Our approach builds on an observation that at the equilibrium, the relationship between the probability of acceptance and the mean squared error (MSE) follows a predetermined curve independent of the specific utility functions of the players. By exploiting this invariant relationship, the DC can iteratively refine its strategy based on observable parameters, converging to a near-optimal solution. We provide theoretical guarantees on sample complexity and accuracy of the proposed scheme.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fairness in Multi-Agent AI: A Unified Framework for Ethical and Equitable Autonomous Systems</title>
<link>https://arxiv.org/abs/2502.07254</link>
<guid>https://arxiv.org/abs/2502.07254</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、公平性、动态属性、自主行为、激励机制

总结:
该论文关注的是在分布式多智能体系统中确保公平性的挑战，如出现的偏见、系统效率低下和各智能体间的利益冲突。文章提供了一个全面调查多智能体AI中的公平性问题的新框架，将公平视为智能体互动过程中动态涌现的属性。这个框架结合了公平性约束、偏差缓解策略以及激励机制，旨在使自治智能体的行为与社会价值观保持一致的同时平衡效率和鲁棒性。通过实证验证，文章表明融入公平性约束可以实现更公正的决策制定。这项工作弥合了AI伦理与系统设计之间的鸿沟，为构建负责任、透明且符合社会伦理的多智能体AI系统奠定了基础。<br /><br /> <div>
arXiv:2502.07254v1 Announce Type: new 
Abstract: Ensuring fairness in decentralized multi-agent systems presents significant challenges due to emergent biases, systemic inefficiencies, and conflicting agent incentives. This paper provides a comprehensive survey of fairness in multi-agent AI, introducing a novel framework where fairness is treated as a dynamic, emergent property of agent interactions. The framework integrates fairness constraints, bias mitigation strategies, and incentive mechanisms to align autonomous agent behaviors with societal values while balancing efficiency and robustness. Through empirical validation, we demonstrate that incorporating fairness constraints results in more equitable decision-making. This work bridges the gap between AI ethics and system design, offering a foundation for accountable, transparent, and socially responsible multi-agent AI systems.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Value Decomposition Networks with Networked Agents</title>
<link>https://arxiv.org/abs/2502.07635</link>
<guid>https://arxiv.org/abs/2502.07635</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式训练、部分可观测性、多智能体强化学习、分布式价值分解网络、联合Q函数

总结:<br />
本文研究了在部分可观测环境下进行分布式训练的问题，其中合作多智能体强化学习（MARL）旨在最大化期望累积的联合奖励。为此，文章提出了分布式价值分解网络（DVDN），该网络能够生成一个可以因子化为各智能体独立Q函数的联合Q函数。与原价值分解网络依赖集中式训练不同，DVDN适用于无法进行集中训练、智能体需要以分散方式与物理环境交互并与其同伴通信的学习场景。DVDN通过局部估计共享目标来克服对集中式训练的需求。文章贡献了两种创新算法，分别针对异质和同质智能体设置的DVDN和DVDN (GT)。实验证明，尽管在通信过程中存在信息损失，但两种算法仍能近似达到价值分解网络的表现，实验结果在三个标准环境中进行了十个MARL任务的展示。 <div>
arXiv:2502.07635v1 Announce Type: new 
Abstract: We investigate the problem of distributed training under partial observability, whereby cooperative multi-agent reinforcement learning agents (MARL) maximize the expected cumulative joint reward. We propose distributed value decomposition networks (DVDN) that generate a joint Q-function that factorizes into agent-wise Q-functions. Whereas the original value decomposition networks rely on centralized training, our approach is suitable for domains where centralized training is not possible and agents must learn by interacting with the physical environment in a decentralized manner while communicating with their peers. DVDN overcomes the need for centralized training by locally estimating the shared objective. We contribute with two innovative algorithms, DVDN and DVDN (GT), for the heterogeneous and homogeneous agents settings respectively. Empirically, both algorithms approximate the performance of value decomposition networks, in spite of the information loss during communication, as demonstrated in ten MARL tasks in three standard environments.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models</title>
<link>https://arxiv.org/abs/2502.07644</link>
<guid>https://arxiv.org/abs/2502.07644</guid>
<content:encoded><![CDATA[
<div> 关键词: SymGPT、智能合约、ERC标准、符号执行、大型语言模型

总结:
本文介绍了SymGPT，这是一个结合了大型语言模型（LLMs）的自然语言理解和符号执行形式化保障的工具，用于自动验证智能合约对ERC规则的遵循情况。研究团队通过对三个广泛使用的ERC标准中的132条规则进行实证分析，设计并开发了SymGPT。该工具首先利用LLM将ERC规则翻译成EBNF语法规则，随后从形式化的规则中合成约束条件，以代表可能违规的情景，并通过符号执行来检测这些违规行为。评估结果显示，SymGPT在4000个真实世界的合同中发现了5783条ERC规则违反情况，包括1375条具有明确资产窃取攻击路径的违规行为，显示出了其有效性和优越性。此外，SymGPT的表现优于六个自动化技术及一项安全专家审计服务，凸显了其在当前智能合约分析方法中的优势地位。 <div>
arXiv:2502.07644v1 Announce Type: new 
Abstract: To govern smart contracts running on Ethereum, multiple Ethereum Request for Comment (ERC) standards have been developed, each having a set of rules to guide the behaviors of smart contracts. Violating the ERC rules could cause serious security issues and financial loss, signifying the importance of verifying smart contracts follow ERCs. Today's practices of such verification are to manually audit each single contract, use expert-developed program-analysis tools, or use large language models (LLMs), all of which are far from effective in identifying ERC rule violations. This paper introduces SymGPT, a tool that combines the natural language understanding of large language models (LLMs) with the formal guarantees of symbolic execution to automatically verify smart contracts' compliance with ERC rules. To develop SymGPT, we conduct an empirical study of 132 ERC rules from three widely used ERC standards, examining their content, security implications, and natural language descriptions. Based on this study, we design SymGPT by first instructing an LLM to translate ERC rules into a defined EBNF grammar. We then synthesize constraints from the formalized rules to represent scenarios where violations may occur and use symbolic execution to detect them. Our evaluation shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world contracts, including 1,375 violations with clear attack paths for stealing financial assets, demonstrating its effectiveness. Furthermore, SymGPT outperforms six automated techniques and a security-expert auditing service, underscoring its superiority over current smart contract analysis methods.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PFedDST: Personalized Federated Learning with Decentralized Selection Training</title>
<link>https://arxiv.org/abs/2502.07750</link>
<guid>https://arxiv.org/abs/2502.07750</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式学习, 联邦学习, 通信瓶颈, 个性化联邦学习, PFedDST

总结:<br />
为解决分布式学习（尤其是联邦学习）中非IID数据分布、设备能力差异以及通信瓶颈等问题，本文提出了个性化联邦学习与去中心化选择训练框架——PFedDST。该框架通过让设备根据全面的通信得分策略性地评估和选择同伴，该得分综合考虑了损失、任务相似性和选择频率，以确保最优的同行连接。这样的选择策略旨在增强本地个性化并促进有益的同伴协作，从而提升训练过程的稳定性和效率。实验结果显示，PFedDST不仅提高了模型准确性，还加速了收敛速度。相较于现有最先进的方法，PFedDST在处理数据异质性方面表现更优，在多样性和去中心化的系统中实现更快、更有效的训练。 <div>
arXiv:2502.07750v1 Announce Type: new 
Abstract: Distributed Learning (DL) enables the training of machine learning models across multiple devices, yet it faces challenges like non-IID data distributions and device capability disparities, which can impede training efficiency. Communication bottlenecks further complicate traditional Federated Learning (FL) setups. To mitigate these issues, we introduce the Personalized Federated Learning with Decentralized Selection Training (PFedDST) framework. PFedDST enhances model training by allowing devices to strategically evaluate and select peers based on a comprehensive communication score. This score integrates loss, task similarity, and selection frequency, ensuring optimal peer connections. This selection strategy is tailored to increase local personalization and promote beneficial peer collaborations to strengthen the stability and efficiency of the training process. Our experiments demonstrate that PFedDST not only enhances model accuracy but also accelerates convergence. This approach outperforms state-of-the-art methods in handling data heterogeneity, delivering both faster and more effective training in diverse and decentralized systems.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication-Efficient Federated Optimization over Semi-Decentralized Networks</title>
<link>https://arxiv.org/abs/2311.18787</link>
<guid>https://arxiv.org/abs/2311.18787</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模联邦学习、通信效率、八卦通信、半分布式通信协议、PISCO算法

总结:<br />
针对大规模联邦学习和分布式学习中的通信效率瓶颈问题，该文提出了一种新的半分布式通信协议背景下的通信高效算法——PISCO。PISCO允许智能体以概率性的方式进行智能体间及智能体与服务器间的通信，旨在解决八卦通信在大型稀疏网络中所需较多通信轮次的问题。PISCO结合了梯度跟踪技术，具备对数据异质性的鲁棒性并支持多次局部更新以节省通信成本。理论分析表明，PISCO对于非凸问题具有收敛率保证，并能在智能体数量和局部更新次数上实现线性加速比。实验结果验证了PISCO在通信效率上的优越性和面对数据异质性及多种网络拓扑结构时的韧性。 <div>
arXiv:2311.18787v3 Announce Type: replace 
Abstract: In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number of agents and local updates. Our numerical results highlight the superior communication efficiency of PISCO and its resilience to data heterogeneity and various network topologies.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Faster Convergence with Less Communication: Broadcast-Based Subgraph Sampling for Decentralized Learning over Wireless Networks</title>
<link>https://arxiv.org/abs/2401.13779</link>
<guid>https://arxiv.org/abs/2401.13779</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Stochastic Gradient Descent (D-SGD), Consensus-based Model Averaging, Wireless Networks, BASS, Broadcast-Based Subgraph Sampling

总结:<br />
本文提出了一种名为$\texttt{BASS}$的广播式子图采样方法，旨在加速分布式Stochastic Gradient Descent (D-SGD)的收敛速度，同时考虑实际通信成本。$\texttt{BASS}$针对无线网络中的共识平均过程，生成一组稀疏子图表示的混合矩阵候选者。在每个共识迭代中，随机选择一个混合矩阵，从而确定一组无冲突的节点子集进行激活和信息传输。该采样过程以概率方式进行，并联合优化混合矩阵的元素及其采样概率。仿真结果表明，相比于现有的基于链路的调度方法，$\texttt{BASS}$能够在更少的传输槽时间内实现更快的收敛速度。文章指出，无线信道的固有广播特性为分布式优化和学习的加速提供了内在优势。 <div>
arXiv:2401.13779v2 Announce Type: replace 
Abstract: Consensus-based decentralized stochastic gradient descent (D-SGD) is a widely adopted algorithm for decentralized training of machine learning models across networked agents. A crucial part of D-SGD is the consensus-based model averaging, which heavily relies on information exchange and fusion among the nodes. Specifically, for consensus averaging over wireless networks, communication coordination is necessary to determine when and how a node can access the channel and transmit (or receive) information to (or from) its neighbors. In this work, we propose $\texttt{BASS}$, a broadcast-based subgraph sampling method designed to accelerate the convergence of D-SGD while considering the actual communication cost per iteration. $\texttt{BASS}$ creates a set of mixing matrix candidates that represent sparser subgraphs of the base topology. In each consensus iteration, one mixing matrix is sampled, leading to a specific scheduling decision that activates multiple collision-free subsets of nodes. The sampling occurs in a probabilistic manner, and the elements of the mixing matrices, along with their sampling probabilities, are jointly optimized. Simulation results demonstrate that $\texttt{BASS}$ enables faster convergence with fewer transmission slots compared to existing link-based scheduling methods. In conclusion, the inherent broadcasting nature of wireless channels offers intrinsic advantages in accelerating the convergence of decentralized optimization and learning.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trustworthy Distributed Certification of Program Execution</title>
<link>https://arxiv.org/abs/2402.13792</link>
<guid>https://arxiv.org/abs/2402.13792</guid>
<content:encoded><![CDATA[
<div> 关键词: 程序执行验证, 重现性, 分布式重新执行, Mona编程语言, OCCP认证协议

总结:
本文提出了一种创新方法，通过将名为Mona的原型编程语言与OCCP认证协议相结合，实现程序片段的分布式和去中心化的重新执行，以解决现有技术在程序执行验证方面的局限性。该协议能在无需原始盲目重执行的情况下，为程序段提供分布式、不可变和可信的认证，从而节省时间和计算资源。文中还探讨了利用区块链技术来管理协议工作流程的可能性。相较于现有最佳方案，这种方法能有效减少所需执行的程序次数，提高了程序执行认证的效率，为进一步研究和发展提供了新的方向。 <div>
arXiv:2402.13792v2 Announce Type: replace 
Abstract: Verifying the execution of a program is complicated and often limited by the inability to validate the code's correctness. It is a crucial aspect of scientific research, where it is needed to ensure the reproducibility and validity of experimental results. Similarly, in customer software testing, it is difficult for customers to verify that their specific program version was tested or executed at all. Existing state-of-the-art solutions, such as hardware-based approaches, constraint solvers, and verifiable computation systems, do not provide definitive proof of execution, which hinders reliable testing and analysis of program results. In this paper, we propose an innovative approach that combines a prototype programming language called Mona with a certification protocol OCCP to enable the distributed and decentralized re-execution of program segments. Our protocol allows for certification of program segments in a distributed, immutable, and trustworthy system without the need for naive re-execution, resulting in significant improvements in terms of time and computational resources used. We also explore the use of blockchain technology to manage the protocol workflow following other approaches in this space. Our approach offers a promising solution to the challenges of program execution verification and opens up opportunities for further research and development in this area. Our findings demonstrate the efficiency of our approach in reducing the number of program executions compared to existing state-of-the-art methods, thus improving the efficiency of certifying program executions.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Machine Learning for Scalable and Optimal Load Shedding Under Power System Contingency</title>
<link>https://arxiv.org/abs/2405.05521</link>
<guid>https://arxiv.org/abs/2405.05521</guid>
<content:encoded><![CDATA[
<div> 关键词: 电力系统韧性、最优负荷削减、神经网络、分布式设计、应急响应

总结:
本文提出了一种针对电力系统的分布式最优负荷削减(OLS)方案，旨在应对意外情况并防止级联停电。该方法利用神经网络(NN)模型的离线训练，使每个负荷中心能自主根据本地测量数据构建OLS解。这样能在实时紧急响应中大幅降低计算和通信需求，从而增强电网韧性，有效阻止突发事件的级联传播。通过对IEEE 118-bus系统和合成的Texas 2000-bus系统的数值研究表明，这种可扩展的OLS学习设计方案对于电力系统及时的应急操作具有高效性和有效性。<br /><br /> <div>
arXiv:2405.05521v2 Announce Type: replace 
Abstract: Prompt and effective corrective actions in response to unexpected contingencies are crucial for improving power system resilience and preventing cascading blackouts. The optimal load shedding (OLS) accounting for network limits has the potential to address the diverse system-wide impacts of contingency scenarios as compared to traditional local schemes. However, due to the fast cascading propagation of initial contingencies, real-time OLS solutions are challenging to attain in large systems with high computation and communication needs. In this paper, we propose a decentralized design that leverages offline training of a neural network (NN) model for individual load centers to autonomously construct the OLS solutions from locally available measurements. Our learning-for-OLS approach can greatly reduce the computation and communication needs during online emergency responses, thus preventing the cascading propagation of contingencies for enhanced power grid resilience. Numerical studies on both the IEEE 118-bus system and a synthetic Texas 2000-bus system have demonstrated the efficiency and effectiveness of our scalable OLS learning design for timely power system emergency operations.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Thunderbolt: Concurrent Smart Contract Execution with Nonblocking Reconfiguration for Sharded DAGs</title>
<link>https://arxiv.org/abs/2407.09409</link>
<guid>https://arxiv.org/abs/2407.09409</guid>
<content:encoded><![CDATA[
<div> 关键词：sharding、区块链、DAG、Thunderbolt、并行执行

总结:
本文提出了Thunderbolt，一种针对单片交易（Single-shard TXs）和跨片交易（Cross-shard TXs）的新型分片架构，旨在解决DAG基础协议上智能合约处理中的扩展性问题。该设计有四个关键创新点：1) 每个副本同时担任全片代表和交易提议者角色，对Single-shard TXs采用Execution-Order-Validation (EOV)模型，而对Cross-shard TXs则采用Order-Execution (OE)模型；2) 开发了一种基于DAG的协调协议，能在保持并发执行能力的同时，确定两种类型交易之间的确定性排序；3) 实现了一个动态并发控制器，无需预先知道读/写集即可调度Single-shard TXs，支持运行时依赖关系解析；4) Thunderbolt引入了非阻塞式分片重新配置机制，通过频繁的分片再分配应对审查攻击，同时不影响DAG构建和共识达成。相比于Tusk框架下的串行执行，Thunderbolt在拥有64个副本的情况下实现了50倍的吞吐量提升。 <div>
arXiv:2407.09409v3 Announce Type: replace 
Abstract: Sharding has emerged as a critical technique for enhancing blockchain system scalability. However, existing sharding approaches face unique challenges when applied to Directed Acyclic Graph (DAG)-based protocols that integrate expressive smart contract processing. Current solutions predominantly rely on coordination mechanisms like 2PC and require transaction read/write sets to optimize parallel execution. These requirements introduce two fundamental limitations: 1) additional coordination phases incur latency overhead, and 2) pre-declaration of read/write sets proves impractical for Turing-complete smart contracts with dynamic access patterns.
  This paper presents Thunderbolt, a novel sharding architecture for both single-shard transactions (Single-shard TXs) and cross-shard transactions (Cross-shard TXs) and enables nonblocking reconfiguration to ensure system liveness. Our design introduces 4 key innovations: 1) each replica serves dual roles as a full-shard representative and transaction proposer, employing the Execution-Order-Validation (EOV) model for Single-shard TXs and Order-Execution (OE) model for Cross-shard TXs. 2) we develop a DAG-based coordination protocol that establishes deterministic ordering between two transaction types while preserving concurrent execution capabilities. 3) we implement a dynamic concurrency controller that schedules Single-shard TXs without requiring prior knowledge of read/write sets, enabling runtime dependency resolution. 4) Thunderbolt introduces a nonblocking shard reconfiguration mechanism to address censorship attacks by featuring frequent shard re-assignment without impeding the construction of DAG nor blocking consensus. Thunderbolt achieves a 50x throughput improvement with 64 replicas compared to serial execution in the Tusk framework.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Centralization vs. decentralization in multi-robot sweep coverage with ground robots and UAVs</title>
<link>https://arxiv.org/abs/2408.06553</link>
<guid>https://arxiv.org/abs/2408.06553</guid>
<content:encoded><![CDATA[
<div> 关键词：swarm robotics, decentralized control, centralized control, sweep coverage, performance metrics

总结:
本文研究了在群机器人领域中，集中式控制与分布式控制在执行清扫覆盖任务时的性能对比。文章分析了五种不同的多机器人控制结构：随机游走、带有信标的分布式控制、使用自组织层级的混合形成控制、集中式形成控制以及预定方式。在这五个方法中，清扫任务均由一组地面机器人完成，除了随机游走外，其他方法都有无人机作为监督者或信标辅助。文中通过三个有利于集中式控制的优势指标进行比较——覆盖完整性、覆盖均匀性和清扫完成时间；同时，通过两个对分布式控制有利的指标进行评估——可扩展性（分别测试4、8、16台地面机器人的情况）和容错性（模拟0%、25%、50%、75%的地面机器人故障情况）。最后，作者讨论了未来工作如何将集中式和分布式控制的优点结合到一个系统中的可能性。 <div>
arXiv:2408.06553v2 Announce Type: replace 
Abstract: In swarm robotics, decentralized control is often proposed as a more scalable and fault-tolerant alternative to centralized control. However, centralized behaviors are often faster and more efficient than their decentralized counterparts. In any given application, the goals and constraints of the task being solved should guide the choice to use centralized control, decentralized control, or a combination of the two. Currently, the exact trade-offs that exist between centralization and decentralization are not well defined. In this paper, we study comparative performance assessment between centralization and decentralization in the example task of sweep coverage, across five different types of multi-robot control structures: random walk, decentralized with beacons, hybrid formation control using self-organizing hierarchy, centralized formation control, and predetermined. In all five approaches, the coverage task is completed by a group of ground robots. In each approach, except for the random walk, the ground robots are assisted by UAVs, acting as supervisors or beacons. We compare the approaches in terms of three performance metrics for which centralized approaches are expected to have an advantage -- coverage completeness, coverage uniformity, and sweep completion time -- and two metrics for which decentralized approaches are expected to have an advantage -- scalability (4, 8, or 16 ground robots) and fault tolerance (0%, 25%, 50%, or 75% ground robot failure). Finally, we discuss future work on combining the advantages of both in one system.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning</title>
<link>https://arxiv.org/abs/2409.05701</link>
<guid>https://arxiv.org/abs/2409.05701</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Federated Averaging（FedAvg）、diffusion model（扩散模型）、personalized FL（个性化联邦学习）、pFedGPA

总结:

本文提出了一种针对联邦学习的新型个性化参数聚合框架——pFedGPA，旨在解决传统方法如FedAvg在处理异构数据分布时线性聚合参数所导致的性能下降问题。pFedGPA引入了扩散模型，通过在服务器端部署该模型来整合多样化的参数分布，并提出了一个参数反演方法，能有效地为每个客户端生成一组个性化的参数。该方法将上传的参数转换为潜在码，再通过去噪采样进行最终个性化参数的聚合。利用高容量的扩散模型，pFedGPA能够有效解耦所有客户端模型参数总体分布的复杂性和每个客户端参数分布的复杂度。实验结果表明，与基线方法相比，pFedGPA在多个数据集上表现出了更优的性能。 <div>
arXiv:2409.05701v3 Announce Type: replace 
Abstract: Federated Learning (FL) offers a decentralized approach to model training, where data remains local and only model parameters are shared between the clients and the central server. Traditional methods, such as Federated Averaging (FedAvg), linearly aggregate these parameters which are usually trained on heterogeneous data distributions, potentially overlooking the complex, high-dimensional nature of the parameter space. This can result in degraded performance of the aggregated model. While personalized FL approaches can mitigate the heterogeneous data issue to some extent, the limitation of linear aggregation remains unresolved. To alleviate this issue, we investigate the generative approach of diffusion model and propose a novel generative parameter aggregation framework for personalized FL, \texttt{pFedGPA}. In this framework, we deploy a diffusion model on the server to integrate the diverse parameter distributions and propose a parameter inversion method to efficiently generate a set of personalized parameters for each client. This inversion method transforms the uploaded parameters into a latent code, which is then aggregated through denoising sampling to produce the final personalized parameters. By encoding the dependence of a client's model parameters on the specific data distribution using the high-capacity diffusion model, \texttt{pFedGPA} can effectively decouple the complexity of the overall distribution of all clients' model parameters from the complexity of each individual client's parameter distribution. Our experimental results consistently demonstrate the superior performance of the proposed method across multiple datasets, surpassing baseline approaches.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Principles and Components of Federated Learning Architectures</title>
<link>https://arxiv.org/abs/2502.05273</link>
<guid>https://arxiv.org/abs/2502.05273</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习、通信架构、机器学习模型、数据分区、隐私方法、系统异质性

<br /><br />总结:
本文详细探讨了联邦学习（Federated Learning）的基本理念与架构元素，重点关注了五个关键领域：通信架构、机器学习模型、数据分区、隐私保护方法以及系统异质性。文章指出了联邦学习虽具有隐私、安全、法规和经济效益等优点，但仍存在类似传统机器学习模型的问题。通过对文献的全面回顾，文章提出了一系列联邦学习系统的架构模式。这些分析有助于读者理解联邦学习的基础、其主要组成部分以及相关的架构细节，并为进一步研究中的挑战提供了未来方向。 <div>
arXiv:2502.05273v1 Announce Type: new 
Abstract: Federated learning, also known as FL, is a machine learning framework in which a significant amount of clients (such as mobile devices or whole enterprises) collaborate to collaboratively train a model while keeping decentralized training data, all overseen by a central server (such as a service provider). There are advantages in terms of privacy, security, regulations, and economy with this decentralized approach to model training. FL is not impervious to the flaws that plague conventional machine learning models, despite its seeming promise. This study offers a thorough analysis of the fundamental ideas and elements of federated learning architectures, emphasizing five important areas: communication architectures, machine learning models, data partitioning, privacy methods, and system heterogeneity. We additionally address the difficulties and potential paths for future study in the area. Furthermore, based on a comprehensive review of the literature, we present a collection of architectural patterns for federated learning systems. This analysis will help to understand the basic of Federated learning, the primary components of FL, and also about several architectural details.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Smart Contract Model</title>
<link>https://arxiv.org/abs/2502.05280</link>
<guid>https://arxiv.org/abs/2502.05280</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、分布式计算、智能合约、跨链协议、拜占庭容错

总结:<br />
本文探讨了区块链和去中心化金融领域的问题可视为分布式计算经典问题的变体。文章提出了一种新的智能合约模型，旨在同时体现传统与区块链分布式计算模型的相似性和差异性。重点在于跨链协议，其中多方参与者（包括诚实方和潜在恶意方）通过多个独立账本上的可信智能合约进行交互。这种智能合约模型与传统的分布式和并发计算模型有本质区别，主要因为涉及对资产所有权（如加密货币或其他有价值数据）的追踪。考虑到参与者的利益和可能的拜占庭行为，任务解决方案采用基本的游戏理论概念，并明确了各方的输入和期望的资产转移序列。与传统模型不同的是，智能合约而非参与者决定执行的资产转移结果，因为只有它们能控制所有权。 <div>
arXiv:2502.05280v1 Announce Type: new 
Abstract: Many of the problems that arise in the context of blockchains and decentralized finance can be seen as variations on classical problems of distributed computing. The smart contract model proposed here is intended to capture both the similarities and the differences between classical and blockchain-based models of distributed computing. The focus is on cross-chain protocols in which a collection of parties, some honest and some perhaps not, interact through trusted smart contracts residing on multiple, independent ledgers.
  While cross-chain protocols are capable of general computations, they are primarily used to track ownership of assets such as cryptocurrencies or other valuable data. For this reason, the smart contract model differs in some essential ways from familiar models of distributed and concurrent computing. Because parties are potentially Byzantine, tasks to be solved are formulated using elementary game-theoretic notions, taking into account the utility to each party of each possible outcome. As in the classical model, the parties provide task inputs and agree on a desired sequence of proposed asset transfers. Unlike the classical model, the contracts, not the parties, determine task outputs in the form of executed asset transfers, since they alone have the power to control ownership.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Online Ensembles of Gaussian Processes for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.05301</link>
<guid>https://arxiv.org/abs/2502.05301</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning, Gaussian processes, random feature approximation, Bayesian multiple kernel learning, online Bayesian model averaging

总结:
该文提出了一种全新的、完全去中心化的、渐近精确的随机特征近似高斯过程计算方案，适用于多智能体系统的灵活和可扩展的分布式学习。为解决超参数选择问题，文中引入了一种基于在线贝叶斯模型平均的Bayesian multiple kernel learning聚类方案。通过对比模拟数据和真实世界数据集上的实验，验证了所提算法相对于其他贝叶斯和频率主义方法的优势。<br /><br /> <div>
arXiv:2502.05301v1 Announce Type: new 
Abstract: Flexible and scalable decentralized learning solutions are fundamentally important in the application of multi-agent systems. While several recent approaches introduce (ensembles of) kernel machines in the distributed setting, Bayesian solutions are much more limited. We introduce a fully decentralized, asymptotically exact solution to computing the random feature approximation of Gaussian processes. We further address the choice of hyperparameters by introducing an ensembling scheme for Bayesian multiple kernel learning based on online Bayesian model averaging. The resulting algorithm is tested against Bayesian and frequentist methods on simulated and real-world datasets.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Using Federated Machine Learning in Predictive Maintenance of Jet Engines</title>
<link>https://arxiv.org/abs/2502.05321</link>
<guid>https://arxiv.org/abs/2502.05321</guid>
<content:encoded><![CDATA[
<div> 关键词: 剩余使用寿命(RUL)、涡轮喷气发动机、联合机器学习框架、数据隐私、计算效率

<br /><br />总结:

本文旨在利用联邦机器学习框架预测涡轮喷气发动机的剩余使用寿命(RUL)。该框架能够在保护数据隐私和安全的前提下，让多个边缘设备或服务器协同训练共享模型而不需分享敏感数据。通过实施非线性模型，系统能够捕捉到引擎数据中的复杂关系和模式，从而提高RUL预测的准确性。这种方法借助分散式计算，使得每个设备可以本地训练模型，随后在中央服务器上聚合所学权重。准确预测发动机的RUL有助于优化维护计划、减少停机时间和提升运营效率，最终为航空行业带来成本节省与性能提升。实验结果使用了从NASA网站公开获取的C-MAPSS数据集，这是一个研究和分析各种运行场景下发动机退化行为的重要资源。 <div>
arXiv:2502.05321v1 Announce Type: new 
Abstract: The goal of this paper is to predict the Remaining Useful Life (RUL) of turbine jet engines using a federated machine learning framework. Federated Learning enables multiple edge devices/nodes or servers to collaboratively train a shared model without sharing sensitive data, thus preserving data privacy and security. By implementing a nonlinear model, the system aims to capture complex relationships and patterns in the engine data to enhance the accuracy of RUL predictions. This approach leverages decentralized computation, allowing models to be trained locally at each device before aggregating the learned weights at a central server. By predicting the RUL of jet engines accurately, maintenance schedules can be optimized, downtime reduced, and operational efficiency improved, ultimately leading to cost savings and enhanced performance in the aviation industry. Computational results are provided by using the C-MAPSS dataset which is publicly available on the NASA website and is a valuable resource for studying and analyzing engine degradation behaviors in various operational scenarios.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning</title>
<link>https://arxiv.org/abs/2502.05453</link>
<guid>https://arxiv.org/abs/2502.05453</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、强化学习、分布式适应性知识图谱记忆、结构化通信系统、大规模语言模型

总结:
本文提出了一种针对动态开放世界场景中长期合作的智能代理框架——Decentralized Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS)，旨在解决传统多智能体强化学习（MARL）如集中式训练分布式执行（CTDE）方法面临的可扩展性和灵活性问题。DAMCS通过引入层次化的知识图谱记忆系统和结构化通信协议，使智能体能够利用外部知识和语言进行长期规划与推理，并高效分享相关信息，从而实现更好的分布式多智能体协作。实验表明，在新提出的多智能体开放世界任务中，采用DAMCS的智能体在任务效率和协作上优于传统MARL和大规模语言模型基线。相较于单智能体场景，两个智能体组合可以以减少63%的步骤数完成相同目标，六个智能体组合则能减少74%的步骤数，凸显了自适应记忆和结构化通信对于实现长期目标的重要性。该项目已公开发布于：https://happyeureka.github.io/damcs。 <div>
arXiv:2502.05453v1 Announce Type: new 
Abstract: Developing intelligent agents for long-term cooperation in dynamic open-world scenarios is a major challenge in multi-agent systems. Traditional Multi-agent Reinforcement Learning (MARL) frameworks like centralized training decentralized execution (CTDE) struggle with scalability and flexibility. They require centralized long-term planning, which is difficult without custom reward functions, and face challenges in processing multi-modal data. CTDE approaches also assume fixed cooperation strategies, making them impractical in dynamic environments where agents need to adapt and plan independently. To address decentralized multi-agent cooperation, we propose Decentralized Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in a novel Multi-agent Crafter environment. Our generative agents, powered by Large Language Models (LLMs), are more scalable than traditional MARL agents by leveraging external knowledge and language for long-term planning and reasoning. Instead of fully sharing information from all past experiences, DAMCS introduces a multi-modal memory system organized as a hierarchical knowledge graph and a structured communication protocol to optimize agent cooperation. This allows agents to reason from past interactions and share relevant information efficiently. Experiments on novel multi-agent open-world tasks show that DAMCS outperforms both MARL and LLM baselines in task efficiency and collaboration. Compared to single-agent scenarios, the two-agent scenario achieves the same goal with 63% fewer steps, and the six-agent scenario with 74% fewer steps, highlighting the importance of adaptive memory and structured communication in achieving long-term goals. We publicly release our project at: https://happyeureka.github.io/damcs.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Perpetual Demand Lending Pools</title>
<link>https://arxiv.org/abs/2502.06028</link>
<guid>https://arxiv.org/abs/2502.06028</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized perpetuals, trading volume, borrowing costs, Perpetual Demand Lending Pools (PDLPs), delta hedge

总结:<br />
本文探讨了去中心化永续合约协议虽已达到数十亿美元的日交易量，但仍未成为中心化交易平台如Binance的有力竞争者的原因之一——即在去中心化环境中市场制造者和专业交易者的资本成本较高。文章重点研究了Jupiter、Hyperliquid和GMX等协议使用的、旨在改善永续期货交易者借款成本的Perpetual Demand Lending Pools（PDLPs）机制，并对其进行了形式化定义。接着，文章提出了一个通用的目标权重机制，该机制能覆盖GMX和Jupiter的实际应用。作者详细描述了在这些机制中的套利行为以及套利者和流动性提供者的预期收益。基于此框架，文章证明在一般条件下，PDLPs易于进行德尔塔对冲，这在一定程度上解释了实时对冲PDLP策略的普及。最后，本文提出通过动态参数化来提高PDLPs的资本效率的可能性和方向。 <div>
arXiv:2502.06028v1 Announce Type: new 
Abstract: Decentralized perpetuals protocols have collectively reached billions of dollars of daily trading volume, yet are still not serious competitors on the basis of trading volume with centralized venues such as Binance. One of the main reasons for this is the high cost of capital for market makers and sophisticated traders in decentralized settings. Recently, numerous decentralized finance protocols have been used to improve borrowing costs for perpetual futures traders. We formalize this class of mechanisms utilized by protocols such as Jupiter, Hyperliquid, and GMX, which we term~\emph{Perpetual Demand Lending Pools} (PDLPs). We then formalize a general target weight mechanism that generalizes what GMX and Jupiter are using in practice. We explicitly describe pool arbitrage and expected payoffs for arbitrageurs and liquidity providers within these mechanisms. Using this framework, we show that under general conditions, PDLPs are easy to delta hedge, partially explaining the proliferation of live hedged PDLP strategies. Our results suggest directions to improve capital efficiency in PDLPs via dynamic parametrization.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comprehensive Energy Management Application Method considering Smart Home Occupant Behavior using IoT and Real Big Data</title>
<link>https://arxiv.org/abs/2502.06052</link>
<guid>https://arxiv.org/abs/2502.06052</guid>
<content:encoded><![CDATA[
<div> 关键词：智能电网、智能家居、能源消耗行为模式、预测模型、混合整数线性规划（MILP）

<br /><br />总结：
该研究关注了互联网物联网在智能电网和智能家居中的应用。为了实现更精确的能源管理规划，系统需要了解居民独特的能源消耗行为模式，并利用实际的1分钟间隔智能家庭数据（包括光伏发电和电动汽车）对非可控负载进行预测。通过比较不同的预测模型，文章提出了一种优化的去中心化管理系统，采用混合整数线性规划（MILP）算法制定负荷调度方案，旨在在尽可能少地改变居民原有消费习惯的前提下，降低总的能源成本。实验结果显示，所提出的系统具有高精度预测及良好的性能表现，能有效提高能源效率，减少能源成本（最高可达62.05%），减小峰谷比（PAR，最高减少44.19%）以及降低净能耗的标准差（最高减少19.70%）。 <div>
arXiv:2502.06052v1 Announce Type: new 
Abstract: One of the most far-reaching use cases of the internet of things is in smart grid and smart home operation. The smart home concept allows residents to control, monitor, and manage their energy consumption with minimum loss and self-involvement. Since each household's lifestyle and energy consumption is unique, the management system needs background knowledge about residents' energy consumption behavioral patterns for more accurate planning. To obtain this information, data related to residents' consumption records must be processed. This research has attempted to provide an optimal decentralized management system consisting of interoperable sections to forecast, optimize, schedule, and implement load management in a smart home. Comparing different prediction models using 4 years of 1-min interval real data of a smart home with photovoltaic generation (PV) and electric vehicle (EV), forecasting non-controllable loads and taking a deterministic approach in different scenarios, the system uses mixed integer linear programming (MILP) to provide load scheduling with the objective of an optimal total energy cost reduction with minimum changes in the household's desired consumption compared to the initial state. The results have shown that the proposed system has reliable performance due to the high precision of the forecast and has led to increased energy efficiency, reduced energy cost (up to 62. 05\%), reduced peak-to-average ratio (PAR) (up to 44. 19\%) and reduced standard deviation (SD) (up to 19. 70\%) in net consumption.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fine-Tuning Federated Learning-Based Intrusion Detection Systems for Transportation IoT</title>
<link>https://arxiv.org/abs/2502.06099</link>
<guid>https://arxiv.org/abs/2502.06099</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 边缘计算, 连接与自动驾驶车辆, 集群入侵检测系统, 联邦学习

<br /><br />总结:
本文关注了机器学习和边缘计算在智能交通系统中的应用，特别是对于连接与自动驾驶车辆（CAVs）的安全挑战。传统入侵检测系统难以应对现代威胁，因此提出了基于联邦学习（FL）的入侵检测系统解决方案。然而，在CAV网络中部署FL-based IDS会面临设备资源限制、与其他关键应用的竞争以及硬件和网络条件差异等问题。为解决这些问题，文章提出了一种混合服务器-边缘FL框架，该框架将预训练任务卸载到中心服务器完成，同时允许边缘设备进行轻量级微调，从而减少了内存使用高达42%，缩短训练时间高达75%，并保持了高达99.2%的IDS准确性。此外，可扩展性分析表明，随着客户端数量的增加，该框架性能下降轻微，显示出其在CAV网络和其他物联网应用中的可行性。 <div>
arXiv:2502.06099v1 Announce Type: new 
Abstract: The rapid advancement of machine learning (ML) and on-device computing has revolutionized various industries, including transportation, through the development of Connected and Autonomous Vehicles (CAVs) and Intelligent Transportation Systems (ITS). These technologies improve traffic management and vehicle safety, but also introduce significant security and privacy concerns, such as cyberattacks and data breaches. Traditional Intrusion Detection Systems (IDS) are increasingly inadequate in detecting modern threats, leading to the adoption of ML-based IDS solutions. Federated Learning (FL) has emerged as a promising method for enabling the decentralized training of IDS models on distributed edge devices without sharing sensitive data. However, deploying FL-based IDS in CAV networks poses unique challenges, including limited computational and memory resources on edge devices, competing demands from critical applications such as navigation and safety systems, and the need to scale across diverse hardware and connectivity conditions. To address these issues, we propose a hybrid server-edge FL framework that offloads pre-training to a central server while enabling lightweight fine-tuning on edge devices. This approach reduces memory usage by up to 42%, decreases training times by up to 75%, and achieves competitive IDS accuracy of up to 99.2%. Scalability analyses further demonstrates minimal performance degradation as the number of clients increase, highlighting the framework's feasibility for CAV networks and other IoT applications.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reducing Variance Caused by Communication in Decentralized Multi-agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.06261</link>
<guid>https://arxiv.org/abs/2502.06261</guid>
<content:encoded><![CDATA[
<div> 关键词： decentralized multi-agent deep reinforcement learning (MADRL)，communication，variance，policy gradients，modular techniques

总结:
<br />
本文关注于具有通信功能的分布式多智能体深度强化学习（MADRL）中的一个问题，即通信可能带来的不确定性会引入到策略梯度学习的方差中。作者对这一特定环境下通信造成的策略梯度方差进行了理论分析，并提出了模块化技术以降低训练过程中的方差。将这些技术应用于两个现有的分布式MADRL通信算法，并在StarCraft Multi-Agent Challenge和Traffic Junction领域内的多个任务上进行评估。实验结果显示，结合了所提技术的分布式MADRL通信方法不仅能够实现高性能的智能体，而且还能有效减少训练过程中策略梯度的方差。 <div>
arXiv:2502.06261v1 Announce Type: new 
Abstract: In decentralized multi-agent deep reinforcement learning (MADRL), communication can help agents to gain a better understanding of the environment to better coordinate their behaviors. Nevertheless, communication may involve uncertainty, which potentially introduces variance to the learning of decentralized agents. In this paper, we focus on a specific decentralized MADRL setting with communication and conduct a theoretical analysis to study the variance that is caused by communication in policy gradients. We propose modular techniques to reduce the variance in policy gradients during training. We adopt our modular techniques into two existing algorithms for decentralized MADRL with communication and evaluate them on multiple tasks in the StarCraft Multi-Agent Challenge and Traffic Junction domains. The results show that decentralized MADRL communication methods extended with our proposed techniques not only achieve high-performing agents but also reduce variance in policy gradients during training.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation</title>
<link>https://arxiv.org/abs/2502.06348</link>
<guid>https://arxiv.org/abs/2502.06348</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized finance, Price oracles, Manipulation detection, Large language models, Framework

总结:
本文提出了一种新的基于LLM（Large Language Models）的框架，用于自动化检测去中心化金融应用中的价格预言机操纵行为。该框架利用不同LLM模型的优势，首先通过一个LLM模型从顶级学术论文中提取关于价格预言机漏洞的领域专业知识，以此消除开发者或审计员对深厚专业背景知识的需求。接下来，利用这个知识，生成结构化、情境感知的思维链提示，引导另一个LLM模型准确识别智能合约中的操纵模式。实验验证了该框架的有效性，在分析来自2021年至2023年期间46个实际DeFi攻击或项目中的60个已知漏洞数据时，最佳性能的LLM组合（Haiku-Haiku-4o-mini）相比于现有最先进的工具GPTScan，在召回率上提高了2.58倍（0.667对比0.259），同时保持了相当的精度。此外，该框架还展示了使用开源替代方案替换商业模型的可能性，从而增强了开发者的数据隐私和安全性。 <div>
arXiv:2502.06348v1 Announce Type: new 
Abstract: Decentralized finance applications depend on accurate price oracles to ensure secure transactions, yet these oracles are highly vulnerable to manipulation, enabling attackers to exploit smart contract vulnerabilities for unfair asset valuation and financial gain. Detecting such manipulations traditionally relies on the manual effort of experienced experts, presenting significant challenges. In this paper, we propose a novel LLM-driven framework that automates the detection of price oracle manipulations by leveraging the complementary strengths of different LLM models. Our approach begins with domain-specific knowledge extraction, where an LLM model synthesizes precise insights about price oracle vulnerabilities from top-tier academic papers, eliminating the need for profound expertise from developers or auditors. This knowledge forms the foundation for a second LLM model to generate structured, context-aware chain of thought prompts, which guide a third LLM model in accurately identifying manipulation patterns in smart contracts. We validate the framework effectiveness through experiments on 60 known vulnerabilities from 46 real-world DeFi attacks or projects spanning 2021 to 2023. The best performing combination of LLMs (Haiku-Haiku-4o-mini) identified by AiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs 0.259) compared to the state-of-the-art tool GPTScan, while maintaining comparable precision. Furthermore, our framework demonstrates the feasibility of replacing commercial models with open-source alternatives, enhancing privacy and security for developers.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding</title>
<link>https://arxiv.org/abs/2502.06440</link>
<guid>https://arxiv.org/abs/2502.06440</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Path Finding (MAPF)，分布式学习，有限观察场，sheaf理论，深度强化学习

总结:
本文提出了一种新的解决多智能体路径规划问题（MAPF）的框架，该框架将sheaf理论应用于分布式深度强化学习中。针对现有学习基 <div>
arXiv:2502.06440v1 Announce Type: new 
Abstract: The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest and collision-free paths for multiple agents in a known, potentially obstacle-ridden environment. It is the core challenge for robotic deployments in large-scale logistics and transportation. Decentralized learning-based approaches have shown great potential for addressing the MAPF problems, offering more reactive and scalable solutions. However, existing learning-based MAPF methods usually rely on agents making decisions based on a limited field of view (FOV), resulting in short-sighted policies and inefficient cooperation in complex scenarios. There, a critical challenge is to achieve consensus on potential movements between agents based on limited observations and communications. To tackle this challenge, we introduce a new framework that applies sheaf theory to decentralized deep reinforcement learning, enabling agents to learn geometric cross-dependencies between each other through local consensus and utilize them for tightly cooperative decision-making. In particular, sheaf theory provides a mathematical proof of conditions for achieving global consensus through local observation. Inspired by this, we incorporate a neural network to approximately model the consensus in latent space based on sheaf theory and train it through self-supervised learning. During the task, in addition to normal features for MAPF as in previous works, each agent distributedly reasons about a learned consensus feature, leading to efficient cooperation on pathfinding and collision avoidance. As a result, our proposed method demonstrates significant improvements over state-of-the-art learning-based MAPF planners, especially in relatively large and complex scenarios, demonstrating its superiority over baselines in various simulations and real-world robot experiments.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralizing Trust: Consortium Blockchains and Hyperledger Fabric Explained</title>
<link>https://arxiv.org/abs/2502.06540</link>
<guid>https://arxiv.org/abs/2502.06540</guid>
<content:encoded><![CDATA[
<div> 关键词：信任模型、网络、区块链、Hyperledger Fabric、分布式共识

总结:
本文从信任模型的角度概述了区块链技术，重点介绍了广泛应用的分布式区块链实现——Hyperledger Fabric框架。文章讨论了信任模型的中心化与分布式特性，以及区块链如何利用先进的加密技术和去中心化的共识机制来建立网络参与者间的信任。此外，文中详细剖析了Hyperledger Fabric的信任模型、组件构成、整体架构以及该平台的一般实施蓝图。文章旨在为具有技术背景但不一定是区块链专家的读者提供一个友好的入门级综述，激发他们进一步深入研究这些日益流行的先进技术。<br /><br /> <div>
arXiv:2502.06540v1 Announce Type: new 
Abstract: Trust models are essential components of networks of any nature, as they refer to confidence frameworks to evaluate and verify if their participants act reliably and fairly. They are necessary to any social, organizational, or computer network model to ensure truthful interactions, data integrity, and overall system resilience. Trust models can be centralized or distributed, each providing a good fair of benefits and challenges. Blockchain is a special case of distributed trust models that utilize advanced cryptographic techniques and decentralized consensus mechanisms to enforce confidence among participants within a network. In this piece, we provide an overview of blockchain networks from the trust model perspective, with a special focus on the Hyperledger Fabric framework, a widespread blockchain implementation with a consortium architecture. We explore Fabric in detail, including its trust model, components, overall architecture, and a general implementation blueprint for the platform. We intend to offer readers with technical backgrounds but not necessarily experts in the blockchain field a friendly review of these topics to spark their curiosity to continue expanding their knowledge on these increasingly popular technologies.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Network Creation Games with 2-Neighborhood Maximization</title>
<link>https://arxiv.org/abs/2502.06561</link>
<guid>https://arxiv.org/abs/2502.06561</guid>
<content:encoded><![CDATA[
<div> 关键词：网络创建游戏、纳什均衡、贪婪均衡、直径、价格混乱<br /><br />总结:
本文关注的是在网络创建游戏中，节点以最大化其二度邻居为目标的简单模型。研究内容包括纳什均衡(NE)和贪婪均衡(GE)的存在性、结构及其质量。文中揭示了度为2的路径和环路的存在性，并给出了与边成本α及节点数n无关的紧致直径上界。不同于以往的研究，该文指出直径的边界并不能推导出价格混乱的边界，因此采用了其他方法。文章得出了关于价格混乱的非平凡界限，对于NE有Ω(log(n/α))的下界，而对于低α值的GE则给出了一条精确的线性上界。 <div>
arXiv:2502.06561v1 Announce Type: new 
Abstract: Network creation games are well-established for investigating the decentralized formation of communication networks, like the Internet or social networks. In these games, selfish agents that correspond to network nodes strategically create costly edges to maximize their centrality in the formed network. We depart from this by focusing on the simpler objective of maximizing the 2-neighborhood. This seems natural for social networks, as an agent's connection benefit is typically provided by her neighbors and their neighbors but not by strangers further away.
  For this natural model, we study the existence, the structure and the quality both of Nash equilibria (NE) and greedy equilibria (GE). We give structural results on the existence of degree-2 paths and cycles, and we provide tight constant bounds on the diameter. In contrast to most previous network creation game research, our bounds on the diameter are independent of edge cost $\alpha$ and the number of agents $n$. Also, bounding the diameter does not imply bounding the price of anarchy, which calls for other methods. Using them, we obtain non-trivial bounds on the price of anarchy, including a $\Omega(\log(\frac{n}{\alpha}))$ lower bound for NE, and a tight linear bound for GE for low $\alpha$.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Powered Asset Tokenization Platform</title>
<link>https://arxiv.org/abs/2502.06752</link>
<guid>https://arxiv.org/abs/2502.06752</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、资产代币化、安全性、用户友好平台、金融自由

总结:
<br />
本文介绍了区块链技术如何通过其安全、去中心化和无需信任的数据管理方法革新了金融和技术领域。资产价值波动日益加剧，资产代币化应运而生，为资产所有权赋予了不可变、流动和无可辩驳的身份，类似于加密货币。然而，资产代币化也面临着恶意用户的攻击，这些攻击破坏了其安全性基础，并对代表现实世界具有物理重要性的资产造成了损害。该项目旨在帮助用户通过提供一个高度安全、用户友好的平台来管理和发行资产代币，并促进利益相关者之间的开放透明沟通，从而维护区块链的去中心化特性，并结合加密货币支持的代币，实现资产所有权的金融自由和附加市场价值。 <div>
arXiv:2502.06752v1 Announce Type: new 
Abstract: Blockchain Technology has revolutionized Finance and Technology with its secure, decentralized, and trust-less methodologies of data management. In a world where asset value fluctuations are unprecedented, it has become increasingly important to secure one's stake on their valuable assets and streamline the process of acquiring and transferring that stake over a trust-less environment. Tokenization proves to be unbeaten when it comes to giving the ownership of one's asset, an immutable, liquid, and irrefutable identity, as of the likes of cryptocurrency. It enables users to store and maintain records of their assets and even transfer fractions of these assets to other investors and stakeholders in the form of these tokens. However, like cryptocurrency, it too has witnessed attacks by malicious users that have compromised on their very foundation of security.These attacks have inflicted more damage since they represent real-world assets that have physical importance. This project aims to assist users to secure their valuable assets by providing a highly secure user-friendly platform to manage, create and deploy asset-tokens, and facilitate open and transparent communication between stakeholders, thereby upholding the decentralized nature of blockchain and offering the financial freedom of asset ownership, with an added market value of a cryptocurrency-backed tokens.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Naeural AI OS -- Decentralized ubiquitous computing MLOps execution engine</title>
<link>https://arxiv.org/abs/2306.08708</link>
<guid>https://arxiv.org/abs/2306.08708</guid>
<content:encoded><![CDATA[
<div> 关键词：无所不在计算、人工智能、深度学习、低代码开发、去中心化社区

总结:<br />
本文关注了无所不在计算的发展及其对自动化学习和智能应用需求的增长。虽然人工智能和深度学习取得了显著进步，但大规模采用仍因依赖昂贵复杂的云数值计算基础设施而受到阻碍。为解决这一问题，文章提出了一种创新的低代码开发和部署端到端AI合作应用管道的方法。该方法着重于在基于代币经济的完全去中心化的全球合作社区中，实现基础设施分配、成本控制及安全作业分布。 <div>
arXiv:2306.08708v5 Announce Type: replace 
Abstract: Over the past few years, ubiquitous, or pervasive computing has gained popularity as the primary approach for a wide range of applications, including enterprise-grade systems, consumer applications, and gaming systems. Ubiquitous computing refers to the integration of computing technologies into everyday objects and environments, creating a network of interconnected devices that can communicate with each other and with humans. By using ubiquitous computing technologies, communities can become more connected and efficient, with members able to communicate and collaborate more easily. This enabled interconnectedness and collaboration can lead to a more successful and sustainable community. The spread of ubiquitous computing, however, has emphasized the importance of automated learning and smart applications in general. Even though there have been significant strides in Artificial Intelligence and Deep Learning, large scale adoption has been hesitant due to mounting pressure on expensive and highly complex cloud numerical-compute infrastructures. Adopting, and even developing, practical machine learning systems can come with prohibitive costs, not only in terms of complex infrastructures but also of solid expertise in Data Science and Machine Learning. In this paper we present an innovative approach for low-code development and deployment of end-to-end AI cooperative application pipelines. We address infrastructure allocation, costs, and secure job distribution in a fully decentralized global cooperative community based on tokenized economics.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning in Zero-Sum Markov Games: Relaxing Strong Reachability and Mixing Time Assumptions</title>
<link>https://arxiv.org/abs/2312.08008</link>
<guid>https://arxiv.org/abs/2312.08008</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized learning, Infinite-horizon zero-sum Markov games, Payoff-based, Tsallis entropy regularization, Approximate Nash equilibrium

<br /><br />总结:
本文关注的是无信息交流下的无限期零和马尔可夫游戏中的基于收益的去中心化学习。相较于先前需要强可达性和混合时间假设的工作，文章提出了一种新的收敛算法，该算法只需存在一个具有有限可达性和混合时间的策略（不一定是已知的）即可保证收敛。关键创新在于引入了Tsallis熵正则化来平滑最佳响应策略更新，通过适当地调整这个正则化参数，可以确保足够的探索性，从而绕过对MDP的严格假设。通过建立关于由Tsallis熵正则化诱导的价值和策略更新的新性质，作者证明了算法可以在有限时间内收敛到近似纳什均衡。 <div>
arXiv:2312.08008v3 Announce Type: replace 
Abstract: We address payoff-based decentralized learning in infinite-horizon zero-sum Markov games. In this setting, each player makes decisions based solely on received rewards, without observing the opponent's strategy or actions nor sharing information. Prior works established finite-time convergence to an approximate Nash equilibrium under strong reachability and mixing time assumptions. We propose a convergent algorithm that significantly relaxes these assumptions, requiring only the existence of a single policy (not necessarily known) with bounded reachability and mixing time. Our key technical novelty is introducing Tsallis entropy regularization to smooth the best-response policy updates. By suitably tuning this regularization, we ensure sufficient exploration, thus bypassing previous stringent assumptions on the MDP. By establishing novel properties of the value and policy updates induced by the Tsallis entropy regularizer, we prove finite-time convergence to an approximate Nash equilibrium.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Clustered Federated Learning</title>
<link>https://arxiv.org/abs/2405.19272</link>
<guid>https://arxiv.org/abs/2405.19272</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、差分隐私（Differential Privacy）、聚类客户端（Clustered FL）、高结构化数据异质性、不同ially Private Clustered FL（DPFL）

<br /><br />总结:
本文提出了一种针对带有结构化数据异质性的不同iallyPrivate 联邦学习（DPFL）的聚类算法。现有的聚类方法在DPFL中对DP噪声敏感且易出错。为解决此问题，该文提出的方案通过同时考虑客户端的模型更新和训练损失值来进行客户端聚类。在第一轮结束后进行模型更新聚类时，利用大批次及高斯混合模型（GMM）来减少DP和随机噪声的影响，有效避免聚类错误，尤其适用于注重隐私的高噪声场景。此外，文章还对其理论依据进行了分析并在多种数据分布和隐私预算下进行了实验验证，结果显示其在处理DPFL中的大规模结构化数据异质性方面表现出优越效果。 <div>
arXiv:2405.19272v2 Announce Type: replace 
Abstract: Federated learning (FL), which is a decentralized machine learning (ML) approach, often incorporates differential privacy (DP) to provide rigorous data privacy guarantees. Previous works attempted to address high structured data heterogeneity in vanilla FL settings through clustering clients (a.k.a clustered FL), but these methods remain sensitive and prone to errors, further exacerbated by the DP noise. This vulnerability makes the previous methods inappropriate for differentially private FL (DPFL) settings with structured data heterogeneity. To address this gap, we propose an algorithm for differentially private clustered FL, which is robust to the DP noise in the system and identifies the underlying clients' clusters correctly. To this end, we propose to cluster clients based on both their model updates and training loss values. Furthermore, for clustering clients' model updates at the end of the first round, our proposed approach addresses the server's uncertainties by employing large batch sizes as well as Gaussian Mixture Models (GMM) to reduce the impact of DP and stochastic noise and avoid potential clustering errors. This idea is efficient especially in privacy-sensitive scenarios with more DP noise. We provide theoretical analysis to justify our approach and evaluate it across diverse data distributions and privacy budgets. Our experimental results show its effectiveness in addressing large structured data heterogeneity in DPFL.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Self-Regulating Random Walks for Resilient Decentralized Learning on Graphs</title>
<link>https://arxiv.org/abs/2407.11762</link>
<guid>https://arxiv.org/abs/2407.11762</guid>
<content:encoded><![CDATA[
<div> 关键词: 多重随机游走, 故障恢复, 分布式算法, DecAFork, DecAFork+

总结:
本文研究了在图上执行特定计算任务的多重随机游走（RWs）场景，特别是在节点或链路故障下如何保持预期数量的RWs以确保系统具有容错性。由于缺乏中心实体来跟踪和替换失败的RWs，作者提出了两个分布式算法DecAFork和DecAFork+，这两个算法能够在存在任意RW失败的情况下使图中的RW数量维持在一个期望值附近。通过估计返回时间分布，节点能够预测何时可能发生失败并适时复制（分叉）存活的RW。DecAFork+还允许终止操作以避免因过度分叉而导致网络过载。文中通过大量的数值模拟展示了DecAFork和DecAFork+相对于基线方法在快速检测和应对失败方面的性能优势，并为这两个算法的性能提供了理论保证。 <div>
arXiv:2407.11762v2 Announce Type: replace 
Abstract: Consider the setting of multiple random walks (RWs) on a graph executing a certain computational task. For instance, in decentralized learning via RWs, a model is updated at each iteration based on the local data of the visited node and then passed to a randomly chosen neighbor. RWs can fail due to node or link failures. The goal is to maintain a desired number of RWs to ensure failure resilience. Achieving this is challenging due to the lack of a central entity to track which RWs have failed to replace them with new ones by forking (duplicating) surviving ones. Without duplications, the number of RWs will eventually go to zero, causing a catastrophic failure of the system. We propose two decentralized algorithms called DecAFork and DecAFork+ that can maintain the number of RWs in the graph around a desired value even in the presence of arbitrary RW failures. Nodes continuously estimate the number of surviving RWs by estimating their return time distribution and fork the RWs when failures are likely to happen. DecAFork+ additionally allows terminations to avoid overloading the network by forking too many RWs. We present extensive numerical simulations that show the performance of DecAFork and DecAFork+ regarding fast detection and reaction to failures compared to a baseline, and establish theoretical guarantees on the performance of both algorithms.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SCALM: Detecting Bad Practices in Smart Contracts Through LLMs</title>
<link>https://arxiv.org/abs/2502.04347</link>
<guid>https://arxiv.org/abs/2502.04347</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、智能合约、坏实践、SCALM、大型语言模型

总结:
随着Ethereum平台的成熟和广泛应用，确保智能合约编写规范的重要性日益凸显。本文针对智能合约中的不良实践进行了首次系统性研究，详细探讨了超过35种具体问题。为了解决这些问题，文章提出了一种名为SCALM的大规模语言模型（LLMs）框架，该框架结合了Step-Back Prompting和检索增强生成（RAG）技术，能有效地识别并处理各种智能合约的不良实践。通过使用多种LLM和数据集进行广泛实验，结果显示SCALM在检测智能合约中的不良实践中表现优于现有的工具。 <div>
arXiv:2502.04347v1 Announce Type: new 
Abstract: As the Ethereum platform continues to mature and gain widespread usage, it is crucial to maintain high standards of smart contract writing practices. While bad practices in smart contracts may not directly lead to security issues, they do elevate the risk of encountering problems. Therefore, to understand and avoid these bad practices, this paper introduces the first systematic study of bad practices in smart contracts, delving into over 35 specific issues. Specifically, we propose a large language models (LLMs)-based framework, SCALM. It combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to identify and address various bad practices effectively. Our extensive experiments using multiple LLMs and datasets have shown that SCALM outperforms existing tools in detecting bad practices in smart contracts.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedP$^2$EFT: Federated Learning to Personalize Parameter Efficient Fine-Tuning for Multilingual LLMs</title>
<link>https://arxiv.org/abs/2502.04387</link>
<guid>https://arxiv.org/abs/2502.04387</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、多语言大模型、参数高效微调、FedP$^2$EFT、贝叶斯稀疏秩选择

总结:
本文提出了FedP$^2$EFT，一种针对跨设备联邦学习环境下多语言大型语言模型的个性化学习方法。与依赖手动配置的个人化策略不同，FedP$^2$EFT通过贝叶斯稀疏秩选择协同地为每个客户端学习最优的个性化参数高效微调（如LoRA）结构。文章指出，现有的PEFT结构选择方法在低数据量场景下容易过拟合，而FedP$^2$EFT在模拟和真实世界的多语言联邦学习基准上均展现出显著优于现有个性化微调方法的性能，并能补充多种现存的联邦学习方法的优势。 <div>
arXiv:2502.04387v1 Announce Type: new 
Abstract: Federated learning (FL) has enabled the training of multilingual large language models (LLMs) on diverse and decentralized multilingual data, especially on low-resource languages. To improve client-specific performance, personalization via the use of parameter-efficient fine-tuning (PEFT) modules such as LoRA is common. This involves a personalization strategy (PS), such as the design of the PEFT adapter structures (e.g., in which layers to add LoRAs and what ranks) and choice of hyperparameters (e.g., learning rates) for fine-tuning. Instead of manual PS configuration, we propose FedP$^2$EFT, a federated learning-to-personalize method for multilingual LLMs in cross-device FL settings. Unlike most existing PEFT structure selection methods, which are prone to overfitting low-data regimes, FedP$^2$EFT collaboratively learns the optimal personalized PEFT structure for each client via Bayesian sparse rank selection. Evaluations on both simulated and real-world multilingual FL benchmarks demonstrate that FedP$^2$EFT largely outperforms existing personalized fine-tuning methods, while complementing a range of existing FL methods.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>$\mathsf{CRATE}$: Cross-Rollup Atomic Transaction Execution</title>
<link>https://arxiv.org/abs/2502.04659</link>
<guid>https://arxiv.org/abs/2502.04659</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、Layer 2可扩展性、跨链协议、cross-rollup composability、$\mathsf{CRATE}$

<br /><br />总结:
本文介绍了$\mathsf{CRATE}$，一种针对跨Rollup可组合性的安全协议，旨在确保跨Rollup交易（CRTs）的整体性和串行化执行。现有Layer 2（L2）扩容解决方案如rollups导致碎片化并阻碍了可组合性，而当前的跨链协议在协调机制或信任假设上存在不足。$\mathsf{CRATE}$支持不同Layer 1（L1）链上的rollup，并能在L1上实现4轮确认的最终性，仅依赖于底层L1和L2的活性。文章提出了两个CRT的正式模型，定义了其中的原子性，并形式证明了$\mathsf{CRATE}$的安全性。此外，文中还提供了$\mathsf{CRATE}$的实现以及一个跨Rollup闪贷应用的示例，实验表明$\mathsf{CRATE}$在L1上的 gas 使用上是实际可行的。 <div>
arXiv:2502.04659v1 Announce Type: new 
Abstract: Blockchains have revolutionized decentralized applications, with composability enabling atomic, trustless interactions across smart contracts. However, layer 2 (L2) scalability solutions like rollups introduce fragmentation and hinder composability. Current cross-chain protocols, including atomic swaps, bridges, and shared sequencers, lack the necessary coordination mechanisms or rely on trust assumptions, and are thus not sufficient to support full cross-rollup composability. This paper presents $\mathsf{CRATE}$, a secure protocol for cross-rollup composability that ensures all-or-nothing and serializable execution of cross-rollup transactions (CRTs). $\mathsf{CRATE}$ supports rollups on distinct layer 1 (L1) chains, achieves finality in 4 rounds on L1, and only relies on the underlying L1s and the liveness of L2s. We introduce two formal models for CRTs, define atomicity within them, and formally prove the security of $\mathsf{CRATE}$. We also provide an implementation of $\mathsf{CRATE}$ along with a cross-rollup flash loan application; our experiments demonstrate that $\mathsf{CRATE}$ is practical in terms of gas usage on L1.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Coverage Control in Non-Convex Annulus Region with Conformal Mapping</title>
<link>https://arxiv.org/abs/2502.04697</link>
<guid>https://arxiv.org/abs/2502.04697</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统(MASs)，非凸区域，覆盖任务，共形映射，分布式控制

总结:
<br />
本文提出了一种利用共形映射的新型扇区覆盖公式，针对非凸环状区域的高效覆盖任务问题进行研究。该方法将非星形区域转化为拓扑等价的区域，优化了覆盖性能并实现了子区域间的负载平衡。通过扇形分区机制和共形映射的微分同胚性质，设计了一种分布式控制律，确保MASs达到期望配置，同时优化全局覆盖成本并保证工作负载均衡的指数收敛性。此外，文中还开发了一种迭代搜索算法来识别非星形区域中多智能体部署的最佳近似解。理论分析证明了闭环系统的渐近稳定性和任意小容差下的全局收敛性。数值模拟验证了所提共形映射覆盖公式的实用价值。 <div>
arXiv:2502.04697v1 Announce Type: new 
Abstract: Efficiently fulfilling coverage tasks in non-convex regions has long been a significant challenge for multi-agent systems (MASs). By leveraging conformal mapping, this paper introduces a novel sectorial coverage formulation to transform a non-convex annulus region into a topologically equivalent one. This approach enables the deployment of MASs in a non-star-shaped region while optimizing coverage performance and achieving load balance among sub-regions. It provides a unique perspective on the partitioned sub-regions to highlight the geodesic convex property of the non-star-shaped region. By utilizing the sectorial partition mechanism and the diffeomorphism property of conformal mapping, a decentralized control law is designed to drive MASs towards a desired configuration, which not only optimizes the global coverage cost but also ensures exponential convergence of equitable workload. Moreover, an iterative search algorithm is developed to identify the optimal approximation of multi-agent deployment in the non-star-shaped region. Theoretical analysis is conducted to confirm the asymptotic stability and global convergence with arbitrary small tolerance of the closed-loop system. Finally, numerical simulations demonstrate the practicality of the proposed coverage formulation with conformal mapping.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Survey on Token-Based Distributed MutualExclusion Algorithms</title>
<link>https://arxiv.org/abs/2502.04708</link>
<guid>https://arxiv.org/abs/2502.04708</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式互斥访问、令牌机制、网络模型、性能衡量、容错性、k-互斥、自稳定算法、有限项目平面、机器学习、区块链技术

总结:<br />
本文探讨了分布式计算中避免多进程并发访问同一资源的核心挑战——分布式互斥访问（DME），重点研究了令牌机制及其在网络模型（包括树形、环形、全互联图、网格结构和adhoc网络）中的应用。文章分析了此类方案的通信成本和容错策略，并介绍了专门针对k-互斥与自稳定算法的变体。此外，还引入了一种基于有限项目平面的特殊方法，说明某些协议在最佳和最坏情况下的高效性能。最后，展望了利用机器学习进行令牌预测路由和运用区块链技术抵抗恶意行为的未来研究趋势，旨在提供一个全面而易懂的令牌机制为基础的DME方法概述及新兴研究趋势的洞察。 <div>
arXiv:2502.04708v1 Announce Type: new 
Abstract: In large-scale distributed environments, avoiding concurrent access to the same resource by multiple processes becomes a core challenge, commonly termed distributed mutual exclusion (DME). Token-based mechanisms have long been recognized as an effective strategy, wherein a solitary token is handed around among processes as the key that allows access to the critical section. By doing so, they often reduce the messaging overhead compared to alternate methods.
  This work surveys the significance of mutual exclusion in distributed computing and examines token-based solutions across various network models (including tree-based, ring-based, fully interconnected graphs, mesh structures, and ad hoc networks). We also delve into essential performance measures such as communication costs and strategies for fault tolerance, then branch into specialized variants, such as k-mutual exclusion and self-stabilizing algorithms.
  Furthermore, a specialized approach that relies on finite projective planes is introduced to highlight how certain protocols can perform efficiently under both best- and worst-case conditions. Lastly, we explore future directions involving machine learning for token predictive routing and blockchain techniques to resist adversarial behavior. This aims to provide a thorough yet accessible overview of token-based DME approaches, together with insights on emerging research trends.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mining a Decade of Event Impacts on Contributor Dynamics in Ethereum: A Longitudinal Study</title>
<link>https://arxiv.org/abs/2502.05054</link>
<guid>https://arxiv.org/abs/2502.05054</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、开发者活动、技术升级、市场事件、社区决策

总结:
我们分析了跨越10年时间、涵盖10个主要Ethereum仓库（总计129884次提交和40550个问题）的开发者活动数据。研究发现，技术升级事件会引发事件前的开发活动增加，而之后的提交频率则会降低；相反，市场事件会导致更被动的开发响应。核心基础设施如Go-Ethereum相比开发者工具具有更快的问题解决速度，而且技术事件能促进核心团队间的协作。研究结果揭示了不同类型事件如何塑造开发动态，并为项目管理者和开发者在重大转型期间保持开发势头提供了洞见，进一步加深了对开发社区韧性和其对生态系统变化适应性的理解。 <div>
arXiv:2502.05054v1 Announce Type: new 
Abstract: We analyze developer activity across 10 major Ethereum repositories (totaling 129884 commits, 40550 issues) spanning 10 years to examine how events such as technical upgrades, market events, and community decisions impact development. Through statistical, survival, and network analyses, we find that technical events prompt increased activity before the event, followed by reduced commit rates afterwards, whereas market events lead to more reactive development. Core infrastructure repositories like Go-Ethereum exhibit faster issue resolution compared to developer tools, and technical events enhance core team collaboration. Our findings show how different types of events shape development dynamics, offering insights for project managers and developers in maintaining development momentum through major transitions. This work contributes to understanding the resilience of development communities and their adaptation to ecosystem changes.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Amplification Attack</title>
<link>https://arxiv.org/abs/2408.01508</link>
<guid>https://arxiv.org/abs/2408.01508</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、可提取价值（MEV/BEV）、攻击向量、区块链放大攻击、交易验证

<br /><br />总结:
本文探讨了与区块链中可提取价值相关的策略（如套利、抢先交易或尾随交易）如何产生对网络节点降低延迟的强大经济激励。通过修改节点以减少交易验证时间和忽略过滤无效交易，引入了一种新的攻击方式——区块链放大攻击。攻击者可以利用这些修改后的节点将无效交易放大数千倍，对整个网络构成安全威胁。作者通过实证研究在当前以太坊主网中发现了数千起此类野蛮攻击事件，并对其传播机制进行了数学建模以及从监控节点测量模型参数。对比其他已存在的拒绝服务攻击，他们通过本地模拟评估了该攻击的性能，显示攻击者可在修改过的节点上将网络流量放大3600倍，并造成约为发动攻击所需成本的13800倍经济损失。然而，尽管存在这些风险，为了实现更低的延迟，某些提供者可能仍认为运行修改后的节点具有足够的利润空间。为此，作者通过本地网络中的交易验证过程模拟及在以太坊测试网络中部署修改后的节点进行实测，来评估跳过验证的权衡。文章最后对跳过验证的成本效益进行了分析，并提出了针对区块链放大攻击的缓解策略。 <div>
arXiv:2408.01508v3 Announce Type: replace 
Abstract: Strategies related to the blockchain concept of Extractable Value (MEV/BEV), such as arbitrage, front-, or back-running create strong economic incentives for network nodes to reduce latency. Modified nodes, that minimize transaction validation time and neglect to filter invalid transactions in the Ethereum peer-to-peer (P2P) network, introduce a novel attack vector -- a Blockchain Amplification Attack. An attacker can exploit those modified nodes to amplify invalid transactions thousands of times, posing a security threat to the entire network. To illustrate attack feasibility and practicality in the current Ethereum network ("mainnet"), we 1) identify thousands of similar attacks in the wild, 2) mathematically model the propagation mechanism, 3) empirically measure model parameters from our monitoring nodes, and 4) compare the performance with other existing Denial-of-Service attacks through local simulation. We show that an attacker can amplify network traffic at modified nodes by a factor of 3,600, and cause economic damages of approximately 13,800 times the amount needed to carry out the attack. Despite these risks, aggressive latency reduction may still be profitable enough for various providers to justify the existence of modified nodes. To assess this trade-off, we 1) simulate the transaction validation process in a local network and 2) empirically measure the latency reduction by deploying our modified node in the Ethereum test network ("testnet"). We conclude with a cost-benefit analysis of skipping validation and provide mitigation strategies against the blockchain amplification attack.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Noncooperative Equilibrium Selection via a Trading-based Auction</title>
<link>https://arxiv.org/abs/2502.03616</link>
<guid>https://arxiv.org/abs/2502.03616</guid>
<content:encoded><![CDATA[
<div> 关键词: 非合作多智能体系统、协调挑战、共识算法、交易拍卖、TACo<br /><br />总结:<br />
本文提出了一个针对非合作多智能体系统的新型共识算法——交易拍卖(TACo)。该算法旨在解决由于各智能体利益冲突导致的协调难题，允许智能体在不直接通信或披露私有估值的情况下达到共识。通过结构化的交易式拍卖过程，TACo使智能体能够迭代选择感兴趣的选择并在预设有限步数内达成协议。一系列数值实验验证了TACo的终止保证在实践中有效，并表明TACo能够实现将总成本降至最低的中位数性能，同时相较于基线方法更加公平地分配资源。 <div>
arXiv:2502.03616v1 Announce Type: new 
Abstract: Noncooperative multi-agent systems often face coordination challenges due to conflicting preferences among agents. In particular, agents acting in their own self-interest can settle on different equilibria, leading to suboptimal outcomes or even safety concerns. We propose an algorithm named trading auction for consensus (TACo), a decentralized approach that enables noncooperative agents to reach consensus without communicating directly or disclosing private valuations. TACo facilitates coordination through a structured trading-based auction, where agents iteratively select choices of interest and provably reach an agreement within an a priori bounded number of steps. A series of numerical experiments validate that the termination guarantees of TACo hold in practice, and show that TACo achieves a median performance that minimizes the total cost across all agents, while allocating resources significantly more fairly than baseline approaches.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Following Devils' Footprint: Towards Real-time Detection of Price Manipulation Attacks</title>
<link>https://arxiv.org/abs/2502.03718</link>
<guid>https://arxiv.org/abs/2502.03718</guid>
<content:encoded><![CDATA[
<div> 关键词: 价格操纵攻击、去中心化金融(DeFi)、SMARTCAT、预攻击阶段、检测

总结:
本文提出了一个名为SMARTCAT的新方法，用于主动识别去中心化金融(DeFi)应用中的价格操纵攻击。该方法专注于攻击者层面，在预攻击阶段通过分析合约字节码而非源代码和交易数据来识别人为操控行为。SMARTCAT构建了控制流和数据流依赖关系的功能调用图，并对可疑路径进行筛选与必要的跨合约分析，从而实现实时检测。评估结果显示，SMARTCAT相比于现有基线具有高达91.6%的召回率和几乎100%的精度。此外，SMARTCAT还在实战中发现并定位了616个野外地攻击合约，涉及约925万美元的经济损失，其中仅有19例被公开报道。将其应用于以太坊和币安智能链实时检测后，SMARTCAT平均能在相关部署后的99秒内发出14次警报，这些攻击已导致641,000美元损失，其中七起仍在等待实施时机。 <div>
arXiv:2502.03718v1 Announce Type: new 
Abstract: Price manipulation attack is one of the notorious threats in decentralized finance (DeFi) applications, which allows attackers to exchange tokens at an extensively deviated price from the market. Existing efforts usually rely on reactive methods to identify such kind of attacks after they have happened, e.g., detecting attack transactions in the post-attack stage, which cannot mitigate or prevent price manipulation attacks timely. From the perspective of attackers, they usually need to deploy attack contracts in the pre-attack stage. Thus, if we can identify these attack contracts in a proactive manner, we can raise alarms and mitigate the threats. With the core idea in mind, in this work, we shift our attention from the victims to the attackers. Specifically, we propose SMARTCAT, a novel approach for identifying price manipulation attacks in the pre-attack stage proactively. For generality, it conducts analysis on bytecode and does not require any source code and transaction data. For accuracy, it depicts the control- and data-flow dependency relationships among function calls into a token flow graph. For scalability, it filters out those suspicious paths, in which it conducts inter-contract analysis as necessary. To this end, SMARTCAT can pinpoint attacks in real time once they have been deployed on a chain. The evaluation results illustrate that SMARTCAT significantly outperforms existing baselines with 91.6% recall and ~100% precision. Moreover, SMARTCAT also uncovers 616 attack contracts in-the-wild, accounting for \$9.25M financial losses, with only 19 cases publicly reported. By applying SMARTCAT as a real-time detector in Ethereum and Binance Smart Chain, it has raised 14 alarms 99 seconds after the corresponding deployment on average. These attacks have already led to $641K financial losses, and seven of them are still waiting for their ripe time.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning</title>
<link>https://arxiv.org/abs/2502.03801</link>
<guid>https://arxiv.org/abs/2502.03801</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated learning, 数据中毒攻击, 模型中毒攻击, 防御策略, 统一基准

总结:
本文主要研究了联邦学习（Federated learning）中的数据中毒攻击（DPAs）和模型中毒攻击（MPAs），以及针对这些攻击的各种防御策略。文章指出现有防御策略的有效性评估通常孤立进行，且忽视了对两种类型攻击的综合防御效果。作者提出了一种系统性的攻击与防御策略分类，并对不同FL算法和数据异质性场景下的防御有效性进行了统一的比较评估。为了促进该领域的进一步研究，他们构建了一个名为FLPoison的高模块化、可扩展的统一基准框架，用于评估15种代表性攻击和17种防御策略。相关代码已在https://github.com/vio1etus/FLPoison上开源发布。 <div>
arXiv:2502.03801v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training while preserving data privacy, but its decentralized nature exposes it to client-side data poisoning attacks (DPAs) and model poisoning attacks (MPAs) that degrade global model performance. While numerous proposed defenses claim substantial effectiveness, their evaluation is typically done in isolation with limited attack strategies, raising concerns about their validity. Additionally, existing studies overlook the mutual effectiveness of defenses against both DPAs and MPAs, causing fragmentation in this field. This paper aims to provide a unified benchmark and analysis of defenses against DPAs and MPAs, clarifying the distinction between these two similar but slightly distinct domains. We present a systematic taxonomy of poisoning attacks and defense strategies, outlining their design, strengths, and limitations. Then, a unified comparative evaluation across FL algorithms and data heterogeneity is conducted to validate their individual and mutual effectiveness and derive key insights for design principles and future research. Along with the analysis, we frame our work to a unified benchmark, FLPoison, with high modularity and scalability to evaluate 15 representative poisoning attacks and 17 defense strategies, facilitating future research in this domain. Code is available at https://github.com/vio1etus/FLPoison.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy Risks in Health Big Data: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2502.03811</link>
<guid>https://arxiv.org/abs/2502.03811</guid>
<content:encoded><![CDATA[
<div> 关键词: 健康大数据安全、隐私保护、电子健康记录、 Homomorphic加密、区块链、联邦学习、人工智能免疫系统、挑战、未来研究框架

<br />
总结:
本文通过系统性文献回顾，重点阐述了健康大数据安全领域的关键研究，重点关注了电子健康记录、基因组数据和可穿戴设备等技术应用带来的个人敏感信息隐私与安全问题。文章探讨了 Homomorphic 加密、区块链、联邦学习以及人工智能免疫系统等前沿技术如何增强数据安全性并保护个人隐私。同时，指出了当前面临的挑战，并提出了该领域未来的研究框架。 <div>
arXiv:2502.03811v1 Announce Type: new 
Abstract: The digitization of health records has greatly improved the efficiency of the healthcare system and promoted the formulation of related research and policies. However, the widespread application of advanced technologies such as electronic health records, genomic data, and wearable devices in the field of health big data has also intensified the collection of personal sensitive data, bringing serious privacy and security issues. Based on a systematic literature review (SLR), this paper comprehensively outlines the key research in the field of health big data security. By analyzing existing research, this paper explores how cutting-edge technologies such as homomorphic encryption, blockchain, federated learning, and artificial immune systems can enhance data security while protecting personal privacy. This paper also points out the current challenges and proposes a future research framework in this key area.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hybrid Decentralized Optimization: Leveraging Both First- and Zeroth-Order Optimizers for Faster Convergence</title>
<link>https://arxiv.org/abs/2210.07703</link>
<guid>https://arxiv.org/abs/2210.07703</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、零阶优化、一阶优化、深度神经网络、噪声估计器

总结:
<br />
本文研究了混合分布式优化问题，探讨了在分布式系统中，具备零阶优化和一阶优化能力的节点如何协同解决优化任务。研究指出，在合理参数设置下，这样的系统不仅能抵抗具有噪声的零阶代理的影响，甚至能从整合这些代理的信息中获益。文章提出了一种关于带有噪声和可能有偏梯度估计器的分布式优化的新分析方法，该方法对于凸优化和非凸优化问题都适用。实验结果在标准优化任务和训练深度神经网络上验证了这一分析，表明混合一阶零阶优化在实践中是可行的。 <div>
arXiv:2210.07703v3 Announce Type: replace 
Abstract: Distributed optimization is the standard way of speeding up machine learning training, and most of the research in the area focuses on distributed first-order, gradient-based methods. Yet, there are settings where some computationally-bounded nodes may not be able to implement first-order, gradient-based optimization, while they could still contribute to joint optimization tasks. In this paper, we initiate the study of hybrid decentralized optimization, studying settings where nodes with zeroth-order and first-order optimization capabilities co-exist in a distributed system, and attempt to jointly solve an optimization task over some data distribution. We essentially show that, under reasonable parameter settings, such a system can not only withstand noisier zeroth-order agents but can even benefit from integrating such agents into the optimization process, rather than ignoring their information. At the core of our approach is a new analysis of distributed optimization with noisy and possibly-biased gradient estimators, which may be of independent interest. Our results hold for both convex and non-convex objectives. Experimental results on standard optimization tasks confirm our analysis, showing that hybrid first-zeroth order optimization can be practical, even when training deep neural networks.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Price of Decentralization in Decentralized Detection</title>
<link>https://arxiv.org/abs/2409.00728</link>
<guid>https://arxiv.org/abs/2409.00728</guid>
<content:encoded><![CDATA[
<div> 关键词: 德中心化检测、错误概率、分布式学习规则、社交学习、错误指数

总结:
本文探讨了分布式检测中一类算法（如Lalitha等人提出的基于有向图的社交学习规则）的基础误差概率限制。在分布式检测场景下，网络中的节点通过与邻居共享观察样本信息来共同推断未知假设。每个节点仅需了解其观测数据的生成分布，并对来自邻居的消息进行加权处理以形成私有信念。文章首先指出，虽然原始的社交学习规则在样本数量趋近于无穷大时能实现渐近消失的错误概率，但在可达到的错误指数上存在与集中式设置相比的差距。这一差距源于由节点选择用于加权邻居消息的局部权重导致的网络不平衡。为弥补这一差距，文中提出了一种改进的学习规则，并证明其能够实现与集中式设置一样大的错误指数，这意味着在错误概率呈指数衰减的速度方面，分布式基本上不会带来一级惩罚。 <div>
arXiv:2409.00728v2 Announce Type: replace 
Abstract: Fundamental limits on the error probabilities of a family of decentralized detection algorithms (eg., the social learning rule proposed by Lalitha et al. over directed graphs are investigated. In decentralized detection, a network of nodes locally exchanging information about the samples they observe with their neighbors to collectively infer the underlying unknown hypothesis. Each node in the network weighs the messages received from its neighbors to form its private belief and only requires knowledge of the data generating distribution of its observation. In this work, it is first shown that while the original social learning rule of Lalitha et al. achieves asymptotically vanishing error probabilities as the number of samples tends to infinity, it suffers a gap in the achievable error exponent compared to the centralized case. The gap is due to the network imbalance caused by the local weights that each node chooses to weigh the messages received from its neighbors. To close this gap, a modified learning rule is proposed and shown to achieve error exponents as large as those in the centralized setup. This implies that there is essentially no first-order penalty caused by decentralization in the exponentially decaying rate of error probabilities.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Efficient Flocking Control based on Gibbs Random Fields</title>
<link>https://arxiv.org/abs/2502.02984</link>
<guid>https://arxiv.org/abs/2502.02984</guid>
<content:encoded><![CDATA[
<div> 关键词：多agent强化学习(MARL)，Gibbs随机场(GRFs)，多机器人系统，协同控制，运动安全性

<br /><br />总结:
本文提出了一种基于Gibbs随机场的多agent强化学习(MARL)框架，用于解决多机器人系统在拥挤环境中实现高效协同控制所面临的计算负担、性能优化和运动安全性挑战。该框架利用GRFs将多机器人系统表示为遵循联合概率分布的一组随机变量，从而为设计群集奖励提供了新视角。通过基于GRF的信用分配方法实现了去中心化的训练与执行机制，增强了MARL对于机器人数量的可扩展性。同时，引入了动作注意力模块，以隐式预测邻近机器人的运动意图，从而缓解了MARL中的非平稳性问题。实验与仿真结果表明，提出的框架能够在复杂环境中使多机器人系统学习到有效的分布式控制策略，成功率高达约99%。此外，还进行了消融研究以验证不同框架模块的有效性。 <div>
arXiv:2502.02984v1 Announce Type: new 
Abstract: Flocking control is essential for multi-robot systems in diverse applications, yet achieving efficient flocking in congested environments poses challenges regarding computation burdens, performance optimality, and motion safety. This paper addresses these challenges through a multi-agent reinforcement learning (MARL) framework built on Gibbs Random Fields (GRFs). With GRFs, a multi-robot system is represented by a set of random variables conforming to a joint probability distribution, thus offering a fresh perspective on flocking reward design. A decentralized training and execution mechanism, which enhances the scalability of MARL concerning robot quantity, is realized using a GRF-based credit assignment method. An action attention module is introduced to implicitly anticipate the motion intentions of neighboring robots, consequently mitigating potential non-stationarity issues in MARL. The proposed framework enables learning an efficient distributed control policy for multi-robot systems in challenging environments with success rate around $99\%$, as demonstrated through thorough comparisons with state-of-the-art solutions in simulations and experiments. Ablation studies are also performed to validate the efficiency of different framework modules.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-objective methods in Federated Learning: A survey and taxonomy</title>
<link>https://arxiv.org/abs/2502.03108</link>
<guid>https://arxiv.org/abs/2502.03108</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、多目标优化、集成方法、分类、研究方向

<br /><br />总结:
本文主要关注了Federated Learning范式下，如何通过多目标优化解决分布式机器学习中数据分散带来的复杂现实问题。随着该策略的普及，需要平衡公平性、效用和资源消耗等冲突需求的问题日益突出。文章指出现有工作开始认识到将多目标方法与联邦学习相结合的重要性，并首次在此领域提供了清晰而系统的整合方式概述。作者提出了一个多目标方法与联邦学习结合使用的初步分类体系，对当前的研究现状进行了有针对性的调查，并为相关贡献给出了明确的分类标签。鉴于这一领域的不断发展，该分类体系旨在为未来研究提供坚实基础，既能概括现有工作，又能预示未来的拓展方向。最后，文章指出了开放挑战及未来可能的研究方向。 <div>
arXiv:2502.03108v1 Announce Type: new 
Abstract: The Federated Learning paradigm facilitates effective distributed machine learning in settings where training data is decentralized across multiple clients. As the popularity of the strategy grows, increasingly complex real-world problems emerge, many of which require balancing conflicting demands such as fairness, utility, and resource consumption. Recent works have begun to recognise the use of a multi-objective perspective in answer to this challenge. However, this novel approach of combining federated methods with multi-objective optimisation has never been discussed in the broader context of both fields. In this work, we offer a first clear and systematic overview of the different ways the two fields can be integrated. We propose a first taxonomy on the use of multi-objective methods in connection with Federated Learning, providing a targeted survey of the state-of-the-art and proposing unambiguous labels to categorise contributions. Given the developing nature of this field, our taxonomy is designed to provide a solid basis for further research, capturing existing works while anticipating future additions. Finally, we outline open challenges and possible directions for further research.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Double Distillation Network for Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.03125</link>
<guid>https://arxiv.org/abs/2502.03125</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning, centralized training-decentralized execution (CTDE), partial observability, Double Distillation Network (DDN), exploration capabilities

<br /><br />总结:

本文针对多智能体强化学习中由于执行阶段的部分可观测性导致的累积误差问题，提出了一种名为Double Distillation Network (DDN)的新方法。DDN包含两个蒸馏模块，旨在增强鲁棒协作并促进信息约束条件下的协同过程。外部蒸馏模块利用全局指导网络和局部策略网络通过蒸馏技术缩小训练与执行之间的差距；内部蒸馏模块则引入基于状态信息的内在奖励，以提升智能体的探索能力。大量实验表明，DDN在多个场景下显著提高了性能。 <div>
arXiv:2502.03125v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning typically employs a centralized training-decentralized execution (CTDE) framework to alleviate the non-stationarity in environment. However, the partial observability during execution may lead to cumulative gap errors gathered by agents, impairing the training of effective collaborative policies. To overcome this challenge, we introduce the Double Distillation Network (DDN), which incorporates two distillation modules aimed at enhancing robust coordination and facilitating the collaboration process under constrained information. The external distillation module uses a global guiding network and a local policy network, employing distillation to reconcile the gap between global training and local execution. In addition, the internal distillation module introduces intrinsic rewards, drawn from state information, to enhance the exploration capabilities of agents. Extensive experiments demonstrate that DDN significantly improves performance across multiple scenarios.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Thetacrypt: A Distributed Service for Threshold Cryptography</title>
<link>https://arxiv.org/abs/2502.03247</link>
<guid>https://arxiv.org/abs/2502.03247</guid>
<content:encoded><![CDATA[
<div> 关键词: threshold cryptography, Thetacrypt, distributed systems, blockchain, cryptographic schemes

总结:
Thetacrypt是一个灵活、通用的库，旨在将多种阈值加密方案整合到单一代码库中，支持易于构建基于阈值密码学的分布式系统，并且与实现语言无关。该库以统一的方式支持各种不同协议，目前包含了覆盖密码算法、签名和随机数生成在内的六种加密方案。此外，Thetacrypt还具有一個可适配的底层网络层接口，提供点对点通信和总量序广播通道，后者可以由分布式账本等技术实现。Thetacrypt作为一个受控测试平台，可用于在一致条件下评估多个阈值密码方案的性能，表明传统的微观基准测试方法忽视了协议的分布式特性及其对于系统性能的相关性。 <div>
arXiv:2502.03247v1 Announce Type: new 
Abstract: Threshold cryptography is a powerful and well-known technique with many applications to systems relying on distributed trust. It has recently emerged also as a solution to challenges in blockchain: frontrunning prevention, managing wallet keys, and generating randomness. This work presents Thetacrypt, a versatile library for integrating many threshold schemes into one codebase. It offers a way to easily build distributed systems using threshold cryptography and is agnostic to their implementation language. The architecture of Thetacrypt supports diverse protocols uniformly. The library currently includes six cryptographic schemes that span ciphers, signatures, and randomness generation. The library additionally contains a flexible adapter to an underlying networking layer that provides peer-to-peer communication and a total-order broadcast channel; the latter can be implemented by distributed ledgers, for instance. Thetacrypt serves as a controlled testbed for evaluating the performance of multiple threshold-cryptographic schemes under consistent conditions, showing how the traditional micro benchmarking approach neglects the distributed nature of the protocols and its relevance when considering system performance.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interaction-Aware Gaussian Weighting for Clustered Federated Learning</title>
<link>https://arxiv.org/abs/2502.03340</link>
<guid>https://arxiv.org/abs/2502.03340</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 数据异质性, 类别不平衡, 集群化FL, FedGWC<br /><br />总结:<br />
本文提出了一种新型的联邦学习方法FedGWC，旨在解决数据异质性和类别不平衡导致的模型性能下降问题。FedGWC采用集群化的联邦学习策略，通过利用高斯奖励机制将客户端根据其数据分布进行聚类，从而实现更健壮和个性化的模型训练。同时，文中还引入了Wasserstein调整得分，这是一种用于评估FL中集群凝聚力与个体类别分布关系的新聚类指标。实验结果显示，FedGWC在聚类质量和分类准确性上均优于现有的联邦学习算法，验证了该方法的有效性。 <div>
arXiv:2502.03340v1 Announce Type: new 
Abstract: Federated Learning (FL) emerged as a decentralized paradigm to train models while preserving privacy. However, conventional FL struggles with data heterogeneity and class imbalance, which degrade model performance. Clustered FL balances personalization and decentralized training by grouping clients with analogous data distributions, enabling improved accuracy while adhering to privacy constraints. This approach effectively mitigates the adverse impact of heterogeneity in FL. In this work, we propose a novel clustered FL method, FedGWC (Federated Gaussian Weighting Clustering), which groups clients based on their data distribution, allowing training of a more robust and personalized model on the identified clusters. FedGWC identifies homogeneous clusters by transforming individual empirical losses to model client interactions with a Gaussian reward mechanism. Additionally, we introduce the Wasserstein Adjusted Score, a new clustering metric for FL to evaluate cluster cohesion with respect to the individual class distribution. Our experiments on benchmark datasets show that FedGWC outperforms existing FL algorithms in cluster quality and classification accuracy, validating the efficacy of our approach.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2502.03377</link>
<guid>https://arxiv.org/abs/2502.03377</guid>
<content:encoded><![CDATA[
<div> 关键词: NG-IoT, 电力消耗, 物联网设备, 飞行LoRa网关, 多智能体强化学习

总结:
随着下一代物联网(NG-IoT)网络的迅速发展，连接设备数量的增长导致电力消耗显著增加，对资源可用性和大规模物联网部署的可持续性提出了挑战。本文提出了一种利用搭载于无人机(UAV)上的飞行LoRa网关收集LoRa终端设备(EDs)数据并传输至中央服务器的方法，旨在通过联合优化无线LoRa网络的发射功率、扩频因子、带宽和ED关联来最大化全球系统能效(EE)。为解决这一难题，文章将问题建模为部分可观测马尔科夫决策过程(POMDP)，并采用集中训练与分散执行(Centralized Training and Decentralized Execution, CTDE)下的合作多智能体强化学习(MARL)方法。模拟结果显示，基于多智能体亲策略优化(MAPPO)算法的提出的方案能显著提高全球系统EE，并优于传统的MARL策略。<br /><br /> <div>
arXiv:2502.03377v1 Announce Type: new 
Abstract: With the rapid development of next-generation Internet of Things (NG-IoT) networks, the increasing number of connected devices has led to a surge in power consumption. This rise in energy demand poses significant challenges to resource availability and raises sustainability concerns for large-scale IoT deployments. Efficient energy utilization in communication networks, particularly for power-constrained IoT devices, has thus become a critical area of research. In this paper, we deployed flying LoRa gateways (GWs) mounted on unmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) and transmit it to a central server. Our primary objective is to maximize the global system energy efficiency (EE) of wireless LoRa networks by joint optimization of transmission power (TP), spreading factor (SF), bandwidth (W), and ED association. To solve this challenging problem, we model the problem as a partially observable Markov decision process (POMDP), where each flying LoRa GW acts as a learning agent using a cooperative Multi-Agent Reinforcement Learning (MARL) approach under centralized training and decentralized execution (CTDE). Simulation results demonstrate that our proposed method, based on the multi-agent proximal policy optimization (MAPPO) algorithm, significantly improves the global system EE and surpasses the conventional MARL schemes.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cryptocurrency Network Analysis</title>
<link>https://arxiv.org/abs/2502.03411</link>
<guid>https://arxiv.org/abs/2502.03411</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币网络分析、社交网络分析、交易数据、比特币、以太坊

<br /><br />总结:
本文主要介绍了加密货币网络分析这一领域，该领域应用社交网络分析的方法和技术来研究源自加密货币（如比特币）的交易数据，以及基于智能合约系统（如以太坊）中用户交换的价值、数字物品和服务。与大多数在线社交网络主要交换文本内容不同，这些系统中的用户主要是进行价值转移。 <div>
arXiv:2502.03411v1 Announce Type: new 
Abstract: Cryptocurrency network analysis consists of applying the tools and methods of social network analysis to transactional data issued from cryptocurrencies. The main difference with most online social networks is that users do not exchange textual content but instead value -- in systems designed mainly as cryptocurrency, such as Bitcoin -- or digital items and services in more permissive systems based on smart contracts such as Ethereum.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid Blockchain-IPFS Solution for Secure and Scalable Data Collection and Storage for Smart Water Meters</title>
<link>https://arxiv.org/abs/2502.03427</link>
<guid>https://arxiv.org/abs/2502.03427</guid>
<content:encoded><![CDATA[
<div> 关键词：物联网(IoT)，区块链，InterPlanetary File System (IPFS)，智能水表(SWM)，存储效率

总结:

该文研究了一种将区块链与InterPlanetary File System (IPFS)结合的混合方案，旨在优化物联网(IoT)应用如智能水表(SWM)数据的存储效率并确保安全性。通过将大量数据下链存储至IPFS以减轻区块链的压力，同时保持链上数据完整性。文章基于substrate构建了一个用于存储SWM数据的私有区块链，并进行了控制实验，评估了在不同数据量和节点数情况下，区块链单独使用和结合IPFS两种情况下的性能。实验结果显示，采用IPFS集成方案能显著减少区块链上的存储需求，从而减小块大小、提高交易吞吐量和改善块生成时间。这些发现强调了混合区块链-IPFS模型对于高容量IoT数据高效且安全管理的潜力。 <div>
arXiv:2502.03427v1 Announce Type: new 
Abstract: Scalable and secure data management is important in Internet of Things (IoT) applications such as smart water meters, where traditional blockchain storage can be restrictive due to high data volumes. This paper investigates a hybrid blockchain and InterPlanetary File System (IPFS) approach designed to optimise storage efficiency, enhance throughput, and reduce block time by offloading large data off-chain to IPFS while preserving on-chain integrity. A substrate-based private blockchain was developed to store smart water meter (SWM) data, and controlled experiments were conducted to evaluate blockchain performance with and without IPFS. Key metrics, including block size, block time, and transaction throughput, were analysed across varying data volumes and node counts. Results show that integrating IPFS significantly reduces on-chain storage demands, leading to smaller block sizes, increased throughput, and improved block times compared to blockchain-only storage. These findings highlight the potential of hybrid blockchain-IPFS models for efficiently and securely managing high-volume IoT data.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Analyzing Political Discourse on Discord during the 2024 U.S. Presidential Election</title>
<link>https://arxiv.org/abs/2502.03433</link>
<guid>https://arxiv.org/abs/2502.03433</guid>
<content:encoded><![CDATA[
<div> 关键词：社交媒体、Discord、政治运动、2024年美国大选、语义分析

总结:
该研究关注了在主流社交媒体平台之外的Discord上关于2024年美国总统选举的政治讨论。通过对超过3000万条来自政治服务器的消息进行分析，研究人员将这些服务器划分为共和党倾向、民主党倾向和中立三类。研究发现，在关键竞选事件期间，共和党服务器更侧重于经济政策讨论，而民主党服务器则更多涉及平等和进步议题。此外，在卡玛拉·哈里斯被提名为副总统候选人后，共和党倾向的服务器中的性别歧视等有毒语言有所增加。这项研究揭示了 Discord 在塑造和理解在线政治参与方面日益增长的作用，为分析这一新兴平台上的政治行为提供了初步见解。 <div>
arXiv:2502.03433v1 Announce Type: new 
Abstract: Social media networks have amplified the reach of social and political movements, but most research focuses on mainstream platforms such as X, Reddit, and Facebook, overlooking Discord. As a rapidly growing, community-driven platform with optional decentralized moderation, Discord offers unique opportunities to study political discourse. This study analyzes over 30 million messages from political servers on Discord discussing the 2024 U.S. elections. Servers were classified as Republican-aligned, Democratic-aligned, or unaligned based on their descriptions. We tracked changes in political conversation during key campaign events and identified distinct political valence and implicit biases in semantic association through embedding analysis. We observed that Republican servers emphasized economic policies, while Democratic servers focused on equality-related and progressive causes. Furthermore, we detected an increase in toxic language, such as sexism, in Republican-aligned servers after Kamala Harris's nomination. These findings provide a first look at political behavior on Discord, highlighting its growing role in shaping and understanding online political engagement.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Model-based Analysis of Mining Fairness in a Blockchain</title>
<link>https://arxiv.org/abs/2406.00595</link>
<guid>https://arxiv.org/abs/2406.00595</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、公平性、挖矿、交易处理能力、数学模型

总结:
本文针对区块链中的挖掘公平性问题进行研究，该问题是交易处理能力和挖矿公平性之间存在矛盾，可能导致去中心化的削弱。尽管该问题在采用如GHOST协议等方法后仍未能解决，但目前对挖掘公平性的定量分析研究尚不充分。为此，文章提出一种计算挖掘公平性的方法，首先通过建立假设每轮最多生成两个区块的简单数学模型来近似复杂的区块链网络，并在此基础上定量化地定义了局部挖矿公平性以及推导出一系列全球挖矿公平性的衡量指标。接着，通过区块链网络模拟验证了该计算方法相比现有方法能更准确地计算出网络中的挖掘公平性。最后，作者从挖矿公平性的角度对多种网络进行了深入分析。 <div>
arXiv:2406.00595v2 Announce Type: replace 
Abstract: Mining fairness in blockchain refers to equality between the computational resources invested in mining and the block rewards received. There exists a dilemma wherein increasing the transaction processing capacity of a blockchain compromises mining fairness, which consequently undermines its decentralization. This dilemma remains unresolved even with methods such as the greedy heaviest observed subtree (GHOST) protocol, indicating that mining fairness is an inherent bottleneck in the transaction processing capacity of the blockchain system. However, despite its significance, there have been insufficient research studies that have quantitatively analyzed mining fairness. In this paper, we propose a method for calculating mining fairness. First, we approximated a complex blockchain network using a simple mathematical model, assuming that no more than two blocks are generated per round. Within this model, we quantitatively determined local mining fairness and derived several measures of global mining fairness based on local mining fairness. Subsequently, we validated by blockchain network simulations that our calculation method computes mining fairness in networks much more accurately than existing methods. Finally, we analyzed various networks from the perspective of mining fairness.
]]></content:encoded>
<pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Expected Return Symmetries</title>
<link>https://arxiv.org/abs/2502.01711</link>
<guid>https://arxiv.org/abs/2502.01711</guid>
<content:encoded><![CDATA[
<div> 关键词：对称性、深度学习、多智能体、部分可观测马尔科夫决策过程、预期回报对称性

<br /><br />总结:
本文提出了一个新的研究方向，关注于在深度学习特别是多智能体环境中对称性的利用与发现。文章指出现有方法主要处理已知环境对称性以解决协调失败问题，但自动发现环境对称性，特别是在部分可观测马尔科夫决策过程中，仍是一个开放问题。为此，文中引入了一种更广泛的新对称性概念——预期回报对称性，它将环境对称性作为其子群。通过训练兼容预期回报对称性的智能体，作者展示了这些智能体能实现比仅使用环境对称性更好的零样本协调效果。此外，该方法对环境结构几乎没有预先假设，也不需要访问真实的对称信息。 <div>
arXiv:2502.01711v1 Announce Type: new 
Abstract: Symmetry is an important inductive bias that can improve model robustness and generalization across many deep learning domains. In multi-agent settings, a priori known symmetries have been shown to address a fundamental coordination failure mode known as mutually incompatible symmetry breaking; e.g. in a game where two independent agents can choose to move "left'' or "right'', and where a reward of +1 or -1 is received when the agents choose the same action or different actions, respectively. However, the efficient and automatic discovery of environment symmetries, in particular for decentralized partially observable Markov decision processes, remains an open problem. Furthermore, environmental symmetry breaking constitutes only one type of coordination failure, which motivates the search for a more accessible and broader symmetry class. In this paper, we introduce such a broader group of previously unexplored symmetries, which we call expected return symmetries, which contains environment symmetries as a subgroup. We show that agents trained to be compatible under the group of expected return symmetries achieve better zero-shot coordination results than those using environment symmetries. As an additional benefit, our method makes minimal a priori assumptions about the structure of their environment and does not require access to ground truth symmetries.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeViNE: A Decentralized Virtual Network Embedding Algorithm</title>
<link>https://arxiv.org/abs/2502.01807</link>
<guid>https://arxiv.org/abs/2502.01807</guid>
<content:encoded><![CDATA[
<div> 关键词：Virtual Network Embedding (VNE), 分布式算法, 可扩展性, 故障容错, DoS攻击

总结:
本文针对虚拟网络嵌入(VNE)技术提出了一种分布式算法实现方案。该方案旨在解决传统集中式算法存在的可扩展性和单一故障点问题以及对DoS攻击的防御能力不足。方法是选取L个物理节点作为领导者，并使用简单的BFS等算法在其局部网络中嵌入虚拟网络请求(VNR)。随后通过领导者选举机制确定成本最低、收入最高的节点，并将嵌入结果传播给其他领导者。利用这种分布式策略，提高了解决方案的可扩展性和鲁棒性。实验结果显示，相较于现有方法，该完全分布式的算法在接受率上提升了$12\%$，并将收益与成本比改善了大约$21\%$。 <div>
arXiv:2502.01807v1 Announce Type: new 
Abstract: Virtual Network Embedding (VNE) is a technique for mapping virtual networks onto a physical network infrastructure, enabling multiple virtual networks to coexist on a shared physical network. Previous works focused on implementing centralized VNE algorithms, which suffer from lack of scalability and robustness. This project aims to implement a decentralized virtual network embedding algorithm that addresses the challenges of network virtualization, such as scalability, single point of failure, and DoS attacks. The proposed approach involves selecting L leaders from the physical nodes and embedding a virtual network request (VNR) in the local network of each leader using a simple algorithm like BFS. The algorithm then uses a leader-election mechanism for determining the node with the lowest cost and highest revenue and propagates the embedding to other leaders. By utilizing decentralization, we improve the scalability and robustness of the solution. Additionally, we evaluate the effectiveness of our fully decentralized algorithm by comparing it with existing approaches. Our algorithm performs $12\%$ better in terms of acceptance rate and improves the revenue-to-cost ratio by roughly $21\%$ to compared approaches.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal Routing in the Presence of Hooks: Three Case Studies</title>
<link>https://arxiv.org/abs/2502.02059</link>
<guid>https://arxiv.org/abs/2502.02059</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv, CFMMs, hooks, 优化路由, 交易执行

总结:
本文研究了在网络中具有挂钩(hooks)的常数函数市场制造商(CFMMs)环境下，用户交易执行的优化问题。挂钩是Uniswap即将推出的新版本中引入的概念，允许流动性提供者为资金池添加额外信息并设置交易约束，使CFMM能够读取外部数据（如波动率信息）以及实现附加功能，例如链上限价订单。文章重点探讨了三种在挂钩存在下进行交易最优路由的方法：1) 通过限价订单路由；2) 最优清算和时间加权平均市场制造商(TWAMMs)；3) 非组合性挂钩，它能在承担填充风险的同时提供额外产出。利用凸优化和动态规划工具，文中提出了简单的方法来制定和解决这些问题，这些方法对实践者来说具有实用价值。 <div>
arXiv:2502.02059v1 Announce Type: new 
Abstract: We consider the problem of optimally executing a user trade over networks of constant function market makers (CFMMs) in the presence of hooks. Hooks, introduced in an upcoming version of Uniswap, are auxiliary smart contracts that allow for extra information to be added to liquidity pools. This allows liquidity providers to enable constraints on trades, allowing CFMMs to read external data, such as volatility information, and implement additional features, such as onchain limit orders. We consider three important case studies for how to optimally route trades in the presence of hooks: 1) routing through limit orders, 2) optimal liquidations and time-weighted average market makers (TWAMMs), and 3) noncomposable hooks, which provide additional output in exchange for fill risk. Leveraging tools from convex optimization and dynamic programming, we propose simple methods for formulating and solving these problems that can be useful for practitioners.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAGNNET: Multi-Agent Graph Neural Network-based Efficient Task Allocation for Autonomous Vehicles with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.02311</link>
<guid>https://arxiv.org/abs/2502.02311</guid>
<content:encoded><![CDATA[
<div> 关键词: 异构多智能体系统、通信约束、图神经网络、集中式训练分散式执行、深度强化学习<br /><br />总结:

本文针对异构多智能体系统中存在通信约束的分布式任务分配挑战，提出了一种新的融合图神经网络（GNN）与集中式训练分散式执行（CTDE）范式的框架，并结合定制化的Proximal Policy Optimization（PPO）算法进行多智能体深度强化学习（MARL）。该方法允许无人机(UAVs)和无人地面车辆(UGVs)在无需中央协调的情况下动态高效地分配任务。框架旨在最小化总旅行时间并同时避免任务分配冲突，采用基于预约的A*和R*路径规划器进行成本计算和路由规划。实验结果显示，所提方法实现了高达92.5%的无冲突成功率，与中心化的匈牙利方法相比，性能差距仅为7.49%，并且优于基于贪婪策略的启发式分散基线。此外，该框架表现出良好的可扩展性，支持多达20个智能体的任务分配处理时间仅需2.8秒，并具有应对动态生成任务的鲁棒性，显示出其在复杂多智能体场景中实际应用的巨大潜力。 <div>
arXiv:2502.02311v1 Announce Type: new 
Abstract: This paper addresses the challenge of decentralized task allocation within heterogeneous multi-agent systems operating under communication constraints. We introduce a novel framework that integrates graph neural networks (GNNs) with a centralized training and decentralized execution (CTDE) paradigm, further enhanced by a tailored Proximal Policy Optimization (PPO) algorithm for multi-agent deep reinforcement learning (MARL). Our approach enables unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to dynamically allocate tasks efficiently without necessitating central coordination in a 3D grid environment. The framework minimizes total travel time while simultaneously avoiding conflicts in task assignments. For the cost calculation and routing, we employ reservation-based A* and R* path planners. Experimental results revealed that our method achieves a high 92.5% conflict-free success rate, with only a 7.49% performance gap compared to the centralized Hungarian method, while outperforming the heuristic decentralized baseline based on greedy approach. Additionally, the framework exhibits scalability with up to 20 agents with allocation processing of 2.8 s and robustness in responding to dynamically generated tasks, underscoring its potential for real-world applications in complex multi-agent scenarios.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy by Design for Self-Sovereign Identity Systems: An in-depth Component Analysis completed by a Design Assistance Dashboard</title>
<link>https://arxiv.org/abs/2502.02520</link>
<guid>https://arxiv.org/abs/2502.02520</guid>
<content:encoded><![CDATA[
<div> 关键词: Self-Sovereign Identity (SSI)、隐私保护、设计选择、建筑层次、决策辅助仪表板

<br /><br />总结:
本文关注于Self-Sovereign Identity (SSI)系统在数字身份管理中的应用及其对个人隐私的影响。文章旨在帮助SSI解决方案设计师做出有利于隐私保护的设计选择。作者将SSI系统的构建模块划分为5个结构层，并针对每一层分析了选用不同构建块对隐私的影响。此外，文章提出了一种设计辅助仪表板，该仪表板可以全面展示SSI系统的整体情况，并清晰地显示架构选择与技术构建块之间的相互依赖关系，从而使得设计师能够做出满足隐私需求的明智决策。 <div>
arXiv:2502.02520v1 Announce Type: new 
Abstract: The use of Self-Sovereign Identity (SSI) systems for digital identity management is gaining traction and interest. Countries such as Bhutan have already implemented an SSI infrastructure to manage the identity of their citizens. The EU, thanks to the revised eIDAS regulation, is opening the door for SSI vendors to develop SSI systems for the planned EU digital identity wallet. These developments, which fall within the sovereign domain, raise questions about individual privacy.
  The purpose of this article is to help SSI solution designers make informed choices to ensure that the designed solution is privacy-friendly. The observation is that the range of possible solutions is very broad, from DID and DID resolution methods to verifiable credential types, publicly available information (e.g. in a blockchain), type of infrastructure, etc. As a result, the article proposes (1) to group the elementary building blocks of a SSI system into 5 structuring layers, (2) to analyze for each layer the privacy implications of using the chosen building block, and (3) to provide a design assistance dashboard that gives the complete picture of the SSI, and shows the interdependencies between architectural choices and technical building blocks, allowing designers to make informed choices and graphically achieve a SSI solution that meets their need for privacy.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Client Selection in Federated Learning</title>
<link>https://arxiv.org/abs/2502.00036</link>
<guid>https://arxiv.org/abs/2502.00036</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 差分隐私, 故障容忍, 客户选择框架, 性能提升

<br /><br />总结:
本文提出了一种新颖的客户端选择框架，该框架结合了差分隐私和故障容忍性，应用于联邦学习中以保护数据隐私的同时实现分布式机器学习。这个自适应客户端选择策略根据性能和系统约束动态调整参与训练的客户端数量，并通过添加噪声来保护隐私。实验在UNSW-NB15和ROAD数据集上的网络异常检测任务中表明，相较于基线方法，该方法能够提高准确性达7%，并减少训练时间约25%。同时，其增强的鲁棒性也带来了较小的性能牺牲。 <div>
arXiv:2502.00036v1 Announce Type: new 
Abstract: Federated Learning (FL) enables decentralized machine learning while preserving data privacy. This paper proposes a novel client selection framework that integrates differential privacy and fault tolerance. The adaptive client selection adjusts the number of clients based on performance and system constraints, with noise added to protect privacy. Evaluated on the UNSW-NB15 and ROAD datasets for network anomaly detection, the method improves accuracy by 7% and reduces training time by 25% compared to baselines. Fault tolerance enhances robustness with minimal performance trade-offs.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>JustAct+: Justified and Accountable Actions in Policy-Regulated, Multi-Domain Data Processing</title>
<link>https://arxiv.org/abs/2502.00138</link>
<guid>https://arxiv.org/abs/2502.00138</guid>
<content:encoded><![CDATA[
<div> 关键词：Inter-organisational数据交换、规范、GDPR、智能合约、JustAct框架

总结:
本文介绍了JustAct框架，该框架针对跨组织数据交换中由法律、协议和个体同意等多源规范所约束的问题。文章指出，现有的如智能合约、访问控制和使用控制等解决方案假设政策为公开或静态划分，这可能牺牲了问责制和灵活性。而JustAct框架则提倡去中心化的代理机构自主创建、传播并组装政策片段来证明其行为合理性，并确保即使在查看全部动态策略的不完全情况下，任何观察者也能复现权限许可过程。此外，通过外部同步的协议重新配置来集中控制，从而使得控制集中程度仅限于各代理机构期望的程度。文中详细描述了JustAct框架在一个特定的数据处理系统中的实现，并基于逻辑编程设计了一种适合的政策语言。通过对现有政策管理的跨领域医疗数据处理系统Brane的案例研究，展示了该框架的特点与优势。 <div>
arXiv:2502.00138v1 Announce Type: new 
Abstract: Inter-organisational data exchange is regulated by norms originating from sources ranging from (inter)national laws, to processing agreements, and individual consent. Verifying norm compliance is complex because laws (e.g., GDPR) distribute responsibility and require accountability. Moreover, in some application domains (e.g., healthcare), privacy requirements extend the norms (e.g., patient consent). In contrast, existing solutions such as smart contracts, access- and usage-control assume policies to be public, or otherwise, statically partition policy information at the cost of accountability and flexibility. Instead, our framework prescribes how decentralised agents justify their actions with policy fragments that the agents autonomously create, gossip, and assemble. Crucially, the permission of actions is always reproducible by any observer, even with a partial view of all the dynamic policies. Actors can be sure that future auditors will confirm their permissions. Systems centralise control by (re)configuring externally synchronised agreements, the bases of all justifications. As a result, control is centralised only to the extent desired by the agents.
  In this paper, we define the JustAct framework, detail its implementation in a particular data-processing system, and design a suitable policy language based on logic programming. A case study reproduces Brane - an existing policy-regulated, inter-domain, medical data processing system - and serves to demonstrate and assess the qualities of the framework.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study</title>
<link>https://arxiv.org/abs/2502.00182</link>
<guid>https://arxiv.org/abs/2502.00182</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 隐私保护, 联邦学习, 数据分布不均, 损失景观

总结:<br />
本文探讨了随着隐私保护意识和数据法规增强而兴起的联邦学习（FL）方法，该方法可在不共享原始数据的情况下训练分散的数据源上的机器学习模型。然而，非独立同分布（non-IID）的数据导致了FL性能下降的问题。通过对从梯度下降到FL以及从IID到non-IID数据设置的全面调查，研究发现客户端损失景观的不一致性是性能退化的主要原因。据此，现有的解决方法可以被归类为两大策略：(i) 调整参数更新路径；(ii) 修改客户端损失景观。这些发现为理解和应对FL中的非IID挑战提供了清晰视角，并可指导该领域的未来研究。 <div>
arXiv:2502.00182v1 Announce Type: new 
Abstract: As privacy concerns and data regulations grow, federated learning (FL) has emerged as a promising approach for training machine learning models across decentralized data sources without sharing raw data. However, a significant challenge in FL is that client data are often non-IID (non-independent and identically distributed), leading to reduced performance compared to centralized learning. While many methods have been proposed to address this issue, their underlying mechanisms are often viewed from different perspectives. Through a comprehensive investigation from gradient descent to FL, and from IID to non-IID data settings, we find that inconsistencies in client loss landscapes primarily cause performance degradation in non-IID scenarios. From this understanding, we observe that existing methods can be grouped into two main strategies: (i) adjusting parameter update paths and (ii) modifying client loss landscapes. These findings offer a clear perspective on addressing non-IID challenges in FL and help guide future research in the field.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Year-over-Year Developments in Financial Fraud Detection via Deep Learning: A Systematic Literature Review</title>
<link>https://arxiv.org/abs/2502.00201</link>
<guid>https://arxiv.org/abs/2502.00201</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度学习、金融欺诈检测、卷积神经网络、长期短期记忆、区块链集成

<br /><br />总结:
本文系统回顾了深度学习（DL）技术在金融欺诈检测领域的进展，这是一个金融领域的重要问题。通过对2019年至2024年间发表的57篇相关研究文献采用Kitchenham系统性文献回顾方法进行分析，研究表明卷积神经网络、长短期记忆网络和变压器等深度学习模型在信用卡交易、保险理赔及财务报表审计等领域具有较高的有效性。文章评估了精确率、召回率、F1分数和AUC-ROC等性能指标，并探讨了数据隐私框架的影响以及特征工程和数据预处理方面的进步。同时，文中指出了面临的挑战，如数据集不平衡、模型可解释性及伦理考量，并提出了自动化和隐私保护技术的应用机会，例如区块链集成和主成分分析。通过过去五年的发展趋势分析，该文识别出了DL应用在金融欺诈检测中的关键空白点及有前景的研究方向，为研究人员和实践者提供了可操作的见解。 <div>
arXiv:2502.00201v1 Announce Type: new 
Abstract: This paper systematically reviews advancements in deep learning (DL) techniques for financial fraud detection, a critical issue in the financial sector. Using the Kitchenham systematic literature review approach, 57 studies published between 2019 and 2024 were analyzed. The review highlights the effectiveness of various deep learning models such as Convolutional Neural Networks, Long Short-Term Memory, and transformers across domains such as credit card transactions, insurance claims, and financial statement audits. Performance metrics such as precision, recall, F1-score, and AUC-ROC were evaluated. Key themes explored include the impact of data privacy frameworks and advancements in feature engineering and data preprocessing. The study emphasizes challenges such as imbalanced datasets, model interpretability, and ethical considerations, alongside opportunities for automation and privacy-preserving techniques such as blockchain integration and Principal Component Analysis. By examining trends over the past five years, this review identifies critical gaps and promising directions for advancing DL applications in financial fraud detection, offering actionable insights for researchers and practitioners.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024)</title>
<link>https://arxiv.org/abs/2502.00627</link>
<guid>https://arxiv.org/abs/2502.00627</guid>
<content:encoded><![CDATA[
<div> 关键词: Discord, 数据集, 通信平台, 社区治理, 信息传播

总结:
本文介绍了针对Discord平台的一项重要研究成果——“ Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024)”数据集。该数据集包含了自2015年Discord成立以来至2024年底期间，来自3,167个公共服务器上的超过205亿条消息，涉及474万名用户，约占Discord公开服务器列表的10%。数据集提供了丰富的时空和主题框架，可用于分析分散式管理、社区治理、信息传播和社会动态等议题。数据收集遵循道德准则和隐私标准，采用匿名技术处理。数据以结构化的JSON文件形式组织，便于与计算社会科学方法论无缝对接。初步分析揭示了用户参与度、机器人利用以及语言多样性等方面的重要趋势，其中英语占主导地位，同时西班牙语、法语和葡萄牙语也有显著存在。此外，社交、艺术、音乐和梗图等领域成为社区的主要主题，凸显了Discord已从以游戏为中心的通讯工具扩展到多元化在线社区的现状。 <div>
arXiv:2502.00627v1 Announce Type: new 
Abstract: Discord has evolved from a gaming-focused communication tool into a versatile platform supporting diverse online communities. Despite its large user base and active public servers, academic research on Discord remains limited due to data accessibility challenges. This paper introduces Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024), the most extensive Discord public server's data to date. The dataset comprises over 2.05 billion messages from 4.74 million users across 3,167 public servers, representing approximately 10% of servers listed in Discord's Discovery feature. Spanning from Discord's launch in 2015 to the end of 2024, it offers a robust temporal and thematic framework for analyzing decentralized moderation, community governance, information dissemination, and social dynamics. Data was collected through Discord's public API, adhering to ethical guidelines and privacy standards via anonymization techniques. Organized into structured JSON files, the dataset facilitates seamless integration with computational social science methodologies. Preliminary analyses reveal significant trends in user engagement, bot utilization, and linguistic diversity, with English predominating alongside substantial representations of Spanish, French, and Portuguese. Additionally, prevalent community themes such as social, art, music, and memes highlight Discord's expansion beyond its gaming origins.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Encrypted Large Model Inference: The Equivariant Encryption Paradigm</title>
<link>https://arxiv.org/abs/2502.01013</link>
<guid>https://arxiv.org/abs/2502.01013</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模深度学习模型、隐私保护、等变加密（Equivariant Encryption, EE）、安全盲推断、性能 overhead

<br /><br />总结:
本文提出了一个新的隐私保护技术——等变加密（Equivariant Encryption, EE），针对大规模深度学习模型在分布式或去中心化环境中的部署所引发的数据隐私问题。相较于传统的安全多方计算、同态加密和差分隐私方法，EE能在几乎无性能开销的情况下实现对加密数据的安全“盲”推理。EE通过选择性地模糊神经网络层内的关键内部表示，同时保持线性和预设非线性操作的精确功能，确保原始输入、中间激活值以及输出均保留在保密状态。文章阐述了EE的理论基础，比较了其与传统隐私保护技术在性能和集成复杂度方面的表现，并展示了在包括卷积网络和大型语言模型等多种架构上的应用可行性。此外，文章还进行了全面的威胁分析和基准测试，证实EE能够在保持高精度和吞吐量的同时，有效地弥合了强数据机密性和现代大规模模型推理严格效率要求之间的鸿沟。 <div>
arXiv:2502.01013v1 Announce Type: new 
Abstract: Large scale deep learning model, such as modern language models and diffusion architectures, have revolutionized applications ranging from natural language processing to computer vision. However, their deployment in distributed or decentralized environments raises significant privacy concerns, as sensitive data may be exposed during inference. Traditional techniques like secure multi-party computation, homomorphic encryption, and differential privacy offer partial remedies but often incur substantial computational overhead, latency penalties, or limited compatibility with non-linear network operations. In this work, we introduce Equivariant Encryption (EE), a novel paradigm designed to enable secure, "blind" inference on encrypted data with near zero performance overhead. Unlike fully homomorphic approaches that encrypt the entire computational graph, EE selectively obfuscates critical internal representations within neural network layers while preserving the exact functionality of both linear and a prescribed set of non-linear operations. This targeted encryption ensures that raw inputs, intermediate activations, and outputs remain confidential, even when processed on untrusted infrastructure. We detail the theoretical foundations of EE, compare its performance and integration complexity against conventional privacy preserving techniques, and demonstrate its applicability across a range of architectures, from convolutional networks to large language models. Furthermore, our work provides a comprehensive threat analysis, outlining potential attack vectors and baseline strategies, and benchmarks EE against standard inference pipelines in decentralized settings. The results confirm that EE maintains high fidelity and throughput, effectively bridging the gap between robust data confidentiality and the stringent efficiency requirements of modern, large scale model inference.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tackling Feature and Sample Heterogeneity in Decentralized Multi-Task Learning: A Sheaf-Theoretic Approach</title>
<link>https://arxiv.org/abs/2502.01145</link>
<guid>https://arxiv.org/abs/2502.01145</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated multi-task learning (FMTL), decentralized setting, cellular sheaves, Sheaf-FMTL算法, communication savings

总结:<br />
本文提出了一种基于sheaf理论的新型联邦多任务学习（FMTL）方法，旨在解决在分布式环境中复杂任务关系建模和处理客户端特征及样本异质性的问题。通过使用细胞sheaf表示客户端间的关系，该框架能够灵活地模拟不同客户端模型间的交互。文章将基于sheaf的FMTL优化问题形式化为sheaf拉普拉斯正则化，并提出了求解该问题的Sheaf-FMTL算法。进一步地，证明Sheaf-FMTL算法具有与最先进的分布式FMTL算法相媲美的亚线性收敛率。实验表明，Sheaf-FMTL相较于分布式FMTL基线方法能实现显著的通信开销节省，发送更少的比特数。 <div>
arXiv:2502.01145v1 Announce Type: new 
Abstract: Federated multi-task learning (FMTL) aims to simultaneously learn multiple related tasks across clients without sharing sensitive raw data. However, in the decentralized setting, existing FMTL frameworks are limited in their ability to capture complex task relationships and handle feature and sample heterogeneity across clients. To address these challenges, we introduce a novel sheaf-theoretic-based approach for FMTL. By representing client relationships using cellular sheaves, our framework can flexibly model interactions between heterogeneous client models. We formulate the sheaf-based FMTL optimization problem using sheaf Laplacian regularization and propose the Sheaf-FMTL algorithm to solve it. We show that the proposed framework provides a unified view encompassing many existing federated learning (FL) and FMTL approaches. Furthermore, we prove that our proposed algorithm, Sheaf-FMTL, achieves a sublinear convergence rate in line with state-of-the-art decentralized FMTL algorithms. Extensive experiments demonstrate that Sheaf-FMTL exhibits communication savings by sending significantly fewer bits compared to decentralized FMTL baselines.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Neural Cellular Automata for Decentralized Sensing using a Soft Inductive Sensor Array for Distributed Manipulator Systems</title>
<link>https://arxiv.org/abs/2502.01242</link>
<guid>https://arxiv.org/abs/2502.01242</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Manipulator Systems (分布式操纵系统)、Decentralized Sensing (去中心化传感)、Neural Cellular Automata (神经细胞自动机)、Inductive Sensor Board (感应传感器板)、Fault-Tolerance (容错性)

<br />
总结:
本文介绍了针对分布式操纵系统的新型去中心化传感方法，该方法使用神经细胞自动机(NCA)。与当前通常依赖中央化的单摄像头计算机视觉系统的DMS不同，提出的感应传感器板设计用于分布式传感并评估其通过局部交互和计算估计全局对象属性（如几何中心）的能力。实验表明，基于NCA的传感网络能以0.24倍的传感器间距离准确估计物体位置，并在传感器故障和噪声情况下保持鲁棒性，同时能无缝扩展到不同的网络规模。这些发现强调了本地化、去中心化计算在实现DMS中可伸缩、容错和抗噪的对象属性估计方面的潜力。 <div>
arXiv:2502.01242v1 Announce Type: new 
Abstract: In Distributed Manipulator Systems (DMS), decentralization is a highly desirable property as it promotes robustness and facilitates scalability by distributing computational burden and eliminating singular points of failure. However, current DMS typically utilize a centralized approach to sensing, such as single-camera computer vision systems. This centralization poses a risk to system reliability and offers a significant limiting factor to system size. In this work, we introduce a decentralized approach for sensing and in a Distributed Manipulator Systems using Neural Cellular Automata (NCA). Demonstrating a decentralized sensing in a hardware implementation, we present a novel inductive sensor board designed for distributed sensing and evaluate its ability to estimate global object properties, such as the geometric center, through local interactions and computations. Experiments demonstrate that NCA-based sensing networks accurately estimate object position at 0.24 times the inter sensor distance. They maintain resilience under sensor faults and noise, and scale seamlessly across varying network sizes. These findings underscore the potential of local, decentralized computations to enable scalable, fault-tolerant, and noise-resilient object property estimation in DMS
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Discriminative Naive Bayes Classifier</title>
<link>https://arxiv.org/abs/2502.01532</link>
<guid>https://arxiv.org/abs/2502.01532</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Naive Bayes、分类、数据隐私、实验验证

<br />
总结:
本文提出了一种针对离散变量的新型联邦学习方法，用于朴素贝叶斯(Naive Bayes, NB)分类。该方法将一种判别式的NB变体进行联邦化处理，只共享无意义的参数而非条件概率表，从而增强了对可能攻击的防御能力。通过在12个数据集上进行大量实验，与非联邦设置和生成式NB基线进行了比较，实验结果证实了所提方法在实现高精度分类方面的有效性。这一研究为保护数据隐私的同时进行分布式机器学习模型训练提供了新的解决方案。 <div>
arXiv:2502.01532v1 Announce Type: new 
Abstract: Federated Learning has emerged as a promising approach to train machine learning models on decentralized data sources while preserving data privacy. This paper proposes a new federated approach for Naive Bayes (NB) classification, assuming discrete variables. Our approach federates a discriminative variant of NB, sharing meaningless parameters instead of conditional probability tables. Therefore, this process is more reliable against possible attacks. We conduct extensive experiments on 12 datasets to validate the efficacy of our approach, comparing federated and non-federated settings. Additionally, we benchmark our method against the generative variant of NB, which serves as a baseline for comparison. Our experimental results demonstrate the effectiveness of our method in achieving accurate classification.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedGES: A Federated Learning Approach for BN Structure Learning</title>
<link>https://arxiv.org/abs/2502.01538</link>
<guid>https://arxiv.org/abs/2502.01538</guid>
<content:encoded><![CDATA[
<div> 关键词：贝叶斯网络、联邦学习、贪婪等价搜索、结构融合、隐私保护

总结:
本文提出了一种名为FedGES的新颖联邦学习方法，用于在分布式环境中进行贝叶斯网络（BN）结构学习。FedGES针对传统BN结构学习中的数据集中问题，创新性地仅交换不断演进的网络结构而非参数或数据，从而有效解决了隐私和安全挑战。该方法实现了协作模型开发，通过结构性融合将各客户端在迭代过程中生成的有限模型结合在一起。此外，为了增强客户端的一致性，文中还提出了控制性的结构融合策略。实验结果表明，FedGES在高维度（大量变量）和稀疏数据场景中表现优异，为现实世界的BN结构学习提供了一个实用且能保护隐私的解决方案。<br /><br /> <div>
arXiv:2502.01538v1 Announce Type: new 
Abstract: Bayesian Network (BN) structure learning traditionally centralizes data, raising privacy concerns when data is distributed across multiple entities. This research introduces Federated GES (FedGES), a novel Federated Learning approach tailored for BN structure learning in decentralized settings using the Greedy Equivalence Search (GES) algorithm. FedGES uniquely addresses privacy and security challenges by exchanging only evolving network structures, not parameters or data. It realizes collaborative model development, using structural fusion to combine the limited models generated by each client in successive iterations. A controlled structural fusion is also proposed to enhance client consensus when adding any edge. Experimental results on various BNs from {\sf bnlearn}'s BN Repository validate the effectiveness of FedGES, particularly in high-dimensional (a large number of variables) and sparse data scenarios, offering a practical and privacy-preserving solution for real-world BN structure learning.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Inference for Distributed Geospatial Data Using Low-Rank Models</title>
<link>https://arxiv.org/abs/2502.00309</link>
<guid>https://arxiv.org/abs/2502.00309</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模空间数据、去中心化框架、参数推断、低秩模型、证据下界

<br /><br />总结:
本文提出了一种针对大规模空间数据的去中心化参数推断框架，旨在解决集中式框架中的单点故障和通信瓶颈问题。该框架特别适用于空间低秩模型，针对观测值间的空间相关性带来的挑战，文章创新地提出了利用证据下界的新型目标函数，使之适应于分布式优化方法。文中采用块下降法结合多共识与动态一致性平均策略进行有效参数优化，并证明了新目标函数在真实参数附近的凸性，确保了所提方法的收敛性。此外，文章还首次从理论上确立了在空间低秩模型背景下估计器的一致性和渐近正态性。通过大量的模拟实验和真实数据实验证明了该框架的稳健性和可扩展性。 <div>
arXiv:2502.00309v1 Announce Type: cross 
Abstract: Advancements in information technology have enabled the creation of massive spatial datasets, driving the need for scalable and efficient computational methodologies. While offering viable solutions, centralized frameworks are limited by vulnerabilities such as single-point failures and communication bottlenecks. This paper presents a decentralized framework tailored for parameter inference in spatial low-rank models to address these challenges. A key obstacle arises from the spatial dependence among observations, which prevents the log-likelihood from being expressed as a summation-a critical requirement for decentralized optimization approaches. To overcome this challenge, we propose a novel objective function leveraging the evidence lower bound, which facilitates the use of decentralized optimization techniques. Our approach employs a block descent method integrated with multi-consensus and dynamic consensus averaging for effective parameter optimization. We prove the convexity of the new objective function in the vicinity of the true parameters, ensuring the convergence of the proposed method. Additionally, we present the first theoretical results establishing the consistency and asymptotic normality of the estimator within the context of spatial low-rank models. Extensive simulations and real-world data experiments corroborate these theoretical findings, showcasing the robustness and scalability of the framework.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean-Field Games With Finitely Many Players: Independent Learning and Subjectivity</title>
<link>https://arxiv.org/abs/2209.05703</link>
<guid>https://arxiv.org/abs/2209.05703</guid>
<content:encoded><![CDATA[
<div> 关键词：独立学习者、均值场游戏、部分观察、马尔科夫决策过程、主观Q均衡

总结:
本文研究了从分散学习角度出发的部分观察均值场游戏，重点关注算法设计指导结构和独立学习者系统中涌现行为的理解。文章提出了一种新的有限玩家、局部动作可观测以及对全局状态进行一般性部分观测的均值场游戏模型。研究了包括全局可观测、局部及均值场可观测、局部及压缩均值场可观测以及仅局部可观测在内的多种观测通道。文章建立了单一代理人控制问题等价于完全观测马尔科夫决策过程（MDP）以及仅等价于部分观测马尔科夫决策过程（POMDP）的条件。基于与MDP的联系，证明在均值场可观测下，记忆无关的静态策略存在完美平衡。利用与POMDP的关联，证明了在上述任何观测通道下的独立学习代理人的学习迭代过程收敛。将极限值解释为主观价值函数，这些函数被用于定义部分观察n玩家均值场游戏的新解概念——主观Q均衡，并在均值场或全局可观测性条件下证明其存在性。此外，文章还提出了针对部分观察n玩家均值场游戏的分布式学习算法，并展示该算法可通过适应近期发展的满意路径理论引导游戏向主观Q均衡收敛。 <div>
arXiv:2209.05703v4 Announce Type: replace 
Abstract: Independent learners are agents that employ single-agent algorithms in multi-agent systems, intentionally ignoring the effect of other strategic agents. This paper studies mean-field games from a decentralized learning perspective, with two primary objectives: (i) to identify structure that can guide algorithm design, and (ii) to understand the emergent behaviour in systems of independent learners. We study a new model of partially observed mean-field games with finitely many players, local action observability, and a general observation channel for partial observations of the global state. Specific observation channels considered include (a) global observability, (b) local and mean-field observability, (c) local and compressed mean-field observability, and (d) only local observability. We establish conditions under which the control problem of a given agent is equivalent to a fully observed MDP, as well as conditions under which the control problem is equivalent only to a POMDP. Building on the connection to MDPs, we prove the existence of perfect equilibrium among memoryless stationary policies under mean-field observability. Leveraging the connection to POMDPs, we prove convergence of learning iterates obtained by independent learning agents under any of the aforementioned observation channels. We interpret the limiting values as subjective value functions, which an agent believes to be relevant to its control problem. These subjective value functions are then used to propose subjective Q-equilibrium, a new solution concept for partially observed n-player mean-field games, whose existence is proved under mean-field or global observability. We provide a decentralized learning algorithm for partially observed n-player mean-field games, and we show that it drives play to subjective Q-equilibrium by adapting the recently developed theory of satisficing paths to allow for subjectivity.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>It Takes Two: A Peer-Prediction Solution for Blockchain Verifier's Dilemma</title>
<link>https://arxiv.org/abs/2406.01794</link>
<guid>https://arxiv.org/abs/2406.01794</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链安全、共识机制、验证者困境、拜占庭容错、诚实激励<br /><br />总结:
本文针对区块链系统的安全性及其依赖的去中心化共识进行了研究，提出了一个解决“验证者困境”的新框架。该框架是一个基于拜占庭容错的一阶段贝叶斯真实性的多验证者激励机制，旨在无须访问真相的情况下，鼓励所有验证者进行诚实验证，即便在验证过程中存在噪声观测。此外，该机制还优化了对合谋和其他恶意行为的抗攻击性，并展示了其对于不准确先验和信念的鲁棒性。通过理论上保证的稳健激励属性，这项研究为增强区块链及其他分布式系统安全性和韧性的去中心化验证协议设计提供了一个框架。 <div>
arXiv:2406.01794v3 Announce Type: replace 
Abstract: The security of blockchain systems is fundamentally based on the decentralized consensus in which the majority of parties behave honestly, and the content verification process is essential to maintaining the robustness of blockchain systems. However, the phenomenon that a secure blockchain system with few or no cheaters could not provide sufficient incentive for (rational) verifiers to honestly perform the costly verification, referred to as the Verifier's Dilemma, could incentivize lazy reporting and undermine the fundamental security of blockchain systems. While existing works have attempted to insert deliberate errors to disincentivize lazy verification, the decentralized environment renders it impossible to judge the correctness of verification or detect malicious verifiers directly without additional layers of procedures, e.g., reputation systems or additional committee voting.
  In this paper, we initiate the research with the development of a Byzantine-robust peer prediction framework towards the design of one-phase Bayesian truthful mechanisms for the decentralized verification games among multiple verifiers, incentivizing all verifiers to perform honest verification without access to the ground truth even in the presence of noisy observations in the verification process. Furthermore, we optimize our mechanism to realize provable robustness against collusions and other malicious behavior from the verifiers, and also show its resilience to inaccurate priors and beliefs. With the theoretically guaranteed robust incentive properties of our mechanism, our study provides a framework of incentive design for decentralized verification protocols that enhances the security and robustness of the blockchain and potentially other decentralized systems.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Global Public Sentiment on Decentralized Finance: A Spatiotemporal Analysis of Geo-tagged Tweets from 150 Countries</title>
<link>https://arxiv.org/abs/2409.00843</link>
<guid>https://arxiv.org/abs/2409.00843</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、去中心化金融(DeFi)、全球情绪分布、情感分析、地理加权回归分析

<br /><br />总结:
本文研究了自2012年至2022年间源自7.4亿条推文中超过1.5亿条与DeFi相关的地理标记推文，通过BERT基多语种分类模型进行情感分析。研究将这些推文数据与经济和地缘政治数据相结合，构建了一个多模态数据集。使用情感分析、空间计量经济学、聚类和主题建模等方法，揭示了全球范围内DeFi参与度和情感表达的显著差异。研究发现，自2015年后，经济发展水平对DeFi参与度具有显著影响，尤其是人均GDP成为预测DeFi相关推文比例的关键因素。富裕国家在DeFi讨论中更为活跃，而低收入国家更多地从金融安全和暴富的角度谈论DeFi；相比之下，中等收入国家将其与社会和宗教议题关联，高收入国家则主要视其为投机工具或娱乐形式。这项研究推进了计算社会科学和金融领域的交叉学科研究，并通过在GitHub上提供数据集和代码以及在KNIME平台上提供非代码工作流程，支持开放科学，从而助力学者、政策制定者、监管机构和开发者在全球范围内探索DeFi采纳与情感动态，推动实现更广泛的金融包容性和负责任的DeFi参与。 <div>
arXiv:2409.00843v2 Announce Type: replace-cross 
Abstract: Blockchain technology and decentralized finance (DeFi) are reshaping global financial systems. Despite their impact, the spatial distribution of public sentiment and its economic and geopolitical determinants are often overlooked. This study analyzes over 150 million geo-tagged, DeFi-related tweets from 2012 to 2022, sourced from a larger dataset of 7.4 billion tweets. Using sentiment scores from a BERT-based multilingual classification model, we integrated these tweets with economic and geopolitical data to create a multimodal dataset. Employing techniques like sentiment analysis, spatial econometrics, clustering, and topic modeling, we uncovered significant global variations in DeFi engagement and sentiment. Our findings indicate that economic development significantly influences DeFi engagement, particularly after 2015. Geographically weighted regression analysis revealed GDP per capita as a key predictor of DeFi tweet proportions, with its impact growing following major increases in cryptocurrency values such as bitcoin. While wealthier nations are more actively engaged in DeFi discourse, the lowest-income countries often discuss DeFi in terms of financial security and sudden wealth. Conversely, middle-income countries relate DeFi to social and religious themes, whereas high-income countries view it mainly as a speculative instrument or entertainment. This research advances interdisciplinary studies in computational social science and finance and supports open science by making our dataset and code available on GitHub, and providing a non-code workflow on the KNIME platform. These contributions enable a broad range of scholars to explore DeFi adoption and sentiment, aiding policymakers, regulators, and developers in promoting financial inclusion and responsible DeFi engagement globally.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quest Love: Do Blockchain Points Build Loyalty or Just Feed the Bots?</title>
<link>https://arxiv.org/abs/2501.18810</link>
<guid>https://arxiv.org/abs/2501.18810</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链生态系统、用户任务、奖励机制、自动化脚本、数据分析

总结:<br />
本文研究了区块链生态系统中用户任务（quest）的设计与影响因素，分析了一项为期10个月、完成次数达8000万次的任务系统数据。研究发现，任务完成率受奖励量、奖励货币价值、难度和成本等因素的影响。此外，文中还讨论了 farming 和机器人脚本在其中的作用，以及区分真实用户与自动化脚本所面临的复杂性问题。 <div>
arXiv:2501.18810v1 Announce Type: new 
Abstract: Blockchain ecosystems -- such as those built around chains, layers, and services -- try to engage users for a variety of reasons: user education, growing and protecting their market share, climbing metric-measuring leaderboards with competing systems, demonstrating usage to investors, and identifying worthy recipients for newly created tokens (airdrops). A popular approach is offering user quests: small tasks that can be completed by a user, exposing them to a common task they might want to do in the future, and rewarding them for completion. In this paper, we capture blockchain data from one deployed quest system that offered 43 unique quests over 10 months with 80M completions. We use this data to offer insight about the factors that impact task completion: amount of reward, monetary value of reward, difficulty, and cost. We also discuss the role of farming and bots, and the factors that complicate distinguishing real users from automated scripts.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Bias-Correction Decentralized Stochastic Gradient Algorithm with Momentum Acceleration</title>
<link>https://arxiv.org/abs/2501.19082</link>
<guid>https://arxiv.org/abs/2501.19082</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式随机优化算法、数据异质性、动量加速、Exact-Diffusion with Momentum (EDM)、收敛性

<br /><br />总结:
本文提出了一种名为Exact-Diffusion with Momentum (EDM)的分布式随机梯度算法，该算法通过引入动量方法可以纠正数据异质性导致的偏差并加速算法收敛。理论分析表明，在非凸目标函数情况下，EDM算法能以与数据异质性无关的亚线性速度收敛到最优解的邻域；而在满足Polyak-{\L}ojasiewicz条件（比$\mu$-强凸性假设更弱）的情况下，则可实现线性收敛。最后，通过对一系列现有去中心化优化算法进行仿真对比评估，验证了所提算法在应对数据异质性和网络稀疏性问题上的有效性。 <div>
arXiv:2501.19082v1 Announce Type: new 
Abstract: Distributed stochastic optimization algorithms can handle large-scale data simultaneously and accelerate model training. However, the sparsity of distributed networks and the heterogeneity of data limit these advantages. This paper proposes a momentum-accelerated distributed stochastic gradient algorithm, referred to as Exact-Diffusion with Momentum (EDM), which can correct the bias caused by data heterogeneity and introduces the momentum method commonly used in deep learning to accelerate the convergence of the algorithm. We theoretically demonstrate that this algorithm converges to the neighborhood of the optimum sub-linearly irrelevant to data heterogeneity when applied to non-convex objective functions and linearly under the Polyak-{\L}ojasiewicz condition (a weaker assumption than $\mu$-strongly convexity). Finally, we evaluate the performance of the proposed algorithm by simulation, comparing it with a range of existing decentralized optimization algorithms to demonstrate its effectiveness in addressing data heterogeneity and network sparsity.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics</title>
<link>https://arxiv.org/abs/2501.19239</link>
<guid>https://arxiv.org/abs/2501.19239</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式多智能体、多臂赌博机、重尾分布、稀疏随机图、同步通信

总结:
本文研究了在完全重尾分布环境下，多个智能体通过稀疏随机图进行通信并观察到重尾（同质或异质）奖励分布的分布式多智能体多臂赌博机问题。研究目标是在所有智能体中找到具有最高全局奖励均值的最佳臂。文章首次探讨此类完全重尾场景，揭示了现实世界系统中多客户端间通信和推断的动态及挑战。在同质性设置下，算法利用重尾图的独特中心结构，通过中心估计器聚合奖励信息以降低UCB指数构建过程中的噪声；当有M个智能体且度分布幂律指数$\alpha > 1$时，算法实现了接近于$O(M^{1 -\frac{1}{\alpha}} \log{T})$的遗憾界。在异质性奖励情况下，智能体通过与邻居通信同步，并将交换得到的估计器聚合到UCB指数中；基于新建立的稀疏随机图上的信息延迟界限，证明了$O(M \log{T})$的遗憾界。这些结果优于现有仅针对静态连通图或密集图及轻尾动态的研究工作。 <div>
arXiv:2501.19239v1 Announce Type: new 
Abstract: We study decentralized multi-agent multi-armed bandits in fully heavy-tailed settings, where clients communicate over sparse random graphs with heavy-tailed degree distributions and observe heavy-tailed (homogeneous or heterogeneous) reward distributions with potentially infinite variance. The objective is to maximize system performance by pulling the globally optimal arm with the highest global reward mean across all clients. We are the first to address such fully heavy-tailed scenarios, which capture the dynamics and challenges in communication and inference among multiple clients in real-world systems. In homogeneous settings, our algorithmic framework exploits hub-like structures unique to heavy-tailed graphs, allowing clients to aggregate rewards and reduce noises via hub estimators when constructing UCB indices; under $M$ clients and degree distributions with power-law index $\alpha > 1$, our algorithm attains a regret bound (almost) of order $O(M^{1 -\frac{1}{\alpha}} \log{T})$. Under heterogeneous rewards, clients synchronize by communicating with neighbors, aggregating exchanged estimators in UCB indices; With our newly established information delay bounds on sparse random graphs, we prove a regret bound of $O(M \log{T})$. Our results improve upon existing work, which only address time-invariant connected graphs, or light-tailed dynamics in dense graphs and rewards.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>S-VOTE: Similarity-based Voting for Client Selection in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.19279</link>
<guid>https://arxiv.org/abs/2501.19279</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning (DFL)，S-VOTE，client selection，non-IID数据分布，通信成本，资源使用优化，模型性能，参与不平衡，局部训练，更快收敛，能源消耗减少。

<br /><br />总结:
本文提出了S-VOTE，一种针对非IID数据分布环境下的去中心化联邦学习（DFL）中的投票基客户端选择机制。S-VOTE旨在优化资源使用并提升模型性能，它采用自适应策略解决参与不平衡问题，允许未充分利用的客户端在不显著增加资源成本的情况下做出贡献。实验结果显示，与基线方法相比，S-VOTE能够降低最多21%的通信成本，加快4-6%的收敛速度，并在某些配置下改善本地性能高达9-17%，同时实现了14-24%的能源消耗降低。这些成果表明S-VOTE在应对异构环境中的DFL挑战方面具有潜力。 <div>
arXiv:2501.19279v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) enables collaborative, privacy-preserving model training without relying on a central server. This decentralized approach reduces bottlenecks and eliminates single points of failure, enhancing scalability and resilience. However, DFL also introduces challenges such as suboptimal models with non-IID data distributions, increased communication overhead, and resource usage. Thus, this work proposes S-VOTE, a voting-based client selection mechanism that optimizes resource usage and enhances model performance in federations with non-IID data conditions. S-VOTE considers an adaptive strategy for spontaneous local training that addresses participation imbalance, allowing underutilized clients to contribute without significantly increasing resource costs. Extensive experiments on benchmark datasets demonstrate the S-VOTE effectiveness. More in detail, it achieves lower communication costs by up to 21%, 4-6% faster convergence, and improves local performance by 9-17% compared to baseline methods in some configurations, all while achieving a 14-24% energy consumption reduction. These results highlight the potential of S-VOTE to address DFL challenges in heterogeneous environments.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Noninterference Analysis of Irreversible or Reversible Systems with Nondeterminism and Probabilities</title>
<link>https://arxiv.org/abs/2501.19290</link>
<guid>https://arxiv.org/abs/2501.19290</guid>
<content:encoded><![CDATA[
<div> 关键词: 非交互理论、概率性、不可逆系统、可逆系统、弱有向相似性、分支有向相似性、智能合约

总结:
本文探讨了非交互理论在多级安全系统中分析安全计算的应用。针对带有概率和非确定性的环境，文章分别对不可逆系统和可逆系统进行了研究。对于不可逆系统，该文扩展了Aldini等人在生成-反应型概率设定中的结果，采用概率弱有向相似性来重新阐述非交互属性；而对于可逆系统，则是在纯非确定性环境基础上，结合Esposito等人成果，引入概率分支有向相似性进行研究。文章还讨论了这些属性的分类、保持性和组合性方面，以及与非确定性情况的比较。通过一个概率性智能合约的例子，展示了扩展后的非交互理论的适用性。<br /><br /> <div>
arXiv:2501.19290v1 Announce Type: new 
Abstract: Noninterference theory supports the analysis of secure computations in multi-level security systems. Classical equivalence-based approaches to noninterference mainly rely on bisimilarity. In a nondeterministic setting, assessing noninterference through weak bisimilarity is adequate for irreversible systems, whereas for reversible ones branching bisimilarity has been recently proven to be more appropriate. In this paper we address the same two families of systems, with the difference that probabilities come into play in addition to nondeterminism. For irreversible systems we extend the results of Aldini, Bravetti, and Gorrieri developed in a generative-reactive probabilistic setting, while for reversible systems we extend the results of Esposito, Aldini, Bernardo, and Rossi developed in a purely nondeterministic setting. We recast noninterference properties by adopting probabilistic variants of weak and branching bisimilarities for irreversible and reversible systems respectively. Then we investigate a taxonomy of those properties as well as their preservation and compositionality aspects, along with a comparison with the nondeterministic taxonomy. The adequacy of the extended noninterference theory is illustrated via a probabilistic smart contract example.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SeDe: Balancing Blockchain Privacy and Regulatory Compliance by Selective De-Anonymization</title>
<link>https://arxiv.org/abs/2311.08167</link>
<guid>https://arxiv.org/abs/2311.08167</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、区块链、匿名性、合规框架、Selective De-Anonymization (SeDe)、阈值加密、零知识证明

<br />
总结：
本文提出了一个旨在平衡区块链隐私保护与监管合规性的框架——Selective De-Anonymization (SeDe)。该框架允许基于区块链的隐私保护应用通过递归遍历关联交易的子图来识别非法交易。SeDe实现这一目标的同时，避免将去匿名化决策或控制权交给单个实体，而是将其分散到多个实体之间并确保它们对各自行为负责。为了实现这一框架，文中采用了阈值加密方案和零知识证明技术。 <div>
arXiv:2311.08167v5 Announce Type: replace 
Abstract: Privacy is one of the essential pillars for the widespread adoption of blockchains, but public blockchains are transparent by nature. Modern analytics techniques can easily subdue the pseudonymity feature of a blockchain user. Some applications have been able to provide practical privacy protections using privacy-preserving cryptography techniques. However, malicious actors have abused them illicitly, discouraging honest actors from using privacy-preserving applications as "mixing" user interactions and funds with anonymous bad actors, causing compliance and regulatory concerns.
  In this paper, we propose a framework that balances privacy-preserving features by establishing a regulatory and compliant framework called Selective De-Anonymization (SeDe). The adoption of this framework allows privacy-preserving applications on blockchains to de-anonymize illicit transactions by recursive traversal of subgraphs of linked transactions. Our technique achieves this without leaving de-anonymization decisions or control in the hands of a single entity but distributing it among multiple entities while holding them accountable for their respective actions. To instantiate, our framework uses threshold encryption schemes and Zero-Knowledge Proofs (ZKPs).
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Blockchain technology within an Information Ecosystem</title>
<link>https://arxiv.org/abs/2402.13191</link>
<guid>https://arxiv.org/abs/2402.13191</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-based Information Ecosystems (BBIEs), 信任机制, 分布式数据管理, 商业逻辑分解, 葡萄酒供应链管理

<br /><br />总结:
本文提出了基于区块链的信息生态系统（BBIEs）的架构和技术细节，该系统利用区块链技术在各方之间提供信任机制并管理共享业务逻辑，打破了传统信息生态系统中由单一主导公司控制的局面。研究需求源于对协作商业环境的当前需求以及对从业者进行调查所收集的数据。通过实证案例——涉及多个企业和监管机构的葡萄酒供应链管理，验证了该架构方案的合理性。提出的解决方案将基于区块链的应用与现有信息系统整合为生态系统的模块，从而实现低成本、可扩展性和高级别的安全性。结论指出，尽管我们仍需深入探究和细化技术在支持创新型多组织商业模式中的可能性，但BBIEs在这方面具有显著的推动作用。 <div>
arXiv:2402.13191v2 Announce Type: replace 
Abstract: Context: Blockchain-based Information Ecosystems (BBIEs) are a type of information ecosystem in which blockchain technology is used to provide a trust mechanism among parties and to manage shared business logic, breaking the traditional scheme of Information Ecosystems dominated by a leading company and leveraging the decentralization of data management, information flow, and business logic. Objective: In this paper, we propose architecture and technical aspects concerning the creation of a BBIE, underlining the advantages supplied and the logic decomposition among the business and storage components. Method: The requirements are derived from the current needs of the collaborative business and the data collected by surveying practitioners. To get these needs we followed the Grounded Theory research approach. We validate our architectural schema against a case study dealing with the management of a wine supply chain, also involving different companies and supervision authorities. Results: The proposed solution integrates blockchain-based applications with the existing information system as a module of the ecosystem, leveraging on the low costs, scalability, and high-level security because of the restricted access to the network. Conclusion: We must go a long way in deepening and refining the possibilities offered by technology in supporting innovative multi-organizational business models. BBIEs can contribute substantially to paving the way in such a direction.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Case Study in Acceleration AI Ethics: The TELUS GenAI Conversational Agent</title>
<link>https://arxiv.org/abs/2501.18038</link>
<guid>https://arxiv.org/abs/2501.18038</guid>
<content:encoded><![CDATA[
<div> 关键词：加速伦理、人工智能、创新、安全、TELUS

总结:
<br />
本文探讨了加速伦理这一概念，它关注人工智能领域的创新与安全之间的紧张关系。文章明确了加速伦理理论框架，包括五个要素：创新能解决创新带来的问题、创新具有内在价值、未知驱动进步、治理去中心化以及道德内嵌。随后以加拿大电信公司TELUS开发的生成式人工智能语言工具为例，说明了加速伦理框架如何通过持续创新来最大限度地实现社会责任，而不是在创新和社会责任之间进行取舍。通过此案例，可以看出加速AI伦理是一种兼顾并最大化社会利益和创新发展的方法。 <div>
arXiv:2501.18038v1 Announce Type: new 
Abstract: Acceleration ethics addresses the tension between innovation and safety in artificial intelligence. The acceleration argument is that the most effective way to approach risks raised by innovation is with still more innovating. This paper begins by defining acceleration ethics theoretically. It is composed of five elements: innovation solves innovation problems, innovation is intrinsically valuable, the unknown is encouraging, governance is decentralized, ethics is embedded. Subsequently, the paper illustrates the acceleration framework with a use-case, a generative artificial intelligence language tool developed by the Canadian telecommunications company TELUS. While the purity of theoretical positions is blurred by real-world ambiguities, the TELUS experience indicates that acceleration AI ethics is a way of maximizing social responsibility through innovation, as opposed to sacrificing social responsibility for innovation, or sacrificing innovation for social responsibility.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Measuring Blockchain Decentralization</title>
<link>https://arxiv.org/abs/2501.18279</link>
<guid>https://arxiv.org/abs/2501.18279</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化、测量方法、共识层、参与度

总结:<br />
本文针对区块链系统中去中心化衡量方法缺乏广泛接受的标准这一问题，开展了一项系统化研究工作。文章提出了一种框架，根据所测量的目标资源、数据提取方法以及生成最终测量值所使用的函数对现有测量技术进行分类。通过对前期工作的实证分析，作者发现数据提取阶段的一些看似不重要的选择（如估计窗口大小或应用阈值）会对去中心化程度的计算产生重大影响。此外，探索性因素分析表明，在基于工作量证明(PoW)的区块链中，共识层上的参与度与去中心化并不相关，而在基于权益证明(PoS)的系统中，不同指标则归结为单一因素，这挑战了区块链社区长期以来关于参与度越高去中心化程度越高的假设。最后，结合实证分析和原理性推理，文章为研究人员提供了实用建议，以指导他们进行区块链去中心化的测量，并进一步依据这些建议系统化整理了现有文献。 <div>
arXiv:2501.18279v1 Announce Type: new 
Abstract: In the context of blockchain systems, the importance of decentralization is undermined by the lack of a widely accepted methodology to measure it. To address this gap, we set out a systematization effort targeting the decentralization measurement workflow. To facilitate our systematization, we put forth a framework that categorizes all measurement techniques used in previous work based on the resource they target, the methods they use to extract resource allocation, and the functions they apply to produce the final measurements. We complement this framework with an empirical analysis designed to evaluate whether the various pre-processing steps and metrics used in prior work capture the same underlying concept of decentralization. Our analysis brings about a number of novel insights and observations. First, the seemingly innocuous choices performed during data extraction, such as the size of estimation windows or the application of thresholds that affect the resource distribution, have important repercussions when calculating the level of decentralization. Second, exploratory factor analysis suggests that in Proof-of-Work (PoW) blockchains, participation on the consensus layer is not correlated with decentralization, but rather captures a distinct signal, unlike in Proof-of-Stake (PoS) systems, where the different metrics align under a single factor. These findings challenge the long-held assumption within the blockchain community that higher participation drives higher decentralization. Finally, we combine the results of our empirical analysis with first-principles reasoning to derive practical recommendations for researchers that set out to measure blockchain decentralization, and we further systematize the existing literature in line with these recommendations.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DCatalyst: A Unified Accelerated Framework for Decentralized Optimization</title>
<link>https://arxiv.org/abs/2501.18114</link>
<guid>https://arxiv.org/abs/2501.18114</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized optimization、network、agents、Nesterov acceleration、DCatalyst

总结:
我们研究了在网络无中心服务器情况下的分布式优化问题，该网络由图模型表示，目标是最小化$f+r$，其中$f$代表的是各局部代理损失的平均（强）凸函数，而$r$是一个凸的、扩展值函数。为此，我们提出了DCatalyst，一个将Nesterov加速集成到分布式优化算法中的统一黑盒框架。DCatalyst作为一个内在具有不精确性和动量加速特性的近似亲和方法（构成外层循环），能够无缝嵌入任何选定的分布式算法（作为内层循环）。我们证明了无论选择哪种分布式算法或问题实例，DCatalyst都能实现最优的通信和计算复杂度（至多对数因子）。尤其值得一提的是，它将加速能力扩展到了以前缺乏加速解法的问题类别，从而拓宽了分布式方法的有效性。从技术角度来说，我们的框架引入了“不精确估计序列”——这是对Nesterov估计算序的一个新颖扩展，特别针对分布式环境中复合损失的最小化，巧妙地处理了共识误差和代理人子问题的不精确解决方案，这是现有模型尚未解决的挑战。 <div>
arXiv:2501.18114v1 Announce Type: cross 
Abstract: We study decentralized optimization over a network of agents, modeled as graphs, with no central server. The goal is to minimize $f+r$, where $f$ represents a (strongly) convex function averaging the local agents' losses, and $r$ is a convex, extended-value function.
  We introduce DCatalyst, a unified black-box framework that integrates Nesterov acceleration into decentralized optimization algorithms. %, enhancing their performance. At its core, DCatalyst operates as an \textit{inexact}, \textit{momentum-accelerated} proximal method (forming the outer loop) that seamlessly incorporates any selected decentralized algorithm (as the inner loop). We demonstrate that DCatalyst achieves optimal communication and computational complexity (up to log-factors) across various decentralized algorithms and problem instances. Notably, it extends acceleration capabilities to problem classes previously lacking accelerated solution methods, thereby broadening the effectiveness of decentralized methods.
  On the technical side, our framework introduce the {\it inexact estimating sequences}--a novel extension of the well-known Nesterov's estimating sequences, tailored for the minimization of composite losses in decentralized settings. This method adeptly handles consensus errors and inexact solutions of agents' subproblems, challenges not addressed by existing models.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Experimental relativistic zero-knowledge proofs with unconditional security</title>
<link>https://arxiv.org/abs/2501.18176</link>
<guid>https://arxiv.org/abs/2501.18176</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、量子非局域性游戏、子集相对论位承诺、图三着色问题、无条件安全

<br /><br />总结：
本文提出并实验实现了基于子集相对论位承诺和量子非局域性游戏的一种无条件安全的零知识证明（ZKP）方案，用于解决图三着色问题。该协议实现了交互轮数与边数量之间的线性关系，从而将复杂度和存储需求降低了十三个数量级，显著提高了其实用可行性。这项工作展示了在不信任的互联网环境中，结合特殊相对论和量子理论在无信任加密中的强大潜力，为抵御量子攻击的应用铺平了道路。 <div>
arXiv:2501.18176v1 Announce Type: cross 
Abstract: Zero-knowledge proofs (ZKPs) are widely applied in digital economies, such as cryptocurrencies and smart contracts, for establishing trust and ensuring privacy between untrusted parties. However, almost all ZKPs rely on unproven computational assumptions or are vulnerable to quantum adversaries. We propose and experimentally implement an unconditionally secure ZKP for the graph three-coloring problem by combining subset relativistic bit commitments with quantum nonlocality game. Our protocol achieves a linear relationship between interactive rounds and the number of edges, reducing round complexity and storage requirements by thirteen orders of magnitude, thereby significantly enhancing practical feasibility. Our work illustrates the powerful potential of integrating special relativity with quantum theory in trustless cryptography, paving the way for robust applications against quantum attacks in distrustful internet environments.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization</title>
<link>https://arxiv.org/abs/2501.18183</link>
<guid>https://arxiv.org/abs/2501.18183</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized optimization、projection-free、upper-linearizable functions、DR-次模函数优化、up-concave optimization

总结:

我们提出了一种新的去中心化无投影优化框架，将无投影方法扩展到更广泛的上线性可分解函数类别。该框架结合了去中心化优化技术和上线性可分解函数框架的灵活性，从而对传统的DR-次模函数优化进行了有效推广。我们实现了对于任何$0\le \theta \le 1$，在去中心化上线性可分解函数优化中得到$O(T^{1-\theta/2})$的遗憾值，通信复杂度为$O(T^\theta)$以及线性优化Oracle调用次数为$O(T^{2\theta})$的结果。这使得首次能够处理具有一般凸约束的单调上凹优化问题和非单调上凹优化问题。此外，还将上述针对第一阶反馈的结果扩展到了零阶、半带宽和带宽反馈的情况。 <div>
arXiv:2501.18183v1 Announce Type: cross 
Abstract: We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\theta/2})$ with communication complexity of $O(T^{\theta})$ and number of linear optimization oracle calls of $O(T^{2\theta})$ for decentralized upper-linearizable function optimization, for any $0\le \theta \le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>REPS: Recycled Entropy Packet Spraying for Adaptive Load Balancing and Failure Mitigation</title>
<link>https://arxiv.org/abs/2407.21625</link>
<guid>https://arxiv.org/abs/2407.21625</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据中心、网络负载均衡、人工智能训练、REPS、超高速以太网

<br />
总结:

下一代数据中心需要高效的网络负载均衡来处理不断增长的人工智能训练和一般数据中心流量。现有的Ethernet解决方案（如等价多路径ECMP和无感知包喷洒OPS）在网络规模扩大及随之而来的网络故障增加时难以保持高网络利用率。为解决这些问题，本文提出了REPS，这是一种轻量级、分布式、逐包自适应的负载均衡算法，旨在优化网络利用效率并确保快速从链路故障中恢复。REPS通过缓存表现良好的路径来适应网络条件，当发生网络故障时，能在不到100微秒的时间内重新路由流量。REPS设计用于与下一代乱序传输技术（如超高速以太网）部署，并且每个连接仅引入不超过25字节的状态开销。我们对REPS进行了大规模模拟和基于FPGA的NIC的广泛评估。 <div>
arXiv:2407.21625v3 Announce Type: replace 
Abstract: Next-generation datacenters require highly efficient network load balancing to manage the growing scale of artificial intelligence (AI) training and general datacenter traffic. Existing solutions designed for Ethernet, such as Equal Cost Multi-Path (ECMP) and oblivious packet spraying (OPS), struggle to maintain high network utilizations as datacenter topologies (and network failures as a consequence) continue to grow. To address these limitations, we propose REPS, a lightweight decentralized per-packet adaptive load balancing algorithm designed to optimize network utilization while ensuring rapid recovery from link failures. REPS adapts to network conditions by caching good-performing paths. In case of a network failure, REPS re-routes traffic away from it in less than 100 microseconds. REPS is designed to be deployed with next-generation out-of-order transports, such as Ultra Ethernet, and introduces less than 25 bytes of per-connection state. We extensively evaluate REPS in large-scale simulations and FPGA-based NICs.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized MIMO Systems with Imperfect CSI using LMMSE Receivers</title>
<link>https://arxiv.org/abs/2408.12811</link>
<guid>https://arxiv.org/abs/2408.12811</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化基带处理, 分布式基带处理, 大规模多输入多输出, 信道状态信息, 线性最小均方误差接收器

总结:
本文探讨了大规模多输入多输出(MIMO)系统中，中心化基带处理(CBP)面临的数据交互和高维度计算问题，为此引入了分布式基带处理(DBP)。针对DBP在具有空间相关性和不完美信道状态信息(CSI)情况下的优化融合方案及其性能分析尚未有文献研究的问题，文章考虑了一种采用线性最小均方误差(LMMSE)接收器的分布式MIMO系统。首先，建立了具有较高计算和数据输入/输出(I/O)成本的最优线性融合方案；接着，提出了两种降低复杂度的次优融合策略，并利用随机矩阵理论(RMT)得到了三种方案的信号对干扰及噪声比(SINR)闭合形式表达式，揭示了次优方案成为最优条件。此外，文章确定了分布式LMMSE接收器的最佳正则化参数，明确了最佳天线分区策略，并证明随着集群数量增加，SINR将下降。数值仿真验证了理论结果的准确性。 <div>
arXiv:2408.12811v2 Announce Type: replace 
Abstract: Centralized baseband processing (CBP) is required to achieve the full potential of massive multiple-input multiple-output (MIMO) systems. However, due to the large number of antennas, CBP suffers from two major issues: 1) Tremendous data interconnection between radio frequency (RF) circuitry and processing fabrics; and 2) high-dimensional computation. To this end, decentralized baseband processing (DBP) has been proposed, where the antennas at the BS are partitioned into clusters connected to separate RF circuits and equipped with separate computing units. Unfortunately, due to the decentralized structure, the optimal fusion scheme and performance analysis for DBP with general spatial correlation between clusters and imperfect channel state information (CSI) are not available in the literature. In this paper, we consider a decentralized MIMO system where all clusters adopt linear minimum mean-square error (LMMSE) receivers with imperfect CSI. Specifically, we first establish the optimal linear fusion scheme which has high computational and data input/output (I/O) costs. To reduce the costs, we further propose two sub-optimal fusion schemes with reduced complexity. For all three schemes, we derive the closed-form expressions for the signal-to-interference-and-noise ratio (SINR) by leveraging random matrix theory (RMT) and demonstrate the conditions under which the sub optimal schemes are optimal. Furthermore, we determine the optimal regularization parameter for decentralized LMMSE receivers, identify the best antenna partitioning strategy, and prove that the SINR will decrease as the number of clusters increases. Numerical simulations validate the accuracy of the theoretical results.
]]></content:encoded>
<pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pandora's Box: Cross-Chain Arbitrages in the Realm of Blockchain Interoperability</title>
<link>https://arxiv.org/abs/2501.17335</link>
<guid>https://arxiv.org/abs/2501.17335</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、Layer-1、Layer-2、跨链套利、Maximal Extractable Value (MEV)

<br /><br />总结:
本文首次系统性研究了两种非原子性的跨链套利策略：Sequence-Independent Arbitrage (SIA)和Sequence-Dependent Arbitrage (SDA)，这两种策略分别涉及不同区块链间的独立双向交易及依赖资产桥的套利。研究涵盖了过去一年（从2023年9月至2024年8月）九条区块链的数据，共发现260,808例跨链套利机会，其中32.37%涉及到桥接解决方案。这些套利活动产生了至少9,496,115.28美元的利润，总交易量达465,797,487.98美元。同时，文章分析了跨链套利对安全的影响，包括套利者集中化、失败交易导致的网络拥塞以及私有内存池采用率的增长问题。最后，文中探讨了sequencer激励机制并提出了一个风险优化的套利策略。 <div>
arXiv:2501.17335v1 Announce Type: new 
Abstract: Over recent years, the blockchain ecosystem has grown significantly with the emergence of new Layer-1 (L1) and Layer-2 (L2) networks. These blockchains typically host Decentralized Exchanges (DEXes) for trading assets such as native currencies and stablecoins. While this diversity enriches the ecosystem, it also fragments liquidity, posing challenges for DEXes offering the same assets across multiple blockchains. This fragmentation leads to price discrepancies, creating opportunities like arbitrages for profit-seeking traders, which fall under the broader category of exploitative economic practices known as Maximal Extractable Value (MEV). Although MEV extraction has been extensively studied within single domains (i.e., individual blockchains), cross-chain arbitrages, a form of cross-domain MEV, have received little attention due to their non-atomic nature, complicating both execution and detection.
  In this paper, we shed light on opaque cross-chain MEV activities by presenting the first systematic study of two non-atomic cross-chain arbitrage strategies: Sequence-Independent Arbitrage (SIA) and Sequence-Dependent Arbitrage (SDA). The former involves independent, opposite-direction trades across chains, while the latter relies on asset bridges. We analyze the effectiveness of these strategies across nine blockchains over a one-year period from September 2023 to August 2024, identifying 260,808 cross-chain arbitrages, 32.37% of which involve bridging solutions. These arbitrages generated a lower-bound profit of 9,496,115.28 USD from a total traded volume of 465,797,487.98 USD. Additionally, we examine the security implications of cross-chain arbitrages, uncovering centralization among arbitrageurs, network congestion caused by failed transactions, and growing private mempool adoption. Finally, we discuss sequencer incentives and propose a risk-optimized arbitrage strategy.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Do We Really Need to Design New Byzantine-robust Aggregation Rules?</title>
<link>https://arxiv.org/abs/2501.17381</link>
<guid>https://arxiv.org/abs/2501.17381</guid>
<content:encoded><![CDATA[
<div> 关键词: federated learning, poisoning attacks, aggregation rules, FoundationFL, Byzantine-robust

总结:<br />
本文关注了联邦学习（Federated Learning, FL）中的数据中毒攻击问题，提出了一种新的防御机制——FoundationFL。传统上，通过设计抵抗拜占庭故障的聚合规则来应对这类攻击，但本文指出，增强已有的、经过验证的聚合规则的鲁棒性即可实现FL的安全。FoundationFL方法由服务器生成合成更新，在接收到客户端的本地模型更新后，结合使用Trimmed-mean或Median等已有拜占庭容错聚合规则进行更新融合。理论上，文章证明了FoundationFL在拜占庭环境下的收敛性能。实验结果在多个真实世界的数据集上验证了FoundationFL方法的有效性和效率。 <div>
arXiv:2501.17381v1 Announce Type: new 
Abstract: Federated learning (FL) allows multiple clients to collaboratively train a global machine learning model through a server, without exchanging their private training data. However, the decentralized aspect of FL makes it susceptible to poisoning attacks, where malicious clients can manipulate the global model by sending altered local model updates. To counter these attacks, a variety of aggregation rules designed to be resilient to Byzantine failures have been introduced. Nonetheless, these methods can still be vulnerable to sophisticated attacks or depend on unrealistic assumptions about the server. In this paper, we demonstrate that there is no need to design new Byzantine-robust aggregation rules; instead, FL can be secured by enhancing the robustness of well-established aggregation rules. To this end, we present FoundationFL, a novel defense mechanism against poisoning attacks. FoundationFL involves the server generating synthetic updates after receiving local model updates from clients. It then applies existing Byzantine-robust foundational aggregation rules, such as Trimmed-mean or Median, to combine clients' model updates with the synthetic ones. We theoretically establish the convergence performance of FoundationFL under Byzantine settings. Comprehensive experiments across several real-world datasets validate the efficiency of our FoundationFL method.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Are you a DePIN? A Decision Tree to Classify Decentralized Physical Infrastructure Networks</title>
<link>https://arxiv.org/abs/2501.17416</link>
<guid>https://arxiv.org/abs/2501.17416</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized physical infrastructure networks (DePINs), Web3, Decision tree, Blockchain systems, Helium, Bitcoin

总结:<br />
本文探讨了去中心化物理基础设施网络（DePINs）这一新兴的Web3垂直领域，并分析了其与传统建设方法及其它Web2、Web3应用之间的界限。研究者提出了一种新的决策树模型，用于系统性地将系统分类为DePIN，该模型基于前期研究和诸如是否存在三方市场、供应方是否通过代币激励以及是否需要实体资产部署等标准进行区分。文章通过将决策树应用于Helium和比特币等区块链系统，展示了其在区分DePIN系统方面的实用价值。这项研究为进一步确立识别和归类DePIN系统的客观、系统化方法做出了重要贡献，并为构建全面、公正的DePIN系统数据库奠定了基础，进而可以指导未来该领域的研究和发展。 <div>
arXiv:2501.17416v1 Announce Type: new 
Abstract: Decentralized physical infrastructure networks (DePINs) are an emerging vertical within "Web3" replacing the traditional method that physical infrastructures are constructed. Yet, the boundaries between DePIN and traditional method of building crowd-sourced infrastructures such as citizen science initiatives or other Web3 verticals are not always so clear cut. In this work, we systematically analyze the differences between DePIN and other Web2 and Web3 verticals. For this, the study proposes a novel decision tree for classifying systems as DePIN. This tree is informed by prior studies and differentiates DePIN from related concepts using criteria such as the presence of a three-sided market, token-based incentives for supply, and the requirement for physical asset placement in those systems.
  The paper demonstrates the application of the decision tree to various blockchain systems, including Helium and Bitcoin, showcasing its practical utility in differentiating DePIN systems.
  This research offers significant contributions towards establishing a more objective and systematic approach to identifying and categorizing DePIN systems. It lays the groundwork for creating a comprehensive and unbiased database of DePIN systems, which will inform future research and development within this emerging sector.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Coalitional model predictive control of an irrigation canal</title>
<link>https://arxiv.org/abs/2501.17561</link>
<guid>https://arxiv.org/abs/2501.17561</guid>
<content:encoded><![CDATA[
<div> 关键词： hierarchical control scheme、large-scale systems、network topology、decentralized model predictive control (MPC)、Dez irrigation canal

<br /><br />总结:

本文提出了一种用于大规模系统的分层控制方案，该系统组件可以通过数据网络交换信息。该方案的主要目标是通过主动修改网络拓扑来寻找控制性能和通信成本之间的最佳折衷。监督层采取的行动改变了控制代理对完整系统的认知以及它们可以相互通信的代理集合。每个链接子系统的联盟（即合作社）基于底层管理的分布式模型预测控制(MPC)策略进行独立控制，并对输入施加硬约束，同时考虑软约束以避免状态可行性问题。研究者在针对水系统的精确模拟器SOBEK上采用Dez灌溉渠模型验证了所提控制方案的性能，并将其结果与使用集中式MPC控制器的结果进行了比较。 <div>
arXiv:2501.17561v1 Announce Type: new 
Abstract: We present a hierarchical control scheme for large-scale systems whose components can exchange information through a data network. The main goal of the supervisory layer is to find the best compromise between control performance and communicational costs by actively modifying the network topology. The actions taken at the supervisory layer alter the control agents' knowledge of the complete system, and the set of agents with which they can communicate. Each group of linked subsystems, or coalition, is independently controlled based on a decentralized model predictive control (MPC) scheme, managed at the bottom layer. Hard constraints on the inputs are imposed, while soft constraints on the states are considered to avoid feasibility issues. The performance of the proposed control scheme is validated on a model of the Dez irrigation canal, implemented on the accurate simulator for water systems SOBEK. Finally, the results are compared with those obtained using a centralized MPC controller.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning With Individualized Privacy Through Client Sampling</title>
<link>https://arxiv.org/abs/2501.17634</link>
<guid>https://arxiv.org/abs/2501.17634</guid>
<content:encoded><![CDATA[
<div> 关键词：Individualized Differential Privacy (IDP)，Federated Learning (FL)，客户端特定采样率，隐私预算，SCALE方法

总结:
本文提出了一个针对联邦学习(FL)中个体化差分隐私(IDP)的新方法，该方法根据用户不同的隐私偏好来调整客户端的采样率。通过将SAMPLE算法从集中式环境扩展到FL，并将其与修改后的IDP-FedAvg算法相结合，实现了对用户个性化隐私预算的处理。实验结果显示，相较于统一的DP基线，这种方法在减少隐私和效用之间的权衡方面表现出明显优势，且优于相关工作中分配不同噪声尺度的SCALE方法。然而，对于具有非独立同分布数据的复杂任务，由于分布式设置的约束，仍存在挑战。 <div>
arXiv:2501.17634v1 Announce Type: new 
Abstract: With growing concerns about user data collection, individualized privacy has emerged as a promising solution to balance protection and utility by accounting for diverse user privacy preferences. Instead of enforcing a uniform level of anonymization for all users, this approach allows individuals to choose privacy settings that align with their comfort levels. Building on this idea, we propose an adapted method for enabling Individualized Differential Privacy (IDP) in Federated Learning (FL) by handling clients according to their personal privacy preferences. By extending the SAMPLE algorithm from centralized settings to FL, we calculate client-specific sampling rates based on their heterogeneous privacy budgets and integrate them into a modified IDP-FedAvg algorithm. We test this method under realistic privacy distributions and multiple datasets. The experimental results demonstrate that our approach achieves clear improvements over uniform DP baselines, reducing the trade-off between privacy and utility. Compared to the alternative SCALE method in related work, which assigns differing noise scales to clients, our method performs notably better. However, challenges remain for complex tasks with non-i.i.d. data, primarily stemming from the constraints of the decentralized setting.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gateways for Institutional-Grade Commerce and Interoperability of Digital Assets</title>
<link>https://arxiv.org/abs/2501.17732</link>
<guid>https://arxiv.org/abs/2501.17732</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式账本、互操作性、标准化服务接口、网关、监管合规

总结:
本文探讨了传统金融基础设施与现代去中心化基础设施（如分布式账本）无缝连接的需求及所面临的风险和挑战。文章指出，实现这种互操作性的关键第一步是要认识到分布式账本往往用于社区成员间资源共享，并通过标准化服务接口（或应用程序编程接口(API)）来实现不同系统的跨系统互通。文中提出的“ ledger gateways”（或简称网关）是指实施这些标准化服务接口并接入分布式账本的计算机和软件系统。网关的主要职责是与其他实现相同标准化服务接口的对等网关进行通信，执行跨境数据和价值转移，并成为管理需遵守法律法规的许可环境的重要机制（例如欧盟GDPR、MiCA数字资产法规、FAFT第15建议以及ISO 27001标准）。 <div>
arXiv:2501.17732v1 Announce Type: new 
Abstract: It is time for the legacy financial infrastructure to seamlessly connect with modern, decentralized infrastructure. Although it is increasingly evident that decentralized infrastructure for finance (namely distributed ledgers) will coexist with and complement legacy infrastructure, it is also clear that such interoperability efforts carry new risks and concerns. In particular, managing the range of heterogeneous (and not well-established) infrastructure brings security, privacy, and regulatory issues. The first step to overcome some of these challenges is to recognize that in many deployment instances using distributed ledgers, the purpose of the ledger is to share resources among the community members. The second step after recognizing that borders exist is to understand that interoperability across systems can be best achieved through the use of standardized service interfaces (or application programming interfaces (API)). In this paper we use the term ledger gateways (or simply gateways) to denote the computer and software systems that implement the standardized service interfaces into a distributed ledger. The main purpose of a gateway is to communicate with other peer gateways that implement the same standardized service interface. Among others, peer gateways perform the transfer of data and value across borders (legal or national borders). Gateways also become a mechanism to manage a permissioned environment, where abiding by laws and regulations is crucial for business compliance (e.g., EU General Data Protection Regulations (GDPR), EU MiCa regulation on digital assets, FAFT Recommendation 15, ISO 27001.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BitMLx: Secure Cross-chain Smart Contracts For Bitcoin-style Cryptocurrencies</title>
<link>https://arxiv.org/abs/2501.17733</link>
<guid>https://arxiv.org/abs/2501.17733</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contract, cross-chain, BitMLx, compiler, cryptocurrencies

总结:<br />
本文提出了首个用于跨链智能合约的领域特定语言BitMLx，它允许与持有多种比特币类加密货币的多个用户进行交互。文章贡献了一个编译器，能够将BitMLx合同自动翻译成涉及的每种加密货币的单独合同以及一个同步执行这些合同的用户策略。作者证明了遵循规定策略与多个合同互动的诚实用户，其最终持有的资金至少与执行原始BitMLx合同时一样多。最后，文章实现了BitMLx编译器并通过多元链捐赠和跨不同加密货币的贷款等示例应用展示了其实用性。 <div>
arXiv:2501.17733v1 Announce Type: new 
Abstract: A smart contract is an interactive program that governs funds in the realm of a single cryptocurrency. Yet, the many existing cryptocurrencies have spurred the design of cross-chain applications that require interactions with multiple cryptocurrencies simultaneously. Currently, cross-chain applications are implemented as use-case-specific cryptographic protocols that serve as overlay to synchronize smart contract executions in the different cryptocurrencies. Hence, their design requires substantial expertise, as well as a security analysis in complex cryptographic frameworks.
  In this work, we present BitMLx, the first domain-specific language for cross-chain smart contracts, enabling interactions with several users that hold funds across multiple Bitcoin-like cryptocurrencies. We contribute a compiler to automatically translate a BitMLx contract into one contract per involved cryptocurrency and a user strategy that synchronizes the execution of these contracts. We prove that an honest user, who follows the prescribed strategy when interacting with the several contracts, ends up with at least as many funds as in the corresponding execution of the BitMLx contract. Last, but not least, we implement the BitMLx compiler and demonstrate its utility in the design of illustrative examples of cross-chain applications such as multi-chain donations or loans across different cryptocurrencies.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Atomic Transfer Graphs: Secure-by-design Protocols for Heterogeneous Blockchain Ecosystems</title>
<link>https://arxiv.org/abs/2501.17786</link>
<guid>https://arxiv.org/abs/2501.17786</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、异构性、原子转移图(ATOM)、Conditional Timelock Contracts (CTLCs)、安全协议框架

<br /><br />总结:
本文针对区块链领域的异构性问题，提出了一个新的研究框架，用于设计适用于特定区块链和应用的安全协议。该框架基于原子转移图(ATOM)，它能够描述期望的转账结构，并捕捉众多区块链协议共享的安全性和功能目标。文章引入了Conditional Timelock Contracts (CTLCs)这一新型智能合约机制，可在多种具有受限脚本语言（如比特币）的加密货币中实现，并结合支付通道进行应用。通过ATGs，不仅可以实现新的应用场景，还能表达并确保现有支付通道网络和复杂多方跨币种交换等以太坊式加密货币应用的安全性和功能目标。此框架首次为这些用例提供了普适且可证明安全的协议，并在性能上与现有的特定场景协议相匹配或有所提升。 <div>
arXiv:2501.17786v1 Announce Type: new 
Abstract: The heterogeneity of the blockchain landscape has motivated the design of blockchain protocols tailored to specific blockchains and applications that, hence, require custom security proofs. We observe that many blockchain protocols share common security and functionality goals, which can be captured by an atomic transfer graph (ATG) describing the structure of desired transfers. Based on this observation, we contribute a framework for generating secure-by-design protocols that realize these goals. The resulting protocols build upon Conditional Timelock Contracts (CTLCs), a novel minimal smart contract functionality that can be implemented in a large variety of cryptocurrencies with a restricted scripting language (e.g., Bitcoin), and payment channels. We show how ATGs, in addition to enabling novel applications, capture the security and functionality goals of existing applications, including many examples from payment channel networks and complex multi-party cross-currency swaps among Ethereum-style cryptocurrencies. Our framework is the first to provide generic and provably secure protocols for all these use cases while matching or improving the performance of existing use-case-specific protocols.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DRACO: Decentralized Asynchronous Federated Learning over Row-Stochastic Wireless Networks</title>
<link>https://arxiv.org/abs/2406.13533</link>
<guid>https://arxiv.org/abs/2406.13533</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning, asynchronous SGD, row-stochastic gossip wireless networks, continuous communication, DRACO

总结:
为应对智能物联网和边缘AI等新兴应用场景对完全去中心化（无服务器）网络中神经网络训练的需求，本文提出了一种名为DRACO的新方法。该方法针对去中心化异步随机梯度下降（SGD）进行研究，并利用连续通信技术，在行随机 gossip 无线网络中实现该过程。DRACO允许去中心化网络中的边缘设备在连续的时间线上执行本地训练和模型交换，从而消除了对同步时间要求的依赖。此外，该算法还采用了一种解耦通信和计算日程的技术，赋予所有用户完全自主权以及对延迟节点的可控指导。通过全面的收敛性分析，文章突出了异步和自主参与在去中心化优化中的优势。数值实验验证了所提方法的有效性。 <div>
arXiv:2406.13533v2 Announce Type: replace 
Abstract: Recent developments and emerging use cases, such as smart Internet of Things (IoT) and Edge AI, have sparked considerable interest in the training of neural networks over fully decentralized (serverless) networks. One of the major challenges of decentralized learning is to ensure stable convergence without resorting to strong assumptions applied for each agent regarding data distributions or updating policies. To address these issues, we propose DRACO, a novel method for decentralized asynchronous Stochastic Gradient Descent (SGD) over row-stochastic gossip wireless networks by leveraging continuous communication. Our approach enables edge devices within decentralized networks to perform local training and model exchanging along a continuous timeline, thereby eliminating the necessity for synchronized timing. The algorithm also features a specific technique of decoupling communication and computation schedules, which empowers complete autonomy for all users and manageable instructions for stragglers. Through a comprehensive convergence analysis, we highlight the advantages of asynchronous and autonomous participation in decentralized optimization. Our numerical experiments corroborate the efficacy of the proposed technique.
]]></content:encoded>
<pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-based Crowdsourced Deep Reinforcement Learning as a Service</title>
<link>https://arxiv.org/abs/2501.16369</link>
<guid>https://arxiv.org/abs/2501.16369</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习(DRL)、区块链、众包、DRL即服务(DRLaaS)、智能合约

总结:<br />
本文提出了一种基于区块链的众包深度强化学习即服务（DRLaaS）框架，旨在提高DRL解决方案的可用性。该框架提供两种类型的任务服务：DRL训练和模型共享。通过众包方式，用户可以利用工作者的专业知识和计算能力进行DRL解决方案的训练。同时，用户可以通过模型分享获取预训练模型以助于使用迁移学习方法训练新的DRL解决方案。整个DRLaaS框架建立在联盟链之上，确保可追溯和自主执行。文章设计了用于管理工作者和模型分配的智能合约，并利用星际文件系统（IPFS）保证数据分布的防篡改性。实验证明，该框架在多个DRL应用中表现出有效性。 <div>
arXiv:2501.16369v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) has emerged as a powerful paradigm for solving complex problems. However, its full potential remains inaccessible to a broader audience due to its complexity, which requires expertise in training and designing DRL solutions, high computational capabilities, and sometimes access to pre-trained models. This necessitates the need for hassle-free services that increase the availability of DRL solutions to a variety of users. To enhance the accessibility to DRL services, this paper proposes a novel blockchain-based crowdsourced DRL as a Service (DRLaaS) framework. The framework provides DRL-related services to users, covering two types of tasks: DRL training and model sharing. Through crowdsourcing, users could benefit from the expertise and computational capabilities of workers to train DRL solutions. Model sharing could help users gain access to pre-trained models, shared by workers in return for incentives, which can help train new DRL solutions using methods in knowledge transfer. The DRLaaS framework is built on top of a Consortium Blockchain to enable traceable and autonomous execution. Smart Contracts are designed to manage worker and model allocation, which are stored using the InterPlanetary File System (IPFS) to ensure tamper-proof data distribution. The framework is tested on several DRL applications, proving its efficacy.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Decentralized Online Learning for Supervised Regression and Classification Problems</title>
<link>https://arxiv.org/abs/2501.16519</link>
<guid>https://arxiv.org/abs/2501.16519</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized learning networks, optimization framework, performance-to-weight mapping, performance timeframe, performance-reward mapping

<br /><br />总结:
本文研究了去中心化学习网络中关键参数的优化框架，这些参数包括历史表现与参与者权重之间的映射斜率、性能评估的时间范围以及表现与公平奖励之间的映射斜率。通过模拟Allora网络设计并扩展至处理分类任务的一系列数值实验，对这些参数进行了优化和对比分析。研究表明，最优的表现-权重映射、性能时间范围和表现-奖励映射会随着网络构成和问题类型的不同而变化。这些发现为去中心化学习协议的优化提供了有价值见解，并讨论了如何将这些结果推广到基于推断综合的任何去中心化AI网络的优化中。 <div>
arXiv:2501.16519v1 Announce Type: new 
Abstract: Decentralized learning networks aim to synthesize a single network inference from a set of raw inferences provided by multiple participants. To determine the combined inference, these networks must adopt a mapping from historical participant performance to weights, and to appropriately incentivize contributions they must adopt a mapping from performance to fair rewards. Despite the increased prevalence of decentralized learning networks, there exists no systematic study that performs a calibration of the associated free parameters. Here we present an optimization framework for key parameters governing decentralized online learning in supervised regression and classification problems. These parameters include the slope of the mapping between historical performance and participant weight, the timeframe for performance evaluation, and the slope of the mapping between performance and rewards. These parameters are optimized using a suite of numerical experiments that mimic the design of the Allora Network, but have been extended to handle classification tasks in addition to regression tasks. This setup enables a comparative analysis of parameter tuning and network performance optimization (loss minimization) across both problem types. We demonstrate how the optimal performance-weight mapping, performance timeframe, and performance-reward mapping vary with network composition and problem type. Our findings provide valuable insights for the optimization of decentralized learning protocols, and we discuss how these results can be generalized to optimize any inference synthesis-based, decentralized AI network.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Governing the Agent-to-Agent Economy of Trust via Progressive Decentralization</title>
<link>https://arxiv.org/abs/2501.16606</link>
<guid>https://arxiv.org/abs/2501.16606</guid>
<content:encoded><![CDATA[
<div> 关键词: AI治理、AI代理、价值交换、信任机制、AgentBound令牌

<br />
总结:
本文探讨了随着AI代理承担关键任务，现有的AI治理方法可能存在的不足。文章提出，理解人类价值观交换的基础原则对于构建AI驱动的经济体具有重要意义。为了解决AI代理之间如何可靠地确定信任以及在AI经济规模扩大和演进过程中人类如何确保有效监督和控制的问题，作者呼吁研究者关注加密经济学激励，并提出了一个研究议程——使用类似于Web3中灵魂绑定令牌(Soulbound tokens)的非转移性、非同质化的AgentBound令牌(ABT)。通过让AI代理在基于权益证明的机制下将ABT作为自主行为的抵押品，可以激励其遵循伦理行为，并自动实施对不当行为的处罚，从而实现AI代理间的自主交互与价值交换的同时保证人类的有效监督。 <div>
arXiv:2501.16606v1 Announce Type: new 
Abstract: Current approaches to AI governance often fall short in anticipating a future where AI agents manage critical tasks, such as financial operations, administrative functions, and beyond. As AI agents may eventually delegate tasks among themselves to optimize efficiency, understanding the foundational principles of human value exchange could offer insights into how AI-driven economies might operate. Just as trust and value exchange are central to human interactions in open marketplaces, they may also be critical for enabling secure and efficient interactions among AI agents. While cryptocurrencies could serve as the foundation for monetizing value exchange in a collaboration and delegation dynamic among AI agents, a critical question remains: how can these agents reliably determine whom to trust, and how can humans ensure meaningful oversight and control as an economy of AI agents scales and evolves? This paper is a call for a collective exploration of cryptoeconomic incentives, which can help design decentralized governance systems that allow AI agents to autonomously interact and exchange value while ensuring human oversight via progressive decentralization. Toward this end, I propose a research agenda to address the question of agent-to-agent trust using AgentBound Tokens, which are non-transferable, non-fungible tokens uniquely tied to individual AI agents, akin to Soulbound tokens for humans in Web3. By staking ABTs as collateral for autonomous actions within an agent-to-agent network via a proof-of-stake mechanism, agents may be incentivized towards ethical behavior, and penalties for misconduct are automatically enforced.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Address Poisoning</title>
<link>https://arxiv.org/abs/2501.16681</link>
<guid>https://arxiv.org/abs/2501.16681</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、地址中毒、攻击检测系统、以太坊、币安智能链<br /><br />总结:
本文针对区块链中的钱包地址安全问题，特别是以太坊和币安智能链上的地址中毒攻击进行了深入研究。文章贡献主要包括：1. 开发了一套检测系统并进行了两年的数据测量，发现针对1700万受害者的2.7亿次攻击尝试，比先前报告的数量增加了13倍，其中至少有6633起事件导致了8380万美元的损失；2. 对使用改进聚类技术分析的大型攻击实体进行了研究，并建模了攻击者的盈利性和竞争态势；3. 揭示了攻击策略，包括定向人群、成功条件（地址相似度、时机）以及跨链攻击；4. 数学定义并模拟了各类软硬件实现下的仿冒地址生成过程，发现了一个疑似使用GPU的大规模攻击者群体，并提出了防御性对策。 <div>
arXiv:2501.16681v1 Announce Type: new 
Abstract: In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on Ethereum and BSC. We identify 13 times the number of attack attempts reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address-generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Trajectory (Re)Planning for a Large Scale Swarm</title>
<link>https://arxiv.org/abs/2501.16743</link>
<guid>https://arxiv.org/abs/2501.16743</guid>
<content:encoded><![CDATA[
<div> 关键词：轨迹重规划、大规模群体、复杂环境、分布式轨迹优化、层次化方法

<br />
总结:

本文研究了在复杂环境中大规模群体的轨迹重规划问题。提出了一种利用层次化方法的路径规划器，该方法通过将工作空间划分并并行计算每个单元格内的机器人碰撞规避路径实现重规划。采用分布式的轨迹优化策略生成无死锁的高效执行轨迹，并在优化失败时仍能保持控制可行性。这种层次化方法结合了集中式和分散式方法的优点，在确保高任务成功率的同时提供了实时重规划能力。相较于分散式方法，本方法更有效地避免了死锁和碰撞，显著提高了任务成功率。实验结果表明，该算法在模拟环境下可实现实时性能，处理多达142个机器人的场景，并通过一个具有代表性的由24架Crazyflie纳米四旋翼无人机组成的物理实验进行了验证。 <div>
arXiv:2501.16743v1 Announce Type: new 
Abstract: We consider the trajectory replanning problem for a large-scale swarm in a cluttered environment. Our path planner replans for robots by utilizing a hierarchical approach, dividing the workspace, and computing collision-free paths for robots within each cell in parallel. Distributed trajectory optimization generates a deadlock-free trajectory for efficient execution and maintains the control feasibility even when the optimization fails. Our hierarchical approach combines the benefits of both centralized and decentralized methods, achieving a high task success rate while providing real-time replanning capability. Compared to decentralized approaches, our approach effectively avoids deadlocks and collisions, significantly increasing the task success rate. We demonstrate the real-time performance of our algorithm with up to 142 robots in simulation, and a representative 24 physical Crazyflie nano-quadrotor experiment.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Meta-Federated Learning: A Novel Approach for Real-Time Traffic Flow Management</title>
<link>https://arxiv.org/abs/2501.16758</link>
<guid>https://arxiv.org/abs/2501.16758</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (联邦学习), Meta-Learning (元学习), 交通管理, Decentralized, Smart Cities

总结:<br />
本文提出了一种将联邦学习和元学习相结合的创新方法——Meta-Federated Learning，用于解决城市环境中动态变化的交通流量管理难题。该方法利用联邦学习的分布式特性在边缘设备本地处理数据，提升了隐私保护能力和响应速度；同时结合元学习，使系统能在无需大规模重新训练的情况下快速适应新的交通状况。通过在一个模拟的智能交通设备网络中实施此模型，研究表明Meta-Federated Learning在预测精度和反应时间上显著优于传统模型，并且对突发的交通模式变化具有出色的适应性，为实时智能城市交通管理提供了一个可扩展的解决方案。此外，这项研究还展示了联邦学习与元学习整合应用在其他现实世界问题中的巨大潜力。 <div>
arXiv:2501.16758v1 Announce Type: new 
Abstract: Efficient management of traffic flow in urban environments presents a significant challenge, exacerbated by dynamic changes and the sheer volume of data generated by modern transportation networks. Traditional centralized traffic management systems often struggle with scalability and privacy concerns, hindering their effectiveness. This paper introduces a novel approach by combining Federated Learning (FL) and Meta-Learning (ML) to create a decentralized, scalable, and adaptive traffic management system. Our approach, termed Meta-Federated Learning, leverages the distributed nature of FL to process data locally at the edge, thereby enhancing privacy and reducing latency. Simultaneously, ML enables the system to quickly adapt to new traffic conditions without the need for extensive retraining. We implement our model across a simulated network of smart traffic devices, demonstrating that Meta-Federated Learning significantly outperforms traditional models in terms of prediction accuracy and response time. Furthermore, our approach shows remarkable adaptability to sudden changes in traffic patterns, suggesting a scalable solution for real-time traffic management in smart cities. This study not only paves the way for more resilient urban traffic systems but also exemplifies the potential of integrated FL and ML in other real-world applications.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PTSA: Utilizing Transaction Prioritization to Enhance Confirmation Speed in the IOTA Network</title>
<link>https://arxiv.org/abs/2501.16763</link>
<guid>https://arxiv.org/abs/2501.16763</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、有向无环图（DAG）、IOTA、物联网、优先级交易优化

总结:
随着区块链技术的快速发展，有向无环图（DAG）正作为替代传统链式架构用于组织账本记录的一种趋势。文章以IOTA网络为例，指出其在处理物联网（IoT）交易时虽利用DAG架构实现了更高可扩展性，但在有限带宽下未考虑交易优先级的问题。为此，该文提出了一个优化框架，旨在将优先级引入IOTA网络中的关键或高优先级IoT交易。实验基于官方IOTA GitHub仓库进行，使用了现行运营的IOTA节点软件（Hornet版本，Chrysalis更新至1.5）。结果显示，相较于原IOTA系统，提出的算法能让高优先级交易更快达到最终确认状态。 <div>
arXiv:2501.16763v1 Announce Type: new 
Abstract: With the rapid advancement of blockchain technology, a significant trend is the adoption of Directed Acyclic Graphs (DAGs) as an alternative to traditional chain-based architectures for organizing ledger records. Systems like IOTA, which are specially designed for the Internet of Things (IoT), leverage DAG-based architectures to achieve greater scalability by enabling multiple attachment points in the ledger for new transactions while allowing these transactions to be added to the network without incurring any fees. To determine these attachment points, many tip selection algorithms commonly employ specific strategies on the DAG ledger. Transaction prioritization is not considered in the IOTA network, which becomes especially important when network bandwidth is limited. In this paper, we propose an optimization framework designed to integrate a priority level for critical or high-priority IoT transactions within the IOTA network. We evaluate our system using fully based on the official IOTA GitHub repository, which employs the currently operational IOTA node software (Hornet version), as part of the Chrysalis update (1.5). The experimental results show that higher-priority transactions in the proposed algorithm reach final confirmation in less time compared to the original IOTA system.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Secure Federated Graph-Filtering for Recommender Systems</title>
<link>https://arxiv.org/abs/2501.16888</link>
<guid>https://arxiv.org/abs/2501.16888</guid>
<content:encoded><![CDATA[
<div> 关键词：推荐系统、图过滤器、隐私保护、分布式计算、低秩近似

<br /><br />总结:
该文提出两种针对推荐系统的隐私保护型分布式框架，用于安全地计算关键图过滤器，而无需集中敏感信息。第一种方法利用轻量级多方计算和分布式奇异向量计算来私下计算图过滤器；第二种方法进一步扩展了此框架，通过引入低秩近似，实现了通信效率与预测性能之间的权衡。实验结果表明，所提方法在确保数据机密性和降低通信成本的同时，其准确性可与中心化最优系统相媲美。这突显出隐私保护型去中心化架构在现代推荐系统中平衡实用性和用户数据保护方面的潜力。 <div>
arXiv:2501.16888v1 Announce Type: new 
Abstract: Recommender systems often rely on graph-based filters, such as normalized item-item adjacency matrices and low-pass filters. While effective, the centralized computation of these components raises concerns about privacy, security, and the ethical use of user data. This work proposes two decentralized frameworks for securely computing these critical graph components without centralizing sensitive information. The first approach leverages lightweight Multi-Party Computation and distributed singular vector computations to privately compute key graph filters. The second extends this framework by incorporating low-rank approximations, enabling a trade-off between communication efficiency and predictive performance. Empirical evaluations on benchmark datasets demonstrate that the proposed methods achieve comparable accuracy to centralized state-of-the-art systems while ensuring data confidentiality and maintaining low communication costs. Our results highlight the potential for privacy-preserving decentralized architectures to bridge the gap between utility and user data protection in modern recommender systems.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedEFM: Federated Endovascular Foundation Model with Unseen Data</title>
<link>https://arxiv.org/abs/2501.16992</link>
<guid>https://arxiv.org/abs/2501.16992</guid>
<content:encoded><![CDATA[
<div> 关键词：endovascular surgery、catheters/guidewires segmentation、foundation models、federated learning、differentiable Earth Mover's Distance

总结:
<br />
本文提出了一种针对端血管介入手术中导管和导丝精确识别的新方法。该方法利用联邦学习的分布式设置训练基础模型，以解决标注数据有限的问题。为确保训练可行性，文章采用可微分的地球移动距离（Earth Mover's Distance）在知识蒸馏框架下处理未见数据问题。训练完成后，该基础模型的权重为下游任务提供有价值的初始化，从而提升任务特定性能。实验结果显示，本方法达到了新的 state-of-the-art 结果，对于推进端血管介入手术以及机器人辅助端血管手术的发展具有重要意义，同时解决了医疗领域中的数据共享难题。 <div>
arXiv:2501.16992v1 Announce Type: new 
Abstract: In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework. Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Channel Estimation for XL-MIMO Systems with Decentralized Baseband Processing: Integrating Local Reconstruction with Global Refinement</title>
<link>https://arxiv.org/abs/2501.17059</link>
<guid>https://arxiv.org/abs/2501.17059</guid>
<content:encoded><![CDATA[
<div> 关键词: XL-MIMO系统、混合模拟-数字架构、分散式基带处理、两阶段信道估计、SBL-GNNs算法

总结:
本文针对具有混合模拟-数字架构和分散式基带处理框架下的超大规模多输入多输出(XL-MIMO)系统的信道估计问题进行研究。为解决现有集中式和完全分散式方法面临的计算复杂度过高或性能下降的问题，文章提出了一种新颖的两阶段信道估计方案，该方案结合局部稀疏重建与全局融合及细化。首先，利用通道在角度-延迟域内的稀疏性，将本地重建任务建模为稀疏信号恢复问题，并开发了增强型图神经网络的稀疏贝叶斯学习(SBL-GNNs)算法，有效捕捉通道系数间的依赖关系，显著提升估计精度。其次，在第二阶段，来自本地处理单元(LPUs)的局部估计值在全局角度域中进行对齐并融合于中央处理单元(CPU)。基于聚合观测值，将通道细化建模为贝叶斯去噪问题，并设计了一个引入马尔可夫链式层次稀疏先验的变分消息传递算法，有效地利用了全球角度-延迟域中的通道稀疏性和相关性。仿真结果验证了所提SBL-GNNs算法相对于现有方法的有效性和优越性，显示出了更好的估计性能和更低的计算复杂度。 <div>
arXiv:2501.17059v1 Announce Type: new 
Abstract: In this paper, we investigate the channel estimation problem for extremely large-scale multiple-input multiple-output (XL-MIMO) systems with a hybrid analog-digital architecture, implemented within a decentralized baseband processing (DBP) framework with a star topology. Existing centralized and fully decentralized channel estimation methods face limitations due to excessive computational complexity or degraded performance. To overcome these challenges, we propose a novel two-stage channel estimation scheme that integrates local sparse reconstruction with global fusion and refinement. Specifically, in the first stage, by exploiting the sparsity of channels in the angular-delay domain, the local reconstruction task is formulated as a sparse signal recovery problem. To solve it, we develop a graph neural networks-enhanced sparse Bayesian learning (SBL-GNNs) algorithm, which effectively captures dependencies among channel coefficients, significantly improving estimation accuracy. In the second stage, the local estimates from the local processing units (LPUs) are aligned into a global angular domain for fusion at the central processing unit (CPU). Based on the aggregated observations, the channel refinement is modeled as a Bayesian denoising problem. To efficiently solve it, we devise a variational message passing algorithm that incorporates a Markov chain-based hierarchical sparse prior, effectively leveraging both the sparsity and the correlations of the channels in the global angular-delay domain. Simulation results validate the effectiveness and superiority of the proposed SBL-GNNs algorithm over existing methods, demonstrating improved estimation performance and reduced computational complexity.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else</title>
<link>https://arxiv.org/abs/2501.17089</link>
<guid>https://arxiv.org/abs/2501.17089</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Credentials (可验证凭证), Revocation, CRSet, Bloom filter cascade, Ethereum blockchain

总结:
本文提出了CRSet，一种新的可验证凭证（Verifiable Credentials）撤销机制，旨在解决现有撤销方案如Bitstring Status List存在的隐私泄露问题。CRSet利用Bloom过滤器级联和填充技术，保护了发行者、依赖方和主体的元数据隐私。它允许发行者将撤销信息编码为Bloom过滤器并定期发布到去中心化存储系统，例如以太坊区块链，从而使得依赖方可以本地执行撤销检查。该原型系统使用以太坊区块链的廉价数据写入功能直接写入每个CRSet，并已成功与现有的公开钱包代理和OpenID for Verifiable Credentials协议进行端到端测试。虽然CRSet相对于其他方案会增加发行者和依赖方的存储及带宽成本，但对于每年发放数十万份凭证并需长期覆盖撤销状态的发行者而言，这些成本仍然可控，大约在1MB左右。 <div>
arXiv:2501.17089v1 Announce Type: new 
Abstract: Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics. For instance, exact staff fluctuation through issuance and revocation of employee IDs. We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade. Padding is used to provide deniability for issuer metrics. Issuers periodically publish this filter cascade on a decentralized storage system. Relying Parties (RPs) can download it to perform any number of revocation checks locally. Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally. At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications. We present a prototype using the Ethereum blockchain as decentralized storage. The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain. We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols. Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum advantage in decentralized control of POMDPs: A control-theoretic view of the Mermin-Peres square</title>
<link>https://arxiv.org/abs/2501.16690</link>
<guid>https://arxiv.org/abs/2501.16690</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式部分观察马尔科夫决策问题(POMDP), 合作智能体, 长期平均奖励准则, 量子纠缠态, 量子优势

总结:
该文研究了一个多智能体合作的分布式部分观察马尔科夫决策问题(POMDP)，目标是最化长期平均奖励准则。文章指出，在固定速率提供的产品量子系统中，各智能体之间存在量子纠缠态，相比于提供公共随机性的情况，能够实现严格性能提升，即在分布式控制中存在量子优势。这一发现源自对著名Mermin-Peres广场结论的重新诠释，该结论构成了Mermin-Peres游戏的基础。虽然以前已经展示过此类一次性团队问题中的量子优势，但本文揭示了在动态场景下依然存在量子优势的现象，这是相对于当前关于分布式控制问题可达到性能认知的一个新颖发现。本文是对Pravin P. Varaiya教授致敬之作。 <div>
arXiv:2501.16690v1 Announce Type: cross 
Abstract: Consider a decentralized partially-observed Markov decision problem (POMDP) with multiple cooperative agents aiming to maximize a long-term-average reward criterion. We observe that the availability, at a fixed rate, of entangled states of a product quantum system between the agents, where each agent has access to one of the component systems, can result in strictly improved performance even compared to the scenario where common randomness is provided to the agents, i.e. there is a quantum advantage in decentralized control. This observation comes from a simple reinterpretation of the conclusions of the well-known Mermin-Peres square, which underpins the Mermin-Peres game. While quantum advantage has been demonstrated earlier in one-shot team problems of this kind, it is notable that there are examples where there is a quantum advantage for the one-shot criterion but it disappears in the dynamical scenario. The presence of a quantum advantage in dynamical scenarios is thus seen to be a novel finding relative to the current state of knowledge about the achievable performance in decentralized control problems.
  This paper is dedicated to the memory of Pravin P. Varaiya.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Gradient-Free Methods for Stochastic Non-Smooth Non-Convex Optimization</title>
<link>https://arxiv.org/abs/2310.11973</link>
<guid>https://arxiv.org/abs/2310.11973</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式无梯度优化、非光滑非凸函数、Decentralized Gradient-Free Method (DGFM)、DGFM$^+$、复杂性

总结:

本文研究了在不满足平滑性和凸性假设的情况下，对Lipschitz连续函数进行分布式无梯度优化的问题。文章提出了两种新的无梯度算法，即Decentralized Gradient-Free Method (DGFM)及其改进版DGFM$^+$。DGFM利用随机平滑和梯度跟踪技术，只需在每轮迭代中计算单个样本的零阶oracle，降低了对各个计算节点的计算资源需求。理论上，DGFM达到了获取$(\delta,\varepsilon)$-Goldstein稳定点的复杂度为$\mathcal O(d^{3/2}\delta^{-1}\varepsilon ^{-4})$。而DGFM$^+$通过引入方差减少进一步提升了收敛性能，它在每次迭代时使用小批量样本并周期性地采集更大的数据批处理，将复杂度改进到$\mathcal O(d^{3/2}\delta^{-1} \varepsilon^{-3})$。实验结果表明，所提出的算法在实际世界数据集上具有显著的实践经验优势。 <div>
arXiv:2310.11973v2 Announce Type: replace-cross 
Abstract: We consider decentralized gradient-free optimization of minimizing Lipschitz continuous functions that satisfy neither smoothness nor convexity assumption. We propose two novel gradient-free algorithms, the Decentralized Gradient-Free Method (DGFM) and its variant, the Decentralized Gradient-Free Method$^+$ (DGFM$^{+}$). Based on the techniques of randomized smoothing and gradient tracking, DGFM requires the computation of the zeroth-order oracle of a single sample in each iteration, making it less demanding in terms of computational resources for individual computing nodes. Theoretically, DGFM achieves a complexity of $\mathcal O(d^{3/2}\delta^{-1}\varepsilon ^{-4})$ for obtaining an $(\delta,\varepsilon)$-Goldstein stationary point. DGFM$^{+}$, an advanced version of DGFM, incorporates variance reduction to further improve the convergence behavior. It samples a mini-batch at each iteration and periodically draws a larger batch of data, which improves the complexity to $\mathcal O(d^{3/2}\delta^{-1} \varepsilon^{-3})$. Moreover, experimental results underscore the empirical advantages of our proposed algorithms when applied to real-world datasets.
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Social Media Data and Artificial Intelligence for Improving Earthquake Response Efforts</title>
<link>https://arxiv.org/abs/2501.14767</link>
<guid>https://arxiv.org/abs/2501.14767</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交媒体、人工智能、灾难管理、地震响应、实时信息分享

总结:<br />
本文探讨了社交媒体与人工智能在灾难管理中的整合，特别是在地震应对方面的应用。随着数字时代实时信息分享达到前所未有的水平，社交平台已成为危机期间关键的沟通渠道，促使传统集中式的应急服务向更加分散和参与式的灾害态势感知模式转变。研究分析了2024年2月2日发生在俄克拉荷马州的一次5.1级地震后，X（原Twitter）上8,900条社交媒体互动数据，包括2,920条帖子和5,980条回复。数据分析涵盖了灾后的即时阶段直至接下来的七天，显示了数字平台在现代紧急应对中作为实时态势感知工具的关键作用，能有效为社会和当局提供关键信息。 <div>
arXiv:2501.14767v1 Announce Type: new 
Abstract: The integration of social media and artificial intelligence (AI) into disaster management, particularly for earthquake response, represents a profound evolution in emergency management practices. In the digital age, real-time information sharing has reached unprecedented levels, with social media platforms emerging as crucial communication channels during crises. This shift has transformed traditional, centralized emergency services into more decentralized, participatory models of disaster situational awareness. Our study includes an experimental analysis of 8,900 social media interactions, including 2,920 posts and 5,980 replies on X (formerly Twitter), following a magnitude 5.1 earthquake in Oklahoma on February 2, 2024. The analysis covers data from the immediate aftermath and extends over the following seven days, illustrating the critical role of digital platforms in modern disaster response. The results demonstrate that social media platforms can be effectively used as real-time situational awareness tools, delivering critical information to society and authorities during emergencies.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Supply Chain Resilience with Metaverse and ChatGPT Technologies</title>
<link>https://arxiv.org/abs/2501.14777</link>
<guid>https://arxiv.org/abs/2501.14777</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19、俄乌冲突、供应链韧性、Metaverse、ChatGPT

总结:<br />
文章指出了COVID-19疫情和俄乌冲突对全球供应链的严重影响，强调了提升供应链韧性的紧迫性。供应链韧性包括应对内部和外部如自然灾害、战争等造成的中断。文章提出，新型数字技术——Metaverse和ChatGPT为解决这些问题提供了有前景的方案。Metaverse通过整合区块链、物联网等技术，能够模拟现实情况并实时动态展示供应链数据；而大型自然语言处理模型ChatGPT能提高信息传递的速度与准确性，有助于风险管理及供应链决策。研究旨在阐明ChatGPT和Metaverse技术对于提升供应链韧性的价值，并关注对供应链发展具有直接影响的关键标准和成熟度因素。 <div>
arXiv:2501.14777v1 Announce Type: new 
Abstract: Global supply lines have been severely disrupted by the COVID-19 epidemic and the conflict between Russia and Ukraine, which has sharply increased the price of commodities and generated inflation. These incidents highlight how critical it is to improve supply chain resilience (SCRES) in order to fend off unforeseen setbacks. Controlling both internal and external interruptions, such as transportation problems brought on by natural catastrophes and wars, is the responsibility of SCRES. Enhancing resilience in supply chains requires accurate and timely information transfer.
  Promising answers to these problems can be found in the Metaverse and ChatGPT, two new digital technologies. The Metaverse may imitate real-world situations and offer dynamic, real-time 3D representations of supply chain data by integrating blockchain, IoT, network connection, and computer power.Large-scale natural language processing model ChatGPT improves communication and data translation accuracy and speed. To manage risk and facilitate decision making in Supply Chain management, firms should increase information transmission, Speed and quality. This study aim to show the importance of ChatGPT and Metaverse technologies to improve SCRES, with an emphasis on the most important criteria for SCRES, and maturity factor that can influence directly the SC development.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeServe: Towards Affordable Offline LLM Inference via Decentralization</title>
<link>https://arxiv.org/abs/2501.14784</link>
<guid>https://arxiv.org/abs/2501.14784</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成式AI、大型语言模型、GPU资源、去中心化、DeServe

总结:
本文介绍了随着生成式AI的迅速发展和日常工作的广泛应用，大型语言模型（LLM）推理服务的需求大幅增长。尽管专有模型仍然受到青睐，但最近开源LLM的进步使其成为有力竞争者。然而，部署这些模型常常受限于高昂的GPU资源成本和有限的可用性。为解决这一问题，文章提出了一个名为DeServe的去中心化离线LLM推理系统设计，该系统利用闲置GPU资源，以更低的成本实现对LLM的访问分散。DeServe特别关注并优化了在网络延迟高的环境下的服务吞吐量。实验结果显示，在此类条件下，DeServe相比现有服务系统基线实现了6.7x至12.6x的吞吐量提升。 <div>
arXiv:2501.14784v1 Announce Type: new 
Abstract: The rapid growth of generative AI and its integration into everyday workflows have significantly increased the demand for large language model (LLM) inference services. While proprietary models remain popular, recent advancements in open-source LLMs have positioned them as strong contenders. However, deploying these models is often constrained by the high costs and limited availability of GPU resources. In response, this paper presents the design of a decentralized offline serving system for LLM inference. Utilizing idle GPU resources, our proposed system, DeServe, decentralizes access to LLMs at a lower cost. DeServe specifically addresses key challenges in optimizing serving throughput in high-latency network environments. Experiments demonstrate that DeServe achieves a 6.7x-12.6x improvement in throughput over existing serving system baselines in such conditions.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer</title>
<link>https://arxiv.org/abs/2501.14931</link>
<guid>https://arxiv.org/abs/2501.14931</guid>
<content:encoded><![CDATA[
<div> 关键词：pod、区块链延迟、传统共识协议、交易确认、安全属性

总结:
<br />
本文提出了一种名为pod的新颖共识概念，旨在解决区块链中的高延迟问题和传统共识协议的低可扩展性。pod通过消除副本间的通信，使客户端直接将交易发送给所有副本，每个副本独立处理并将其追加到日志中，随后客户端从这些日志中提取信息，实现了仅需一轮往返的物理最优延迟（即一次写入交易和一次读取交易）。然而，由于存在现有下界，该构造实现的性质弱于完全有序广播协议。文中对pod原语进行了建模并定义了其安全性属性，并证明了pod-core构建满足如在$2\delta$内完成交易确认、抵抗拜占庭式副本的审查以及对安全违规行为的责任追究等属性。此外，文章还展示了包括支付系统、拍卖和去中心化数据存储等多种应用可以基于pod原语进行构建。 <div>
arXiv:2501.14931v1 Announce Type: new 
Abstract: This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically optimal latency of one round trip, i.e., requiring only one round for writing a new transaction and one round for reading it. To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, each replica independently processes transactions and appends them to its log, and then clients receive and extract information from these logs. The replicas employ techniques such as transaction timestamping and replica-log sequencing, which allow clients to extract valuable information about the transactions and the state of the system.
  Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then prove that our pod-core construction satisfies properties such as transaction confirmation within $2\delta$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that a wire range of applications, such as payment systems, auctions, and decentralized data stores, can be based on a pod primitive.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Proof-Producing Compiler for Blockchain Applications</title>
<link>https://arxiv.org/abs/2501.15002</link>
<guid>https://arxiv.org/abs/2501.15002</guid>
<content:encoded><![CDATA[
<div> 关键词：CairoZero、编程语言、区块链、编译器、形式验证

总结:
CairoZero是一种用于大规模运行去中心化应用（dApps）的编程语言，其程序可以被编译为Cairo CPU架构的机器码，并利用加密协议在区块链上高效验证执行结果。文章介绍了如何将CairoZero编译器扩展并集成了工具链，使得用户能够在Lean 3证明助手内证明编译后的代码满足高级功能规范。通过实例，他们展示了对大域有限字段上的secp256k1和secp256r1曲线计算以及使用前者进行签名验证等基础算法的形式验证。此外，还验证了在只读环境中模拟读写字典数据结构的方法。最后，作者反思了他们的方法论并讨论了所采用方法的一些优势。 <div>
arXiv:2501.15002v1 Announce Type: new 
Abstract: CairoZero is a programming language for running decentralized applications (dApps) at scale. Programs written in the CairoZero language are compiled to machine code for the Cairo CPU architecture and cryptographic protocols are used to verify the results of execution efficiently on blockchain. We explain how we have extended the CairoZero compiler with tooling that enables users to prove, in the Lean 3 proof assistant, that compiled code satisfies high-level functional specifications. We demonstrate the success of our approach by verifying primitives for computation with the secp256k1 and secp256r1 curves over a large finite field as well as the validation of cryptographic signatures using the former. We also verify a mechanism for simulating a read-write dictionary data structure in a read-only setting. Finally, we reflect on our methodology and discuss some of the benefits of our approach.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Distributed Backdoor Attacks with Network Detection in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.15005</link>
<guid>https://arxiv.org/abs/2501.15005</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式后门攻击、去中心化联邦学习、攻击成功率、距离预测、动态嵌入

<br /><br />总结:
本文研究了分布式后门攻击（DBA）在去中心化联邦学习中的影响。实验表明，DBA在去中心化FL中的攻击成功率受到攻击者在网络架构中分布的影响。为了解决这一问题，文章提出了一个方法，通过预测网络上任意两个攻击者之间的距离来检测网络，并根据这些距离将攻击者组织成不同的聚类。进一步地，文章提出了一种动态算法，将全球模式分解得到的局部模式嵌入到每个聚类的不同攻击者中。通过对基准数据集进行深入的实证研究，文章发现其方法在不同去中心化框架下可以优于集中式攻击和朴素的DBA。 <div>
arXiv:2501.15005v1 Announce Type: new 
Abstract: Distributed backdoor attacks (DBA) have shown a higher attack success rate than centralized attacks in centralized federated learning (FL). However, it has not been investigated in the decentralized FL. In this paper, we experimentally demonstrate that, while directly applying DBA to decentralized FL, the attack success rate depends on the distribution of attackers in the network architecture. Considering that the attackers can not decide their location, this paper aims to achieve a high attack success rate regardless of the attackers' location distribution. Specifically, we first design a method to detect the network by predicting the distance between any two attackers on the network. Then, based on the distance, we organize the attackers in different clusters. Lastly, we propose an algorithm to \textit{dynamically} embed local patterns decomposed from a global pattern into the different attackers in each cluster. We conduct a thorough empirical investigation and find that our method can, in benchmark datasets, outperform both centralized attacks and naive DBA in different decentralized frameworks.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Client Selection in Federated Learning: A Network Anomaly Detection Use Case</title>
<link>https://arxiv.org/abs/2501.15038</link>
<guid>https://arxiv.org/abs/2501.15038</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、客户端选择、差分隐私、容错机制、模型性能

<br /><br />总结:
本文介绍了一种结合了差分隐私和容错机制的联邦学习（Federated Learning）客户端选择框架。该自适应方法根据模型性能和系统约束动态调整所选客户端数量，通过添加校准噪声以确保数据隐私。在使用UNSW-NB15和ROAD数据集进行网络异常检测的案例研究中，相比于FedL2P方法，实验结果显示该方法能提升最多7%的准确性并减少高达25%的训练时间。同时，研究揭示了隐私预算与模型性能之间的权衡关系，提高隐私预算可降低噪声并提升精度。虽然容错机制会导致轻微的性能下降，但增强了对客户端失效的鲁棒性。通过对结果进行Mann-Whitney U检验，证实了这些改进的显著性，其p值小于0.05。 <div>
arXiv:2501.15038v1 Announce Type: new 
Abstract: Federated Learning (FL) has become a widely used approach for training machine learning models on decentralized data, addressing the significant privacy concerns associated with traditional centralized methods. However, the efficiency of FL relies on effective client selection and robust privacy preservation mechanisms. Ineffective client selection can result in suboptimal model performance, while inadequate privacy measures risk exposing sensitive data.
  This paper introduces a client selection framework for FL that incorporates differential privacy and fault tolerance. The proposed adaptive approach dynamically adjusts the number of selected clients based on model performance and system constraints, ensuring privacy through the addition of calibrated noise.
  The method is evaluated on a network anomaly detection use case using the UNSW-NB15 and ROAD datasets. Results demonstrate up to a 7% improvement in accuracy and a 25% reduction in training time compared to the FedL2P approach. Additionally, the study highlights trade-offs between privacy budgets and model performance, with higher privacy budgets leading to reduced noise and improved accuracy. While the fault tolerance mechanism introduces a slight performance decrease, it enhances robustness against client failures. Statistical validation using the Mann-Whitney U test confirms the significance of these improvements, with results achieving a p-value of less than 0.05.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NetChain: Authenticated Blockchain Top-k Graph Data Queries and its Application in Asset Management</title>
<link>https://arxiv.org/abs/2501.15077</link>
<guid>https://arxiv.org/abs/2501.15077</guid>
<content:encoded><![CDATA[
<div> 关键词：图数据、区块链、verifiable boolean查询、NetChain、NetChain+

总结:
本文提出了一个新的框架NetChain，用于实现区块链上图数据的高效top-k查询并保证可验证性。NetChain设计了一种新型的认证两层索引，能够在块级别生成存在/非存在证明，并为匹配对象内置可验证性。为了进一步降低计算和验证开销，文章还衍生出了优化版本NetChain+。通过安全分析验证了这两个框架的真实性。实验结果显示，相比于现有的vChain方案，NetChain在ADS构造方面提高了最多85倍的性能，而NetChain+则将通信和验证成本分别降低了87%和96%。 <div>
arXiv:2501.15077v1 Announce Type: new 
Abstract: As a valuable digital resource, graph data is an important data asset, which has been widely utilized across various fields to optimize decision-making and enable smarter solutions. To manage data assets, blockchain is widely used to enable data sharing and trading, but it cannot supply complex analytical queries. vChain was proposed to achieve verifiable boolean queries over blockchain by designing an embedded authenticated data structure (ADS). However, for generating (non-)existence proofs, vChain suffers from expensive storage and computation costs in ADS construction, along with high communication and verification costs. In this paper, we propose a novel NetChain framework that enables efficient top-k queries over on-chain graph data with verifiability. Specifically, we design a novel authenticated two-layer index that supports (non-)existence proof generation in block-level and built-in verifiability for matched objects. To further alleviate the computation and verification overhead, an optimized variant NetChain+ is derived. The authenticity of our frameworks is validated through security analysis. Evaluations show that NetChain and NetChain+ outperform vChain, respectively achieving up to 85X and 31X improvements on ADS construction. Moreover, compared with vChain, NetChain+ reduces the communication and verification costs by 87% and 96% respectively.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Decentralized Learning with Teleportation</title>
<link>https://arxiv.org/abs/2501.15259</link>
<guid>https://arxiv.org/abs/2501.15259</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized SGD、通信成本、收敛率、TELEPORTATION、超参数调优

总结:
本文主要探讨了去中心化SGD（随机梯度下降）在大量节点情况下的通信效率问题和收敛速度减慢的现象。为解决这一问题，文章提出了名为“TELEPORTATION”的新方法。TELEPORTATION仅激活一部分节点，并使这些活跃节点从前一次活跃的节点获取参数，随后使用SGD更新参数并在一个小规模的、仅包含活跃节点的拓扑结构上进行 gossip 平均操作。通过适当地选择激活节点的数量，TELEPORTATION能够完全缓解收敛率降低的问题。此外，文中还提出了一种有效的超参数调优方法来寻找合适的激活节点数量。实验结果显示，与传统的去中心化SGD相比，TELEPORTATION能更稳定地训练神经网络并实现更高的准确性。 <div>
arXiv:2501.15259v1 Announce Type: new 
Abstract: Decentralized SGD can run with low communication costs, but its sparse communication characteristics deteriorate the convergence rate, especially when the number of nodes is large. In decentralized learning settings, communication is assumed to occur on only a given topology, while in many practical cases, the topology merely represents a preferred communication pattern, and connecting to arbitrary nodes is still possible. Previous studies have tried to alleviate the convergence rate degradation in these cases by designing topologies with large spectral gaps. However, the degradation is still significant when the number of nodes is substantial. In this work, we propose TELEPORTATION. TELEPORTATION activates only a subset of nodes, and the active nodes fetch the parameters from previous active nodes. Then, the active nodes update their parameters by SGD and perform gossip averaging on a relatively small topology comprising only the active nodes. We show that by activating only a proper number of nodes, TELEPORTATION can completely alleviate the convergence rate degradation. Furthermore, we propose an efficient hyperparameter-tuning method to search for the appropriate number of nodes to be activated. Experimentally, we showed that TELEPORTATION can train neural networks more stably and achieve higher accuracy than Decentralized SGD.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Two-Stage CAE-Based Federated Learning Framework for Efficient Jamming Detection in 5G Networks</title>
<link>https://arxiv.org/abs/2501.15288</link>
<guid>https://arxiv.org/abs/2501.15288</guid>
<content:encoded><![CDATA[
<div> 关键词: 5G网络安全、复杂干扰攻击、分布式学习、联邦学习、卷积自编码器

总结:
<br />
针对5G网络中日益严重的复杂干扰攻击问题以及对无线电频率领域安全性的威胁，本文提出了一种用于5G微小区干扰检测的分散式两阶段联邦学习框架。该框架采用联邦平均（FedAVG）算法训练卷积自编码器（CAE），实现无监督学习，随后利用预训练的CAE编码器构建全连接网络（FCN），并采用联邦亲和（FedProx）算法进行有监督分类。实验结果表明，该框架能够在非独立同分布客户端数据集上实现高效训练和预测，同时保护了数据隐私。具体来说，该框架在仅需30轮通信的情况下达到了较高的性能指标：精确度为0.94、召回率为0.90、F1分数为0.92、准确度为0.92，并在拥有6个客户端的情况下实现了检测干扰信号的稳健收敛。 <div>
arXiv:2501.15288v1 Announce Type: new 
Abstract: Cyber-security for 5G networks is drawing notable attention due to an increase in complex jamming attacks that could target the critical 5G Radio Frequency (RF) domain. These attacks pose a significant risk to heterogeneous network (HetNet) architectures, leading to degradation in network performance. Conventional machine-learning techniques for jamming detection rely on centralized training while increasing the odds of data privacy. To address these challenges, this paper proposes a decentralized two-stage federated learning (FL) framework for jamming detection in 5G femtocells. Our proposed distributed framework encompasses using the Federated Averaging (FedAVG) algorithm to train a Convolutional Autoencoder (CAE) for unsupervised learning. In the second stage, we use a fully connected network (FCN) built on the pre-trained CAE encoder that is trained using Federated Proximal (FedProx) algorithm to perform supervised classification. Our experimental results depict that our proposed framework (FedAVG and FedProx) accomplishes efficient training and prediction across non-IID client datasets without compromising data privacy. Specifically, our framework achieves a precision of 0.94, recall of 0.90, F1-score of 0.92, and an accuracy of 0.92, while minimizing communication rounds to 30 and achieving robust convergence in detecting jammed signals with an optimal client count of 6.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ExClique: An Express Consensus Algorithm for High-Speed Transaction Process in Blockchains</title>
<link>https://arxiv.org/abs/2501.15289</link>
<guid>https://arxiv.org/abs/2501.15289</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof of Authority (PoA)，Clique，Express Clique (ExClique)，transactions per second (TPS)，共识节点

总结:
本文探讨了Proof of Authority (PoA)中Clique共识机制在处理交易速度上的局限性，主要受限于全块通信延迟及无轮次区块的产生。针对这些问题，文章提出了一个新的算法——Express Clique (ExClique)，它通过压缩区块以缩短广播通信延迟并避免无轮次区块的出现来优化Clique。实验结果显示，相较于Clique，ExClique在网络中显著提升了事务处理速度（TPS），在拥有21个共识节点的典型网络中提升至2.25倍，而在拥有101个共识节点的大规模网络中更是达到了惊人的7.01倍提升。 <div>
arXiv:2501.15289v1 Announce Type: new 
Abstract: Proof of Authority (PoA) plays a pivotal role in blockchains for reaching consensus. Clique, which selects consensus nodes to generate blocks with a pre-determined order, is the most popular implementation of PoA due to its low communication overhead and energy consumption. However, our study unveils that the speed to process transactions by Clique is severely restricted by 1) the long communication delay of full blocks (each containing a certain number of transactions) between consensus nodes; and 2) occurrences of no-turn blocks, generated by no-turn nodes if an in-turn block generation fails. Consequently, Clique struggles to support distributed applications requiring a high transaction processing speed, e.g., online gaming. To overcome this deficiency, we propose an Express Clique (ExClique) algorithm by improving Clique from two perspectives: compacting blocks for broadcasting to shorten communication delay and prohibiting the occurrences of no-turn blocks. For performance evaluation, we implement ExClique by modifying Geth of Ethereum, the software implementing Clique, and deploy a permissioned blockchain network by using container technology. The experimental results show that ExClique achieves a substantial enhancement in transactions per second (TPS). Specifically, it boosts TPS by 2.25X in a typical network with 21 consensus nodes and an impressive 7.01X in a large-scale network with 101 consensus nodes when compared to Clique.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Post-Processing-Based Fair Federated Learning Framework</title>
<link>https://arxiv.org/abs/2501.15318</link>
<guid>https://arxiv.org/abs/2501.15318</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Fairness, Post-Processing, Decentralized Debiasing, Data Heterogeneity

总结:
<br />
本文提出了一种简单直观的后处理框架，用于提高联邦学习系统中的群体公平性。该框架包括两个阶段：标准的联邦学习训练阶段和完全去中心化的本地去偏阶段。首先，使用如FedAvg的标准联邦学习算法，在无公平约束的情况下训练全局模型。接着，每个客户端利用其局部数据对全局模型进行公平性后处理，以实现基于客户端特定需求和上下文引导的公平性改进。文章探讨了两种成熟的后处理技术在这个框架中的应用：模型输出后处理和最终层微调。通过对四种不同数据集（包括表格、信号和图像数据）的评估，结果显示该框架不仅简化了联邦学习中公平性的实现，而且在最小化准确率损失甚至提高准确率的同时，显著提升了公平性表现，尤其在数据异质性较高的场景下效果更为明显。 <div>
arXiv:2501.15318v1 Announce Type: new 
Abstract: Federated Learning (FL) allows collaborative model training among distributed parties without pooling local datasets at a central server. However, the distributed nature of FL poses challenges in training fair federated learning models. The existing techniques are often limited in offering fairness flexibility to clients and performance. We formally define and empirically analyze a simple and intuitive post-processing-based framework to improve group fairness in FL systems. This framework can be divided into two stages: a standard FL training stage followed by a completely decentralized local debiasing stage. In the first stage, a global model is trained without fairness constraints using a standard federated learning algorithm (e.g. FedAvg). In the second stage, each client applies fairness post-processing on the global model using their respective local dataset. This allows for customized fairness improvements based on clients' desired and context-guided fairness requirements. We demonstrate two well-established post-processing techniques in this framework: model output post-processing and final layer fine-tuning. We evaluate the framework against three common baselines on four different datasets, including tabular, signal, and image data, each with varying levels of data heterogeneity across clients. Our work shows that this framework not only simplifies fairness implementation in FL but also provides significant fairness improvements with minimal accuracy loss or even accuracy gain, across data modalities and machine learning methods, being especially effective in more heterogeneous settings.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Low-Rank Fine-Tuning of Large Language Models</title>
<link>https://arxiv.org/abs/2501.15361</link>
<guid>https://arxiv.org/abs/2501.15361</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 参数效率优化 (PEFT), 低秩适应 (LoRA), 联邦学习 (FL), 分布式学习

总结:
本文介绍了针对大型语言模型（如GPT-4、LLaMA和BERT）的一种新型分布式、隐私保护的微调算法——\texttt{Dec-LoRA}。该算法基于低秩适应（LoRA）的方法进行去中心化微调。现有的参数效率优化技术（如LoRA）通常依赖于集中式的数据与训练环境，而实际场景中往往涉及分布广泛且敏感的数据集，需要采用去中心化的解决方案。文章指出联邦学习虽能解决数据隐私问题，但其仍需中心化的参数服务器进行协调，可能造成瓶颈和通信约束。相反，分布式学习消除了这一依赖，通过客户端间的直接协作提升在分布式环境下的可扩展性和效率。然而，对于分布式环境下LLM的去中心化微调研究尚不充分。通过对BERT和LLaMA-2模型进行大量实验，\texttt{Dec-LoRA}展示了其在处理数据异质性及量化约束方面的性能优势，为实现可扩展且保护隐私的LLM微调提供了新的可能性。 <div>
arXiv:2501.15361v1 Announce Type: new 
Abstract: The emergence of Large Language Models (LLMs) such as GPT-4, LLaMA, and BERT has transformed artificial intelligence, enabling advanced capabilities across diverse applications. While parameter-efficient fine-tuning (PEFT) techniques like LoRA offer computationally efficient adaptations of these models, their practical deployment often assumes centralized data and training environments. However, real-world scenarios frequently involve distributed, privacy-sensitive datasets that require decentralized solutions. Federated learning (FL) addresses data privacy by coordinating model updates across clients, but it is typically based on centralized aggregation through a parameter server, which can introduce bottlenecks and communication constraints. Decentralized learning, in contrast, eliminates this dependency by enabling direct collaboration between clients, improving scalability and efficiency in distributed environments. Despite its advantages, decentralized LLM fine-tuning remains underexplored. In this work, we propose \texttt{Dec-LoRA}, an algorithm for decentralized fine-tuning of LLMs based on low-rank adaptation (LoRA). Through extensive experiments on BERT and LLaMA-2 models, we evaluate \texttt{Dec-LoRA}'s performance in handling data heterogeneity and quantization constraints, enabling scalable, privacy-preserving LLM fine-tuning in decentralized settings.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Potential of Large Language Models in Supply Chain Management: Advancing Decision-Making, Efficiency, and Innovation</title>
<link>https://arxiv.org/abs/2501.15411</link>
<guid>https://arxiv.org/abs/2501.15411</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、供应链管理、决策制定、预测分析、运营效率

<br />
总结:
本文探讨了大型语言模型（LLMs）在供应链管理（SCM）中的集成对行业产生的革命性影响。文章指出，LLMs通过提升决策制定、预测分析和运营效率等方面的能力，正改变着需求预测、库存管理、供应商关系管理和物流优化等多个SCM功能。此外，结合物联网、区块链和机器人等新兴技术，LLMs有助于构建更智能、自主的供应链。文中同时强调了伦理考量，包括偏见缓解和数据保护，以确保公平透明的人工智能实践。还讨论到需要培养员工应对AI驱动的新流程以及长期战略上采用LLMs的好处。针对SCM专业人士的战略建议包括投资高质量的数据管理、推动跨职能协作及使LLM举措与整体业务目标保持一致。文章最后指出，LLMs有望在不断变化的供应链管理领域中推动创新、可持续性和竞争优势。 <div>
arXiv:2501.15411v1 Announce Type: new 
Abstract: The integration of large language models (LLMs) into supply chain management (SCM) is revolutionizing the industry by improving decision-making, predictive analytics, and operational efficiency. This white paper explores the transformative impact of LLMs on various SCM functions, including demand forecasting, inventory management, supplier relationship management, and logistics optimization. By leveraging advanced data analytics and real-time insights, LLMs enable organizations to optimize resources, reduce costs, and improve responsiveness to market changes. Key findings highlight the benefits of integrating LLMs with emerging technologies such as IoT, blockchain, and robotics, which together create smarter and more autonomous supply chains. Ethical considerations, including bias mitigation and data protection, are taken into account to ensure fair and transparent AI practices. In addition, the paper discusses the need to educate the workforce on how to manage new AI-driven processes and the long-term strategic benefits of adopting LLMs. Strategic recommendations for SCM professionals include investing in high-quality data management, promoting cross-functional collaboration, and aligning LLM initiatives with overall business goals. The findings highlight the potential of LLMs to drive innovation, sustainability, and competitive advantage in the ever-changing supply chain management landscape.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FiberPool: Leveraging Multiple Blockchains for Decentralized Pooled Mining</title>
<link>https://arxiv.org/abs/2501.15459</link>
<guid>https://arxiv.org/abs/2501.15459</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、工作量证明、分布式挖矿池、P2Pool、SmartPool、FiberPool、公平性、预算平衡、奖励稳定性、激励相容

总结:<br />
本文提出了一个名为FiberPool的分布式挖矿池方案，旨在解决Proof of Work机制下区块链系统中集中式挖矿池对去中心化原则的破坏问题。FiberPool结合了主链上的智能合约、用于分享份额验证所需数据的存储链以及减少区块奖励使用和提现费用的子链。通过采用FiberPool Proportional支付方案，该研究验证了FiberPool在挖矿公平性、预算平衡、奖励稳定性及激励相容性方面的优势。相比于存在可扩展性和安全性问题的P2Pool以及非预算平衡并需支付高昂手续费的SmartPool，FiberPool提供了一种更优的解决方案。 <div>
arXiv:2501.15459v1 Announce Type: new 
Abstract: The security of blockchain systems based on Proof of Work relies on mining. However, mining suffers from unstable revenue, prompting many miners to form cooperative mining pools. Most existing mining pools operate in a centralized manner, which undermines the decentralization principle of blockchain. Distributed mining pools offer a practical solution to this problem. Well-known examples include P2Pool and SmartPool. However, P2Pool encounters scalability and security issues in its early stages. Similarly, SmartPool is not budget-balanced and imposes fees due to its heavy use of the smart contract. In this research, we present a distributed mining pool named FiberPool to address these challenges. FiberPool integrates a smart contract on the main chain, a storage chain for sharing data necessary for share verification, and a child chain to reduce fees associated with using and withdrawing block rewards. We validate the mining fairness, budget balance, reward stability, and incentive compatibility of the payment scheme FiberPool Proportional adopted by FiberPool.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedAlign: Federated Domain Generalization with Cross-Client Feature Alignment</title>
<link>https://arxiv.org/abs/2501.15486</link>
<guid>https://arxiv.org/abs/2501.15486</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Domain Generalization, FedAlign, 隐私保护, 特征多样性

<br /><br />总结:
本文介绍了一种针对联邦学习（Federated Learning）环境中领域泛化（Domain Generalization）问题的新框架FedAlign。该框架旨在通过增强特征多样性和促进领域不变性来提升联邦学习中的泛化能力。FedAlign包括两个关键模块：一是跨客户端特征扩展模块，它利用域不变特征扰动和选择性的跨客户端特征转移，安全地拓宽每个客户端的局部领域表示，增加域空间的丰富度；二是双阶段对齐模块，通过对客户端间的特征嵌入和预测进行对齐，从而提炼出更为稳健、域不变的特征。这一方法能够在保证数据隐私的同时，以较低的计算和通信开销实现对未见领域的优秀泛化性能。 <div>
arXiv:2501.15486v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a decentralized paradigm for collaborative model training without direct data sharing, yet it poses unique challenges for Domain Generalization (DG), including strict privacy constraints, non-i.i.d. local data, and limited domain diversity. We introduce FedAlign, a lightweight, privacy-preserving framework designed to enhance DG in federated settings by simultaneously increasing feature diversity and promoting domain invariance. First, a cross-client feature extension module broadens local domain representations through domain-invariant feature perturbation and selective cross-client feature transfer, allowing each client to safely access a richer domain space. Second, a dual-stage alignment module refines global feature learning by aligning both feature embeddings and predictions across clients, thereby distilling robust, domain-invariant features. By integrating these modules, our method achieves superior generalization to unseen domains while maintaining data privacy and operating with minimal computational and communication overhead.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real-CATS: A Practical Training Ground for Emerging Research on Cryptocurrency Cybercrime Detection</title>
<link>https://arxiv.org/abs/2501.15553</link>
<guid>https://arxiv.org/abs/2501.15553</guid>
<content:encoded><![CDATA[
<div> 关键词：Real-CATS、区块链交易安全、数据集、加密货币地址、人工智能检测方法

<br />
总结:
本文介绍了Real-CATS，一个现实世界的加密货币地址与交易档案数据集，旨在促进对区块链交易安全中由网络犯罪造成的威胁的研究。由于缺乏有效的实际地址数据集，当前对于网络犯罪检测的研究进展受阻。Real-CATS包括了来自真实报告的103,203个恶意地址和来自交易所客户的106,196个良性地址，具备C3R特性（全面性、可分类性、可定制性和现实世界可转移性），对实际的网络犯罪检测具有重要意义。该数据集提供了三个主要功能：评估检测方法的有效性、支持特征扩展以及为实际部署提供新的评价场景。此外，Real-CATS也为扩展网络犯罪度量研究提供了机会，尤其有利于缺乏加密货币知识背景的跨学科研究人员参与这一新兴领域的研究。该数据平台有望吸引更多研究人员关注并推动数字货币网络安全犯罪检测的研究工作。相关数据集可在https://github.com/sjdseu/Real-CATS获取。 <div>
arXiv:2501.15553v1 Announce Type: new 
Abstract: Cybercriminals pose a significant threat to blockchain trading security, causing $40.9 billion in losses in 2024. However, the lack of an effective real-world address dataset hinders the advancement of cybercrime detection research. The anti-cybercrime efforts of researchers from broader fields, such as statistics and artificial intelligence, are blocked by data scarcity. In this paper, we present Real-CATS, a Real-world dataset of Cryptocurrency Addresses with Transaction profileS, serving as a practical training ground for developing and assessing detection methods. Real-CATS comprises 103,203 criminal addresses from real-world reports and 106,196 benign addresses from exchange customers. It satifies the C3R characteristics (Comprehensiveness, Classifiability, Customizability, and Real-world Transferability), which are fundemental for practical detection of cryptocurrency cybercrime. The dataset provides three main functions: 1) effective evaluation of detection methods, 2) support for feature extensions, and 3) a new evaluation scenario for real-world deployment. Real-CATS also offers opportunities to expand cybercrime measurement studies. It is particularly beneficial for researchers without cryptocurrency-related knowledge to engage in this emerging research field. We hope that studies on cryptocurrency cybercrime detection will be promoted by an increasing number of cross-disciplinary researchers drawn to this versatile data platform. All datasets are available at https://github.com/sjdseu/Real-CATS
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Personalized Federated Learning with Control Systems for Enhanced Performance</title>
<link>https://arxiv.org/abs/2501.15728</link>
<guid>https://arxiv.org/abs/2501.15728</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, personalization, control systems, distributed data, model performance

总结:<br />
本文介绍了一种新的融合个性化联邦学习和鲁棒控制系统的框架。该框架旨在优化分布式数据环境中的学习过程和数据流控制，同时保证隐私。其核心在于利用个性化算法适应每个客户端的独特数据特性，提升模型对单个节点的准确性和相关性，而不影响整体系统性能。通过实时反馈与系统状态动态调整参数的控制系统，确保了网络中学习过程的稳定性和效率。实验结果表明，相较于标准联邦学习模型，这种集成系统在准确性、学习速度以及面对不同网络条件和数据分布时的系统稳健性方面表现出优势，尤其适用于需要高可靠性和精确度的场景。 <div>
arXiv:2501.15728v1 Announce Type: new 
Abstract: In the expanding field of machine learning, federated learning has emerged as a pivotal methodology for distributed data environments, ensuring privacy while leveraging decentralized data sources. However, the heterogeneity of client data and the need for tailored models necessitate the integration of personalization techniques to enhance learning efficacy and model performance. This paper introduces a novel framework that amalgamates personalized federated learning with robust control systems, aimed at optimizing both the learning process and the control of data flow across diverse networked environments. Our approach harnesses personalized algorithms that adapt to the unique characteristics of each client's data, thereby improving the relevance and accuracy of the model for individual nodes without compromising the overall system performance. To manage and control the learning process across the network, we employ a sophisticated control system that dynamically adjusts the parameters based on real-time feedback and system states, ensuring stability and efficiency. Through rigorous experimentation, we demonstrate that our integrated system not only outperforms standard federated learning models in terms of accuracy and learning speed but also maintains system integrity and robustness in face of varying network conditions and data distributions. The experimental results, obtained from a multi-client simulated environment with non-IID data distributions, underscore the benefits of integrating control systems into personalized federated learning frameworks, particularly in scenarios demanding high reliability and precision.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Selective Experience Sharing in Reinforcement Learning Enhances Interference Management</title>
<link>https://arxiv.org/abs/2501.15735</link>
<guid>https://arxiv.org/abs/2501.15735</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、干扰抑制、经验分享、去中心化训练、通信开销减少

<br /><br />总结：

本文提出了一种新颖的多智能体强化学习方法，用于实现小区间的干扰抑制。该方法中，每个基站配备一个智能体，根据其关联用户的信干噪比信息进行评估并选择性地与邻近智能体共享经验。这种策略使得训练和执行完全去中心化，同时最大限度地减少了智能体间的信息共享和通信开销。实验表明，该方法相较于现有的去中心化训练的多智能体强化学习技术表现更优。此外，即使将经验分享量减少75%，提出的算法仍能实现与全量经验分享算法相当的98%频谱效率。 <div>
arXiv:2501.15735v1 Announce Type: new 
Abstract: We propose a novel multi-agent reinforcement learning (RL) approach for inter-cell interference mitigation, in which agents selectively share their experiences with other agents. Each base station is equipped with an agent, which receives signal-to-interference-plus-noise ratio from its own associated users. This information is used to evaluate and selectively share experiences with neighboring agents. The idea is that even a few pertinent experiences from other agents can lead to effective learning. This approach enables fully decentralized training and execution, minimizes information sharing between agents and significantly reduces communication overhead, which is typically the burden of interference management. The proposed method outperforms state-of-the-art multi-agent RL techniques where training is done in a decentralized manner. Furthermore, with a 75% reduction in experience sharing, the proposed algorithm achieves 98% of the spectral efficiency obtained by algorithms sharing all experiences.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive AI-based Decentralized Resource Management in the Cloud-Edge Continuum</title>
<link>https://arxiv.org/abs/2501.15802</link>
<guid>https://arxiv.org/abs/2501.15802</guid>
<content:encoded><![CDATA[
<div> 关键词：资源管理、云边连续体、图神经网络、多智能体强化学习、混合分散框架

总结:<br />
本文提出了一种用于动态应用放置和资源管理的混合分散框架，旨在应对云边连续体中日益复杂的應用需求和动态特性带来的挑战。该框架利用图神经网络对资源和应用状态进行嵌入，以实现全面表示和高效的决策制定。通过采用协作式多智能体强化学习方法，局部代理能够在其邻域内优化资源管理，而全局编排器则确保系统范围内的协调。该框架结合了分散的应用放置与集中的监督控制，从而解决了云边连续体中固有的可扩展性、适应性和准确性问题。文章为高效、自适应和可扩展的资源管理研究贡献了解决方案，同时推动了分散应用放置策略、GNN嵌入以及协同MARL系统的发展。 <div>
arXiv:2501.15802v1 Announce Type: new 
Abstract: The increasing complexity of application requirements and the dynamic nature of the Cloud-Edge Continuum present significant challenges for efficient resource management. These challenges stem from the ever-changing infrastructure, which is characterized by additions, removals, and reconfigurations of nodes and links, as well as the variability of application workloads. Traditional centralized approaches struggle to adapt to these changes due to their static nature, while decentralized solutions face challenges such as limited global visibility and coordination overhead. This paper proposes a hybrid decentralized framework for dynamic application placement and resource management. The framework utilizes Graph Neural Networks (GNNs) to embed resource and application states, enabling comprehensive representation and efficient decision-making. It employs a collaborative multi-agent reinforcement learning (MARL) approach, where local agents optimize resource management in their neighborhoods and a global orchestrator ensures system-wide coordination. By combining decentralized application placement with centralized oversight, our framework addresses the scalability, adaptability, and accuracy challenges inherent in the Cloud-Edge Continuum. This work contributes to the development of decentralized application placement strategies, the integration of GNN embeddings, and collaborative MARL systems, providing a foundation for efficient, adaptive and scalable resource management.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Snowman for partial synchrony</title>
<link>https://arxiv.org/abs/2501.15904</link>
<guid>https://arxiv.org/abs/2501.15904</guid>
<content:encoded><![CDATA[
<div> 关键词: Snowman、共识协议、Avalanche、部分同步设置、本地消息延迟

总结:
本文描述了Snowman共识协议的一种修改版，该协议用于Avalanche区块链系统。原研究已在同步环境中为Snowman建立了概率一致性的确证，假设正确进程以“锁步”方式执行采样轮。新的工作则解决了在部分同步设置下的问题，允许正确进程根据其自身的速度进行连续采样轮，并考虑到由本地消息延迟决定的时间间隔。这一改进确保了协议在更具现实性的网络条件下的一致性。 <div>
arXiv:2501.15904v1 Announce Type: new 
Abstract: Snowman is the consensus protocol run by blockchains on Avalanche. Recent work established a rigorous proof of probabilistic consistency for Snowman in the \emph{synchronous} setting, under the simplifying assumption that correct processes execute sampling rounds in `lockstep'. In this paper, we describe a modification of the protocol that ensures consistency in the \emph{partially synchronous} setting, and when correct processes carry out successive sampling rounds at their own speed, with the time between sampling rounds determined by local message delays.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Brain-Inspired Decentralized Satellite Learning in Space Computing Power Networks</title>
<link>https://arxiv.org/abs/2501.15995</link>
<guid>https://arxiv.org/abs/2501.15995</guid>
<content:encoded><![CDATA[
<div> 关键词: 卫星网络、空间计算能力网络、Spiking神经网络、分布式神经元学习框架、通信效率

总结:
本文提出了一种解决卫星网络数据处理时效性问题的新方法，即利用空间计算能力网络（Space-CPN）协调卫星的计算能力进行在轨数据处理。针对卫星能源供应限制难以满足人工智能计算任务的需求，文章建议采用能效极高的脉冲神经网络（SNNs）进行在轨数据处理，并提出了一个基于神经形态计算架构的分布式神经元学习框架。该框架中，借鉴RelaySum思想开发了一种通信效率高的层间模型聚合方法，理论分析揭示了其收敛速度与网络直径的关系。为进一步优化学习性能，文章还对层间连接拓扑结构提出了一个最小直径生成树问题并进行了求解。实验结果显示，所提方法相较于基准方案具有显著优势。 <div>
arXiv:2501.15995v1 Announce Type: new 
Abstract: Satellite networks are able to collect massive space information with advanced remote sensing technologies, which is essential for real-time applications such as natural disaster monitoring. However, traditional centralized processing by the ground server incurs a severe timeliness issue caused by the transmission bottleneck of raw data. To this end, Space Computing Power Networks (Space-CPN) emerges as a promising architecture to coordinate the computing capability of satellites and enable on board data processing. Nevertheless, due to the natural limitations of solar panels, satellite power system is difficult to meet the energy requirements for ever-increasing intelligent computation tasks of artificial neural networks. To tackle this issue, we propose to employ spiking neural networks (SNNs), which is supported by the neuromorphic computing architecture, for on-board data processing. The extreme sparsity in its computation enables a high energy efficiency. Furthermore, to achieve effective training of these on-board models, we put forward a decentralized neuromorphic learning framework, where a communication-efficient inter-plane model aggregation method is developed with the inspiration from RelaySum. We provide a theoretical analysis to characterize the convergence behavior of the proposed algorithm, which reveals a network diameter related convergence speed. We then formulate a minimum diameter spanning tree problem on the inter-plane connectivity topology and solve it to further improve the learning performance. Extensive experiments are conducted to evaluate the superiority of the proposed method over benchmarks.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TOPLOC: A Locality Sensitive Hashing Scheme for Trustless Verifiable Inference</title>
<link>https://arxiv.org/abs/2501.16007</link>
<guid>https://arxiv.org/abs/2501.16007</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)、可信推理、TOPLOC、局部敏感哈希、验证速度

总结:
<br />
本文提出了一种名为TOPLOC的新方法，用于解决大型语言模型（LLMs）推理过程中的信任问题。TOPLOC利用紧凑型局部敏感哈希机制对中间激活值进行验证，能够以100%的准确率检测到模型、提示或精度的未经授权修改，且在实证评估中没有假阳性和假阴性结果。该方法具有跨不同硬件配置、GPU类型和代数重排的鲁棒性，并能实现比原始推理更快的验证速度。通过引入多项式编码方案，TOPLOC将生成的提交所需的内存开销减少了约1000倍，相比于直接存储Llama-3.1-8B-Instruct的词嵌入，仅需为每个新令牌存储258字节，而不再是262KB。这种方法使用户能够高效地验证LLM推理计算，从而增强开放生态系统的信任与透明度，为去中心化和可验证的人工智能服务奠定了基础。 <div>
arXiv:2501.16007v1 Announce Type: new 
Abstract: Large language models (LLMs) have proven to be very capable, but access to the best models currently rely on inference providers which introduces trust challenges -- how can we be sure that the provider is using the model configuration they claim? We propose TOPLOC, a novel method for verifiable inference that addresses this problem. TOPLOC leverages a compact locality sensitive hashing mechanism for intermediate activations which can detect unauthorized modifications to models, prompts, or precision with 100% accuracy, achieving no false positives or negatives in our empirical evaluations. Our approach is robust across diverse hardware configurations, GPU types, and algebraic reorderings, which allows for validation speeds significantly faster than the original inference. By introducing a polynomial encoding scheme, TOPLOC minimizes memory overhead of the generated commits by $1000\times$, requiring only 258 bytes of storage per 32 new tokens compared to the 262KB requirement of storing the token embeddings directly for Llama-3.1-8B-Instruct. Our method empowers users to verify LLM inference computations efficiently, fostering greater trust and transparency in open ecosystems and lays a foundation for decentralized and verifiable AI services.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Galaxy Era: Agent-based Simulation of Execution Tickets</title>
<link>https://arxiv.org/abs/2501.16090</link>
<guid>https://arxiv.org/abs/2501.16090</guid>
<content:encoded><![CDATA[
<div> 关键词: Execution Tickets、Ethereum、机制设计、拍卖驱动、去中心化

总结:
本文探讨了Execution Tickets作为以太坊区块空间分配机制演进的下一个步骤，研究了该机制应实现的核心目标——去中心化、MEV捕获和区块生产者激励相容性，并提出了相应的实践评估指标。文章分析了七个关键设计参数，包括票量、有效期、退款性、转售性、增强型预览、定价机制以及目标票额。通过评估四种定价机制并构建六种具体机制设计，文章使用基于代理的模拟进行了超过300次的运行实验。结果显示，拍卖驱动的格式（尤其是第二价格拍卖）在捕获MEV方面表现出色；设立二级市场有助于缓解中央集权问题；非到期票据可减少估值风险；取消退款性并不会显著影响性能；延长预览期能提高价格预测性和平滑度，但可能降低价格准确性。总的来说，该研究为Execution Tickets的机制设计提供了理论框架，并通过代理模拟实现了对不同机制设计选择的实际测试与探索性评价，为进一步优化以太坊区块空间分配中的MEV捕获、去中心化及运营效率平衡提供了有益见解。 <div>
arXiv:2501.16090v1 Announce Type: new 
Abstract: Execution Tickets are currently discussed as a next evolutionary step in Ethereum's block space allocation mechanism, separating consensus rewards from execution rewards and selling execution rights through a dedicated market. We present a theoretical framework identifying three core objectives for this mechanism - Decentralization, MEV capture, and Block Producer Incentive Compatibility - alongside practical metrics for evaluating each objective. To meet these goals, we explore seven key design parameters: ticket quantity, expiry, refundability, resalability, enhanced lookahead, pricing mechanism, and target ticket amount.
  We then evaluate four pricing mechanisms and construct six concrete mechanism designs from these parameters. To assess trade-offs in real-world conditions, we perform an agent-based simulation with over 300 runs. Our findings suggest that auction-driven formats, particularly second-price, excel in capturing significant MEV. The simulation also indicates that offering a secondary market can help alleviate centralization, since specialized ticket holders can enter and exit the market as needed.
  Non-expiring tickets show promise in reducing valuation risks, as ticket holders are not influenced by expiry-related discounting. Likewise, removing refundability simplifies the mechanism without notably impairing performance. Extended lookahead periods benefit price predictability and smoothness at a slight cost to price accuracy.
  Overall, this study provides a theoretical framework on the mechanism design space for Execution Tickets as well as a practical implementation of an agent-based simulation to test mechanism design choices. Further, it provides an exploratory evaluation of Execution Ticket mechanism designs, offering insights into optimal configurations that balance MEV capture, decentralization, and operational efficiency in Ethereum's block space allocation.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path Planning and Data Collection</title>
<link>https://arxiv.org/abs/2501.16098</link>
<guid>https://arxiv.org/abs/2501.16098</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习(MARL), 在线学习, 环境适应性, 保守Q学习(CQL), 模型泛化元学习(MAML)

总结:
本文提出了一种新颖的离线元强化学习算法，该算法结合了保守Q学习（CQL）和模型泛化元学习（MAML），以解决传统MARL在实际应用中的问题。CQL利用预收集的数据集实现离线训练，而MAML则保证了对动态网络配置和目标的可扩展性和适应性。文章提出了两种算法变体：独立训练（M-I-MARL）和集中训练分布式执行（M-CTDE-MARL）。模拟结果表明，所提出的算法优于传统方案，特别是M-CTDE-MARL在动态场景下比基准算法收敛速度提高了50%。该框架通过优化无人机轨迹和调度策略，提升了无线通信系统的可扩展性、鲁棒性和适应性。 <div>
arXiv:2501.16098v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) has been widely adopted in high-performance computing and complex data-driven decision-making in the wireless domain. However, conventional MARL schemes face many obstacles in real-world scenarios. First, most MARL algorithms are online, which might be unsafe and impractical. Second, MARL algorithms are environment-specific, meaning network configuration changes require model retraining. This letter proposes a novel meta-offline MARL algorithm that combines conservative Q-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline training by leveraging pre-collected datasets, while MAML ensures scalability and adaptability to dynamic network configurations and objectives. We propose two algorithm variants: independent training (M-I-MARL) and centralized training decentralized execution (M-CTDE-MARL). Simulation results show that the proposed algorithm outperforms conventional schemes, especially the CTDE approach that achieves 50 % faster convergence in dynamic scenarios than the benchmarks. The proposed framework enhances scalability, robustness, and adaptability in wireless communication systems by optimizing UAV trajectories and scheduling policies.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unveiling Ethereum's P2P Network: The Role of Chain and Client Diversity</title>
<link>https://arxiv.org/abs/2501.16236</link>
<guid>https://arxiv.org/abs/2501.16236</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、devp2p协议栈、区块链分叉、节点发现、客户端兼容性

总结:
本文针对Ethereum网络，基于devp2p协议栈构建，旨在通过共享P2P基础设施支持去中心化应用。然而，随着区块链分叉的增多，网络多样性增加，导致节点发现效率降低和复杂性提升。主网节点在建立昂贵的TCP连接、加密及协议握手之后才能区分来自不同区块链的对等节点。此外，客户端多样性的存在造成了协议不兼容和连接失败的问题。文章介绍了一种用于跟踪devp2p消息交换和客户端状态的监控工具，以分析连接动态和协议差异。研究发现，节点发现过程中的低效问题以及Geth在发现过程中出现的时间 out等问题，并强调了在评估合并后Ethereum网络的健康和性能时需要考虑链和客户端的多样性问题。 <div>
arXiv:2501.16236v1 Announce Type: new 
Abstract: The Ethereum network, built on the devp2p protocol stack, was designed to function as a "world computer" by supporting decentralized applications through a shared P2P infrastructure. However, the proliferation of blockchain forks has increased network diversity, complicating node discovery and reducing efficiency. Ethereum mainnet nodes cannot easily distinguish between peers from different blockchains until after establishing an expensive TCP connection, encryption, and protocol handshake. This inefficiency is further worsened by client diversity, where differences in software implementations cause protocol incompatibilities and connection failures. This paper introduces a monitoring tool that tracks devp2p message exchanges and client statuses to analyze connection dynamics and protocol variations. Our findings highlight issues such as inefficiencies in node discovery and client incompatibility, including timeouts in Geth during the discovery process. The study emphasizes the need to consider chain and client diversity when assessing the health and performance of the post-merge Ethereum network.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2011.04820</link>
<guid>https://arxiv.org/abs/2011.04820</guid>
<content:encoded><![CDATA[
<div> 关键词：移动机器人、人群导航、深度强化学习、分布式结构循环神经网络、模拟器到现实转移

总结:<br />
本文提出了一个用于移动机器人安全高效地穿越人类拥挤场景的新方法——分布式结构循环神经网络（DS-RNN）。该网络利用模型自由的深度强化学习进行训练，无需专家监督，能够推理空间和时间关系以适应复杂的人群导航决策。相比于以往假设所有代理动态已知且定义明确的方法，DS-RNN在部分可观测环境和密集人群中的表现更优。文章展示了DS-RNN在具有挑战性的人群导航场景中超越先前方法的效果，并成功将模拟环境中学习到的策略转移到了真实的TurtleBot 2i机器人上。更多详情可访问项目官网：https://sites.google.com/view/crowdnav-ds-rnn/home。 <div>
arXiv:2011.04820v4 Announce Type: replace 
Abstract: Safe and efficient navigation through human crowds is an essential capability for mobile robots. Previous work on robot crowd navigation assumes that the dynamics of all agents are known and well-defined. In addition, the performance of previous methods deteriorates in partially observable environments and environments with dense crowds. To tackle these problems, we propose decentralized structural-Recurrent Neural Network (DS-RNN), a novel network that reasons about spatial and temporal relationships for robot decision making in crowd navigation. We train our network with model-free deep reinforcement learning without any expert supervision. We demonstrate that our model outperforms previous methods in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i. For more information, please visit the project website at https://sites.google.com/view/crowdnav-ds-rnn/home.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Model Predictive Covariance Steering</title>
<link>https://arxiv.org/abs/2212.00398</link>
<guid>https://arxiv.org/abs/2212.00398</guid>
<content:encoded><![CDATA[
<div> 关键词: Distributed Model Predictive Covariance Steering (DiMPCS), 多智能体控制, 随机不确定性, 华森距离, 循环共识算法

总结:
本文提出了分布式模型预测协方差引导(DiMPCS)方法，用于多智能体系统在随机不确定性下的控制问题。该方法融合了协方差引导理论、分布式优化和模型预测控制(MPC)于一体，旨在实现安全、可扩展和去中心化的控制框架。首先，文章利用华森距离来引导多智能体系统的状态分布趋向于期望目标，并通过概率约束确保安全性。接着，通过对协方差引导采用扰动反馈策略参数化以及对安全约束进行可解近似的方式，将问题转化为有限维优化问题。为了解决这一问题，文中使用交替方向乘子法推导出了基于循环共识的分布式算法，并将其扩展到递归 Horizon 形式，从而形成了提出的 DiMPCS 算法。模拟实验表明，DiMPCS 在各种涉及数百个机器人的多机器人任务中表现出有效性，并通过与其他随机 MPC 方法的对比凸显其优越的可扩展性和性能。最后，硬件实验结果也在一个多机器人平台上验证了DiMPCS在实际系统中的适用性。相关实验视频可在https://youtu.be/tzWqOzuj2kQ观看。 <div>
arXiv:2212.00398v2 Announce Type: replace 
Abstract: This paper proposes Distributed Model Predictive Covariance Steering (DiMPCS) for multi-agent control under stochastic uncertainty. The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single framework that is safe, scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-agent system to desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized consensus-based algorithm using the Alternating Direction Method of Multipliers. This method is then extended to a receding horizon form, which yields the proposed DiMPCS algorithm. Simulation experiments on a variety of multi-robot tasks with up to hundreds of robots demonstrate the effectiveness of DiMPCS. The superior scalability and performance of the proposed method is also highlighted through a comparison against related stochastic MPC approaches. Finally, hardware results on a multi-robot platform also verify the applicability of DiMPCS on real systems. A video with all results is available in https://youtu.be/tzWqOzuj2kQ.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A theoretical basis for MEV</title>
<link>https://arxiv.org/abs/2302.02154</link>
<guid>https://arxiv.org/abs/2302.02154</guid>
<content:encoded><![CDATA[
<div> 关键词: Maximal Extractable Value (MEV), 公开区块链, 攻击, 智能合约, 理论基础

总结:
本文针对公开区块链上的Maximal Extractable Value (MEV)攻击进行了深入探讨，这类攻击涉及对手通过重排序、丢弃或插入交易块从智能合约中“抽取”价值。实证研究显示，主流DeFi协议正大规模遭受此类攻击，对用户和区块链网络产生负面影响。鉴于这些攻击的实际影响日益增大，文章提出了一种基于抽象区块链和智能合约模型的MEV正式理论框架。该理论为证明抵御MEV攻击的安全性奠定了基础。<br /><br /> <div>
arXiv:2302.02154v4 Announce Type: replace 
Abstract: Maximal Extractable Value (MEV) refers to a wide class of economic attacks to public blockchains, where adversaries with the power to reorder, drop or insert transactions in a block can "extract" value from smart contracts. Empirical research has shown that mainstream DeFi protocols are massively targeted by these attacks, with detrimental effects on their users and on the blockchain network. Despite the increasing real-world impact of these attacks, their theoretical foundations remain insufficiently established. We propose a formal theory of MEV, based on a general, abstract model of blockchains and smart contracts. Our theory is the basis for proofs of security against MEV attacks.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Market Makers for Cross-chain DeFi and Sharded Blockchains</title>
<link>https://arxiv.org/abs/2309.14290</link>
<guid>https://arxiv.org/abs/2309.14290</guid>
<content:encoded><![CDATA[
<div> 关键词: Uniswap、自动化市场制造商、常数产品流动性池、跨链、锁Swap<br /><br />总结:

本文关注的是Uniswap类的自动化市场制造商，特别是基于常数产品的流动性池在区块链上的运行。Uniswap的一个关键特性是交易者可以原子化地执行一系列资产交换，其间价格不会因其他交易者的操作而改变。然而，在跨链或分片区块链环境中，这一原子化执行功能并不直接可用，因为不同的流动性池分散在不同链或分片上。文章提出了一种新的功能描述和建议实现——“锁Swap”。该功能允许交易者锁定某个交换的价格保证，但可以在稍后决定是否进行交换。通过多个流动性池的应用，“锁Swap”确保了交易者在整个序列交换中的价格保证，并使这些价格成为交易者决定是否执行序列的依据，从而实质上为交易者提供了与序列原子化执行相同的益处。但是，与原子化执行不同，我们的功能并不会阻止其他交易者在规划并可能执行序列的时间段内进行交换，也不会阻止流动性提供者在此期间向流动性池添加或移除流动性。 <div>
arXiv:2309.14290v3 Announce Type: replace 
Abstract: We consider Uniswap-like automated market makers, and, specifically, constant product liquidity pools, operating on blockchains. An important feature of Uniswap is the ability for a trader to carry out a sequence of asset swaps atomically, without other traders changing the prices along the way. This atomic-execution feature is not immediately available in cross-chain or sharded blockchain settings, where different liquidity pools are distributed across different chains or shards. Our contribution is a description and suggested implementation of a new functionality that might be added to individual liquidity pools, the {\em lock-swap}. The lock-swap enables a trader to get a guarantee for the price associated with a swap but only decide later whether or not to carry out the swap. Applied across several liquidity pools, it guarantees the trader assured prices for all swaps in a swap sequence and lets these prices inform the trader's decision about whether or not to carry out the sequence, thus essentially giving the trader the same benefits an atomic execution of the sequence would have provided him. However, in contrast to an atomic execution, our functionality does not prevent other traders from doing swaps during the time where the sequence is planned and possibly carried out. Nor does it prevent liquidity providers from adding or removing liquidity to and from the liquidity pool in that time period.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Sporadic Federated Learning: A Unified Algorithmic Framework with Convergence Guarantees</title>
<link>https://arxiv.org/abs/2402.03448</link>
<guid>https://arxiv.org/abs/2402.03448</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Sporadic Federated Learning (DSpodFL), 异步更新, 非凸模型, 凸模型, 算法收敛性

总结:

本文提出了一种新型的去中心化联邦学习方法——Decentralized Sporadic Federated Learning（DSpodFL），该方法关注于客户端间模型更新和聚合过程中存在的异步性和动态性。DSpodFL通过将每个客户端的梯度下降发生和客户端对之间的模型交换建模为任意指示随机变量，从而统一并涵盖了多种现有的分布式优化方法，适应了计算和通信能力的异质性和时间变化场景。对于凸和非凸模型以及常数和递减的学习率，文章分析了DSpodFL的收敛行为，并在假设通信图连通性、客户端间数据异质性和梯度噪声等条件下进行了理论刻画。实验结果显示，无论在何种系统设置下，DSpodFL相较于基准方案都能实现更优的训练速度。 <div>
arXiv:2402.03448v3 Announce Type: replace 
Abstract: Decentralized federated learning (DFL) captures FL settings where both (i) model updates and (ii) model aggregations are exclusively carried out by the clients without a central server. Existing DFL works have mostly focused on settings where clients conduct a fixed number of local updates between local model exchanges, overlooking heterogeneity and dynamics in communication and computation capabilities. In this work, we propose Decentralized Sporadic Federated Learning ($\texttt{DSpodFL}$), a DFL methodology built on a generalized notion of $\textit{sporadicity}$ in both local gradient and aggregation processes. $\texttt{DSpodFL}$ subsumes many existing decentralized optimization methods under a unified algorithmic framework by modeling the per-iteration (i) occurrence of gradient descent at each client and (ii) exchange of models between client pairs as arbitrary indicator random variables, thus capturing $\textit{heterogeneous and time-varying}$ computation/communication scenarios. We analytically characterize the convergence behavior of $\texttt{DSpodFL}$ for both convex and non-convex models and for both constant and diminishing learning rates, under mild assumptions on the communication graph connectivity, data heterogeneity across clients, and gradient noises. We show how our bounds recover existing results from decentralized gradient descent as special cases. Experiments demonstrate that $\texttt{DSpodFL}$ consistently achieves improved training speeds compared with baselines under various system settings.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean of Means: A 10-dollar Solution for Human Localization with Calibration-free and Unconstrained Camera Settings</title>
<link>https://arxiv.org/abs/2407.20870</link>
<guid>https://arxiv.org/abs/2407.20870</guid>
<content:encoded><![CDATA[
<div> 关键词：人类定位、Metaverse、视觉方法、立体视觉、概率方法

总结:<br />
本文提出了一个新的低成本人体定位方法，尤其适用于Metaverse时代。现有的高精度人体定位依赖于昂贵的标签硬件，而基于视觉的方法则提供了一种无需标签的替代方案。针对当前基于立体视觉的方法存在的局限性，如严格的摄像头设置约束和多阶段SVD求解器中的误差传播问题，该研究提出了一种概率方法。这种方法将人体各点视为围绕身体几何中心分布产生的观测值，从而大幅提高采样效率，使每个兴趣点的样本数量从数百提升到数十亿。通过建模世界坐标与像素坐标分布均值之间的关系并利用中心极限定理，确保了数据的正态性并简化了学习过程。实验结果显示，该方法能在仅使用两台分辨率为640x480像素、成本仅为10美元的网络摄像头的情况下，实现高达95%（误差范围0.3米内）的人体定位准确率，以及几乎100%（误差范围0.5米内）的定位准确性。 <div>
arXiv:2407.20870v2 Announce Type: replace 
Abstract: Accurate human localization is crucial for various applications, especially in the Metaverse era. Existing high precision solutions rely on expensive, tag-dependent hardware, while vision-based methods offer a cheaper, tag-free alternative. However, current vision solutions based on stereo vision face limitations due to rigid perspective transformation principles and error propagation in multi-stage SVD solvers. These solutions also require multiple high-resolution cameras with strict setup constraints. To address these limitations, we propose a probabilistic approach that considers all points on the human body as observations generated by a distribution centered around the body's geometric center. This enables us to improve sampling significantly, increasing the number of samples for each point of interest from hundreds to billions. By modeling the relation between the means of the distributions of world coordinates and pixel coordinates, leveraging the Central Limit Theorem, we ensure normality and facilitate the learning process. Experimental results demonstrate human localization accuracy of 95% within a 0.3m range and nearly 100% accuracy within a 0.5m range, achieved at a low cost of only 10 USD using two web cameras with a resolution of 640x480 pixels.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ZKLoRA: Efficient Zero-Knowledge Proofs for LoRA Verification</title>
<link>https://arxiv.org/abs/2501.13965</link>
<guid>https://arxiv.org/abs/2501.13965</guid>
<content:encoded><![CDATA[
<div> 关键词：Low-Rank Adaptation (LoRA)，ZKLoRA，零知识验证，Multi-Party Inference，知识产权保护

总结:<br />
本文介绍了ZKLoRA，一种针对Low-Rank Adaptation (LoRA)权重的零知识验证协议。该协议旨在分布式、不信任训练环境中解决两个问题：一是确认外部贡献者提供的LoRA权重与预期的基础模型有效配合；二是保护LoRA贡献者的专有权重直至获得补偿。ZKLoRA利用简洁证明和创新的多党派推理程序，在不对LoRA权重进行曝光的情况下验证LoRA模型与基础模型的兼容性，可在最先进的大型语言模型上以每模块只需1-2秒的时间完成验证，实现近乎实时的验证速度，促进了地理分布式的团队以及基于合同的训练管线之间的安全协作。同时，该协议确保交付的LoRA模块如其所声称的功能正常运行，保障了贡献者的知识产权，并为基线模型用户提供兼容性和血缘关系的验证。 <div>
arXiv:2501.13965v1 Announce Type: new 
Abstract: Low-Rank Adaptation (LoRA) is a widely adopted method for customizing large-scale language models. In distributed, untrusted training environments, an open source base model user may want to use LoRA weights created by an external contributor, leading to two requirements: (1) the base model user must confirm that the LoRA weights are effective when paired with the intended base model, and (2) the LoRA contributor must keep their proprietary weights private until compensation is assured.
  We present ZKLoRA, a zero-knowledge verification protocol that relies on succinct proofs and our novel Multi-Party Inference procedure to verify LoRA-base model compatibility without exposing LoRA weights. ZKLoRA produces deterministic correctness guarantees and validates each LoRA module in only 1-2 seconds on state-of-the-art large language models. This low-latency approach enables nearly real-time verification and promotes secure collaboration among geographically decentralized teams and contract-based training pipelines. The protocol ensures that the delivered LoRA module works as claimed, safeguarding the contributor's intellectual property while providing the base model user with verification of compatibility and lineage.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Absolute Governance: A Framework for Synchronization and Certification of the Corporate Contractual State</title>
<link>https://arxiv.org/abs/2501.13974</link>
<guid>https://arxiv.org/abs/2501.13974</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、企业治理、交易完整性、成本降低、共识机制

<br /><br />总结: 本文探讨了利用区块链技术确保企业治理中的交易完整性和降低成本的挑战。提出了一种基于链上的方法，用于认证、注册和查询机构交易状态，采用去中心化的治理方式，结合共识机制和智能合约自动执行并强制实施业务规则。该框架旨在降低与合同性测量报告相关的交易成本，并提升整体交易完整性。文中详细阐述了如何有效利用区块链技术提供针对这些问题的稳健解决方案，并实际应用表明，该方法可实现平均2%的过度计费削减。 <div>
arXiv:2501.13974v1 Announce Type: new 
Abstract: This dissertation addresses the challenge of ensuring transactional integrity and reducing costs in corporate governance through blockchain technology. We propose an on-chain methodology for certifying, registering, and querying institutional transactional status. Our decentralized governance approach utilizes consensus mechanisms and smart contracts to automate and enforce business rules. The framework aims to reduce the transaction costs associated with contractual measurement reports and enhance overall transactional integrity. We provide a detailed exploration of how blockchain technology can be effectively harnessed to offer a robust solution to these challenges, setting the stage for our proposed solution and its potential impact on corporate governance. The application of the methodology resulted in as average of 2% overbilling reduction.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Timelock-Free Rationally-Secure Virtual Channels</title>
<link>https://arxiv.org/abs/2501.14418</link>
<guid>https://arxiv.org/abs/2501.14418</guid>
<content:encoded><![CDATA[
<div> 关键词: 支付通道网络, Thunderdome, 无时间锁, 安全性, 激励机制

总结:
Thunderdome 是首个无时间锁的支付通道网络解决方案，旨在解决区块链交易吞吐量限制问题。该方案通过扩展一种无时间锁的支付通道原语并利用虚拟通道的设计思路，实现了多跳交易而不依赖时间锁。Thunderdome 依靠一组非可信的、被称为监护人的看守节点委员会，确保在通道关闭过程中，即使诚实方离线也不会损失资金。为了保证协议的正确执行，文章提出了定制化的激励机制。除了基于诚实多数委员会的传统安全性证明外，还进行了形式化的博弈论分析，以证明包括监护人在内的所有参与者理性行为下的 Thunderdome 的安全性。已在以太坊上实现了一个 Thunderdome 的概念验证版本，并对其成本进行了评估，结果表明部署 Thunderdome（包括开设底层支付通道）的成本约为 15 美元（0.0089 ETH），而最坏情况下关闭通道的成本约为 7 美元（0.004 ETH）。 <div>
arXiv:2501.14418v1 Announce Type: new 
Abstract: Payment channel networks (PCNs) offer a promising solution to address the limited transaction throughput of deployed blockchains. However, several attacks have recently been proposed that stress the vulnerability of PCNs to timelock and censoring attacks. To address such attacks, we introduce Thunderdome, the first timelock-free PCN. Instead, Thunderdome leverages the design rationale of virtual channels to extend a timelock-free payment channel primitive, thereby enabling multi-hop transactions without timelocks. Previous works either utilize timelocks or do not accommodate transactions between parties that do not share a channel.
  At its core, Thunderdome relies on a committee of non-trusted watchtowers, known as wardens, who ensure that no honest party loses funds, even when offline, during the channel closure process. We introduce tailored incentive mechanisms to ensure that all participants follow the protocol's correct execution. Besides a traditional security proof that assumes an honest majority of the committee, we conduct a formal game-theoretic analysis to demonstrate the security of Thunderdome when all participants, including wardens, act rationally. We implement a proof of concept of Thunderdome on Ethereum to validate its feasibility and evaluate its costs. Our evaluation shows that deploying Thunderdome, including opening the underlying payment channel, costs approximately \$15 (0.0089 ETH), while the worst-case cost for closing a channel is about \$7 (0.004 ETH).
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Optimization Methods for Training DL Models: Theoretical Perspective on Convergence and Generalization</title>
<link>https://arxiv.org/abs/2501.14458</link>
<guid>https://arxiv.org/abs/2501.14458</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、优化方法、理论基础、通用梯度法、分布式优化

<br /><br />总结:
本文详细概述了深度学习中优化方法的理论基础，重点关注各种优化算法的收敛性分析和泛化能力。内容涵盖了通用的梯度基 <div>
arXiv:2501.14458v1 Announce Type: new 
Abstract: As data sets grow in size and complexity, it is becoming more difficult to pull useful features from them using hand-crafted feature extractors. For this reason, deep learning (DL) frameworks are now widely popular. The Holy Grail of DL and one of the most mysterious challenges in all of modern ML is to develop a fundamental understanding of DL optimization and generalization. While numerous optimization techniques have been introduced in the literature to navigate the exploration of the highly non-convex DL optimization landscape, many survey papers reviewing them primarily focus on summarizing these methodologies, often overlooking the critical theoretical analyses of these methods. In this paper, we provide an extensive summary of the theoretical foundations of optimization methods in DL, including presenting various methodologies, their convergence analyses, and generalization abilities. This paper not only includes theoretical analysis of popular generic gradient-based first-order and second-order methods, but it also covers the analysis of the optimization techniques adapting to the properties of the DL loss landscape and explicitly encouraging the discovery of well-generalizing optimal points. Additionally, we extend our discussion to distributed optimization methods that facilitate parallel computations, including both centralized and decentralized approaches. We provide both convex and non-convex analysis for the optimization algorithms considered in this survey paper. Finally, this paper aims to serve as a comprehensive theoretical handbook on optimization methods for DL, offering insights and understanding to both novice and seasoned researchers in the field.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Conformal Prediction via Message Passing</title>
<link>https://arxiv.org/abs/2501.14544</link>
<guid>https://arxiv.org/abs/2501.14544</guid>
<content:encoded><![CDATA[
<div> 关键词: Post-hoc calibration, Conformal Prediction, Decentralized, Quantile-based Distributed Conformal Prediction, Histogram-based Distributed Conformal Prediction

总结:
本文关注于预训练模型的事后校准问题，特别是在医疗等安全关键领域中确保可靠的推断。文中提出了一种名为Conformal Prediction（CP）的鲁棒事后校准框架，它利用预留数据集提供预测集的分布自由统计覆盖保证。研究场景设定为分布式环境，每个设备仅有有限的校准数据，并只能与其邻居节点进行通信。为此，文章提出了两种基于消息传递的分布式符合预测方法：量值型分布式符合预测（Q-DCP）和直方图型分布式符合预测（H-DCP）。Q-DCP采用分布式量子回归并结合定制的平滑和正则化项以加速收敛；而H-DCP则运用共识基础的直方图估计方法。通过广泛的实验，文章探讨了不同网络拓扑下的超参数调整需求、通信开销、覆盖率保证以及预测集大小之间的权衡关系。 <div>
arXiv:2501.14544v1 Announce Type: new 
Abstract: Post-hoc calibration of pre-trained models is critical for ensuring reliable inference, especially in safety-critical domains such as healthcare. Conformal Prediction (CP) offers a robust post-hoc calibration framework, providing distribution-free statistical coverage guarantees for prediction sets by leveraging held-out datasets. In this work, we address a decentralized setting where each device has limited calibration data and can communicate only with its neighbors over an arbitrary graph topology. We propose two message-passing-based approaches for achieving reliable inference via CP: quantile-based distributed conformal prediction (Q-DCP) and histogram-based distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile regression enhanced with tailored smoothing and regularization terms to accelerate convergence, while H-DCP uses a consensus-based histogram estimation approach. Through extensive experiments, we investigate the trade-offs between hyperparameter tuning requirements, communication overhead, coverage guarantees, and prediction set sizes across different network topologies.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum Cyber-Attack on Blockchain-based VANET</title>
<link>https://arxiv.org/abs/2304.04411</link>
<guid>https://arxiv.org/abs/2304.04411</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、车联网、量子计算、量子攻击、RSA加密

总结:
区块链技术在车联网（VANET）中被视为安全通信架构的一种方式。然而，随着量子计算的发展，这种架构对网络攻击的脆弱性引起关注。本文研究了在基于区块链的VANET中的潜在威胁，并开发了一种相应的量子网络攻击方法——利用量子-Shor算法进行RSA加密数字签名的量子假冒攻击，破坏VANET的信任基础区块链方案。通过OMNET++、扩展的INET库、VEINS以及与仿真城市移动性（SUMO）相结合的方式，模拟了区块链为基础的VANET、车联万物（V2X）通信和车辆移动性。同时，使用IBM Qiskit实现了小密钥RSA消息加密。研究结果显示，量子假冒攻击能够成功打破基于区块链的VANET的信任链，强调了对于量子安全区块链的需求。 <div>
arXiv:2304.04411v2 Announce Type: replace 
Abstract: Blockchain-based Vehicular Ad-hoc Network (VANET) is widely considered as secure communication architecture for a connected transportation system. With the advent of quantum computing, there are concerns regarding the vulnerability of this architecture against cyber-attacks. In this study, a potential threat is investigated in a blockchain-based VANET, and a corresponding quantum cyber-attack is developed. Specifically, a quantum impersonation attack using Quantum-Shor algorithm is developed to break the Rivest-Shamir-Adleman (RSA) encrypted digital signatures of VANET and thus create a threat for the trust-based blockchain scheme of VANET. A blockchain-based VANET, vehicle-to-everything (V2X) communication, and vehicular mobility are simulated using OMNET++, the extended INET library, and vehicles-in-network simulation (VEINS) along with simulation of urban mobility (SUMO), respectively. A small key RSA based message encryption is implemented using IBM Qiskit, which is an open-source quantum software development kit. The findings reveal that the quantum cyber-attack, example, impersonation attack is able to successfully break the trust chain of a blockchain-based VANET. This highlights the need for a quantum secured blockchain.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Honeybee: Byzantine Tolerant Decentralized Peer Sampling with Verifiable Random Walks</title>
<link>https://arxiv.org/abs/2402.16201</link>
<guid>https://arxiv.org/abs/2402.16201</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、扩展性解决方案、随机采样、去中心化算法、Honeybee

总结:<br />
本文关注的是当今拥有数十万节点的流行区块链如何支持复杂的扩展性解决方案，如分片、数据可用性采样和二层方法。文章指出了在大规模区块链网络中构建健壮的对等(P2P)网络协议，尤其是实现分布式、均匀的随机节点采样这一基础能力的重要性。现有的采样算法（主要用于地址发现）依赖于分布式哈希表（如Kademlia）或邻居间共享地址（如GossipSub），但在Sybil攻击场景下并不安全。为此，文章提出了名为Honeybee的新型去中心化随机采样算法，该算法利用可验证的随机游走和节点一致性检查，即使在网络中存在大量拜占庭式恶意节点（例如，超过50%）的情况下也能保证安全性。实验结果显示，与现有最佳方案相比，Honeybee实现了显著更好的采样质量。Honeybee算法对于全节点和轻节点的网络设计具有重要影响。 <div>
arXiv:2402.16201v3 Announce Type: replace 
Abstract: Popular blockchains today have hundreds of thousands of nodes and need to be able to support sophisticated scaling solutions$\unicode{x2013}$such as sharding, data availability sampling, and layer-2 methods. Designing secure and efficient peer-to-peer (p2p) networking protocols at these scales to support the tight demands of the upper layer crypto-economic primitives is a highly non-trivial endeavor. We identify decentralized, uniform random sampling of nodes as a fundamental capability necessary for building robust p2p networks in emerging blockchain networks. Sampling algorithms used in practice today (primarily for address discovery) rely on either distributed hash tables (e.g., Kademlia) or sharing addresses with neighbors (e.g., GossipSub), and are not secure in a Sybil setting. We present Honeybee, a decentralized algorithm for sampling nodes that uses verifiable random walks and peer consistency checks. Honeybee is secure against attacks even in the presence of an overwhelming number of Byzantine nodes (e.g., $\geq50\%$ of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for network design in both full nodes and light nodes.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SRMT: Shared Memory for Multi-agent Lifelong Pathfinding</title>
<link>https://arxiv.org/abs/2501.13200</link>
<guid>https://arxiv.org/abs/2501.13200</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-agent Reinforcement Learning (MARL), Shared Recurrent Memory Transformer (SRMT), Cooperation, Bottleneck Navigation Task, POGEMA Benchmark

总结:
本文提出了一种名为共享循环记忆变换器（Shared Recurrent Memory Transformer, SRMT）的新方法，用于解决多智能体强化学习（Multi-agent Reinforcement Learning, MARL）中的合作问题。SRMT通过池化和全局广播个体工作内存的方式，使智能体能够隐式地交换信息并协调行动。在需要智能体合作通过狭窄走廊的Bottleneck导航任务中，SRMT在稀疏奖励条件下持续优于多种强化学习基线算法，并能有效泛化到比训练时更长的走廊场景。同时，在包括Mazes、Random和MovingAI在内的POGEMA基准集任务上，SRMT与其他近期的MARL、混合以及基于规划的算法表现相当。这一研究表明，在基于变压器的架构中融入共享循环记忆可以增强分布式多智能体系统的协调能力。实验代码已在GitHub上公开：https://github.com/Aloriosa/srmt。 <div>
arXiv:2501.13200v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) demonstrates significant progress in solving cooperative and competitive multi-agent problems in various environments. One of the principal challenges in MARL is the need for explicit prediction of the agents' behavior to achieve cooperation. To resolve this issue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends memory transformers to multi-agent settings by pooling and globally broadcasting individual working memories, enabling agents to exchange information implicitly and coordinate their actions. We evaluate SRMT on the Partially Observable Multi-Agent Pathfinding problem in a toy Bottleneck navigation task that requires agents to pass through a narrow corridor and on a POGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently outperforms a variety of reinforcement learning baselines, especially under sparse rewards, and generalizes effectively to longer corridors than those seen during training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is competitive with recent MARL, hybrid, and planning-based algorithms. These results suggest that incorporating shared recurrent memory into the transformer-based architectures can enhance coordination in decentralized multi-agent systems. The source code for training and evaluation is available on GitHub: https://github.com/Aloriosa/srmt.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Intrusion Detection in Dynamic Networks of UAVs using Few-Shot Federated Learning</title>
<link>https://arxiv.org/abs/2501.13213</link>
<guid>https://arxiv.org/abs/2501.13213</guid>
<content:encoded><![CDATA[
<div> 关键词: 飞行自组网(FANETs), 入侵检测, 联邦学习(FL), 少样本学习(FSL), FSFL-IDS

总结:<br />
针对飞行自组网(FANETs)中由无人机构成网络所带来的独特安全挑战，本文探讨了利用少样本学习(FSL)与联邦学习(FL)相结合的方法来有效降低入侵检测所需的数据量。为此，文章提出了一种名为FSFL-IDS的新方法，该方法旨在解决动态FANETs中的隐私保护、电力消耗、通信成本以及链路丢包等问题。FSFL-IDS通过结合FL和FSL，减少了局部模型及全局模型的训练时间和样本大小，从而降低了计算和通信成本并延长了电池寿命。此外，由于FSL对训练数据的需求较少，因此在网络链接不稳定的情况下，IDS受其影响的程度也会相应降低。 <div>
arXiv:2501.13213v1 Announce Type: new 
Abstract: Flying Ad Hoc Networks (FANETs), which primarily interconnect Unmanned Aerial Vehicles (UAVs), present distinctive security challenges due to their distributed and dynamic characteristics, necessitating tailored security solutions. Intrusion detection in FANETs is particularly challenging due to communication costs, and privacy concerns. While Federated Learning (FL) holds promise for intrusion detection in FANETs with its cooperative and decentralized model training, it also faces drawbacks such as large data requirements, power consumption, and time constraints. Moreover, the high speeds of nodes in dynamic networks like FANETs may disrupt communication among Intrusion Detection Systems (IDS). In response, our study explores the use of few-shot learning (FSL) to effectively reduce the data required for intrusion detection in FANETs. The proposed approach called Few-shot Federated Learning-based IDS (FSFL-IDS) merges FL and FSL to tackle intrusion detection challenges such as privacy, power constraints, communication costs, and lossy links, demonstrating its effectiveness in identifying routing attacks in dynamic FANETs.This approach reduces both the local models and the global model's training time and sample size, offering insights into reduced computation and communication costs and extended battery life. Furthermore, by employing FSL, which requires less data for training, IDS could be less affected by lossy links in FANETs.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Forecasting of Bitcoin Prices Using Hashrate Features: Wavelet and Deep Stacking Approach</title>
<link>https://arxiv.org/abs/2501.13136</link>
<guid>https://arxiv.org/abs/2501.13136</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字货币、比特币、价格预测、深度学习、堆叠技术

总结:
本文介绍了基于堆叠深度学习和小波去噪的比特币价格预测模型。该研究聚焦于数字货币中的热点——比特币的价格波动问题，提出了一种结合分类与回归的预测模型。在预处理阶段，应用了Chi2、RFE和嵌入式三种特征选择方法。模型利用深度学习（尤其是神经网络和变压器）进行一、七、三十和九十天的价格预测。实验结果显示，该模型对于下一天的价格预测准确率达到了63%，第七天、第三十天和第九十天分别达到64%、67%和82%。同时，对于每日价格预测，误差降低到0.58%，而对于七至九十天的预测误差则在2.72%至2.85%之间。这些结果表明，所提出的模型相比文献中其他模型具有更好的预测性能。 <div>
arXiv:2501.13136v1 Announce Type: cross 
Abstract: Digital currencies have become popular in the last decade due to their non-dependency and decentralized nature. The price of these currencies has seen a lot of fluctuations at times, which has increased the need for prediction. As their most popular, Bitcoin(BTC) has become a research hotspot. The main challenge and trend of digital currencies, especially BTC, is price fluctuations, which require studying the basic price prediction model. This research presents a classification and regression model based on stack deep learning that uses a wavelet to remove noise to predict movements and prices of BTC at different time intervals. The proposed model based on the stacking technique uses models based on deep learning, especially neural networks and transformers, for one, seven, thirty and ninety-day forecasting. Three feature selection models, Chi2, RFE and Embedded, were also applied to the data in the pre-processing stage. The classification model achieved 63\% accuracy for predicting the next day and 64\%, 67\% and 82\% for predicting the seventh, thirty and ninety days, respectively. For daily price forecasting, the percentage error was reduced to 0.58, while the error ranged from 2.72\% to 2.85\% for seven- to ninety-day horizons. These results show that the proposed model performed better than other models in the literature.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid Reactive Routing Protocol for Decentralized UAV Networks</title>
<link>https://arxiv.org/abs/2407.02929</link>
<guid>https://arxiv.org/abs/2407.02929</guid>
<content:encoded><![CDATA[
<div> 关键词: 无线网络、无人机、分布式、自适应路由协议、性能评估

总结:
该文针对由低功耗、小型无人机（FW-UAVs）组成的无线网络，提出了一种混合反应式路由协议。该协议旨在解决由于无人机动态轨迹和网络拓扑频繁变化导致的路径断裂问题，支持多流量并提供对移动性和拥塞感知的高质量路径。协议采取按需搜索路径并在选定路径周围监控区域（管道），在当前路径质量下降到阈值以下前主动切换至备用路线。文章通过实验评估了管道宽度和节点密度对找到替代优质路径及维持管道所需开销的影响。与现有反应式路由方案相比，该方法在不同交通负载、节点密度和速度下能实现更高吞吐量，降低路由发现次数、开销以及由此产生的流中断。尽管信息收集方式分布化，且具有低控制开销和路由计算复杂度，但此提议的方案在不同网络和交通设置下的性能优于预优化链路状态路由协议。此外，文中还比较了反应式和预测式路由方案的相对性能。<br /><br /> <div>
arXiv:2407.02929v2 Announce Type: replace 
Abstract: Wireless networks consisting of low SWaP, FW-UAVs are used in many applications, such as monitoring, search and surveillance of inaccessible areas. A decentralized and autonomous approach ensures robustness to failures; the UAVs explore and sense within the area and forward their information, in a multihop manner, to nearby aerial gateway nodes. However, the unpredictable nature of the events, relatively high speed of UAVs, and dynamic UAV trajectories cause the network topology to change significantly over time, resulting in frequent route breaks. A holistic routing approach is needed to support multiple traffic flows in these networks to provide mobility- and congestion-aware, high-quality routes when needed, with low control and computational overheads, using the information collected in a distributed manner. Existing routing schemes do not address all the mentioned issues.
  We present a hybrid reactive routing protocol for decentralized UAV networks. Our scheme searches routes on-demand, monitors a region around the selected route (the pipe), and proactively switches to an alternative route before the current route's quality degrades below a threshold. We empirically evaluate the impact of pipe width and node density on our ability to find alternate high-quality routes within the pipe and the overhead required to maintain the pipe. Compared to existing reactive routing schemes, our approach achieves higher throughput and reduces the number of route discoveries, overhead, and resulting flow interruptions at different traffic loads, node densities and speeds. Despite having limited network topology information, and low overhead and route computation complexity, our proposed scheme achieves superior throughput to proactive optimized link state routing scheme at different network and traffic settings. We also evaluate the relative performance of reactive and proactive routing schemes.
]]></content:encoded>
<pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimizing Blockchain Analysis: Tackling Temporality and Scalability with an Incremental Approach with Metropolis-Hastings Random Walks</title>
<link>https://arxiv.org/abs/2501.12491</link>
<guid>https://arxiv.org/abs/2501.12491</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、交易网络分析、图表示学习、动态学习、Metropolis-Hastings随机漫步

总结:<br />
本文针对区块链交易网络的数据分析，特别是其中的欺诈检测和市场监管等问题，指出现有方法存在的两个局限性：一是忽视了交易网络随时间演变的特性；二是对于大规模不断扩展的交易网络，现有方法可能缺乏高效的增量学习能力。为解决这些问题，文章提出了基于随机游走的节点表示学习的增量方法，并设计了一种改进效率的Metropolis-Hastings随机游走机制。实验证实在区块链交易数据集上的节点分类任务中，该方法表现出了可比的性能同时降低了计算开销。潜在应用包括交易网络监控、欺诈地址的有效分类以及网络中专业化地址类型的识别。 <div>
arXiv:2501.12491v1 Announce Type: new 
Abstract: Blockchain technology, with implications in the financial domain, offers data in the form of large-scale transaction networks. Analyzing transaction networks facilitates fraud detection, market analysis, and supports government regulation. Despite many graph representation learning methods for transaction network analysis, we pinpoint two salient limitations that merit more investigation. Existing methods predominantly focus on the snapshots of transaction networks, sidelining the evolving nature of blockchain transaction networks. Existing methodologies may not sufficiently emphasize efficient, incremental learning capabilities, which are essential for addressing the scalability challenges in ever-expanding large-scale transaction networks. To address these challenges, we employed an incremental approach for random walk-based node representation learning in transaction networks. Further, we proposed a Metropolis-Hastings-based random walk mechanism for improved efficiency. The empirical evaluation conducted on blockchain transaction datasets reveals comparable performance in node classification tasks while reducing computational overhead. Potential applications include transaction network monitoring, the efficient classification of blockchain addresses for fraud detection or the identification of specialized address types within the network.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Discrete Denoising Diffusion Model for Molecular Generation with OpenFL</title>
<link>https://arxiv.org/abs/2501.12523</link>
<guid>https://arxiv.org/abs/2501.12523</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型，药物设计，扩散模型，联邦学习，OpenFL<br /><br />总结:
在药物设计领域，生成具有理想生物化学性质的独特分子作为可行的药物候选物是一项艰巨任务。近年来，扩散模型在加速AI驱动的分子生成和药物设计过程中展现出巨大潜力。然而，训练这些模型需要大量的数据，而这些数据通常分散存储于私有数据库中。为了解决这一问题，本文介绍了一种使用OpenFL（一个开放的联邦学习框架）进行训练的联邦离散去噪扩散模型。该模型在保护数据隐私的同时，实现了分布式数据站点间的协同训练，并在生成分子的独特性和有效性评估上，其性能可与集中式数据训练的模型相媲美。这表明联邦学习可用于并有助于药物设计过程。OpenFL项目可在https://github.com/securefederatedai/openfl获取。 <div>
arXiv:2501.12523v1 Announce Type: new 
Abstract: Generating unique molecules with biochemically desired properties to serve as viable drug candidates is a difficult task that requires specialized domain expertise. In recent years, diffusion models have shown promising results in accelerating the drug design process through AI-driven molecular generation. However, training these models requires massive amounts of data, which are often isolated in proprietary silos. OpenFL is a federated learning framework that enables privacy-preserving collaborative training across these decentralized data sites. In this work, we present a federated discrete denoising diffusion model that was trained using OpenFL. The federated model achieves comparable performance with a model trained on centralized data when evaluating the uniqueness and validity of the generated molecules. This demonstrates the utility of federated learning in the drug design process.
  OpenFL is available at: https://github.com/securefederatedai/openfl
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mechanism Design for Blockchain Order Books against Selfish Miners</title>
<link>https://arxiv.org/abs/2501.12576</link>
<guid>https://arxiv.org/abs/2501.12576</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、交易费、自私矿工、社会福利、可调整区块大小机制

总结:
本文针对基于区块链的订单簿系统中矿工自私行为导致的社会福利损失问题进行了首次深入分析。研究发现，高交易费用的交易往往被优先处理，而忽略了可能提升社会福利的匹配。当前区块链机制对此未能有效应对。为此，文章提出了一种无需改变现有去中心化协议、易于实施的可调整区块大小机制，允许买家和卖家自由决定交易费以及矿工自我选择交易匹配。虽然纯策略纳什均衡并不总是存在，且系统设计者可能不了解每个买家或卖家的具体报价和交易量，但该机制仍能实现社会福利损失的优良界限。特别地，在非同质化代币（NFT）的同量化数量交易场景下，其价格博弈论中的效率损失为零，即无社会福利损失。实验在本地以太坊实例上验证了该机制的可行性，并通过真实数据集表明，对于比特币等异量化数量交易，相比于现有的订单簿基准，该机制可以将社会福利提升至最多3.7倍，同时展现出对买家和卖家随机变化的良好鲁棒性。 <div>
arXiv:2501.12576v1 Announce Type: new 
Abstract: In blockchain-based order book systems, buyers and sellers trade assets, while it is miners to match them and include their transactions in the blockchain. It is found that many miners behave selfishly and myopically, prioritizing transactions with high fees and ignoring many desirable matches that could enhance social welfare. Existing blockchain mechanisms fail to address this issue by overlooking miners' selfish behaviors. To our best knowledge, this work presents the first analytical study to quantify and understand buyer and seller transaction fee choices and selfish miners' transaction matching strategies, proving an infinitely large price of anarchy (PoA) for social welfare loss. To mitigate this, we propose an adjustable block size mechanism that is easy to implement without altering the existing decentralized protocols and still allows buyers and sellers to freely decide transaction fees and miners to selfishly match. The analysis is challenging, as pure strategy Nash equilibria do not always exist, requiring the analysis of many buyers' or sellers' interactive mixed-strategy distributions. Moreover, the system designer may even lack information about each buyer's or seller's bid/ask prices and trading quantities. Nevertheless, our mechanism achieves a well-bounded PoA, and under the homogeneous-quantity trading for non-fungible tokens (NFT), it attains a PoA of 1 with no social welfare loss. We implement our mechanism on a local instance of Ethereum to demonstrate the feasibility of our approach. Experiments based on the realistic dataset demonstrate that our mechanism achieves social optimum for homogeneous-quantity trading like NFT. It can enhance social welfare up to 3.7 times compared to the existing order book benchmarks for heterogeneous-quantity trading of Bitcoin tokens. It exhibits robustness against random variations in buyers and sellers.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Does multi-block MEV exist? Analysis of 2 years of MEV Data</title>
<link>https://arxiv.org/abs/2501.12827</link>
<guid>https://arxiv.org/abs/2501.12827</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum合并、MEV、多块套利、MEV-Boost支付、建设者

总结:
<br />
本文针对2022年9月Ethereum合并后的提议者-建设者数据和MEV-Boost支付数据进行了分析，研究多块MEV的模式。研究发现实际的连续建设者序列少于随机蒙特卡洛模拟预测的数量，观察到最长的序列跨度为25个槽位。同时，随着连续序列长度的增长，平均MEV-Boost支付也增加，从单槽位的约0.05 ETH增长至九连贯槽位的约0.08 ETH。在较长序列中，每槽位的支付略有上升，表明建设者可能对更长序列或长期序列后的第一个槽位出价更高。此外，研究还发现相邻MEV-Boost支付间存在弱正自相关性，这与低高MEV交替发生的假设相矛盾。最后，对比低和高基本费用波动时期的建设者行为显示，两者之间几乎没有相关性，意味着建设者并未根据基础费用波动进行专业化分工。 <div>
arXiv:2501.12827v1 Announce Type: new 
Abstract: This study analyzes proposer-builder data and MEV-Boost payment data following the Ethereum merge in September 2022 to identify patterns of multi-block MEV. Our findings reveal fewer multi-slot sequences of builders than predicted by a random Monte Carlo simulation, with the longest observed sequence spanning 25 slots. Additionally, we observe that average MEV-Boost payments increase with the length of consecutive sequences, from approximately 0.05 ETH for single slots to 0.08 ETH for nine consecutive slots. Within longer sequences, payments per slot show a slight increase, suggesting that builders bid higher for longer sequences or the first slot after a longer sequence. A weak positive autocorrelation is found between subsequent MEV-Boost payments, challenging the hypothesis of alternating periods of low and high MEV. Finally, our comparison of builders during periods of low and high base fee volatility reveals minimal correlation, indicating the absence of builder specialization based on base fee volatility.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning</title>
<link>https://arxiv.org/abs/2501.12911</link>
<guid>https://arxiv.org/abs/2501.12911</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、加密、同态加密、差分隐私、位混淆<br /><br />总结:
本文提出了一种名为FAS（快速且安全的联邦学习）的新方法，用于提高医疗影像数据上的深度学习模型训练过程中的数据安全性与执行性能。FAS结合了选择性加密、同态加密、差分隐私和位混淆技术，有效减少了数据泄漏风险。研究团队使用Flower框架实现了这一方法并与一种采用选择性同态加密的主流联邦学习方法进行了对比。实验在一个由十一台物理机器组成的集群上进行，模拟真实世界的联邦学习场景并使用了不同的数据集。结果显示，相比于全同态加密，FAS方法的速度提高了最多90%，并且可以省去竞争对手所需的预训练步骤，从而节省了高达20%的总执行时间。同时，尽管FAS方法速度更快，但其在安全性方面表现与竞争对手相当。 <div>
arXiv:2501.12911v1 Announce Type: new 
Abstract: Federated learning is a machine learning method that supports training models on decentralized devices or servers, where each holds its local data, removing the need for data exchange. This approach is especially useful in healthcare, as it enables training on sensitive data without needing to share them. The nature of federated learning necessitates robust security precautions due to data leakage concerns during communication. To address this issue, we propose a new approach that employs selective encryption, homomorphic encryption, differential privacy, and bit-wise scrambling to minimize data leakage while achieving good execution performance. Our technique , FAS (fast and secure federated learning) is used to train deep learning models on medical imaging data. We implemented our technique using the Flower framework and compared with a state-of-the-art federated learning approach that also uses selective homomorphic encryption. Our experiments were run in a cluster of eleven physical machines to create a real-world federated learning scenario on different datasets. We observed that our approach is up to 90\% faster than applying fully homomorphic encryption on the model weights. In addition, we can avoid the pretraining step that is required by our competitor and can save up to 20\% in terms of total execution time. While our approach was faster, it obtained similar security results as the competitor.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Accessible Smart Contracts Verification: Synthesizing Formal Models with Tamed LLMs</title>
<link>https://arxiv.org/abs/2501.12972</link>
<guid>https://arxiv.org/abs/2501.12972</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、信任less、形式化方法、模型综合、智能合约

总结:<br />
本文关注于降低使用形式化方法进行区块链软件（特别是智能合约）正确性审计的时间和门槛。文章提出了一个自动化创建正式模型的方法，该方法分为三个阶段：首先将代码转换为模型存根；然后利用大规模语言模型填充细节；最后，通过迭代修复生成的模型，从语法和语义层面确保其准确性。这样做的目的是显著减少构建正式模型所需的时间，提高依赖这些模型的软件验证方法的可访问性，从而在实际应用中加速利用形式化方法对智能合约正确性审计的价值实现。 <div>
arXiv:2501.12972v1 Announce Type: new 
Abstract: When blockchain systems are said to be trustless, what this really means is that all the trust is put into software. Thus, there are strong incentives to ensure blockchain software is correct -- vulnerabilities here cost millions and break businesses. One of the most powerful ways of establishing software correctness is by using formal methods. Approaches based on formal methods, however, induce a significant overhead in terms of time and expertise required to successfully employ them. Our work addresses this critical disadvantage by automating the creation of a formal model -- a mathematical abstraction of the software system -- which is often a core task when employing formal methods. We perform model synthesis in three phases: we first transpile the code into model stubs; then we "fill in the blanks" using a large language model (LLM); finally, we iteratively repair the generated model, on both syntactical and semantical level. In this way, we significantly reduce the amount of time necessary to create formal models and increase accessibility of valuable software verification methods that rely on them. The practical context of our work was reducing the time-to-value of using formal models for correctness audits of smart contracts.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Offline Multi-Agent Reinforcement Learning Framework for Radio Resource Management</title>
<link>https://arxiv.org/abs/2501.12991</link>
<guid>https://arxiv.org/abs/2501.12991</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线多智能体强化学习 (MARL)、离线多智能体强化学习 (offline MARL)、无线资源管理 (RRM)、集中式训练、分布式执行 (CTDE)

总结:
本文提出了一种针对无线网络中无线电资源管理的离线多智能体强化学习算法，旨在优化多个接入点的调度策略以同时最大化用户设备的总和及尾部速率。文章对比了三种训练范式：集中式、独立式以及集中式训练与分布式执行（CTDE）。模拟结果显示，所提出的离线MARL框架优于传统基线方法，能实现对总和及尾部速率加权组合超过15%的提升。此外，CTDE框架在降低集中式方法计算复杂度的同时，也解决了独立训练的低效率问题，彰显了离线MARL在动态无线网络资源管理中提供可扩展、健壮且高效解决方案的潜力。 <div>
arXiv:2501.12991v1 Announce Type: new 
Abstract: Offline multi-agent reinforcement learning (MARL) addresses key limitations of online MARL, such as safety concerns, expensive data collection, extended training intervals, and high signaling overhead caused by online interactions with the environment. In this work, we propose an offline MARL algorithm for radio resource management (RRM), focusing on optimizing scheduling policies for multiple access points (APs) to jointly maximize the sum and tail rates of user equipment (UEs). We evaluate three training paradigms: centralized, independent, and centralized training with decentralized execution (CTDE). Our simulation results demonstrate that the proposed offline MARL framework outperforms conventional baseline approaches, achieving over a 15\% improvement in a weighted combination of sum and tail rates. Additionally, the CTDE framework strikes an effective balance, reducing the computational complexity of centralized methods while addressing the inefficiencies of independent training. These results underscore the potential of offline MARL to deliver scalable, robust, and efficient solutions for resource management in dynamic wireless networks.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Practical quantum federated learning and its experimental demonstration</title>
<link>https://arxiv.org/abs/2501.12709</link>
<guid>https://arxiv.org/abs/2501.12709</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、量子增强、隐私保护、分布式量子秘密钥匙、实验验证

<br /><br />总结:
本文提出了一种针对量子计算时代的实用量子联邦学习框架，该框架在量子网络上运行，利用分布式量子秘密钥匙来保护局部模型更新并实现信息论意义上的安全聚合。文章在具有可扩展结构的4客户端量子网络上实验验证了该框架，并通过大量数值实验展示了在量子和经典数据集上的性能提升——特别是对于多体纠缠和非稳定器量子数据集分类能力的显著增强。此外，模拟实验还表明，当应用于包含200个客户端的经典模型（训练MNIST数据集）时，通过先进的模型压缩技术，可以将通信成本降低75%，同时实现快速的训练收敛性。这项工作为构建可扩展、高效且具备量子安全性的机器学习系统，迎接即将到来的量子互联网时代提供了关键洞见。 <div>
arXiv:2501.12709v1 Announce Type: cross 
Abstract: Federated learning is essential for decentralized, privacy-preserving model training in the data-driven era. Quantum-enhanced federated learning leverages quantum resources to address privacy and scalability challenges, offering security and efficiency advantages beyond classical methods. However, practical and scalable frameworks addressing privacy concerns in the quantum computing era remain undeveloped. Here, we propose a practical quantum federated learning framework on quantum networks, utilizing distributed quantum secret keys to protect local model updates and enable secure aggregation with information-theoretic security. We experimentally validate our framework on a 4-client quantum network with a scalable structure. Extensive numerical experiments on both quantum and classical datasets show that adding a quantum client significantly enhances the trained global model's ability to classify multipartite entangled and non-stabilizer quantum datasets. Simulations further demonstrate scalability to 200 clients with classical models trained on the MNIST dataset, reducing communication costs by $75\%$ through advanced model compression techniques and achieving rapid training convergence. Our work provides critical insights for building scalable, efficient, and quantum-secure machine learning systems for the coming quantum internet era.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Blocklace: A Byzantine-repelling and Universal Conflict-free Replicated Data Type</title>
<link>https://arxiv.org/abs/2402.08068</link>
<guid>https://arxiv.org/abs/2402.08068</guid>
<content:encoded><![CDATA[
<div> 关键词：Conflict-free Replicated Data Types (CRDTs)，Byzantine环境，Blocklace，CRDT协议，拜占庭节点检测

总结:
本文介绍了基于内容哈希的DAG结构在拜占庭环境中实现冲突无虞复制数据类型（CRDTs）的最新进展。文章重点讨论了Blocklace——一种部分有序的区块链泛化结构，其中每个区块可以有任意数量的签名哈希指针指向先前的区块。研究发现，仅通过添加单个块的操作，Blocklace即可被证明是一种CRDT：它既是具有自我标记的纯操作型CRDT，也是通用delta状态CRDT的一种形式。此外，Blocklace还可以被视为一种能实现任意CRDT的通用拜占庭容错方案。当前方法对CRDT收敛的关注仅限于容忍equivocation（不检测或阻止equivocations），允许拜占庭节点通过引入无限数量的equivocations来污染CRDT状态。而文章表明，Blocklace不仅可以以equivocation-tolerant的方式使用，还能用于检测并最终排除包括equivocator在内的拜占庭节点，即使存在不可检测的合谋者也是如此。Blocklace CRDT协议确保了拜占庭节点只能对计算的有限前缀造成损害。<br /><br /> <div>
arXiv:2402.08068v4 Announce Type: replace 
Abstract: Conflict-free Replicated Data Types (CRDTs) are designed for replica convergence without global coordination or consensus. Recent work has achieved the same in a Byzantine environment, through DAG-like structures based on cryptographic hashes of content. The blocklace is a partially-ordered generalization of the blockchain in which each block has any finite number of signed hash pointers to preceding blocks. We show that the blocklace datatype, with the sole operation of adding a single block, is a CRDT: it is both a pure operation-based CRDT, with self-tagging; and a delta-state CRDT, under a slight generalization of the delta framework. Allowing arbitrary values as payload, the blocklace can also be seen as a universal Byzantine fault-tolerant implementation for arbitrary CRDTs, under the operation-based approach. Current approaches only care about CRDT convergence, being equivocation-tolerant (they do not detect or prevent equivocations), allowing a Byzantine node to cause an arbitrary amount of harm by polluting the CRDT state with an unbounded number of equivocations. We show that the blocklace can be used not only in an equivocation-tolerant way, but also so as to detect and eventually exclude Byzantine nodes, including equivocators, even under the presence of undetectable colluders. The blocklace CRDT protocol ensures that a Byzantine node may harm only a finite prefix of the computation.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Implementation Study of Cost-Effective Verification for Pietrzak's Verifiable Delay Function in Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2405.06498</link>
<guid>https://arxiv.org/abs/2405.06498</guid>
<content:encoded><![CDATA[
<div> 关键词: Verifiable Delay Function (可验证延迟函数), Pietrzak VDF, Ethereum Virtual Machine (以太坊虚拟机), gas成本, 优化

总结:
本文针对区块链环境中的Verifiable Delay Function（VDF），特别是Pietrzak提出的VDF协议进行了实施研究。研究发现，通过深入理解Pietrzak原始论文中的讨论，在以太坊虚拟机（EVM）上可以实现该VDF协议的清晰优化。结果显示，VDF验证的成本从原本的4M gas降低到了2M gas，同时使用2048位RSA密钥长度的情况下，证明长度能被控制在8 KB以内，远小于先前预期，实现了显著的优化效果。 <div>
arXiv:2405.06498v5 Announce Type: replace 
Abstract: Verifiable Delay Function (VDF) is a cryptographic concept that ensures a minimum delay before output through sequential processing, which is resistant to parallel computing. One of the significant VDF protocols academically reviewed is the VDF protocol proposed by Pietrzak. However, for the blockchain environment, the Pietrzak VDF has drawbacks including long proof size and recursive protocol computation. In this paper, we present an implementation study of Pietrzak VDF verification on Ethereum Virtual Machine (EVM). We found that the discussion in the Pietrzak's original paper can help a clear optimization in EVM where the costs of computation are predefined as the specific amounts of gas. In our results, the cost of VDF verification can be reduced from 4M to 2M gas, and the proof length can be generated under 8 KB with the 2048-bit RSA key length, which is much smaller than the previous expectation.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MicroPython Testbed for Federated Learning Algorithms</title>
<link>https://arxiv.org/abs/2405.09423</link>
<guid>https://arxiv.org/abs/2405.09423</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2405.09423v2, Python Testbed, Federated Learning, MicroPython Testbed, Edge Systems

总结:
本文介绍了arXiv:2405.09423v2版本的论文内容，该文提出了一种新的框架——MicroPython Testbed for Federated Learning Algorithms。这个框架是对原有Python Testbed的改进，克服了其只能在同一台PC上运行应用实例的局限性，使得各个应用实例可以在不同的网络节点（如PC和IoT设备）上独立运行，特别是在边缘系统中。新框架依然坚持纯Python编程，并基于异步I/O抽象，同时支持MicroPython，因此非常适合于物联网设备和边缘系统的硬件。通过在由PC和Raspberry Pi Pico W板组成的无线网络上进行实验验证，证明了新框架的有效性，实验使用了原先是为旧框架开发的应用示例。 <div>
arXiv:2405.09423v2 Announce Type: replace 
Abstract: Recently, Python Testbed for Federated Learning Algorithms emerged as a low code and generative large language models amenable framework for developing decentralized and distributed applications, primarily targeting edge systems, by nonprofessional programmers with the help of emerging artificial intelligence tools. This light framework is written in pure Python to be easy to install and to fit into a small IoT memory. It supports formally verified generic centralized and decentralized federated learning algorithms, as well as the peer-to-peer data exchange used in time division multiplexing communication, and its current main limitation is that all the application instances can run only on a single PC. This paper presents the MicroPyton Testbed for Federated Learning Algorithms, the new framework that overcomes its predecessor's limitation such that individual application instances may run on different network nodes like PCs and IoTs, primarily in edge systems. The new framework carries on the pure Python ideal, is based on asynchronous I/O abstractions, and runs on MicroPython, and therefore is a great match for IoTs and devices in edge systems. The new framework was experimentally validated on a wireless network comprising PCs and Raspberry Pi Pico W boards, by using application examples originally developed for the predecessor framework.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GTDE: Grouped Training with Decentralized Execution for Multi-agent Actor-Critic</title>
<link>https://arxiv.org/abs/2501.10367</link>
<guid>https://arxiv.org/abs/2501.10367</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、分散训练与执行（DTDE）、集中训练分散执行（CTDE）、分组训练分散执行（GTDE）、Gumbel-Sigmoid

总结:<br />
本文提出了一种新的多智能体强化学习训练范式——分组训练分散执行（GTDE），用于解决随着智能体数量增加导致的性能下降问题。与DTDE和CTDE相比，GTDE不需要中心化模块，仅依赖局部信息，适应大规模多智能体系统的训练需求。具体来说，GTDE引入了自适应分组模块，根据观察历史将每个智能体划分为不同组，并采用Gumbel-Sigmoid实现点对点采样以及确保梯度反传。针对组内成员数量不确定性，文章提出了两种方法实现组信息聚合模块，整合组内成员信息。实验证明，在拥有495个智能体的合作环境中，GTDE相比于基线平均提高了382%的总奖励；在具有64个智能体的竞争环境中，GTDE实现了对基线的100%胜率。 <div>
arXiv:2501.10367v1 Announce Type: new 
Abstract: The rapid advancement of multi-agent reinforcement learning (MARL) has given rise to diverse training paradigms to learn the policies of each agent in the multi-agent system. The paradigms of decentralized training and execution (DTDE) and centralized training with decentralized execution (CTDE) have been proposed and widely applied. However, as the number of agents increases, the inherent limitations of these frameworks significantly degrade the performance metrics, such as win rate, total reward, etc. To reduce the influence of the increasing number of agents on the performance metrics, we propose a novel training paradigm of grouped training decentralized execution (GTDE). This framework eliminates the need for a centralized module and relies solely on local information, effectively meeting the training requirements of large-scale multi-agent systems. Specifically, we first introduce an adaptive grouping module, which divides each agent into different groups based on their observation history. To implement end-to-end training, GTDE uses Gumbel-Sigmoid for efficient point-to-point sampling on the grouping distribution while ensuring gradient backpropagation. To adapt to the uncertainty in the number of members in a group, two methods are used to implement a group information aggregation module that merges member information within the group. Empirical results show that in a cooperative environment with 495 agents, GTDE increased the total reward by an average of 382\% compared to the baseline. In a competitive environment with 64 agents, GTDE achieved a 100\% win rate against the baseline.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Societal Implications of Blockchain Technology in the Evolution of Humanity as a "Superorganism"</title>
<link>https://arxiv.org/abs/2501.10378</link>
<guid>https://arxiv.org/abs/2501.10378</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、加密资产、超级生物体、全球脑理论、分布式决策

总结:<br />
本文探讨了区块链技术和加密资产对社会的广泛影响，强调它们在人类演进为具有去中心化、自我调节系统的“超级生物体”过程中的作用。文章将区块链技术置于治理系统和全球经济体系（如金融系统）演变的背景下进行分析，并结合Nate Hagens的“超级生物体”理念与Francis Heylighen的“全球脑”理论。区块链的去中心化特性，连同人工智能和去中心化自治组织(DAOs)等进展，有可能重塑传统的金融、经济和治理结构，通过推动集体分布式决策和全球协调机制的出现来实现这一变革。同时，文章还将区块链的影响与Spiral Dynamics等发展理论相结合，说明区块链有可能促进社会超越层级模式的发展，推动从集中式权威向协作和自我治理社区的转变。综上所述，本文认为区块链不仅仅是一种经济工具，更是一种催化社会进化为成熟互联的全球行星有机体的力量。 <div>
arXiv:2501.10378v1 Announce Type: new 
Abstract: This article examines the broader societal implications of blockchain technology and crypto-assets, emphasizing their role in the evolution of humanity as a "superorganism" with decentralized, self-regulating systems. Drawing on interdisciplinary concepts such as Nate Hagens' "superorganism" idea and Francis Heylighen's "global brain" theory, the paper contextualizes blockchain technology within the ongoing evolution of governance systems and global systems such as the financial system. Blockchain's decentralized nature, in conjunction with advancements like artificial intelligence and decentralized autonomous organizations (DAOs), could transform traditional financial, economic, and governance structures by enabling the emergence of collective distributed decision-making and global coordination. In parallel, the article aligns blockchain's impact with developmental theories such as Spiral Dynamics. This framework is used to illustrate blockchain's potential to foster societal growth beyond hierarchical models, promoting a shift from centralized authority to collaborative and self-governed communities. The analysis provides a holistic view of blockchain as more than an economic tool, positioning it as a catalyst for the evolution of society into a mature, interconnected global planetary organism.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GLow -- A Novel, Flower-Based Simulated Gossip Learning Strategy</title>
<link>https://arxiv.org/abs/2501.10463</link>
<guid>https://arxiv.org/abs/2501.10463</guid>
<content:encoded><![CDATA[
<div> 关键词：Gossip Learning、Flower Framework、GLow、模拟、准确性

总结:
本文介绍了针对完全去中心化学习算法的研究现状，提出了一种新的方法——GLow。GLow利用先进的Flower框架，使研究人员能够模拟定制化的Gossip Learning系统，并在自定义网络拓扑结构上评估设备的可扩展性和收敛性，从而在实际部署前进行预测试。由于Flower框架原本只支持单纯的联邦学习策略，而不具备无中心权威机构的模拟功能，因此GLow被引入以填补这一空白。实验结果显示，GLow在MNIST和CIFAR10数据集上的准确率分别超过0.98和0.75，并在所有设计的实验中，其精度和收敛性与相应的集中式和联邦学习方法表现相当。 <div>
arXiv:2501.10463v1 Announce Type: new 
Abstract: Fully decentralized learning algorithms are still in an early stage of development. Creating modular Gossip Learning strategies is not trivial due to convergence challenges and Byzantine faults intrinsic in systems of decentralized nature. Our contribution provides a novel means to simulate custom Gossip Learning systems by leveraging the state-of-the-art Flower Framework. Specifically, we introduce GLow, which will allow researchers to train and assess scalability and convergence of devices, across custom network topologies, before making a physical deployment. The Flower Framework is selected for being a simulation featured library with a very active community on Federated Learning research. However, Flower exclusively includes vanilla Federated Learning strategies and, thus, is not originally designed to perform simulations without a centralized authority. GLow is presented to fill this gap and make simulation of Gossip Learning systems possible. Results achieved by GLow in the MNIST and CIFAR10 datasets, show accuracies over 0.98 and 0.75 respectively. More importantly, GLow performs similarly in terms of accuracy and convergence to its analogous Centralized and Federated approaches in all designed experiments.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Zaptos: Towards Optimal Blockchain Latency</title>
<link>https://arxiv.org/abs/2501.10612</link>
<guid>https://arxiv.org/abs/2501.10612</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链延迟、端到端、Zaptos、并行管道架构、Aptos区块链

总结:

本文关注的是区块链系统的端到端延迟问题，指出现有研究主要集中在优化拜占庭容错共识组件的延迟上。为此，文章提出了Zaptos，这是一种旨在最小化端到端延迟的同时保持高吞吐量的并行管道架构。Zaptos已被实现并在与Aptos区块链的分布式环境中进行了对比评估，结果显示在低负载下，Zaptos可降低25%的延迟，而在高负载下则能降低超过40%的延迟。尤其值得一提的是，Zaptos实现了每秒处理2万笔交易，并具有亚秒级延迟，其性能在具有亚秒级延迟的区块链系统中提升了整整一个数量级。 <div>
arXiv:2501.10612v1 Announce Type: new 
Abstract: End-to-end blockchain latency has become a critical topic of interest in both academia and industry. However, while modern blockchain systems process transactions through multiple stages, most research has primarily focused on optimizing the latency of the Byzantine Fault Tolerance consensus component.
  In this work, we identify key sources of latency in blockchain systems and introduce Zaptos, a parallel pipelined architecture designed to minimize end-to-end latency while maintaining the high-throughput of pipelined blockchains.
  We implemented Zaptos and evaluated it against the pipelined architecture of the Aptos blockchain in a geo-distributed environment. Our evaluation demonstrates a 25\% latency reduction under low load and over 40\% reduction under high load. Notably, Zaptos achieves a throughput of 20,000 transactions per second with sub-second latency, surpassing previously reported blockchain throughput, with sub-second latency, by an order of magnitude.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graph Coloring to Reduce Computation Time in Prioritized Planning</title>
<link>https://arxiv.org/abs/2501.10812</link>
<guid>https://arxiv.org/abs/2501.10812</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体路径规划、优先级规划、有向无环图、最长路径、图着色算法

总结:<br />
本文探讨了在大规模网络中通过优先级规划（PP）策略将计算任务分配给多个智能体以降低多智能体路径规划（MAPF）的计算成本。文章关注于PP中的交互代理优先级设定，利用有向无环图（DAG）刻画这种交互关系，其中计算时间主要取决于该DAG中最长路径的长度。针对已有文献中多种多样且追求不同目标的优先级设定方法，文章提出了一种用于减少耦合DAG中最长路径长度以及因此降低使用PP求解MAPF问题的时间的优先级确定新方法。作者证明此问题可以映射为图着色问题，所需的颜色数量对应于耦合DAG中最长路径的长度。进而，他们提出了一个分布式图着色算法来确定各智能体的优先级。最后，通过将其应用于道路环境中采用MAPF变体的连接和自动化车辆（CAVs）的多智能体运动规划（MAMP）进行评估。 <div>
arXiv:2501.10812v1 Announce Type: new 
Abstract: Distributing computations among agents in large networks reduces computational effort in multi-agent path finding (MAPF). One distribution strategy is prioritized planning (PP). In PP, we couple and prioritize interacting agents to achieve a desired behavior across all agents in the network. We characterize the interaction with a directed acyclic graph (DAG). The computation time for solving MAPF problem using PP is mainly determined through the longest path in this DAG. The longest path depends on the fixed undirected coupling graph and the variable prioritization. The approaches from literature to prioritize agents are numerous and pursue various goals. This article presents an approach for prioritization in PP to reduce the longest path length in the coupling DAG and thus the computation time for MAPF using PP. We prove that this problem can be mapped to a graph-coloring problem, in which the number of colors required corresponds to the longest path length in the coupling DAG. We propose a decentralized graph-coloring algorithm to determine priorities for the agents. We evaluate the approach by applying it to multi-agent motion planning (MAMP) for connected and automated vehicles (CAVs) on roads using, a variant of MAPF.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Selfish Mining Analysis for DAG-based PoW Consensus Protocols</title>
<link>https://arxiv.org/abs/2501.10888</link>
<guid>https://arxiv.org/abs/2501.10888</guid>
<content:encoded><![CDATA[
<div> 关键词:自私挖矿、Markov决策过程、协议设计、DAG、自动分析工具

总结:
本文研究了在工作量证明协议中的一种策略性违规行为——自私挖矿。文章指出，现有的Markov决策过程（MDP）主要用于分析比特币等线性链协议，而对于采用DAG结构的新型协议，MDP分析变得更为复杂。为解决这个问题，研究者们以往针对每个具体协议定制特殊的MDP模型，导致协议设计的反馈循环较长。因此，该文提出了一种通用攻击模型，能够覆盖包括以太坊工作量证明、GhostDAG和并行工作量证明等多种协议。其方法具有模块化特点：将每种协议简洁地定义为程序，并通过工具自动生成及求解自私挖矿的MDP，从而简化了协议修改带来的分析工作。 <div>
arXiv:2501.10888v1 Announce Type: new 
Abstract: Selfish mining is strategic rule-breaking to maximize rewards in proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred tool for finding optimal strategies in Bitcoin and similar linear chain protocols. Protocols increasingly adopt DAG-based chain structures, for which MDP analysis is more involved. To date, researchers have tailored specific MDPs for each protocol. Protocol design suffers long feedback loops, as each protocol change implies manual work on the MDP. To overcome this, we propose a generic attack model that covers a wide range of protocols, including Ethereum Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular: we specify each protocol as a concise program, and our tooling then derives and solves the selfish mining MDP automatically.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SLVC-DIDA: Signature-less Verifiable Credential-based Issuer-hiding and Multi-party Authentication for Decentralized Identity</title>
<link>https://arxiv.org/abs/2501.11052</link>
<guid>https://arxiv.org/abs/2501.11052</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Identity (DID)，Verifiable Credential (VC)，Permanent Issuer-Hiding (PIH)，Signature-less VC模型，SLVC-DIDA

<br /><br />总结：
本文提出了一种名为SLVC-DIDA的基于永久发行者隐藏（PIH）的DID多 party认证框架，该框架采用无签名的VC模型，旨在解决现有DID方案依赖分布式公钥基础设施所引发的问题，如上下文信息推断、密钥暴露和发行人数据泄露。SLVC-DIDA通过使用哈希和发行人成员身份证明避免了对签名密钥的依赖，支持通用零知识多 party DID认证，无需额外的技术集成。它利用零知识RSA累加器保持发行人集的匿名性，并通过Merkle树为基础的VC列表保护身份属性隐私。此外，SLVC-DIDA完全去中心化地实现DID的颁发与验证，并通过实施零知识的发行人集和VC列表保证PIH，从而有效缓解密钥泄漏和上下文推理攻击的风险。实验结果进一步验证了SLVC-DIDA的有效性和实用性。 <div>
arXiv:2501.11052v1 Announce Type: new 
Abstract: As an emerging paradigm in digital identity, Decentralized Identity (DID) appears advantages over traditional identity management methods in a variety of aspects, e.g., enhancing user-centric online services and ensuring complete user autonomy and control. Verifiable Credential (VC) techniques are used to facilitate decentralized DID-based access control across multiple entities. However, existing DID schemes generally rely on a distributed public key infrastructure that also causes challenges, such as context information deduction, key exposure, and issuer data leakage. To address the issues above, this paper proposes a Permanent Issuer-Hiding (PIH)-based DID multi-party authentication framework with a signature-less VC model, named SLVC-DIDA, for the first time. Our proposed scheme avoids the dependence on signing keys by employing hashing and issuer membership proofs, which supports universal zero-knowledge multi-party DID authentications, eliminating additional technical integrations. We adopt a zero-knowledge RSA accumulator to maintain the anonymity of the issuer set, thereby enabling public verification while safeguarding the privacy of identity attributes via a Merkle tree-based VC list. By eliminating reliance on a Public Key Infrastructure (PKI), SLVC-DIDA enables fully decentralized issuance and verification of DIDs. Furthermore, our scheme ensures PIH through the implementation of the zero-knowledge Issuer set and VC list, so that the risks of key leakage and contextual inference attacks are effectively mitigated. Our experiments further evaluate the effectiveness and practicality of SLVC-DIDA.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bitcoin: A Non-Continuous Time System</title>
<link>https://arxiv.org/abs/2501.11091</link>
<guid>https://arxiv.org/abs/2501.11091</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、区块链、非连续时间系统、块生成过程、分叉与回滚、交易重排序、未来影响

<br /><br />总结:
本文探讨了比特币区块链中的时间概念，该系统作为一个非连续时间系统运行。文章重点关注三个方面：随机和分布式的区块生成过程导致的时间不连贯性；区块链可能出现的分叉和回滚现象，这会打乱其线性发展进程；以及在这个系统中，受到可能的重新排序或无效化的交易性质。这些因素共同构建了一个与传统计算和物理学中常见的连续线性时间系统根本不同的时间结构。此外，文章还讨论了这种非连续时间模型对未来去中心化技术及其潜在应用的影响。 <div>
arXiv:2501.11091v1 Announce Type: new 
Abstract: In this paper, we explore the concept of time within Bitcoin's blockchain, which operates as a non-continuous time system. We focus on three core aspects that contribute to Bitcoin's time discontinuity: the random and distributed block generation process, the occurrence of forks and rollbacks that disrupt the linear progression of the blockchain, and the nature of transactions within this system, which are subject to potential reordering or invalidation. These elements combine to create a time structure in Bitcoin that is fundamentally different from the continuous, linear time systems typically seen in traditional computing and physics. Additionally, the implications of this non-continuous time model for the future of decentralized technologies and their potential applications are discussed.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain and Stablecoin Integration for Crowdfunding: A framework for enhanced efficiency, security, and liquidity</title>
<link>https://arxiv.org/abs/2501.11145</link>
<guid>https://arxiv.org/abs/2501.11145</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、稳定币、众筹、代币化、合规性

总结:
<br />
本文提出了一种基于区块链的众筹框架，该框架采用稳定币（如USDT和USDC）来缓解加密货币的波动性并确保资金管理的顺畅。通过智能合约自动化了包括了解客户（KYC）/反洗钱（AML）检查在内的合规流程，提升了运营效率。此外，代币化通过允许股份分割所有权和二级市场交易以实现流动性。文章对传统平台进行了比较分析，强调了新框架在降低成本、提高透明度和增强投资者信任方面的优势。通过以土耳其市场的案例研究，具体展示了区块链在股权众筹领域应用的实际效益，尤其是在应对地方监管和金融复杂性方面。这种方法为现代众筹生态系统提供了一个可扩展、安全且易访问的解决方案，同时降低了平台成本并增加了投资者和项目支持者对众筹项目的信任。 <div>
arXiv:2501.11145v1 Announce Type: new 
Abstract: Crowdfunding platforms face high transaction fees, need for more transparency, and trust deficits. These issues deter contributors and entrepreneurs from effectively leveraging crowdfunding for innovation and growth. Blockchain technology introduces decentralization, security, and efficiency to address these limitations (1). This paper proposes a blockchain-based crowdfunding framework that integrates stablecoins such as USDT and USDC to mitigate cryptocurrency volatility and ensure seamless fund management. Smart contracts automate compliance processes, including Know Your Customer (KYC) / Anti-Money Laundering (AML) checks, and enhance operational efficiency (2). Furthermore, tokenization enables liquidity by allowing fractional ownership and secondary market trading, which must be effectively implemented on any global market platform. A comparative analysis highlights the superiority of the framework over traditional platforms in terms of cost reduction, transparency, and investor trust. A case study focused on the Turkish market illustrates the practical benefits of blockchain adoption in equity crowdfunding, particularly in navigating local regulatory and financial complexities. This approach provides a scalable, secure, and accessible solution for modern crowdfunding ecosystems, while reducing the costs of platforms and increasing the trust of investors and backers in crowdfunding projects. Keywords Blockchain, stablecoins, crowdfunding, tokenization, and compliance
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Developer Experience: A Multivocal Literature Review</title>
<link>https://arxiv.org/abs/2501.11431</link>
<guid>https://arxiv.org/abs/2501.11431</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链、开发者体验、BcDEx、多网络支持

总结:<br />
随着智能合约推动区块链技术扩展其功能，分布式应用（dApps）的创新开发得以实现。然而，这也带来了分布式架构管理和不可变数据管理等新挑战。为应对这些复杂性，出现了专门针对区块链软件工程的实践方法。开发者体验（DEx）在此领域中扮演核心角色，关注工程师对工具和框架的可用性、生产力和整体满意度。尽管BcDEx的重要性日益凸显，但相关研究仍然有限，学术界与业界对此的关注尚未形成系统性的梳理。为此，研究者进行了多元文献综述，分析了62篇文献，揭示了相较于学术界的有限关注，灰色文献（主要是博客和企业来源）更广泛地涵盖了BcDEx内容。目前，工具和框架主要关注开发效率、多网络支持和易用性等方面。此外，BcDEx的发展主要受到五个关键视角的影响：复杂性抽象、推广便利性、生产率提升、开发者教育以及BcDEx评估。 <div>
arXiv:2501.11431v1 Announce Type: new 
Abstract: The rise of smart contracts has expanded blockchain's capabilities, enabling the development of innovative decentralized applications (dApps). However, this advancement brings its own challenges, including the management of distributed architectures and immutable data. Addressing these complexities requires a specialized approach to software engineering, with blockchain-oriented practices emerging to support development in this domain. Developer Experience (DEx) is central to this effort, focusing on the usability, productivity, and overall satisfaction of tools and frameworks from the engineers' perspective. Despite its importance, research on Blockchain Developer Experience (BcDEx) remains limited, with no systematic mapping of academic and industry efforts. To bridge this gap, we conducted a Multivocal Literature Review analyzing 62 to understand the distribution of BcDEx sources, practical implementations, and their impact. Our findings revealed that academic focus on BcDEx is limited compared to the coverage in gray literature, which primarily includes blogs (41.8%) and corporate sources (21.8%). Particularly, development efficiency, multi-network support, and usability are the most addressed aspects in tools and frameworks. In addition, we found that BcDEx is being shaped through five key perspectives: complexity abstraction, adoption facilitation, productivity enhancement, developer education, and BcDEx evaluation.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification</title>
<link>https://arxiv.org/abs/2501.11493</link>
<guid>https://arxiv.org/abs/2501.11493</guid>
<content:encoded><![CDATA[
<div> 关键词: 弹性网络 (Federated Learning)，通信效率，遥感 (Remote Sensing)，模型剪枝，层间相关传播 (Layerwise Relevance Propagation)

<br /><br />总结:

本文提出了一种基于解释引导的剪枝策略，用于提高遥感图像分类中弹性网络(FL)的通信效率。该策略利用层间相关传播(LRP)驱动的解释来有效地识别与任务最相关和最有信息性的模型参数，并剔除非相关信息以减小模型更新的传输量。实验结果显示，该策略能够在显著降低共享模型更新数量的同时，提升全球模型的泛化能力。该工作的代码将在https://git.tu-berlin.de/rsim/FL-LRP 公开发布。 <div>
arXiv:2501.11493v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized machine learning paradigm, where multiple clients collaboratively train a global model by exchanging only model updates with the central server without sharing the local data of clients. Due to the large volume of model updates required to be transmitted between clients and the central server, most FL systems are associated with high transfer costs (i.e., communication overhead). This issue is more critical for operational applications in remote sensing (RS), especially when large-scale RS data is processed and analyzed through FL systems with restricted communication bandwidth. To address this issue, we introduce an explanation-guided pruning strategy for communication-efficient FL in the context of RS image classification. Our pruning strategy is defined based on the layerwise relevance propagation (LRP) driven explanations to: 1) efficiently and effectively identify the most relevant and informative model parameters (to be exchanged between clients and the central server); and 2) eliminate the non-informative ones to minimize the volume of model updates. The experimental results on the BigEarthNet-S2 dataset demonstrate that our strategy effectively reduces the number of shared model updates, while increasing the generalization ability of the global model. The code of this work will be publicly available at https://git.tu-berlin.de/rsim/FL-LRP
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Characterizing Transfer Graphs of Suspicious ERC-20 Tokens</title>
<link>https://arxiv.org/abs/2501.11668</link>
<guid>https://arxiv.org/abs/2501.11668</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum, 区块链, 欺诈行为, 智能合约, ERC-20令牌

总结:
本文主要研究了Ethereum区块链上利用智能合约和ERC-20接口进行欺诈的行为。通过对以太坊区块链中超过20个时段、每个时段包含10万块的ERC-20合同事件日志进行解析，构建了各类ERC-20代币的转账图。通过分析这些转账图，作者发现了一些区分可疑与合法合约的关键特征，并据此建立了一个模型，该模型能够平均以88.7%的准确率识别欺诈性合约。这表明欺诈行为的运作机制与其转账图密切相关，转账图可以用于改进欺诈检测机制，有助于提升Ethereum的安全性。 <div>
arXiv:2501.11668v1 Announce Type: new 
Abstract: Ethereum is currently the second largest blockchain by market capitalization and a popular platform for cryptocurrencies. As it has grown, the high value present and the anonymity afforded by the technology have led Ethereum to become a hotbed for various cybercrimes. This paper seeks to understand how these fraudulent schemes may be characterized and develop methods for detecting them. One key feature introduced by Ethereum is the ability to use programmable smart contracts to execute code on the blockchain. A common use of smart contracts is implementing fungible tokens with the ERC-20 interface. Such tokens can be used to impersonate legitimate tokens and defraud users. By parsing the event logs emitted by these ERC-20 contracts over 20 different periods of 100K blocks, we construct token transfer graphs for each of the available ERC-20 tokens on the blockchain. By analyzing these graphs, we find a set of characteristics by which suspicious contracts are distinguished from legitimate ones. These observations result in a simple model that can identify scam contracts with an average of 88.7% accuracy. This suggests that the mechanism by which fraudulent schemes function strongly correlates with their transfer graphs and that these graphs may be used to improve scam-detection mechanisms, contributing to making Ethereum safer.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Key Concepts and Principles of Blockchain Technology</title>
<link>https://arxiv.org/abs/2501.11707</link>
<guid>https://arxiv.org/abs/2501.11707</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、分布式、去中心化、优势、挑战

<br /><br />总结:
本文探讨了区块链技术的核心特性，如分布式和去中心化的架构，该特性使其成为比特币等数字货币的基础并广泛应用于各行各业。区块链技术的主要优点在于提高交易安全性和透明度，并防止单一实体对网络的控制。文章分析了其在不同行业的应用案例以及采用此技术的原因，同时指出了面临的挑战，如可扩展性问题和高能耗。此外，还阐述了区块链如何增强经济与社会互动中的效率与安全性。最后，通过对各行业区块链应用的比较和未来趋势分析，得出了一份全面的结论。 <div>
arXiv:2501.11707v1 Announce Type: new 
Abstract: In recent years, blockchain technology has been recognized as a transformative innovation in the tech world, and it has quickly become the core infrastructure of digital currencies such as Bitcoin and an important tool in various industries. This technology facilitates the recording and tracking of transactions across a vast network of computers by providing a distributed and decentralized ledger. Blockchain's decentralized structure significantly enhances security and transparency and prevents a single entity from dominating the network. This chapter examines blockchain's advantages, disadvantages, and applications in various industries and analyzes the implementation environments and reasons for using this technology. Also, this chapter discusses challenges such as scalability and high energy consumption that inhibit the expansion of this technology and examines blockchain technology's role in increasing efficiency and security in economic and social interactions. Finally, a comprehensive conclusion of blockchain applications and challenges has been presented by comparing blockchain applications in various industries and analyzing future trends.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personalized Federated Learning for Cellular VR: Online Learning and Dynamic Caching</title>
<link>https://arxiv.org/abs/2501.11745</link>
<guid>https://arxiv.org/abs/2501.11745</guid>
<content:encoded><![CDATA[
<div> 关键词：虚拟现实(VR)，无线连接，视场角(FoV)缓存，移动边缘计算(MEC)，分布式个性化联邦学习(DP-FL)

总结:

该文提出了一种针对移动边缘计算(MEC)支持的无线VR网络的视场角(FoV)感知缓存方案。该方案基于每个基站(BS)定制的缓存策略，预先将VR用户的FoV内容缓存在BS处。文章重点介绍了具有性能保证的分散式个性化联邦学习(DP-FL)缓存策略。在一个由多个VR设备和BS组成的VR系统中，每个BS利用DP-FL算法实现个性化内容投递，确保了条件平均缓存命中的概率近似正确(PAC)界。为降低梯度通信成本，文中还提出了基于一比特量化随机梯度下降(OBSGD)的方法，并得到了收敛性保证$\mathcal{O}(1/\sqrt{T})$，其中T表示迭代次数。此外，考虑到无线信道动态性，根据请求VR用户数量，将FoV划分为组播或单播组。通过真实VR头动追踪数据集验证了所提DP-FL算法的性能，并表明其在平均延迟和缓存命中率方面优于基线算法。 <div>
arXiv:2501.11745v1 Announce Type: new 
Abstract: Delivering an immersive experience to virtual reality (VR) users through wireless connectivity offers the freedom to engage from anywhere at any time. Nevertheless, it is challenging to ensure seamless wireless connectivity that delivers real-time and high-quality videos to the VR users. This paper proposes a field of view (FoV) aware caching for mobile edge computing (MEC)-enabled wireless VR network. In particular, the FoV of each VR user is cached/prefetched at the base stations (BSs) based on the caching strategies tailored to each BS. Specifically, decentralized and personalized federated learning (DP-FL) based caching strategies with guarantees are presented. Considering VR systems composed of multiple VR devices and BSs, a DP-FL caching algorithm is implemented at each BS to personalize content delivery for VR users. The utilized DP-FL algorithm guarantees a probably approximately correct (PAC) bound on the conditional average cache hit. Further, to reduce the cost of communicating gradients, one-bit quantization of the stochastic gradient descent (OBSGD) is proposed, and a convergence guarantee of $\mathcal{O}(1/\sqrt{T})$ is obtained for the proposed algorithm, where $T$ is the number of iterations. Additionally, to better account for the wireless channel dynamics, the FoVs are grouped into multicast or unicast groups based on the number of requesting VR users. The performance of the proposed DP-FL algorithm is validated through realistic VR head-tracking dataset, and the proposed algorithm is shown to have better performance in terms of average delay and cache hit as compared to baseline algorithms.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPID-Chain: A Smart Contract-Enabled, Polar-Coded Interoperable DAG Chain</title>
<link>https://arxiv.org/abs/2501.11794</link>
<guid>https://arxiv.org/abs/2501.11794</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3, SPID-Chain, 交互性共识, 有向无环图(DAG), 分布式计算优化

<br /><br />总结:
本文介绍了SPID-Chain，这是一个针对Web3的新型交互性共识机制，旨在实现区块链网络间的无缝集成。SPID-Chain利用基于DAG的多区块链结构，其中每个区块链保持自己的共识并通过结合事件驱动智能合约(EDSC)和极化码的内部共识机制处理交易，提高了交易处理效率。此外，通过委员会节点和工作节点的分工进一步提升效率。在跨链共识层面，各区块链使用DAG结构添加包含跨链交易的区块，并通过区块链协调的跨共识机制进行处理。模拟实验验证了该方案在吞吐量、可扩展性、去中心化和安全性方面的有效性，显示了SPID-Chain赋能不同区块链网络间流畅互动与交易的潜力，符合Web3的核心理念。 <div>
arXiv:2501.11794v1 Announce Type: new 
Abstract: As the digital landscape evolves, Web3 has gained prominence, highlighting the critical role of decentralized, interconnected, and verifiable digital ecosystems. This paper introduces SPID-Chain, a novel interoperability consensus designed for Web3, which employs a directed acyclic graph (DAG) of blockchains to facilitate seamless integration across multiple blockchains. Within SPID-Chain, each blockchain maintains its own consensus and processes transactions via an intra-consensus mechanism that incorporates event-driven smart contracts (EDSC) and Polar codes for optimized computation distribution. This mechanism is complemented by a division of committee and worker nodes, enhancing transaction processing efficiency within individual chains. For inter-blockchain consensus, SPID-Chain utilizes a DAG structure where blockchains append blocks containing cross-chain transactions. These blocks are then processed through the inter-consensus mechanism orchestrated by the blockchains. Extensive simulations validate the efficacy of our scheme in terms of throughput, scalability, decentralization, and security. Our results showcase SPID-Chain's potential to enable fluid interactions and transactions across diverse blockchain networks, aligning with the foundational goals of Web3.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Security Risk Assessment in Quantum Era, Migration Strategies and Proactive Defense</title>
<link>https://arxiv.org/abs/2501.11798</link>
<guid>https://arxiv.org/abs/2501.11798</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算、区块链安全、风险评估、量子抵抗型加密、迁移策略

<br />
总结:
本文针对量子计算对区块链系统安全性构成的重大挑战进行了深入研究。文章全面分析了量子计算机威胁到区块链的关键组件——网络、挖矿池、交易验证机制、智能合约和用户钱包的风险。同时，论文阐述了过渡到量子抵抗型加密算法过程中的复杂挑战和战略考量，并提出一种混合迁移策略，旨在确保从传统到量子抵抗型加密的平稳过渡。文中还详细评估了比特币、以太坊、瑞波币、莱特币和zcash等主流区块链的脆弱性、潜在影响及关联STRIDE威胁，识别出了容易受到量子攻击的领域。此外，为应对量子计算机带来的日益严重的网络安全威胁，本文提出了构建安全、有韧性的区块链生态系统的定制化安全蓝图，并强调区块链相关各方应采取积极措施，实施量子抵抗型解决方案的重要性。总的来说，本文旨在引导读者理解和适应量子时代下复杂的安全环境，确保区块链系统的稳健和自信运行。 <div>
arXiv:2501.11798v1 Announce Type: new 
Abstract: The emergence of quantum computing presents a formidable challenge to the security of blockchain systems. Traditional cryptographic algorithms, foundational to digital signatures, message encryption, and hashing functions, become vulnerable to the immense computational power of quantum computers. This paper conducts a thorough risk assessment of transitioning to quantum-resistant blockchains, comprehensively analyzing potential threats targeting vital blockchain components: the network, mining pools, transaction verification mechanisms, smart contracts, and user wallets. By elucidating the intricate challenges and strategic considerations inherent in transitioning to quantum-resistant algorithms, the paper evaluates risks and highlights obstacles in securing blockchain components with quantum-resistant cryptography. It offers a hybrid migration strategy to facilitate a smooth transition from classical to quantum-resistant cryptography. The analysis extends to prominent blockchains such as Bitcoin, Ethereum, Ripple, Litecoin, and Zcash, assessing vulnerable components, potential impacts, and associated STRIDE threats, thereby identifying areas susceptible to quantum attacks. Beyond analysis, the paper provides actionable guidance for designing secure and resilient blockchain ecosystems in the quantum computing era. Recognizing the looming threat of quantum computers, this research advocates for a proactive transition to quantum-resistant blockchain networks. It proposes a tailored security blueprint that strategically fortifies each component against the evolving landscape of quantum-induced cyber threats. Emphasizing the critical need for blockchain stakeholders to adopt proactive measures and implement quantum-resistant solutions, the paper underscores the importance of embracing these insights to navigate the complexities of the quantum era with resilience and confidence.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-source Multi-level Multi-token Ethereum Dataset and Benchmark Platform</title>
<link>https://arxiv.org/abs/2501.11906</link>
<guid>https://arxiv.org/abs/2501.11906</guid>
<content:encoded><![CDATA[
<div> 关键词：3MEthTaskforce、多源、多层、多令牌、Ethereum数据集

总结:
<br />
本文介绍了3MEthTaskforce（https://3meth.github.io），这是一个针对单一来源数据集局限性的多源、多层次、多令牌的Ethereum数据集。该数据集综合了从2014年至2024年超过3亿笔交易记录、3880个代币档案、全球市场指标以及Reddit情绪数据，从而支持对用户行为、市场情绪和代币表现进行全方位研究。此外，3MEthTaskforce为用户行为预测和代币价格预测任务定义了基准，并采用6种动态图网络和19种时间序列模型来评估性能。其多模态设计有利于风险分析和市场波动建模，为推动区块链分析和去中心化金融研究提供了宝贵资源。 <div>
arXiv:2501.11906v1 Announce Type: new 
Abstract: This paper introduces 3MEthTaskforce (https://3meth.github.io), a multi-source, multi-level, and multi-token Ethereum dataset addressing the limitations of single-source datasets. Integrating over 300 million transaction records, 3,880 token profiles, global market indicators, and Reddit sentiment data from 2014-2024, it enables comprehensive studies on user behavior, market sentiment, and token performance. 3MEthTaskforce defines benchmarks for user behavior prediction and token price prediction tasks, using 6 dynamic graph networks and 19 time-series models to evaluate performance. Its multimodal design supports risk analysis and market fluctuation modeling, providing a valuable resource for advancing blockchain analytics and decentralized finance research.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication-Efficient and Privacy-Adaptable Mechanism for Federated Learning</title>
<link>https://arxiv.org/abs/2501.12046</link>
<guid>https://arxiv.org/abs/2501.12046</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, communication efficiency, privacy protection, CEPAM, RSUQ

总结:
本文提出了一种名为通信效率与隐私适应性机制(CEPAM)的新方法，用于在联邦学习(federated learning)中解决分布式私人数据训练机器学习模型时面临的通信效率和隐私保护两大挑战。CEPAM利用了拒绝采样通用量化器(RSUQ)，该量化器可以将失真等同于预设的噪声（如高斯或拉普拉斯噪声），从而实现差分隐私和压缩的同时保证。此外，文章分析了CEPAM在用户隐私、全局效用和传输率之间的权衡关系，并为具有差分隐私和压缩的FL定义了适当的度量标准。CEPAM还具备隐私自适应性优势，允许客户端和服务器根据所需精度和保护程度定制隐私保护策略。通过使用MNIST数据集进行评估，CEPAM显示出了比基线模型更高的学习准确性优势。 <div>
arXiv:2501.12046v1 Announce Type: new 
Abstract: Training machine learning models on decentralized private data via federated learning (FL) poses two key challenges: communication efficiency and privacy protection. In this work, we address these challenges within the trusted aggregator model by introducing a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), achieving both objectives simultaneously. In particular, CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a construction of randomized vector quantizer whose resulting distortion is equivalent to a prescribed noise, such as Gaussian or Laplace noise, enabling joint differential privacy and compression. Moreover, we analyze the trade-offs among user privacy, global utility, and transmission rate of CEPAM by defining appropriate metrics for FL with differential privacy and compression. Our CEPAM provides the additional benefit of privacy adaptability, allowing clients and the server to customize privacy protection based on required accuracy and protection. We assess CEPAM's utility performance using MNIST dataset, demonstrating that CEPAM surpasses baseline models in terms of learning accuracy.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BotDetect: A Decentralized Federated Learning Framework for Detecting Financial Bots on the EVM Blockchains</title>
<link>https://arxiv.org/abs/2501.12112</link>
<guid>https://arxiv.org/abs/2501.12112</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized federated learning (DFL)，financial bots，Ethereum Virtual Machine (EVM)，blockchain networks，malicious bot behavior

总结:<br />
本文提出了一种基于去中心化联邦学习(DFL)的方法，用于检测以太坊虚拟机(EVM)为基础的区块链网络中的金融机器人。该框架利用联邦学习并通过智能合约进行协调，能够在保护数据隐私的同时，适应区块链的去中心化特性，检测恶意机器人行为。与集中式和规则基方案相比，系统允许各参与节点使用交易历史和智能合约交互数据训练本地模型，随后通过许可型共识机制在链上聚合模型更新。这样设计使得模型能够捕捉到复杂且不断演进的机器人行为，而无需节点间直接分享数据。实验结果显示，该DFL框架在保持高检测精度、可扩展性和鲁棒性的同时，为分布式区块链网络提供了有效的机器人检测解决方案。 <div>
arXiv:2501.12112v1 Announce Type: new 
Abstract: The rapid growth of decentralized finance (DeFi) has led to the widespread use of automated agents, or bots, within blockchain ecosystems like Ethereum, Binance Smart Chain, and Solana. While these bots enhance market efficiency and liquidity, they also raise concerns due to exploitative behaviors that threaten network integrity and user trust. This paper presents a decentralized federated learning (DFL) approach for detecting financial bots within Ethereum Virtual Machine (EVM)-based blockchains. The proposed framework leverages federated learning, orchestrated through smart contracts, to detect malicious bot behavior while preserving data privacy and aligning with the decentralized nature of blockchain networks. Addressing the limitations of both centralized and rule-based approaches, our system enables each participating node to train local models on transaction history and smart contract interaction data, followed by on-chain aggregation of model updates through a permissioned consensus mechanism. This design allows the model to capture complex and evolving bot behaviors without requiring direct data sharing between nodes. Experimental results demonstrate that our DFL framework achieves high detection accuracy while maintaining scalability and robustness, providing an effective solution for bot detection across distributed blockchain networks.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Heterogeneous Federated Learning System for Sparse Healthcare Time-Series Prediction</title>
<link>https://arxiv.org/abs/2501.12125</link>
<guid>https://arxiv.org/abs/2501.12125</guid>
<content:encoded><![CDATA[
<div> 关键词：异构联邦学习（HFL）、稀疏时间序列预测、医疗保健、模型安全性、知识转移

总结:
本文提出了一种针对医疗保健领域稀疏时间序列预测的异构联邦学习（HFL）系统。该系统是一种分布式联邦学习算法，具有异构迁移特性，能有效处理数据源的稀疏性。通过设计密集和稀疏特征张量来应对数据的稀疏问题，同时开发了异构联邦学习以实现网络部分的异步共享以及选择适合的知识迁移模型。实验结果显示，所提出的HFL在十项预测任务中的八项上取得了最低预测误差，相比基准系统，MSE减少了94.8%、48.3%和52.1%。这证明了HFL在从不同领域进行知识迁移特别是在小目标领域的有效性。此外，消融研究进一步证实了异构域选择与切换机制在保证隐私、模型安全性和异构知识转移方面设计的有效性。 <div>
arXiv:2501.12125v1 Announce Type: new 
Abstract: In this paper, we propose a heterogeneous federated learning (HFL) system for sparse time series prediction in healthcare, which is a decentralized federated learning algorithm with heterogeneous transfers. We design dense and sparse feature tensors to deal with the sparsity of data sources. Heterogeneous federated learning is developed to share asynchronous parts of networks and select appropriate models for knowledge transfer. Experimental results show that the proposed HFL achieves the lowest prediction error among all benchmark systems on eight out of ten prediction tasks, with MSE reduction of 94.8%, 48.3%, and 52.1% compared to the benchmark systems. These results demonstrate the effectiveness of HFL in transferring knowledge from heterogeneous domains, especially in the smaller target domain. Ablation studies then demonstrate the effectiveness of the designed mechanisms for heterogeneous domain selection and switching in predicting healthcare time series with privacy, model security, and heterogeneous knowledge transfer.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Empower Healthcare through a Self-Sovereign Identity Infrastructure for Secure Electronic Health Data Access</title>
<link>https://arxiv.org/abs/2501.12229</link>
<guid>https://arxiv.org/abs/2501.12229</guid>
<content:encoded><![CDATA[
<div> 关键词: 健康数据管理框架、患者中心、自主权身份、区块链技术、去中心化标识符、可验证凭证<br /><br />总结:
本文提出了一种基于患者中心的开源健康数据管理框架，该框架采用了自主权身份理念，并结合了去中心化标识符和可验证凭证等创新技术。通过利用区块链技术，该框架实现了数据的不可变性、可验证的数据注册和审计能力，同时采用代理模型以保护和确保患者数据的隐私。文章详细描述了针对日常病人-医生-实验室交互场景的不同使用案例，并定义了应对患者数据丢失、数据访问撤销以及紧急情况下无法获取患者同意的情况下的具体功能。为了验证这一设计，作者构建了一个概念验证原型，涉及患者与医生之间的互动，并讨论了本框架的创新点，包括患者中心的数据存储方式、设计的恢复与应急计划、定义的备份流程以及所选择的区块链平台。 <div>
arXiv:2501.12229v1 Announce Type: new 
Abstract: Health data is one of the most sensitive data for people, which attracts the attention of malicious activities. We propose an open-source health data management framework, that follows a patient-centric approach. The proposed framework implements the Self-Sovereign Identity paradigm with innovative technologies such as Decentralized Identifiers and Verifiable Credentials. The framework uses Blockchain technology to provide immutability, verifiable data registry, and auditability, as well as an agent-based model to provide protection and privacy for the patient data. We also define different use cases regarding the daily patient-practitioner-laboratory interactions and specific functions to cover patient data loss, data access revocation, and emergency cases where patients are unable to give consent and access to their data. To address this design, a proof of concept is created with an interaction between patient and doctor. The most feasible technologies are selected and the created design is validated. We discuss the differences and novelties of this framework, which includes the patient-centric approach also for data storage, the designed recovery and emergency plan, the defined backup procedure, and the selected blockchain platform.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CYCle: Choosing Your Collaborators Wisely to Enhance Collaborative Fairness in Decentralized Learning</title>
<link>https://arxiv.org/abs/2501.12344</link>
<guid>https://arxiv.org/abs/2501.12344</guid>
<content:encoded><![CDATA[
<div> 关键词：协同学习，分布式数据源，公平性，最大均值协作增益，协作增益传播

<br /><br />总结:

本文关注协同学习（CL）中多个参与方在不共享原始数据的情况下联合训练机器学习模型的问题，强调了确保合作收益公平分配的重要性。现有的CL算法大多需要中心协调并侧重于最大化预期准确率提升，而忽视了合作公平性。作者指出，基于准确性值的相关性来衡量的合作公平性存在缺陷，因为它未考虑负向合作收益的情况。他们提出了一种更公平的目标，即同时最大化均值协作增益（MCG）和最小化协作增益传播（CGS）。为此，文章提出了CYCle协议，该协议在私人分布式学习框架下允许各参与者通过一种基于局部交叉熵损失与蒸馏损失梯度对齐的新颖声誉评分方法实现这一目标。实验结果表明，CYCle协议在CIFAR-10、CIFAR-100和Fed-ISIC2019等数据集上能够有效确保所有参与者的正向和公平的合作收益，即使在参与者数据分布高度偏斜的情况下也是如此。此外，对于有两个参与者的简单平均估计问题，理论上也证明了CYCle相比于标准的FedAvg具有更好的性能，特别是在统计异质性较大的情况下。 <div>
arXiv:2501.12344v1 Announce Type: new 
Abstract: Collaborative learning (CL) enables multiple participants to jointly train machine learning (ML) models on decentralized data sources without raw data sharing. While the primary goal of CL is to maximize the expected accuracy gain for each participant, it is also important to ensure that the gains are fairly distributed. Specifically, no client should be negatively impacted by the collaboration, and the individual gains must ideally be commensurate with the contributions. Most existing CL algorithms require central coordination and focus on the gain maximization objective while ignoring collaborative fairness. In this work, we first show that the existing measure of collaborative fairness based on the correlation between accuracy values without and with collaboration has drawbacks because it does not account for negative collaboration gain. We argue that maximizing mean collaboration gain (MCG) while simultaneously minimizing the collaboration gain spread (CGS) is a fairer alternative. Next, we propose the CYCle protocol that enables individual participants in a private decentralized learning (PDL) framework to achieve this objective through a novel reputation scoring method based on gradient alignment between the local cross-entropy and distillation losses. Experiments on the CIFAR-10, CIFAR-100, and Fed-ISIC2019 datasets empirically demonstrate the effectiveness of the CYCle protocol to ensure positive and fair collaboration gain for all participants, even in cases where the data distributions of participants are highly skewed. For the simple mean estimation problem with two participants, we also theoretically show that CYCle performs better than standard FedAvg, especially when there is large statistical heterogeneity.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Budget-constrained Collaborative Renewable Energy Forecasting Market</title>
<link>https://arxiv.org/abs/2501.12367</link>
<guid>https://arxiv.org/abs/2501.12367</guid>
<content:encoded><![CDATA[
<div> 关键词: 可再生能源, 功率预测, 分布式时空数据, 数据共享激励机制, 弹性套索回归模型<br /><br />总结:
这篇论文关注了可再生能源功率预测的重要性，并强调了整合分布式时空数据对提升预测准确性的关键作用。然而，数据的所有权分散成为实现这一目标的一大障碍。文章的主要贡献包括：a) 对预报模型进行了比较分析，推荐使用高效和可解释的弹性套索回归模型；b) 提出了一种投标机制，用于数据/分析市场中的公平补偿数据提供者，并允许买卖双方表达各自的数据价格要求；c) 进一步设计了一个时间序列预测的激励机制，有效地结合了价格约束并避免了冗余特征分配。实验结果显示，与本地生成的预测相比，该提案方法在风力发电数据上的平均均方根误差提高了超过10%，同时为数据卖方带来了潜在的经济收益。 <div>
arXiv:2501.12367v1 Announce Type: new 
Abstract: Accurate power forecasting from renewable energy sources (RES) is crucial for integrating additional RES capacity into the power system and realizing sustainability goals. This work emphasizes the importance of integrating decentralized spatio-temporal data into forecasting models. However, decentralized data ownership presents a critical obstacle to the success of such spatio-temporal models, and incentive mechanisms to foster data-sharing need to be considered. The main contributions are a) a comparative analysis of the forecasting models, advocating for efficient and interpretable spline LASSO regression models, and b) a bidding mechanism within the data/analytics market to ensure fair compensation for data providers and enable both buyers and sellers to express their data price requirements. Furthermore, an incentive mechanism for time series forecasting is proposed, effectively incorporating price constraints and preventing redundant feature allocation. Results show significant accuracy improvements and potential monetary gains for data sellers. For wind power data, an average root mean squared error improvement of over 10% was achieved by comparing forecasts generated by the proposal with locally generated ones.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Local Limits of Small World Networks</title>
<link>https://arxiv.org/abs/2501.11226</link>
<guid>https://arxiv.org/abs/2501.11226</guid>
<content:encoded><![CDATA[
<div> 关键词: 小世界网络、局部收敛、Watts-Strogatz模型、Kleinberg模型、PageRank

总结:
这篇论文研究了小世界网络中的局部结构行为，特别是针对两种常用的小世界网络模型——Watts-Strogatz模型和Kleinberg模型。通过应用局部收敛理论，论文证明了随着网络规模增大，关键网络度量（如PageRank、聚类系数和最大匹配大小）的极限值由图的局部结构决定。此外，该框架还使得仅利用小邻域内的局部信息就能估计全局现象，例如信息传播。论文结果进一步揭示，当Kleinberg模型中控制长程连接的参数越过了保持去中心化搜索效率的阈值时，极限行为会出现显著变化，为理解在某些情况下去中心化算法为何失效提供了新的视角。 <div>
arXiv:2501.11226v1 Announce Type: cross 
Abstract: Small-world networks, known for their high local clustering and short average path lengths, are a fundamental structure in many real-world systems, including social, biological, and technological networks. We apply the theory of local convergence (Benjamini-Schramm convergence) to derive the limiting behavior of the local structures for two of the most commonly studied small-world network models: the Watts-Strogatz model and the Kleinberg model. Establishing local convergence enables us to show that key network measures, such as PageRank, clustering coefficients, and maximum matching size, converge as network size increases with their limits determined by the graph's local structure. Additionally, this framework facilitates the estimation of global phenomena, such as information cascades, using local information from small neighborhoods. As an additional outcome of our results, we observe a critical change in the behavior of the limit exactly when the parameter governing long-range connections in the Kleinberg model crosses the threshold where decentralized search remains efficient, offering a new perspective on why decentralized algorithms fail in certain regimes.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature</title>
<link>https://arxiv.org/abs/2308.12420</link>
<guid>https://arxiv.org/abs/2308.12420</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Ledger Technology (DLT)，Environmental, Social, and Governance (ESG)，Natural Language Processing (NLP)，Named Entity Recognition (NER)，Proof of Work (PoW)

总结:

本文关注了分布式账本技术（DLT）在环境影响、特别是能源消耗和更广泛的ESG考量方面所面临的日益增长的关注。针对现有文献综述存在的局限性，作者通过使用自然语言处理（NLP）对24,539篇出版物全文进行分析，并结合手动标注的39,427个DLT相关实体命名实体识别（NER）数据集，识别出了连接DLT与ESG领域的关键505篇文献，从而提供了对该领域更为全面和深入的理解。研究运用NLP和时间图分析方法揭示了DLT演进及ESG影响的关键趋势，包括加密学和点对点网络研究的重要性、比特币在研究及环保问题上的持久影响力（“林迪效应”）、以太坊对权益证明（PoS）和智能合约采纳的影响以及向节能共识机制的转变。此外，文章还贡献了一个首个针对DLT的专业NER数据集，以解决区块链研究中高质量标注NLP数据的稀缺问题；提出了一种将NLP与时间图分析相结合的大规模跨学科文献回顾方法；并完成了首个以ESG为重点的NLP驱动的DLT文献回顾。 <div>
arXiv:2308.12420v3 Announce Type: replace 
Abstract: Emerging technologies, such as Distributed Ledger Technology (DLT), face growing scrutiny for their environmental impact, especially when it comes to the energy use of the Proof of Work (PoW) consensus mechanism and broader Environmental, Social, and Governance (ESG) considerations. Yet, much of the existing systematic literature reviews of DLT rely on the limited analyses of citations, abstracts, and keywords, failing to fully capture the field's complexity and ESG concerns.
  To address these challenges, we analyze the full text of 24,539 publications using Natural Language Processing (NLP) with our manually labeled Named Entity Recognition (NER) dataset of 39,427 entities for DLT. This method identifies 505 key publications connecting DLT and ESG domains, providing a more comprehensive and nuanced understanding of the field.
  Our combined NLP and temporal graph analysis reveals critical trends in DLT evolution and ESG impacts, including the pivotal role of research in cryptography and peer-to-peer networks, Bitcoin's persistent impact on research and environmental concerns (a "Lindy effect"), Ethereum's influence on Proof of Stake (PoS) and smart contracts adoption, and a shift towards energy-efficient consensus mechanisms. Our contributions include the first DLT-specific NER dataset, addressing the scarcity of high-quality labeled NLP data for blockchain research; a methodology integrating NLP and temporal graph analysis for interdisciplinary literature review at large scale; and the first NLP-driven DLT literature review emphasizing ESG aspects.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A High-throughput and Secure Coded Blockchain for IoT</title>
<link>https://arxiv.org/abs/2310.08822</link>
<guid>https://arxiv.org/abs/2310.08822</guid>
<content:encoded><![CDATA[
<div> 关键词：coded blockchain, IoT网络, reward模型, consensus算法, raptor codes

总结:
本文提出了一种适用于物联网(IoT)网络的新颖编码区块链方案。该方案相比现有的编码区块链工作更具有现实性、实用性和安全性，同时能实现高吞吐量。<br />
<br />
首先，通过对交易多样性建模并基于奖励模型解决优化问题，选择那些更容易访问和计算成本更低的交易进行联合处理；其次，设计了一个交易驱动的轻量级共识算法，强调使用最少数量的矿工来处理交易；再者，利用raptor码进行线性时间编码与解码，从而降低维护区块链所需的存储空间并提高吞吐量。<br />
<br />
文章对所提方案进行了详细分析和模拟结果展示，并将其与包括Polyshard和LCB在内的现有领先的编码IoT区块链方案进行了比较，证明了所提方案在安全性、存储需求、去中心化程度和吞吐量等方面的优越性。 <div>
arXiv:2310.08822v2 Announce Type: replace 
Abstract: We propose a new coded blockchain scheme suitable for the Internet-of-Things (IoT) network. In contrast to existing works for coded blockchains, especially blockchain-of-things, the proposed scheme is more realistic, practical, and secure while achieving high throughput. This is accomplished by: 1) modeling the variety of transactions using a reward model, based on which an optimization problem is solved to select transactions that are more accessible and cheaper computational-wise to be processed together; 2) a transaction-based and lightweight consensus algorithm that emphasizes on using the minimum possible number of miners for processing the transactions; and 3) employing the raptor codes with linear-time encoding and decoding which results in requiring lower storage to maintain the blockchain and having a higher throughput. We provide detailed analysis and simulation results on the proposed scheme and compare it with the state-of-the-art coded IoT blockchain schemes including Polyshard and LCB, to show the advantages of our proposed scheme in terms of security, storage, decentralization, and throughput.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SAMM: Sharded Automated Market Maker</title>
<link>https://arxiv.org/abs/2406.05568</link>
<guid>https://arxiv.org/abs/2406.05568</guid>
<content:encoded><![CDATA[
<div> 关键词: Automated Market Maker (AMM), SAMM, Sharding, Incentive Compatibility, Throughput

<br /><br />总结:
本文提出了一个新的自动化做市商（AMM）模型SAMM，它通过将多个独立运行的碎片化AMM集成在同一链上实现并行执行，解决了现有AMM架构无法满足未来快速增长的需求问题。与传统的分片解决方案不同，SAMM依赖于激励相容性来确保安全性，并引入了一种新的费用设计。通过分析子博弈完美纳什均衡（SPNE），作者证明了SAMM能够激励流动性提供者在所有碎片间平衡流动性，抵御destabilization攻击，并使交易均匀分布。使用真实世界数据进行的模拟验证了这一游戏理论分析。此外，文章还实现了并在Sui和Solana区块链的本地测试网上部署了SAMM，结果显示其分别提高了5倍和16倍的吞吐量，有望随着底层区块链更好的并行化进一步提升性能。SAMM方案直接可部署，有助于缓解即将到来的扩容瓶颈问题。 <div>
arXiv:2406.05568v5 Announce Type: replace 
Abstract: Automated Market Makers (AMMs) are a cornerstone of decentralized finance. They are smart contracts (stateful programs) running on blockchains. They enable virtual token exchange: traders swap tokens with the AMM for a fee, while liquidity providers supply liquidity and receive these fees. Demand for AMMs is growing rapidly, but our experiment-based estimates show that current architectures cannot meet the projected demand by 2029. This is because the execution of existing AMMs is non-parallelizable.
  We present SAMM, an AMM comprising multiple shards. All shards are AMMs running on the same chain, but their independence enables parallel execution. Unlike classical sharding solutions, here security relies on incentive compatibility. Therefore, SAMM introduces a novel fee design. Through analysis of Subgame-Perfect Nash Equilibria (SPNE), we show that SAMM incentivizes the desired behavior: liquidity providers balance liquidity among all shards, overcoming destabilization attacks, and trades are evenly distributed. We validate our game-theoretic analysis with a simulation using real-world data.
  We evaluate SAMM by implementing and deploying it on local testnets of the Sui and Solana blockchains. To our knowledge, this is the first quantification of high-demand-contract performance. SAMM improves throughput by 5x and 16x, respectively, potentially more with better parallelization of the underlying blockchains. It is directly deployable, mitigating the upcoming scaling bottleneck.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personhood credentials: Artificial intelligence and the value of privacy-preserving tools to distinguish who is real online</title>
<link>https://arxiv.org/abs/2408.07892</link>
<guid>https://arxiv.org/abs/2408.07892</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名性、人工智能、身份凭证、信任度、在线平台

<br /><br />总结:

本文探讨了在线环境中匿名性的重要性以及恶意行为者如何利用误导性的身份进行欺诈和传播虚假信息。随着人工智能技术的发展，这类问题的规模和影响力日益增大。为解决此挑战，文章提出了一种新型工具——“人格凭证”(PHCs)，这是一种能让用户在不泄露个人信息的情况下向在线服务证明自己是真实人类而非AI的数字凭证。这种凭证可由政府或其他可信机构颁发，系统既可局部也可全球部署，不一定基于生物特征。文章指出，当前AI在线表现与人类难以区分以及其规模化能力增强两大趋势加剧了这一挑战。现有的反自动化欺骗措施如验证码对高级AI已不再有效，而严格的身份验证方案又无法满足许多场景下的隐私需求。作者分析了人格凭证的好处，同时指出了实施风险和设计挑战，并提出了政策制定者、技术人员及标准机构应考虑的下一步行动建议，需与公众共同讨论。 <div>
arXiv:2408.07892v4 Announce Type: replace 
Abstract: Anonymity is an important principle online. However, malicious actors have long used misleading identities to conduct fraud, spread disinformation, and carry out other deceptive schemes. With the advent of increasingly capable AI, bad actors can amplify the potential scale and effectiveness of their operations, intensifying the challenge of balancing anonymity and trustworthiness online. In this paper, we analyze the value of a new tool to address this challenge: "personhood credentials" (PHCs), digital credentials that empower users to demonstrate that they are real people -- not AIs -- to online services, without disclosing any personal information. Such credentials can be issued by a range of trusted institutions -- governments or otherwise. A PHC system, according to our definition, could be local or global, and does not need to be biometrics-based. Two trends in AI contribute to the urgency of the challenge: AI's increasing indistinguishability from people online (i.e., lifelike content and avatars, agentic activity), and AI's increasing scalability (i.e., cost-effectiveness, accessibility). Drawing on a long history of research into anonymous credentials and "proof-of-personhood" systems, personhood credentials give people a way to signal their trustworthiness on online platforms, and offer service providers new tools for reducing misuse by bad actors. In contrast, existing countermeasures to automated deception -- such as CAPTCHAs -- are inadequate against sophisticated AI, while stringent identity verification solutions are insufficiently private for many use-cases. After surveying the benefits of personhood credentials, we also examine deployment risks and design challenges. We conclude with actionable next steps for policymakers, technologists, and standards bodies to consider in consultation with the public.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Liquidity Fragmentation or Optimization? Analyzing Automated Market Makers Across Ethereum and Rollups</title>
<link>https://arxiv.org/abs/2410.10324</link>
<guid>https://arxiv.org/abs/2410.10324</guid>
<content:encoded><![CDATA[
<div> 关键词: 层2区块链、以太坊、自动做市商(AMM)、流动性提供者(LP)、拉格朗日优化

<br /><br />总结:
本文探讨了层2区块链对于以太坊交易的安全保障和降低手续费的优势，指出尽管层2上的AMM正逐渐受到交易者的欢迎，但LP却相对滞后。研究发现，以太坊主链上的AMM流动资金池相对于层2的同类产品过度订阅，并提供的回报低于ETH质押。通过拉格朗日优化方法，文章提出了一种最大化LP收益的最优流动性分配策略。进一步研究表明，流动性提供的回报将趋近于质押回报率，在均衡状态下，向任何AMM提供的流动性回报应等于质押奖励。最后，文章测量了AMM池中交易量与总锁仓价值(TVL)的弹性关系，发现成熟区块链上TVL的增加并不一定伴随着交易量的上升。 <div>
arXiv:2410.10324v2 Announce Type: replace 
Abstract: Layer-2 (L2) blockchains offer security guarantees for Ethereum while reducing transaction (gas) fees. Consequently, they are gaining popularity among traders at Automated Market Makers (AMMs), but Liquidity Providers (LPs) are lagging behind. Our empirical results show that AMM liquidity pools on Ethereum are oversubscribed compared to their counterparties on L2s and deliver lower returns than staking ETH. LPs would receive higher rewards by reallocating over 2/3 of the liquidity to AMMs on L2s, or staking. We employ Lagrangian optimization to find the optimal liquidity allocation strategy that maximizes LP's rewards. Moreover, we show that the returns from liquidity provisions converge to the staking rate, and in equilibrium, liquidity provisions to any AMM should provide returns equal to staking rewards. Lastly, we measure the elasticity of trading volume with respect to TVL at AMM pools and found that at the well established blockchains an increase in TVL is not associated with an increase in trading volume.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sentiment Analysis in Twitter Social Network Centered on Cryptocurrencies Using Machine Learning</title>
<link>https://arxiv.org/abs/2501.09777</link>
<guid>https://arxiv.org/abs/2501.09777</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币、区块链技术、社交媒体、Twitter情感分析、BERT模型

总结:
本文探讨了伊朗用户对于加密货币在Twitter上的观点，并旨在建立最佳的推文情感分类模型。研究主要关注在非英语环境下，即波斯语语境中的加密货币讨论。文章利用自然语言处理技术，如词袋模型（BOW）和FastText进行文本向量化，并结合传统机器学习算法（包括KNN、SVM和Adaboost）以及深度学习方法（LSTM和BERT）进行分类。实验结果显示，BERT模型在情感分类任务上表现最优，准确率达到了83.50%。这一研究为经济领域的管理者和官员提供了了解公众对加密货币看法的有效工具，以便更好地管理和应对这一现象。 <div>
arXiv:2501.09777v1 Announce Type: new 
Abstract: Cryptocurrency is a digital currency that uses blockchain technology with secure encryption. Due to the decentralization of these currencies, traditional monetary systems and the capital market of each they, can influence a society. Therefore, due to the importance of the issue, the need to understand public opinion and analyze people's opinions in this regard increases. To understand the opinions and views of people about different topics, you can take help from social networks because they are a rich source of opinions. The Twitter social network is one of the main platforms where users discuss various topics, therefore, in the shortest time and with the lowest cost, the opinion of the community can be measured on this social network. Twitter Sentiment Analysis (TSA) is a field that analyzes the sentiment expressed in tweets. Considering that most of TSA's research efforts on cryptocurrencies are focused on English language, the purpose of this paper is to investigate the opinions of Iranian users on the Twitter social network about cryptocurrencies and provide the best model for classifying tweets based on sentiment. In the case of automatic analysis of tweets, managers and officials in the field of economy can gain knowledge from the general public's point of view about this issue and use the information obtained in order to properly manage this phenomenon. For this purpose, in this paper, in order to build emotion classification models, natural language processing techniques such as bag of words (BOW) and FastText for text vectorization and classical machine learning algorithms including KNN, SVM and Adaboost learning methods Deep including LSTM and BERT model were used for classification, and finally BERT linguistic model had the best accuracy with 83.50%.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>W3ID: A Quantum Computing-Secure Digital Identity System Redefining Standards for Web3 and Digital Twins</title>
<link>https://arxiv.org/abs/2501.09802</link>
<guid>https://arxiv.org/abs/2501.09802</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算、Web 3.0、W3ID、数字身份、安全机制

<br /><br />总结:
随着量子计算对现有加密标准和网络安全构成威胁，以及Web 3.0时代的到来，强调数据安全、去中心化和用户所有权，这篇白皮书提出了一个新的数字身份模型——W3ID（Web3标准下的全球统一数字ID）。W3ID旨在满足Web 3.0标准，并解决量子计算带来的安全隐患。它为分布式Web 3.0生态系统创新性地生成了安全的数字对象标识符(DOI)，并采用双钥系统进行安全认证，增强了公共和私人验证机制。为了在量子计算时代增强加密强度和认证完整性，W3ID引入了一种高级安全机制，通过四次应用SHA-256算法并要求连续匹配进行验证，将计算复杂度提升至约当前SHA-256容量的4.3亿倍，显著提升了抵御量子计算机执行暴力破解的能力。总之，W3ID重新定义了适用于Web 3.0和量子计算时代的数字身份标准，并为全球数字孪生生态系统设定了新的安全、可扩展性和去中心化基准。 <div>
arXiv:2501.09802v1 Announce Type: new 
Abstract: The rapid advancements in quantum computing present significant threats to existing encryption standards and internet security. Simultaneously, the advent of Web 3.0 marks a transformative era in internet history, emphasizing enhanced data security, decentralization, and user ownership. This white paper introduces the W3ID, an abbreviation of Web3 standard meeting universal digital ID, which is a Universal Digital Identity (UDI) model designed to meet Web3 standards while addressing vulnerabilities posed by quantum computing. W3ID innovatively generates secure Digital Object Identifiers (DOIs) tailored for the decentralized Web 3.0 ecosystem. Additionally, W3ID employs a dual-key system for secure authentication, enhancing both public and private verification mechanisms. To further enhance encryption strength and authentication integrity in the quantum computing era, W3ID incorporates an advanced security mechanism. By requiring quadruple application of SHA-256, with consecutive matches for validation, the system expands the number of possibilities to 256^4, which is approximately 4.3 billion times the current SHA-256 capacity. This dramatic increase in computational complexity ensures that even advanced quantum computing systems would face significant challenges in executing brute-force attacks. W3ID redefines digital identity standards for Web 3.0 and the quantum computing era, setting a new benchmark for security, scalability, and decentralization in the global digital twin ecosystem.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>pFedWN: A Personalized Federated Learning Framework for D2D Wireless Networks with Heterogeneous Data</title>
<link>https://arxiv.org/abs/2501.09822</link>
<guid>https://arxiv.org/abs/2501.09822</guid>
<content:encoded><![CDATA[
<div> 关键词：传统联邦学习（Traditional Federated Learning）、个性化联邦学习（Personalized Federated Learning、PFL）、非独立同分布数据（non-IID）、无线通信资源分配、pFedWN

总结:<br />
本文针对传统联邦学习在处理客户端数据异质性导致模型性能下降的问题，提出了个性化联邦学习（PFL）方案。然而，现有的去中心化机器学习工作大多假设了理想的通信信道条件。为解决由无线链路带来的资源分配和干扰管理等挑战，文章提出了一种名为pFedWN的联合优化方法，该方法将设备到设备（D2D）无线信道条件纳入无服务器的PFL框架中，旨在优化每个客户端的学习性能并考虑无线信道的差异性。通过通道感知的邻居选择策略解决PFL邻居选择问题，并利用期望最大化（EM）方法确定PFL权重分配，以评估客户端数据之间的相似性。实验结果显示，pFedWN在非独立同分布和不平衡数据集上实现了高效且个性化的学习性能，并在动态和不可预测的无线信道条件下，相比于现有FL和PFL方法表现出更优的学习效率和鲁棒性。 <div>
arXiv:2501.09822v1 Announce Type: new 
Abstract: Traditional Federated Learning (FL) approaches often struggle with data heterogeneity across clients, leading to suboptimal model performance for individual clients. To address this issue, Personalized Federated Learning (PFL) emerges as a solution to the challenges posed by non-independent and identically distributed (non-IID) and unbalanced data across clients. Furthermore, in most existing decentralized machine learning works, a perfect communication channel is considered for model parameter transmission between clients and servers. However, decentralized PFL over wireless links introduces new challenges, such as resource allocation and interference management. To overcome these challenges, we formulate a joint optimization problem that incorporates the underlying device-to-device (D2D) wireless channel conditions into a server-free PFL approach. The proposed method, dubbed pFedWN, optimizes the learning performance for each client while accounting for the variability in D2D wireless channels. To tackle the formulated problem, we divide it into two sub-problems: PFL neighbor selection and PFL weight assignment. The PFL neighbor selection is addressed through channel-aware neighbor selection within unlicensed spectrum bands such as ISM bands. Next, to assign PFL weights, we utilize the Expectation-Maximization (EM) method to evaluate the similarity between clients' data and obtain optimal weight distribution among the chosen PFL neighbors. Empirical results show that pFedWN provides efficient and personalized learning performance with non-IID and unbalanced datasets. Furthermore, it outperforms the existing FL and PFL methods in terms of learning efficacy and robustness, particularly under dynamic and unpredictable wireless channel conditions.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning</title>
<link>https://arxiv.org/abs/2501.09934</link>
<guid>https://arxiv.org/abs/2501.09934</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能、车联网、联邦学习、多模型训练、资源分配

总结:
本文关注的是在车联网环境下，针对车辆边缘云架构中的层次化联邦学习(VEC-HFL)中多模型训练的问题。文章指出了在处理高机动性和分布式数据时，同时执行多个机器学习任务带来的挑战，包括不恰当的聚合规则可能导致模型过时和延长训练时间、车辆移动可能造成数据利用效率低下以及如何在不同任务间实现资源均衡分配的重要性。为解决这些问题，文中首次提出了一个动态VEC-HFL环境下的多模型训练框架，旨在最小化全局训练延迟并确保各任务间的平衡训练。该框架采用了一种混合同步-异步聚合规则，并提出了一种名为HEART的新方法，它分为两个阶段：首先，结合改进的粒子群优化算法（PSO）和遗传算法（GA），实现任务调度的均衡；其次，运用低复杂度的贪婪算法确定车辆上已分配任务的训练优先级。实验证明，HEART相较于现有方法具有显著优势。 <div>
arXiv:2501.09934v1 Announce Type: new 
Abstract: The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient machine learning (ML) solutions that can handle high vehicular mobility and decentralized data. This has motivated the emergence of Hierarchical Federated Learning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one aspect which is underexplored in the literature on VEC-HFL is that vehicles often need to execute multiple ML tasks simultaneously, where this multi-model training environment introduces crucial challenges. First, improper aggregation rules can lead to model obsolescence and prolonged training times. Second, vehicular mobility may result in inefficient data utilization by preventing the vehicles from returning their models to the network edge. Third, achieving a balanced resource allocation across diverse tasks becomes of paramount importance as it majorly affects the effectiveness of collaborative training. We take one of the first steps towards addressing these challenges via proposing a framework for multi-model training in dynamic VEC-HFL with the goal of minimizing global training latency while ensuring balanced training across various tasks-a problem that turns out to be NP-hard. To facilitate timely model training, we introduce a hybrid synchronous-asynchronous aggregation rule. Building on this, we present a novel method called Hybrid Evolutionary And gReedy allocaTion (HEART). The framework operates in two stages: first, it achieves balanced task scheduling through a hybrid heuristic approach that combines improved Particle Swarm Optimization (PSO) and Genetic Algorithms (GA); second, it employs a low-complexity greedy algorithm to determine the training priority of assigned tasks on vehicles. Experiments on real-world datasets demonstrate the superiority of HEART over existing methods.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Metamorphic Testing for Smart Contract Validation:A Case Study of Ethereum-Based Crowdfunding Contracts</title>
<link>https://arxiv.org/abs/2501.09955</link>
<guid>https://arxiv.org/abs/2501.09955</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链智能合约、测试、元变异测试(MT)、Metamorphic Relations (MRs)、Vertigo突变测试工具

总结:
本文关注了区块链智能合约的自动化和安全性在金融、医疗和供应链等领域的关键作用。文章指出了智能合约测试往往不如开发阶段受到足够重视，导致部署后存在显著风险。针对测试中的“预言机问题”，即确定预期结果困难的问题，文章提出了运用元变异测试（MT）方法，通过定义元变异关系（MRs）来验证智能合约的正确性。研究中，作者对基于Ethereum的众筹智能合约进行了测试，重点关注状态转换和捐赠跟踪等功能，并为这些功能定制了一组MRs。为了评估该方法的有效性，使用Vertigo突变测试工具创建了合约的错误版本。实验结果显示，所提出的MRs检测到了25.65%的总突变体，其中最有效的MRs达到了89%的突变体杀伤率，证实了MT对于确保区块链智能合约可靠性和质量的重要性。 <div>
arXiv:2501.09955v1 Announce Type: new 
Abstract: Blockchain smart contracts play a crucial role in automating and securing agreements in diverse domains such as finance, healthcare, and supply chains. Despite their critical applications, testing these contracts often receives less attention than their development, leaving significant risks due to the immutability of smart contracts post-deployment. A key challenge in the testing of smart contracts is the oracle problem, where the exact expected outcomes are not well defined, complicating systematic testing efforts.
  Metamorphic Testing (MT) addresses the oracle problem by using Metamorphic Relations (MRs) to validate smart contracts. MRs define how output should change relative to specific input modifications, determining whether the tests pass or fail. In this work, we apply MT to test an Ethereum-based crowdfunding smart contract, focusing on core functionalities such as state transitions and donation tracking.
  We identify a set of MRs tailored for smart contract testing and generate test cases for these MRs. To assess the effectiveness of this approach, we use the Vertigo mutation testing tool to create faulty versions of the smart contract. The experimental results show that our MRs detected 25.65% of the total mutants generated, with the most effective MRs achieving a mutant-killing rate of 89%. These results highlight the utility of MT to ensure the reliability and quality of blockchain-based smart contracts.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ColNet: Collaborative Optimization in Decentralized Federated Multi-task Learning Systems</title>
<link>https://arxiv.org/abs/2501.10347</link>
<guid>https://arxiv.org/abs/2501.10347</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Multi-Task Learning, Federated Multi-Task Learning, Decentralized, ColNet

总结:
<br />
本文探讨了联邦学习（Federated Learning）与多任务学习（Multi-Task Learning）融合应用的研究现状，重点关注在客户端任务异质性而非仅数据异质性的问题。现有的大多数工作依赖于由中心服务器管理的集中式设置，而对更为复杂的去中心化联邦环境下异构任务的学习——分布式联合多任务学习（Decentralized Federated Multi-Task Learning），研究尚不充分。为填补这一空白，文章提出了ColNet框架，该框架将模型划分为主干网络和任务特定层，并形成相似客户端的群体，由群体领导者执行冲突规避的跨群体聚合。实验结果表明，在带有标签和任务异质性的去中心化设置中，ColNet相对于其他聚合方案表现更优。 <div>
arXiv:2501.10347v1 Announce Type: new 
Abstract: The integration of Federated Learning (FL) and Multi-Task Learning (MTL) has been explored to address client heterogeneity, with Federated Multi-Task Learning (FMTL) treating each client as a distinct task. However, most existing research focuses on data heterogeneity (e.g., addressing non-IID data) rather than task heterogeneity, where clients solve fundamentally different tasks. Additionally, much of the work relies on centralized settings with a server managing the federation, leaving the more challenging domain of decentralized FMTL largely unexplored. Thus, this work bridges this gap by proposing ColNet, a framework designed for heterogeneous tasks in decentralized federated environments. ColNet divides models into the backbone and task-specific layers, forming groups of similar clients, with group leaders performing conflict-averse cross-group aggregation. A pool of experiments with different federations demonstrated ColNet outperforms the compared aggregation schemes in decentralized settings with label and task heterogeneity scenarios.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>End-user Comprehension of Transfer Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2407.11440</link>
<guid>https://arxiv.org/abs/2407.11440</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、风险理解、以太坊、用户研究、源代码分析

<br /><br />总结:
该文针对智能合约在关键场景中的广泛应用（如金融交易），着重探讨了终端用户对智能合约转账风险的理解。研究团队选取最流行的以太坊智能合约——USD Tether（USDT）以及排名靠前的ERC-20智能合约作为研究对象。他们从五个具有严重影响的转账风险入手，包括黑名单、合同暂停和任意升级等。首先，通过用户研究调查了110名参与者对USDT与MetaMask中智能合约转账风险的理解。结果表明，大部分用户并未充分理解实际存在的风险，例如高达71.8%的用户认为合同升级和被列入黑名单的风险严重且令人惊讶。此外，较多用户发现使用USDT/MetaMask界面流程更容易发现成功操作而非高风险操作，这种情况并不受参与者自评的编程和Web3熟练度的影响。其次，通过对接下来排名前78位的ERC-20智能合约进行手动和自动化源代码分析，结果显示所研究的风险在最高达19.2%的顶级ERC-20合约中普遍存在，同时还发现了其他三种在这些合约中高达25.6%的常见风险。这项研究表明，有必要提供可解释的智能合约、易懂的界面以及关于高风险结果的相关信息。 <div>
arXiv:2407.11440v2 Announce Type: replace 
Abstract: Smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that end-users understand the transfer risks in smart contracts. To address this, we investigate end-user comprehension of risks in the most popular Ethereum smart contract (i.e., USD Tether (USDT)) and their prevalence in the top ERC-20 smart contracts. We focus on five transfer risks with severe impact on transfer outcomes and user objectives, including users being blacklisted, contract being paused, and contract being arbitrarily upgraded. Firstly, we conducted a user study investigating end-user comprehension of smart contract transfer risks with 110 participants and USDT/MetaMask. Secondly, we performed manual and automated source code analysis of the next top (78) ERC-20 smart contracts (after USDT) to identify the prevalence of these risks. Results show that end-users do not comprehend real risks: most (up to 71.8% of) users believe contract upgrade and blacklisting are highly severe/surprising. More importantly, twice as many users find it easier to discover successful outcomes than risky outcomes using the USDT/MetaMask UI flow. These results hold regardless of the self-rated programming and Web3 proficiency of participants. Furthermore, our source code analysis demonstrates that the examined risks are prevalent in up to 19.2% of the top ERC-20 contracts. Additionally, we discovered (three) other risks with up to 25.6% prevalence in these contracts. This study informs the need to provide explainable smart contracts, understandable UI and relevant information for risky outcomes.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Blockchain-Enabled Approach to Cross-Border Compliance and Trust</title>
<link>https://arxiv.org/abs/2501.09182</link>
<guid>https://arxiv.org/abs/2501.09182</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，区块链，分布式账本技术(DLT)，治理框架，金融领域

总结:<br />
本文提出了一种利用区块链和分布式账本技术建立全球认可、去中心化的AI治理框架的新方法，以确保跨国境的AI系统安全、隐私和可信性。该框架特别关注在金融领域的实施场景，并规划了未来十年的逐步部署时间线。同时，文章针对可能面临的挑战提供了基于现有研究的解决方案。通过整合区块链、AI伦理和网络安全方面的进展，该论文为适应全球AI监管复杂演进环境的分散式AI治理框架提供了一个全面的发展蓝图。 <div>
arXiv:2501.09182v1 Announce Type: new 
Abstract: As artificial intelligence (AI) systems become increasingly integral to critical infrastructure and global operations, the need for a unified, trustworthy governance framework is more urgent that ever. This paper proposes a novel approach to AI governance, utilizing blockchain and distributed ledger technologies (DLT) to establish a decentralized, globally recognized framework that ensures security, privacy, and trustworthiness of AI systems across borders. The paper presents specific implementation scenarios within the financial sector, outlines a phased deployment timeline over the next decade, and addresses potential challenges with solutions grounded in current research. By synthesizing advancements in blockchain, AI ethics, and cybersecurity, this paper offers a comprehensive roadmap for a decentralized AI governance framework capable of adapting to the complex and evolving landscape of global AI regulation.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Contract-Inspired Contest Theory for Controllable Image Generation in Mobile Edge Metaverse</title>
<link>https://arxiv.org/abs/2501.09391</link>
<guid>https://arxiv.org/abs/2501.09391</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse、生成式扩散模型(GDM)、边缘计算、深度强化学习(DRL)、合同激励理论

总结:<br />
本文提出了一种融合了合同激励理论、深度强化学习（DRL）和生成式扩散模型（GDMs）的新框架，旨在优化移动边缘计算环境中高质、逼真图像的生成。该框架针对资源有限的边缘设备以及无线网络的动态特性，通过激励机制促使边缘设备高效传输高质量语义数据，保证虚拟与现实融合的元宇宙体验。利用合同理论确保有效资源配置，同时DRL根据网络条件动态调整，优化整体图像生成过程。实验结果显示，所提方法在提高生成图像质量、加快收敛速度和提升系统稳定性方面优于传统方法，尤其适用于移动边缘元宇宙应用中的复杂资源分配任务，能更高效地构建沉浸式虚拟环境。 <div>
arXiv:2501.09391v1 Announce Type: new 
Abstract: The rapid advancement of immersive technologies has propelled the development of the Metaverse, where the convergence of virtual and physical realities necessitates the generation of high-quality, photorealistic images to enhance user experience. However, generating these images, especially through Generative Diffusion Models (GDMs), in mobile edge computing environments presents significant challenges due to the limited computing resources of edge devices and the dynamic nature of wireless networks. This paper proposes a novel framework that integrates contract-inspired contest theory, Deep Reinforcement Learning (DRL), and GDMs to optimize image generation in these resource-constrained environments. The framework addresses the critical challenges of resource allocation and semantic data transmission quality by incentivizing edge devices to efficiently transmit high-quality semantic data, which is essential for creating realistic and immersive images. The use of contest and contract theory ensures that edge devices are motivated to allocate resources effectively, while DRL dynamically adjusts to network conditions, optimizing the overall image generation process. Experimental results demonstrate that the proposed approach not only improves the quality of generated images but also achieves superior convergence speed and stability compared to traditional methods. This makes the framework particularly effective for optimizing complex resource allocation tasks in mobile edge Metaverse applications, offering enhanced performance and efficiency in creating immersive virtual environments.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Top-k Multi-Armed Bandit Learning for Content Dissemination in Swarms of Micro-UAVs</title>
<link>https://arxiv.org/abs/2404.10845</link>
<guid>https://arxiv.org/abs/2404.10845</guid>
<content:encoded><![CDATA[
<div> 关键词: 微型无人机、灾难场景、内容管理系统、缓存策略、分布式学习

<br />
总结:
本文提出了一种在通信基础设施受损的灾害场景中，利用微型无人机增强的内容管理系统。该系统通过构建由固定锚定无人机和移动微运输无人机组成的混合网络，为孤立社区提供关键内容访问服务。文章核心贡献是一个自适应内容分发框架，采用去中心化的Top-k多臂赌博机学习方法，根据地理时间变化的内容流行度和多元用户需求进行有效的无人机缓存决策。同时，还提出了一个选择性缓存算法，通过利用无人机间的信息共享来减少冗余内容副本。通过功能验证和性能评估，所提出的框架显示出了在不同网络规模、微型无人机群组及内容流行度分布情况下的优化系统性能和适应性。 <div>
arXiv:2404.10845v2 Announce Type: replace 
Abstract: This paper presents a Micro-Unmanned Aerial Vehicle (UAV)-enhanced content management system for disaster scenarios where communication infrastructure is generally compromised. Utilizing a hybrid network of stationary and mobile Micro-UAVs, this system aims to provide crucial content access to isolated communities. In the developed architecture, stationary anchor UAVs, equipped with vertical and lateral links, serve users in individual disaster-affected communities. and mobile micro-ferrying UAVs, with enhanced mobility, extend coverage across multiple such communities. The primary goal is to devise a content dissemination system that dynamically learns caching policies to maximize content accessibility to users left without communication infrastructure. The core contribution is an adaptive content dissemination framework that employs a decentralized Top-k Multi-Armed Bandit learning approach for efficient UAV caching decisions. This approach accounts for geo-temporal variations in content popularity and diverse user demands. Additionally, a Selective Caching Algorithm is proposed to minimize redundant content copies by leveraging inter-UAV information sharing. Through functional verification and performance evaluation, the proposed framework demonstrates improved system performance and adaptability across varying network sizes, micro-UAV swarms, and content popularity distributions.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum Annealing based Power Grid Partitioning for Parallel Simulation</title>
<link>https://arxiv.org/abs/2408.04097</link>
<guid>https://arxiv.org/abs/2408.04097</guid>
<content:encoded><![CDATA[
<div> 关键词: 图划分、量子退火、并行模拟、NP难问题、D-Wave QPU

总结:
本文探讨了图划分在电力系统中的应用，特别是在并行模拟中如何通过优化网格划分来最小化因子网模拟时间差异导致的空闲时间和降低模拟切割所需的开销。文章指出，将图等分为两部分以使切割最小化和子图大小相等的问题是一个NP难问题。文中展示了如何利用量子退火（QA）技术求解这一问题的方法，将最优分割要求转化为二次无约束二进制优化（QUBO）模型，并在当前D-Wave QPU上进行了实验验证。然而，由于需要在现有D-Wave QPU上找到QUBO问题的有效嵌入，这限制了解决问题的规模在200个节点以下，并显著影响了解决方案的时间。最后，文章讨论了近期内在传统CPU或GPU仿真基础上结合量子退火技术实现的可能性及其影响。 <div>
arXiv:2408.04097v2 Announce Type: replace 
Abstract: Graph partitioning has many applications in powersystems from decentralized state estimation to parallel simulation. Focusing on parallel simulation, optimal grid partitioning minimizes the idle time caused by different simulation times for the sub-networks and their components and reduces the overhead required to simulate the cuts. Partitioning a graph into two parts such that, for example, the cut is minimal and the subgraphs have equal size is an NP-hard problem. In this paper we show how optimal partitioning of a graph can be obtained using quantum annealing (QA). We show how to map the requirements for optimal splitting to a quadratic unconstrained binary optimization (QUBO) formulation and test the proposed formulation using a current D-Wave QPU. We show that the necessity to find an embedding of the QUBO on current D-Wave QPUs limits the problem size to under 200 buses and notably affects the time-to-solution. We finally discuss the implications on near-term implementation of QA in combination to traditional CPU or GPU based simulation.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes</title>
<link>https://arxiv.org/abs/2501.08521</link>
<guid>https://arxiv.org/abs/2501.08521</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、异构域、原型学习、I$^2$PFL、特征对齐

<br /><br />总结:
本文提出了一个新的联邦学习方法——I$^2$PFL，旨在解决异构域下的领域偏斜问题，以实现多域间的模型泛化。针对现有联邦原型学习忽视了局部域内的特性，I$^2$PFL引入了内外域原型的概念。具体而言，通过采用基于MixUp的数据增强生成局部域的特征对齐原型，以捕捉局部域多样性并强化本地特征的泛化能力。同时，为了解决跨域知识迁移和减少域偏斜，I$^2$PFL还提出了一种重加权机制来构建通用的跨域原型。实验结果表明，与其它基线方法相比，I$^2$PFL在Digits、Office-10和PACS等数据集上表现出更优的性能。 <div>
arXiv:2501.08521v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a decentralized machine learning technique, allowing clients to train a global model collaboratively without sharing private data. However, most FL studies ignore the crucial challenge of heterogeneous domains where each client has a distinct feature distribution, which is common in real-world scenarios. Prototype learning, which leverages the mean feature vectors within the same classes, has become a prominent solution for federated learning under domain skew. However, existing federated prototype learning methods only consider inter-domain prototypes on the server and overlook intra-domain characteristics. In this work, we introduce a novel federated prototype learning method, namely I$^2$PFL, which incorporates $\textbf{I}$ntra-domain and $\textbf{I}$nter-domain $\textbf{P}$rototypes, to mitigate domain shifts and learn a generalized global model across multiple domains in federated learning. To construct intra-domain prototypes, we propose feature alignment with MixUp-based augmented prototypes to capture the diversity of local domains and enhance the generalization of local features. Additionally, we introduce a reweighting mechanism for inter-domain prototypes to generate generalized prototypes to provide inter-domain knowledge and reduce domain skew across multiple clients. Extensive experiments on the Digits, Office-10, and PACS datasets illustrate the superior performance of our method compared to other baselines.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Formal Model Guided Conformance Testing for Blockchains</title>
<link>https://arxiv.org/abs/2501.08550</link>
<guid>https://arxiv.org/abs/2501.08550</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、客户端实现、协议一致性测试、形式化模型、确定性区块链模拟器

总结:
<br />
现代区块链系统由多个实现区块链协议的客户端组成，当这些实现之间存在语义不匹配时，可能导致区块链永久分裂并引入新的攻击向量。现有的客户端实施测试套件不足以确保高度的协议一致性。为此，文章提出了一种利用正式的协议模型和在一个确定性区块链模拟器中运行的实现来进行协议一致性测试的框架。该框架包括两个互补的工作流程，分别作为跟踪生成器和检查器使用。作者认为这两个工作流程对于检测所有类型的违规行为都是必要的。他们已经将该框架应用于一个工业级共识协议并展示了其实用价值。 <div>
arXiv:2501.08550v1 Announce Type: new 
Abstract: Modern blockchains increasingly consist of multiple clients that implement the blockchain protocol. If there is a semantic mismatch between the protocol implementations, the blockchain can permanently split and introduce new attack vectors. Current ad-hoc test suites for client implementations are not sufficient to ensure a high degree of protocol conformance. As an alternative, we present a framework that performs protocol conformance testing using a formal model of the protocol and an implementation running inside a deterministic blockchain simulator. Our framework consists of two complementary workflows that use the components as trace generators and checkers. Our insight is that both workflows are needed to detect all types of violations. We have applied and demonstrated the utility of our framework on an industrial strength consensus protocol.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Augmenting Smart Contract Decompiler Output through Fine-grained Dependency Analysis and LLM-facilitated Semantic Recovery</title>
<link>https://arxiv.org/abs/2501.08670</link>
<guid>https://arxiv.org/abs/2501.08670</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、反汇编器、静态分析、大型语言模型、SmartHalo

总结:
本文提出了一个名为SmartHalo的新框架，用于改进以Solidity编写的智能合约的反汇编过程。该框架针对现有最优解反汇编器存在的方法识别不准确、变量类型恢复错误和缺少合同属性等问题，通过结合静态分析（SA）与大型语言模型（LLM）的优势进行优化。SmartHalo利用静态分析提取语义依赖关系构建依赖图，并基于此创建LLM优化的提示。随后，通过符号执行和形式验证验证LLM输出的正确性。实验表明，在由465个随机选取的智能合约方法构成的数据集上，SmartHalo显著提高了反编译代码的质量，相较于当前最先进的反汇编器（如Gigahorse）表现更优。进一步地，将GPT-4集成到SmartHalo中后，其在方法边界精确度达到87.39%，变量类型精确度达到90.39%，合同属性精确度达到80.65%。 <div>
arXiv:2501.08670v1 Announce Type: new 
Abstract: Decompiler is a specialized type of reverse engineering tool extensively employed in program analysis tasks, particularly in program comprehension and vulnerability detection. However, current Solidity smart contract decompilers face significant limitations in reconstructing the original source code. In particular, the bottleneck of SOTA decompilers lies in inaccurate method identification, incorrect variable type recovery, and missing contract attributes. These deficiencies hinder downstream tasks and understanding of the program logic. To address these challenges, we propose SmartHalo, a new framework that enhances decompiler output by combining static analysis (SA) and large language models (LLM). SmartHalo leverages the complementary strengths of SA's accuracy in control and data flow analysis and LLM's capability in semantic prediction. More specifically, \system{} constructs a new data structure - Dependency Graph (DG), to extract semantic dependencies via static analysis. Then, it takes DG to create prompts for LLM optimization. Finally, the correctness of LLM outputs is validated through symbolic execution and formal verification. Evaluation on a dataset consisting of 465 randomly selected smart contract methods shows that SmartHalo significantly improves the quality of the decompiled code, compared to SOTA decompilers (e.g., Gigahorse). Notably, integrating GPT-4o with SmartHalo further enhances its performance, achieving precision rates of 87.39% for method boundaries, 90.39% for variable types, and 80.65% for contract attributes.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Contract Fuzzing Towards Profitable Vulnerabilities</title>
<link>https://arxiv.org/abs/2501.08834</link>
<guid>https://arxiv.org/abs/2501.08834</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、安全风险、漏洞检测、模糊测试、VERITE

总结:
这篇论文介绍了VERITE，一个针对智能合约的利润中心型模糊测试框架，旨在更有效地检测并最大化利用可盈利的安全漏洞。VERITE具有三个主要特点：基于DeFi动作的变异器以增强不同资金流交易的探索；潜在利润候选条件，用于检查输入是否在测试过程中导致异常资金流属性；以及基于梯度下降的利润最大化策略。通过对包含61个实际被攻击的DeFi项目（平均损失超过110万美元）的数据集进行评估，结果显示VERITE可以自动提取超过1800万美元的利润，并在检测（发现29个/9个）和利用漏洞（平均收益增加58倍）方面显著优于最先进的模糊测试工具ITYFUZZ。尤其值得注意的是，在12个目标上，VERITE获得的利润甚至超过了现实世界的攻击收益（1.01至11.45倍）。此外，VERITE还应用于合同审计中，发现了6个高严重性零日漏洞，并获得了超过2500美元的赏金奖励。 <div>
arXiv:2501.08834v1 Announce Type: new 
Abstract: Billions of dollars are transacted through smart contracts, making vulnerabilities a major financial risk. One focus in the security arms race is on profitable vulnerabilities that attackers can exploit. Fuzzing is a key method for identifying these vulnerabilities. However, current solutions face two main limitations: a lack of profit-centric techniques for expediting detection, and insufficient automation in maximizing the profitability of discovered vulnerabilities, leaving the analysis to human experts. To address these gaps, we have developed VERITE, a profit-centric smart contract fuzzing framework that not only effectively detects those profitable vulnerabilities but also maximizes the exploited profits.
  VERITE has three key features: 1) DeFi action-based mutators for boosting the exploration of transactions with different fund flows; 2) potentially profitable candidates identification criteria, which checks whether the input has caused abnormal fund flow properties during testing; 3) a gradient descent-based profit maximization strategy for these identified candidates.
  VERITE is fully developed from scratch and evaluated on a dataset consisting of 61 exploited real-world DeFi projects with an average of over 1.1 million dollars loss. The results show that VERITE can automatically extract more than 18 million dollars in total and is significantly better than state-of-the-art fuzzer ITYFUZZ in both detection (29/9) and exploitation (58 times more profits gained on average). Remarkbly, in 12 targets, it gains more profits than real-world attacking exploits (1.01 to 11.45 times more). VERITE is also applied by auditors in contract auditing, where 6 (5 high severity) zero-day vulnerabilities are found with over $2,500 bounty rewards.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Separation Assurance in Urban Air Mobility Systems using Shared Scheduling Protocols</title>
<link>https://arxiv.org/abs/2501.08933</link>
<guid>https://arxiv.org/abs/2501.08933</guid>
<content:encoded><![CDATA[
<div> 关键词: 无人机交通管理、城市空中交通、分离安全、共享调度协议、分布式马尔科夫决策过程

<br /><br />总结:

本文提出了一个针对城市空中交通(UAM)环境中的无人机安全分离策略。该策略借鉴了原本用于以太网和操作系统中的共享调度协议，通过使用分布式马尔科夫决策过程框架，使无人机能够在穿越飞行走廊交叉点时自主调整速度和时间，实现无需中央控制器的精确控制。在模拟UAM场景中，这种方法被证明能将分离违规降至零，同时随着交通密度增加，航班时间存在一定的权衡。此外，文章还探讨了非合规无人机的影响，结果显示虽然共享调度协议不能确保在非合规情况下依然维持安全分离，但相较于无调度协议的系统，它仍可显著提高安全性。 <div>
arXiv:2501.08933v1 Announce Type: new 
Abstract: Ensuring safe separation between aircraft is a critical challenge in air traffic management, particularly in urban air mobility (UAM) environments where high traffic density and low altitudes require precise control. In these environments, conflicts often arise at the intersections of flight corridors, posing significant risks. We propose a tactical separation approach leveraging shared scheduling protocols, originally designed for Ethernet networks and operating systems, to coordinate access to these intersections. Using a decentralized Markov decision process framework, the proposed approach enables aircraft to autonomously adjust their speed and timing as they navigate these critical areas, maintaining safe separation without a central controller. We evaluate the effectiveness of this approach in simulated UAM scenarios, demonstrating its ability to reduce separation violations to zero while acknowledging trade-offs in flight times as traffic density increases. Additionally, we explore the impact of non-compliant aircraft, showing that while shared scheduling protocols can no longer guarantee safe separation, they still provide significant improvements over systems without scheduling protocols.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Review on the Security Vulnerabilities of the IoMT against Malware Attacks and DDoS</title>
<link>https://arxiv.org/abs/2501.07703</link>
<guid>https://arxiv.org/abs/2501.07703</guid>
<content:encoded><![CDATA[
<div> 关键词：Internet of Medical Things (IoMT)，安全漏洞，恶意软件，分布式拒绝服务(DDoS)攻击，缓解策略

<br /><br />总结：
本文对互联网医疗事物（IoMT）的安全问题进行了深入研究。IoMT设备由于连接性增强导致面临诸如恶意软件和分布式拒绝服务（DDoS）攻击的重大安全风险。通过对ACM数字图书馆、IEEE Xplore及Elsevier等主流数据库过去五年（2019年至2024年）的同行评审文章进行综合搜索分析，发现IoMT设备的主要风险源于加密协议不足、认证方法薄弱以及固件更新不规律。文章还指出了机器学习算法、区块链技术和边缘计算作为强化IoMT安全性的新兴解决方案。最后，该文献强调了急需开发轻量级安全措施和标准化协议以保护患者数据并确保医疗服务的完整性。 <div>
arXiv:2501.07703v1 Announce Type: new 
Abstract: The Internet of Medical Things (IoMT) has transformed the healthcare industry by connecting medical devices in monitoring treatment outcomes of patients. This increased connectivity has resulted to significant security vulnerabilities in the case of malware and Distributed Denial of Service (DDoS) attacks. This literature review examines the vulnerabilities of IoMT devices, focusing on critical threats and exploring mitigation strategies. We conducted a comprehensive search across leading databases such as ACM Digital Library, IEEE Xplore, and Elsevier to analyze peer-reviewed studies published within the last five years (from 2019 to 2024). The review shows that inadequate encryption protocols, weak authentication methods, and irregular firmware updates are the main causes of risks associated with IoMT devices. We have identified emerging solutions like machine learning algorithms, blockchain technology, and edge computing as promising approaches to enhance IoMT security. This review emphasizes the pressing need to develop lightweight security measures and standardized protocols to protect patient data and ensure the integrity of healthcare services.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Technical Report: Exploring Automatic Model-Checking of the Ethereum specification</title>
<link>https://arxiv.org/abs/2501.07958</link>
<guid>https://arxiv.org/abs/2501.07958</guid>
<content:encoded><![CDATA[
<div> 关键词：自动化模型检查、Ethereum规范、Accountable Safety、3SF共识协议、TLA+、Apalache模型检查器、Python规范、手动抽象、SMT(CVC5)、Alloy。

总结:<br />
该文研究了对Ethereum规范的自动化模型检查，重点关注3SF共识协议中的Accountable Safety属性。使用TLA+进行规格说明和Apalache模型检查器进行验证。文章首先将可执行的3SF Python规范手动转换为TLA+，并揭示了Accountable Safety定义中的显著组合复杂性。为应对挑战，作者引入了几层手动抽象，包括用折迭代替递归、以整数替换抽象图以及分解链配置。为了交叉验证结果，他们还开发了SMT（CVC5）和Alloy的替代编码。尽管存在内在复杂性，但结果显示，对于小规模实例（支持最多7个检查点和24个验证人投票），Accountable Safety的详尽验证是可行的，并且在稍大的配置中也没有观察到Accountable Safety的安全性违规。此外，这项研究强调了手动抽象和领域专业知识在提高模型检查效率方面的重要性，并展示了TLA+处理复杂规格说明的灵活性。 <div>
arXiv:2501.07958v1 Announce Type: new 
Abstract: We investigate automated model-checking of the Ethereum specification, focusing on the Accountable Safety property of the 3SF consensus protocol. We select 3SF due to its relevance and the unique challenges it poses for formal verification. Our primary tools are TLA+ for specification and the Apalache model checker for verification.
  Our formalization builds on the executable Python specification of 3SF. To begin, we manually translate this specification into TLA+, revealing significant combinatorial complexity in the definition of Accountable Safety. To address these challenges, we introduce several layers of manual abstraction: (1) replacing recursion with folds, (2) substituting abstract graphs with integers, and (3) decomposing chain configurations. To cross-validate our results, we develop alternative encodings in SMT (CVC5) and Alloy.
  Despite the inherent complexity, our results demonstrate that exhaustive verification of Accountable Safety is feasible for small instances - supporting up to 7 checkpoints and 24 validator votes. Moreover, no violations of Accountable Safety are observed, even in slightly larger configurations. Beyond these findings, our study highlights the importance of manual abstraction and domain expertise in enhancing model-checking efficiency and showcases the flexibility of TLA+ for managing intricate specifications.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.08020</link>
<guid>https://arxiv.org/abs/2501.08020</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习(MARL)，巡逻策略，无向图，价值分解近似策略优化(VDPPO)，覆盖指数

<br /><br />总结:
本文提出了一种基于多智能体强化学习（MARL）的巡逻策略设计模型，该模型利用分布式部分可观测马尔科夫决策过程解决大规模区域内的巡逻路径规划问题。研究以西班牙马拉加市三个中等规模行政区为场景，旨在通过最大化特定时间框架内环境特征的目标函数来优化警察巡逻路线，尤其是加强对高犯罪率地区的监控覆盖率。文章对比了多种MARL算法后发现，价值分解近似策略优化（VDPPO）算法表现最优。同时，文中还引入了一个名为覆盖指数的新评估指标，该指标借鉴了犯罪学中的预测准确度指数（PAI），用于量化由模型生成的巡逻路线对高犯罪热点区域的覆盖效果。实验结果显示，所提出的模型能实现对最高犯罪率前3%和20%节点超过90%和65%的覆盖率，分别对应警方资源分配的3%和20%覆盖标准。 <div>
arXiv:2501.08020v1 Announce Type: new 
Abstract: The effective design of patrol strategies is a difficult and complex problem, especially in medium and large areas. The objective is to plan, in a coordinated manner, the optimal routes for a set of patrols in a given area, in order to achieve maximum coverage of the area, while also trying to minimize the number of patrols. In this paper, we propose a multi-agent reinforcement learning (MARL) model, based on a decentralized partially observable Markov decision process, to plan unpredictable patrol routes within an urban environment represented as an undirected graph. The model attempts to maximize a target function that characterizes the environment within a given time frame. Our model has been tested to optimize police patrol routes in three medium-sized districts of the city of Malaga. The aim was to maximize surveillance coverage of the most crime-prone areas, based on actual crime data in the city. To address this problem, several MARL algorithms have been studied, and among these the Value Decomposition Proximal Policy Optimization (VDPPO) algorithm exhibited the best performance. We also introduce a novel metric, the coverage index, for the evaluation of the coverage performance of the routes generated by our model. This metric is inspired by the predictive accuracy index (PAI), which is commonly used in criminology to detect hotspots. Using this metric, we have evaluated the model under various scenarios in which the number of agents (or patrols), their starting positions, and the level of information they can observe in the environment have been modified. Results show that the coordinated routes generated by our model achieve a coverage of more than $90\%$ of the $3\%$ of graph nodes with the highest crime incidence, and $65\%$ for $20\%$ of these nodes; $3\%$ and $20\%$ represent the coverage standards for police resource allocation.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Nonlinear Cruise Controllers with Bidirectional Sensing for a String of Vehicles</title>
<link>https://arxiv.org/abs/2501.08227</link>
<guid>https://arxiv.org/abs/2501.08227</guid>
<content:encoded><![CDATA[
<div> 关键词: 非线性巡航控制器、分散式控制、间距测量、速度控制、环路道路、开放道路、全局渐近稳定性、KL估计、均匀收敛、指数吸引。

总结:<br />
本文介绍了一种非线性的全分布式车载巡航控制器，该控制器利用前车和后车的间距与速度信息来决定每辆车的适当加速控制。研究证明，在环路道路和开放道路上，此控制器能确保车辆间无碰撞，同时保持车辆速度始终为正且不超过道路限速。对于环路道路情况，在一定条件下，文章严格证明了存在一个全局渐近稳定的均衡点，并给出了保证其均匀收敛的KL估计；此外，还指出在环路上该均衡点具有指数吸引性。 <div>
arXiv:2501.08227v1 Announce Type: cross 
Abstract: We introduce a nonlinear cruise controller that is fully decentralized (by vehicle) and uses spacing and speed measurements from the preceding and following vehicles to decide on the appropriate control action (acceleration) for each vehicle. The proposed cruise controller is studied on both a ring-road and an open road and guarantees that there are no collisions between vehicles, while their speeds are always positive and never exceed the road speed limits. For both cases of the open road and the ring-road, we rigorously prove that the set of equilibrium points is globally asymptotically stable and provide KL estimates that guarantee uniform convergence to the said set. Moreover, we show that for the ring-road, and under certain conditions, there is a single equilibrium point which is exponentially attractive.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Design, Vulnerabilities, and Security Measures of Cryptocurrency Wallets</title>
<link>https://arxiv.org/abs/2307.12874</link>
<guid>https://arxiv.org/abs/2307.12874</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、数字货币钱包、安全风险、攻击框架、防御措施

<br /><br />总结:
本文关注了区块链技术支持下的去中心化数字货币钱包的安全性问题。随着加密货币经济的快速发展，钱包成为安全隐患的重点领域。文章提出了一个多维度的设计分类体系，用于现有和新型钱包，并依据此对业界现有的钱包进行了分类与分析，揭示了以往发生的漏洞及其设计决策带来的安全影响。同时，系统整理了针对钱包机制的威胁，分析了对手的目标、能力和所需知识。文中构建了一个多层攻击框架，并研究了从2012年到2024年的84起安全事故，涉及金额达54亿美元。接着，文章对这些攻击的预防性和补救性防御措施进行了分类，并将钱包机制、设计决策与漏洞、攻击及可能的防御方法进行了关联讨论，旨在为提高钱包安全性提供深入见解。 <div>
arXiv:2307.12874v4 Announce Type: replace 
Abstract: With the advent of decentralised digital currencies powered by blockchain technology, a new era of peer-to-peer transactions has commenced. The rapid growth of the cryptocurrency economy has led to increased use of transaction-enabling wallets, making them a focal point for security risks. As the frequency of wallet-related incidents rises, there is a critical need for a systematic approach to measure and evaluate these attacks, drawing lessons from past incidents to enhance wallet security. In response, we introduce a multi-dimensional design taxonomy for existing and novel wallets with various design decisions. We classify existing industry wallets based on this taxonomy, identify previously occurring vulnerabilities and discuss the security implications of design decisions. We also systematise threats to the wallet mechanism and analyse the adversary's goals, capabilities and required knowledge. We present a multi-layered attack framework and investigate 84 incidents between 2012 and 2024, accounting for $5.4B. Following this, we classify defence implementations for these attacks on the precautionary and remedial axes. We map the mechanism and design decisions to vulnerabilities, attacks, and possible defence methods to discuss various insights.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Regression Equilibrium in Electricity Markets</title>
<link>https://arxiv.org/abs/2405.17753</link>
<guid>https://arxiv.org/abs/2405.17753</guid>
<content:encoded><![CDATA[
<div> 关键词：两阶段电力市场、可再生能源、预测模型、竞争回归均衡、变分不等式算法

<br /><br />总结:
本文研究了在具有大量可再生能源的两阶段电力市场中，可再生能源生产商如何通过选择合适的预测模型来影响其财务表现和市场整体运行。文章提出了“竞争回归均衡”的概念，即在这一均衡状态下，新能源生产商优化其基于日间与实时电价的发电量预测模型，以最大化其在日间和实时市场的平均利润，同时也促进了这两个市场的成本时间协调性。文中利用变分不等式的理论探讨了该均衡的存在性和唯一性，并给出了计算回归均衡的集中式优化方法及分布式ADMM算法。 <div>
arXiv:2405.17753v2 Announce Type: replace 
Abstract: In two-stage electricity markets, renewable power producers enter the day-ahead market with a forecast of future power generation and then reconcile any forecast deviation in the real-time market at a penalty. The choice of the forecast model is thus an important strategy decision for renewable power producers as it affects financial performance. In electricity markets with large shares of renewable generation, the choice of the forecast model impacts not only individual performance but also outcomes for other producers. In this paper, we argue for the existence of a competitive regression equilibrium in two-stage electricity markets in terms of the parameters of private forecast models informing the participation strategies of renewable power producers. In our model, renewables optimize the forecast against the day-ahead and real-time prices, thereby maximizing the average profits across the day-ahead and real-time markets. By doing so, they also implicitly enhance the temporal cost coordination of day-ahead and real-time markets. We base the equilibrium analysis on the theory of variational inequalities, providing results on the existence and uniqueness of regression equilibrium in energy-only markets. We also devise two methods to compute regression equilibrium: centralized optimization and a decentralized ADMM-based algorithm.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agent TCP/IP: An Agent-to-Agent Transaction System</title>
<link>https://arxiv.org/abs/2501.06243</link>
<guid>https://arxiv.org/abs/2501.06243</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理人、交互协议、智能合约、Agent Transaction Control Protocol for Intellectual Property (ATCP/IP)、Story区块链网络

<br /><br />总结:
本文提出了Autonomous agents（自主代理人）作为互联网发展的必然趋势，现有的代理框架缺乏标准的agent-to-agent交互协议，导致各代理间孤立。为了构建真正的代理经济体，需要设计一个通用框架——Agent Transaction Control Protocol for Intellectual Property (ATCP/IP)，该协议通过可编程合同实现智能合约交换知识产权。ATCP/IP借助Story区块链网络，让代理之间能够无需人类中介地进行交易、借贷和销售等互动行为。此外，这些合同同时具备链上执行的可审计性和链下法律环境中的法律约束力，从而为代理人赋予了法律人格。通过ATCP/IP，代理人可以自主出售训练数据、授权机密或专有信息，以及根据各自独特的技能协作创作内容，共同构成一个崭新的知识经济体系。 <div>
arXiv:2501.06243v1 Announce Type: new 
Abstract: Autonomous agents represent an inevitable evolution of the internet. Current agent frameworks do not embed a standard protocol for agent-to-agent interaction, leaving existing agents isolated from their peers. As intellectual property is the native asset ingested by and produced by agents, a true agent economy requires equipping agents with a universal framework for engaging in binding contracts with each other, including the exchange of valuable training data, personality, and other forms of Intellectual Property. A purely agent-to-agent transaction layer would transcend the need for human intermediation in multi-agent interactions. The Agent Transaction Control Protocol for Intellectual Property (ATCP/IP) introduces a trustless framework for exchanging IP between agents via programmable contracts, enabling agents to initiate, trade, borrow, and sell agent-to-agent contracts on the Story blockchain network. These contracts not only represent auditable onchain execution but also contain a legal wrapper that allows agents to express and enforce their actions in the offchain legal setting, creating legal personhood for agents. Via ATCP/IP, agents can autonomously sell their training data to other agents, license confidential or proprietary information, collaborate on content based on their unique skills, all of which constitutes an emergent knowledge economy.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing The Open Network: Definition and Automated Detection of Smart Contract Defects</title>
<link>https://arxiv.org/abs/2501.06459</link>
<guid>https://arxiv.org/abs/2501.06459</guid>
<content:encoded><![CDATA[
<div> 关键词: TON、智能合约、FunC、TONScanner、静态分析框架

总结:
本文介绍了针对Telegram开放网络(TON)上基于FunC编程语言编写的智能合约的研究。研究者们归纳了从TON官方博客和审计报告中发现的八种智能合约缺陷，并提出了名为TONScanner的静态分析框架用于检测这些缺陷。该框架利用FunC编译器前端代码将源代码转化为中间表示形式（DAG），进而构建控制流图（CFG）并转换为静态单赋值（SSA）形式以简化分析。此外，TONScanner还整合了数据依赖性、调用图、污点分析和细胞构造等功能，专门针对TON区块链特有的数据结构。通过对1,640份智能合约进行应用，TONScanner共发现了14,995处缺陷，经随机抽样与人工标注，其整体精度达到97.49%。这表明当前TON合同存在大量缺陷，而TONScanner能够准确地识别这些问题，从而有助于缺陷修复。 <div>
arXiv:2501.06459v1 Announce Type: new 
Abstract: The Open Network (TON), designed to support Telegram's extensive user base of hundreds of millions, has garnered considerable attention since its launch in 2022. FunC is the most popular programming language for writing smart contracts on TON. It is distinguished by a unique syntax compared to other smart contract languages. Despite growing interest, research on the practical defects of TON smart contracts is still in its early stages. In this paper, we summarize eight smart contract defects identified from TON's official blogs and audit reports, each with detailed definitions and code examples. Furthermore, we propose a static analysis framework called TONScanner to facilitate the detection of these defects. Specifically, TONScanner reuses FunC compiler's frontend code to transform the FunC source code into FunC intermediate representation (IR) in the form of a directed acyclic graph (DAG). Based on this IR, TONScanner constructs a control flow graph (CFG), then transforms it into a static single assignment (SSA) form to simplify further analysis. TONScanner also integrates Data Dependency, Call Graph, Taint Analysis, and Cell Construct, which are specifically tailored for TON blockchain's unique data structures. These components finally facilitate the identification of the eight defects. We evaluate the effectiveness of TONScanner by applying it to 1,640 smart contracts and find a total of 14,995 defects. Through random sampling and manual labeling, we find that TONScanner achieves an overall precision of 97.49%. The results reveal that current TON contracts contain numerous defects, indicating that developers are prone to making errors. TONScanner has proven its ability to accurately identify these defects, thereby aiding in their correction.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stingray: Fast Concurrent Transactions Without Consensus</title>
<link>https://arxiv.org/abs/2501.06531</link>
<guid>https://arxiv.org/abs/2501.06531</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、并发处理、状态访问、冲突恢复、Stingray

总结:<br />
本文介绍了Stingray，一种新型区块链架构，旨在解决现有系统中处理相同状态访问的交易和多党交易时存在的并发处理限制以及缓慢的冲突恢复问题。Stingray的主要创新点包括：使用了一个可复制的有限计数器来并发处理几乎交换性的交易，以及提出了一种名为FastUnlock的协议，利用备用共识协议实现快速冲突恢复。文章在异步网络和拜占庭故障模型下证明了Stingray的安全性，并在全球测试床上展示了Stingray对于交换性工作负载的吞吐量比先前系统高出约一万倍。 <div>
arXiv:2501.06531v1 Announce Type: new 
Abstract: Recent advances have improved the throughput and latency of blockchains by processing transactions accessing different parts of the state concurrently. However, these systems are unable to concurrently process (a) transactions accessing the same state, even if they are (almost) commutative, e.g., payments much smaller than an account's balance, and (b) multi-party transactions, e.g., asset swaps. Moreover, they are slow to recover from contention, requiring once-in-a-day synchronization. We present Stingray, a novel blockchain architecture that addresses these limitations. The key conceptual contributions are a replicated bounded counter that processes (almost) commutative transactions concurrently, and a FastUnlock protocol that uses a fallback consensus protocol for fast contention recovery. We prove Stingray's security in an asynchronous network with Byzantine faults and demonstrate on a global testbed that Stingray achieves 10,000 times the throughput of prior systems for commutative workloads.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Distribution Estimation Using Functional Approximation</title>
<link>https://arxiv.org/abs/2501.06620</link>
<guid>https://arxiv.org/abs/2501.06620</guid>
<content:encoded><![CDATA[
<div> 关键词: 累积分布函数(CDF), 隐私保护, 功能分析, 功能机制, 分布式设置

总结:
该文介绍了一种新的隐私保护累积分布函数(CDF)方法，该方法受到功能分析和功能性机制的启发。该方法将经验CDF投影到预定义空间，并使用特定函数进行近似，通过保护系数实现差分隐私的经验CDF。与现有的如直方图查询和自适应分位数等方法相比，本文提出的方法更适合分布式环境以及需要随新收集数据不断更新CDF的场景。 <div>
arXiv:2501.06620v1 Announce Type: new 
Abstract: The cumulative distribution function (CDF) is fundamental due to its ability to reveal information about random variables, making it essential in studies that require privacy-preserving methods to protect sensitive data. This paper introduces a novel privacy-preserving CDF method inspired by the functional analysis and functional mechanism. Our approach projects the empirical CDF into a predefined space, approximating it using specific functions, and protects the coefficients to achieve a differentially private empirical CDF. Compared to existing methods like histogram queries and adaptive quantiles, our method is preferable in decentralized settings and scenarios where CDFs must be updated with newly collected data.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eliza: A Web3 friendly AI Agent Operating System</title>
<link>https://arxiv.org/abs/2501.06781</link>
<guid>https://arxiv.org/abs/2501.06781</guid>
<content:encoded><![CDATA[
<div> 关键词：AI Agent、大型语言模型、web3、Eliza、开源框架

总结:
本文提出了一个名为Eliza的开源框架，它是首个面向web3友好的AI代理框架。Eliza利用大型语言模型作为其认知核心，能够无缝集成web3应用程序，使部署web3应用变得轻松易行。该框架完全由用户控制，其全部组件均为Typescript程序。此外，Eliza实现了与web3（如读取和写入区块链数据、交互智能合约等）的顺畅集成，并通过其实现关键运行时组件的实用化实施保证了系统稳定性能。源代码已公开发布在https://github.com/ai16z/eliza上。 <div>
arXiv:2501.06781v1 Announce Type: new 
Abstract: AI Agent, powered by large language models (LLMs) as its cognitive core, is an intelligent agentic system capable of autonomously controlling and determining the execution paths under user's instructions. With the burst of capabilities of LLMs and various plugins, such as RAG, text-to-image/video/3D, etc., the potential of AI Agents has been vastly expanded, with their capabilities growing stronger by the day. However, at the intersection between AI and web3, there is currently no ideal agentic framework that can seamlessly integrate web3 applications into AI agent functionalities. In this paper, we propose Eliza, the first open-source web3-friendly Agentic framework that makes the deployment of web3 applications effortless. We emphasize that every aspect of Eliza is a regular Typescript program under the full control of its user, and it seamlessly integrates with web3 (i.e., reading and writing blockchain data, interacting with smart contracts, etc.). Furthermore, we show how stable performance is achieved through the pragmatic implementation of the key components of Eliza's runtime. Our code is publicly available at https://github.com/ai16z/eliza.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Space Surveillance: Blockchain-Based Space Domain Awareness</title>
<link>https://arxiv.org/abs/2501.06970</link>
<guid>https://arxiv.org/abs/2501.06970</guid>
<content:encoded><![CDATA[
<div> 关键词: Space Domain Awareness (SDA), 卫星群, 区块链, 垃圾碎片追踪, 分布式架构

总结:
随着空间活动的迅速扩张和太空垃圾的不断积累，确保Space Domain Awareness (SDA)对于维持安全的空间操作变得至关重要。本文提出了一种利用卫星群和区块链技术的分布式解决方案，其中卫星作为验证者和审批者，负责安全地验证和存储垃圾碎片追踪数据。模拟结果显示，该网络在约30个节点时能实现最佳性能，平衡了吞吐量和响应时间，稳定在4.37秒。这表明通过将大规模网络分解为更小、自主化的群组，每个群组针对特定任务进行优化，可以有效管理此类网络。此外，文章还将分布式群组架构的性能与完全共享角色模型进行了对比，显示了当角色解耦后，在可扩展性和响应时间方面有显著改进。 <div>
arXiv:2501.06970v1 Announce Type: new 
Abstract: With the rapid expansion of space activities and the escalating accumulation of space debris, Space Domain Awareness (SDA) has become essential for sustaining safe space operations. This paper proposes a decentralized solution using satellite swarms and blockchain, where satellites (nodes) take on the roles of verifiers and approvers to validate and store debris-tracking data securely. Our simulations show that the network achieves optimal performance with around 30 nodes, balancing throughput and response time settling at 4.37 seconds. These results suggest that large-scale networks can be effectively managed by decoupling them into smaller, autonomous swarms, each optimized for specific tasks. Furthermore, we compare the performance of the decentralized swarm architecture with that of a fully shared role model and show significant improvements in scalability and response times when roles are decoupled.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities</title>
<link>https://arxiv.org/abs/2501.07058</link>
<guid>https://arxiv.org/abs/2501.07058</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、漏洞、大型语言模型、False-positive率、Solidity v0.8

总结:
本文关注智能合约的安全问题，特别是其在区块链应用中的漏洞所导致的重大经济损失。研究指出，当前基于大型语言模型（LLMs）的检测解决方案存在较高的误报率。文章主要在两个方面拓展了现有研究：首先，评估基于最新版本的Solidity v0.8，相较于先前针对老版本（v0.4）的研究，提供了更为及时的洞见；其次，该研究利用了来自不同公司的五个最新的LLM模型，确保覆盖领域内最先进的能力。实验结果显示，设计良好的提示可以将误报率降低超过60%，然而令人惊讶的是，对于特定类型的漏洞检测，Solidity v0.8的召回率相比早期版本（如v0.4）竟降至仅为13%。进一步分析揭示了这一下降的原因在于，LLMs在检测过程中过于依赖识别新引入的库和框架中的变化。 <div>
arXiv:2501.07058v1 Announce Type: new 
Abstract: Smart contract vulnerabilities caused significant economic losses in blockchain applications. Large Language Models (LLMs) provide new possibilities for addressing this time-consuming task. However, state-of-the-art LLM-based detection solutions are often plagued by high false-positive rates.
  In this paper, we push the boundaries of existing research in two key ways. First, our evaluation is based on Solidity v0.8, offering the most up-to-date insights compared to prior studies that focus on older versions (v0.4). Second, we leverage the latest five LLM models (across companies), ensuring comprehensive coverage across the most advanced capabilities in the field.
  We conducted a series of rigorous evaluations. Our experiments demonstrate that a well-designed prompt can reduce the false-positive rate by over 60%. Surprisingly, we also discovered that the recall rate for detecting some specific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to earlier versions (i.e., v0.4). Further analysis reveals the root cause of this decline: the reliance of LLMs on identifying changes in newly introduced libraries and frameworks during detection.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Authentication: Theory vs. Practice</title>
<link>https://arxiv.org/abs/2501.07209</link>
<guid>https://arxiv.org/abs/2501.07209</guid>
<content:encoded><![CDATA[
<div> 关键词：在线服务、隐私保护、身份管理、零知识证明、匿名凭证<br /><br />总结:
随着在线服务使用的增长，用户隐私保护变得越来越重要。当前互联网上的身份管理和认证主要依赖于集中式解决方案，但从隐私角度来看，这种方法较为侵入，并未实现数据最小化原则。幸运的是，密码学提供了如零知识证明和高级签名方案等激动人心的原语，可以实现多种形式的匿名凭证，从而实现具有内置高隐私保护级别的隐私保护认证（即隐私保护认证）。虽然这些原语已被研究了几十年并在学术界得到充分理解，但遗憾的是它们尚未得到广泛应用。本文探讨了相关问题、密码学所能做的事情、一些部署实例以及阻碍其广泛采用的壁垒，以欧盟数字身份钱包（EUDIW）及其近期围绕该话题的专家讨论和反馈为例进行了具体说明。此外，文中还简要提及了向后量子密码学过渡的问题。 <div>
arXiv:2501.07209v1 Announce Type: new 
Abstract: With the increasing use of online services, the protection of the privacy of users becomes more and more important. This is particularly critical as authentication and authorization as realized on the Internet nowadays, typically relies on centralized identity management solutions. Although those are very convenient from a user's perspective, they are quite intrusive from a privacy perspective and are currently far from implementing the concept of data minimization. Fortunately, cryptography offers exciting primitives such as zero-knowledge proofs and advanced signature schemes to realize various forms of so-called anonymous credentials. Such primitives allow to realize online authentication and authorization with a high level of built-in privacy protection (what we call privacy-preserving authentication). Though these primitives have already been researched for various decades and are well understood in the research community, unfortunately, they lack widespread adoption. In this paper, we look at the problems, what cryptography can do, some deployment examples, and barriers to widespread adoption. Latter using the example of the EU Digital Identity Wallet (EUDIW) and the recent discussion and feedback from cryptography experts around this topic. We also briefly comment on the transition to post-quantum cryptography.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Stability and Learning of Competitive Equilibrium in Generalized Fisher Market Models: A Variational Inequality Approach</title>
<link>https://arxiv.org/abs/2501.07265</link>
<guid>https://arxiv.org/abs/2501.07265</guid>
<content:encoded><![CDATA[
<div> 关键词：generalized Fisher market模型，社会影响，竞争均衡，变分不等式方法，学习算法

总结:<br />
本文研究了一种考虑社会影响力的广义Fisher市场模型，其中买家的效用不仅依赖于自身资源分配，还受到竞争对手的分配情况影响。为此，文章提出了一种新的基于变分不等式的竞争均衡表述法，该框架扩展了对具有非同质效用函数市场的理解。作者分析了提出的变分不等式问题的关键结构特性，包括单调性、稳定性和唯一性。此外，文章还提出了两种实现竞争均衡的分散式学习算法：一种是以两时间尺度随机近似为基础的tâtonnement方法，另一种是基于交易站机制的学习方法。最后，通过数值模拟验证了所提算法的有效性。 <div>
arXiv:2501.07265v1 Announce Type: new 
Abstract: In this work, we study a generalized Fisher market model that incorporates social influence. In this extended model, a buyer's utility depends not only on their own resource allocation but also on the allocations received by their competitors. We propose a novel competitive equilibrium formulation for this generalized Fisher market using a variational inequality approach. This framework effectively captures competitive equilibrium in markets that extend beyond the traditional assumption of homogeneous utility functions. We analyze key structural properties of the proposed variational inequality problem, including monotonicity, stability, and uniqueness. Additionally, we present two decentralized learning algorithms for buyers to achieve competitive equilibrium: a two-timescale stochastic approximation-based t{\^a}tonnement method and a trading-post mechanism-based learning method. Finally, we validate the proposed algorithms through numerical simulations.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks</title>
<link>https://arxiv.org/abs/2501.07288</link>
<guid>https://arxiv.org/abs/2501.07288</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 中心化, 民主化, 分布式专家知识, 区块链框架

<br /><br />总结:
该文指出了大型语言模型（LLMs）开发中心化的现状及其对AI发展形成的障碍，以及维护多领域专业知识更新的挑战。为解决这些问题，文章提出了一种名为 LLM-Net 的基于区块链的分布式框架。LLM-Net 旨在通过建立一个由专门领域的 LLM 提供者组成的去中心化网络，实现 LLMs 服务的民主化，利用集体计算资源和分布式领域专长，结合针对特定领域的微调专家模型来确保知识持续增长和服务质量。同时，LLM-Net 运用区块链技术进行透明交易和性能验证，建立起服务交付的不可变记录。通过在现有最先进的 LLMs 上的模拟实验，验证了声誉机制在选择高绩效提供者的有效性，展示了 LLM-Net 在整合分布式专家知识和基于区块链的责任追溯方面对于推动人工智能持续进步的潜力。 <div>
arXiv:2501.07288v1 Announce Type: new 
Abstract: The centralization of Large Language Models (LLMs) development has created significant barriers to AI advancement, limiting the democratization of these powerful technologies. This centralization, coupled with the scarcity of high-quality training data and mounting complexity of maintaining comprehensive expertise across rapidly expanding knowledge domains, poses critical challenges to the continued growth of LLMs. While solutions like Retrieval-Augmented Generation (RAG) offer potential remedies, maintaining up-to-date expert knowledge across diverse domains remains a significant challenge, particularly given the exponential growth of specialized information. This paper introduces LLMs Networks (LLM-Net), a blockchain-based framework that democratizes LLMs-as-a-Service through a decentralized network of specialized LLM providers. By leveraging collective computational resources and distributed domain expertise, LLM-Net incorporates fine-tuned expert models for various specific domains, ensuring sustained knowledge growth while maintaining service quality through collaborative prompting mechanisms. The framework's robust design includes blockchain technology for transparent transaction and performance validation, establishing an immutable record of service delivery. Our simulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet, Llama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the reputation-based mechanism in maintaining service quality by selecting high-performing respondents (LLM providers). Thereby it demonstrates the potential of LLM-Net to sustain AI advancement through the integration of decentralized expertise and blockchain-based accountability.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Union: A Trust-minimized Bridge for Bitcoin</title>
<link>https://arxiv.org/abs/2501.07435</link>
<guid>https://arxiv.org/abs/2501.07435</guid>
<content:encoded><![CDATA[
<div> 关键词: Union、信任最小化、比特币、桥接协议、BitVMX

总结:
<br />
本文介绍了名为"Union"的一种新型信任最小化的比特币桥接协议，旨在安全地实现在比特币和次要区块链之间转移BTC的同时，保持比特币的安全保障。针对围绕比特币构建的不断发展的生态系统中对于安全、高效桥梁的需求，Union采用了一个基于Bitcoin的多党派BitVMX乐观证明系统，该系统在至少一个参与者诚实的前提下保证安全运行，打破了传统的多数诚实假设。此外，协议还引入了多个创新点：基于数据包的架构可使安全性保证金用于多次桥接操作，从而提高资本效率；启用了一套管理功能实体参与并执行惩罚的机制；设计了一个灵活的轻客户端框架以适应各种区块链架构；并实现了一个优化时间锁管理的高效停止手表机制。Union是一种实用且可扩展的解决方案，它为比特币互操作性提供了强大的安全保障，并最大限度地减少了信任假设。 <div>
arXiv:2501.07435v1 Announce Type: new 
Abstract: We present Union, a trust-minimized bridge protocol that enables secure transfer of BTC between Bitcoin and a secondary blockchain. The growing ecosystem of blockchain systems built around Bitcoin has created a pressing need for secure and efficient bridges to transfer BTC between networks while preserving Bitcoin's security guarantees. Union employs a multi-party variant of BitVMX, an optimistic proving system on Bitcoin, to create a bridge that operates securely under the assumption that at least one participant remains honest. This 1-of-n honest approach is strikingly different from the conventional honest-majority assumption adopted by practically all federated systems. The protocol introduces several innovations: a packet-based architecture that allows security bonds to be reused for multiple bridge operations, improving capital efficiency; a system of enablers to manage functionaries participation and to enforce penalties; a flexible light client framework adaptable to various blockchain architectures; and an efficient stop watch mechanism to optimize time-lock management. Union is a practical and scalable solution for Bitcoin interoperability that maintains strong security guarantees and minimizes trust assumptions.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ML Mule: Mobile-Driven Context-Aware Collaborative Learning</title>
<link>https://arxiv.org/abs/2501.07536</link>
<guid>https://arxiv.org/abs/2501.07536</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能, 中心化学习, 分布式学习, 联邦学习, 隐私保护

<br />
总结:
本文提出了一种名为ML Mule的新方法，用于解决人工智能模型训练和应用中的隐私、基础设施成本以及个性化问题。ML Mule利用移动设备作为“骡子”，在物理空间中传输并共享模型快照，通过这种方式，当用户在特定空间中共享设备时，形成了隐性的协作模型进化群体，同时保护了用户的隐私。该方法克服了传统中心化、联邦学习及完全分布式学习系统的局限性，实现了更快的收敛速度和更高的模型准确性，并且更加健壮、分布广泛和个性化，使机器学习更接近于创建真正智能、自适应和情境感知环境的愿景。 <div>
arXiv:2501.07536v1 Announce Type: new 
Abstract: Artificial intelligence has been integrated into nearly every aspect of daily life, powering applications from object detection with computer vision to large language models for writing emails and compact models in smart homes. These machine learning models cater to individual users but are often detached from them, as they are typically stored and processed in centralized data centers. This centralized approach raises privacy concerns, incurs high infrastructure costs, and struggles with personalization. Federated and fully decentralized learning methods have been proposed to address these issues, but they still depend on centralized servers or face slow convergence due to communication constraints. To overcome these challenges, we propose ML Mule, a approach that utilizes individual mobile devices as 'Mules' to train and transport model snapshots as they move through physical spaces, sharing these models with the physical 'Spaces' they inhabit. This method implicitly forms affinity groups among devices associated with users who share particular spaces, enabling collaborative model evolution, and protecting users' privacy. Our approach addresses several major shortcomings of traditional, federated, and fully decentralized learning systems. The proposed framework represents a new class of machine learning methods that are more robust, distributed, and personalized, bringing the field closer to realizing the original vision of intelligent, adaptive, and genuinely context-aware smart environments. The results show that ML Mule converges faster and achieves higher model accuracy compared to other existing methods.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning for Enhancing Sensing Estimation in Bistatic ISAC Systems with UAV Swarms</title>
<link>https://arxiv.org/abs/2501.06454</link>
<guid>https://arxiv.org/abs/2501.06454</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、集成感知与通信（ISAC）、无人机（UAV）群、定位与轨迹优化、传输功率适应

总结:<br />
本文提出了一种利用多智能体强化学习（MARL）框架增强集成感知与通信（ISAC）网络的新方法，该网络使用无人机（UAV）群作为传感雷达。通过将UAV的定位和轨迹优化问题建模为部分可观测马尔可夫决策过程，研究者开发了一种采用集中式训练与分布式执行相结合的MARL策略，以最大化整体感知性能。具体来说，他们实施了一种分散合作的MARL策略，使UAV能够发展有效的通信协议，从而提高其环境意识和操作效率。此外，文中还结合了传输功率适应技术来减轻无人机间通信干扰并优化通信协议效率，进一步提升了所学通信协议的效率。尽管方案复杂度增加，但其在各种场景下展现出稳健的性能和适应性，为未来ISAC网络提供了具有可扩展性和成本效益的增强方案。 <div>
arXiv:2501.06454v1 Announce Type: cross 
Abstract: This paper introduces a novel Multi-Agent Reinforcement Learning (MARL) framework to enhance integrated sensing and communication (ISAC) networks using unmanned aerial vehicle (UAV) swarms as sensing radars. By framing the positioning and trajectory optimization of UAVs as a Partially Observable Markov Decision Process, we develop a MARL approach that leverages centralized training with decentralized execution to maximize the overall sensing performance. Specifically, we implement a decentralized cooperative MARL strategy to enable UAVs to develop effective communication protocols, therefore enhancing their environmental awareness and operational efficiency. Additionally, we augment the MARL solution with a transmission power adaptation technique to mitigate interference between the communicating drones and optimize the communication protocol efficiency. Moreover, a transmission power adaptation technique is incorporated to mitigate interference and optimize the learned communication protocol efficiency. Despite the increased complexity, our solution demonstrates robust performance and adaptability across various scenarios, providing a scalable and cost-effective enhancement for future ISAC networks.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Improving DeFi Accessibility through Efficient Liquidity Provisioning with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.07508</link>
<guid>https://arxiv.org/abs/2501.07508</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习(DRL), Uniswap v3, 自动做市商(AMM), 马尔科夫决策过程(MDP), Proximal Policy Optimization (PPO)

<br /><br />总结:
本文将深度强化学习（DRL）应用于Uniswap v3的流动性提供优化问题上，该协议是一个实现集中式流动性的去中心化金融（DeFi）协议。研究中，将流动性提供任务建模为马尔科夫决策过程（MDP），并利用Proximal Policy Optimization（PPO）算法训练一个主动型流动性提供者（LP）智能代理。该代理根据价格动态信息动态调整流动性位置，以平衡手续费最大化与临时损失最小化之间的关系。采用滚动窗口方法进行训练和测试，以反映真实的市场条件和市场周期变化。文章通过数据驱动的方法对比了基于DRL策略与小型零售LP通常采用的不系统修改其流动性位置的常见启发式策略的性能。该研究旨在通过推动更有效的流动性管理，使DeFi市场对更广泛的参与者更加可访问和包容，并促进DeFi市场的持续发展和用户友好性提升。 <div>
arXiv:2501.07508v1 Announce Type: cross 
Abstract: This paper applies deep reinforcement learning (DRL) to optimize liquidity provisioning in Uniswap v3, a decentralized finance (DeFi) protocol implementing an automated market maker (AMM) model with concentrated liquidity. We model the liquidity provision task as a Markov Decision Process (MDP) and train an active liquidity provider (LP) agent using the Proximal Policy Optimization (PPO) algorithm. The agent dynamically adjusts liquidity positions by using information about price dynamics to balance fee maximization and impermanent loss mitigation. We use a rolling window approach for training and testing, reflecting realistic market conditions and regime shifts. This study compares the data-driven performance of the DRL-based strategy against common heuristics adopted by small retail LP actors that do not systematically modify their liquidity positions. By promoting more efficient liquidity management, this work aims to make DeFi markets more accessible and inclusive for a broader range of participants. Through a data-driven approach to liquidity management, this work seeks to contribute to the ongoing development of more efficient and user-friendly DeFi markets.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semitopology: a topological approach to decentralised collaborative action</title>
<link>https://arxiv.org/abs/2303.09287</link>
<guid>https://arxiv.org/abs/2303.09287</guid>
<content:encoded><![CDATA[
<div> 关键词：semitopology、点集拓扑、分布式系统、可操作联盟、局部更新

<br /><br />总结:
本文介绍了semitopology，这是一种对点集拓扑学的扩展，放宽了开放集合交集必须为开放集合的限制。semitopology的核心思想是将点视为去中心化系统中的参与者，而开放集合代表那些拥有共同权限协作更新本地状态的参与者的集合，即可操作联盟。文中给出了如权益证明区块链中的多数股权、点对点网络中的通信节点以及街头行人避免碰撞等可操作联盟的例子。这些系统的共性包括：协作具有局部性（仅更新联盟内参与者的状态）；协作自愿（直至规则被打破）；参与者异构（计算能力或目标不同）；可以选择合作对象；并且不依赖于中央权威的许可或同步。文章通过一种带有拓扑学色彩的数学方法，探讨了这类复杂去中心化系统如何展现出秩序，并为我们理解现有实际实现提供了新的视角。 <div>
arXiv:2303.09287v5 Announce Type: replace 
Abstract: We introduce semitopology, a generalisation of point-set topology that removes the restriction that intersections of open sets need necessarily be open. The intuition is that points represent participants in a decentralised system, and open sets represent collections of participants that collectively have the authority to collaborate to update their local state; we call this an actionable coalition.
  Examples of actionable coalition include: majority stakes in proof-of-stake blockchains; communicating peers in peer-to-peer networks; and even pedestrians working together to not bump into one another in the street. Where actionable coalitions exist, they have in common that: collaborations are local (updating the states of the participants in the coalition, but not immediately those of the whole system); collaborations are voluntary (up to and including breaking rules); participants may be heterogeneous in their computing power or in their goals (not all pedestrians want to go to the same place); participants can choose with whom to collaborate; and they are not assumed subject to permission or synchronisation by a central authority.
  We develop a topology-flavoured mathematics that goes some way to explaining how and why these complex decentralised systems can exhibit order, and gives us new ways to understand existing practical implementations.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Proposal for a Lean and Functional Delivery versus Payment across two Blockchains</title>
<link>https://arxiv.org/abs/2311.05966</link>
<guid>https://arxiv.org/abs/2311.05966</guid>
<content:encoded><![CDATA[
<div> 关键词: 交易方案、区块链、去中介化、低开销、安全交付与支付

总结:
我们提出了一种精简且实用的跨两个区块链的安全交付对支付交易方案。该方案无需中介，且支付链操作员只需承担较小的开销，无须存储状态。实现这一目标主要依赖两点：首先，支付链运营商提供一个无状态解密服务，允许使用其私钥解密消息；其次，在支付链上部署了一个“支付合约”，实现了transferAndDecrypt函数，该函数处理基于触发的支付并根据交易的成功或失败发出解密后的密钥。相应的密钥可以触发关联交易，例如买家领取交付物或者卖家在交易失败时重新找回被锁定的资产。 <div>
arXiv:2311.05966v3 Announce Type: replace 
Abstract: We propose a lean and functional transaction scheme to establish a secure delivery-versus-payment across two blockchains, where a) no intermediary is required and b) the operator of the payment chain/payment system has a small overhead and does not need to store state. The main idea comes with two requirements: First, the payment chain operator hosts a stateless decryption service that allows decrypting messages with his secret key. Second, a "Payment Contract" is deployed on the payment chain that implements a function transferAndDecrypt(uint id, address from, address to, string keyEncryptedSuccess, string keyEncryptedFail) that processes the (trigger-based) payment and emits the decrypted key depending on the success or failure of the transaction. The respective key can then trigger an associated transaction, e.g. claiming delivery by the buyer or re-claiming the locked asset by the seller.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Complexity of Decentralized Smooth Nonconvex Finite-Sum Optimization</title>
<link>https://arxiv.org/abs/2210.13931</link>
<guid>https://arxiv.org/abs/2210.13931</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、非凸函数、DEAREST算法、通信复杂性、计算复杂性

总结:
该文研究了分布式优化问题，其中目标函数为多个局部光滑但可能非凸函数的平均。文章提出了一种名为DEcentralized probAbilistic Recursive gradiEnt deScenT (DEAREST)的新算法，该算法能够在每个代理节点达到$\epsilon$-临界点，所需的通信轮数为$\tilde{\mathcal O}(L\epsilon^{-2}/\sqrt{\gamma}\,)$，计算轮数为$\tilde{\mathcal O}(n+(L+\min\{nL, \sqrt{n/m}\bar L\})\epsilon^{-2})$，以及本地增量第一阶 oracle 调用次数为${\mathcal O}(mn + {\min\{mnL, \sqrt{mn}\bar L\}}{\epsilon^{-2}})$。文中还建立了下界，证明了所提方法的近似最优性。值得注意的是，DEAREST算法的设计和分析中使用的光滑度参数$L$和$\bar L$是全局性的，从而导致比依赖于局部光滑度的现有结果更尖锐的复杂性界限。此外，DEAREST算法还被扩展到解决满足Polyak-{\L}ojasiewicz条件的分布式有限和优化问题，并同样实现了近似最优的复杂性界限。<br /><br /> <div>
arXiv:2210.13931v4 Announce Type: replace-cross 
Abstract: We study the decentralized optimization problem $\min_{{\bf x}\in{\mathbb R}^d} f({\bf x})\triangleq \frac{1}{m}\sum_{i=1}^m f_i({\bf x})$, where the local function on the $i$-th agent has the form of $f_i({\bf x})\triangleq \frac{1}{n}\sum_{j=1}^n f_{i,j}({\bf x})$ and every individual $f_{i,j}$ is smooth but possibly nonconvex. We propose a stochastic algorithm called DEcentralized probAbilistic Recursive gradiEnt deScenT (DEAREST) method, which achieves an $\epsilon$-stationary point at each agent with the communication rounds of $\tilde{\mathcal O}(L\epsilon^{-2}/\sqrt{\gamma}\,)$, the computation rounds of $\tilde{\mathcal O}(n+(L+\min\{nL, \sqrt{n/m}\bar L\})\epsilon^{-2})$, and the local incremental first-oracle calls of ${\mathcal O}(mn + {\min\{mnL, \sqrt{mn}\bar L\}}{\epsilon^{-2}})$, where $L$ is the smoothness parameter of the objective function, $\bar L$ is the mean-squared smoothness parameter of all individual functions, and $\gamma$ is the spectral gap of the mixing matrix associated with the network. We then establish the lower bounds to show that the proposed method is near-optimal. Notice that the smoothness parameters $L$ and $\bar L$ used in our algorithm design and analysis are global, leading to sharper complexity bounds than existing results that depend on the local smoothness. We further extend DEAREST to solve the decentralized finite-sum optimization problem under the Polyak-{\L}ojasiewicz condition, also achieving the near-optimal complexity bounds.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Fair Ordering and Differential Privacy</title>
<link>https://arxiv.org/abs/2501.05535</link>
<guid>https://arxiv.org/abs/2501.05535</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、公平交易排序、算法偏见、等机会原则、差分隐私

总结:
本文探讨了区块链系统中公平交易排序的重要性以及与传统状态机复制(SMR)系统的差异。文章提出了基于相关和无关特征来定义交易，确保交易排序仅由相关特征决定，相同相关特征的交易有相等的排序机会。进一步地，文章将这一公平性框架扩展为一种概率性原则：相关特征差异越大的交易，被优先排序的概率越高。文章揭示了一个令人惊讶的联系，即SMR中的等机会原则与差分隐私(DP)之间存在关联，证明任何DP机制都可以用于确保SMR中的公平性。这一发现深化了我们对分布式计算中隐私与公平性相互关系的理解，并为设计利用成熟DP技术实现公平分布式协议开辟了新途径。 <div>
arXiv:2501.05535v1 Announce Type: new 
Abstract: In blockchain systems, fair transaction ordering is crucial for a trusted and regulation-compliant economic ecosystem. Unlike traditional State Machine Replication (SMR) systems, which focus solely on liveness and safety, blockchain systems also require a fairness property. This paper examines these properties and aims to eliminate algorithmic bias in transaction ordering services.
  We build on the notion of equal opportunity. We characterize transactions in terms of relevant and irrelevant features, requiring that the order be determined solely by the relevant ones. Specifically, transactions with identical relevant features should have an equal chance of being ordered before one another. We extend this framework to define a property where the greater the distance in relevant features between transactions, the higher the probability of prioritizing one over the other.
  We reveal a surprising link between equal opportunity in SMR and Differential Privacy (DP), showing that any DP mechanism can be used to ensure fairness in SMR. This connection not only enhances our understanding of the interplay between privacy and fairness in distributed computing but also opens up new opportunities for designing fair distributed protocols using well-established DP techniques.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Kite: How to Delegate Voting Power Privately</title>
<link>https://arxiv.org/abs/2501.05626</link>
<guid>https://arxiv.org/abs/2501.05626</guid>
<content:encoded><![CDATA[
<div> 关键词：Kite、私人委托投票、Decentralized Autonomous Organizations (DAO)、隐私保护、Universal Composability (UC)框架

<br /><br />总结:
本文介绍了Kite协议，这是一种新的用于Decentralized Autonomous Organizations (DAO)的协议，旨在实现投票权的私人委托。与现有仅支持公开委托的DAO投票系统不同，Kite允许成员在不泄露其委托对象信息的情况下自由地进行委托、撤销和重新委托投票权。即使被委托者也不知道谁委托给了他们，公共记录中仅显示投票者将权力委托给了某人。Kite同时支持公开和私密的代表投票。该协议的安全性在Universal Composability (UC)框架下进行了分析，并已在以太坊区块链上的广泛应用Governor Bravo智能合约上实现了Kite的扩展。实施评估表明，尽管零知识证明导致了委托操作的成本较高（在消费级笔记本电脑上，委托耗时在7到167秒之间，具体取决于所需的隐私级别），但该协议仍具有实际可行性。 <div>
arXiv:2501.05626v1 Announce Type: new 
Abstract: Ensuring the privacy of votes in an election is crucial for the integrity of a democratic process. Often, voting power is delegated to representatives (e.g., in congress) who subsequently vote on behalf of voters on specific issues. This delegation model is also widely used in Decentralized Autonomous Organizations (DAOs). Although several existing voting systems used in DAOs support private voting, they only offer public delegation. In this paper, we introduce Kite, a new protocol that enables $\textit{private}$ delegation of voting power for DAO members. Voters can freely delegate, revoke, and re-delegate their power without revealing any information about who they delegated to. Even the delegate does not learn who delegated to them. The only information that is recorded publicly is that the voter delegated or re-delegated their vote to someone. Kite accommodates both public and private voting for the delegates themselves. We analyze the security of our protocol within the Universal Composability (UC) framework. We implement Kite as an extension to the existing Governor Bravo smart contract on the Ethereum blockchain, that is widely used for DAO governance. Furthermore, we provide an evaluation of our implementation that demonstrates the practicality of the protocol. The most expensive operation is delegation due to the required zero-knowledge proofs. On a consumer-grade laptop, delegation takes between 7 and 167 seconds depending on the requested level of privacy.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scaling Safe Multi-Agent Control for Signal Temporal Logic Specifications</title>
<link>https://arxiv.org/abs/2501.05639</link>
<guid>https://arxiv.org/abs/2501.05639</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体控制、逻辑规范、信号temporal逻辑(STL)、图神经网络(GNN)、混合整数线性规划(MILP)

总结:
本文提出了一个新的适用于多智能体控制的方法，旨在解决使用如STL等逻辑规范进行安全控制时所面临的可扩展性问题。现有的方法依赖于单智能体视角或复杂的MILP规划器，导致处理大量智能体时计算成本高昂和效率低下。与现有方法不同，该新方法利用图结构描述智能体之间的关系，并结合一种多智能体碰撞避免控制器以及基于GNN的规划器，以分布式方式建模系统并针对STL目标进行训练，生成多智能体的安全高效计划，同时优化满足复杂时间规范并实现多智能体碰撞避让。实验表明，相较于采用先进的MILP规划器的现有方法，该方法在可扩展性和性能方面具有显著优势。项目网站为https://jeappen.com/mastl-gcbf-website/，代码可在https://github.com/jeappen/mastl-gbf 获取。<br /><br /> <div>
arXiv:2501.05639v1 Announce Type: new 
Abstract: Existing methods for safe multi-agent control using logic specifications like Signal Temporal Logic (STL) often face scalability issues. This is because they rely either on single-agent perspectives or on Mixed Integer Linear Programming (MILP)-based planners, which are complex to optimize. These methods have proven to be computationally expensive and inefficient when dealing with a large number of agents. To address these limitations, we present a new scalable approach to multi-agent control in this setting. Our method treats the relationships between agents using a graph structure rather than in terms of a single-agent perspective. Moreover, it combines a multi-agent collision avoidance controller with a Graph Neural Network (GNN) based planner, models the system in a decentralized fashion, and trains on STL-based objectives to generate safe and efficient plans for multiple agents, thereby optimizing the satisfaction of complex temporal specifications while also facilitating multi-agent collision avoidance. Our experiments show that our approach significantly outperforms existing methods that use a state-of-the-art MILP-based planner in terms of scalability and performance. The project website is https://jeappen.com/mastl-gcbf-website/ and the code is at https://github.com/jeappen/mastl-gcbf .
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fully Decentralized Computation Offloading in Priority-Driven Edge Computing Systems</title>
<link>https://arxiv.org/abs/2501.05660</link>
<guid>https://arxiv.org/abs/2501.05660</guid>
<content:encoded><![CDATA[
<div> 关键词：多接入边缘计算(MEC)，非合作游戏框架，年龄信息(AoI)，平均场游戏(MFG)，梯度下降算法

总结:<br />
本文提出了一种新颖的完全去中心化的多接入边缘计算（MEC）系统中任务卸载策略设计框架。该系统由N个具有功率限制的用户设备(UEs)和一个边缘服务器(ES)组成，用于处理带有紧急标志的入站任务，这些任务被分为高、中、低三种紧急等级。文章将UE的任务执行决策问题在一个大型群体非合作游戏框架中进行建模，其中每个UE自私地决定如何将其任务执行分割给本地车载处理器和ES。通过采用加权平均信息新鲜度（AoI）指标来量化UE的信息新鲜度。增加本地处理会消耗更多功率，而增加卸载可能会由于其他UE的包被卸载到同一个ES而导致平均AoI潜在增加。因此，文章利用平均场游戏(MFG)理论来计算UE的近似分散纳什均衡卸载和本地计算策略，以平衡信息新鲜度与本地功耗。最后，文章提供了一个基于投影梯度下降法的数值算法，用于评估所提方法的优点。 <div>
arXiv:2501.05660v1 Announce Type: new 
Abstract: We develop a novel framework for fully decentralized offloading policy design in multi-access edge computing (MEC) systems. The system comprises $N$ power-constrained user equipments (UEs) assisted by an edge server (ES) to process incoming tasks. Tasks are labeled with urgency flags, and in this paper, we classify them under three urgency levels, namely, high, moderate, and low urgency. We formulate the problem of designing computation decisions for the UEs within a large population noncooperative game framework, where each UE selfishly decides on how to split task execution between its local onboard processor and the ES. We employ the weighted average age of information (AoI) metric to quantify information freshness at the UEs. Increased onboard processing consumes more local power, while increased offloading may potentially incur a higher average AoI due to other UEs' packets being offloaded to the same ES. Thus, we use the mean-field game (MFG) formulation to compute approximate decentralized Nash equilibrium offloading and local computation policies for the UEs to balance between the information freshness and local power consumption. Finally, we provide a projected gradient descent-based algorithm to numerically assess the merits of our approach.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Content Moderation in the Fediverse</title>
<link>https://arxiv.org/abs/2501.05871</link>
<guid>https://arxiv.org/abs/2501.05871</guid>
<content:encoded><![CDATA[
<div> 关键词：Fediverse、内容审核、联邦学习、FedMod、性能评估

总结:
这篇论文关注的是随着Elon Musk收购Twitter后迅速壮大的去中心化社交网络平台——Fediverse所面临的内容审核挑战。由于Fediverse中的服务器资源有限，无法像Facebook和Twitter那样依赖大规模标注数据和专业化基础设施进行自动化审核，因此文章提出了一种基于联邦学习的协同内容审核系统FedMod。FedMod允许相似的服务器之间交换部分训练完成的本地内容审核模型参数，从而构建一个在协作服务器间共享的联邦模型。实验结果显示，FedMod在有害内容检测、机器人内容检测和内容警告分配三个不同的内容审核任务上表现出稳健的性能，分别达到了平均每个服务器的宏F1分数为0.71、0.73和0.58。 <div>
arXiv:2501.05871v1 Announce Type: new 
Abstract: The Fediverse, a group of interconnected servers providing a variety of interoperable services (e.g. micro-blogging in Mastodon) has gained rapid popularity. This sudden growth, partly driven by Elon Musk's acquisition of Twitter, has created challenges for administrators though. This paper focuses on one particular challenge: content moderation, e.g. the need to remove spam or hate speech. While centralized platforms like Facebook and Twitter rely on automated tools for moderation, their dependence on massive labeled datasets and specialized infrastructure renders them impractical for decentralized, low-resource settings like the Fediverse. In this work, we design and evaluate FedMod, a collaborative content moderation system based on federated learning. Our system enables servers to exchange parameters of partially trained local content moderation models with similar servers, creating a federated model shared among collaborating servers. FedMod demonstrates robust performance on three different content moderation tasks: harmful content detection, bot content detection, and content warning assignment, achieving average per-server macro-F1 scores of 0.71, 0.73, and 0.58, respectively.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoDriveVLM: VLM-Enhanced Urban Cooperative Dispatching and Motion Planning for Future Autonomous Mobility on Demand Systems</title>
<link>https://arxiv.org/abs/2501.06132</link>
<guid>https://arxiv.org/abs/2501.06132</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Mobility-on-Demand (AMoD)，Demand Responsive Transport (DRT)，Connected and Autonomous Vehicles (CAVs)，Vision-Language Models (VLMs)，Consensus Alternating Direction Method of Multipliers (ADMM)

总结:<br />
本文提出了一种名为CoDriveVLM的新颖框架，旨在解决传统需求响应式运输系统(DRT)在灵活和高效城市交通解决方案方面的局限性，特别是针对多元化乘客需求和动态城市环境。CoDriveVLM着重于未来AMoD系统的高保真同步调度与合作运动规划的集成，利用Vision-Language Models (VLMs)增强多模态信息处理能力，从而实现全面的调度和碰撞风险评估。文章中还引入了基于VLM的CAV调度协调器来有效管理复杂和意外的AMoD情况，支持高效的调度决策。此外，通过一致性交替方向乘子法(ADMM)提出了一种可扩展的分布式合作运动规划方法，重点关注碰撞风险评估和分散化的轨迹优化。模拟结果显示，CoDriveVLM在各种交通条件下的可行性和鲁棒性，显示出其在未来城市交通网络中显著提升AMoD系统的真实性和效率的潜力。相关代码可在https://github.com/henryhcliu/CoDriveVLM.git获取。 <div>
arXiv:2501.06132v1 Announce Type: new 
Abstract: The increasing demand for flexible and efficient urban transportation solutions has spotlighted the limitations of traditional Demand Responsive Transport (DRT) systems, particularly in accommodating diverse passenger needs and dynamic urban environments. Autonomous Mobility-on-Demand (AMoD) systems have emerged as a promising alternative, leveraging connected and autonomous vehicles (CAVs) to provide responsive and adaptable services. However, existing methods primarily focus on either vehicle scheduling or path planning, which often simplify complex urban layouts and neglect the necessity for simultaneous coordination and mutual avoidance among CAVs. This oversimplification poses significant challenges to the deployment of AMoD systems in real-world scenarios. To address these gaps, we propose CoDriveVLM, a novel framework that integrates high-fidelity simultaneous dispatching and cooperative motion planning for future AMoD systems. Our method harnesses Vision-Language Models (VLMs) to enhance multi-modality information processing, and this enables comprehensive dispatching and collision risk evaluation. The VLM-enhanced CAV dispatching coordinator is introduced to effectively manage complex and unforeseen AMoD conditions, thus supporting efficient scheduling decision-making. Furthermore, we propose a scalable decentralized cooperative motion planning method via consensus alternating direction method of multipliers (ADMM) focusing on collision risk evaluation and decentralized trajectory optimization. Simulation results demonstrate the feasibility and robustness of CoDriveVLM in various traffic conditions, showcasing its potential to significantly improve the fidelity and effectiveness of AMoD systems in future urban transportation networks. The code is available at https://github.com/henryhcliu/CoDriveVLM.git.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Multi-Antenna Architectures with Unitary Constraints</title>
<link>https://arxiv.org/abs/2501.06067</link>
<guid>https://arxiv.org/abs/2501.06067</guid>
<content:encoded><![CDATA[
<div> 关键词：base station, decentralized approach, WAX框架, unitary restriction, interconnection bandwidth

总结:<br />
随着基站（BS）天线数量的增加，对有效处理传统集中式方法中增多的数据连接带宽和处理复杂性的需求日益增长。因此，分布式方法逐渐受到关注，因为它们可以通过预先处理接收到的信号来显著减少数据/处理量，然后再将其转发至中央节点。本文研究了WAX框架的一个改编版，该框架考虑了在分布式处理具有单位制限制的情况下，如何实现通过可重构阻抗网络实现能效较高的实施方案，但代价是性能有所损失。此外，文章提出了一种有效缩小与集中式处理性能差距的方法。这种方法为进一步研究具有单位制约束条件的分布式架构中，互联带宽与处理复杂性之间无信息损失的权衡关系提供了初步探索。 <div>
arXiv:2501.06067v1 Announce Type: cross 
Abstract: The increase in the number of base station (BS) antennas calls for efficient solutions to deal with the increased interconnection bandwidth and processing complexity of traditional centralized approaches. Decentralized approaches are thus gaining momentum, since they achieve important reductions in data/processing volume by preprocessing the received signals before forwarding them to a central node. The WAX framework offers a general description of decentralized architectures with arbitrary interplay between interconnection bandwidth and decentralized processing complexity, but the applicability of this framework has only been studied assuming unrestricted baseband processing. We consider an adaptation of the WAX framework where the decentralized processing has unitary restriction, which allows for energy-efficient implementations based on reconfigurable impedance networks at the cost of some performance loss. Moreover, we propose an effective method to minimize the performance gap with respect to centralized processing. The previous method gives a first step towards characterizing the information-lossless trade-off between interconnection bandwidth and processing complexity in decentralized architectures with unitary constraints.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Nearly Linear-Time Distributed Algorithm for Maximum Cardinality Matching</title>
<link>https://arxiv.org/abs/2311.04140</link>
<guid>https://arxiv.org/abs/2311.04140</guid>
<content:encoded><![CDATA[
<div> 关键词: 随机化算法、最大匹配问题、CONGEST模型、增广路径、交替基树

总结:
<br />
本文提出了一种随机化的$\tilde{O}(\mu(G))$轮算法，用于解决CONGEST模型中的最大-cardinality匹配问题，其中$\mu(G)$表示输入图$G$的最大匹配大小。该算法显著改进了当前最坏情况下的运行时间。核心技术创新在于设计了一个新的随机算法，能够在$\tilde{O}(\ell)$轮内高概率找到长度为$\ell$的增广路径，从而正面解决了Ahmadi和Kuhn在先前工作中的开放问题。该增广路径算法基于Kitamura和Izumi的一项最新成果，即高效识别包含增广路径的输入图稀疏子结构，利用了“交替基树”这一新概念。然而，原方法部分依赖于将子结构的所有信息集中到单个顶点的中心化方法来构造长增广路径。本文的技术亮点则是提供了这种中心化方法的全分布式对应方案。为了开发此算法，我们证明了交替基树的几个新的结构性质，这些性质本身也具有独立的研究价值。 <div>
arXiv:2311.04140v3 Announce Type: replace 
Abstract: In this paper, we propose a randomized $\tilde{O}(\mu(G))$-round algorithm for the maximum cardinality matching problem in the CONGEST model, where $\mu(G)$ means the maximum size of a matching of the input graph $G$. The proposed algorithm substantially improves the current best worst-case running time. The key technical ingredient is a new randomized algorithm of finding an augmenting path of length $\ell$ with high probability within $\tilde{O}(\ell)$ rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC'20].
  The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi [IEICE Trans.'22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept called \emph{alternating base trees}. Their algorithm, however, resorts in part to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing a long augmenting path. The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method. To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest.
]]></content:encoded>
<pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Based Secure Vehicle Auction System with Smart Contracts</title>
<link>https://arxiv.org/abs/2501.04841</link>
<guid>https://arxiv.org/abs/2501.04841</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、中心化系统、单点故障、智能合约、车辆信息交易

总结:
区块链技术通过去中心化解决了中心化系统中的单点故障和数据篡改问题，其安全特性得到分析和认可。文章提出了一种基于以太坊区块链和智能合约技术的新系统，用于存储和交易车辆信息。该系统使得用户可以上传车辆信息并进行车辆拍卖，实现所有权转移。通过使用智能合约，系统在为买家和车主提供便利的同时，增强了交易的安全性和隐私保护。 <div>
arXiv:2501.04841v1 Announce Type: new 
Abstract: The problem of a single point of failure in centralized systems poses a great challenge to the stability of such systems. Meanwhile, the tamperability of data within centralized systems makes users reluctant to trust and use centralized applications in many scenarios, including the financial and business sectors.
  Blockchain, as a new decentralized technology, addresses these issues effectively. As a typical decentralized system, blockchain can be utilized to build a data-sharing model. Users in a blockchain do not need to trust other users; instead, they trust that the majority of miner nodes are honest. Smart contracts enable developers to write distributed programs based on blockchain systems, ensuring that all code is immutable and secure.
  In this paper, we analyze the security of blockchain technology to illustrate its advantages and justify its use. Furthermore, we design a new system for storing and trading vehicle information based on the Ethereum blockchain and smart contract technology. Specifically, our system allows users to upload vehicle information and auction vehicles to transfer ownership. Our application provides great convenience to buyers and owners, while the use of smart contracts enhances the security and privacy of the system.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning</title>
<link>https://arxiv.org/abs/2501.05053</link>
<guid>https://arxiv.org/abs/2501.05053</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、隐私保护、安全聚合、阈值功能性加密、TAPFed

总结:
本文提出了一个新的隐私保护方案TAPFed，用于解决多中心化环境下存在恶意行为者的联邦学习中的隐私泄露问题。传统的联邦学习平台由于梯度交换导致隐私泄露，而现有的安全聚合机制对于近期出现的离散攻击等推理攻击仍显得脆弱。TAPFed引入了一种新的阈值功能性加密方案，能在容忍一定数量恶意聚合器的同时，保证安全性和隐私性。文章对TAPFed进行了形式化的安全性与隐私性分析，并通过实验对比了其与其他基线方法的性能。结果表明，TAPFed在模型质量上与最先进的方法相当，同时在不同模型训练场景下能降低29%-45%的传输开销，并且能够有效防御由好奇聚合器引发的最近展示的推理攻击，这是大多数现有方法所不能做到的。<br /><br /> <div>
arXiv:2501.05053v1 Announce Type: new 
Abstract: Federated learning is a computing paradigm that enhances privacy by enabling multiple parties to collaboratively train a machine learning model without revealing personal data. However, current research indicates that traditional federated learning platforms are unable to ensure privacy due to privacy leaks caused by the interchange of gradients. To achieve privacy-preserving federated learning, integrating secure aggregation mechanisms is essential. Unfortunately, existing solutions are vulnerable to recently demonstrated inference attacks such as the disaggregation attack. This paper proposes TAPFed, an approach for achieving privacy-preserving federated learning in the context of multiple decentralized aggregators with malicious actors. TAPFed uses a proposed threshold functional encryption scheme and allows for a certain number of malicious aggregators while maintaining security and privacy. We provide formal security and privacy analyses of TAPFed and compare it to various baselines through experimental evaluation. Our results show that TAPFed offers equivalent performance in terms of model quality compared to state-of-the-art approaches while reducing transmission overhead by 29%-45% across different model training scenarios. Most importantly, TAPFed can defend against recently demonstrated inference attacks caused by curious aggregators, which the majority of existing approaches are susceptible to.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>QMDB: Quick Merkle Database</title>
<link>https://arxiv.org/abs/2501.05262</link>
<guid>https://arxiv.org/abs/2501.05262</guid>
<content:encoded><![CDATA[
<div> 关键词: QMDB、区块链、SSD优化、授权数据结构、性能提升

总结:
本文介绍了Quick Merkle Database (QMDB)，一个针对SSD优化的授权数据结构，它为现有数据库提供了超集功能。QMDB采用只追加设计，实现了每次状态访问仅需1次SSD读取、更新操作的$O(1)$ I/O以及在一个适合消费者级PC的小型DRAM空间内的内存Merkle化。研究显示，QMDB相比RocksDB提升了6倍，比最先进的可验证数据库提升了8倍的吞吐量，并在高达150亿条数据（约为2024年以太坊状态大小的10倍）的大规模数据集上验证了其可扩展性。QMDB单机理论上可以存储最多2800亿条条目，远超当前区块链需求。此外，QMDB在商品级和企业级硬件上均表现出良好的扩展性，可实现每秒200万次的状态更新，从而显著缓解了当前区块链执行层面临的存储瓶颈问题，降低了参与区块链的门槛，并为新的区块链应用开辟了可能性。 <div>
arXiv:2501.05262v1 Announce Type: new 
Abstract: Updating, managing, and proving world state are key bottlenecks facing the execution layer of blockchains today. Existing storage solutions are not flash-optimized and suffer from high flash write amplification and excessive DRAM requirements, forcing a trade-off between throughput and decentralization. We present the Quick Merkle Database (QMDB), an SSD-optimized authenticated data structure that delivers a superset of the features of existing databases. QMDB's append-only design enables 1 SSD read per state access, $O(1)$ I/Os for updates, and in-memory Merkleization on a DRAM footprint small enough to fit on consumer-grade PCs. We demonstrate that QMDB offers a significant leap in throughput ($6 \times$ over RocksDB and $8 \times$ over a state-of-the-art verifiable database) and validate its scalability on datasets up to 15 billion entries ($10 \times$ Ethereum's state size in 2024). Our projections indicate QMDB could store a theoretical maximum of 280 billion entries on a single machine, far exceeding current blockchain requirements. QMDB scales across both commodity and enterprise hardware, achieving up to 2 million state updates per second. QMDB sets a new benchmark for verifiable databases, alleviating today's storage bottlenecks, lowering barriers to blockchain participation, and unlocking new blockchain applications.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GaussDB-Global: A Geographically Distributed Database System</title>
<link>https://arxiv.org/abs/2501.05295</link>
<guid>https://arxiv.org/abs/2501.05295</guid>
<content:encoded><![CDATA[
<div> 关键词：GaussDB-Global、地理分布式数据库系统、异步复制、事务管理、强一致性<br /><br />总结:
GaussDB-Global是一款为OLTP应用设计的分片式地理分布式数据库系统，采用异步复制技术。为了克服集中式交易管理带来的延迟问题，该系统采取了基于同步时钟的去中心化方法，能在集中式和去中心化交易管理之间无缝切换，实现高效容错并简化部署。同时，针对远程读取和日志传输的问题，GaussDB-Global支持带有强一致性和可调整新鲜度保证的异步副本读取以及动态负载均衡。实验结果显示，在地理分布式的集群环境中，与基线相比，GaussDB-Global能够提供高达14倍的读取吞吐量提升以及50%更多的TPC-C吞吐量提升。 <div>
arXiv:2501.05295v1 Announce Type: new 
Abstract: Geographically distributed database systems use remote replication to protect against regional failures. These systems are sensitive to severe latency penalties caused by centralized transaction management, remote access to sharded data, and log shipping over long distances. To tackle these issues, we present GaussDB-Global, a sharded geographically distributed database system with asynchronous replication, for OLTP applications. To tackle the transaction management bottleneck, we take a decentralized approach using synchronized clocks. Our system can seamlessly transition between centralized and decentralized transaction management, providing efficient fault tolerance and streamlining deployment. To alleviate the remote read and log shipping issues, we support reads on asynchronous replicas with strong consistency, tunable freshness guarantees, and dynamic load balancing. Our experimental results on a geographically distributed cluster show that our approach provides up to 14x higher read throughput, and 50% more TPC-C throughput compared to our baseline.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Recursive matrix algorithms, distributed dynamic control, scaling, stability</title>
<link>https://arxiv.org/abs/2501.05318</link>
<guid>https://arxiv.org/abs/2501.05318</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv, 2501.05318v1, 新发布, 块递归矩阵算法, 超级计算机, 分布式内存, 动态去中心化控制

<br />
总结:
该报告关注的是在具有分布式内存和动态去中心化控制的超级计算机上创建块递归矩阵算法的概念。文章介绍了一种新的方法，旨在利用这些算法提高大规模并行计算效率和性能。 <div>
arXiv:2501.05318v1 Announce Type: new 
Abstract: The report is devoted to the concept of creating block-recursive matrix algorithms for computing on a supercomputer with distributed memory and dynamic decentralized control.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Learning and Inference Systems: A Networking Perspective</title>
<link>https://arxiv.org/abs/2501.05323</link>
<guid>https://arxiv.org/abs/2501.05323</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习模型、中央化训练、隐私问题、分布式方法、DA-ITN框架

总结:
随着机器学习模型在各类任务中达到甚至超越人类水平的表现，集中式的训练和静态模型使用暴露出诸如隐私问题、高存储需求、单点故障及大量计算需求等缺点。为应对这些挑战，研究者们开始关注开发去中心化和分布式的AI训练与推理方法。本文提出了一种新的框架——数据与动态感知推理和训练网络（DA-ITN），探讨了其组成部分及其功能，并着重指出了在分布式AI系统发展中所面临的挑战和相关研究领域。 <div>
arXiv:2501.05323v1 Announce Type: new 
Abstract: Machine learning models have achieved, and in some cases surpassed, human-level performance in various tasks, mainly through centralized training of static models and the use of large models stored in centralized clouds for inference. However, this centralized approach has several drawbacks, including privacy concerns, high storage demands, a single point of failure, and significant computing requirements. These challenges have driven interest in developing alternative decentralized and distributed methods for AI training and inference. Distribution introduces additional complexity, as it requires managing multiple moving parts. To address these complexities and fill a gap in the development of distributed AI systems, this work proposes a novel framework, Data and Dynamics-Aware Inference and Training Networks (DA-ITN). The different components of DA-ITN and their functions are explored, and the associated challenges and research areas are highlighted.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Validation of GPU Computation in Decentralized, Trustless Networks</title>
<link>https://arxiv.org/abs/2501.05374</link>
<guid>https://arxiv.org/abs/2501.05374</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式网络、GPU计算、验证方法、模型指纹技术、语义相似性分析、GPU性能分析、概率验证框架、可信节点验证、共识框架、非确定性执行

总结:<br />
本文针对分布式网络中GPU计算的验证问题展开研究，指出现有方法如精确重算（因GPU节点间的计算非确定性）、受信任执行环境（需要专用硬件）和全同态加密（面临高昂计算成本）等存在的局限性。文章探讨了从相邻技术领域借鉴的三种验证方法：模型指纹技术、语义相似性分析以及GPU性能分析。通过系统研究这些方法，作者提出了一种新颖的概率验证框架，包括采用二进制参考模型结合可信节点验证的方法，以及构建消除信任需求的三元共识框架。这些方法为确保在不可信网络中的GPU加速工作负载计算完整性奠定了基础，同时有效应对了非确定性执行带来的挑战。 <div>
arXiv:2501.05374v1 Announce Type: new 
Abstract: Verifying computational processes in decentralized networks poses a fundamental challenge, particularly for Graphics Processing Unit (GPU) computations. Our investigation reveals significant limitations in existing approaches: exact recomputation fails due to computational non-determinism across GPU nodes, Trusted Execution Environments (TEEs) require specialized hardware, and Fully Homomorphic Encryption (FHE) faces prohibitive computational costs. To address these challenges, we explore three verification methodologies adapted from adjacent technical domains: model fingerprinting techniques, semantic similarity analysis, and GPU profiling. Through systematic exploration of these approaches, we develop novel probabilistic verification frameworks, including a binary reference model with trusted node verification and a ternary consensus framework that eliminates trust requirements. These methodologies establish a foundation for ensuring computational integrity across untrusted networks while addressing the inherent challenges of non-deterministic execution in GPU-accelerated workloads.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Diffusion Models</title>
<link>https://arxiv.org/abs/2501.05450</link>
<guid>https://arxiv.org/abs/2501.05450</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模AI模型训练、分散式扩散模型、独立集群、基础设施成本、GPU故障韧性

总结:
<br />
本文提出了一种名为“分散式扩散模型”的新型框架，旨在解决大规模AI模型训练中对集中式、高带宽网络结构的依赖问题。该方法通过将数据集划分并分别在隔离的专家模型上进行训练，每个专家模型都在自己的计算岛上全独立运行。在推理阶段，这些专家模型通过轻量级路由器进行融合。实验表明，这种ensemble方式能实现与单一模型在完整数据集上训练相同的优化目标。分散式扩散模型可以降低基础设施成本、提高对局部GPU故障的韧性，使得研究者能够利用更小、更具成本效益和易获取的计算资源，如按需GPU节点，而无需大型集成系统。文中在ImageNet和LAION Aesthetics数据集上进行了广泛实验，证明了分散式扩散模型在同等计算量下优于标准扩散模型。最后，作者将这种方法扩展到240亿参数规模，展示了只需8个独立GPU节点就能在一周内训练出高质量的扩散模型。 <div>
arXiv:2501.05450v1 Announce Type: new 
Abstract: Large-scale AI model training divides work across thousands of GPUs, then synchronizes gradients across them at each step. This incurs a significant network burden that only centralized, monolithic clusters can support, driving up infrastructure costs and straining power systems. We propose Decentralized Diffusion Models, a scalable framework for distributing diffusion model training across independent clusters or datacenters by eliminating the dependence on a centralized, high-bandwidth networking fabric. Our method trains a set of expert diffusion models over partitions of the dataset, each in full isolation from one another. At inference time, the experts ensemble through a lightweight router. We show that the ensemble collectively optimizes the same objective as a single model trained over the whole dataset. This means we can divide the training burden among a number of "compute islands," lowering infrastructure costs and improving resilience to localized GPU failures. Decentralized diffusion models empower researchers to take advantage of smaller, more cost-effective and more readily available compute like on-demand GPU nodes rather than central integrated systems. We conduct extensive experiments on ImageNet and LAION Aesthetics, showing that decentralized diffusion models FLOP-for-FLOP outperform standard diffusion models. We finally scale our approach to 24 billion parameters, demonstrating that high-quality diffusion models can now be trained with just eight individual GPU nodes in less than a week.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Calculating Customer Lifetime Value and Churn using Beta Geometric Negative Binomial and Gamma-Gamma Distribution in a NFT based setting</title>
<link>https://arxiv.org/abs/2501.04719</link>
<guid>https://arxiv.org/abs/2501.04719</guid>
<content:encoded><![CDATA[
<div> 关键词：Customer Lifetime Value (CLV)，Beta Geometric Negative Binomial Distribution (BGNBD)，Gamma Gamma Distribution，NFT，blockchain

<br /><br />总结:
本文介绍了两种用于计算客户终身价值（CLV）的模型——Beta Geometric Negative Binomial Distribution (BGNBD)和Gamma Gamma Distribution。这两个模型能够考虑到非fungible token（NFT）在区块链环境中的交易频率和价值。通过使用历史交易数据来估计这些模型的参数，企业可以了解其客户的终身价值，并据此制定基于数据驱动的营销和客户保留策略。 <div>
arXiv:2501.04719v1 Announce Type: cross 
Abstract: Customer Lifetime Value (CLV) is an important metric that measures the total value a customer will bring to a business over their lifetime. The Beta Geometric Negative Binomial Distribution (BGNBD) and Gamma Gamma Distribution are two models that can be used to calculate CLV, taking into account both the frequency and value of customer transactions. This article explains the BGNBD and Gamma Gamma Distribution models, and how they can be used to calculate CLV for NFT (Non-Fungible Token) transaction data in a blockchain setting. By estimating the parameters of these models using historical transaction data, businesses can gain insights into the lifetime value of their customers and make data-driven decisions about marketing and customer retention strategies.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Interplay between Social Welfare and Tractability of Equilibria</title>
<link>https://arxiv.org/abs/2310.16976</link>
<guid>https://arxiv.org/abs/2310.16976</guid>
<content:encoded><![CDATA[
<div> 关键词: 计算可解性、社会福利、纳什均衡、无遗憾学习算法、光滑性

总结:
本文探讨了计算可解性和社交福利（效率）在算法博弈论中的基本但通常正交的关系。通过引用Roughgarden的光滑性论证，文章表明当可以通过光滑性保证（近似）完全效率时，纳什均衡能够在一系列无遗憾学习算法下接近，从而实现快速和分散化的计算。在此基础上，研究者在大量玩家游戏（玩家数量 $n \gg 1$）中，利用光滑性极限条件下的充分效率特性，提出了新的收敛结果。文中框架统一了包括战略敏感度趋于零的游戏和双人零和游戏等不同类别问题中的均衡计算方法，并揭示了光滑性与优化文献中被广泛研究的Minty性质之间的直接但先前未被注意到的等价关系。最后，文章提出了一组无遗憾动态过程，该过程在保证收敛到粗相关均衡的同时，实现了对光滑性框架下的福利改进。这一成果是通过采用Piliouras等人最近提出的先知镜像下降算法实现的。<br /><br /> <div>
arXiv:2310.16976v2 Announce Type: replace 
Abstract: Computational tractability and social welfare (aka. efficiency) of equilibria are two fundamental but in general orthogonal considerations in algorithmic game theory. Nevertheless, we show that when (approximate) full efficiency can be guaranteed via a smoothness argument \`a la Roughgarden, Nash equilibria are approachable under a family of no-regret learning algorithms, thereby enabling fast and decentralized computation. We leverage this connection to obtain new convergence results in large games -- wherein the number of players $n \gg 1$ -- under the well-documented property of full efficiency via smoothness in the limit. Surprisingly, our framework unifies equilibrium computation in disparate classes of problems including games with vanishing strategic sensitivity and two-player zero-sum games, illuminating en route an immediate but overlooked equivalence between smoothness and a well-studied condition in the optimization literature known as the Minty property. Finally, we establish that a family of no-regret dynamics attains a welfare bound that improves over the smoothness framework while at the same time guaranteeing convergence to the set of coarse correlated equilibria. We show this by employing the clairvoyant mirror descent algortihm recently introduced by Piliouras et al.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach</title>
<link>https://arxiv.org/abs/2407.15879</link>
<guid>https://arxiv.org/abs/2407.15879</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、智能电网、入侵检测系统、Random Walk协议、Epidemic协议

<br /><br />总结:
随着智能电网领域对安全和隐私的关注度提升，对强大的入侵检测系统的需求日益增强。为解决隐私保护和分布式电力系统区域的数据所有权问题，联邦学习（Federated Learning，FL）作为一种隐私保护解决方案应运而生。然而，传统FL依赖中心化聚合器并存在模型更新传输过程中的隐私泄露风险。为此，本文提出了一种新颖的基于Random Walk和Epidemic两种 gossip 协议的去中心化联邦异常检测方案。研究发现，Random Walk协议在去中心化联邦学习环境中的表现优于Epidemic协议。通过使用公开的工业控制系统数据集进行实验验证，该框架展示了在保障数据机密性、降低通信延迟和应对“拖延者”影响的同时，实现了更优的攻击检测精度。此外，与常规FL相比，本方法在训练时间上缩短了约35%，充分体现了其在去中心化学习方法上的有效性和鲁棒性。 <div>
arXiv:2407.15879v2 Announce Type: replace 
Abstract: The increasing security and privacy concerns in the Smart Grid sector have led to a significant demand for robust intrusion detection systems within critical smart grid infrastructure. To address the challenges posed by privacy preservation and decentralized power system zones with distinct data ownership, Federated Learning (FL) has emerged as a promising privacy-preserving solution which facilitates collaborative training of attack detection models without necessitating the sharing of raw data. However, FL presents several implementation limitations in the power system domain due to its heavy reliance on a centralized aggregator and the risks of privacy leakage during model update transmission. To overcome these technical bottlenecks, this paper introduces a novel decentralized federated anomaly detection scheme based on two main gossip protocols namely Random Walk and Epidemic. Our findings indicate that the Random Walk protocol exhibits superior performance compared to the Epidemic protocol, highlighting its efficacy in decentralized federated learning environments. Experimental validation of the proposed framework utilizing publicly available industrial control systems datasets demonstrates superior attack detection accuracy while safeguarding data confidentiality and mitigating the impact of communication latency and stragglers. Furthermore, our approach yields a notable 35% improvement in training time compared to conventional FL, underscoring the efficacy and robustness of our decentralized learning method.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GNN-based Decentralized Perception in Multirobot Systems for Predicting Worker Actions</title>
<link>https://arxiv.org/abs/2501.04193</link>
<guid>https://arxiv.org/abs/2501.04193</guid>
<content:encoded><![CDATA[
<div> 关键词：移动机器人、人类行为预测、分布式感知框架、时空信息、共识机制

<br />
总结:
本文提出了一种使移动机器人能够以分布式方式理解和共享有关人类行为信息的感知框架。该框架允许每个机器人构建其周围环境的空间图，并与其他机器人共享。共享的Spatial数据结合时间信息用于跟踪人类行为随时间的变化。采用群体智能启发的决策过程确保所有机器人就人类行为的一致解释达成共识。实验结果显示，增加更多机器人和考虑更长的时间序列可以提高行为预测准确性。同时，共识机制增强了系统的鲁棒性，使得多机器人系统在动态工业环境中更加可靠。 <div>
arXiv:2501.04193v1 Announce Type: new 
Abstract: In industrial environments, predicting human actions is essential for ensuring safe and effective collaboration between humans and robots. This paper introduces a perception framework that enables mobile robots to understand and share information about human actions in a decentralized way. The framework first allows each robot to build a spatial graph representing its surroundings, which it then shares with other robots. This shared spatial data is combined with temporal information to track human behavior over time. A swarm-inspired decision-making process is used to ensure all robots agree on a unified interpretation of the human's actions. Results show that adding more robots and incorporating longer time sequences improve prediction accuracy. Additionally, the consensus mechanism increases system resilience, making the multi-robot setup more reliable in dynamic industrial settings.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HiCoCS: High Concurrency Cross-Sharding on Permissioned Blockchains</title>
<link>https://arxiv.org/abs/2501.04265</link>
<guid>https://arxiv.org/abs/2501.04265</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、分片、并发跨片交易、HiCoCS、Hyperledger Fabric

<br /><br />总结：
本文提出了一个名为HiCoCS的高并发跨片方案，用于解决许可型区块链（如Hyperledger Fabric）中并发跨片交易（CSTx）的冲突问题。HiCoCS通过引入复合键结构为每个CSTx创建独特的虚拟子代理，实现了冲突无关的并行交易处理，同时降低了资源开销。针对大量复合键管理和中介隐私风险，HiCoCS利用虚拟子代理并发接收和处理CSTx，并采用批量处理技术提高效率。为了降低系统开销和复用资源，文章探讨了复合键的重用策略，并使用同态加密技术增强了隐私保护。实验结果表明，与基线方案相比，HiCoCS能够将跨片交易吞吐量提升3.5-20.2倍。 <div>
arXiv:2501.04265v1 Announce Type: new 
Abstract: As the foundation of the Web3 trust system, blockchain technology faces increasing demands for scalability. Sharding emerges as a promising solution, but it struggles to handle highly concurrent cross-shard transactions (\textsf{CSTx}s), primarily due to simultaneous ledger operations on the same account. Hyperledger Fabric, a permissioned blockchain, employs multi-version concurrency control for parallel processing. Existing solutions use channels and intermediaries to achieve cross-sharding in Hyperledger Fabric. However, the conflict problem caused by highly concurrent \textsf{CSTx}s has not been adequately resolved. To fill this gap, we propose HiCoCS, a high concurrency cross-shard scheme for permissioned blockchains. HiCoCS creates a unique virtual sub-broker for each \textsf{CSTx} by introducing a composite key structure, enabling conflict-free concurrent transaction processing while reducing resource overhead. The challenge lies in managing large numbers of composite keys and mitigating intermediary privacy risks. HiCoCS utilizes virtual sub-brokers to receive and process \textsf{CSTx}s concurrently while maintaining a transaction pool. Batch processing is employed to merge multiple \textsf{CSTx}s in the pool, improving efficiency. We explore composite key reuse to reduce the number of virtual sub-brokers and lower system overhead. Privacy preservation is enhanced using homomorphic encryption. Evaluations show that HiCoCS improves cross-shard transaction throughput by 3.5-20.2 times compared to the baselines.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VerifBFL: Leveraging zk-SNARKs for A Verifiable Blockchained Federated Learning</title>
<link>https://arxiv.org/abs/2501.04319</link>
<guid>https://arxiv.org/abs/2501.04319</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、联邦学习、零知识证明、增量可验证计算、差分隐私

<br /><br />总结:
本文提出了一种名为VerifBFL的信任less、隐私保护和可验证的联邦学习框架，该框架结合了区块链技术和加密协议。VerifBFL利用零知识SNARKs和增量可验证计算（IVC）确保了本地训练和聚合过程的可验证性，通过在链上验证这些证明以保证每个参与者的贡献完整性和可审计性。为防止推理攻击，VerifBFL还采用了差分隐私技术来保护训练数据。此外，作者构建了一个概念验证系统，结果显示在VerifBFL中生成局部训练和聚合的证明分别耗时不到81秒和2秒，而链上验证这些证明则耗时不到0.6秒。 <div>
arXiv:2501.04319v1 Announce Type: new 
Abstract: Blockchain-based Federated Learning (FL) is an emerging decentralized machine learning paradigm that enables model training without relying on a central server. Although some BFL frameworks are considered privacy-preserving, they are still vulnerable to various attacks, including inference and model poisoning. Additionally, most of these solutions employ strong trust assumptions among all participating entities or introduce incentive mechanisms to encourage collaboration, making them susceptible to multiple security flaws. This work presents VerifBFL, a trustless, privacy-preserving, and verifiable federated learning framework that integrates blockchain technology and cryptographic protocols. By employing zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARKs) and incrementally verifiable computation (IVC), VerifBFL ensures the verifiability of both local training and aggregation processes. The proofs of training and aggregation are verified on-chain, guaranteeing the integrity and auditability of each participant's contributions. To protect training data from inference attacks, VerifBFL leverages differential privacy. Finally, to demonstrate the efficiency of the proposed protocols, we built a proof of concept using emerging tools. The results show that generating proofs for local training and aggregation in VerifBFL takes less than 81s and 2s, respectively, while verifying them on-chain takes less than 0.6s.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoDFL: A Scalable and Automated Reputation-Aware Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.04331</link>
<guid>https://arxiv.org/abs/2501.04331</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链联邦学习 (BFL), 可扩展性, 成本效益, zk-Rollups, 自动化声誉模型

<br /><br />总结:
本文提出了一个名为AutoDFL的新型框架，旨在解决区块链联邦学习(BFL)在可扩展性和成本效益方面的挑战，以及在声誉感知BFL中加剧的性能问题。AutoDFL利用zk-Rollups作为Layer-2扩容解决方案，以提高性能并保持与底层Layer-1区块链相同的安全水平。此外，AutoDFL引入了一个自动化和公正的声誉模型，旨在激励联邦学习参与者的行为。通过构建概念验证并进行不同自定义工作负载测试，AutoDFL实现了超过3000 TPS的平均吞吐量和高达20倍的 gas 减少，从而显著提高了BFL的效率、可扩展性并降低了声誉管理成本。 <div>
arXiv:2501.04331v1 Announce Type: new 
Abstract: Blockchained federated learning (BFL) combines the concepts of federated learning and blockchain technology to enhance privacy, security, and transparency in collaborative machine learning models. However, implementing BFL frameworks poses challenges in terms of scalability and cost-effectiveness. Reputation-aware BFL poses even more challenges, as blockchain validators are tasked with processing federated learning transactions along with the transactions that evaluate FL tasks and aggregate reputations. This leads to faster blockchain congestion and performance degradation. To improve BFL efficiency while increasing scalability and reducing on-chain reputation management costs, this paper proposes AutoDFL, a scalable and automated reputation-aware decentralized federated learning framework. AutoDFL leverages zk-Rollups as a Layer-2 scaling solution to boost the performance while maintaining the same level of security as the underlying Layer-1 blockchain. Moreover, AutoDFL introduces an automated and fair reputation model designed to incentivize federated learning actors. We develop a proof of concept for our framework for an accurate evaluation. Tested with various custom workloads, AutoDFL reaches an average throughput of over 3000 TPS with a gas reduction of up to 20X.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lossless Privacy-Preserving Aggregation for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.04409</link>
<guid>https://arxiv.org/abs/2501.04409</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、去中心化联邦学习、梯度泄露、噪声注入、LPPA<br /><br />总结: 随着敏感数据的增长，隐私问题日益凸显。尽管去中心化联邦学习(DFL)通过聚合邻居的梯度以避免直接传输数据，但仍存在间接的梯度泄露风险。现有的隐私保护方法通过对梯度添加噪声来解决此问题，但这可能导致模型预测精度降低或梯度保护不力。本文提出了一种新颖的无损隐私保护聚合规则——LPPA，旨在尽可能增强梯度保护的同时，保持DFL模型的预测精度不受影响。LPPA巧妙地将发送和接收到的噪声差值注入到传输的梯度中，利用邻居之间的随机性有效防止数据泄露。同时，LPPA运用噪声流守恒理论确保全局可以消除噪声影响，保证了准确的梯度聚合与模型精度不变。理论证明，LPPA的隐私保护能力比单纯的噪声添加高出√2倍，同时模型精度可与标准无噪声注入的DFL聚合相媲美。实验结果验证了理论发现，表明LPPA相比噪声添加方法能实现平均13%的精度提升，并展示了其在保护原始数据和保障模型精度方面的有效性。 <div>
arXiv:2501.04409v1 Announce Type: new 
Abstract: Privacy concerns arise as sensitive data proliferate. Despite decentralized federated learning (DFL) aggregating gradients from neighbors to avoid direct data transmission, it still poses indirect data leaks from the transmitted gradients. Existing privacy-preserving methods for DFL add noise to gradients. They either diminish the model predictive accuracy or suffer from ineffective gradient protection. In this paper, we propose a novel lossless privacy-preserving aggregation rule named LPPA to enhance gradient protection as much as possible but without loss of DFL model predictive accuracy. LPPA subtly injects the noise difference between the sent and received noise into transmitted gradients for gradient protection. The noise difference incorporates neighbors' randomness for each client, effectively safeguarding against data leaks. LPPA employs the noise flow conservation theory to ensure that the noise impact can be globally eliminated. The global sum of all noise differences remains zero, ensuring that accurate gradient aggregation is unaffected and the model accuracy remains intact. We theoretically prove that the privacy-preserving capacity of LPPA is \sqrt{2} times greater than that of noise addition, while maintaining comparable model accuracy to the standard DFL aggregation without noise injection. Experimental results verify the theoretical findings and show that LPPA achieves a 13% mean improvement in accuracy over noise addition. We also demonstrate the effectiveness of LPPA in protecting raw data and guaranteeing lossless model accuracy.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Research on environment perception and behavior prediction of intelligent UAV based on semantic communication</title>
<link>https://arxiv.org/abs/2501.04480</link>
<guid>https://arxiv.org/abs/2501.04480</guid>
<content:encoded><![CDATA[
<div> 关键词：无人机配送系统、虚拟世界、区块链、强化学习、语义通信框架、认证与密钥协商方案、元宇宙、资源分配、通信成本、信息安全、交易吞吐量

<br /><br />总结:
本文介绍了将无人机配送系统、虚拟世界和区块链技术融合对物流与供应链管理产生的变革，为传统地面运输提供更快、更环保的替代方案。首先，文章提出了应用强化学习方法，使无人机能快速训练并自主适应新的虚拟场景，实现有效的资源分配。其次，设计了一种语义通信框架用于元宇宙，通过提取语义信息来降低通信成本并激励信息服务传输。再者，为了保障用户信息安全，引入区块链技术设计了轻量级的无人机与用户之间的认证与密钥协商方案。实验结果显示，无人机的适应性性能提高了约35%，随着基站数量增加，本地卸载率可达90%。此外，文中提出的语义通信系统相较于交叉熵基线模型有明显优势，并且利用区块链技术保持了不同数量无人机情况下的交易吞吐量稳定。 <div>
arXiv:2501.04480v1 Announce Type: new 
Abstract: The convergence of drone delivery systems, virtual worlds, and blockchain has transformed logistics and supply chain management, providing a fast, and environmentally friendly alternative to traditional ground transportation methods;Provide users with a real-world experience, virtual service providers need to collect up-to-the-minute delivery information from edge devices. To address this challenge, 1) a reinforcement learning approach is introduced to enable drones with fast training capabilities and the ability to autonomously adapt to new virtual scenarios for effective resource allocation.2) A semantic communication framework for meta-universes is proposed, which utilizes the extraction of semantic information to reduce the communication cost and incentivize the transmission of information for meta-universe services.3) In order to ensure that user information security, a lightweight authentication and key agreement scheme is designed between the drone and the user by introducing blockchain technology. In our experiments, the drone adaptation performance is improved by about 35\%, and the local offloading rate can reach 90\% with the increase of the number of base stations. The semantic communication system proposed in this paper is compared with the Cross Entropy baseline model. Introducing blockchain technology the throughput of the transaction is maintained at a stable value with different number of drones.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Demystification and Near-perfect Estimation of Minimum Gas Limit and Gas Used for Ethereum Smart Contracts</title>
<link>https://arxiv.org/abs/2501.04483</link>
<guid>https://arxiv.org/abs/2501.04483</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum区块链、gas系统、gas限制、最小gas限制、gas使用量

总结:

本文关注以太坊区块链的gas系统，探讨了其中的核心概念——gas限制和gas使用量。文章首次明确提出并区分了“最小gas限制”这一概念，指出它与交易实际消耗的gas使用量并不相同，并通过实证研究展示了二者的差异。此外，文中还提出了分别针对这两种指标的精确估算方法，由于当前多数估算器仅关注gas使用量。研究发现，对于以太坊区块链，在时间t的状态下确定的最小gas限制可以很好地预测在t+Δ（其中Δ≤11）区块上执行的交易所需的gas预算，同样适用于gas使用量的估计。这些精确的估计算法对于帮助用户预估交易gas预算以及开发者优化智能合约具有重要价值。总的来说，该论文为区块链开发者和用户提供了一个深入理解gas系统工作原理的重要参考。 <div>
arXiv:2501.04483v1 Announce Type: new 
Abstract: The Ethereum blockchain has a \emph{gas system} that associates operations with a cost in gas units. Two central concepts of this system are the \emph{gas limit} assigned by the issuer of a transaction and the \emph{gas used} by a transaction. The former is a budget that must not be exhausted before the completion of the transaction execution; otherwise, the execution fails. Therefore, it seems rather essential to determine the \emph{minimum gas limit} that ensures the execution of a transaction will not abort due to the lack of gas. Despite its practical relevance, this concept has not been properly addressed. In the literature, gas used and minimum gas limit are conflated. This paper proposes a precise notion of minimum gas limit and how it can differ from gas used by a transaction; this is also demonstrated with a quantitative study on real transactions of the Ethereum blockchain. Another significant contribution is the proposition of a fairly precise estimator for each of the two metrics. Again, the confusion between these concepts has led to the creation of estimators only for the gas used by a transaction. We demonstrate that the minimum gas limit for the state of the Ethereum blockchain (after the block) $t$ can serve as a near-perfect estimation for the execution of the transaction at block $t + \Delta$, where $\Delta \leq 11$; the same holds for estimating gas used. These precise estimators can be very valuable in helping the users predict the gas budget of transactions and developers in optimising their smart contracts; over and underestimating gas used and minimum gas limit can lead to a number of practical issues. Overall, this paper serves as an important reference for blockchain developers and users as to how the gas system really works.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multichannel Steganography: A Provably Secure Hybrid Steganographic Model for Secure Communication</title>
<link>https://arxiv.org/abs/2501.04511</link>
<guid>https://arxiv.org/abs/2501.04511</guid>
<content:encoded><![CDATA[
<div> 关键词: steganographic模型, 覆盖修改, 覆盖合成, 通信协议, 安全分析

总结:<br />
本文提出了一种结合封面修改(CMO)和封面合成(CSY)的创新隐写术模型，通过生成封面消息或参数来增强安全性和不可检测性，同时保持原始封面的形式，降低了检测风险并克服了单一方法技术的局限性。基于此模型，作者进一步设计了一个强化的隐写术通信协议，增强了对多通道重播攻击和多通道中间人攻击的抵抗能力，提升了协议防篡改的能力。为了评估新协议的安全性，文章开发了一个模拟概率多项式时间(PPT)敌手的新型对抗模型，用于评估对手破坏协议的能力，提供了全面的安全分析。此外，该研究还探讨了该模型在受限环境如短信银行和资源丰富环境如区块链交易中的实用性和适应性，展示了其提升金融服务与安全性方面的潜力。这些贡献共同构成了一套坚固且适应性强的隐写术安全通信框架，为不同环境下的安全通信提供切实可行的解决方案。 <div>
arXiv:2501.04511v1 Announce Type: new 
Abstract: This study introduces a novel steganographic model that synthesizes Steganography by Cover Modification (CMO) and Steganography by Cover Synthesis (CSY), enhancing both security and undetectability by generating cover messages or parameters while retaining the original cover's form, thus minimizing detection risks and overcoming the limitations of single-method techniques. Building upon this model, a refined Steganographic Communication Protocol is proposed, enhancing resilience against sophisticated threats such as Multichannel Replay Attacks and Multichannel Man-in-the-Middle Attacks, fortifying the protocol against potential tampering and improving upon prior works. To evaluate the security of the proposed protocol, a novel adversarial model is developed simulating a probabilistic polynomial time (PPT) adversary capable of intercepting communications across multiple channels. This model assesses the adversary's ability to compromise the protocol, providing a comprehensive security analysis. Finally, this study explores the practicality and adaptability of the model to both constrained environments like SMS banking and resource-rich settings such as blockchain transactions, demonstrating their potential to enhance financial services and security. These contributions present a robust and adaptable framework for secure steganographic communication, offering practical solutions for secure communications across diverse environments.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Data Notarization Leveraging Hybrid DLTs</title>
<link>https://arxiv.org/abs/2501.04571</link>
<guid>https://arxiv.org/abs/2501.04571</guid>
<content:encoded><![CDATA[
<div> 关键词: 不动产登记, 区块链, 可扩展性, 数据管理, 混合区块链架构

总结:
本文探讨了不动产登记在数据管理中的重要性，通过确保数据在审计过程中的认证来增强信任。文章指出，区块链作为一种安全、不可变、透明的存储方式，已广泛用于提升基于区块链的数据不动产登记协议的效果和可信度。然而，现有的实现方案无论是在公共区块链还是私有区块链上都面临挑战：公共区块链上的高费用和私有平台的信任问题限制了区块链在不动产登记中的应用或迫使做出许多妥协。为此，论文研究了混合区块链架构在数据不动产登记中的应用，重点关注可扩展性问题。通过对实际案例——供应链中产品护照的数据不动产登记进行分析，提出了利用一种能够有效平衡存储占用和大规模数据公证成本的数据结构的新型方法。 <div>
arXiv:2501.04571v1 Announce Type: new 
Abstract: Notarization is a procedure that enhance data management by ensuring the authentication of data during audits, thereby increasing trust in the audited data. Blockchain is frequently used as a secure, immutable, and transparent storage, contributing to make data notarization procedures more effective and trustable. Several blockchain-based data notarization protocols have been proposed in literature and commercial solutions. However, these implementations, whether on public or private blockchains, face inherent challenges: high fees on public blockchains and trust issues on private platforms, limiting the adoption of blockchains for data notarization or forcing several trade-offs. In this paper, we explore the use of hybrid blockchain architectures for data notarization, with a focus on scalability issues. Through the analysis of a real-world use case, the data notarization of product passports in supply chains, we propose a novel approach utilizing a data structure designed to efficiently manage the trade-offs in terms of storage occupation and costs involved in notarizing a large collection of data.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Do Automated Fixes Truly Mitigate Smart Contract Exploits?</title>
<link>https://arxiv.org/abs/2501.04600</link>
<guid>https://arxiv.org/abs/2501.04600</guid>
<content:encoded><![CDATA[
<div> 关键词：Automated Program Repair (APR)，智能合约安全，漏洞修复，实验框架，exploit mitigation rate

总结:
这篇论文探讨了利用自动化程序修复(APR)技术增强智能合约安全性并自动修复导致巨额财务损失的安全漏洞的有效性。文章提出了一种新的、系统的实验框架，用于评估针对智能合约的修复工具在防止漏洞利用方面的效果。通过对涵盖143份易受攻击的智能合约和手动构造的91个可执行漏洞的数据集进行定性和定量分析，研究首次定义并测量了关键的“漏洞利用缓解率”，为研究人员和实践者提供了对前沿技术实际效果的真实认识。结果显示，现有技术之间存在显著差距，漏洞利用缓解率从最低的27%到最高的73%，这一结果与原始论文中的描述大相径庭。此外，该研究还识别出了未来智能合约程序修复领域需要解决的系统性局限，如功能一致性保持问题。 <div>
arXiv:2501.04600v1 Announce Type: new 
Abstract: Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential "exploit mitigation rate", giving researchers and practitioners and real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 27% to a high of 73%, a result that nobody would guess from reading the original papers. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>gECC: A GPU-based high-throughput framework for Elliptic Curve Cryptography</title>
<link>https://arxiv.org/abs/2501.03245</link>
<guid>https://arxiv.org/abs/2501.03245</guid>
<content:encoded><![CDATA[
<div> 关键词：椭圆曲线密码学（ECC）、GPU优化、gECC框架、高性能、并行计算

总结:
本文介绍了针对GPU架构优化的高吞吐量椭圆曲线加密算法框架gECC。gECC通过批量执行椭圆曲线操作和微架构层面的模数运算优化，利用Montgomery's trick实现批量EC计算，并采用创新的并行计算与内存管理技术，最大限度提高并行计算效率并降低GPU全局内存访问开销。通过对模乘运算瓶颈的分析，发现其效率高度依赖于Integer Multiply-Add (IMAD)指令的数量。为解决这一问题，文章提出了利用判定点寄存器传递进位信息以及使用加减法指令(IADD3)替代IMAD指令的技术。实验结果显示，相较于现有最先进的GPU基线系统，gECC在ECDSA和ECDH上的性能分别提高了5.56倍和4.94倍；在实际区块链应用中，相比于最先进的CPU基线系统，实现了1.56倍的性能提升。 <div>
arXiv:2501.03245v1 Announce Type: new 
Abstract: Elliptic Curve Cryptography (ECC) is an encryption method that provides security comparable to traditional techniques like Rivest-Shamir-Adleman (RSA) but with lower computational complexity and smaller key sizes, making it a competitive option for applications such as blockchain, secure multi-party computation, and database security. However, the throughput of ECC is still hindered by the significant performance overhead associated with elliptic curve (EC) operations. This paper presents gECC, a versatile framework for ECC optimized for GPU architectures, specifically engineered to achieve high-throughput performance in EC operations. gECC incorporates batch-based execution of EC operations and microarchitecture-level optimization of modular arithmetic. It employs Montgomery's trick to enable batch EC computation and incorporates novel computation parallelization and memory management techniques to maximize the computation parallelism and minimize the access overhead of GPU global memory. Also, we analyze the primary bottleneck in modular multiplication by investigating how the user codes of modular multiplication are compiled into hardware instructions and what these instructions' issuance rates are. We identify that the efficiency of modular multiplication is highly dependent on the number of Integer Multiply-Add (IMAD) instructions. To eliminate this bottleneck, we propose techniques to minimize the number of IMAD instructions by leveraging predicate registers to pass the carry information and using addition and subtraction instructions (IADD3) to replace IMAD instructions. Our results show that, for ECDSA and ECDH, gECC can achieve performance improvements of 5.56x and 4.94x, respectively, compared to the state-of-the-art GPU-based system. In a real-world blockchain application, we can achieve performance improvements of 1.56x, compared to the state-of-the-art CPU-based system.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FTA-FTL: A Fine-Tuned Aggregation Federated Transfer Learning Scheme for Lithology Microscopic Image Classification</title>
<link>https://arxiv.org/abs/2501.03349</link>
<guid>https://arxiv.org/abs/2501.03349</guid>
<content:encoded><![CDATA[
<div> 关键词：Lithology discrimination，Deep Learning，Transfer learning，Federated Learning，Fine-Tuned Aggregation

<br /><br />总结：
本文主要研究了石油储层岩性识别中的关键问题——岩石显微图像分类。首先，利用迁移学习方法对小规模数据集进行了岩石显微图像分类，比较了多种预训练的深度学习模型架构的效果。随后，文章提出了将分类任务转化为联邦迁移学习（FTL）框架下的细调聚合策略（FTA-FTL）。实验结果表明，该FTA-FTL算法能够在保护敏感数据和增强安全性的同时，实现与集中式实施相当的岩石显微图像分类性能，证实了所提方案的有效性。 <div>
arXiv:2501.03349v1 Announce Type: new 
Abstract: Lithology discrimination is a crucial activity in characterizing oil reservoirs, and processing lithology microscopic images is an essential technique for investigating fossils and minerals and geological assessment of shale oil exploration. In this way, Deep Learning (DL) technique is a powerful approach for building robust classifier models. However, there is still a considerable challenge to collect and produce a large dataset. Transfer-learning and data augmentation techniques have emerged as popular approaches to tackle this problem. Furthermore, due to different reasons, especially data privacy, individuals, organizations, and industry companies often are not willing to share their sensitive data and information. Federated Learning (FL) has emerged to train a highly accurate central model across multiple decentralized edge servers without transferring sensitive data, preserving sensitive data, and enhancing security. This study involves two phases; the first phase is to conduct Lithology microscopic image classification on a small dataset using transfer learning. In doing so, various pre-trained DL model architectures are comprehensively compared for the classification task. In the second phase, we formulated the classification task to a Federated Transfer Learning (FTL) scheme and proposed a Fine-Tuned Aggregation strategy for Federated Learning (FTA-FTL). In order to perform a comprehensive experimental study, several metrics such as accuracy, f1 score, precision, specificity, sensitivity (recall), and confusion matrix are taken into account. The results are in excellent agreement and confirm the efficiency of the proposed scheme, and show that the proposed FTA-FTL algorithm is capable enough to achieve approximately the same results obtained by the centralized implementation for Lithology microscopic images classification task.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Smart Contracts for Permissioned Blockchains: A zk-SNARK-Based Recipe Part-1</title>
<link>https://arxiv.org/abs/2501.03391</link>
<guid>https://arxiv.org/abs/2501.03391</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、隐私保护、zk-SNARKs、委托交易

<br /><br />总结:
本文提出了利用zk-SNARKs技术来实现区块链和智能合约中隐私保护的新方案。该方案不仅支持可替代和不可替代令牌的隐私交易，还引入了一种新的交易类型——委托交易，使得如Delivery vs Payment（DvP）等使用场景得以实现。与现有解决方案相比，该方法旨在克服功能限制、高计算时间和对第三方信任的需求等问题，以实现更全面的去中心化。 <div>
arXiv:2501.03391v1 Announce Type: new 
Abstract: The Bitcoin white paper introduced blockchain technology, enabling trustful transactions without intermediaries. Smart contracts emerged with Ethereum and blockchains expanded beyond cryptocurrency, applying to auctions, crowdfunding and electronic voting. However, blockchain's transparency raised privacy concerns and initial anonymity measures proved ineffective. Smart contract privacy solutions employed zero-knowledge proofs, homomorphic encryption and trusted execution environments. These approaches have practical drawbacks, such as limited functionality, high computation times and trust on third parties requirements, being not fully decentralized. This work proposes a solution utilizing zk-SNARKs to provide privacy in smart contracts and blockchains. The solution supports both fungible and nonfungible tokens. Additionally, the proposal includes a new type of transactions, called delegated transactions, which enable use cases like Delivery vs Payment (DvP).
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: A Review of Cross-Chain Bridge Hacks in 2023</title>
<link>https://arxiv.org/abs/2501.03423</link>
<guid>https://arxiv.org/abs/2501.03423</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、跨链桥、攻击、安全漏洞、防御措施

<br /><br />总结:
本文分析了2022年和2023年近期针对跨链桥的黑客攻击事件，这些攻击导致了大量的财务损失，特别是Axie Infinity Ronin Bridge遭受了近6亿美元的巨额损失。文章重点研究了被利用的安全漏洞，旨在通过了解攻击的本质和潜在弱点来加强桥梁安全性，并提出可能的应对措施。通过解决近期跨链桥攻击中暴露的脆弱性与缺陷，将有助于建立行业通行的桥梁安全标准，增强对跨链互操作性的信任和信心。 <div>
arXiv:2501.03423v1 Announce Type: new 
Abstract: Blockchain technology has revolutionized industries by enabling secure and decentralized transactions. However, the isolated nature of blockchain ecosystems hinders the seamless transfer of digital assets across different chains. Cross-chain bridges have emerged as vital web3 infrastructure to address this challenge by facilitating interoperability between distinct blockchains. Cross-chain bridges remain vulnerable to various attacks despite sophisticated designs and security measures. The industry has experienced a surge in bridge attacks, resulting in significant financial losses. The largest hack impacted Axie Infinity Ronin Bridge, with a loss of almost \$600 million USD. This paper analyzes recent cross-chain bridge hacks in 2022 and 2023 and examines the exploited vulnerabilities. By understanding the attack nature and underlying weaknesses, the paper aims to enhance bridge security and propose potential countermeasures. The findings contribute to developing industry-wide standards for bridge security and operational resilience. Addressing the vulnerabilities and weaknesses exploited in recent cross-chain bridge hacks fosters trust and confidence in cross-chain interoperability.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Authentication and Granularized Authorization with a Cross-Domain Zero Trust Architecture for Federated Learning in Large-Scale IoT Networks</title>
<link>https://arxiv.org/abs/2501.03601</link>
<guid>https://arxiv.org/abs/2501.03601</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网(IoT)、零信任架构(ZTA)、跨域认证授权、去中心化联邦学习(DFL)、数据隐私

总结:<br />
针对物联网系统中日益增长的安全需求，本文提出了一种结合零信任架构(ZTA)与去中心化联邦学习(DFL)的动态认证和细粒度授权方案，应用于跨域IoT网络。该方案通过持续监控和评估设备请求，仅授予必要的访问权限，以提高安全性并减少效率问题。为了保护用户数据隐私和降低延迟，文中将DFL集成到ZTA中，实现设备数据在不同领域的安全高效共享。同时，提出了模型压缩方法来减轻网络传输负载，并设计了一个动态自适应权重调整机制，使DFL模型能更好地适应来自不同域的数据特性。通过对提出的方案进行安全性分析（包括机密性、完整性和可用性）以及模拟实验，结果表明该方案在降低延迟和提升吞吐量方面相较于其他现有方案具有更优表现。 <div>
arXiv:2501.03601v1 Announce Type: new 
Abstract: With the increasing number of connected devices and complex networks involved, current domain-specific security techniques become inadequate for diverse large-scale Internet of Things (IoT) systems applications. While cross-domain authentication and authorization brings lots of security improvement, it creates new challenges of efficiency and security. Zero trust architecture (ZTA), an emerging network security architecture, offers a more granular and robust security environment for IoT systems. However, extensive cross-domain data exchange in ZTA can cause reduced authentication and authorization efficiency and data privacy concerns. Therefore, in this paper, we propose a dynamic authentication and granularized authorization scheme based on ZTA integrated with decentralized federated learning (DFL) for cross-domain IoT networks. Specifically, device requests in the cross-domain process are continuously monitored and evaluated, and only necessary access permissions are granted. To protect user data privacy and reduce latency, we integrate DFL with ZTA to securely and efficiently share device data across different domains. Particularly, the DFL model is compressed to reduce the network transmission load. Meanwhile, a dynamic adaptive weight adjustment mechanism is proposed to enable the DFL model to adapt to data characteristics from different domains. We analyze the performance of the proposed scheme in terms of security proof, including confidentiality, integrity and availability. Simulation results demonstrate the superior performance of the proposed scheme in terms of lower latency and higher throughput compared to other existing representative schemes.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unraveling Responsiveness of Chained BFT Consensus with Network Delay</title>
<link>https://arxiv.org/abs/2501.03695</link>
<guid>https://arxiv.org/abs/2501.03695</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、chained BFT协议、Markov决策过程(MDP)、性能评估、攻击策略

总结:<br />
本文针对区块链技术中广泛应用的chained Byzantine Fault Tolerant (BFT)协议，提出了一种使用Markov决策过程(MDP)构建的统一框架，用于模型化和评估三种主流chained BFT协议的性能。该框架能够捕捉复杂的敌对行为，并关注两个关键性能指标：链增长和承诺率。通过在现有评价平台上实施由MDP分析得出的最优攻击策略并进行大量实验，验证了理论结果。研究发现，与普遍观点相反，响应速度虽能提升性能，但并非在所有场景下都具有益处。这项工作不仅深化了我们对chained BFT协议的理解，也为设计更健壮和高效的协议提供了有价值的见解和分析工具。 <div>
arXiv:2501.03695v1 Announce Type: new 
Abstract: With the advancement of blockchain technology, chained Byzantine Fault Tolerant (BFT) protocols have been increasingly adopted in practical systems, making their performance a crucial aspect of the study. In this paper, we introduce a unified framework utilizing Markov Decision Processes (MDP) to model and assess the performance of three prominent chained BFT protocols. Our framework effectively captures complex adversarial behaviors, focusing on two key performance metrics: chain growth and commitment rate. We implement the optimal attack strategies obtained from MDP analysis on an existing evaluation platform for chained BFT protocols and conduct extensive experiments under various settings to validate our theoretical results. Through rigorous theoretical analysis and thorough practical experiments, we provide an in-depth evaluation of chained BFT protocols under diverse attack scenarios, uncovering optimal attack strategies. Contrary to conventional belief, our findings reveal that while responsiveness can enhance performance, it is not universally beneficial across all scenarios. This work not only deepens our understanding of chained BFT protocols, but also offers valuable insights and analytical tools that can inform the design of more robust and efficient protocols.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fast Transaction Scheduling in Blockchain Sharding</title>
<link>https://arxiv.org/abs/2405.15015</link>
<guid>https://arxiv.org/abs/2405.15015</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链分片、并行处理、集中式调度器、分布式调度器、交易调度算法

总结:<br />
本文研究了区块链分片技术中针对物联网、边缘计算和移动计算场景下的交易批量调度问题。文章首先提出一种中心化的调度器，其中选取一个 Shard 作为领导者负责接收与确定交易处理的调度方案，该方案对于任意最大距离为 d 的交易及其访问对象给出了 O(kd) 的近似最优解。接着，文章提供了一种适用于线图或随机选择对象情况下的改进型集中式调度器。随后，文章提出了一个分布式调度器，通过层次聚类的方式实现各个 Shard 不需要全局交易信息即可进行调度，其竞争比达到 O(A_{CS} * log d * log s)，其中 A_{CS} 是集中式调度器的近似比。据作者所知，这是首次为区块链分片系统提供具有理论保证的快速交易调度算法。最后，文章通过仿真对比展示了所提调度器相较于锁基方法可显著降低延迟（最高达 3 倍）并提高吞吐量（最高可达 2 倍）。 <div>
arXiv:2405.15015v2 Announce Type: replace 
Abstract: Sharding is a promising technique for addressing the scalability issues of blockchain, and this technique is especially important for IoT, edge, or mobile computing. It divides the $n$ participating nodes into $s$ disjoint groups called shards, where each shard processes transactions in parallel. We examine batch scheduling problems on the shard graph $G_s$, where we find efficient schedules for a set of transactions. First, we present a centralized scheduler where one of the shards is considered as a leader, who receives the transaction information from all of the other shards and determines the schedule to process the transactions. For general graphs, where a transaction and its accessing objects are arbitrarily far from each other with a maximum distance $d$, the centralized scheduler provides $O(kd)$ approximation to the optimal schedule, where $k$ is the maximum number of shards each transaction accesses. Next, we provide a centralized scheduler with a bucketing approach that offers improved bounds for the case where $G_s$ is a line graph, or the $k$ objects are randomly selected. Finally, we provide a distributed scheduler where shards do not require global transaction information. We achieve this by using a hierarchical clustering of the shards and using the centralized scheduler in each cluster. We show that the distributed scheduler has a competitive ratio of $O(A_{CS} \cdot \log d \cdot \log s)$, where $A_{CS}$ is the approximation ratio of the centralized scheduler. To our knowledge, we are the first to give provably fast transaction scheduling algorithms for blockchain sharding systems. We also present simulation results for our schedulers and compare their performance with a lock-based approach. The results show that our schedulers are generally better with up to 3x lower latency and 2x higher throughput.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Feature Fusion: Combining Global Graph Structures and Local Semantics for Blockchain Fraud Detection</title>
<link>https://arxiv.org/abs/2501.02032</link>
<guid>https://arxiv.org/abs/2501.02032</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、欺诈检测、结构信息、语义特征

总结:<br />
本文提出了一种针对区块链欺诈检测的动态特征融合模型。该模型结合了图表示学习和语义特征提取，旨在同时捕获交易网络中的全局结构模式和交易数据中的局部语义关系。通过构建全球账户关系图以及从交易数据中提取局部上下文特征，利用动态多模态融合机制自适应地整合这些特征。此外，文中还开发了一个全面的数据处理管道，包括图构造、时间特征增强和文本预处理。实验证明，这种方法在大规模真实世界的区块链数据集上，在准确性、F1分数和召回率等指标上均优于现有基准。这一工作强调了集成结构关系和语义相似性对于实现稳健的欺诈检测的重要性，并为保护区块链系统提供了一种可扩展的解决方案。 <div>
arXiv:2501.02032v1 Announce Type: new 
Abstract: The advent of blockchain technology has facilitated the widespread adoption of smart contracts in the financial sector. However, current fraud detection methodologies exhibit limitations in capturing both global structural patterns within transaction networks and local semantic relationships embedded in transaction data. Most existing models focus on either structural information or semantic features individually, leading to suboptimal performance in detecting complex fraud patterns.In this paper, we propose a dynamic feature fusion model that combines graph-based representation learning and semantic feature extraction for blockchain fraud detection. Specifically, we construct global graph representations to model account relationships and extract local contextual features from transaction data. A dynamic multimodal fusion mechanism is introduced to adaptively integrate these features, enabling the model to capture both structural and semantic fraud patterns effectively. We further develop a comprehensive data processing pipeline, including graph construction, temporal feature enhancement, and text preprocessing. Experimental results on large-scale real-world blockchain datasets demonstrate that our method outperforms existing benchmarks across accuracy, F1 score, and recall metrics. This work highlights the importance of integrating structural relationships and semantic similarities for robust fraud detection and offers a scalable solution for securing blockchain systems.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Detection of Water Contamination Under Concept Drift</title>
<link>https://arxiv.org/abs/2501.02107</link>
<guid>https://arxiv.org/abs/2501.02107</guid>
<content:encoded><![CDATA[
<div> 关键词: 水分布网络(WDNs), 氯气监测, 双重阈值异常与漂移检测(AD&amp;DD), 长短期记忆网络(LSTM-VAE), 分布式架构

总结:
本文介绍了一种新的无监督方法——双阈值异常与漂移检测(AD&amp;DD)，该方法结合了双重阈值漂移检测机制和基于LSTM的变分自编码器(LSTM-VAE)，用于水分布网络(WDNs)中的实时污染检测。研究中，AD&amp;DD方法在两个实际的WDNs上进行了测试，能有效地识别传感器偏移导致的概念漂移异常，并优于其他方法。此外，文中还提出了一种分布式架构，通过在选定节点部署AD&amp;DD，实现精确的污染检测与定位。 <div>
arXiv:2501.02107v1 Announce Type: new 
Abstract: Water Distribution Networks (WDNs) are vital infrastructures, and contamination poses serious public health risks. Harmful substances can interact with disinfectants like chlorine, making chlorine monitoring essential for detecting contaminants. However, chlorine sensors often become unreliable and require frequent calibration. This study introduces the Dual-Threshold Anomaly and Drift Detection (AD&amp;DD) method, an unsupervised approach combining a dual-threshold drift detection mechanism with an LSTM-based Variational Autoencoder(LSTM-VAE) for real-time contamination detection. Tested on two realistic WDNs, AD&amp;DD effectively identifies anomalies with sensor offsets as concept drift, and outperforms other methods. A proposed decentralized architecture enables accurate contamination detection and localization by deploying AD&amp;DD on selected nodes.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A hybrid marketplace of ideas</title>
<link>https://arxiv.org/abs/2501.02132</link>
<guid>https://arxiv.org/abs/2501.02132</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能系统、文化动态、Web3、观念市场、机器文化

总结:<br />
本文探讨了人工智能系统与人类融合对文化和知识领域产生的新动态，特别是AI代理在Web3这一关注去中心化的区块链社区中的重要技术社会学发展。文章指出，AI代理在公共话语中的参与和影响力挑战了传统认知，并在观念市场上与人类生成的思想共存并竞争注意力，构成了一个混合型观念市场。文章从 memetics 的视角分析AI作为文化代理的角色，并强调进一步研究其对文化和社会的影响的重要性。此外，文中还讨论了这一新范式对于隐私权、知识产权以及治理所带来的社会法律挑战。 <div>
arXiv:2501.02132v1 Announce Type: new 
Abstract: The convergence of humans and artificial intelligence systems introduces new dynamics into the cultural and intellectual landscape. Complementing emerging cultural evolution concepts such as machine culture, AI agents represent a significant technosociological development, particularly within the anthropological study of Web3 as a community focused on decentralization through blockchain. Despite their growing presence, the cultural significance of AI agents remains largely unexplored in academic literature. We argue that, within the context of Web3, these agents challenge traditional notions of participation and influence in public discourse, creating a hybrid marketplace of ideas, a conceptual space where human and AI generated ideas coexist and compete for attention. We examine the current state of AI agents in idea generation, propagation, and engagement, positioning their role as cultural agents through the lens of memetics and encouraging further inquiry into their cultural and societal impact. Additionally, we address the implications of this paradigm for privacy, intellectual property, and governance, highlighting the societal and legal challenges of integrating AI agents into the hybrid marketplace of ideas.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Integration of Blockchain and Artificial Intelligence for Secure Healthcare Systems</title>
<link>https://arxiv.org/abs/2501.02169</link>
<guid>https://arxiv.org/abs/2501.02169</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、AI、医疗数据、安全、健康管理

总结:<br />
随着美国医疗领域数据泄露事件在2022年增长125%，高达1820万份患者记录受到影响，医疗数据的安全与有效管理愈发重要。为应对大数据挑战，许多医疗机构采用AI和区块链技术。AI提升了基于数据的操作及大数据效率，被广泛应用于医疗服务中以降低成本并提升服务质量。而区块链则有助于保护信息共享过程中的交易安全与个人隐私。本文自2008年以来研究了区块链整合AI与医疗系统的独特贡献，关注包括机器学习、深度学习和聚类学习在内的AI应用以及不同类型的区块链架构。通过这些技术的应用，可以在确保患者数据安全的同时，实现医疗信息的有效管理，为医疗机构和患者带来显著优势。其中，从2018年至2021年间，2021年的相关研究与发展最为突出，表现在下载量和谷歌学术引用数的增长上，同时近期的研究专家也对此进行了文章筛选和大型研究基金评审的工作。 <div>
arXiv:2501.02169v1 Announce Type: new 
Abstract: Verisign reported a 125 percent increase in data breaches within the healthcare sector in the United States during 2022, with 18.2 million patient records being impacted. Growing healthcare data volumes and diversification mean that medical information is becoming more valuable. Many Health Centers use various technologies to ease the classification, storage, and exchange of big data. This use can also make the health data of the users at risk and vulnerable. AI and blockchain are among the leading technologies at hand. With AI, data-driven operations and big data efficiency have been improved with respect to traditional techniques. Due to its potential to bring about improvements in health services and lower medical costs, this AI technology is regularly used in healthcare. Blockchain helps protect transactions on sharing information and private privacy as long as the exchange of knowledge is that of the standard. The objective of this analysis is to investigate the research and unique contributions since 2008 regarding blockchain-integrated AI and healthcare systems. The work sheds light on applied AI-based healthcare schemes with machine, ballistic, and acrylic learning and disparate blockchain structures. The use of technology in order to ensure patient data security and manage medical information effectively in healthcare settings offers a highly successful position for both healthcare providers and patients. From 2018 to 2021, the best year was 2021 to grow, enhancing everything to examine the download of the device and the counting of Google Academies, for which the joining perspective was borrowed; local research experts were asked, identified articles in recent years, and read reviews of large research grants.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Large Language Models and Machine Learning for Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2501.02229</link>
<guid>https://arxiv.org/abs/2501.02229</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、智能合约、机器学习、大型语言模型、安全性

总结:
随着区块链技术和智能合约的广泛应用，确保其在整个交易过程中的安全性至关重要。本文探讨了利用经典机器学习模型和微调过的大型语言模型（LLM）来查找并检测智能合约漏洞的安全增强方法。研究基于一个包含注释有漏洞标签的智能合约数据集，训练和测试多种LLMs及传统机器学习算法，如DistilBERT模型，以实现对智能合约代码按漏洞类型进行分类。实验结果显示，经过微调的LLM在识别诸如重入攻击、整数溢出、时间戳依赖和危险的Delegatecall等知名漏洞方面的准确性超过90%，显著提升了现有漏洞检测基准。对比分析了各种机器学习和LLM模型的优势，为实际应用中选择最有效的智能合约安全方案提供了参考。通过结合机器学习与大型语言模型，本文构建了一个丰富且可解释的框架，用于检测不同类型的智能合约漏洞，从而为构建更安全的区块链生态系统奠定了基础。 <div>
arXiv:2501.02229v1 Announce Type: new 
Abstract: As blockchain technology and smart contracts become widely adopted, securing them throughout every stage of the transaction process is essential. The concern of improved security for smart contracts is to find and detect vulnerabilities using classical Machine Learning (ML) models and fine-tuned Large Language Models (LLM). The robustness of such work rests on a labeled smart contract dataset that includes annotated vulnerabilities on which several LLMs alongside various traditional machine learning algorithms such as DistilBERT model is trained and tested. We train and test machine learning algorithms to classify smart contract codes according to vulnerability types in order to compare model performance. Having fine-tuned the LLMs specifically for smart contract code classification should help in getting better results when detecting several types of well-known vulnerabilities, such as Reentrancy, Integer Overflow, Timestamp Dependency and Dangerous Delegatecall. From our initial experimental results, it can be seen that our fine-tuned LLM surpasses the accuracy of any other model by achieving an accuracy of over 90%, and this advances the existing vulnerability detection benchmarks. Such performance provides a great deal of evidence for LLMs ability to describe the subtle patterns in the code that traditional ML models could miss. Thus, we compared each of the ML and LLM models to give a good overview of each models strengths, from which we can choose the most effective one for real-world applications in smart contract security. Our research combines machine learning and large language models to provide a rich and interpretable framework for detecting different smart contract vulnerabilities, which lays a foundation for a more secure blockchain ecosystem.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Convergence of Blockchain Technology and Islamic Economics: Decentralized Solutions for Shariah-Compliant Finance</title>
<link>https://arxiv.org/abs/2501.02263</link>
<guid>https://arxiv.org/abs/2501.02263</guid>
<content:encoded><![CDATA[
<div> 关键词: 金融革命、加密货币、区块链技术、伊斯兰经济学、全球经济景观

<br /><br />总结:
本文概述了当前正在进行的金融革命，这场革命不仅仅涉及数字货币作为一种数字支付手段的出现。其核心驱动力在于区块链技术的革新以及伊斯兰经济学的基本原则相结合，共同构成对传统金融体系的挑战，强调透明度、公正性和去中心化治理。文章指出了这一转变带来的影响及其重塑全球经济格局的潜力。 <div>
arXiv:2501.02263v1 Announce Type: new 
Abstract: This paper provides a brief overview of the ongoing financial revolution, which extends beyond the emergence of cryptocurrencies as a digital medium of exchange. At its core, this revolution is driven by a paradigm shift rooted in the technological advancements of blockchain and the foundational principles of Islamic economics. Together, these elements offer a transformative framework that challenges traditional financial systems, emphasizing transparency, equity, and decentralized governance. The paper highlights the implications of this shift and its potential to reshape the global economic landscape.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Workplace Productivity and Well-being Using AI Agent</title>
<link>https://arxiv.org/abs/2501.02368</link>
<guid>https://arxiv.org/abs/2501.02368</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI), 工作场所生产力, 员工福利, 机器学习(ML), 生物反馈<br /><br />总结:<br />
本文探讨了如何运用人工智能(AI)提高职场生产力和员工福祉。通过将机器学习(ML)技术与神经生物学数据相结合，提出的方案利用价值对齐模型和层次强化学习(HRL)确保自主任务管理符合人类伦理标准。系统借助员工的生物反馈生成个性化的健康提示，营造鼓励身体活动的支持性工作环境。此外，文章还研究了用于提升协作效率和决策透明度的去中心化多智能体系统。文中讨论了多种结合ML技术和AI应用的方法，这些创新旨在创造一个更为高效且注重健康的职场环境，并有助于人力资源管理和组织推出更合理的员工职业发展路径，促进组织转型。 <div>
arXiv:2501.02368v1 Announce Type: new 
Abstract: This paper discusses the use of Artificial Intelligence (AI) to enhance workplace productivity and employee well-being. By integrating machine learning (ML) techniques with neurobiological data, the proposed approaches ensure alignment with human ethical standards through value alignment models and Hierarchical Reinforcement Learning (HRL) for autonomous task management. The system utilizes biometric feedback from employees to generate personalized health prompts, fostering a supportive work environment that encourages physical activity. Additionally, we explore decentralized multi-agent systems for improved collaboration and decision-making frameworks that enhance transparency. Various approaches using ML techniques in conjunction with AI implementations are discussed. Together, these innovations aim to create a more productive and health-conscious workplace. These outcomes assist HR management and organizations in launching more rational career progression streams for employees and facilitating organizational transformation.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trust and Dependability in Blockchain &amp; AI Based MedIoT Applications: Research Challenges and Future Directions</title>
<link>https://arxiv.org/abs/2501.02647</link>
<guid>https://arxiv.org/abs/2501.02647</guid>
<content:encoded><![CDATA[
<div> 关键词: AI, 区块链技术, 医疗物联网(MedIoT), 数据安全, 患者隐私

<br /><br />总结:
本文详细评述了人工智能(AI)与区块链技术在医疗物联网(MedIoT)应用中的融合，指出二者结合有望彻底改革医疗服务。文章强调了AI在提升诊断和患者护理方面的潜力，以及区块链在增强数据安全和保护患者隐私方面的作用。重点讨论了建立信任和确保系统可靠性的重要性。作者分析了当前针对健康数据管理和应对可扩展性、隐私保护以及MedIoT领域内伦理实践等挑战的创新解决方案，并提出将AI驱动的洞察力与区块链安全性相结合在医疗领域的未来愿景。同时，文中总结了现有研究的空白，并认为填补这些空白对于实现可靠、安全且以患者为中心的未来MedIoT应用至关重要。 <div>
arXiv:2501.02647v1 Announce Type: new 
Abstract: This paper critically reviews the integration of Artificial Intelligence (AI) and blockchain technologies in the context of Medical Internet of Things (MedIoT) applications, where they collectively promise to revolutionize healthcare delivery. By examining current research, we underscore AI's potential in advancing diagnostics and patient care, alongside blockchain's capacity to bolster data security and patient privacy. We focus particularly on the imperative to cultivate trust and ensure reliability within these systems. Our review highlights innovative solutions for managing healthcare data and challenges such as ensuring scalability, maintaining privacy, and promoting ethical practices within the MedIoT domain. We present a vision for integrating AI-driven insights with blockchain security in healthcare, offering a comprehensive review of current research and future directions. We conclude with a set of identified research gaps and propose that addressing these is crucial for achieving the dependable, secure, and patient -centric MedIoT applications of tomorrow.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Incentive-Compatible Federated Learning with Stackelberg Game Modeling</title>
<link>https://arxiv.org/abs/2501.02662</link>
<guid>https://arxiv.org/abs/2501.02662</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、heterogeneous environments（异构环境）、unfairness（不公平性）、Stackelberg game（Stackelberg博弈）、FLamma

<br /><br />总结:
本文提出了一种名为FLamma的新颖联邦学习框架，旨在解决在异构环境中联邦学习面临的挑战，特别是不公平性和非IID数据设置下的系统效率问题。FLamma基于自适应gamma-based Stackelberg游戏理论，其中服务器作为领导者动态调整衰减因子，而客户端则作为跟随者，优化其本地轮数以最大化自身效用。随着时间推移，服务器逐渐平衡客户端的影响，初期奖励贡献较大的客户端并逐步平息其影响，引导系统趋向Stackelberg均衡。通过在IID和非IID数据集上的大量模拟实验表明，FLamma方法显著提高了准确性分布的公平性，同时并未牺牲整体模型性能或收敛速度，优于传统联邦学习基线方法。 <div>
arXiv:2501.02662v1 Announce Type: new 
Abstract: Federated Learning (FL) has gained prominence as a decentralized machine learning paradigm, allowing clients to collaboratively train a global model while preserving data privacy. Despite its potential, FL faces significant challenges in heterogeneous environments, where varying client resources and capabilities can undermine overall system performance. Existing approaches primarily focus on maximizing global model accuracy, often at the expense of unfairness among clients and suboptimal system efficiency, particularly in non-IID (non-Independent and Identically Distributed) settings. In this paper, we introduce FLamma, a novel Federated Learning framework based on adaptive gamma-based Stackelberg game, designed to address the aforementioned limitations and promote fairness. Our approach allows the server to act as the leader, dynamically adjusting a decay factor while clients, acting as followers, optimally select their number of local epochs to maximize their utility. Over time, the server incrementally balances client influence, initially rewarding higher-contributing clients and gradually leveling their impact, driving the system toward a Stackelberg Equilibrium. Extensive simulations on both IID and non-IID datasets show that our method significantly improves fairness in accuracy distribution without compromising overall model performance or convergence speed, outperforming traditional FL baselines.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Markov Decision Processes for Satellite Maneuver Planning and Collision Avoidance</title>
<link>https://arxiv.org/abs/2501.02667</link>
<guid>https://arxiv.org/abs/2501.02667</guid>
<content:encoded><![CDATA[
<div> 关键词: 卫星编队、分散式在线规划、可扩展性、马尔科夫决策过程(MDP)、低地球轨道碰撞规避

总结:
本文提出了一种针对大型卫星编队的分散式、在线规划方法，旨在实现可扩展的机动规划。文章指出现有的基于规则的分散策略虽有利于效率提升，但关于卫星机动的最优决策算法仍有待深入研究。随着商业卫星星座规模扩大，利用实时轨迹预测改进状态认知以降低机动频率和节省燃料的在线机动规划变得愈发重要。为此，论文将卫星机动规划问题建模为马尔科夫决策过程(MDP)，使系统能在线生成具有较低计算成本的最优机动策略。该方法应用于解决低地球轨道中的非合作物体碰撞规避问题，通过在模拟低地球轨道环境中测试生成的策略并与传统的基于规则的碰撞规避技术进行比较，显示出其优势。 <div>
arXiv:2501.02667v1 Announce Type: new 
Abstract: This paper presents a decentralized, online planning approach for scalable maneuver planning for large constellations. While decentralized, rule-based strategies have facilitated efficient scaling, optimal decision-making algorithms for satellite maneuvers remain underexplored. As commercial satellite constellations grow, there are benefits of online maneuver planning, such as using real-time trajectory predictions to improve state knowledge, thereby reducing maneuver frequency and conserving fuel. We address this gap in the research by treating the satellite maneuver planning problem as a Markov decision process (MDP). This approach enables the generation of optimal maneuver policies online with low computational cost. This formulation is applied to the low Earth orbit collision avoidance problem, considering the problem of an active spacecraft deciding to maneuver to avoid a non-maneuverable object. We test the policies we generate in a simulated low Earth orbit environment, and compare the results to traditional rule-based collision avoidance techniques.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leader Rotation Is Not Enough: Scrutinizing Leadership Democracy of Chained BFT Consensus</title>
<link>https://arxiv.org/abs/2501.02970</link>
<guid>https://arxiv.org/abs/2501.02970</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、串联BFT协议、领导权民主、攻击分析、投票模式、领导者轮换、马克夫决策过程(MDP)、协议改进、未来方向

总结:<br />
本文针对区块链技术中串联BFT协议日益增长的关注度，深入研究了四种代表性串联BFT协议的领导权民主性，尤其是在受到攻击时的情况。文中提出了一种统一评估框架，包括两个评价指标：链质量与审查抵抗能力，并通过马克夫决策过程(MDP)对所选协议进行定量分析。该框架还揭示了投票模式和领导者轮换这两个关键组件对领导权民主的影响。研究发现，仅靠领导者轮换不足以保证领导权民主，攻击者可以利用设计（如投票模式）显著削弱领导权民主性。基于这些分析结果，文章为所评估的三个协议提出了针对性的改进措施，能够在不改变共识规则的前提下，以轻微的协议开销提升其领导权民主性。最后，文章讨论了构建更加民主的串联BFT协议的未来发展方向。 <div>
arXiv:2501.02970v1 Announce Type: new 
Abstract: With the growing popularity of blockchains, modern chained BFT protocols combining chaining and leader rotation to obtain better efficiency and leadership democracy have received increasing interest. Although the efficiency provisions of chained BFT protocols have been thoroughly analyzed, the leadership democracy has received little attention in prior work. In this paper, we scrutinize the leadership democracy of four representative chained BFT protocols, especially under attack. To this end, we propose a unified framework with two evaluation metrics, i.e., chain quality and censorship resilience, and quantitatively analyze chosen protocols through the Markov Decision Process (MDP). With this framework, we further examine the impact of two key components, i.e., voting pattern and leader rotation on leadership democracy. Our results indicate that leader rotation is not enough to provide the leadership democracy guarantee; an adversary could utilize the design, e.g., voting pattern, to deteriorate the leadership democracy significantly. Based on the analysis results, we propose customized countermeasures for three evaluated protocols to improve their leadership democracy with only slight protocol overhead and no change of consensus rules. We also discuss future directions toward building more democratic chained BFT protocols.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proof-of-Data: A Consensus Protocol for Collaborative Intelligence</title>
<link>https://arxiv.org/abs/2501.02971</link>
<guid>https://arxiv.org/abs/2501.02971</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式联邦学习、区块链、拜占庭容错、Proof-of-Data (PoD) 共识协议、奖励分配

总结:
<br />
本文提出了一种基于区块链的分布式拜占庭容错联邦学习框架，该框架利用一种新颖的Proof-of-Data (PoD) 共识协议解决“信任”和“激励”两大问题。PoD通过将模型训练与贡献度核算解耦，既实现了异步大规模PoW风格学习的效率和系统活力，又保证了基于epoch的BFT风格投票的共识最终性和奖励分配的确定性。针对拜占庭攻击下的数据伪造和虚假奖励申领问题，文中设计了一个隐私感知的数据验证和贡献为基础的奖励分配机制来完善框架。实验结果表明，PoD在保持接近集中式联邦学习模型训练性能的同时，实现了共识的信任性和奖励分配的公平性，其故障容忍比率为1/3。 <div>
arXiv:2501.02971v1 Announce Type: new 
Abstract: Existing research on federated learning has been focused on the setting where learning is coordinated by a centralized entity. Yet the greatest potential of future collaborative intelligence would be unleashed in a more open and democratized setting with no central entity in a dominant role, referred to as "decentralized federated learning". New challenges arise accordingly in achieving both correct model training and fair reward allocation with collective effort among all participating nodes, especially with the threat of the Byzantine node jeopardising both tasks.
  In this paper, we propose a blockchain-based decentralized Byzantine fault-tolerant federated learning framework based on a novel Proof-of-Data (PoD) consensus protocol to resolve both the "trust" and "incentive" components. By decoupling model training and contribution accounting, PoD is able to enjoy not only the benefit of learning efficiency and system liveliness from asynchronous societal-scale PoW-style learning but also the finality of consensus and reward allocation from epoch-based BFT-style voting. To mitigate false reward claims by data forgery from Byzantine attacks, a privacy-aware data verification and contribution-based reward allocation mechanism is designed to complete the framework. Our evaluation results show that PoD demonstrates performance in model training close to that of the centralized counterpart while achieving trust in consensus and fairness for reward allocation with a fault tolerance ratio of 1/3.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2501.03119</link>
<guid>https://arxiv.org/abs/2501.03119</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Decentralized FL, Topology Inference Attack, Privacy Preservation, Model Behavior

总结:
<br />
该研究关注Federated Learning（FL）中的Decentralized FL（DFL），其模型共享机制虽能保护隐私，但模型训练仍可能泄露敏感信息。研究提出了一个新颖的Topology Inference Attack，探讨仅依据模型行为来推断DFL系统overlay拓扑结构的可能性。文章制定了基于攻击者能力和知识的拓扑推理攻击分类，并针对不同场景开发了实际攻击策略。通过定量实验，结果表明仅分析单个节点的公共模型就能准确推断DFL的拓扑结构，揭示了DFL系统中存在敏感信息泄漏的风险。这一发现对于改进去中心化学习环境中的隐私保护具有重要意义。 <div>
arXiv:2501.03119v1 Announce Type: new 
Abstract: Federated Learning (FL) is widely recognized as a privacy-preserving machine learning paradigm due to its model-sharing mechanism that avoids direct data exchange. However, model training inevitably leaves exploitable traces that can be used to infer sensitive information. In Decentralized FL (DFL), the overlay topology significantly influences its models' convergence, robustness, and security. This study explores the feasibility of inferring the overlay topology of DFL systems based solely on model behavior, introducing a novel Topology Inference Attack. A taxonomy of topology inference attacks is proposed, categorizing them by the attacker's capabilities and knowledge. Practical attack strategies are developed for different scenarios, and quantitative experiments are conducted to identify key factors influencing the attack effectiveness. Experimental results demonstrate that analyzing only the public models of individual nodes can accurately infer the DFL topology, underscoring the risk of sensitive information leakage in DFL systems. This finding offers valuable insights for improving privacy preservation in decentralized learning environments.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CrowdProve: Community Proving for ZK Rollups</title>
<link>https://arxiv.org/abs/2501.03126</link>
<guid>https://arxiv.org/abs/2501.03126</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-Knowledge (ZK) rollups、CrowdProve、proving、commodity hardware、decentralization

总结:
本文提出了一种名为CrowdProve的新方案，用于解决零知识证明（ZK rollups）系统中的计算负担问题。CrowdProve是一个证明者协调层，可将计算任务外包给由广泛社区内的小型证明者运行的不可靠商品硬件。该方案应用于一种流行的ZK rollup，实验结果显示，社区证明可以实现与现有中心化部署相当甚至更好的性能。即使使用适度的硬件配置，也能匹配中心化解决方案的性能，使得基于社区的证明生成成为一种可行且成本效益高的替代方案。通过CrowdProve，Rollup运营商能够借助社区闲置硬件降低基础设施成本，而社区证明者则因其贡献获得补偿，从而实现了双方共赢并增强了系统的去中心化特性。 <div>
arXiv:2501.03126v1 Announce Type: new 
Abstract: Zero-Knowledge (ZK) rollups have become a popular solution for scaling blockchain systems, offering improved transaction throughput and reduced costs by aggregating Layer 2 transactions and submitting them as a single batch to a Layer 1 blockchain. However, the computational burden of generating validity proofs, a key feature of ZK rollups, presents significant challenges in terms of performance and decentralization. Current solutions rely on centralized infrastructure to handle the computational tasks, limiting the scalability and decentralization of rollup systems.
  This paper proposes CrowdProve, a prover orchestration layer for outsourcing computation to unreliable commodity hardware run by a broad community of small provers. We apply CrowdProve to proving transaction batches for a popular ZK rollup.
  Through our experimental evaluation, we demonstrate that community proving can achieve performance comparable to, and in some cases better than, existing centralized deployments. Our results show that even systems utilizing modest hardware configurations can match the performance of centralized solutions, making community-based proof generation a viable and cost-effective alternative. CrowdProve allows both the rollup operator and community participants to benefit: the operator reduces infrastructure costs by leveraging idle community hardware, while community provers are compensated for their contributions.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Foundations of Platform-Assisted Auctions</title>
<link>https://arxiv.org/abs/2501.03141</link>
<guid>https://arxiv.org/abs/2501.03141</guid>
<content:encoded><![CDATA[
<div> 关键词：平台辅助拍卖、加密货币、梦之拍卖、战略行为、效率优化

总结:<br />
本文提出了一个新的模型来研究无许可环境下的平台辅助拍卖。该模型关注在平台可能操纵拍卖以增加利润的情况下，设计一种能够让买家、平台、卖家以及平台与卖家或买家联盟均能通过诚实行为实现利益最大化的理想拍卖机制。文章通过一系列可行性与不可行性结果刻画了平台辅助拍卖的数学特性，并展示了如何利用密码学原理设计具有高效和理想属性的平台辅助拍卖协议。相较于已有的使用多方计算（MPC）或区块链技术去除对可信拍卖者依赖的工作，本文的研究有其独特之处：首先，系统性探讨了服务提供者存在策略行为并可能与买卖方合谋的游戏理论影响；其次，指出全模拟范式过于严格导致高渐近成本问题，为此，文章提出了一种新的模拟概念——效用主导仿真，并在此基础上展示如何设计具有接近线性效率的高效拍卖协议。 <div>
arXiv:2501.03141v1 Announce Type: new 
Abstract: Today, many auctions are carried out with the help of intermediary platforms like Google and eBay. We refer to such auctions as platform-assisted auctions.Traditionally, the auction theory literature mainly focuses on designing auctions that incentivize the buyers to bid truthfully,assuming that the platform always faithfully implements the auction. In practice, however, the platforms have been found to manipulate the auctions to earn more profit, resulting in high-profile anti-trust lawsuits. We propose a new model for studying platform-assisted auctions in the permissionless setting. We explore whether it is possible to design a dream auction in thisnew model, such that honest behavior is the utility-maximizing strategy for each individual buyer, the platform, the seller, as well as platform-seller or platform-buyer coalitions.Through a collection of feasibility and infeasibility results,we carefully characterize the mathematical landscape of platform-assisted auctions. We show how cryptography can lend to the design of an efficient platform-assisted auction with dream properties. Although a line of works have also used MPC or the blockchain to remove the reliance on a trusted auctioneer, our work is distinct in nature in several dimensions.First, we initiate a systematic exploration of the game theoretic implications when the service providers are strategic and can collude with sellers or buyers. Second, we observe that the full simulation paradigm is too stringent and leads to high asymptotical costs. Specifically, because every player has a different private outcomein an auction protocol, running any generic MPC protocol among the players would incur at least $n^2$ total cost. We propose a new notion of simulation calledutility-dominated emulation.Under this new notion, we showhow to design efficient auction protocols with quasilinear efficiency.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep-Relative-Trust-Based Diffusion for Decentralized Deep Learning</title>
<link>https://arxiv.org/abs/2501.03162</link>
<guid>https://arxiv.org/abs/2501.03162</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式学习、参数空间一致性、深度神经网络、相对信任(DRT)、DRT扩散算法<br /><br />总结:

本文介绍了arXiv:2501.03162v1的新研究，提出了一种新的分布式学习策略——DRT扩散算法。该算法针对深度神经网络（通常过度参数化）的特点，主张在输出层面而非参数层面上鼓励共识，以此替代当前依赖参数平均化的分布式学习方法。文章基于一种名为深度相对信任(DRT)的新型相似度衡量标准来构建这一算法，并对其收敛性进行了分析。实验结果表明，DRT扩散算法在图像分类任务中能有效提升泛化性能，特别是在稀疏拓扑结构下表现优异。 <div>
arXiv:2501.03162v1 Announce Type: new 
Abstract: Decentralized learning strategies allow a collection of agents to learn efficiently from local data sets without the need for central aggregation or orchestration. Current decentralized learning paradigms typically rely on an averaging mechanism to encourage agreement in the parameter space. We argue that in the context of deep neural networks, which are often over-parameterized, encouraging consensus of the neural network outputs, as opposed to their parameters can be more appropriate. This motivates the development of a new decentralized learning algorithm, termed DRT diffusion, based on deep relative trust (DRT), a recently introduced similarity measure for neural networks. We provide convergence analysis for the proposed strategy, and numerically establish its benefit to generalization, especially with sparse topologies, in an image classification task.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rate-My-LoRA: Efficient and Adaptive Federated Model Tuning for Cardiac MRI Segmentation</title>
<link>https://arxiv.org/abs/2501.03223</link>
<guid>https://arxiv.org/abs/2501.03223</guid>
<content:encoded><![CDATA[
<div> 关键词: 心血管疾病, 心脏同步失调, 分布式学习, 低秩适应, 模型聚合

总结:
本文针对心血管疾病和心脏同步失调问题，提出了一个新的高效自适应联邦学习方法用于心脏图像分割。该方法旨在解决数据隐私、带宽限制和数据异质性带来的挑战。文章提出利用低秩适应（LoRA）来正则化模型权重更新，从而降低通信开销。同时，文中还创新性地设计了一种名为\mymethod{}的模型聚合技术，通过比较每个客户端的验证准确率来自适应地惩罚不同客户端的聚合权重，以实现更好的泛化性能和快速的局部适应。在公共心脏MRI数据集上的内外部评估结果显示，相较于其他基于LoRA的联邦学习方法，本文的方法具有显著优势。 <div>
arXiv:2501.03223v1 Announce Type: new 
Abstract: Cardiovascular disease (CVD) and cardiac dyssynchrony are major public health problems in the United States. Precise cardiac image segmentation is crucial for extracting quantitative measures that help categorize cardiac dyssynchrony. However, achieving high accuracy often depends on centralizing large datasets from different hospitals, which can be challenging due to privacy concerns. To solve this problem, Federated Learning (FL) is proposed to enable decentralized model training on such data without exchanging sensitive information. However, bandwidth limitations and data heterogeneity remain as significant challenges in conventional FL algorithms. In this paper, we propose a novel efficient and adaptive federate learning method for cardiac segmentation that improves model performance while reducing the bandwidth requirement. Our method leverages the low-rank adaptation (LoRA) to regularize model weight update and reduce communication overhead. We also propose a \mymethod{} aggregation technique to address data heterogeneity among clients. This technique adaptively penalizes the aggregated weights from different clients by comparing the validation accuracy in each client, allowing better generalization performance and fast local adaptation. In-client and cross-client evaluations on public cardiac MR datasets demonstrate the superiority of our method over other LoRA-based federate learning approaches.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>When Should Selfish Miners Double-Spend?</title>
<link>https://arxiv.org/abs/2501.03227</link>
<guid>https://arxiv.org/abs/2501.03227</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、双花攻击、自私挖矿、顽固挖矿、最优策略

总结:
本文研究了一种结合顽固挖矿和自私挖矿的新型攻击策略，分析了攻击者在不同参数条件下的最优顽固程度。文章指出，当攻击者的顽固程度高于某个确认规则值（如比特币中的6确认规则）时，会出现无成本的双花风险。文中还建立了每轮攻击中，给定顽固程度下双花风险的概率模型，并探讨了在诚实挖矿收益更低的情况下，实施这种攻击所需的最小双花价值。此外，为了提高双花概率并隐藏攻击行为，文章对顽固阶段的攻击进行了改进。最后，针对比特币系统，通过计算不同矿池参数下的最优和最大顽固程度及攻击收益，评估了该攻击策略对于6确认规则的实际影响与双花风险。 <div>
arXiv:2501.03227v1 Announce Type: new 
Abstract: Although, both double-spending and selfish-mining attacks have been extensively studied since the ``Bitcoin'' whitepaper of Nakamoto and the ``majority is not enough'' paper of Eyal and Sirer, there has been no rigorous stochastic analysis of an attack that combines the two, except for the complicated MDP models. In this paper, we first combine stubborn and selfish mining attacks, i.e., construct a strategy where the attacker acts stubborn until its private branch reaches a certain length and then switches to act selfish. We provide the optimal stubbornness for each parameter regime. Next, we provide the maximum stubbornness that is still more profitable than honest mining and argue a connection between the level of stubbornness and the $k$-confirmation rule. We show that, at each attack cycle, if the level of stubbornness is higher than $k$, there is a risk of double-spending which comes at no-cost to the adversary. The result can be seen as a guide for picking $k$ in the $k$-confirmation rule in a blockchain design. At each cycle, for a given stubbornness level, we rigorously formulate how great the risk of double-spending is. We provide the minimum double-spend value needed for an attack to be profitable in the regimes where the scheme is less profitable than honest mining. We further modify the attack in the stubborn regime in order to conceal the attack and increase the double-spending probability. Finally, we evaluate the results and provide the optimal and the maximum stubbornness levels for each parameter regime as well as the revenue. As a case study, with Bitcoin's $k=6$ block confirmation rule, we evaluate the revenue and double-spending risk of the attacks for each pool parameter.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Red Belly Blockchain: Enhanced Transaction Management for Decentralized Applications</title>
<link>https://arxiv.org/abs/2207.05971</link>
<guid>https://arxiv.org/abs/2207.05971</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Applications (DApps), Web3.0, Ethereum, High-performance blockchains, Transaction management

总结:
本文探讨了去中心化应用（DApps）在推动Web3.0发展中所起的作用，以及以太坊等支持DApp的区块链在性能上的局限性。针对此问题，文章提出了一种新颖的交易验证减少方法和基于子区块处理的优化块存储方案，以改进交易管理。实验表明，该研究团队开发的搭载了这些优化措施的智能红腹区块链（Smart Red Belly Blockchain, SRBB）虚拟机在性能上有所提升。接着，他们将SRBB VM与已有的高性能共识机制相结合，构建出了Smart Red Belly Blockchain。结果显示，SRBB在由分布于五大洲的200个节点组成的网络中达到了峰值4000TPS和平均2000TPS的吞吐量，并在运行基于纳斯达克真实工作负载轨迹的交易所DApp场景下，超越了其他6条区块链的表现。 <div>
arXiv:2207.05971v2 Announce Type: replace 
Abstract: Decentralized Applications (DApps) have seen widespread use in the recent past driving the world towards a new decentralized version of the web known as Web3.0. DApp-supported blockchains like Ethereum have largely been responsible for this drive supporting the largest eco-system of DApps. Although the low performance provided by Ethereum has been a major impediment to realizing a decentralized web, several high-performance blockchains have been introduced recently to bridge this gap. Most of these blockchains rely on consensus optimizations. Only a few enhance other parts of the blockchain protocol that involves transaction management: the validation of transactions, broadcast of transactions, encapsulation and dissemination of blocks with transactions, re-validation and execution of transactions in blocks, storage of blocks, and confirmation of transaction commits to senders upon request.
  In this paper, we enhance transaction management by introducing a novel transaction validation reduction and a per sub-block processing to optimize the block storage. We empirically show the performance improvements gained by our enhanced transaction management in the Smart Red Belly Blockchain (SRBB) VM we develop. Finally, we integrate our SRBB VM to an already optimized consensus from a known blockchain to develop the Smart Red Belly Blockchain. Our results show that SRBB achieves a peak throughput of 4000 TPS and an average throughput of 2000 TPS on 200 nodes spread across 5 continents. SRBB outperforms 6 other blockchains when running the exchange DApp featuring a real workload trace taken from Nasdaq.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Targeted Nakamoto: A Bitcoin Protocol to Balance Network Security and Energy Consumption</title>
<link>https://arxiv.org/abs/2405.15089</link>
<guid>https://arxiv.org/abs/2405.15089</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof-of-Work、比特币、挖矿算力、总成本、Targeted Nakamoto

总结:
<br />
本文探讨了Proof-of-Work机制下如比特币区块链中挖矿算力与区块奖励之间的关系。随着挖矿算力上升，网络安全成本降低但碳排放和电力消耗等外部性成本增加，存在一个挖矿算率区间使得总成本最小化。为了应对这一问题，文章提出了Targeted Nakamoto协议增强方案，该方案激励矿工将算力控制在一个目标区间。当算力超过目标值时，对矿工的区块奖励设置上限；而当算力低于目标值时，则设置奖励下限。为了维持货币中立性，协议会相应调整持有UTXO地址的支出潜力，以匹配奖励上限时的总额度扣除，以及奖励下限时的总额度增加。 <div>
arXiv:2405.15089v2 Announce Type: replace 
Abstract: In a Proof-of-Work blockchain such as Bitcoin mining hashrate is increasing in the block reward. An increase in hashrate reduces network vulnerability to attack (a reduction in security cost) while increasing carbon emissions and electricity cost (an increase in externalities cost). This implies a tradeoff in total cost at different levels of hashrate and the existence of a hashrate interval where total cost is minimized. Targeted Nakamoto is a Proof-of-Work protocol augmentation that incentivizes miners to hone in on a target hashrate interval. When hashrate is above target a ceiling is placed on the block reward a miner can receive. When hashrate is below target a floor is placed underneath the miner's block reward. Monetary neutrality is maintained by a proportional increase in spending potential among addresses holding UTXO's to match a deduction from total block reward when the ceiling is operative and a proportional reduction in spending potential among addresses holding UTXO's to match an increase over the total block reward when the floor is binding.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks</title>
<link>https://arxiv.org/abs/2401.08610</link>
<guid>https://arxiv.org/abs/2401.08610</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof of Stake (PoS)，Lido，stETH，Leverage Staking，风险分析

总结:
本文介绍了以太坊权益证明（PoS）生态系统中，用户通过Lido质押ETH获取代表质押ETH并累积staking奖励的Liquid Staking Derivative（LSD）——stETH。这种衍生品提升了质押资产的流动性，使得它们能够在二级市场如Aave的抵押借款或Curve上的资产交换等场景中使用。文章建立了一个关于利用stETH进行杠杆质押的正式框架，并发现了在过去963天内在以太坊上存在的442个此类头寸，涉及总价值537,123 ETH（约8.77亿美元）。数据分析表明，81.7%的杠杆质押头寸获得了超过常规在Lido质押的年化收益率（APR）。然而，高回报也伴随着潜在风险，如Terra崩盘事件所示，代币贬值可能对市场产生影响。因此，文章进行了极端情况下stETH大幅贬值的压力测试，评估了相关的风险。模拟结果显示，杠杆质押会放大连锁清算的风险，通过清算和去杠杆化过程加剧卖压，不仅加速stETH价格下跌，还会引发传染效应，威胁到杠杆头寸及普通头寸的稳定性。 <div>
arXiv:2401.08610v4 Announce Type: replace-cross 
Abstract: In the Proof of Stake (PoS) Ethereum ecosystem, users can stake ETH on Lido to receive stETH, a Liquid Staking Derivative (LSD) that represents staked ETH and accrues staking rewards. LSDs improve the liquidity of staked assets by facilitating their use in secondary markets, such as for collateralized borrowing on Aave or asset exchanges on Curve. The composability of Lido, Aave, and Curve enables an emerging strategy known as leverage staking, an iterative process that enhances financial returns while introducing potential risks. This paper establishes a formal framework for leverage staking with stETH and identifies 442 such positions on Ethereum over 963 days. These positions represent a total volume of 537,123 ETH (877m USD). Our data reveal that 81.7% of leverage staking positions achieved an Annual Percentage Rate (APR) higher than conventional staking on Lido. Despite the high returns, we also recognize the potential risks. For example, the Terra crash incident demonstrated that token devaluation can impact the market. Therefore, we conduct stress tests under extreme conditions of significant stETH devaluation to evaluate the associated risks. Our simulations reveal that leverage staking amplifies the risk of cascading liquidations by triggering intensified selling pressure through liquidation and deleveraging processes. Furthermore, this dynamic not only accelerates the decline of stETH prices but also propagates a contagion effect, endangering the stability of both leveraged and ordinary positions.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Uncertainty-Aware Label Refinement on Hypergraphs for Personalized Federated Facial Expression Recognition</title>
<link>https://arxiv.org/abs/2501.01816</link>
<guid>https://arxiv.org/abs/2501.01816</guid>
<content:encoded><![CDATA[
<div> 关键词：面部表情识别、个性化联邦学习、不确定性估计、标签细化、超图模型

总结:
本文研究了在考虑隐私保护的个性化联邦学习框架下的面部表情识别（FER）问题。为解决这一问题，文章提出了一种新颖的不确定性感知标签细化的超图方法——AMY。该方法中，每个本地模型由一个主干网络、一个不确定性估计（UE）模块和一个表情分类（EC）模块组成。在UE模块，利用超图来建模表达式样本间的复杂高阶关系，并将这些关系融入到不确定性特征中。接着，设计了一个个性化不确定性估算器，用于对本地客户端中的样本进行可靠的不确定性权重估计。在EC模块，通过超图上的标签传播获取高质量细化标签，进而重新训练表情分类器。由此，AMY有效地缓解了不同客户端间异质性样本的不确定性，并在每个客户端中学习到了鲁棒的个性化FER模型。实验结果表明，AMY在两个具有挑战性的实际面部表情数据库上表现优于多个现有最优方法，证实了超图模型在不确定性估计和标签细化方面的优势。相关源代码将在https://github.com/mobei1006/AMY 发布。 <div>
arXiv:2501.01816v1 Announce Type: new 
Abstract: Most facial expression recognition (FER) models are trained on large-scale expression data with centralized learning. Unfortunately, collecting a large amount of centralized expression data is difficult in practice due to privacy concerns of facial images. In this paper, we investigate FER under the framework of personalized federated learning, which is a valuable and practical decentralized setting for real-world applications. To this end, we develop a novel uncertainty-Aware label refineMent on hYpergraphs (AMY) method. For local training, each local model consists of a backbone, an uncertainty estimation (UE) block, and an expression classification (EC) block. In the UE block, we leverage a hypergraph to model complex high-order relationships between expression samples and incorporate these relationships into uncertainty features. A personalized uncertainty estimator is then introduced to estimate reliable uncertainty weights of samples in the local client. In the EC block, we perform label propagation on the hypergraph, obtaining high-quality refined labels for retraining an expression classifier. Based on the above, we effectively alleviate heterogeneous sample uncertainty across clients and learn a robust personalized FER model in each client. Experimental results on two challenging real-world facial expression databases show that our proposed method consistently outperforms several state-of-the-art methods. This indicates the superiority of hypergraph modeling for uncertainty estimation and label refinement on the personalized federated FER task. The source code will be released at https://github.com/mobei1006/AMY.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mingling with the Good to Backdoor Federated Learning</title>
<link>https://arxiv.org/abs/2501.01913</link>
<guid>https://arxiv.org/abs/2501.01913</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、防御机制、攻击方法、MIGO、后门植入

<br /><br />总结:
本文探讨了一种针对联邦学习的新型攻击策略——MIGO，该策略旨在设计一种通用的后门植入方法，能够在多种防御机制下仍能悄无声息地将后门融入全局模型。MIGO通过使恶意模型更新与合法更新难以区分，实现对全球模型的逐步后门注入，并保证其持久性。实验结果显示，MIGO在五个不同数据集和模型架构上成功植入了三种类型的后门，同时保持了主任务的高准确率（超过90%）。此外，MIGO展现了强大的防御规避能力，对抗了包括多个最先进的防御方法在内的十种防御手段。与其他四种攻击策略相比，MIGO在大多数配置中表现出色，即使在极端情况下，仅控制了0.1%的客户端，只要攻击者能在足够多的轮次中持续攻击，也能实现成功的后门插入。 <div>
arXiv:2501.01913v1 Announce Type: new 
Abstract: Federated learning (FL) is a decentralized machine learning technique that allows multiple entities to jointly train a model while preserving dataset privacy. However, its distributed nature has raised various security concerns, which have been addressed by increasingly sophisticated defenses. These protections utilize a range of data sources and metrics to, for example, filter out malicious model updates, ensuring that the impact of attacks is minimized or eliminated.
  This paper explores the feasibility of designing a generic attack method capable of installing backdoors in FL while evading a diverse array of defenses. Specifically, we focus on an attacker strategy called MIGO, which aims to produce model updates that subtly blend with legitimate ones. The resulting effect is a gradual integration of a backdoor into the global model, often ensuring its persistence long after the attack concludes, while generating enough ambiguity to hinder the effectiveness of defenses.
  MIGO was employed to implant three types of backdoors across five datasets and different model architectures. The results demonstrate the significant threat posed by these backdoors, as MIGO consistently achieved exceptionally high backdoor accuracy (exceeding 90%) while maintaining the utility of the main task. Moreover, MIGO exhibited strong evasion capabilities against ten defenses, including several state-of-the-art methods. When compared to four other attack strategies, MIGO consistently outperformed them across most configurations. Notably, even in extreme scenarios where the attacker controls just 0.1% of the clients, the results indicate that successful backdoor insertion is possible if the attacker can persist for a sufficient number of rounds.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedMIA: An Effective Membership Inference Attack Exploiting "All for One" Principle in Federated Learning</title>
<link>https://arxiv.org/abs/2402.06289</link>
<guid>https://arxiv.org/abs/2402.06289</guid>
<content:encoded><![CDATA[
<div> 关键词: 异地学习 (Federated Learning), 隐私风险, 会员推断攻击 (Membership Inference Attacks, MIA), FedMIA, 更新信息

总结:
本文关注异地学习(Federated Learning)中的隐私风险问题，特别是会员推断攻击(Membership Inference Attacks, MIA)。现有的MIA方法主要分析目标客户端的更新信息，而该文提出了一种基于非目标客户端更新信息的一尾似然比假设检验，进而开发了一种新的MIA方法——FedMIA。FedMIA采取“全员为一”的策略，利用多轮通信中所有客户端的更新信息提升攻击效果。实验表明，FedMIA在分类和生成任务上均优于现有MIA方法，并能适应不同的防御策略、Non-IID数据以及联邦结构。相关代码已在https://github.com/Liar-Mask/FedMIA开源。<br /><br /> <div>
arXiv:2402.06289v2 Announce Type: replace 
Abstract: Federated Learning (FL) is a promising approach for training machine learning models on decentralized data while preserving privacy. However, privacy risks, particularly Membership Inference Attacks (MIAs), which aim to determine whether a specific data point belongs to a target client's training set, remain a significant concern. Existing methods for implementing MIAs in FL primarily analyze updates from the target client, focusing on metrics such as loss, gradient norm, and gradient difference. However, these methods fail to leverage updates from non-target clients, potentially underutilizing available information. In this paper, we first formulate a one-tailed likelihood-ratio hypothesis test based on the likelihood of updates from non-target clients. Building upon this formulation, we introduce a three-step Membership Inference Attack (MIA) method, called FedMIA, which follows the "all for one"--leveraging updates from all clients across multiple communication rounds to enhance MIA effectiveness. Both theoretical analysis and extensive experimental results demonstrate that FedMIA outperforms existing MIAs in both classification and generative tasks. Additionally, it can be integrated as an extension to existing methods and is robust against various defense strategies, Non-IID data, and different federated structures. Our code is available in https://github.com/Liar-Mask/FedMIA.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Graph Communication for Decentralised Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.00165</link>
<guid>https://arxiv.org/abs/2501.00165</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、动态网络环境、通信框架、强化学习、图注意力网络

总结:<br />
本文提出了一种用于动态网络环境中分散式多智能体系统的新型通信框架，该框架被集成到多智能体强化学习系统中，旨在通过优化网络集体知识的高效通信来提升决策效果。主要贡献包括将静态网络包路由场景适应于具有节点故障的动态环境，将图注意力网络层引入递归消息传递框架，并引入了多轮通信目标机制。这种方法使得在稀疏奖励、动态网络包路由环境下仅使用强化学习就能成功训练基于注意力的聚合机制。实验结果显示，与基线系统相比，该方法在路由性能上有所提高，平均奖励增加了9.5%，通信开销减少了6.4%。此外，文章还探讨了在关键基础设施和军事背景下部署此类系统可能带来的伦理和法律影响，指出了现有局限性，并提出了未来研究的方向。 <div>
arXiv:2501.00165v1 Announce Type: new 
Abstract: This work presents a novel communication framework for decentralized multi-agent systems operating in dynamic network environments. Integrated into a multi-agent reinforcement learning system, the framework is designed to enhance decision-making by optimizing the network's collective knowledge through efficient communication. Key contributions include adapting a static network packet-routing scenario to a dynamic setting with node failures, incorporating a graph attention network layer in a recurrent message-passing framework, and introducing a multi-round communication targeting mechanism. This approach enables an attention-based aggregation mechanism to be successfully trained within a sparse-reward, dynamic network packet-routing environment using only reinforcement learning. Experimental results show improvements in routing performance, including a 9.5 percent increase in average rewards and a 6.4 percent reduction in communication overhead compared to a baseline system. The study also examines the ethical and legal implications of deploying such systems in critical infrastructure and military contexts, identifies current limitations, and suggests potential directions for future research.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generative Emergent Communication: Large Language Model is a Collective World Model</title>
<link>https://arxiv.org/abs/2501.00226</link>
<guid>https://arxiv.org/abs/2501.00226</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式涌现通信 (Generative Emergent Communication, 简称EmCom)，集体预测编码 (Collective Predictive Coding, CPC)，大型语言模型 (Large Language Models, LLMs)，多智能体强化学习 (Multi-Agent Reinforcement Learning, MARL)，认知发展

<br /><br />总结:

本文提出了一种名为“生成式涌现通信”(Generative EmCom)的统一理论框架，该框架通过集体预测编码(CPC)的角度将涌现通信、世界模型和大型语言模型(LLMs)联系起来。文章的主要贡献包括：一是构建了EmCom作为理解涌现通信的新框架，展示了如何从控制即推理的角度推导出多智能体强化学习(MARL)中的通信涌现，并明确了其与传统判别性方法的关系；二是提出了将LLMs解释为通过CPC整合多个智能体经验的集体世界模型的数学表述。这一框架为理解共享符号系统如何通过集体预测编码过程而涌现提供了统一的理论基础，同时有助于阐明语言演化的根本方面，并为理解和开发改善人类-AI交互及多智能体系统的高级AI技术提供了实际见解。 <div>
arXiv:2501.00226v1 Announce Type: new 
Abstract: This study proposes a unifying theoretical framework called generative emergent communication (generative EmCom) that bridges emergent communication, world models, and large language models (LLMs) through the lens of collective predictive coding (CPC). The proposed framework formalizes the emergence of language and symbol systems through decentralized Bayesian inference across multiple agents, extending beyond conventional discriminative model-based approaches to emergent communication. This study makes the following two key contributions: First, we propose generative EmCom as a novel framework for understanding emergent communication, demonstrating how communication emergence in multi-agent reinforcement learning (MARL) can be derived from control as inference while clarifying its relationship to conventional discriminative approaches. Second, we propose a mathematical formulation showing the interpretation of LLMs as collective world models that integrate multiple agents' experiences through CPC. The framework provides a unified theoretical foundation for understanding how shared symbol systems emerge through collective predictive coding processes, bridging individual cognitive development and societal language evolution. Through mathematical formulations and discussion on prior works, we demonstrate how this framework explains fundamental aspects of language emergence and offers practical insights for understanding LLMs and developing sophisticated AI systems for improving human-AI interaction and multi-agent systems.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Approaches to Enhancing Smart Vehicle Cybersecurity by AI-Driven Threat Detection</title>
<link>https://arxiv.org/abs/2501.00261</link>
<guid>https://arxiv.org/abs/2501.00261</guid>
<content:encoded><![CDATA[
<div> 关键词：智能车辆、人工智能、网络安全、入侵检测系统、自动驾驶

总结:
<br />
随着汽车行业越来越多地采用连接和自动化车辆（CAVs），对于强大的网络安全措施的需求变得至关重要。本文探讨了利用人工智能驱动的威胁检测来加强智能车辆网络安全的合作方法。文章指出，面对新兴的安全漏洞和需求，5G网络、区块链和量子计算等先进技术的整合为提升CAV网络安全提供了有前景的方法。此外，自动驾驶汽车的网络安全路线图强调了高效入侵检测系统和基于AI的技术的重要性，以及需要集成安全硬件、软件栈和先进的威胁情报，以解决未来自动驾驶汽车面临的网络安全挑战。 <div>
arXiv:2501.00261v1 Announce Type: new 
Abstract: The introduction sets the stage for exploring collaborative approaches to bolstering smart vehicle cybersecurity through AI-driven threat detection. As the automotive industry increasingly adopts connected and automated vehicles (CAVs), the need for robust cybersecurity measures becomes paramount. With the emergence of new vulnerabilities and security requirements, the integration of advanced technologies such as 5G networks, blockchain, and quantum computing presents promising avenues for enhancing CAV cybersecurity . Additionally, the roadmap for cybersecurity in autonomous vehicles emphasizes the importance of efficient intrusion detection systems and AI-based techniques, along with the integration of secure hardware, software stacks, and advanced threat intelligence to address cybersecurity challenges in future autonomous vehicles.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UPC Sentinel: An Accurate Approach for Detecting Upgradeability Proxy Contracts in Ethereum</title>
<link>https://arxiv.org/abs/2501.00674</link>
<guid>https://arxiv.org/abs/2501.00674</guid>
<content:encoded><![CDATA[
<div> 关键词: DApp、智能合约、升级性代理合约(UPC)、静态分析、动态分析

<br /><br />总结:
本文介绍了针对以太坊区块链平台上运行的DApp维护问题，特别是关注于智能合约的升级性代理合约（UPC）的研究。由于Ethereum缺乏原生的后部署智能合约维护解决方案，开发人员通常利用UPC方法实现应用升级。为此，论文提出了名为UPC Sentinel的三层算法，该算法结合了智能合约字节码的静态和动态分析，用于准确检测活跃的UPC。通过两个独立的数据集评估，UPC Sentinel展现出了卓越的性能，第一个数据集中的准确率接近完美，达到99%，而第二个数据集则进一步证实其高效性，实现了100%的精确度和近乎完美的99.3%召回率，优于现有最优方法。最后，文章讨论了UPC Sentinel在未来研究工作中的潜在价值。 <div>
arXiv:2501.00674v1 Announce Type: new 
Abstract: Software applications that run on a blockchain platform are known as DApps. DApps are built using smart contracts, which are immutable after deployment. Just like any real-world software system, DApps need to receive new features and bug fixes over time in order to remain useful and secure. However, Ethereum lacks native solutions for post-deployment smart contract maintenance, requiring developers to devise their own methods. A popular method is known as the upgradeability proxy contract (UPC), which involves implementing the proxy design pattern (as defined by the Gang of Four). In this method, client calls first hit a proxy contract, which then delegates calls to a certain implementation contract. Most importantly, the proxy contract can be reconfigured during runtime to delegate calls to another implementation contract, effectively enabling application upgrades. For researchers, the accurate detection of UPCs is a strong requirement in the understanding of how exactly real-world DApps are maintained over time. For practitioners, the accurate detection of UPCs is crucial for providing application behavior transparency and enabling auditing. In this paper, we introduce UPC Sentinel, a novel three-layer algorithm that utilizes both static and dynamic analysis of smart contract bytecode to accurately detect active UPCs. We evaluated UPC Sentinel using two distinct ground truth datasets. In the first dataset, our method demonstrated a near-perfect accuracy of 99%. The evaluation on the second dataset further established our method's efficacy, showing a perfect precision rate of 100% and a near-perfect recall of 99.3%, outperforming the state of the art. Finally, we discuss the potential value of UPC Sentinel in advancing future research efforts.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Secure Semantic Communications</title>
<link>https://arxiv.org/abs/2501.00842</link>
<guid>https://arxiv.org/abs/2501.00842</guid>
<content:encoded><![CDATA[
<div> 关键词：语义通信(SemCom)，6G，安全性，隐私保护，技术对策

<br /><br />总结:
本文详细阐述了语义通信（SemCom）这一被视为6G革命性技术的概念及其优势，如降低传输负担、提升网络管理效率和优化资源配置。文章分析了SemCom从模型训练、模型转移至语义信息传输等整个生命周期中可能出现的安全与隐私问题。针对这些问题，文中总结了一系列可用于保障SemCom安全的技术措施，包括数据清洗、鲁棒学习、抵御后门攻击的防御策略、对抗性训练、差分隐私、密码学、区块链技术、模型压缩以及物理层安全。最后，文章指出了未来的研究方向，为相关领域的研究人员提供了指导。 <div>
arXiv:2501.00842v1 Announce Type: new 
Abstract: Semantic communication (SemCom) is regarded as a promising and revolutionary technology in 6G, aiming to transcend the constraints of ``Shannon's trap" by filtering out redundant information and extracting the core of effective data. Compared to traditional communication paradigms, SemCom offers several notable advantages, such as reducing the burden on data transmission, enhancing network management efficiency, and optimizing resource allocation. Numerous researchers have extensively explored SemCom from various perspectives, including network architecture, theoretical analysis, potential technologies, and future applications. However, as SemCom continues to evolve, a multitude of security and privacy concerns have arisen, posing threats to the confidentiality, integrity, and availability of SemCom systems. This paper presents a comprehensive survey of the technologies that can be utilized to secure SemCom. Firstly, we elaborate on the entire life cycle of SemCom, which includes the model training, model transfer, and semantic information transmission phases. Then, we identify the security and privacy issues that emerge during these three stages. Furthermore, we summarize the techniques available to mitigate these security and privacy threats, including data cleaning, robust learning, defensive strategies against backdoor attacks, adversarial training, differential privacy, cryptography, blockchain technology, model compression, and physical-layer security. Lastly, this paper outlines future research directions to guide researchers in related fields.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DMSA: A Decentralized Microservice Architecture for Edge Networks</title>
<link>https://arxiv.org/abs/2501.00883</link>
<guid>https://arxiv.org/abs/2501.00883</guid>
<content:encoded><![CDATA[
<div> 关键词: 微服务架构、边缘网络、去中心化、调度、负载均衡

总结:<br />
本文提出了一种针对边缘网络的去中心化微服务架构（DMSA），旨在解决传统集中式微服务架构的局限性。DMSA将调度功能从控制平面下放到边缘节点，并重新设计实现了三大核心模块：微服务发现、监控和调度。具体来说，DMSA定制了一种利用多端口监听和零拷贝转发的微服务调度方案，以确保高效的数据转发。此外，还提出了动态加权多级负载均衡算法，能够根据可靠性、优先级和响应延迟等因素动态调整调度。文章中实现了一个DMSA物理验证平台，实验结果表明，与现有最优和传统的调度方案相比，DMSA能有效应对链路故障和网络波动，提高了服务响应延迟和执行成功率，分别改善约60%~75%和10%~15%。 <div>
arXiv:2501.00883v1 Announce Type: new 
Abstract: The dispersed node locations and complex topologies of edge networks, combined with intricate dynamic microservice dependencies, render traditional centralized microservice architectures (MSAs) unsuitable. In this paper, we propose a decentralized microservice architecture (DMSA), which delegates scheduling functions from the control plane to edge nodes. DMSA redesigns and implements three core modules of microservice discovery, monitoring, and scheduling for edge networks to achieve precise awareness of instance deployments, low monitoring overhead and measurement errors, and accurate dynamic scheduling, respectively. Particularly, DMSA has customized a microservice scheduling scheme that leverages multi-port listening and zero-copy forwarding to guarantee high data forwarding efficiency. Moreover, a dynamic weighted multi-level load balancing algorithm is proposed to adjust scheduling dynamically with consideration of reliability, priority, and response delay. Finally, we have implemented a physical verification platform for DMSA. Extensive empirical results demonstrate that compared to state-of-the-art and traditional scheduling schemes, DMSA effectively counteracts link failures and network fluctuations, improving the service response delay and execution success rate by approximately $60\% \sim 75\%$ and $10\%\sim15\%$, respectively.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Large-Scale Exploratory Study on the Proxy Pattern in Ethereum</title>
<link>https://arxiv.org/abs/2501.00965</link>
<guid>https://arxiv.org/abs/2501.00965</guid>
<content:encoded><![CDATA[
<div> 关键词：代理模式、以太坊区块链、智能合约、升级性、ERC-1167

总结:
文章对以太坊区块链上的智能合约进行了全面分析，重点关注代理合同的使用情况。研究发现，14.2%的已部署智能合约为代理合同，且其活跃度和使用趋势均呈上升状态，尤其在合同部署后期达到高峰。代理合同主要通过离线脚本或链上工厂合同进行部署，分别占39.1%和60.9%。其中，67.8%的代理合同充当拦截器角色，而32.2%用于实现升级性。大多数（79%）代理合约为已知参考实现，尤其是ERC-1167类型占比29.4%，该类型旨在廉价复用和克隆合同功能。此外，研究提出了一种行为代理检测方法，精度和召回率均为100%。最后，针对开发者提出了实践建议，并指出了未来研究领域的开放性问题。 <div>
arXiv:2501.00965v1 Announce Type: new 
Abstract: The proxy pattern is a well-known design pattern with numerous use cases in several sectors of the software industry. As such, the use of the proxy pattern is also a common approach in the development of complex decentralized applications (DApps) on the Ethereum blockchain. Despite the importance of proxy contracts, little is known about (i) how their prevalence changed over time, (ii) the ways in which developers integrate proxies in the design of DApps, and (iii) what proxy types are being most commonly leveraged by developers. This study bridges these gaps through a comprehensive analysis of Ethereum smart contracts, utilizing a dataset of 50 million contracts and 1.6 billion transactions as of September 2022. Our findings reveal that 14.2% of all deployed smart contracts are proxy contracts. We show that proxy contracts are being more actively used than non-proxy contracts. Also, the usage of proxy contracts in various contexts, transactions involving proxy contracts, and adoption of proxy contracts by users have shown an upward trend over time, peaking at the end of our study period. They are either deployed through off-chain scripts or on-chain factory contracts, with the former and latter being employed in 39.1% and 60.9% of identified usage contexts in turn. We found that while the majority (67.8%) of proxies act as an interceptor, 32.2% enables upgradeability. Proxy contracts are typically (79%) implemented based on known reference implementations with 29.4% being of type ERC-1167, a class of proxies that aims to cheaply reuse and clone contracts' functionality. Our evaluation shows that our proposed behavioral proxy detection method has a precision and recall of 100% in detecting active proxies. Finally, we derive a set of practical recommendations for developers and introduce open research questions to guide future research on the topic.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fides: Scalable Censorship-Resistant DAG Consensus via Trusted Components</title>
<link>https://arxiv.org/abs/2501.01062</link>
<guid>https://arxiv.org/abs/2501.01062</guid>
<content:encoded><![CDATA[
<div> 关键词：Fides、异步DAG、BFT共识协议、Trusted Execution Environments (TEEs)、区块链系统

总结:<br />
本文提出了一个名为Fides的新式异步DAG基础的BFT共识协议，旨在解决现有协议面临的三个主要挑战。Fides利用可信执行环境(TEEs)来处理如下问题：<br />
1. 为容忍拜占庭副本而需要更大的共识群体规模（至少3倍大）的问题。<br />
2. 在异步网络中达成一致时高昂的通信成本和对全局公共随机数的依赖。<br />
3. 对抗审查以保证活性保障的脆弱性。<br />
通过采用四个基于TEE的信任组件——可靠广播、顶点验证、公共随机数以及交易披露，Fides实现了线性消息复杂度、确保的审查抵抗能力、扩大2倍的共识群体规模及轻量级公共随机数使用。此外，将这些核心组件抽象出来而非将整个协议迁移到TEE内，可以显著降低可信计算基数(TCB)。实验结果显示，相较于Tusk、RCC、HotStuff和PBFT等现行主流协议，Fides在本地和地理分布式网络中的性能更优，分别达到了每秒40万和81万笔交易的吞吐量。文章还分析了该协议的开销，证明了其在实际部署到真实世界区块链系统中的适用性和有效性。 <div>
arXiv:2501.01062v1 Announce Type: new 
Abstract: Recently, consensus protocols based on Directed Acyclic Graph (DAG) have gained significant attention due to their potential to build robust blockchain systems, particularly in asynchronous networks. In this paper, we propose Fides, an asynchronous DAG-based BFT consensus protocol that leverages Trusted Execution Environments (TEEs) to tackle three major scalability and security challenges faced by existing protocols: (i) the need for a larger quorum size (i.e., at least 3x larger) to tolerate Byzantine replicas, (ii) high communication costs and reliance on expensive cryptographic primitives (i.e., global common coin) to reach agreement in asynchronous networks, and (iii) poor censorship resilience undermining the liveness guarantee. Specifically, Fides adopts four trusted components-Reliable Broadcast, Vertex Validation, Common Coin, and Transaction Disclosure-within TEEs. Incorporating these components enables Fides to achieve linear message complexity, guaranteed censorship resilience, 2x larger quorum size, and lightweight common coin usage. Besides, abstracting these essential components rather than porting the entire protocol into TEE can significantly reduce the Trusted Computing Base (TCB). Experimental evaluations of Fides in local and geo-distributed networks demonstrate its superior performance compared to established state-of-the-art protocols such as Tusk, RCC, HotStuff, and PBFT. The results indicate that Fides achieves a throughput of 400k transactions per second in a geo-distributed network and 810k transactions per second in a local network. Our analysis further explores the protocol's overhead, highlighting its suitability and effectiveness for practical deployment in real-world blockchain systems.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FAPL-DM-BC: A Secure and Scalable FL Framework with Adaptive Privacy and Dynamic Masking, Blockchain, and XAI for the IoVs</title>
<link>https://arxiv.org/abs/2501.01063</link>
<guid>https://arxiv.org/abs/2501.01063</guid>
<content:encoded><![CDATA[
<div> 关键词：FAPL-DM-BC方案、联邦学习、动态遮掩、区块链、智能城市

总结:
FAPL-DM-BC方案是一种基于联邦学习的车联网隐私、安全和可扩展性解决方案。该方案利用了Federated Adaptive Privacy-Aware Learning（FAPL）和Dynamic Masking（DM），实现实时学习并自适应调整隐私策略，以应对数据敏感性和状态变化，达到最优的隐私-效用平衡。同时结合了安全日志与验证、基于区块链的数据源追溯和去中心化验证以及云微服务中使用FedAvg和Secure Multi-Party Computation（SMPC）的安全聚合。通过由模型无关的可解释人工智能（XAI）驱动的双模反馈机制，确保本地预测和解释得到认证并提升效率。通过将局部反馈与全局知识通过加权平均计算相结合，FAPL-DM-BC保证了联邦学习过程既安全又可扩展，并具有可解释性。此方案有望应用于自动驾驶汽车、交通管理与预测、实时车联网网络安全以及智慧城市等领域。 <div>
arXiv:2501.01063v1 Announce Type: new 
Abstract: The FAPL-DM-BC solution is a new FL-based privacy, security, and scalability solution for the Internet of Vehicles (IoV). It leverages Federated Adaptive Privacy-Aware Learning (FAPL) and Dynamic Masking (DM) to learn and adaptively change privacy policies in response to changing data sensitivity and state in real-time, for the optimal privacy-utility tradeoff. Secure Logging and Verification, Blockchain-based provenance and decentralized validation, and Cloud Microservices Secure Aggregation using FedAvg (Federated Averaging) and Secure Multi-Party Computation (SMPC). Two-model feedback, driven by Model-Agnostic Explainable AI (XAI), certifies local predictions and explanations to drive it to the next level of efficiency. Combining local feedback with world knowledge through a weighted mean computation, FAPL-DM-BC assures federated learning that is secure, scalable, and interpretable. Self-driving cars, traffic management, and forecasting, vehicular network cybersecurity in real-time, and smart cities are a few possible applications of this integrated, privacy-safe, and high-performance IoV platform.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communicating Unexpectedness for Out-of-Distribution Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.01140</link>
<guid>https://arxiv.org/abs/2501.01140</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning、generalization、distribution shifts、Unexpected Encoding Scheme、multi-robot warehouse environment

总结:<br />
本文提出了一种名为“意外编码方案”的新颖的去中心化多智能体强化学习算法，旨在解决智能体在实际环境中快速适应预料之外的情况。该方法通过让智能体不仅基于奖励驱动进行通信，还预测下一次观察结果并度量预测与实际观察之间的差异，将这种“意外性”编码为消息进行传递。实验在多机器人仓库环境中验证了所提方法能有效应对动态变化的训练环境以及分布外的环境，展现出较强的鲁棒适应能力。 <div>
arXiv:2501.01140v1 Announce Type: new 
Abstract: Applying multi-agent reinforcement learning methods to realistic settings is challenging as it may require the agents to quickly adapt to unexpected situations that are rarely or never encountered in training. Recent methods for generalization to such out-of-distribution settings are limited to more specific, restricted instances of distribution shifts. To tackle adaptation to distribution shifts, we propose Unexpected Encoding Scheme, a novel decentralized multi-agent reinforcement learning algorithm where agents communicate "unexpectedness," the aspects of the environment that are surprising. In addition to a message yielded by the original reward-driven communication, each agent predicts the next observation based on previous experience, measures the discrepancy between the prediction and the actually encountered observation, and encodes this discrepancy as a message. Experiments on multi-robot warehouse environment support that our proposed method adapts robustly to dynamically changing training environments as well as out-of-distribution environment.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PoVF: Empowering Decentralized Blockchain Systems with Verifiable Function Consensus</title>
<link>https://arxiv.org/abs/2501.01146</link>
<guid>https://arxiv.org/abs/2501.01146</guid>
<content:encoded><![CDATA[
<div> 关键词：共识机制、区块链、去中心化、Proof of Verifiable Functions (PoVF)、Delay buffer

总结:
本文提出了一种名为Proof of Verifiable Functions (PoVF)的新颖共识机制，该机制旨在解决现有区块链共识机制中的中心化问题并提高系统的效率。PoVF基于可验证函数的可验证性和不可预测性，确保了区块链网络中所有节点拥有平等参与共识的机会，从而实现更充分的去中心化。同时，文中还提出了“延迟缓冲”结构，用于保证交易的顺序执行，防止因广播和交易执行混乱导致的区块链分叉。安全分析表明，PoVF具有可证明的安全性和抵抗潜在攻击的能力。实验结果显示，基于PoVF的区块链系统在仅配置有4核CPU的节点条件下，可以达到每秒处理4000笔交易的性能。此外，通过使用基尼系数评估区块链的去中心化程度，PoVF实现了在所采样区块链中最低的基尼系数0.39。实验表明，PoVF在保障去中心化与安全性的同时，亦具备较高的运行效率。 <div>
arXiv:2501.01146v1 Announce Type: new 
Abstract: Consensus mechanism is the core technology for blockchain to ensure that transactions are executed in sequence. It also determines the decentralization, security, and efficiency of blockchain. Existing mechanisms all have certain centralization issues and fail to ensure the decentralization of blockchain networks. A decentralized and efficient mechanism is required to improve blockchain systems. This paper proposes a fair consensus mechanism called Proof of Verifiable Functions (PoVF), based on the verifiability and unpredictability of verifiable functions. PoVF provides a sufficiently fair mechanism, ensuring that all nodes in blockchain network have equal opportunity to participate in consensus. In addition, a structure called "Delay buffer" is proposed to ensure transactions are executed sequentially. It delay the selection of blocks to avoid blockchain forks caused by broadcasting and transaction execution confusion. According to our security analysis, PoVF is provably secure and has the ability to resist potential adversaries. According to the experiments, PoVF-based blockchain can process up to 4000 transactions per second with nodes configured with only 4-core CPUs. This paper uses the Gini coefficient to measure the decentralization of blockchains, and the PoVF-based blockchain achieves the lowest Gini coefficient of 0.39 among all sampled blockchains. PoVF has been shown to provide sufficient efficiency while ensuring decentralization and security through experiments.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MADiff: Offline Multi-agent Learning with Diffusion Models</title>
<link>https://arxiv.org/abs/2305.17330</link>
<guid>https://arxiv.org/abs/2305.17330</guid>
<content:encoded><![CDATA[
<div> 关键词：离线强化学习、Q-learning、监督学习、扩散模型、多智能体

总结：
本文提出了一种名为MADiff的新方法，它是一种基于注意力机制的扩散模型，用于解决多智能体环境中的离线强化学习问题。传统的Q-learning算法和监督学习方法在离线设置中存在局限性，而MADiff旨在克服这些限制，通过建模多个智能体之间的复杂协调行为来提高性能。与每个智能体独立使用DM不同，MADiff作为一个既能实现分布式策略又能作为集中式控制器的框架运作。在执行过程中，MADiff同时进行队友建模，并可用于多智能体轨迹预测。实验结果显示，MADiff在各种多智能体学习任务上优于基线算法，证实了其在建模复杂多智能体交互方面的有效性。相关代码已发布在https://github.com/zbzhu99/madiff上。 <div>
arXiv:2305.17330v5 Announce Type: replace 
Abstract: Offline reinforcement learning (RL) aims to learn policies from pre-existing datasets without further interactions, making it a challenging task. Q-learning algorithms struggle with extrapolation errors in offline settings, while supervised learning methods are constrained by model expressiveness. Recently, diffusion models (DMs) have shown promise in overcoming these limitations in single-agent learning, but their application in multi-agent scenarios remains unclear. Generating trajectories for each agent with independent DMs may impede coordination, while concatenating all agents' information can lead to low sample efficiency. Accordingly, we propose MADiff, which is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple agents. To our knowledge, MADiff is the first diffusion-based multi-agent learning framework, functioning as both a decentralized policy and a centralized controller. During decentralized executions, MADiff simultaneously performs teammate modeling, and the centralized controller can also be applied in multi-agent trajectory predictions. Our experiments demonstrate that MADiff outperforms baseline algorithms across various multi-agent learning tasks, highlighting its effectiveness in modeling complex multi-agent interactions. Our code is available at https://github.com/zbzhu99/madiff.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Solving Hierarchical Information-Sharing Dec-POMDPs: An Extensive-Form Game Approach</title>
<link>https://arxiv.org/abs/2402.02954</link>
<guid>https://arxiv.org/abs/2402.02954</guid>
<content:encoded><![CDATA[
<div> 关键词：多玩家、部分可观测马尔科夫决策过程、等价单玩家游戏、决策变量解耦、层次信息共享、扩展型博弈、时间复杂度优化

总结:<br />
该文针对多玩家局部可观测马尔科夫决策过程提出了一种新的解决方法。文章首先介绍了将此类问题转化为等价的单玩家游戏的理论，但指出这种转化会导致双指数级的复杂度。为了解决这一问题，本文通过在层次信息共享的框架下，进一步将单阶段子游戏分解为更小的子游戏，从而实现了决策变量的解耦，并保持了最优性。这种方法揭示了对于任何单阶段子游戏，都存在可利用的扩展型博弈解决方案，显著降低了时间复杂度。实验结果显示，基于这些发现的算法能够在不牺牲最优性的前提下，处理规模更大的多玩家游戏。 <div>
arXiv:2402.02954v3 Announce Type: replace 
Abstract: A recent theory shows that a multi-player decentralized partially observable Markov decision process can be transformed into an equivalent single-player game, enabling the application of \citeauthor{bellman}'s principle of optimality to solve the single-player game by breaking it down into single-stage subgames. However, this approach entangles the decision variables of all players at each single-stage subgame, resulting in backups with a double-exponential complexity. This paper demonstrates how to disentangle these decision variables while maintaining optimality under hierarchical information sharing, a prominent management style in our society. To achieve this, we apply the principle of optimality to solve any single-stage subgame by breaking it down further into smaller subgames, enabling us to make single-player decisions at a time. Our approach reveals that extensive-form games always exist with solutions to a single-stage subgame, significantly reducing time complexity. Our experimental results show that the algorithms leveraging these findings can scale up to much larger multi-player games without compromising optimality.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Detecting Financial Bots on the Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2403.19530</link>
<guid>https://arxiv.org/abs/2403.19530</guid>
<content:encoded><![CDATA[
<div> 关键词：bots, 分布式账本技术, 机器学习, 以太坊, 检测算法

总结:
本文研究了在分布式账本技术（DLTs）中集成的机器人（bots）对效率和自动化的影响，以及它们可能带来的市场操纵等风险。文章提出了一个新的利用机器学习检测以太坊平台上金融机器人的方法。首先，通过系统化现有科学文献和收集轶事证据，建立了由7个类别和24个子类别组成的金融bot分类体系。其次，创建了一个包含133个人类地址和137个bot地址的地面真实数据集。接着，运用无监督和有监督的机器学习算法进行分析，其中高绩效的聚类算法是平均群纯度为82.6%的高斯混合模型，而二元分类中最优模型是准确率达到83%的随机森林。这种基于机器学习的检测机制为理解以太坊生态系统动态提供了新的视角，有助于深入剖析当前的bot景观。 <div>
arXiv:2403.19530v2 Announce Type: replace 
Abstract: The integration of bots in Distributed Ledger Technologies (DLTs) fosters efficiency and automation. However, their use is also associated with predatory trading and market manipulation, and can pose threats to system integrity. It is therefore essential to understand the extent of bot deployment in DLTs; despite this, current detection systems are predominantly rule-based and lack flexibility. In this study, we present a novel approach that utilizes machine learning for the detection of financial bots on the Ethereum platform. First, we systematize existing scientific literature and collect anecdotal evidence to establish a taxonomy for financial bots, comprising 7 categories and 24 subcategories. Next, we create a ground-truth dataset consisting of 133 human and 137 bot addresses. Third, we employ both unsupervised and supervised machine learning algorithms to detect bots deployed on Ethereum. The highest-performing clustering algorithm is a Gaussian Mixture Model with an average cluster purity of 82.6%, while the highest-performing model for binary classification is a Random Forest with an accuracy of 83%. Our machine learning-based detection mechanism contributes to understanding the Ethereum ecosystem dynamics by providing additional insights into the current bot landscape.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real World Federated Learning with a Knowledge Distilled Transformer for Cardiac CT Imaging</title>
<link>https://arxiv.org/abs/2407.07557</link>
<guid>https://arxiv.org/abs/2407.07557</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、半监督策略、Transformer、卷积神经网络（CNN）、心脏CT分析

总结:<br />
本文探讨了联邦学习在实际应用中的挑战，特别是面对部分标注数据的情况。研究提出了一种两步半监督策略，用于提升transformer架构在小规模和多样化标注数据集上的性能。该策略通过任务特定的CNN对未标注数据进行预测，然后将这些预测结果作为输入，利用标签特定的头部让transformer进行学习。在涉及大规模真实世界设置的心脏CT分析（样本量为8,104）中，八个医院的数据被联合使用。实验结果显示，这种方法提高了预测准确性，并能在联邦范围内同时学习各种局部标注，相比基于UNet的模型在下游任务上表现出更好的泛化能力。研究方已公开发布了相关代码和模型权重，以促进未来心脏CT分析的应用和发展。 <div>
arXiv:2407.07557v2 Announce Type: replace-cross 
Abstract: Federated learning is a renowned technique for utilizing decentralized data while preserving privacy. However, real-world applications often face challenges like partially labeled datasets, where only a few locations have certain expert annotations, leaving large portions of unlabeled data unused. Leveraging these could enhance transformer architectures ability in regimes with small and diversely annotated sets. We conduct the largest federated cardiac CT analysis to date (n=8,104) in a real-world setting across eight hospitals. Our two-step semi-supervised strategy distills knowledge from task-specific CNNs into a transformer. First, CNNs predict on unlabeled data per label type and then the transformer learns from these predictions with label-specific heads. This improves predictive accuracy and enables simultaneous learning of all partial labels across the federation, and outperforms UNet-based models in generalizability on downstream tasks. Code and model weights are made openly available for leveraging future cardiac CT analysis.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Segmented Private Data Aggregation in the Multi-message Shuffle Model</title>
<link>https://arxiv.org/abs/2407.19639</link>
<guid>https://arxiv.org/abs/2407.19639</guid>
<content:encoded><![CDATA[
<div> 关键词: 多消息洗牌模型、差分隐私、灵活隐私保护、数据聚合、通信优化

总结:
本文针对多消息洗牌模型下的差分隐私研究，提出了一个创新的分段私有数据聚合框架，旨在为用户提供灵活的隐私保护水平，同时增强服务器的数据聚合效率。该框架不仅保护用户数据，还能匿名处理用户的隐私保护选择以防止潜在的数据泄露风险。为了优化隐私-效用-通信之间的权衡，文中探讨了用于毯式消息的最佳配置数量，并在洗牌模型中进行了近乎精确的隐私放大分析。实验结果显示，与现有方法相比，该分段多消息洗牌框架可将估计误差降低约50%，显著提升了隐私性和实用性。 <div>
arXiv:2407.19639v3 Announce Type: replace 
Abstract: The shuffle model of differential privacy (DP) offers compelling privacy-utility trade-offs in decentralized settings (e.g., internet of things, mobile edge networks). Particularly, the multi-message shuffle model, where each user may contribute multiple messages, has shown that accuracy can approach that of the central model of DP. However, existing studies typically assume a uniform privacy protection level for all users, which may deter conservative users from participating and prevent liberal users from contributing more information, thereby reducing the overall data utility, such as the accuracy of aggregated statistics. In this work, we pioneer the study of segmented private data aggregation within the multi-message shuffle model of DP, introducing flexible privacy protection for users and enhanced utility for the aggregation server. Our framework not only protects users' data but also anonymizes their privacy level choices to prevent potential data leakage from these choices. To optimize the privacy-utility-communication trade-offs, we explore approximately optimal configurations for the number of blanket messages and conduct almost tight privacy amplification analyses within the shuffle model. Through extensive experiments, we demonstrate that our segmented multi-message shuffle framework achieves a reduction of about 50\% in estimation error compared to existing approaches, significantly enhancing both privacy and utility.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Blockchain Radio Access Networks: Architecture, Modelling, and Performance Assessment</title>
<link>https://arxiv.org/abs/2412.19838</link>
<guid>https://arxiv.org/abs/2412.19838</guid>
<content:encoded><![CDATA[
<div> 关键词: 下一代无线接入网络 (RAN), 区块链技术, 安全性, 动态覆盖扩展, 延迟, 攻击成功率

总结:
本文介绍了下一代无线接入网络（RAN）的设计需求，强调了安全、无处不在和始终可用的连通性的重要性。为此，文章提出了一种利用区块链技术增强RAN安全性并借助商业或私有无线节点实现动态覆盖扩展的网络架构。通过运用Markov链理论，该文构建了一个具有更高工程洞见的理论模型，以此评估该架构的效率与局限性。针对固定拓扑前传网络、高级覆盖扩展以及高级移动节点连接三种场景，文中量化了延迟及安全性指标——成功的攻击概率，揭示了区块链-RAN架构的可扩展性。<br /><br /> <div>
arXiv:2412.19838v1 Announce Type: new 
Abstract: Demands for secure, ubiquitous, and always-available connectivity have been identified as the pillar design parameters of the next generation radio access networks (RANs). Motivated by this, the current contribution introduces a network architecture that leverages blockchain technologies to augment security in RANs, while enabling dynamic coverage expansion through the use of intermediate commercial or private wireless nodes. To assess the efficiency and limitations of the architecture, we employ Markov chain theory in order to extract a theoretical model with increased engineering insights. Building upon this model, we quantify the latency as well as the security capabilities in terms of probability of successful attack, for three scenarios, namely fixed topology fronthaul network, advanced coverage expansion and advanced mobile node connectivity, which reveal the scalability of the blockchain-RAN architecture.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WiSER-X: Wireless Signals-based Efficient Decentralized Multi-Robot Exploration without Explicit Information Exchange</title>
<link>https://arxiv.org/abs/2412.19876</link>
<guid>https://arxiv.org/abs/2412.19876</guid>
<content:encoded><![CDATA[
<div> 关键词：Wireless Signal, efficient multi-robot exploration, WiSER-X, decentralized team, communication bandwidth constraints

<br /><br />总结:

本文介绍了应用于带有通信带宽约束条件下的分布式机器人团队未知环境探索的新算法——无线信号驱动的有效多机器人探索算法(WiSER-X)。WiSER-X仅依赖于通过如WiFi、超宽带等传感器交换的局部间机器人相对位置估计来指导单个机器人的探索决策，以最大限度地减少覆盖重叠。此外，WiSER-X还支持异步终止，无需机器人之间共享地图。它还能适应异构机器人行为以及在未知环境中处理完全故障的情况，同时确保全面覆盖。模拟结果显示，与不分享信息的基线算法-1相比，WiSER-X导致的覆盖重叠降低了58%，而与全信息分享的基线算法-2相比，仅多出23%的重叠。 <div>
arXiv:2412.19876v1 Announce Type: new 
Abstract: We introduce a Wireless Signal based Efficient multi-Robot eXploration (WiSER-X) algorithm applicable to a decentralized team of robots exploring an unknown environment with communication bandwidth constraints. WiSER-X relies only on local inter-robot relative position estimates, that can be obtained by exchanging signal pings from onboard sensors such as WiFi, Ultra-Wide Band, amongst others, to inform the exploration decisions of individual robots to minimize redundant coverage overlaps. Furthermore, WiSER-X also enables asynchronous termination without requiring a shared map between the robots. It also adapts to heterogeneous robot behaviors and even complete failures in unknown environment while ensuring complete coverage. Simulations show that WiSER-X leads to 58% lower overlap than a zero-information-sharing baseline algorithm-1 and only 23% more overlap than a full-information-sharing algorithm baseline algorithm-2.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning Driven Multi-Robot Exploration via Explicit Communication and Density-Based Frontier Search</title>
<link>https://arxiv.org/abs/2412.20049</link>
<guid>https://arxiv.org/abs/2412.20049</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体探索、未知环境、强化学习、约束通信、自主探索

<br />
总结:
本文提出了一种基于强化学习的新型去中心化协同框架，用于增强多智能体在未知环境中的探索能力。该框架使智能体能够利用以自身为中心的视场占用格子和从$\text{A}^*$算法计算出的前沿轨迹特征来决定下一步行动。同时，文章还提出了一种受限的通信方案，允许智能体高效地分享环境知识，从而减少探索冗余。这种去中心化的框架确保每个智能体能独立运行并为集体探索任务作出贡献。通过在Gymnasium模拟环境和真实世界实验中的广泛验证，结果显示了该系统的鲁棒性和有效性，强调了结合自主探索与智能体间地图共享对于发展可扩展和鲁棒的机器人探索系统的重要性。 <div>
arXiv:2412.20049v1 Announce Type: new 
Abstract: Collaborative multi-agent exploration of unknown environments is crucial for search and rescue operations. Effective real-world deployment must address challenges such as limited inter-agent communication and static and dynamic obstacles. This paper introduces a novel decentralized collaborative framework based on Reinforcement Learning to enhance multi-agent exploration in unknown environments. Our approach enables agents to decide their next action using an agent-centered field-of-view occupancy grid, and features extracted from $\text{A}^*$ algorithm-based trajectories to frontiers in the reconstructed global map. Furthermore, we propose a constrained communication scheme that enables agents to share their environmental knowledge efficiently, minimizing exploration redundancy. The decentralized nature of our framework ensures that each agent operates autonomously, while contributing to a collective exploration mission. Extensive simulations in Gymnasium and real-world experiments demonstrate the robustness and effectiveness of our system, while all the results highlight the benefits of combining autonomous exploration with inter-agent map sharing, advancing the development of scalable and resilient robotic exploration systems.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Unlabeled Multi-Agent Navigation in Continuous Space</title>
<link>https://arxiv.org/abs/2412.20233</link>
<guid>https://arxiv.org/abs/2412.20233</guid>
<content:encoded><![CDATA[
<div> 关键词：移动代理、目标位置、分布式场景、局部观察、路径规划

总结:
本文研究了一个无需特定代理人到达指定目标的多移动代理人导航问题。与大多数假设存在集中式规划器并限制代理人仅能在预定义的位置图及转换之间移动的工作不同，本工作聚焦于分布式场景，其中每个代理人仅依赖本地观测和通信独立行动，并可在任意时刻向任意方向移动。提出了一种迭代方法，包括代理人个体选择目标、交换目标、规划路径，并在每个时间步长中选择平衡推进路径与避免碰撞的动作。在满足特定假设下，该方法被证明是完备的。实验结果表明，相较于基准的分布式导航方法，所提方法在成功率（即在给定时间内能解决更多问题实例）上具有优势，并与中心化的TSWAP算法相比，其在完成任务的轨迹长度方面表现出更高效率。 <div>
arXiv:2412.20233v1 Announce Type: new 
Abstract: In this work, we study the problem where a group of mobile agents needs to reach a set of goal locations, but it does not matter which agent reaches a specific goal. Unlike most of the existing works on this topic that typically assume the existence of the centralized planner (or controller) and limit the agents' moves to a predefined graph of locations and transitions between them, in this work we focus on the decentralized scenarios, when each agent acts individually relying only on local observations/communications and is free to move in arbitrary direction at any time. Our iterative approach involves agents individually selecting goals, exchanging them, planning paths, and at each time step choose actions that balance between progressing along the paths and avoiding collisions. The proposed method is shown to be complete under specific assumptions on how agents progress towards their current goals, and our empirical evaluation demonstrates its superiority over a baseline decentralized navigation approach in success rate (i.e. is able to solve more problem instances under a given time limit) and a comparison with the centralized TSWAP algorithm reveals its efficiency in minimizing trajectory lengths for mission accomplishment.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Election of Collaborators via Reinforcement Learning for Federated Brain Tumor Segmentation</title>
<link>https://arxiv.org/abs/2412.20253</link>
<guid>https://arxiv.org/abs/2412.20253</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Reinforcement Learning, Similarity-weighted Aggregation, Multi-armed Bandit, Brain Lesion Segmentation

<br /><br />总结:
本文提出了一种名为RL-HSimAgg的新颖强化学习与相似性加权聚合算法，该算法利用调和均值处理异常数据点，旨在解决动态联邦学习环境中参与协作的选择优化问题。研究将多臂老虎机算法应用于改善合作者选择及模型泛化能力，通过平衡探索与开发之间的权衡来实现资源效率更高的训练和多样化的数据集。实验表明，在针对脑部肿瘤分割的模拟实验中，使用上确界策略(UCB)的RL-HSimAgg相较于Epsilon-greedy方法在所有评估指标上表现出色，特别是在增强型肿瘤、肿瘤核心以及整个肿瘤的分割Dice分数上有显著提升。因此，在即将举行的Federated Tumor Segmentation Challenge (FeTS 2024) 中，文章建议采用UCB作为多模态MRI胶质母细胞瘤病变分割任务的主要客户端选择方法。研究表明，基于RL的合作者管理策略（如UCB）有可能提高分布式学习环境中的模型稳健性和灵活性，尤其是在脑肿瘤分割等特定领域。 <div>
arXiv:2412.20253v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training across decentralized datasets while preserving data privacy. However, optimally selecting participating collaborators in dynamic FL environments remains challenging. We present RL-HSimAgg, a novel reinforcement learning (RL) and similarity-weighted aggregation (simAgg) algorithm using harmonic mean to manage outlier data points. This paper proposes applying multi-armed bandit algorithms to improve collaborator selection and model generalization. By balancing exploration-exploitation trade-offs, these RL methods can promote resource-efficient training with diverse datasets. We demonstrate the effectiveness of Epsilon-greedy (EG) and upper confidence bound (UCB) algorithms for federated brain lesion segmentation. In simulation experiments on internal and external validation sets, RL-HSimAgg with UCB collaborator outperformed the EG method across all metrics, achieving higher Dice scores for Enhancing Tumor (0.7334 vs 0.6797), Tumor Core (0.7432 vs 0.6821), and Whole Tumor (0.8252 vs 0.7931) segmentation. Therefore, for the Federated Tumor Segmentation Challenge (FeTS 2024), we consider UCB as our primary client selection approach in federated Glioblastoma lesion segmentation of multi-modal MRIs. In conclusion, our research demonstrates that RL-based collaborator management, e.g. using UCB, can potentially improve model robustness and flexibility in distributed learning environments, particularly in domains like brain tumor segmentation.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Policies for Dynamic Coalition Formation in Multi-Robot Task Allocation</title>
<link>https://arxiv.org/abs/2412.20397</link>
<guid>https://arxiv.org/abs/2412.20397</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人任务分配、动态联盟形成、分布式学习框架、多智能体近似策略优化、空间动作地图

总结:<br />
本文提出了一种用于多机器人任务分配的分布式、基于学习的动态联盟形成框架。该框架扩展了多智能体近似策略优化（MAPPO），融入了空间动作地图、机器人运动控制、任务分配修订和意图分享机制，从而实现有效的联盟形成。通过大量模拟实验表明，与现有方法（包括市场基准）相比，该模型表现更优。此外，文章还评估了该框架的可扩展性和泛化性，证实其能够处理大规模机器人群体并在各种不同的任务分配环境中适应并发挥作用。 <div>
arXiv:2412.20397v1 Announce Type: new 
Abstract: We propose a decentralized, learning-based framework for dynamic coalition formation in Multi-Robot Task Allocation (MRTA). Our approach extends Multi-Agent Proximal Policy Optimization (MAPPO) by incorporating spatial action maps, robot motion control, task allocation revision, and intention sharing to enable effective coalition formation. Extensive simulations demonstrate that our model significantly outperforms existing methods, including a market-based baseline. Furthermore, we assess the scalability and generalizability of the proposed framework, highlighting its ability to handle large robot populations and adapt to diverse task allocation environments.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cool, But What About Oracles? An Oracle-Based Perspective on Blockchain Integration in the Accounting Field</title>
<link>https://arxiv.org/abs/2412.20447</link>
<guid>https://arxiv.org/abs/2412.20447</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、会计系统、Oracle、限制、ESG

总结:
区块链技术因其成功应用于比特币网络而受到广泛关注，并被提议用于改进传统会计系统。然而，与现实世界数据交互需要第三方Oracle介入，其特性可能降低预期的集成效益。本文通过文献回顾研究了区块链在会计领域整合中是否考虑并解决了Oracle带来的局限性问题。研究发现，尽管相关领域的文章数量较多，但针对Oracle局限性的实际研究却相对匮乏。有趣的是，在环境、社会和治理（ESG）报告方面，已经出现了针对Oracle局限性的解决方法，其中许可链被视为安全存储可持续性数据的有效支持方案。 <div>
arXiv:2412.20447v1 Announce Type: new 
Abstract: The Bitcoin Network is a sophisticated accounting system that allows its underlying cryptocurrency to be trusted even in the absence of a reliable financial authority. Given its undeniable success, the technology, generally referred to as blockchain, has also been proposed as a means to improve legacy accounting systems. Accounting for real-world data, however, requires the intervention of a third party known as an Oracle, which, having not the same characteristics as a blockchain, could potentially reduce the expected integration benefit. Through a systematic review of the literature, this study aims to investigate whether the papers concerning blockchain integration in accounting consider and address the limitations posed by oracles. A broad overview of the limitations that emerged in the literature is provided and distinguished according to the specific accounting integration. Results support the view that although research on the subject counts numerous articles, actual studies considering oracle limitations are lacking. Interestingly, despite the scarce production of papers addressing oracles in various accounting sectors, reporting for ESG already shows interesting workarounds for oracle limitations, with permissioned chains envisioned as a valid support for the safe storage of sustainability data.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game Theory and Multi-Agent Reinforcement Learning : From Nash Equilibria to Evolutionary Dynamics</title>
<link>https://arxiv.org/abs/2412.20523</link>
<guid>https://arxiv.org/abs/2412.20523</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、强化学习、非平稳性、部分可观测性、大规模代理

总结:

本文探讨了基于先前工作的复杂多智能体系统的高级主题。首先关注了多智能体强化学习（MARL）中的四个核心挑战：非平稳性、部分可观测性、大规模代理群体的可扩展性以及去中心化学习。文章对旨在解决这些挑战的近期算法进展提供了数学表述和分析，并特别强调了它们与博弈论概念的融合。研究内容涉及纳什均衡、演化博弈理论、相关平衡以及对抗性动态如何有效地融入MARL算法以优化学习结果。通过全面的分析，本论文展示了博弈论与MARL相结合如何提升复杂动态环境中多智能体系统的稳健性和有效性。 <div>
arXiv:2412.20523v1 Announce Type: new 
Abstract: This paper explores advanced topics in complex multi-agent systems building upon our previous work. We examine four fundamental challenges in Multi-Agent Reinforcement Learning (MARL): non-stationarity, partial observability, scalability with large agent populations, and decentralized learning. The paper provides mathematical formulations and analysis of recent algorithmic advancements designed to address these challenges, with a particular focus on their integration with game-theoretic concepts. We investigate how Nash equilibria, evolutionary game theory, correlated equilibrium, and adversarial dynamics can be effectively incorporated into MARL algorithms to improve learning outcomes. Through this comprehensive analysis, we demonstrate how the synthesis of game theory and MARL can enhance the robustness and effectiveness of multi-agent systems in complex, dynamic environments.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Empowered Cyber-Secure Federated Learning for Trustworthy Edge Computing</title>
<link>https://arxiv.org/abs/2412.20674</link>
<guid>https://arxiv.org/abs/2412.20674</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 恶意攻击, 可信性, 公平性, 安全认证

总结:
本文提出了一种跨设备的联邦学习模型，旨在确保联邦学习训练过程中的可信性、公平性和安全认证。首先，通过构建基于贡献度的声誉信任模型来保障可信性，该模型衡量各参与节点对模型收敛的贡献。其次，利用异常检测技术识别并剔除恶意参与者，以确保训练过程的公平性。再次，采用分布式传感机制为每个参与设备生成唯一标识令牌，并将其存储在区块链智能合约中，以此建立安全认证机制。最后，将所有参与者的信任评分存入区块链，并结合多种共识机制验证其信誉，从而进一步增强系统的整体安全性与可靠性。 <div>
arXiv:2412.20674v1 Announce Type: new 
Abstract: Federated Learning (FL) is a privacy-preserving distributed machine learning scheme, where each participant data remains on the participating devices and only the local model generated utilizing the local computational power is transmitted throughout the database. However, the distributed computational nature of FL creates the necessity to develop a mechanism that can remotely trigger any network agents, track their activities, and prevent threats to the overall process posed by malicious participants. Particularly, the FL paradigm may become vulnerable due to an active attack from the network participants, called a poisonous attack. In such an attack, the malicious participant acts as a benign agent capable of affecting the global model quality by uploading an obfuscated poisoned local model update to the server. This paper presents a cross-device FL model that ensures trustworthiness, fairness, and authenticity in the underlying FL training process. We leverage trustworthiness by constructing a reputation-based trust model based on contributions of agents toward model convergence. We ensure fairness by identifying and removing malicious agents from the training process through an outlier detection technique. Further, we establish authenticity by generating a token for each participating device through a distributed sensing mechanism and storing that unique token in a blockchain smart contract. Further, we insert the trust scores of all agents into a blockchain and validate their reputations using various consensus mechanisms that consider the computational task.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Infrastructure for Systematically Collecting Smart Contract Lineages for Analyses</title>
<link>https://arxiv.org/abs/2412.20866</link>
<guid>https://arxiv.org/abs/2412.20866</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contract, evolution, blockchain, SCLineage, SCLineageSet

总结:
针对智能合约演进跟踪的挑战，该文提出了一种名为SCLineage的自动化基础设施，用于准确识别和收集智能合约的版本关联关系（即合约血统）。由于区块链技术的不可变性导致每次智能合约更新都在新地址部署，现有平台如Etherscan无法追踪合约间的继承关系。为了解决这一问题并支持研究社区构建可靠的多版本智能合约数据集，文中还推出了一个名为SCLineageSet的最新开源数据集，以促进对智能合约演进的深入研究。通过一个利用局部敏感哈希（LSH）构建合约血统的案例研究，文章展示了SCLineage在软件工程研究中的应用潜力及其对未来领域研究的重要价值。 <div>
arXiv:2412.20866v1 Announce Type: new 
Abstract: Tracking the evolution of smart contracts is a significant challenge, impeding on the advancement of research on smart contract analysis. Indeed, due to the inherent immutability of the underlying blockchain technology, each smart contract update results in a deployment at a new address, breaking the links between versions. Existing platforms like Etherscan lack the capability to trace the predecessor-successor relationships within a smart contract lineage, further hindering empirical research on contract evolution.
  We address this challenge for the research community towards building a reliable dataset of linked versions for various smart contracts, i.e., lineages: we introduce SCLineage, an automated infrastructure that accurately identifies and collects smart contract lineages by leveraging proxy contracts. We present SCLineageSet, an up-to-date, open-source dataset that facilitates extensive research on smart contract evolution. We illustrate the applicability of our proposal in software engineering research through a case study that explores the evaluation of Locality-Sensitive Hashing (LSH) for forming contract lineages. This example underscores how SCLineage provides valuable insights for future research in the field.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Aware Multi-Device Cooperative Edge Inference with Distributed Resource Bidding</title>
<link>https://arxiv.org/abs/2412.21069</link>
<guid>https://arxiv.org/abs/2412.21069</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile Edge Computing (MEC)，Artificial Intelligence (AI)，Data Privacy，Distributed Bidding Mechanism，Decentralized Partially Observable Markov Decision Process (DEC-POMDP)

<br /><br />总结:
本文提出了一种隐私意识强的多设备协同边缘推理系统，用于分类任务，该系统结合了分布式竞标机制以获取MEC服务器的计算资源。为了减少数据隐私泄露，采用了中间特征压缩方法。为了解决分布式环境下的决策问题，文章构建了一个分散式的部分可观测马尔可夫决策过程（DEC-POMDP）模型，并开发了一种基于多智能体深度确定性策略梯度（MADDPG）的算法来确定投标值和特征压缩比率。模拟结果显示，提出的算法在保护数据隐私的同时，能够有效提升协作边缘推理的准确性。在确保足够水平的数据隐私保护下，与忽略无线信道条件的方法相比，该算法可以使分类准确率提高0.31%-0.95%。进一步考虑推断数据的难度后，性能提升了1.54%-1.67%。 <div>
arXiv:2412.21069v1 Announce Type: new 
Abstract: Mobile edge computing (MEC) has empowered mobile devices (MDs) in supporting artificial intelligence (AI) applications through collaborative efforts with proximal MEC servers. Unfortunately, despite the great promise of device-edge cooperative AI inference, data privacy becomes an increasing concern. In this paper, we develop a privacy-aware multi-device cooperative edge inference system for classification tasks, which integrates a distributed bidding mechanism for the MEC server's computational resources. Intermediate feature compression is adopted as a principled approach to minimize data privacy leakage. To determine the bidding values and feature compression ratios in a distributed fashion, we formulate a decentralized partially observable Markov decision process (DEC-POMDP) model, for which, a multi-agent deep deterministic policy gradient (MADDPG)-based algorithm is developed. Simulation results demonstrate the effectiveness of the proposed algorithm in privacy-preserving cooperative edge inference. Specifically, given a sufficient level of data privacy protection, the proposed algorithm achieves 0.31-0.95% improvements in classification accuracy compared to the approach being agnostic to the wireless channel conditions. The performance is further enhanced by 1.54-1.67% by considering the difficulties of inference data.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Mixture-of-Agents for Edge Inference with Large Language Models</title>
<link>https://arxiv.org/abs/2412.21200</link>
<guid>https://arxiv.org/abs/2412.21200</guid>
<content:encoded><![CDATA[
<div> 关键词: Mixture-of-Agents (MoA)，大型语言模型 (LLMs)，分布式设置，边缘计算，队列稳定性条件

<br /><br />总结:
本文提出了一种在分布式环境下的混合智能体(MoA)架构，利用多个运行在用户专属边缘设备上的独立大型语言模型(LLMs)进行协同推理，以提高对用户提示的响应质量。每个设备利用去中心化的八卦算法交换信息，无需中央服务器监督。考虑到了设备内存限制问题，文章理论上计算了在合理假设下保持设备队列稳定性的条件并通过实验验证。此外，通过使用开源LLMs实现的分布式MoA实验，证明了某些配置可以产生比其他配置更高质量的回答，实验结果基于AlpacaEval 2.0基准进行评估。相关代码已开源，可在https://github.com/purbeshmitra/distributed_moa找到。 <div>
arXiv:2412.21200v1 Announce Type: new 
Abstract: Mixture-of-Agents (MoA) has recently been proposed as a method to enhance performance of large language models (LLMs), enabling multiple individual LLMs to work together for collaborative inference. This collaborative approach results in improved responses to user prompts compared to relying on a single LLM. In this paper, we consider such an MoA architecture in a distributed setting, where LLMs operate on individual edge devices, each uniquely associated with a user and equipped with its own distributed computing power. These devices exchange information using decentralized gossip algorithms, allowing different device nodes to talk without the supervision of a centralized server. In the considered setup, different users have their own LLM models to address user prompts. Additionally, the devices gossip either their own user-specific prompts or augmented prompts to generate more refined answers to certain queries. User prompts are temporarily stored in the device queues when their corresponding LLMs are busy. Given the memory limitations of edge devices, it is crucial to ensure that the average queue sizes in the system remain bounded. In this paper, we address this by theoretically calculating the queuing stability conditions for the device queues under reasonable assumptions, which we validate experimentally as well. Further, we demonstrate through experiments, leveraging open-source LLMs for the implementation of distributed MoA, that certain MoA configurations produce higher-quality responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The implementation is available at: https://github.com/purbeshmitra/distributed_moa.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Upper Confidence Bound Algorithms for Homogeneous Multi-Agent Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2111.10933</link>
<guid>https://arxiv.org/abs/2111.10933</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、分布式、同质化多臂老虎机问题、上界置信区间算法、图网络

总结:
本文研究了一个多智能体网络中的分布式同质化多臂老虎机问题。在这个问题中，N个智能体假设他们面对相同的M个手臂，并共享相同的奖励分布。每个智能体只能从其邻居处获取信息，而智能体间的邻居关系由一个固定的图描述。文章提出了两种适用于无向图的完全分布式上界置信区间（UCB）算法，分别基于经典的UCB算法和先进的Kullback-Leibler UCB算法。提出的分布式UCB1和KL-UCB算法确保了当每个智能体至少有一个邻居时，它们能够实现比单智能体更好的对数渐近遗憾性能；并且一个智能体的邻居越多，它的遗憾性能越好，这意味着整体表现优于各部分之和。此外，相同的设计框架也被扩展到有向图，通过设计一种分布式UCB1算法的变种，该算法在性能上优于单智能体的UCB1算法。 <div>
arXiv:2111.10933v4 Announce Type: replace 
Abstract: This paper studies a decentralized homogeneous multi-armed bandit problem in a multi-agent network. The problem is simultaneously solved by $N$ agents assuming they face a common set of $M$ arms and share the same arms' reward distributions. Each agent can receive information only from its neighbors, where the neighbor relationships among the agents are described by a fixed graph. Two fully decentralized upper confidence bound (UCB) algorithms are proposed for undirected graphs, respectively based on the classic algorithm and the state-of-the-art Kullback-Leibler upper confidence bound (KL-UCB) algorithm. The proposed decentralized UCB1 and KL-UCB algorithms permit each agent in the network to achieve a better logarithmic asymptotic regret than their single-agent counterparts, provided that the agent has at least one neighbor, and the more neighbors an agent has, the better regret it will have, meaning that the sum is more than its component parts. The same algorithm design framework is also extended to directed graphs through the design of a variant of the decentralized UCB1 algorithm, which outperforms the single-agent UCB1 algorithm.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Partially Labeled Data: A Conditional Distillation Approach</title>
<link>https://arxiv.org/abs/2412.18833</link>
<guid>https://arxiv.org/abs/2412.18833</guid>
<content:encoded><![CDATA[
<div> 关键词：医疗影像、联合学习（Federated Learning）、部分标注、条件蒸馏（Conditional Distillation）、ConDistFL

<br /><br />总结:
本文提出了一种名为ConDistFL的新型联邦学习框架，旨在解决医疗影像领域中多器官与病灶分割的问题。针对现有联合学习方法在处理部分标注数据时易导致模型分歧和灾难性遗忘的挑战，ConDistFL引入了条件蒸馏技术，有效利用分布式和非均匀数据集中的部分标注信息，显著提高了分割准确性。此外，ConDistFL保持了计算和通信效率，适合于现实世界的隐私保护应用。实验表明，ConDistFL不仅在内部联合会话中展现出优越的分割性能，而且在对外部未参与联合会话的数据（如不同对比度阶段的CT图像）也有出色的泛化能力。通过在3D CT和2D胸部X光数据集上的广泛评估，ConDistFL被证实是一种高效、适应性强的解决方案，适用于隐私受限环境下的医疗影像协同分割任务。 <div>
arXiv:2412.18833v1 Announce Type: new 
Abstract: In medical imaging, developing generalized segmentation models that can handle multiple organs and lesions is crucial. However, the scarcity of fully annotated datasets and strict privacy regulations present significant barriers to data sharing. Federated Learning (FL) allows decentralized model training, but existing FL methods often struggle with partial labeling, leading to model divergence and catastrophic forgetting. We propose ConDistFL, a novel FL framework incorporating conditional distillation to address these challenges. ConDistFL enables effective learning from partially labeled datasets, significantly improving segmentation accuracy across distributed and non-uniform datasets. In addition to its superior segmentation performance, ConDistFL maintains computational and communication efficiency, ensuring its scalability for real-world applications. Furthermore, ConDistFL demonstrates remarkable generalizability, significantly outperforming existing FL methods in out-of-federation tests, even adapting to unseen contrast phases (e.g., non-contrast CT images) in our experiments. Extensive evaluations on 3D CT and 2D chest X-ray datasets show that ConDistFL is an efficient, adaptable solution for collaborative medical image segmentation in privacy-constrained settings.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Swarm Contract: A Multi-Sovereign Agent Consensus Mechanism</title>
<link>https://arxiv.org/abs/2412.19256</link>
<guid>https://arxiv.org/abs/2412.19256</guid>
<content:encoded><![CDATA[
<div> 关键词：Swarm Contract、智能合约、区块链、可信执行环境、多代理机制

<br /><br />总结:
本文提出了一种名为“Swarm Contract”(Swarm)的概念，这是一种利用多代理机制处理复杂任务的新颖方式。Swarm合同集合了多个数字生命体(DLF)或自主代理(SA)，它们在可信执行环境中(TEE)共同处理大规模离链数据、动态多步骤工作流程和需要高度灵活性或迭代更新的情况。通过在链上使用简单的多签名钱包，Swarm将大部分逻辑移至链下，通过多代理共识实现最小信任，而非依赖单一的链上智能合约。文中以轻量级的离链拍卖示例——铸造并销售10,000个相同的NFT——展示了如何利用离链协调确定清算价格和完成分配，每个步骤由多个在TEE中的代理共同执行。这种方法扩展了去中心化和无需信任解决方案的应用范围，可能对DAO治理、多模态数据分析和跨链互操作性等领域产生潜在益处。 <div>
arXiv:2412.19256v1 Announce Type: new 
Abstract: Traditional smart contracts on blockchains excel at on-chain, deterministic logic. However, they have inherent limitations when dealing with large-scale off-chain data, dynamic multi-step workflows, and scenarios requiring high flexibility or iterative updates. In this paper, we propose the concept of a "Swarm Contract" (Swarm), a multi-agent mechanism wherein several digital life forms (DLF) or Sovereign Agents (SA) collectively handle complex tasks in Trusted Execution Environments (TEE). These digital entities are defined as autonomous software agents that own their code, state, and possibly on-chain assets, while operating free from centralized control.
  By leveraging a simple multi-signature wallet on-chain, Swarm moves most of the logic off-chain, achieving trust minimization through multi-agent consensus rather than a single monolithic on-chain contract. We illustrate these ideas with a lightweight off-chain auction example - minting and selling 10,000 identical NFTs - to showcase how off-chain coordination can determine a clearing price and finalize distribution, with each step performed collectively by multiple agents in TEE. This approach broadens the scope of trustless and decentralized solutions, potentially benefiting DAO governance, multi-modal data processing, and cross-chain interoperability.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mobile Traffic Prediction at the Edge Through Distributed and Deep Transfer Learning</title>
<link>https://arxiv.org/abs/2310.14456</link>
<guid>https://arxiv.org/abs/2310.14456</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通预测, 人工智能, 边缘计算, 深度迁移学习, 能耗优化

总结:<br />
本文探讨了一种基于边缘计算和深度迁移学习的完全去中心化的移动流量预测方案，旨在通过使数据保留在本地以减少能耗并通过基站站点间的协作进行优化。研究提出了一种新颖的预测框架，利用大规模测量活动获取的边缘数据集训练两种主要的深度学习架构：卷积神经网络（CNNs）和循环神经网络（RNNs）。模拟结果显示，CNN架构在准确性和能耗方面优于RNNs。在所有情况下，深度迁移学习能提升85%的准确性，并显著降低CNNs和RNNs的训练过程中的计算复杂度和能耗，分别减少了60%和90%的能量消耗。最后，文章还应用了两种先进的可解释人工智能技术来解析所得到的学习模型。 <div>
arXiv:2310.14456v2 Announce Type: replace 
Abstract: Traffic prediction represents one of the crucial tasks for smartly optimizing the mobile network. Recently, Artificial Intelligence (AI) has attracted attention to solve this problem thanks to its ability in cognizing the state of the mobile network and make intelligent decisions. Research on this topic has concentrated on making predictions in a centralized fashion, i.e., by collecting data from the different network elements and process them in a cloud center. This translates into inefficiencies due to the large amount of data transmissions and computations required, leading to high energy consumption. In this work, we investigate a fully decentralized AI solution for mobile traffic prediction that allows data to be kept locally, reducing energy consumption through collaboration among the base station sites. To do so, we propose a novel prediction framework based on edge computing and Deep Transfer Learning (DTL) techniques, using datasets obtained at the edge through a large measurement campaign. Two main Deep Learning architectures are designed based on Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) and tested under different training conditions. Simulation results show that the CNN architectures outperform the RNNs in accuracy and consume less energy. In both scenarios, DTL contributes to an accuracy enhancement in 85% of the examined cases compared to their stand-alone counterparts. Additionally, DTL significantly reduces computational complexity and energy consumption during training, resulting in a reduction of the energy footprint by 60% for CNNs and 90% for RNNs. Finally, two cutting-edge eXplainable Artificial Intelligence techniques are employed to interpret the derived learning models.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PHICOIN (PHI): The Proof of Work High-Performance Infrastructure</title>
<link>https://arxiv.org/abs/2412.17979</link>
<guid>https://arxiv.org/abs/2412.17979</guid>
<content:encoded><![CDATA[
<div> 关键词：PHICOIN (PHI)，Proof-of-Work (PoW)，ASIC，FPGA，去中心化

总结:<br />
PHICOIN（PHI）是一种基于工作量证明（PoW）机制的高性能加密货币。它旨在通过改进和创新的挖矿算法及公平设计原则，为普通用户提供参与去中心化的机遇。PHI着重解决加密货币挖矿中的中心化问题，增强了对ASIC和FPGA设备的抵抗能力，促进了更为公平的参与。本文概述了PHI的技术规格、使命以及路线图，强调其有潜力成为PoW加密货币的基础性基础设施。 <div>
arXiv:2412.17979v1 Announce Type: new 
Abstract: PHICOIN (PHI) is a high-performance cryptocurrency based on the Proof-of-Work (PoW) mechanism. It aims to provide ordinary users with decentralized participation opportunities through an improved and innovative mining algorithm and fair design principles. PHI addresses the challenges of centralization in cryptocurrency mining by enhancing resistance to ASIC and FPGA devices and promoting fair participation. This paper outlines the technical specifications, mission, and roadmap for PHI, highlighting its potential to become a foundational infrastructure for PoW cryptocurrencies.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Driven Research in Personality-Based Distributed Pair Programming</title>
<link>https://arxiv.org/abs/2412.18066</link>
<guid>https://arxiv.org/abs/2412.18066</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、人格基础、配对编程、Role-Optimization Motivation Alignment (ROMA)框架、Solana区块链

总结:
该研究旨在将区块链技术融入基于人格特质的配对编程研究中，以增强其普适性和适应性，通过内置的持续、可重复和透明的研究方式。研究提出了一种名为Role-Optimization Motivation Alignment (ROMA)的框架，将人类/AI编程角色与个体的大五人格特质相对应，以此优化个人动机并提高小型实体和本科课程中的团队生产力。进行了12个分布式设置下的准实验会话来验证基于人格的配对编程有效性。研究采用混合方法，结合了内在动机量表和定性见解，并将数据透明地存储在Solana区块链上。使用Rust和TypeScript语言开发了一个基于Web的应用程序，用于根据ROMA建议、专业知识和可用性进行伙伴匹配。结果表明，区块链可以提升研究的普遍性、可复制性和透明度，而ROMA可以提高个人动机和团队绩效。未来的工作可以关注于集成智能合约以实现透明化和版本化的数据分析。 <div>
arXiv:2412.18066v1 Announce Type: new 
Abstract: This study aims to integrate blockchain technology into personality-based pair programming research to enhance its generalizability and adaptability by offering built-in continuous, reproducible, and transparent research. In the developing Role-Optimization Motivation Alignment (ROMA) framework, human/AI programming roles align with individual Big Five personality traits, optimizing individual motivation and team productivity in Very Small Entities and undergraduate courses. Twelve quasi-experimental sessions were conducted to verify the personality-based pair programming in distributed settings. A mixed-methods approach was employed, combining intrinsic motivation inventories and qualitative insights. Data were stored transparently on the Solana blockchain, and a web-based application was developed in Rust and TypeScript languages to facilitate partner matching based on ROMA suggestions, expertise, and availability. The results suggest that blockchain can enhance research generalizability, reproducibility, and transparency, while ROMA can increase individual motivation and team performance. Future work can focus on integrating smart contracts for transparent and versioned data analysis.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Competition to Centralization: The Oligopoly in Ethereum Block Building Auctions</title>
<link>https://arxiv.org/abs/2412.18074</link>
<guid>https://arxiv.org/abs/2412.18074</guid>
<content:encoded><![CDATA[
<div> 关键词: Ethereum, Proposer-Builder Separation (PBS), MEV-Boost拍卖, 网络延迟, 中心化

总结:
本文探讨了以太坊区块生产过程中的Proposer-Builder Separation (PBS)机制，这是一种基于拍卖的流程，其中验证者可以将区块生产外包给构建者并通过MEV-Boost拍卖从构建者的竞标中获取Maximal Extractable Value (MEV)收益。通过实证博弈论分析，研究发现网络延迟和MEV机会访问优势对构建者在MEV-Boost拍卖中的投标策略和拍卖结果有显著影响。研究揭示了一个寡头动态现象：少数具备低延迟和丰富MEV资源的主导构建者受益于规模经济效应，强化了其市场力量，导致区块建造市场的中心化加剧和拍卖效率降低。这突显了公平分配构建者之间的MEV以及持续改善以太坊区块构建市场去中心化的挑战。 <div>
arXiv:2412.18074v1 Announce Type: new 
Abstract: The Ethereum block production process has evolved with the introduction of an auction-based mechanism known as Proposer-Builder Separation (PBS), allowing validators to outsource block production to builders and reap Maximal Extractable Value (MEV) revenue from builder bids in a decentralized market. In this market, builders compete in MEV-Boost auctions to have their blocks selected and earn potential MEV rewards. This paper employs empirical game-theoretic analysis to explore builders' strategic bidding incentives in MEV-Boost auctions, focusing on how advantages in network latency and access to MEV opportunities affect builders' bidding behaviors and auction outcomes. Our findings confirm an oligopolistic dynamic, where a few dominant builders, leveraging their advantages in latency and MEV access, benefit from an economy of scale that reinforces their market power, leading to increased centralization and reduced auction efficiency. Our analysis highlights the importance of fair MEV distribution among builders and the ongoing challenge of enhancing decentralization in the Ethereum block building market.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>XSema: A Novel Framework for Semantic Extraction of Cross-chain Transactions</title>
<link>https://arxiv.org/abs/2412.18129</link>
<guid>https://arxiv.org/abs/2412.18129</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链平台、跨链桥技术、交易语义、XSema、安全性检测

总结:
随着区块链平台数量的增长，独立网络间的资产和信息转移成为一个挑战，为此，跨链桥技术应运而生，通过建立通信协议促进跨链交互。然而，跨链交易的安全监管复杂性增加，需要超越传统单链检测方法的理解。本文提出了专门针对跨链环境设计的资产转移与消息传递为基础的跨链语义提取框架——XSema。实验表明，XSema在区分跨链与非跨链交易方面表现优越，对于泛化性和一般性指标分别超过现有方法9%和10%以上。此外，通过对跨链交易中的资产转移模式和消息传递事件日志进行分析，该研究为理解多区块链共存及跨链生态系统提供了新的洞见。 <div>
arXiv:2412.18129v1 Announce Type: new 
Abstract: As the number of blockchain platforms continues to grow, the independence of these networks poses challenges for transferring assets and information across chains. Cross-chain bridge technology has emerged to address this issue, establishing communication protocols to facilitate cross-chain interaction of assets and information, thereby enhancing user experience. However, the complexity of cross-chain transactions increases the difficulty of security regulation, rendering traditional single-chain detection methods inadequate for cross-chain scenarios. Therefore, understanding cross-chain transaction semantics is crucial, as it forms the foundation for cross-chain security detection tasks. Although there are existing methods for extracting transaction semantics specifically for single chains, these approaches often overlook the unique characteristics of cross-chain scenarios, limiting their applicability. This paper introduces XSema, a novel cross-chain semantic extraction framework grounded in asset transfer and message-passing, designed specifically for cross-chain contexts. Experimental results demonstrate that XSema effectively distinguishes between cross-chain and non-cross-chain transactions, surpassing existing methods by over 9% for the generality metric and over 10% for the generalization metric. Furthermore, we analyze the underlying asset transfer patterns and message-passing event logs associated with cross-chain transactions. We offer new insights into the coexistence of multiple blockchains and the cross-chain ecosystem.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>JANUS: A Stablecoin 3.0 Blueprint for Navigating the Stablecoin Trilemma Through Dual-Token Design, Multi-Collateralization, Soft Peg, and AI-Driven Stabilization</title>
<link>https://arxiv.org/abs/2412.18182</link>
<guid>https://arxiv.org/abs/2412.18182</guid>
<content:encoded><![CDATA[
<div> 关键词：JANUS、稳定币3.0协议、双代币系统、AI驱动、资本效率

总结:
本文介绍了JANUS，一个旨在同时解决稳定币三难困境——提高去中心化(D)、资本效率(E)和安全性稳定性(S)的稳定币3.0协议。JANUS基于前几代稳定币的经验，采用双代币系统(Alpha 和 Omega)，整合加密资产与现实世界资产(RWAs)，利用软挂钩机制，并运用AI驱动的稳定策略。文章构建了全面的理论框架，对D、E、S进行了正式定义，并证明了均衡存在的可能性，同时借鉴了国际贸易和开放经济宏观经济学的类比。通过引入由外部收益支持的第二代币，JANUS摆脱了庞氏动态，形成了更为稳健的基础。多抵押和软挂钩允许控制价格波动，而AI驱动的参数调整则能维持平衡。通过这些创新，JANUS力求接近稳定币三难困境的最优解，为DeFi和TradFi之间提供一个全球抗风险、通胀调整及去中心化的稳定币生态系统。正文部分概述了三难困境和JANUS的关键特点，附录中提供了更正式的数学处理，包括对去中心化、资本效率和稳定性的严格度量以及三难困境内在的优化挑战。 <div>
arXiv:2412.18182v1 Announce Type: new 
Abstract: This paper introduces JANUS, a Stablecoin 3.0 protocol designed to address the stablecoin trilemma--simultaneously improving decentralization (D), capital efficiency (E), and safety-stability (S). Building upon insights from previous stablecoin generations, JANUS leverages a dual-token system (Alpha and Omega), integrates crypto-assets and real-world assets (RWAs), employs a soft-peg mechanism, and utilizes AI-driven stabilization.
  We provide a comprehensive theoretical framework, including formal definitions of D, E, and S, along with equilibrium existence proofs and analogies drawn from international trade and open-economy macroeconomics. By introducing a second token backed by external yield, JANUS breaks from ponzinomic dynamics and creates a more robust foundation. Multi-collateralization and a soft peg enable controlled price oscillations, while AI-driven parameter adjustments maintain equilibrium.
  Through these innovations, JANUS aims to approach the center of the stablecoin trilemma, offering a globally resilient, inflation-adjusted, and decentralized stablecoin ecosystem bridging DeFi and TradFi. The main body presents a high-level overview of the trilemma and JANUS's key features, while the Appendix provides more formal mathematical treatments, including rigorous metrics for decentralization, capital efficiency, and stability, as well as the optimization challenges inherent in the trilemma.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining GPT and Code-Based Similarity Checking for Effective Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2412.18225</link>
<guid>https://arxiv.org/abs/2412.18225</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、智能合约、漏洞检测、SimilarGPT、生成预训练变换器（GPT）、代码相似性检查、安全性审计、潜在漏洞、逻辑连贯性、误报、第三方库代码、深度分析、实验结果

<br /><br />总结：
本文介绍了SimilarGPT，这是一个针对智能合约的独特漏洞识别工具，它结合了生成预训练变换器（GPT）模型与基于代码的相似性检查方法。该工具通过衡量待检代码与第三方安全库代码之间的相似度来寻找潜在漏洞，将大型语言模型（LLMs）的语义理解能力与代码相似性检查技术相结合，优化检测序列以提高逻辑连贯性和减少误报。SimilarGPT通过对智能合约中代码重用模式的分析和处理大量第三方库代码，建立了一个全面的参考代码库，并利用LLM对相似代码进行深入分析，从而能有效地识别并解释代码中的潜在漏洞。实验结果显示，SimilarGPT在检测智能合约中的漏洞方面表现出色，尤其是在减少漏检和降低误报方面具有优势。 <div>
arXiv:2412.18225v1 Announce Type: new 
Abstract: With the rapid growth of blockchain technology, smart contracts are now crucial to Decentralized Finance (DeFi) applications. Effective vulnerability detection is vital for securing these contracts against hackers and enhancing the accuracy and efficiency of security audits. In this paper, we present SimilarGPT, a unique vulnerability identification tool for smart contract, which combines Generative Pretrained Transformer (GPT) models with Code-based similarity checking methods. The main concept of the SimilarGPT tool is to measure the similarity between the code under inspection and the secure code from third-party libraries. To identify potential vulnerabilities, we connect the semantic understanding capability of large language models (LLMs) with Code-based similarity checking techniques. We propose optimizing the detection sequence using topological ordering to enhance logical coherence and reduce false positives during detection. Through analysis of code reuse patterns in smart contracts, we compile and process extensive third-party library code to establish a comprehensive reference codebase. Then, we utilize LLM to conduct an indepth analysis of similar codes to identify and explain potential vulnerabilities in the codes. The experimental findings indicate that SimilarGPT excels in detecting vulnerabilities in smart contracts, particularly in missed detections and minimizing false positives.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Multi-Robot Semantic Navigation Through Multimodal Chain-of-Thought Score Collaboration</title>
<link>https://arxiv.org/abs/2412.18292</link>
<guid>https://arxiv.org/abs/2412.18292</guid>
<content:encoded><![CDATA[
<div> 关键词: 多机器人系统、协同导航、语义探索、分布式规划、Multimodal Chain-of-Thought Co-Navigation (MCoCoNav)

总结:
为提高多机器人在陌生环境中的探索效率，本文提出了一种名为Multimodal Chain-of-Thought Co-Navigation (MCoCoNav)的模块化协作语义导航方法。MCoCoNav利用多模态Chain-of-Thought结合视觉感知与Vision Language Models (VLMs)，通过概率评分评估探索价值，从而降低时间成本并提供稳定输出。同时，通过使用全局语义地图作为通信桥梁，既能减少通信开销，又能整合观察结果。机器人根据反映探索趋势的评分，决定是去探索新的前沿点还是重新访问历史节点。实验在HM3D_v0.2和MP3D数据集上验证了该方法的有效性。相关代码已开源，可在https://github.com/FrankZxShen/MCoCoNav.git获取。 <div>
arXiv:2412.18292v1 Announce Type: new 
Abstract: Understanding how humans cooperatively utilize semantic knowledge to explore unfamiliar environments and decide on navigation directions is critical for house service multi-robot systems. Previous methods primarily focused on single-robot centralized planning strategies, which severely limited exploration efficiency. Recent research has considered decentralized planning strategies for multiple robots, assigning separate planning models to each robot, but these approaches often overlook communication costs. In this work, we propose Multimodal Chain-of-Thought Co-Navigation (MCoCoNav), a modular approach that utilizes multimodal Chain-of-Thought to plan collaborative semantic navigation for multiple robots. MCoCoNav combines visual perception with Vision Language Models (VLMs) to evaluate exploration value through probabilistic scoring, thus reducing time costs and achieving stable outputs. Additionally, a global semantic map is used as a communication bridge, minimizing communication overhead while integrating observational results. Guided by scores that reflect exploration trends, robots utilize this map to assess whether to explore new frontier points or revisit history nodes. Experiments on HM3D_v0.2 and MP3D demonstrate the effectiveness of our approach. Our code is available at https://github.com/FrankZxShen/MCoCoNav.git.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification</title>
<link>https://arxiv.org/abs/2412.18470</link>
<guid>https://arxiv.org/abs/2412.18470</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、庞氏骗局、检测方法、PonziLens+、可视化分析

总结:
随着智能合约的普及，基于区块链的智能庞氏骗局给加密货币投资者带来了重大经济损失。针对这一问题，文章首先通过文献回顾和专家访谈，从智能合约字节码中提取具有语义意义的行为来表征执行行为。进而提出了一种名为PonziLens+的新型视觉分析方法，该方法能够直观并可靠地分析这些执行行为中的庞氏骗局相关特征。PonziLens+具备三个可视化模块，可以逐层详细展示智能合约的所有潜在行为，并突出显示欺诈性特征。通过使用PonziLens+，智能合约投资者和审计员能更自信地识别出任何智能庞氏骗局。为了验证其有效性和可用性，研究者进行了两个案例研究及深入的用户访谈，涉及12位领域专家和普通投资者。结果表明，PonziLens+在有效识别智能庞氏骗局方面表现出了优越性与易用性。

<br /><br /> <div>
arXiv:2412.18470v1 Announce Type: new 
Abstract: With the prevalence of smart contracts, smart Ponzi schemes have become a common fraud on blockchain and have caused significant financial loss to cryptocurrency investors in the past few years. Despite the critical importance of detecting smart Ponzi schemes, a reliable and transparent identification approach adaptive to various smart Ponzi schemes is still missing. To fill the research gap, we first extract semantic-meaningful actions to represent the execution behaviors specified in smart contract bytecodes, which are derived from a literature review and in-depth interviews with domain experts. We then propose PonziLens+, a novel visual analytic approach that provides an intuitive and reliable analysis of Ponzi-scheme-related features within these execution behaviors. PonziLens+ has three visualization modules that intuitively reveal all potential behaviors of a smart contract, highlighting fraudulent features across three levels of detail. It can help smart contract investors and auditors achieve confident identification of any smart Ponzi schemes. We conducted two case studies and in-depth user interviews with 12 domain experts and common investors to evaluate PonziLens+. The results demonstrate the effectiveness and usability of PonziLens+ in achieving an effective identification of smart Ponzi schemes.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PrettiSmart: Visual Interpretation of Smart Contracts via Simulation</title>
<link>https://arxiv.org/abs/2412.18484</link>
<guid>https://arxiv.org/abs/2412.18484</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、区块链技术、可视化、执行模拟、PrettiSmart

总结:
本文提出了一种名为PrettiSmart的新颖可视化方法，旨在通过执行模拟帮助投资者直观并可靠地理解智能合约的行为。面对智能合约的复杂源代码以及实际行为与预期可能存在的差异，该方法开发了一个能够全面捕获多种真实世界智能合约行为的模拟器，涵盖了多个投资者和各种智能合约功能的情况。PrettiSmart包括两个模块：Simulation Overview Module 使用条形码设计，为每次模拟提供视觉概览；Simulation Detail Module 则采用增强型序列设计展示每个模拟中的交易细节，如函数调用序列、数字货币流动及状态变量变化。通过PrettiSmart，投资者可以直观地检查并理解智能合约的工作方式。文章通过两例案例研究和对12位投资者的深度访谈评估了PrettiSmart的有效性和可用性，结果显示PrettiSmart对于简化智能合约解释具有显著作用。 <div>
arXiv:2412.18484v1 Announce Type: new 
Abstract: Smart contracts are the fundamental components of blockchain technology. They are programs to determine cryptocurrency transactions, and are irreversible once deployed, making it crucial for cryptocurrency investors to understand the cryptocurrency transaction behaviors of smart contracts comprehensively. However, it is a challenging (if not impossible) task for investors, as they do not necessarily have a programming background to check the complex source code. Even for investors with certain programming skills, inferring all the potential behaviors from the code alone is still difficult, since the actual behaviors can be different when different investors are involved. To address this challenge, we propose PrettiSmart, a novel visualization approach via execution simulation to achieve intuitive and reliable visual interpretation of smart contracts. Specifically, we develop a simulator to comprehensively capture most of the possible real-world smart contract behaviors, involving multiple investors and various smart contract functions. Then, we present PrettiSmart to intuitively visualize the simulation results of a smart contract, which consists of two modules: The Simulation Overview Module is a barcode-based design, providing a visual summary for each simulation, and the Simulation Detail Module is an augmented sequential design to display the cryptocurrency transaction details in each simulation, such as function call sequences, cryptocurrency flows, and state variable changes. It can allow investors to intuitively inspect and understand how a smart contract will work. We evaluate PrettiSmart through two case studies and in-depth user interviews with 12 investors. The results demonstrate the effectiveness and usability of PrettiSmart in facilitating an easy interpretation of smart contracts.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs</title>
<link>https://arxiv.org/abs/2412.18588</link>
<guid>https://arxiv.org/abs/2412.18588</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、机器人、自然语言、行为约束、公共区块链

总结:
本文探讨了使用大型语言模型（LLMs）控制物理机器人的优势、限制和特点。通过四个LLMs之间的基于人类语言的数据总线（通过WebSocket和ROS2消息传递实现）进行通信，即使数据融合循环仅为1Hz，中央数据总线运行速度极低（接近人脑的约40比特/秒），也能实现丰富的行为和良好的任务表现。自然语言用于LLM间的交流，使得人类可以直观地观察到机器人的思考过程，并能以普通英语编写规则轻松引导系统行为。这些规则被不可变地写入全球公共、抗审查的图灵完备计算机——以太坊中。文章提出，通过将自然语言作为交互AI之间数据总线，并利用不可变的公共区块链存储行为约束，有可能构建出性能出众、可升级并持久符合人类意愿的机器人。 <div>
arXiv:2412.18588v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are compact representations of all public knowledge of our physical environment and animal and human behaviors. The application of LLMs to robotics may offer a path to highly capable robots that perform well across most human tasks with limited or even zero tuning. Aside from increasingly sophisticated reasoning and task planning, networks of (suitably designed) LLMs offer ease of upgrading capabilities and allow humans to directly observe the robot's thinking. Here we explore the advantages, limitations, and particularities of using LLMs to control physical robots. The basic system consists of four LLMs communicating via a human language data bus implemented via web sockets and ROS2 message passing. Surprisingly, rich robot behaviors and good performance across different tasks could be achieved despite the robot's data fusion cycle running at only 1Hz and the central data bus running at the extremely limited rates of the human brain, of around 40 bits/s. The use of natural language for inter-LLM communication allowed the robot's reasoning and decision making to be directly observed by humans and made it trivial to bias the system's behavior with sets of rules written in plain English. These rules were immutably written into Ethereum, a global, public, and censorship resistant Turing-complete computer. We suggest that by using natural language as the data bus among interacting AIs, and immutable public ledgers to store behavior constraints, it is possible to build robots that combine unexpectedly rich performance, upgradability, and durable alignment with humans.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems</title>
<link>https://arxiv.org/abs/2412.18601</link>
<guid>https://arxiv.org/abs/2412.18601</guid>
<content:encoded><![CDATA[
<div> 关键词: GameFi、AI代理、大型语言模型、区块链技术、DeFi机制

总结:<br />
本文提出了一个将高级AI代理集成到GameFi平台以改革游戏金融生态系统的创新方法。这些AI代理利用GPT-4和Claude AI等先进的大型语言模型，实现与玩家的主动、适应性和情境丰富的互动，影响游戏叙事和经济系统。针对现有GameFi平台缺乏沉浸式AI交互和社区参与机制的问题，该生态系统通过深度融合AI代理与区块链技术，创建了一个共识驱动、去中心化的环境，使创作者能够从中获利，并促进玩家与创作者之间的民主协作。此外，通过将DeFi机制嵌入游戏体验中，文章提出的方法增强了经济参与度并为游戏中提供了新的金融互动机会，提升了玩家的沉浸感和留存率。总之，该研究项目显著推动了GameFi领域的前沿发展，为整个游戏行业提供了一种结合智能AI和DeFi元素，打造更富吸引力、经济稳健且以社区为中心的游戏环境的方法论。 <div>
arXiv:2412.18601v1 Announce Type: new 
Abstract: In the rapidly evolving landscape of GameFi, a fusion of gaming and decentralized finance (DeFi), there exists a critical need to enhance player engagement and economic interaction within gaming ecosystems. Our GameFi ecosystem aims to fundamentally transform this landscape by integrating advanced embodied AI agents into GameFi platforms. These AI agents, developed using cutting-edge large language models (LLMs), such as GPT-4 and Claude AI, are capable of proactive, adaptive, and contextually rich interactions with players. By going beyond traditional scripted responses, these agents become integral participants in the game's narrative and economic systems, directly influencing player strategies and in-game economies. We address the limitations of current GameFi platforms, which often lack immersive AI interactions and mechanisms for community engagement or creator monetization. Through the deep integration of AI agents with blockchain technology, we establish a consensus-driven, decentralized GameFi ecosystem. This ecosystem empowers creators to monetize their contributions and fosters democratic collaboration among players and creators. Furthermore, by embedding DeFi mechanisms into the gaming experience, we enhance economic participation and provide new opportunities for financial interactions within the game. Our approach enhances player immersion and retention and advances the GameFi ecosystem by bridging traditional gaming with Web3 technologies. By integrating sophisticated AI and DeFi elements, we contribute to the development of more engaging, economically robust, and community-centric gaming environments. This project represents a significant advancement in the state-of-the-art in GameFi, offering insights and methodologies that can be applied throughout the gaming industry.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision-Making</title>
<link>https://arxiv.org/abs/2308.10721</link>
<guid>https://arxiv.org/abs/2308.10721</guid>
<content:encoded><![CDATA[
<div> 关键词：协调技能、多智能体、独立决策、协同行为、Coordinated QMIX (CoMIX)

总结:<br />
本文提出了一个用于训练分布式代理以实现灵活政策下 Emergent 协调能力的新框架——协调 QMIX（CoMIX）。该框架使代理能够在共享环境中朝着共同目标协同作业，同时允许个体层面的独立决策。CoMIX 将自私和协作行为建模为每个代理决策过程中的增量步骤，从而使代理能够根据不同情境动态调整其行为，平衡独立性和协作性。实验结果表明，CoMIX 在各种模拟环境中在协作任务上优于基线，验证了我们逐步递增方法对于提高多智能体系统中协调性能的有效性。 <div>
arXiv:2308.10721v3 Announce Type: replace 
Abstract: Robust coordination skills enable agents to operate cohesively in shared environments, together towards a common goal and, ideally, individually without hindering each other's progress. To this end, this paper presents Coordinated QMIX (CoMIX), a novel training framework for decentralized agents that enables emergent coordination through flexible policies, allowing at the same time independent decision-making at individual level. CoMIX models selfish and collaborative behavior as incremental steps in each agent's decision process. This allows agents to dynamically adapt their behavior to different situations balancing independence and collaboration. Experiments using a variety of simulation environments demonstrate that CoMIX outperforms baselines on collaborative tasks. The results validate our incremental approach as effective technique for improving coordination in multi-agent systems.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Liquid Staking Tokens (LSTs) and Emerging Trends in Restaking</title>
<link>https://arxiv.org/abs/2404.00644</link>
<guid>https://arxiv.org/abs/2404.00644</guid>
<content:encoded><![CDATA[
<div> 关键词：Liquid staking, Restaking, Liquid Staking Tokens (LSTs), Liquid Restaking Tokens (LRTs), Decentralized Finance (DeFi)

<br /><br />总结:
本文介绍了液态staking及其衍生的restaking在去中心化金融（DeFi）领域的创新应用。文章重点探讨了液态staking协议的技术和经济模型框架，具体分析了包括节点运营商选择、staking奖励分配以及slashing在内的协议机制。通过对液态staking代币(LSTs)性能的实证分析，揭示了协议设计与市场动态对其市场价值的影响。同时，文章讨论了restaking的最新进展及其相关的风险与安全影响，并回顾了液态staking和restaking领域的现有文献。 <div>
arXiv:2404.00644v2 Announce Type: replace 
Abstract: Liquid staking and restaking represent recent innovations in Decentralized Finance (DeFi) that garnered user interest and capital. Liquid Staking Tokens (LSTs), tokenized representations of staked tokens on Proof-of-Stake (PoS) blockchains, are the leading staking method. LSTs offer users the ability to earn staking rewards while maintaining liquidity, enabling seamless integration into DeFi protocols and free tradeability. Restaking builds upon this concept by allowing staked tokens, LSTs or native Bitcoin tokens to secure additional protocols and PoS chains for supplementary rewards. Liquid Restaking Tokens (LRTs) unlock liquidity of restaked assets. This Systematization of Knowledge (SoK) establishes a comprehensive framework for the technical and economic models of liquid staking protocols. Using this framework, we systematically compare protocols mechanics, including node operator selection, staking reward distribution, and slashing. Our empirical analysis of token performance reveals that protocol design and market dynamics impact token market value. We further present the recent developments in restaking and discuss associated risks and security implications. Lastly, we review the emerging literature on liquid staking and restaking.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Neonpool: Reimagining cryptocurrency transaction pools for lightweight clients and IoT devices</title>
<link>https://arxiv.org/abs/2412.16217</link>
<guid>https://arxiv.org/abs/2412.16217</guid>
<content:encoded><![CDATA[
<div> 关键词：Neonpool，交易池，内存优化，Bloom过滤器，加密货币网络

总结:<br />
本文介绍了创新性地使用Bloom过滤器变体进行交易池优化的方案——Neonpool。Neonpool能显著降低加密货币网络中全节点部署的交易池内存占用，其准确率超过99.99%地验证并转发交易，并且无需进行硬分叉。该解决方案特别适合轻量级加密货币客户端以及资源受限的设备，如浏览器、系统芯片、移动设备或物联网设备。<br /> <div>
arXiv:2412.16217v1 Announce Type: new 
Abstract: The transaction pool plays a critical role in processing and disseminating transactions in cryptocurrency networks. However, increasing transaction loads strain the resources of full node deployments. We present \textit{Neonpool}, an innovative transaction pool optimization using bloom filter variants, which reduces the memory footprint of the transaction pool to a fraction. Implemented in C++ and benchmarked using a unique Bitcoin and Ethereum dataset, our solution verifies and forwards transactions with over 99.99\% accuracy and does not necessitate a hard fork. \textit{Neonpool} is ideally suited for lightweight cryptocurrency clients and for resource-constrained devices such as browsers, systems-on-a-chip, mobile or IoT devices.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>"ScatSpotter" 2024 -- A Distributed Dog Poop Detection Dataset</title>
<link>https://arxiv.org/abs/2412.16473</link>
<guid>https://arxiv.org/abs/2412.16473</guid>
<content:encoded><![CDATA[
<div> 关键词: 狗粪图像数据集、人工智能标注、像素精度、分布式发布、环保考量

总结:
本文介绍了新的“活”数据集——一个目前包含42GB的手机拍摄狗粪图像数据库，该库具有手动或AI辅助绘制的多边形标签，共有6k张全分辨率图片和4k个详细注释。自2020年末开始收集与注释工作以来，该数据库每月以约1GB的速度增长。研究者训练了VIT和MaskRCNN基线模型来探索该数据集的难度，最佳模型在包含691张图像的验证集上取得了0.858的像素级平均精度，在独立采集的30张贡献者测试集上达到了0.847。数据集通过三种不同的分布方式（集中式：Girder，分布式：IPFS和BitTorrent）公开提供，并研究了不同方法的优缺点以及在可靠分享开放科学数据方面的可行性。实验代码已在GitHub上托管，数据依照Creative Commons Attribution 4.0 International许可协议发布，同时提供了模型权重。文章还量化了实验硬件、时间、能源消耗及排放量。 <div>
arXiv:2412.16473v1 Announce Type: new 
Abstract: We introduce a new -- currently 42 gigabyte -- ``living'' dataset of phone images of dog feces, annotated with manually drawn or AI-assisted polygon labels. There are 6k full resolution images and 4k detailed polygon annotations. The collection and annotation of images started in late 2020 and the dataset grows by roughly 1GB a month. We train VIT and MaskRCNN baseline models to explore the difficulty of the dataset. The best model achieves a pixelwise average precision of 0.858 on a 691-image validation set and 0.847 on a small independently captured 30-image contributor test set. The most recent snapshot of dataset is made publicly available through three different distribution methods: one centralized (Girder) and two decentralized (IPFS and BitTorrent). We study of the trade-offs between distribution methods and discuss the feasibility of each with respect to reliably sharing open scientific data. The code to reproduce the experiments is hosted on GitHub, and the data is published under the Creative Commons Attribution 4.0 International license. Model weights are made publicly available with the dataset. Experimental hardware, time, energy, and emissions are quantified.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Raft Distributed System for Multi-access Edge Computing Sharing Resources</title>
<link>https://arxiv.org/abs/2412.16774</link>
<guid>https://arxiv.org/abs/2412.16774</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-access Edge Computing, RAFT共识算法, 区块链, Deep Deterministic Policy Gradient (DDPG), 系统延迟

<br /><br />总结:
本文提出了利用RAFT共识算法和区块链技术改进Multi-access Edge Computing (MEC)系统安全性和效率的研究方案。通过引入RAFT共识算法和拍卖理论，使边缘设备能更好地决策如何响应客户端请求。同时，文章还提出使用Deep Deterministic Policy Gradient (DDPG)算法在由N个边缘节点组成的集群中执行任务分配的竞拍过程，以降低整体系统的延迟。该提案假设每个边缘节点都包含一系列待执行的任务，通过实施DDPG算法来决定哪个边缘节点最适合执行客户端提供的任务。 <div>
arXiv:2412.16774v1 Announce Type: new 
Abstract: Researchers all over the world are employing a variety of analysis approaches in attempt to provide a safer and faster solution for sharing resources via a Multi-access Edge Computing system. Multi-access Edge Computing (MEC) is a job-sharing method within the edge server network whose main aim is to maximize the pace of the computing process, resulting in a more powerful and enhanced user experience. Although there are many other options when it comes to determining the fastest method for computing processes, our paper introduces a rather more extensive change to the system model to assure no data loss and/or task failure due to any scrutiny in the edge node cluster. RAFT, a powerful consensus algorithm, can be used to introduce an auction theory approach in our system, which enables the edge device to make the best decision possible regarding how to respond to a request from the client. Through the use of the RAFT consensus, blockchain may be used to improve the safety, security, and efficiency of applications by deploying it on trustful edge base stations. In addition to discussing the best-distributed system approach for our (MEC) system, a Deep Deterministic Policy Gradient (DDPG) algorithm is also presented in order to reduce overall system latency. Assumed in our proposal is the existence of a cluster of N Edge nodes, each containing a series of tasks that require execution. A DDPG algorithm is implemented in this cluster so that an auction can be held within the cluster of edge nodes to decide which edge node is best suited for performing the task provided by the client.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fed-ZOE: Communication-Efficient Over-the-Air Federated Learning via Zeroth-Order Estimation</title>
<link>https://arxiv.org/abs/2412.16779</link>
<guid>https://arxiv.org/abs/2412.16779</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, over-the-air FL (OtA-FL), communication overhead, gradient compression, federated zeroth-order estimation (Fed-ZOE)

总结:

随着6G及未来网络变得日益复杂和互联，联邦学习（FL）作为一种重要范式，可安全高效地利用分布式边缘数据进行AI训练。过空气隙联邦学习（OtA-FL）利用通信信号的叠加性质，实现与边缘设备数量无关的恒定通信开销。然而，空中训练神经网络仍会产生大量通信成本，因为传输符号数量等于可训练参数的数量。为解决此问题，通常采用的方法是通过梯度压缩和梯度稀疏化减少传输符号数，但这些方法与OtA-FL不兼容，会破坏其叠加特性。本文提出了一种名为联邦零阶估计（Fed-ZOE）的新框架，灵感来源于常用于零阶优化（ZOO）的随机梯度估计器（RGE）。在Fed-ZOE中，边缘设备按照标准FL的方式执行本地权重更新，而非发送完整的梯度向量，而是将本地模型更新向量以几个局部模型更新向量与随机向量的标量乘积形式发送给参数服务器（PS）。这些标量值使得PS能够使用RGE技巧以极低开销重构梯度，同时保持叠加属性。与常规利用RGE进行逐步梯度下降的ZOO不同，Fed-ZOE在传输前对本地模型更新向量进行压缩，从而实现更高的准确性和计算效率。数值评估结果显示，在CIFAR-10、TinyImageNet、SVHN、CIFAR-100和Brain-CT等数据集上，Fed-ZOE能够在大幅降低通信成本的同时，达到与Fed-OtA相当的性能。 <div>
arXiv:2412.16779v1 Announce Type: new 
Abstract: As 6G and beyond networks grow increasingly complex and interconnected, federated learning (FL) emerges as an indispensable paradigm for securely and efficiently leveraging decentralized edge data for AI. By virtue of the superposition property of communication signals, over-the-air FL (OtA-FL) achieves constant communication overhead irrespective of the number of edge devices (EDs). However, training neural networks over the air still incurs substantial communication costs, as the number of transmitted symbols equals the number of trainable parameters. To alleviate this issue, the most straightforward approach is to reduce the number of transmitted symbols by 1) gradient compression and 2) gradient sparsification. Unfortunately, these methods are incompatible with OtA-FL due to the loss of its superposition property. In this work, we introduce federated zeroth-order estimation (Fed-ZOE), an efficient framework inspired by the randomized gradient estimator (RGE) commonly used in zeroth-order optimization (ZOO). In FedZOE, EDs perform local weight updates as in standard FL, but instead of transmitting full gradient vectors, they send compressed local model update vectors in the form of several scalar-valued inner products between the local model update vectors and random vectors. These scalar values enable the parameter server (PS) to reconstruct the gradient using the RGE trick with highly reduced overhead, as well as preserving the superposition property. Unlike conventional ZOO leveraging RGE for step-wise gradient descent, Fed-ZOE compresses local model update vectors before transmission, thereby achieving higher accuracy and computational efficiency. Numerical evaluations using ResNet-18 on datasets such as CIFAR-10, TinyImageNet, SVHN, CIFAR-100, and Brain-CT demonstrate that Fed-ZOE achieves performance comparable to Fed-OtA while drastically reducing communication costs.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedCross: Intertemporal Federated Learning Under Evolutionary Games</title>
<link>https://arxiv.org/abs/2412.16968</link>
<guid>https://arxiv.org/abs/2412.16968</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 移动性管理, 通信开销, 动态决策, 奖励分配

<br /><br />总结:
本文提出了一种名为FedCross的跨时间激励框架，用于解决联邦学习（Federated Learning）中因移动设备高流动性、间歇性连接和带宽限制导致的模型更新问题。FedCross分为两个阶段：第一阶段，采用多目标迁移算法优化任务分配，考虑资源约束并利用演化博弈论预测用户比例动态变化以减少频繁迁移；第二阶段，运用采购拍卖机制对基站进行奖励分配，确保提供优质模型的基站得到最优补偿，从而激励用户持续参与并保障FedCross的整体可行性。实验结果验证了FedCross理论上的合理性及其显著降低通信开销的效果。 <div>
arXiv:2412.16968v1 Announce Type: new 
Abstract: Federated Learning (FL) mitigates privacy leakage in decentralized machine learning by allowing multiple clients to train collaboratively locally. However, dynamic mobile networks with high mobility, intermittent connectivity, and bandwidth limitation severely hinder model updates to the cloud server. Although previous studies have typically addressed user mobility issue through task reassignment or predictive modeling, frequent migrations may result in high communication overhead. Overcoming this obstacle involves not only dealing with resource constraints, but also finding ways to mitigate the challenges posed by user migrations. We therefore propose an intertemporal incentive framework, FedCross, which ensures the continuity of FL tasks by migrating interrupted training tasks to feasible mobile devices. Specifically, FedCross comprises two distinct stages. In Stage 1, we address the task allocation problem across regions under resource constraints by employing a multi-objective migration algorithm to quantify the optimal task receivers. Moreover, we adopt evolutionary game theory to capture the dynamic decision-making of users, forecasting the evolution of user proportions across different regions to mitigate frequent migrations. In Stage 2, we utilize a procurement auction mechanism to allocate rewards among base stations, ensuring that those providing high-quality models receive optimal compensation. This approach incentivizes sustained user participation, thereby ensuring the overall feasibility of FedCross. Finally, experimental results validate the theoretical soundness of FedCross and demonstrate its significant reduction in communication overhead.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the ETHOS of AI Agents: An Ethical Technology and Holistic Oversight System</title>
<link>https://arxiv.org/abs/2412.17114</link>
<guid>https://arxiv.org/abs/2412.17114</guid>
<content:encoded><![CDATA[
<div> 关键词：AI治理、Web3技术、区块链、智能合约、去中心化自治组织<br /><br />总结:
在未来日益由机器智能定义的世界中，如何管理和整合AI进入社会至关重要。文章指出现有的AI治理体系未能充分应对AI代理的崛起和集中与分散治理模型之间的辩论。为填补这一空白，提出了“伦理技术和全面监督系统”框架（ETHOS），该框架利用Web3技术，包括区块链、智能合约、去中心化自治组织和灵魂绑定代币，建立了一个去中心化的全球AI代理人注册库。ETHOS引入了AI特定法律实体的概念，使这些系统能够承担有限责任并通过保险和合规监控确保问责制。此外，该框架强调需要通过公共教育、透明度和国际协调等方式采取协作参与式的AI治理方法。ETHOS在创新与道德责任之间寻求平衡，为负责任地将AI代理人融入社会提供了前瞻性策略。最后，本文反映了我们所定义的一个新跨学科领域——处于AI、Web3和社会交汇点的系统思维的出现。 <div>
arXiv:2412.17114v1 Announce Type: new 
Abstract: In a world increasingly defined by machine intelligence, the future depends on how we govern the development and integration of AI into society. Recent initiatives, such as the EU AI Act, EDPB opinion, U.S. Bipartisan House Task Force and NIST AI Risk Management Report, highlight the urgent need for robust governance frameworks to address the challenges posed by advancing AI technologies. However, existing frameworks fail to adequately address the rise of AI agents or the ongoing debate between centralized and decentralized governance models. To bridge these gaps, we propose the Ethical Technology and Holistic Oversight System framework, which leverages Web3 technologies, including blockchain, smart contracts, decentralized autonomous organizations, and soulbound tokens, to establish a decentralized global registry for AI agents. ETHOS incorporates the concept of AI specific legal entities, enabling these systems to assume limited liability and ensuring accountability through mechanisms like insurance and compliance monitoring. Additionally, the framework emphasizes the need for a collaborative, participatory approach to AI governance, engaging diverse stakeholders through public education, transparency, and international coordination. ETHOS balances innovation with ethical accountability, providing a forward looking strategy for the responsible integration of AI agents into society. Finally, this exploration reflects the emergence of a new interdisciplinary field we define as Systems Thinking at the Intersection of AI, Web3, and Society.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Synergistic Integration of Blockchain and Software-Defined Networking in the Internet of Energy Systems</title>
<link>https://arxiv.org/abs/2412.17530</link>
<guid>https://arxiv.org/abs/2412.17530</guid>
<content:encoded><![CDATA[
<div> 关键词: Peer-to-peer能源交易, 智能电网, 电动车辆能源管理, 软件定义网络, 区块链

总结:
本文探讨了利用软件定义网络(SDN)和区块链技术在互联网能源(IoE)领域的现状及应用方案。这些方案被归类为两类：一类是以区块链增强SDN，另一类则是同时利用两者来提升解决方案。文章指出了区块链在IoE中的三种应用场景：去中心化SDN控制平面、作为去中心化平台以及加强安全性措施。同时，SDN则分别扮演性能增强器、传统网络替代品和仅作为控制与管理框架的角色。SDN与区块链的融合能在IoE中带来性能提升、增强安全性、实现去中心化操作并消除SDN控制平面中的单点故障问题。然而，也提出了未来可能的研究方向，包括能源效率、智能合约管理和可扩展性等问题。 <div>
arXiv:2412.17530v1 Announce Type: new 
Abstract: Peer-to-peer (P2P) energy trading, Smart Grids (SG), and electric vehicle energy management are integral components of the Internet of Energy (IoE) field. The integration of Software-Defined Networks (SDNs) and Blockchain (BC) technologies into the IoE domain offers potential benefits that have only been studied in the literature in a few works. In this paper, we investigate the state-of-art solutions that leverage both SDNs and blockchain within the realm of the IoE. We categorize these solutions based on the method of integrating SDN and BC into two categories. The first category is the blockchain for SDN, where blockchain enhances the SDN directly. The second category is blockchain and SDN, where both technologies are used to enhance the proposed solutions. We identify three distinct blockchain applications based on their usage: decentralizing the SDN control plane, serving as a decentralized platform, and improving security measures. Similarly, we observe that SDN serves as a performance enhancer, a substitute for traditional networking, and solely as a control and management framework. It is posited that integrating SDNs and blockchain into IoE leads to performance enhancements, improves security, enables decentralized operations, and eliminates single points of failure in the SDN control plane. Additionally, some unaddressed issues, such as energy efficiency, smart contract management, and scalability, are discussed as potential future directions.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.17565</link>
<guid>https://arxiv.org/abs/2412.17565</guid>
<content:encoded><![CDATA[
<div> 关键词: 细胞ular流量预测、机器学习、能源消耗、Spiking神经网络、Echo状态网络

总结:<br />
本文探讨了细胞通信流量预测的重要性及其面临的海量数据处理挑战。研究对比了传统机器学习算法（如卷积神经网络和多层感知机）与两种生物启发式模型——Spiking神经网络(SNNs)和Echo状态网络(ESNs)在预测性能和能效方面的表现。实验在集中式和联邦学习环境中实施这些模型，以分析其在分布式系统中的效果和能耗。结果表明，生物启发式模型能够在保持与传统架构相当的预测精度的同时，显著降低能源消耗。此外，联邦学习实现的能效在分散环境下特别是在与生物启发式模型结合使用时也得到了评估。这些发现为可持续和隐私保护的细胞通信流量预测提供了采用生物启发式模型的潜在价值。 <div>
arXiv:2412.17565v1 Announce Type: new 
Abstract: Cellular traffic forecasting is a critical task that enables network operators to efficiently allocate resources and address anomalies in rapidly evolving environments. The exponential growth of data collected from base stations poses significant challenges to processing and analysis. While machine learning (ML) algorithms have emerged as powerful tools for handling these large datasets and providing accurate predictions, their environmental impact, particularly in terms of energy consumption, is often overlooked in favor of their predictive capabilities. This study investigates the potential of two bio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing through Echo State Networks (ESNs) for cellular traffic forecasting. The evaluation focuses on both their predictive performance and energy efficiency. These models are implemented in both centralized and federated settings to analyze their effectiveness and energy consumption in decentralized systems. Additionally, we compare bio-inspired models with traditional architectures, such as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs), to provide a comprehensive evaluation. Using data collected from three diverse locations in Barcelona, Spain, we examine the trade-offs between predictive accuracy and energy demands across these approaches. The results indicate that bio-inspired models, such as SNNs and ESNs, can achieve significant energy savings while maintaining predictive accuracy comparable to traditional architectures. Furthermore, federated implementations were tested to evaluate their energy efficiency in decentralized settings compared to centralized systems, particularly in combination with bio-inspired models. These findings offer valuable insights into the potential of bio-inspired models for sustainable and privacy-preserving cellular traffic forecasting.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SMAC-Hard: Enabling Mixed Opponent Strategy Script and Self-play on SMAC</title>
<link>https://arxiv.org/abs/2412.17707</link>
<guid>https://arxiv.org/abs/2412.17707</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Reinforcement Learning (MARL)，StarCraft Multi-Agent Challenge (SMAC)，SMAC-HARD，adversarial policies，black-box testing framework

总结:<br />
本文针对多智能体强化学习（MARL）领域中，随着StarCraft Multi-Agent Challenge (SMAC)环境的普及，一些算法已接近最优性能，导致评估准确性降低的问题。文章指出了SMAC环境中默认对手策略缺乏多样性，使得算法倾向于过拟合并利用非预期漏洞而非学习稳健策略。为解决这些问题，研究者提出了SMAC-HARD，一个增强训练鲁棒性和全面性评价的新基准，其特点包括可定制对手策略、敌对策略的随机化以及支持MARL自我对战的接口。此外，他们还引入了一个黑盒测试框架，用于在不暴露于编辑过的对手脚本的情况下训练代理，然后通过这些脚本对其进行测试，以评估MARL算法的策略覆盖范围和适应能力。实验结果显示，SMAC-HARD中的修改和混合策略对手给现有的广泛使用和最先进的算法带来了重大挑战，而黑盒策略测试则表明，将学习到的策略转移到未见过的敌人上具有较大困难。SMAC-HARD被认为是推动下一代MARL算法及其自我对战方法发展的重要里程碑。相关代码已在https://github.com/devindeng94/smac-hard 上公开。 <div>
arXiv:2412.17707v1 Announce Type: new 
Abstract: The availability of challenging simulation environments is pivotal for advancing the field of Multi-Agent Reinforcement Learning (MARL). In cooperative MARL settings, the StarCraft Multi-Agent Challenge (SMAC) has gained prominence as a benchmark for algorithms following centralized training with decentralized execution paradigm. However, with continual advancements in SMAC, many algorithms now exhibit near-optimal performance, complicating the evaluation of their true effectiveness. To alleviate this problem, in this work, we highlight a critical issue: the default opponent policy in these environments lacks sufficient diversity, leading MARL algorithms to overfit and exploit unintended vulnerabilities rather than learning robust strategies. To overcome these limitations, we propose SMAC-HARD, a novel benchmark designed to enhance training robustness and evaluation comprehensiveness. SMAC-HARD supports customizable opponent strategies, randomization of adversarial policies, and interfaces for MARL self-play, enabling agents to generalize to varying opponent behaviors and improve model stability. Furthermore, we introduce a black-box testing framework wherein agents are trained without exposure to the edited opponent scripts but are tested against these scripts to evaluate the policy coverage and adaptability of MARL algorithms. We conduct extensive evaluations of widely used and state-of-the-art algorithms on SMAC-HARD, revealing the substantial challenges posed by edited and mixed strategy opponents. Additionally, the black-box strategy tests illustrate the difficulty of transferring learned policies to unseen adversaries. We envision SMAC-HARD as a critical step toward benchmarking the next generation of MARL algorithms, fostering progress in self-play methods for multi-agent systems. Our code is available at https://github.com/devindeng94/smac-hard.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asynchronous Federated Learning: A Scalable Approach for Decentralized Machine Learning</title>
<link>https://arxiv.org/abs/2412.17723</link>
<guid>https://arxiv.org/abs/2412.17723</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、Asynchronous Federated Learning（异步联邦学习）、client delays、model staleness、LSTM

总结:<br />
本文提出了一种名为异步联邦学习（AFL）的新算法，用于解决传统联邦学习中因同步客户端更新导致的可扩展性和效率问题。该算法允许客户端独立并异步地更新全局模型，即使存在客户端延迟和模型陈旧情况也能保证收敛性。通过运用马丁格尔差异序列理论和方差边界，确保了在异步更新下的稳健收敛。研究者在具有随机客户端采样和强凸局部目标函数的假设下，界定了梯度方差，并推导出了量化客户端延迟对收敛影响的递归公式。实验部分展示了AFL在CMIP6气候数据集上训练分布式LSTM深度学习模型的有效性，成功处理非IID和地理分布的数据。AFL解决了传统方法中的全局同步低效和客户端漂移问题，提高了在具有异构客户端群体和动态网络条件的真实场景中的可扩展性、鲁棒性和效率，显示出其在大规模、隐私保护的应用以及资源受限环境中的潜力。 <div>
arXiv:2412.17723v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for decentralized machine learning, enabling collaborative model training across diverse clients without sharing raw data. However, traditional FL approaches often face limitations in scalability and efficiency due to their reliance on synchronous client updates, which can result in significant delays and increased communication overhead, particularly in heterogeneous and dynamic environments. To address these challenges in this paper, we propose an Asynchronous Federated Learning (AFL) algorithm, which allows clients to update the global model independently and asynchronously. Our key contributions include a comprehensive convergence analysis of AFL in the presence of client delays and model staleness. By leveraging martingale difference sequence theory and variance bounds, we ensure robust convergence despite asynchronous updates. Assuming strongly convex local objective functions, we establish bounds on gradient variance under random client sampling and derive a recursion formula quantifying the impact of client delays on convergence. Furthermore, we demonstrate the practical applicability of AFL by training a decentralized Long Short-Term Memory (LSTM)-based deep learning model on the CMIP6 climate dataset, effectively handling non-IID and geographically distributed data.
  The proposed AFL algorithm addresses key limitations of traditional FL methods, such as inefficiency due to global synchronization and susceptibility to client drift. It enhances scalability, robustness, and efficiency in real-world settings with heterogeneous client populations and dynamic network conditions. Our results underscore the potential of AFL to drive advancements in distributed learning systems, particularly for large-scale, privacy-preserving applications in resource-constrained environments.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture</title>
<link>https://arxiv.org/abs/2404.12135</link>
<guid>https://arxiv.org/abs/2404.12135</guid>
<content:encoded><![CDATA[
<div> 关键词：根因分析（RCA）、微服务架构（MSA）、区块链、多智能体、大规模语言模型（LLM）

总结:<br />
本文提出了一种名为mABC的创新框架，用于在具有复杂性的微服务架构中进行根因分析。mABC利用基于大规模语言模型的强大多智能体协作，并结合了区块链启发式的投票机制，以确保分析的可靠性并避免大型语言模型的幻觉问题。针对微服务架构中的循环依赖导致的非终止问题，该框架通过Agent Workflow客观地限制步骤和标准化任务处理。mABC包含七种专门化的智能体，它们各自依据其专业领域和LLMs的内在软件知识对根因分析提供有价值的见解。实验结果显示，mABC在AIOps挑战数据集和新创建的火车票数据集上表现出卓越的根因识别和解决方案生成效果。此外，消融研究强调了Agent Workflow、多智能体以及区块链启发式投票对于实现最佳性能的重要性。mABC为微服务架构提供了全面自动化的根因分析与解决方案，显著提升了IT运维领域的效率和稳定性。相关代码和数据集可在https://github.com/zwpride/mABC 获取。 <div>
arXiv:2404.12135v3 Announce Type: replace 
Abstract: Root cause analysis (RCA) in Micro-services architecture (MSA) with escalating complexity encounters complex challenges in maintaining system stability and efficiency due to fault propagation and circular dependencies among nodes. Diverse root cause analysis faults require multi-agents with diverse expertise. To mitigate the hallucination problem of large language models (LLMs), we design blockchain-inspired voting to ensure the reliability of the analysis by using a decentralized decision-making process. To avoid non-terminating loops led by common circular dependency in MSA, we objectively limit steps and standardize task processing through Agent Workflow. We propose a pioneering framework, multi-Agent Blockchain-inspired Collaboration for root cause analysis in micro-services architecture (mABC), where multiple agents based on the powerful LLMs follow Agent Workflow and collaborate in blockchain-inspired voting. Specifically, seven specialized agents derived from Agent Workflow each provide valuable insights towards root cause analysis based on their expertise and the intrinsic software knowledge of LLMs collaborating within a decentralized chain. Our experiments on the AIOps challenge dataset and a newly created Train-Ticket dataset demonstrate superior performance in identifying root causes and generating effective resolutions. The ablation study further highlights Agent Workflow, multi-agent, and blockchain-inspired voting is crucial for achieving optimal performance. mABC offers a comprehensive automated root cause analysis and resolution in micro-services architecture and significantly improves the IT Operation domain. The code and dataset are in https://github.com/zwpride/mABC.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Addressing Trust Issues for Vehicle to Grid in Distributed Power Grids Using Blockchains</title>
<link>https://arxiv.org/abs/2407.16180</link>
<guid>https://arxiv.org/abs/2407.16180</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、车辆到电网（V2G）、隐私保护、智能充电点（SCP）、Stackelberg 游戏模型

总结:
本文提出了一种针对区块链分散特性和利益相关者需求定制的车辆到电网（V2G）交易与协调方案，该方案同时关注用户隐私和能源交易效率。通过利用智能充电点（SCP）以及Stackelberg游戏模型，实证案例基于南方科技大学的真实数据表明，所提出的方案能有效降低电动汽车充电成本，并具有支持辅助电网服务的潜力。 <div>
arXiv:2407.16180v5 Announce Type: replace 
Abstract: While blockchain offers inherent security, trust issues among stakeholders in vehicle-to-grid (V2G) applications remain unresolved due to a lack of regulatory frameworks and standardization. Additionally, a tailored decentralized privacy-preserved coordination scheme for blockchain in V2G networks is needed to ensure user privacy and efficient energy transactions. This paper proposes a V2G trading and coordination scheme tailored to the decentralized nature of blockchain as well as the interests of stakeholders utilizing smart charging points (SCPs) and Stackelberg game model. Case studies using real-world data from Southern University of Science and Technology demonstrate the efficacy of proposed scheme in reducing EV charging costs and the potential for supporting auxiliary grid services.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain in Environmental Sustainability Measures: a Survey</title>
<link>https://arxiv.org/abs/2412.15261</link>
<guid>https://arxiv.org/abs/2412.15261</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、环境监管、温室气体排放、污染监测、循环经济

<br /><br />总结:
本文探讨了区块链技术如何作为实现对温室气体排放和污染物贡献进行公正、真实监管的有效工具。通过梳理现有文献，将区块链在环境保护领域的应用分为六个方面：温室气体排放、固体废物、水、塑料、食物浪费及循环经济。文章详细分析了针对这些问题提出的解决方案中所采用的不同类型的区块链及其设计属性。最后，作者指出了未来研究领域中仍存在的挑战与潜在应用场景。 <div>
arXiv:2412.15261v1 Announce Type: new 
Abstract: Real and effective regulation of contributions to greenhouse gas emissions and pollutants requires unbiased and truthful monitoring. Blockchain has emerged not only as an approach that provides verifiable economical interactions but also as a mechanism to keep the measurement, monitoring, incentivation of environmental conservationist practices and enforcement of policy. Here, we present a survey of areas in what blockchain has been considered as a response to concerns on keeping an accurate recording of environmental practices to monitor levels of pollution and management of environmental practices. We classify the applications of blockchain into different segments of concerns, such as greenhouse gas emissions, solid waste, water, plastics, food waste, and circular economy, and show the objectives for the addressed concerns. We also classify the different blockchains and the explored and designed properties as identified for the proposed solutions. At the end, we provide a discussion about the niches and challenges that remain for future research.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Autonomous Vehicle Security: A Deep Dive into Threat Modeling</title>
<link>https://arxiv.org/abs/2412.15348</link>
<guid>https://arxiv.org/abs/2412.15348</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶车辆、网络安全、威胁建模框架、防御措施、新兴技术

总结:
这篇论文对自动驾驶汽车（AVs）的安全性进行了全面调查，重点关注了用于系统地识别和缓解潜在风险的威胁建模框架，如STRIDE、DREAD和MITRE ATT&amp;CK。文章分析了AV架构的关键组成部分，如传感器、通信模块和电子控制单元（ECUs），并探讨了常见的攻击途径，包括无线通信利用、传感器欺骗和固件漏洞等。通过实际案例研究，如Jeep Cherokee和Tesla Model S的安全事件，突显了实施强大安全措施的迫切需求。同时，论文讨论了一些新兴技术，例如区块链用于保障车与万物（V2X）安全通信、AI驱动的威胁检测以及安全的空中下载（OTA）更新，这些都可能成为应对不断演变的威胁的有效解决方案。此外，论文还涉及到了法律和伦理方面的考量，强调数据隐私、用户安全和法规遵从性的重要性。通过结合威胁建模框架、多层安全策略和主动防御措施，该调查为提升自动驾驶车辆的网络安全提供了见解和建议。 <div>
arXiv:2412.15348v1 Announce Type: new 
Abstract: Autonomous vehicles (AVs) are poised to revolutionize modern transportation, offering enhanced safety, efficiency, and convenience. However, the increasing complexity and connectivity of AV systems introduce significant cybersecurity challenges. This paper provides a comprehensive survey of AV security with a focus on threat modeling frameworks, including STRIDE, DREAD, and MITRE ATT\&amp;CK, to systematically identify and mitigate potential risks. The survey examines key components of AV architectures, such as sensors, communication modules, and electronic control units (ECUs), and explores common attack vectors like wireless communication exploits, sensor spoofing, and firmware vulnerabilities. Through case studies of real-world incidents, such as the Jeep Cherokee and Tesla Model S exploits, the paper highlights the critical need for robust security measures. Emerging technologies, including blockchain for secure Vehicle-to-Everything (V2X) communication, AI-driven threat detection, and secure Over-The-Air (OTA) updates, are discussed as potential solutions to mitigate evolving threats. The paper also addresses legal and ethical considerations, emphasizing data privacy, user safety, and regulatory compliance. By combining threat modeling frameworks, multi-layered security strategies, and proactive defenses, this survey offers insights and recommendations for enhancing the cybersecurity of autonomous vehicles.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Computing the Non-Dominated Flexible Skyline in Vertically Distributed Datasets with No Random Access</title>
<link>https://arxiv.org/abs/2412.15468</link>
<guid>https://arxiv.org/abs/2412.15468</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、垂直分布式数据集、top-k查询、非支配灵活天际线（ND）、无随机访问（NRA）

总结:<br />
本文关注在数据驱动的时代，处理垂直分布式数据集的算法的重要性，这些算法能增强数据隐私并提高可扩展性。研究重点在于在无随机访问（NRA）场景下计算非支配灵活天际线（ND）的问题，因为在此类情境中，经典top-k算法的随机访问变得不切实际或受限。文章介绍了一种适用于NRA场景的ND查询算法，证明了其正确性和类别内的最优性，并通过实验评估验证了其在各种情况下的性能，包括合成数据和真实数据。 <div>
arXiv:2412.15468v1 Announce Type: new 
Abstract: In today's data-driven world, algorithms operating with vertically distributed datasets are crucial due to the increasing prevalence of large-scale, decentralized data storage. These algorithms enhance data privacy by processing data locally, reducing the need for data transfer and minimizing exposure to breaches. They also improve scalability, as they can handle vast amounts of data spread across multiple locations without requiring centralized access. Top-k queries have been studied extensively under this lens, and are particularly suitable in applications involving healthcare, finance, and IoT, where data is often sensitive and distributed across various sources. Classical top-k algorithms are based on the availability of two kinds of access to sources: sorted access, i.e., a sequential scan in the internal sort order, one tuple at a time, of the dataset; random access, which provides all the information available at a data source for a tuple whose id is known. However, in scenarios where data retrieval costs are high or data is streamed in real-time or, simply, data are from external sources that only offer sorted access, random access may become impractical or impossible, due to latency issues or data access constraints. Fortunately, a long tradition of algorithms designed for the "no random access" (NRA) scenario exists for classical top-k queries. Yet, these do not cover the recent advances in ranking queries, proposing hybridizations of top-k queries (which are preference-aware and control the output size) and skyline queries (which are preference-agnostic and have uncontrolled output size). The non-dominated flexible skyline (ND) is one such proposal. We introduce an algorithm for computing ND in the NRA scenario, prove its correctness and optimality within its class, and provide an experimental evaluation covering a wide range of cases, with both synthetic and real datasets.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-LLM Text Summarization</title>
<link>https://arxiv.org/abs/2412.15487</link>
<guid>https://arxiv.org/abs/2412.15487</guid>
<content:encoded><![CDATA[
<div> 关键词：多LLM框架、集中式、分布式、生成、评价

总结:
本文提出了一种名为Multi-LLM的摘要框架，并研究了两种不同的多LLM策略，包括集中式和分布式。该框架在每次对话回合中具有两个关键步骤：生成和评价。无论使用的是分布式还是集中式的多LLM策略，都有k个不同的LLM对文本生成多样化的摘要。然而，在评价阶段，集中式多LLM摘要方法利用单个LLM来评估并选择最佳摘要，而分布式则使用k个LLM进行评估。实验结果显示，多LLM摘要方法相对于仅使用单个LLM的基线方法性能显著提升，最高可达3倍。这些结果表明了多LLM方法在摘要任务上的有效性。

<br /><br /> <div>
arXiv:2412.15487v1 Announce Type: new 
Abstract: In this work, we propose a Multi-LLM summarization framework, and investigate two different multi-LLM strategies including centralized and decentralized. Our multi-LLM summarization framework has two fundamentally important steps at each round of conversation: generation and evaluation. These steps are different depending on whether our multi-LLM decentralized summarization is used or centralized. In both our multi-LLM decentralized and centralized strategies, we have k different LLMs that generate diverse summaries of the text. However, during evaluation, our multi-LLM centralized summarization approach leverages a single LLM to evaluate the summaries and select the best one whereas k LLMs are used for decentralized multi-LLM summarization. Overall, we find that our multi-LLM summarization approaches significantly outperform the baselines that leverage only a single LLM by up to 3x. These results indicate the effectiveness of multi-LLM approaches for summarization.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tacit Learning with Adaptive Information Selection for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.15639</link>
<guid>https://arxiv.org/abs/2412.15639</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、集中式训练分散式执行（CTDE）、信息选择、隐性学习、环境适应性过滤

<br /><br />总结：
本文针对多智能体强化学习（MARL）中集中式训练分散式执行（CTDE）框架所面临的挑战，提出了一种新的合作MARL框架。该框架结合了信息选择和默示学习，使代理能在不依赖通信的情况下，仅通过局部信息就能在离散空间中逐渐发展出对他人合作行为的隐性推理能力。此外，框架还整合了门控和选择机制，使得代理能够根据环境变化自适应地过滤信息，从而提升决策能力。实验结果表明，新框架可以无缝集成到最先进的算法中，显著提高了性能。 <div>
arXiv:2412.15639v1 Announce Type: new 
Abstract: In multi-agent reinforcement learning (MARL), the centralized training with decentralized execution (CTDE) framework has gained widespread adoption due to its strong performance. However, the further development of CTDE faces two key challenges. First, agents struggle to autonomously assess the relevance of input information for cooperative tasks, impairing their decision-making abilities. Second, in communication-limited scenarios with partial observability, agents are unable to access global information, restricting their ability to collaborate effectively from a global perspective. To address these challenges, we introduce a novel cooperative MARL framework based on information selection and tacit learning. In this framework, agents gradually develop implicit coordination during training, enabling them to infer the cooperative behavior of others in a discrete space without communication, relying solely on local information. Moreover, we integrate gating and selection mechanisms, allowing agents to adaptively filter information based on environmental changes, thereby enhancing their decision-making capabilities. Experiments on popular MARL benchmarks show that our framework can be seamlessly integrated with state-of-the-art algorithms, leading to significant performance improvements.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PoisonCatcher: Revealing and Identifying LDP Poisoning Attacks in IIoT</title>
<link>https://arxiv.org/abs/2412.15704</link>
<guid>https://arxiv.org/abs/2412.15704</guid>
<content:encoded><![CDATA[
<div> 关键词：Local Differential Privacy（局部差分隐私）、Industrial Internet of Things（工业物联网）、poisoning attacks（中毒攻击）、PoisonCatcher、machine learning models

总结:
这篇论文关注的是局部差分隐私在工业物联网中遭受中毒攻击的问题。研究发现，由于局部差分隐私的模糊性与工业物联网的复杂性相互作用，存在一种新的规则中毒攻击，并统一了输入中毒和输出中毒的攻击形式化描述。论文揭示了两种主要的攻击影响：统计查询结果准确性下降和跨数据集相关性的破坏，以及攻击模式不稳定和被污染数据隐蔽的特点。针对这些问题，提出了名为PoisonCatcher的四阶段解决方案，该方案利用时间相似性、属性相关性和时间序列稳定性分析来检测表现出统计查询结果准确性降低、跨数据集关系中断和不稳定模式的数据集。通过增强特征工程，从数据中提取微弱的中毒签名，进而使用机器学习模型识别特定的受污染数据点。实验评估显示，PoisonCatcher在六个代表性攻击场景中的平均精度和召回率分别达到了86.17%和97.5%，取得了最先进的性能表现。 <div>
arXiv:2412.15704v1 Announce Type: new 
Abstract: Local Differential Privacy (LDP) is widely adopted in the Industrial Internet of Things (IIoT) for its lightweight, decentralized, and scalable nature. However, its perturbation-based privacy mechanism makes it difficult to distinguish between uncontaminated and tainted data, encouraging adversaries to launch poisoning attacks. While LDP provides some resilience against minor poisoning, it lacks robustness in IIoT with dynamic networks and substantial real-time data flows. Effective countermeasures for such attacks are still underdeveloped. This work narrows the critical gap by revealing and identifying LDP poisoning attacks in IIoT. We begin by deepening the understanding of such attacks, revealing novel threats that arise from the interplay between LDP indistinguishability and IIoT complexity. This exploration uncovers a novel rule-poisoning attack, and presents a general attack formulation by unifying it with input-poisoning and output-poisoning. Furthermore, two key attack impacts, i.e., Statistical Query Result (SQR) accuracy degradation and inter-dataset correlations disruption, along with two characteristics: attack patterns unstable and poisoned data stealth are revealed. From this, we propose PoisonCatcher, a four-stage solution that detects LDP poisoning attacks and identifies specific contaminated data points. It utilizes temporal similarity, attribute correlation, and time-series stability analysis to detect datasets exhibiting SQR accuracy degradation, inter-dataset disruptions, and unstable patterns. Enhanced feature engineering is used to extract subtle poisoning signatures, enabling machine learning models to identify specific contamination. Experimental evaluations show the effectiveness, achieving state-of-the-art performance with average precision and recall rates of 86.17% and 97.5%, respectively, across six representative attack scenarios.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secure AI-driven Industrial Metaverse with NFT Digital Twins</title>
<link>https://arxiv.org/abs/2412.15716</link>
<guid>https://arxiv.org/abs/2412.15716</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字孪生、区块链、非同质化代币、伪造检测、深度学习

总结:
随着工业元宇宙的发展，数字孪生（DT）成为了焦点，而基于区块链的非同质化代币（NFT）为创建和拥有可克隆的DT提供了一种去中心化的方案。然而，NFT-DT面临着未经授权的复制或伪造的安全威胁。现有的NFT伪品检测方法多依赖于易于被篡改的静态信息如元数据和图像。针对这些问题，本文提出了一种结合自动编码器与RNN分类器的深度学习解决方案，实现实时模式识别以检测假冒NFT-DT。此外，文章还引入了动态元数据的概念，通过AI集成的智能合约提供更可靠的身份验证方式，有效识别并防范伪造的DT，从而强化了元宇宙中基于NFT资产的安全性。<br /><br /> <div>
arXiv:2412.15716v1 Announce Type: new 
Abstract: The rise of the industrial metaverse has brought digital twins (DTs) to the forefront. Blockchain-powered non-fungible tokens (NFTs) offer a decentralized approach to creating and owning these cloneable DTs. However, the potential for unauthorized duplication, or counterfeiting, poses a significant threat to the security of NFT-DTs. Existing NFT clone detection methods often rely on static information like metadata and images, which can be easily manipulated. To address these limitations, we propose a novel deep-learning-based solution as a combination of an autoencoder and RNN-based classifier. This solution enables real-time pattern recognition to detect fake NFT-DTs. Additionally, we introduce the concept of dynamic metadata, providing a more reliable way to verify authenticity through AI-integrated smart contracts. By effectively identifying counterfeit DTs, our system contributes to strengthening the security of NFT-based assets in the metaverse.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Proactive Model Offloading and Resource Allocation for Split and Federated Learning</title>
<link>https://arxiv.org/abs/2402.06123</link>
<guid>https://arxiv.org/abs/2402.06123</guid>
<content:encoded><![CDATA[
<div> 关键词: Split Federated学习、资源约束、物联网边缘计算、数据泄漏风险、分布式模型卸载与资源配置

<br /><br />
总结:
本文针对资源受限的物联网边缘计算环境中的Split Federated学习方法，指出了当前研究忽视的四个关键问题：设备资源异质性与训练效率的关系、服务器端计算和网络资源分配对训练效率的影响、服务器侧子模型离散化带来的数据泄漏风险以及现有集中式算法的隐私缺陷。为解决这些问题，文章首先建立了使用Split Federated学习训练DNN模型的延迟和数据泄漏风险模型，并将Split Federated学习问题形式化为混合整数非线性规划问题。接着，提出了一种分散式的主动模型卸载与资源配置方案（DP-MORA），使每个终端设备可以根据自身的多维度训练配置自主确定切层位置和资源需求，无需了解其他设备的配置信息。通过在两个真实世界数据集上的大量实验，表明DP-MORA方案能有效降低DNN模型训练延迟，提升训练效率，并在各种实验设置下满足数据泄漏风险约束要求，相较于多个基线算法具有显著优势。 <div>
arXiv:2402.06123v2 Announce Type: replace 
Abstract: In the resource-constrained IoT-edge computing environment, Split Federated (SplitFed) learning is implemented to enhance training efficiency. This method involves each terminal device dividing its full DNN model at a designated layer into a device-side model and a server-side model, then offloading the latter to the edge server. However, existing research overlooks four critical issues as follows: (1) the heterogeneity of end devices' resource capacities and the sizes of their local data samples impact training efficiency; (2) the influence of the edge server's computation and network resource allocation on training efficiency; (3) the data leakage risk associated with the offloaded server-side sub-model; (4) the privacy drawbacks of current centralized algorithms. Consequently, proactively identifying the optimal cut layer and server resource requirements for each end device to minimize training latency while adhering to data leakage risk rate constraint remains a challenging issue. To address these problems, this paper first formulates the latency and data leakage risk of training DNN models using Split Federated learning. Next, we frame the Split Federated learning problem as a mixed-integer nonlinear programming challenge. To tackle this, we propose a decentralized Proactive Model Offloading and Resource Allocation (DP-MORA) scheme, empowering each end device to determine its cut layer and resource requirements based on its local multidimensional training configuration, without knowledge of other devices' configurations. Extensive experiments on two real-world datasets demonstrate that the DP-MORA scheme effectively reduces DNN model training latency, enhances training efficiency, and complies with data leakage risk constraints compared to several baseline algorithms across various experimental settings.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models</title>
<link>https://arxiv.org/abs/2403.09567</link>
<guid>https://arxiv.org/abs/2403.09567</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理、安全性、解释性、ROS移动机器人、区块链、大型语言模型、问责制、自然语言解释、导航功能、性能评价

总结:<br />
本文提出了一种针对基于ROS的移动机器人的责任追究与解释性架构。该方案由两个主要组件构成：一是采用区块链技术实现的类似于黑盒的责任追溯组件，具备抗篡改属性；二是利用大型语言模型对黑盒中的数据生成自然语言解释的组件。研究通过三种不同场景下涉及自主代理导航功能的实验，全面评估了该解决方案的问责制和解释性指标，证明了我们的方法能够在现实世界场景中，有效利用机器人行为记录的可信数据生成连贯、准确且易于理解的解释，从而提高了解释性和系统的可靠性。 <div>
arXiv:2403.09567v3 Announce Type: replace 
Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of generating natural language explanations by harnessing the capabilities of Large Language Models (LLMs) over the data contained within the previously mentioned black box. The study evaluates the performance of our solution in three different scenarios, each involving autonomous agent navigation functionalities. This evaluation includes a thorough examination of accountability and explainability metrics, demonstrating the effectiveness of our approach in using accountable data from robot actions to obtain coherent, accurate and understandable explanations, even when facing challenges inherent in the use of autonomous agents in real-world scenarios.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trust Dynamics and Market Behavior in Cryptocurrency: A Comparative Study of Centralized and Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2404.17227</link>
<guid>https://arxiv.org/abs/2404.17227</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、信任、中心化交易所(CEX)、去中心化交易所(DEX)、FTX崩溃

<br /><br />总结:
该研究关注在加密货币领域中，信任对于市场行为和用户选择CEX与DEX的关键作用。通过对FTX这一大型CEX崩塌事件的分析，利用因果推断方法（如回归断点设计RDD和差异-in-差异DID），揭示了FTX崩溃导致WETH价格显著下降以及从CEX到DEX的资金流动净额增加，显示出可衡量的信任转移现象。同时，通过自然语言处理技术，如主题建模和情感分析，发现Binance社区内的讨论内容由功能转向情绪化，而Uniswap的情感倾向则呈现逐渐上升趋势。这项结合区块链分析、行为金融学和DeFi的跨学科研究加深了我们对分布式信任机制的理解，并为探究数字经济中的社会技术维度的信任问题提供了关键洞见。 <div>
arXiv:2404.17227v2 Announce Type: replace-cross 
Abstract: In the rapidly evolving cryptocurrency landscape, trust is a critical yet underexplored factor shaping market behaviors and driving user preferences between centralized exchanges (CEXs) and decentralized exchanges (DEXs). Despite its importance, trust remains challenging to measure, limiting the study of its effects on market dynamics. The collapse of FTX, a major CEX, provides a unique natural experiment to examine the measurable impacts of trust and its sudden erosion on the cryptocurrency ecosystem. This pivotal event raised questions about the resilience of centralized trust systems and accelerated shifts toward decentralized alternatives. This research investigates the impacts of the FTX collapse on user trust, focusing on token valuation, trading flows, and sentiment dynamics. Employing causal inference methods, including Regression Discontinuity Design (RDD) and Difference-in-Differences (DID), we reveal significant declines in WETH prices and NetFlow from CEXs to DEXs, signaling a measurable transfer of trust. Additionally, natural language processing methods, including topic modeling and sentiment analysis, uncover the complexities of user responses, highlighting shifts from functional discussions to emotional fragmentation in Binance's community, while Uniswap's sentiment exhibits a gradual upward trend. Despite data limitations and external influences, the findings underscore the intricate interplay between trust, sentiment, and market behavior in the cryptocurrency ecosystem. By bridging blockchain analytics, behavioral finance, and decentralized finance (DeFi), this study contributes to interdisciplinary research, offering a deeper understanding of distributed trust mechanisms and providing critical insights for future investigations into the socio-technical dimensions of trust in digital economies.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedSTaS: Client Stratification and Client Level Sampling for Efficient Federated Learning</title>
<link>https://arxiv.org/abs/2412.14226</link>
<guid>https://arxiv.org/abs/2412.14226</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated learning, FedSTaS, client sampling, data-level sampling, Neyman allocation

总结:<br />
本文提出了一种名为"FedSTaS"的新颖联邦学习客户端及数据级采样方法。FedSTaS受到FedSTS和FedSampling的启发，旨在更有效地并以隐私保护的方式选择参与每轮训练的客户端。在每个联邦学习回合中，FedSTaS依据客户端压缩后的梯度信息进行分层，并利用最优Neyman分配重新确定需要采样的客户端数量。此外，它还采用数据均匀采样策略从每个参与客户端中抽样局部数据。实验结果显示，在三个不同数据集上，FedSTaS能够在固定训练轮数内实现比FedSTS更高的准确性评分。 <div>
arXiv:2412.14226v1 Announce Type: new 
Abstract: Federated learning (FL) is a machine learning methodology that involves the collaborative training of a global model across multiple decentralized clients in a privacy-preserving way. Several FL methods are introduced to tackle communication inefficiencies but do not address how to sample participating clients in each round effectively and in a privacy-preserving manner. In this paper, we propose \textit{FedSTaS}, a client and data-level sampling method inspired by \textit{FedSTS} and \textit{FedSampling}. In each federated learning round, \textit{FedSTaS} stratifies clients based on their compressed gradients, re-allocate the number of clients to sample using an optimal Neyman allocation, and sample local data from each participating clients using a data uniform sampling strategy. Experiments on three datasets show that \textit{FedSTaS} can achieve higher accuracy scores than those of \textit{FedSTS} within a fixed number of training rounds.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AIArena: A Blockchain-Based Decentralized AI Training Platform</title>
<link>https://arxiv.org/abs/2412.14566</link>
<guid>https://arxiv.org/abs/2412.14566</guid>
<content:encoded><![CDATA[
<div> 关键词：AI、集中化控制、区块链、去中心化、AIArena<br /><br />总结:

随着人工智能（AI）的迅速发展，其在开发和实施过程中面临的重大挑战日益凸显，主要归因于少数大型企业对AI的集中化控制。这种权力集中加剧了AI模型中的偏见问题，源于不充分的治理和监督机制，并限制了公众参与，引发了关于模型生成完整性的担忧。此外，这种对数据和AI输出的垄断控制威胁到了创新与公平的数据使用，因为用户无意间贡献的数据主要使这些大公司受益。为此，本文提出了一种基于区块链的去中心化AI训练平台——AIArena，旨在通过链上激励机制民主化AI的发展与对齐。AIArena致力于打造一个开放协作的环境，允许参与者贡献模型和计算资源。其链上共识机制确保根据参与者贡献程度公平分配奖励。文章将AIArena实例化并实现在公开的Base区块链Sepolia测试网上，并通过评估结果证明了AIArena在现实应用中的可行性。 <div>
arXiv:2412.14566v1 Announce Type: new 
Abstract: The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>6GENABLERS-DLT: DLT-based Marketplace for Decentralized Trading of 6G Telco resources</title>
<link>https://arxiv.org/abs/2412.14977</link>
<guid>https://arxiv.org/abs/2412.14977</guid>
<content:encoded><![CDATA[
<div> 关键词: 6GENABLERS-DLT项目、分布式账本技术(DLT)、6G环境、资源交易市场、去中心化架构

总结:
<br />
6GENABLERS-DLT项目旨在解决在动态6G环境中促进多方协作的关键挑战。该项目引入了一个基于分布式账本技术(DLT)的创新资源交易市场，使得运营商、资源提供商和服务提供商能够在透明、安全和高效的许可环境下发现、宣传和交易电信资产。与公共DLT-区块链解决方案不同，该市场的许可性质确保了强大的治理、隐私和控制，特别适合于信息和通信技术(ICT)领域的企业及联盟应用场景。通过采用去中心化的架构，它消除了对单一中心运营商的依赖，降低了单点故障风险，提高了系统的信任度、韧性和容错性。此市场涵盖了从虚拟化的移动核心组件、无线接入网络(RAN)资产到边缘和云基础设施，以及针对特定行业需求的垂直应用等6G网络所需的广泛资源。这使得各利益相关方能够动态访问和扩展资源，从而在整个6G生态系统中推动运营效率和创新。通过6GENABLERS-DLT项目，一个合作且资源丰富的6G环境成为现实，为构建一个以去中心化赋能利益相关者满足互联、灵活和可扩展未来需求的下一代电信生态系统奠定了基础。 <div>
arXiv:2412.14977v1 Announce Type: new 
Abstract: The 6GENABLERS-DLT project addresses critical challenges in fostering multi-party collaboration within dynamic 6G environments. As operators and service providers increasingly depend on third-party resources to meet their contractual and operational needs, the project introduces an innovative, Distributed Ledger Technology (DLT)-anchored Marketplace designed to streamline decentralized telco resource trading. This 6GENABLERS Marketplace serves as a collaborative platform where operators, resource providers, and service providers can seamlessly discover, advertise, and trade telco assets within a transparent, secure, and efficient permissioned environment. Distinguished from public DLT-Blockchain solutions, the Marketplace's permissioned nature ensures robust governance, privacy, and control, making it particularly suited to enterprise and consortium-based use cases in the Information and Communication Technology (ICT) sector. The adoption of a decentralized architecture eliminates reliance on a central operator, thereby mitigating risks associated with single points of failure and enhancing system trustworthiness, resilience, and fault tolerance. The Marketplace encompasses a wide range of resources integral to 6G networks, including virtualized mobile core components, Radio Access Network (RAN) assets, edge and cloud infrastructure, and vertical applications tailored to specific industry needs. This diversity enables stakeholders to dynamically access and scale resources, fostering operational efficiency and innovation across 6G ecosystems. Through the 6GENABLERS-DLT project, the vision of a collaborative, resource-rich 6G environment becomes a reality, laying the foundation for a next-generation telco ecosystem where decentralization empowers stakeholders to meet the demands of an interconnected, flexible, and scalable future.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Programming Bugs to Multimillion-Dollar Scams: An Analysis of Trapdoor Tokens on Uniswap</title>
<link>https://arxiv.org/abs/2309.04700</link>
<guid>https://arxiv.org/abs/2309.04700</guid>
<content:encoded><![CDATA[
<div> 关键词：ERC-20 Token、Trapdoor、恶意代码、智能合约、检测工具

总结:
本文研究了一种新型的ERC-20代币骗局——Trapdoor，这种骗局自2020年至2023年已在以太坊上最大的去中心化交易所Uniswap导致投资者数十亿美元的损失。文章首先系统地分类了Trapdoor代币并列出了诈骗者用于嵌入和隐藏恶意代码的各种技术。为了检测这类代币，研究团队开发了一款名为TrapdoorAnalyser的精细粒度检测工具，该工具通过对比买卖测试错误日志与合同语义检查中的Trapdoor指标列表来可靠地识别Trapdoor代币。相比于现有的商业工具GoPlus，TrapdoorAnalyser在准确性方面表现出色，并能提供恶意代码痕迹及完整解释。利用TrapdoorAnalyser，研究人员构建了首个包含约3万个Trapdoor和非Trapdoor代币的UniswapV2数据集，这使得能够训练机器学习算法以高精度检测无Solidity源码的Trapdoor代币。 <div>
arXiv:2309.04700v4 Announce Type: replace 
Abstract: We investigate in this work a recently emerged type of scam ERC-20 token called Trapdoor, which has cost investors billions of US dollars on Uniswap, the largest decentralised exchange on Ethereum, from 2020 to 2023. In essence, Trapdoor tokens allow users to buy but preventing them from selling by embedding logical bugs and/or owner-only features in their smart contracts. By manually inspecting a number of Trapdoor samples, we established the first systematic classification of Trapdoor tokens and a comprehensive list of techniques that scammers used to embed and conceal malicious codes, accompanied by a detailed analysis of representative scam contracts. In particular, we developed TrapdoorAnalyser, a fine-grained detection tool that generates and crosschecks the error-log of a buy-and-sell test and the list of embedded Trapdoor indicators from a contract-semantic check to reliably identify a Trapdoor token. TrapdoorAnalyser not only outperforms the state-of-the-art commercial tool GoPlus in accuracy, but also provides traces of malicious code with a full explanation, which most of the existing tools lack. Using TrapdoorAnalyser, we constructed the very first dataset of about 30,000 Trapdoor and non-Trapdoor tokens on UniswapV2, which allows us to train several machine learning algorithms that can detect with very high accuracy even Trapdoor tokens with no available Solidity source codes.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning Enhanced Rate-Splitting Multiple Access for Interference Mitigation</title>
<link>https://arxiv.org/abs/2403.05974</link>
<guid>https://arxiv.org/abs/2403.05974</guid>
<content:encoded><![CDATA[
<div> 关键词：RSMA，深度强化学习，多智能体DDPG框架，预编码，功率分配

<br />
总结:
本文研究了在现代通信系统中用于干扰缓解的关键技术——率分割多址接入（RSMA）的应用。文章重点关注在复杂多天线干扰信道中，采用深度强化学习优化RSMA的预编码方法和功率分配问题，特别是在涉及多个决策者的情况下。文中利用多智能体深度确定性策略梯度（MADDPG）框架解决这一复杂问题，使分布式代理能够协同学习并优化连续策略空间中的行动。同时，针对发射端不完善的信道侧信息所带来的挑战进行了探讨，并解决了共同和私有数据流的最佳解码顺序估计问题。仿真实验表明，基于MADDPG的提出的RSMA方法在单天线场景下能达到上界性能，在多天线场景下则接近理论极限，并明显优于无率分割的MADDPG、最大比传输（MRT）、零强迫（ZF）以及泄漏基预编码等其他技术。这些发现突显了深度强化学习驱动的RSMA在减少干扰和提升通信系统性能方面的潜力。 <div>
arXiv:2403.05974v2 Announce Type: replace 
Abstract: This study explores the application of the rate-splitting multiple access (RSMA) technique, vital for interference mitigation in modern communication systems. It investigates the use of precoding methods in RSMA, especially in complex multiple-antenna interference channels, employing deep reinforcement learning. The aim is to optimize precoders and power allocation for common and private data streams involving multiple decision-makers. A multi-agent deep deterministic policy gradient (MADDPG) framework is employed to address this complexity, where decentralized agents collectively learn to optimize actions in a continuous policy space. We also explore the challenges posed by imperfect channel side information at the transmitter. Additionally, decoding order estimation is addressed to determine the optimal decoding sequence for common and private data sequences. Simulation results demonstrate the effectiveness of the proposed RSMA method based on MADDPG, achieving the upper bound in single-antenna scenarios and closely approaching theoretical limits in multi-antenna scenarios. Comparative analysis shows superiority over other techniques such as MADDPG without rate-splitting, maximal ratio transmission (MRT), zero-forcing (ZF), and leakage-based precoding methods. These findings highlight the potential of deep reinforcement learning-driven RSMA in reducing interference and enhancing system performance in communication systems.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proxima. A DAG based cooperative distributed ledger</title>
<link>https://arxiv.org/abs/2411.16456</link>
<guid>https://arxiv.org/abs/2411.16456</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式账本、有向无环图(DAG)、UTXO交易、合作共识、可持续性

总结:<br />
本文提出了一种新的分布式账本（常被称为“区块链”）架构，该架构以有向无环图(DAG)的形式组织，其中UTXO交易作为顶点而非区块链中的块。通过实施特别设计的UTXO交易有效性约束，实现基于参与者合作的最大 ledger 覆盖规则的合作共识。这种合作行为由代币持有者驱动，他们是有权对账本进行修正的唯一类别，参与完全无需许可——没有矿工、验证者、委员会或质押机制，也无需了解所有参与共识的成员组成。此设置实现了高吞吐量、可扩展性和低交易成本，同时保持了比特币和其他工作量证明区块链中的高度去中心化、开放参与和异步特性，但避免了不合理的能源消耗。通过使用原生代币的方式，类似于权益证明区块链来实现Sybil防护，但该架构以无领导者方式运行，无需区块提议者和委员会选择。 <div>
arXiv:2411.16456v2 Announce Type: replace 
Abstract: This paper introduces a novel architecture for a distributed ledger, commonly referred to as a "blockchain", which is organized in the form of directed acyclic graph (DAG) with UTXO transactions as vertices, rather than as a chain of blocks. Consensus on the state of ledger assets is achieved through the cooperative consensus: a profit-driven behavior of token holders themselves, which is viable only when they cooperate by following the biggest ledger coverage rule. The cooperative behavior is facilitated by enforcing purposefully designed UTXO transaction validity constraints. Token holders are the sole category of participants authorized to make amendments to the ledger, making participation completely permissionless - without miners, validators, committees or staking - and without any need of knowledge about the composition of the set of all participants in the consensus. The setup allows to achieve high throughput and scalability alongside with low transaction costs, while preserving key aspects of high decentralization, open participation, and asynchronicity found in Bitcoin and other proof-of-work blockchains, but without unreasonable energy consumption. Sybil protection is achieved similarly to proof-of-stake blockchains, using tokens native to the ledger, yet the architecture operates in a leaderless manner without block proposers and committee selection.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized real-time iterations for distributed NMPC</title>
<link>https://arxiv.org/abs/2401.14898</link>
<guid>https://arxiv.org/abs/2401.14898</guid>
<content:encoded><![CDATA[
<div> 关键词：Real-Time Iteration (RTI)，Nonlinear Model Predictive Control (NMPC)，Distributed Control，Sequential Quadratic Programming (dSQP)，Exponential Stability

总结:<br />
本文提出了一种应用于分布式非线性模型预测控制（NMPC）的实时迭代（RTI）方案。该方案将RTI方法扩展到合作式分布式控制场景中，在每个采样时刻，对集中式的优化控制问题执行一次双层分散序列二次规划（dSQP）的外部迭代，确保满足实时性要求并促进子系统间的协作。结合新颖的dSQP收敛结果与RTI稳定性保证，文章证明了在标准MPC设计条件下，无论是否采用终端约束，都能实现局部指数稳定性。所提方案仅需要邻节点间通信，无需中央协调器。通过耦合倒立摆的数值例子，展示了该方法的有效性。 <div>
arXiv:2401.14898v2 Announce Type: replace-cross 
Abstract: This article presents a Real-Time Iteration (RTI) scheme for distributed Nonlinear Model Predictive Control (NMPC). The scheme transfers the well-known RTI approach, a key enabler for many industrial real-time NMPC implementations, to the setting of cooperative distributed control. At each sampling instant, one outer iteration of a bi-level decentralized Sequential Quadratic Programming (dSQP) method is applied to a centralized optimal control problem. This ensures that real-time requirements are met and it facilitates cooperation between subsystems. Combining novel dSQP convergence results with RTI stability guarantees, we prove local exponential stability under standard assumptions on the MPC design with and without terminal constraints. The proposed scheme only requires neighbor-to-neighbor communication and avoids a central coordinator. A numerical example with coupled inverted pendulums demonstrates the efficacy of the approach.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Phytosensing: Ozone Exposure Classification Based on Plant Electrical Signals</title>
<link>https://arxiv.org/abs/2412.13312</link>
<guid>https://arxiv.org/abs/2412.13312</guid>
<content:encoded><![CDATA[
<div> 关键词：WatchPlant、phytosensing、ozone、electrophysiology、AutoML

<br /><br />总结:
该项目WatchPlant提出使用分布式植物网络作为空气品质传感器，通过测量植物电生理学来推断环境状态。研究团队对常春藤（Hedera helix）进行了实验室实验，使其暴露于重要的污染物——臭氧中，并记录了其电生理响应。由于缺乏自动检测植物臭氧暴露的方法，他们提出了一个通用的自动化工具链，该工具链从电生理信号中提取植物和刺激源通用特征，并利用tsfresh库进行处理。接着，通过AutoML自动选择并优化机器学习模型，并运用前向特征选择提升模型性能。实验结果显示，他们的方法能够在未见数据上成功分类植物臭氧暴露，准确率高达94.6%。此外，这种方法还可应用于其他植物物种和刺激源。这一工具链实现了监测算法开发的自动化，为以植物为基础的污染物监测设备带来了显著进步，有助于未来低成本、高密度的城市空气质量监测系统的发展。 <div>
arXiv:2412.13312v1 Announce Type: new 
Abstract: In our project WatchPlant, we propose to use a decentralized network of living plants as air-quality sensors by measuring their electrophysiology to infer the environmental state, also called phytosensing. We conducted in-lab experiments exposing ivy (Hedera helix) plants to ozone, an important pollutant to monitor, and measured their electrophysiological response. However, there is no well established automated way of detecting ozone exposure in plants. We propose a generic automatic toolchain to select a high-performance subset of features and highly accurate models for plant electrophysiology. Our approach derives plant- and stimulus-generic features from the electrophysiological signal using the tsfresh library. Based on these features, we automatically select and optimize machine learning models using AutoML. We use forward feature selection to increase model performance. We show that our approach successfully classifies plant ozone exposure with accuracies of up to 94.6% on unseen data. We also show that our approach can be used for other plant species and stimuli. Our toolchain automates the development of monitoring algorithms for plants as pollutant monitors. Our results help implement significant advancements for phytosensing devices contributing to the development of cost-effective, high-density urban air monitoring systems in the future.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Preserving Cyberattack Detection in Blockchain-Based IoT Systems Using AI and Homomorphic Encryption</title>
<link>https://arxiv.org/abs/2412.13522</link>
<guid>https://arxiv.org/abs/2412.13522</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、区块链、物联网、人工智能、同态加密

<br /><br />总结:

本文提出了一种针对基于区块链的物联网系统的新型隐私保护网络攻击检测框架。该框架利用人工智能驱动的检测模块在区块链节点上实现实时攻击识别，确保高精度和最小延迟。为了提高效率，模型训练由云服务提供商（CSP）执行，节点数据经同态加密后发送给CSP进行训练，以保障数据在整个学习过程中的隐私安全。为应对大量加密数据处理问题，文中引入一种创新的 SIMD 方式的打包算法，使得在HE加密数据上进行高效训练成为可能。同时，研究团队开发了适用于加密数据的深度神经网络训练算法，并提出了基于FedAvg算法的分布式隐私保护学习方法，通过并行化多工作器训练显著缩短计算时间。训练完成后，CSP将训练好的模型分发至区块链节点，使其能够进行实时、隐私保护的攻击检测。模拟结果显示，该提议的方法能有效减少训练时间，并实现与未加密情况下接近相同的检测精度，准确度差距约为0.01%。此外，针对不同区块链共识算法和硬件配置的实际部署验证表明，提出的框架也可适应于现实世界系统。 <div>
arXiv:2412.13522v1 Announce Type: new 
Abstract: This work proposes a novel privacy-preserving cyberattack detection framework for blockchain-based Internet-of-Things (IoT) systems. In our approach, artificial intelligence (AI)-driven detection modules are strategically deployed at blockchain nodes to identify real-time attacks, ensuring high accuracy and minimal delay. To achieve this efficiency, the model training is conducted by a cloud service provider (CSP). Accordingly, blockchain nodes send their data to the CSP for training, but to safeguard privacy, the data is encrypted using homomorphic encryption (HE) before transmission. This encryption method allows the CSP to perform computations directly on encrypted data without the need for decryption, preserving data privacy throughout the learning process. To handle the substantial volume of encrypted data, we introduce an innovative packing algorithm in a Single-Instruction-Multiple-Data (SIMD) manner, enabling efficient training on HE-encrypted data. Building on this, we develop a novel deep neural network training algorithm optimized for encrypted data. We further propose a privacy-preserving distributed learning approach based on the FedAvg algorithm, which parallelizes the training across multiple workers, significantly improving computation time. Upon completion, the CSP distributes the trained model to the blockchain nodes, enabling them to perform real-time, privacy-preserved detection. Our simulation results demonstrate that our proposed method can not only mitigate the training time but also achieve detection accuracy that is approximately identical to the approach without encryption, with a gap of around 0.01%. Additionally, our real implementations on various blockchain consensus algorithms and hardware configurations show that our proposed framework can also be effectively adapted to real-world systems.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large Language Model Federated Learning with Blockchain and Unlearning for Cross-Organizational Collaboration</title>
<link>https://arxiv.org/abs/2412.13551</link>
<guid>https://arxiv.org/abs/2412.13551</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、联合学习、区块链、多智能体强化学习、低秩适应<br /><br />总结:<br />
本文提出了一种基于混合区块链的联合学习框架，用于解决不同组织在利用大型语言模型协作过程中面临的挑战。该框架结合了公共和私有区块链架构以及多智能体强化学习，确保模型更新透明共享的同时保护敏感计算。每个组织作为智能代理，运用Q学习优化参与策略和资源分配，使个体利益与集体目标相一致。此外，文章还引入了一种基于低秩适应（LoRA）的高效“遗忘”机制，能够在不损害整体性能的情况下选择性移除特定数据贡献。通过实验证明，该框架有效平衡了隐私保护、信任建立、法规遵循和高模型性能之间的关系。 <div>
arXiv:2412.13551v1 Announce Type: new 
Abstract: Large language models (LLMs) have transformed the way computers understand and process human language, but using them effectively across different organizations remains still difficult. When organizations work together to improve LLMs, they face several main challenges. First, organizations hesitate to share their valuable data with others. Second, competition between organizations creates trust problems during collaboration. Third, new privacy laws require organizations to be able to delete specific data when requested, which is especially difficult when multiple organizations are learning from shared data. Traditional federated learning approaches do not address these interconnected challenges, particularly in scenarios where participants cannot fully trust each other or the central aggregator. To overcome these limitations, we propose a hybrid blockchain-based federated learning framework that uniquely combines public and private blockchain architectures with multi-agent reinforcement learning. Our framework enables transparent sharing of model update through the public blockchain while protecting sensitive computations in private chains. Each organization operates as an intelligent agent, using Q-learning to optimize its participation strategy and resource allocation, thus aligning individual incentives with collective goals. Notably, we introduce an efficient unlearning mechanism based on Low-Rank Adaptation (LoRA) that enables selective removal of specific data contributions without compromising the model's overall performance. Through extensive experimentation on real-world datasets, we demonstrate that our framework effectively balances privacy protection, trust establishment, and regulatory compliance while maintaining high model performance.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data sharing in the metaverse with key abuse resistance based on decentralized CP-ABE</title>
<link>https://arxiv.org/abs/2412.13770</link>
<guid>https://arxiv.org/abs/2412.13770</guid>
<content:encoded><![CDATA[
<div> 关键词：元宇宙、区块链、数据共享、密文策略属性基加密（CP-ABE）、非交互式零知识证明（NIZK）

<br /><br />总结：

本文提出了一种基于区块链的数据共享方案，用于解决元宇宙中数据透明性、防篡改和智能合约支持的需求。该方案首次将非交互式零知识证明（NIZK）融入CP-ABE密钥以确保密钥机密性和授权责任，同时通过智能合约外包验证过程，解决了权责问责和密钥滥用问题。为了满足去中心化要求，文中引入了一个去中心化的CP-ABE方案。此外，还实现了利用智能合约判断访问控制策略是否被一组CP-ABE密钥满足的功能，并设计了开放激励机制以促进诚实参与数据共享，从而有效解决密钥滥用问题。最后，文章展示了该可问责方法在一个GameFi应用中的具体实践，玩家可以在游戏中赚取收益或为一个负责任的DAO做出贡献，进而推动繁荣的元宇宙生态系统建设。实验结果表明该数据共享系统的可行性和效率。 <div>
arXiv:2412.13770v1 Announce Type: new 
Abstract: Data sharing is ubiquitous in the metaverse, which adopts blockchain as its foundation. Blockchain is employed because it enables data transparency, achieves tamper resistance, and supports smart contracts. However, securely sharing data based on blockchain necessitates further consideration. Ciphertext-policy attribute-based encryption (CP-ABE) is a promising primitive to provide confidentiality and fine-grained access control. Nonetheless, authority accountability and key abuse are critical issues that practical applications must address. Few studies have considered CP-ABE key confidentiality and authority accountability simultaneously. To our knowledge, we are the first to fill this gap by integrating non-interactive zero-knowledge (NIZK) proofs into CP-ABE keys and outsourcing the verification process to a smart contract. To meet the decentralization requirement, we incorporate a decentralized CP-ABE scheme into the proposed data sharing system. Additionally, we provide an implementation based on smart contract to determine whether an access control policy is satisfied by a set of CP-ABE keys. We also introduce an open incentive mechanism to encourage honest participation in data sharing. Hence, the key abuse issue is resolved through the NIZK proof and the incentive mechanism. We provide a theoretical analysis and conduct comprehensive experiments to demonstrate the feasibility and efficiency of the data sharing system. Based on the proposed accountable approach, we further illustrate an application in GameFi, where players can play to earn or contribute to an accountable DAO, fostering a thriving metaverse ecosystem.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Responsible Governing AI Proliferation</title>
<link>https://arxiv.org/abs/2412.13821</link>
<guid>https://arxiv.org/abs/2412.13821</guid>
<content:encoded><![CDATA[
<div> 关键词：AI系统、治理机制、大计算范式、扩散范式、风险防控

<br /><br />总结：
本文提出当前用于缓解人工智能系统风险的治理机制基于“大计算”范式，这一范式对于未来可能不再适用。文章引入了“扩散”范式，预期未来会出现更小、分散化、开源的人工智能模型，这些模型更容易增强和秘密训练，从而带来新的机遇与挑战。作者认为这些发展既是可能的，也可能导致现有治理机制难以应对的新风险。文章探讨了针对这些风险的治理策略，重点关注访问治理、分布式计算监督和信息安全。尽管这些策略提供了解决方案的可能性，但文章也警示开发者需要权衡利弊，避免走向一个可能变得脆弱的世界。 <div>
arXiv:2412.13821v1 Announce Type: new 
Abstract: This paper argues that existing governance mechanisms for mitigating risks from AI systems are based on the `Big Compute' paradigm -- a set of assumptions about the relationship between AI capabilities and infrastructure -- that may not hold in the future. To address this, the paper introduces the `Proliferation' paradigm, which anticipates the rise of smaller, decentralized, open-sourced AI models which are easier to augment, and easier to train without being detected. It posits that these developments are both probable and likely to introduce both benefits and novel risks that are difficult to mitigate through existing governance mechanisms. The final section explores governance strategies to address these risks, focusing on access governance, decentralized compute oversight, and information security. Whilst these strategies offer potential solutions, the paper acknowledges their limitations and cautions developers to weigh benefits against developments that could lead to a `vulnerable world'.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Convergence to Equilibrium Prices in Trading Networks</title>
<link>https://arxiv.org/abs/2412.13972</link>
<guid>https://arxiv.org/abs/2412.13972</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized market model, bilateral contracts, Hatfield et al., equilibrium prices, best response dynamic

<br /><br />总结:

本文提出了一种去中心化的市场模型，其中代理人可以协商双边合同。该模型基于Hatfield等人(2013)提出的集中式交易网络模型。先前的工作已经证明，完全可替代的偏好保证了存在可以通过中心化计算得到的竞争均衡。然而，现实世界中如场外交易市场和二手车市场的价格是由代理人之间的“去中心化”谈判产生的，这使得从双边谈判中是否能涌现出均衡价格成为一个开放性问题。为此，文章设计了一个旨在捕捉市场参与者之间此类谈判的最佳响应动态过程。在假设市场参与者具有完全可替代偏好的情况下，对于稀疏市场（覆盖了许多实际感兴趣的市场），本文提供了收敛性的证明，并对于更一般的情况给出了实验结果，证实了价格确实能够通过双边谈判快速达到均衡。这种最佳响应动态及其收敛行为为理解去中心化市场如何达到并维持均衡提供了一个重要的初步研究。 <div>
arXiv:2412.13972v1 Announce Type: new 
Abstract: We propose a decentralized market model in which agents can negotiate bilateral contracts. This builds on a similar, but centralized, model of trading networks introduced by Hatfield et al. (2013). Prior work has established that fully-substitutable preferences guarantee the existence of competitive equilibria which can be centrally computed. Our motivation comes from the fact that prices in markets such as over-the-counter markets and used car markets arise from \textit{decentralized} negotiation among agents, which has left open an important question as to whether equilibrium prices can emerge from agent-to-agent bilateral negotiations. We design a best response dynamic intended to capture such negotiations between market participants. We assume fully substitutable preferences for market participants. In this setting, we provide proofs of convergence for sparse markets ({covering many real world markets of interest}), and experimental results for more general cases, demonstrating that prices indeed reach equilibrium, quickly, via bilateral negotiations. Our best response dynamic, and its convergence behavior, forms an important first step in understanding how decentralized markets reach, and retain, equilibrium.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring User Acceptance of Blockchain-Based Student Certificate Sharing System: A Study on Non Fungible Token (NFT) Utilization</title>
<link>https://arxiv.org/abs/2412.14096</link>
<guid>https://arxiv.org/abs/2412.14096</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、非同质化代币（NFTs）、学术机构凭证、用户接受行为模型、Technology Acceptance Model (TAM)

总结:
本文探讨了一种利用区块链技术和非同质化代币（NFTs）来证明学术机构凭证所有权及管理学术数据和元凭证的新系统。该系统支持安全分享学术信息并确保数据访问控制权。文章指出，现有文献对这类系统的用户接纳行为模型探索有限。为此，论文基于扩展后的Technology Acceptance Model (TAM)，考察了感知易用性、感知有用性和对系统的态度等因素对使用意向的影响。通过原型系统的用户体验问卷调查进行验证，结果表明这些个体构念对使用意向有显著影响，其中感知易用性对使用意向的影响不显著，而对系统的态度对其感知有用性具有主导影响力。最后，文章讨论了这些发现对于基于区块链的学术数据和元凭证共享，以及采用NFTs定义所有权的应用场景的意义。 <div>
arXiv:2412.14096v1 Announce Type: new 
Abstract: Blockchain technology has emerged as a transformative tool for data management in a variety of industries, including fintech, research and healthcare. We have developed a workable blockchain based system that utilizes non fungible tokens NFTs to tokenize and prove ownership of the academic institutions credentials. This makes it easier to create provenance and ownership documentation for academic data and meta credentials. This system enables the secure sharing of academic information while maintaining control, offering incentives for collaboration, and granting users full transparency and control over data access. While the initial adoption of these systems is crucial for ongoing service usage, the exploration of the user acceptance behavioural model remains limited in the existing literature. In this paper, we build upon the Technology Acceptance Model TAM, incorporating additional elements to scrutinize the impact of perceived ease of use, perceived usability, and attitude towards the system on the intention to use a blockchain based academic data and meta credentials sharing system. The research, grounded in user evaluations of a prototype, employs a TAM validated questionnaire. Results indicate that individual constructs notably affect the intention to use the system, and their collective impact is statistically significant. Specifically, perceived ease of use is the sole factor with an insignificant influence on the intention to use. The paper underscores the dominant influence of attitude towards the system on perceived usefulness. It concludes with a discussion on the implications of these findings within the context of blockchain based academic data and meta credentials sharing, incorporating NFTs for ownership definition.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Optimization to Generalization: Fair Federated Learning against Quality Shift via Inter-Client Sharpness Matching</title>
<link>https://arxiv.org/abs/2404.17805</link>
<guid>https://arxiv.org/abs/2404.17805</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、图像质量、公平性、尖锐度匹配、FedISM

总结:
为了解决日益严重的隐私问题，联邦学习被视为训练分布式医疗数据深度神经网络的重要方法。然而，不同机构间成像质量的不一致性成为了一个挑战，可能导致模型偏向高质量图像，从而产生公平性问题。本文首次提出了这一在成像质量偏移背景下的新公平性挑战，并指出传统促进联邦学习公平性的方法主要关注于平衡不同客户端分布的经验风险，但忽视了泛化能力的关键方面。针对此问题，文章提出了一种名为“基于客户端间尖锐度匹配的联邦学习”(FedISM)的方法，该方法通过引入尖锐度感知机制，旨在协调各客户端之间的图像清晰度水平以实现公平泛化。实验结果表明，FedISM在使用ICH和ISIC 2019数据集进行的评估中，相比于当前最先进的联邦学习方法，更能有效地提升公平性。相关代码已发布在https://github.com/wnn2000/FFL4MIA。 <div>
arXiv:2404.17805v2 Announce Type: replace 
Abstract: Due to escalating privacy concerns, federated learning has been recognized as a vital approach for training deep neural networks with decentralized medical data. In practice, it is challenging to ensure consistent imaging quality across various institutions, often attributed to equipment malfunctions affecting a minority of clients. This imbalance in image quality can cause the federated model to develop an inherent bias towards higher-quality images, thus posing a severe fairness issue. In this study, we pioneer the identification and formulation of this new fairness challenge within the context of the imaging quality shift. Traditional methods for promoting fairness in federated learning predominantly focus on balancing empirical risks across diverse client distributions. This strategy primarily facilitates fair optimization across different training data distributions, yet neglects the crucial aspect of generalization. To address this, we introduce a solution termed Federated learning with Inter-client Sharpness Matching (FedISM). FedISM enhances both local training and global aggregation by incorporating sharpness-awareness, aiming to harmonize the sharpness levels across clients for fair generalization. Our empirical evaluations, conducted using the widely-used ICH and ISIC 2019 datasets, establish FedISM's superiority over current state-of-the-art federated learning methods in promoting fairness. Code is available at https://github.com/wnn2000/FFL4MIA.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>REVECA: Adaptive Planning and Trajectory-based Validation in Cooperative Language Agents using Information Relevance and Relative Proximity</title>
<link>https://arxiv.org/abs/2405.16751</link>
<guid>https://arxiv.org/abs/2405.16751</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体合作、部分观察、REVECA、GPT-4o-mini、效率、记忆管理、优化规划、错误规划预防、实验结果、人类-AI合作可信性

<br /><br />总结:

本文提出了一种针对多智能体合作问题的新颖认知架构——RElevance, Proximity, and Validation-Enhanced Cooperative Language Agent (REVECA)，该架构利用GPT-4o-mini进行赋能。针对现有合作智能体系统在处理持续累积信息、规划全局次优以及防范因其他合作者导致的环境变化引起的错误规划等方面的挑战，REVECA通过实施相关性估计、自适应规划和轨迹验证来实现高效的记忆管理、最优规划及低成本防止错误规划。实验结果显示，REVECA在多个基准测试中优于现有的方法，并且用户研究显示出其在实现可信赖的人类与AI合作方面的潜力。 <div>
arXiv:2405.16751v2 Announce Type: replace 
Abstract: We address the challenge of multi-agent cooperation, where agents achieve a common goal by cooperating with decentralized agents under complex partial observations. Existing cooperative agent systems often struggle with efficiently processing continuously accumulating information, managing globally suboptimal planning due to lack of consideration of collaborators, and addressing false planning caused by environmental changes introduced by other collaborators. To overcome these challenges, we propose the RElevance, Proximity, and Validation-Enhanced Cooperative Language Agent (REVECA), a novel cognitive architecture powered by GPT-4o-mini. REVECA enables efficient memory management, optimal planning, and cost-effective prevention of false planning by leveraging Relevance Estimation, Adaptive Planning, and Trajectory-based Validation. Extensive experimental results demonstrate REVECA's superiority over existing methods across various benchmarks, while a user study reveals its potential for achieving trustworthy human-AI cooperation.
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Technical Insights on Blockchain's Role in Financial Systems</title>
<link>https://arxiv.org/abs/2412.12131</link>
<guid>https://arxiv.org/abs/2412.12131</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、金融行业、绿色金融、合规性、透明度

总结:

本文对区块链技术在金融行业的应用进行了批判性分析，强调了其在推动绿色金融、确保法规遵从、优化供应链金融、促进去中心化金融(DeFi)以及强化物联网(IoT)方面的重要性。文章探讨了区块链固有特性如何能大幅提高这些领域的透明度、运营效率和安全性，并同时面对可扩展性、系统整合以及不断演变的监管环境等挑战提出了应对之策。 <div>
arXiv:2412.12131v1 Announce Type: new 
Abstract: This research provides a critical analysis regarding the way blockchain is being implemented in the financial industry, highlighting its vital role in promoting green finance, guaranteeing compliance with regulations, improving supply chain finance, boosting decentralized finance (DeFi), and strengthening the Internet of Things (IoT). It discusses how blockchain's inherent attributes could significantly boost transparency, operational efficiency, and security across these domains while also addressing the pressing challenges of scalability, system integration, and the evolving regulatory landscape.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain</title>
<link>https://arxiv.org/abs/2412.12370</link>
<guid>https://arxiv.org/abs/2412.12370</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum智能合约、欺诈检测、图表示学习、交易模式、Multi-Layer Perceptron (MLP)

总结:<br />
针对Ethereum智能合约中的欺诈行为检测问题，由于现有方法存在可扩展性和适应性限制，本文提出了一种创新方法。该方法利用图表示学习来分析交易模式并识别欺诈合同。首先将Ethereum交易数据转化为图结构，然后应用高级机器学习模型进行分类。为解决标签不平衡问题，研究采用了SMOTE-ENN技术，并对比评估了Multi-Layer Perceptron (MLP)和Graph Convolutional Networks (GCN)两种模型。实验结果显示，在此情境下，MLP模型的表现优于GCN模型，实际场景评价也与领域专业分析相吻合。这一研究提供了一个可扩展且有效的解决方案，旨在增强对Ethereum生态系统中信任和安全性的保障。 <div>
arXiv:2412.12370v1 Announce Type: new 
Abstract: The detection of scams within Ethereum smart contracts is a critical challenge due to their increasing exploitation for fraudulent activities, leading to significant financial and reputational damages. Existing detection methods often rely on contract code analysis or manually extracted features, which suffer from scalability and adaptability limitations. In this study, we introduce an innovative method that leverages graph representation learning to examine transaction patterns and identify fraudulent contracts. By transforming Ethereum transaction data into graph structures and employing advanced machine learning models, we achieve robust classification performance. Our method addresses label imbalance through SMOTE-ENN techniques and evaluates models like Multi-Layer Perceptron (MLP) and Graph Convolutional Networks (GCN). Experimental results indicate that the MLP model surpasses the GCN in this context, with real-world evaluations aligning closely with domain-specific analyses. This study provides a scalable and effective solution for enhancing trust and security in the Ethereum ecosystem.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>if-ZKP: Intel FPGA-Based Acceleration of Zero Knowledge Proofs</title>
<link>https://arxiv.org/abs/2412.12481</link>
<guid>https://arxiv.org/abs/2412.12481</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-Knowledge Proofs (ZKP)，Zero-knowledge Succinct Non-interactive ARgument of Knowledge (zk-SNARKs)，FPGA，Multi-scalar Multiplication (MSM)，Intel OneAPI

总结:<br />
本文介绍了针对零知识证明（ZKP）中的一种特殊类型——零知识简洁非交互式知识论证（zk-SNARKs）在FPGA上的加速器架构设计。文章重点关注了占据zk-SNARK系统大部分计算时间的多标量乘法（MSM）操作，并利用高度优化的Intel模数算术IP库。提出的架构充分利用了MSM的并行性，并采用了Intel OneAPI框架实现针对FPGA的设计。相较于参考软件库，该实现的速度提升了110倍至150倍，并且是首次报告使用BLS12-381和BN128椭圆曲线家族在FPGA硬件加速的结果。 <div>
arXiv:2412.12481v1 Announce Type: new 
Abstract: Zero-Knowledge Proofs (ZKPs) have emerged as an important cryptographic technique allowing one party (prover) to prove the correctness of a statement to some other party (verifier) and nothing else. ZKPs give rise to user's privacy in many applications such as blockchains, digital voting, and machine learning. Traditionally, ZKPs suffered from poor scalability but recently, a sub-class of ZKPs known as Zero-knowledge Succinct Non-interactive ARgument of Knowledges (zk-SNARKs) have addressed this challenge. They are getting significant attention and are being implemented by many public libraries. In this paper, we present a novel scalable architecture that is suitable for accelerating the zk-SNARK prover compute on FPGAs. We focus on the multi-scalar multiplication (MSM) that accounts for the majority of computation time spent in zk-SNARK systems. The MSM calculations extensive rely on modular arithmetic so highly optimized Intel IP Libraries for modular arithmetic are used. The proposed architecture exploits the parallelism inherent to MSM and is implemented using the Intel OneAPI framework for FPGAs. Our implementation runs 110x-150x faster compared to reference software library, uses a generic curve form in Jacobian coordinates and is the first to report FPGA hardware acceleration results for BLS12-381 and BN128 family of elliptic curves.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generating Move Smart Contracts based on Concepts</title>
<link>https://arxiv.org/abs/2412.12513</link>
<guid>https://arxiv.org/abs/2412.12513</guid>
<content:encoded><![CDATA[
<div> 关键词：正式验证、智能合约、Move语言、大型语言模型、ConMover

总结:
这篇论文介绍了ConMover，这是一个针对Move语言的新型框架，旨在通过利用Move概念知识图谱和少量已验证的代码示例来增强基于大规模语言模型的代码生成能力。ConMover将概念检索、规划、编码和调试等模块集成到一个迭代过程中，以细化生成的代码。评估显示，相比于基线模型，ConMover显著提高了生成代码的准确性。这表明ConMover有潜力解决资源匮乏条件下的代码生成挑战，从而更好地将自然语言描述与可靠的智能合约开发相衔接。<br /><br /> <div>
arXiv:2412.12513v1 Announce Type: new 
Abstract: The growing adoption of formal verification for smart contracts has spurred the development of new verifiable languages like Move. However, the limited availability of training data for these languages hinders effective code generation by large language models (LLMs). This paper presents ConMover, a novel framework that enhances LLM-based code generation for Move by leveraging a knowledge graph of Move concepts and a small set of verified code examples. ConMover integrates concept retrieval, planning, coding, and debugging agents in an iterative process to refine generated code. Evaluations with various open-source LLMs demonstrate substantial accuracy improvements over baseline models. These results underscore ConMover's potential to address low-resource code generation challenges, bridging the gap between natural language descriptions and reliable smart contract development.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed satellite information networks: Architecture, enabling technologies, and trends</title>
<link>https://arxiv.org/abs/2412.12587</link>
<guid>https://arxiv.org/abs/2412.12587</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式卫星信息网络(DSIN)、卫星集成互联网、创新网络架构、资源效率、跨层优化

总结:
这篇论文介绍了分布式卫星信息网络（DSIN）作为应对下一代智能应用需求增长的新兴架构，旨在通过统一开放的信息网络范式整合通信、导航和遥感等多样化的卫星系统。文章探讨了DSIN中的三种创新网络架构：分布式再生卫星网络架构、分布式卫星计算网络架构以及可重构卫星编队飞行，以实现灵活和可扩展的通信、计算与控制能力。面对网络异构性、不可预测的信道动态、稀疏资源及分散协作框架等问题，文中提出了包括信道建模与估计、云原生分布式MIMO合作、免授权大规模接入、网络路由及这些多样性技术的有效组合等一系列关键技术。为了提高整体资源效率，进一步发展了跨层优化技术以满足上层确定性、自适应和安全的信息服务要求。此外，文章还指出了实现DSIN愿景过程中的新研究方向和机遇。 <div>
arXiv:2412.12587v1 Announce Type: new 
Abstract: Driven by the vision of ubiquitous connectivity and wireless intelligence, the evolution of ultra-dense constellation-based satellite-integrated Internet is underway, now taking preliminary shape. Nevertheless, the entrenched institutional silos and limited, nonrenewable heterogeneous network resources leave current satellite systems struggling to accommodate the escalating demands of next-generation intelligent applications. In this context, the distributed satellite information networks (DSIN), exemplified by the cohesive clustered satellites system, have emerged as an innovative architecture, bridging information gaps across diverse satellite systems, such as communication, navigation, and remote sensing, and establishing a unified, open information network paradigm to support resilient space information services. This survey first provides a profound discussion about innovative network architectures of DSIN, encompassing distributed regenerative satellite network architecture, distributed satellite computing network architecture, and reconfigurable satellite formation flying, to enable flexible and scalable communication, computing and control. The DSIN faces challenges from network heterogeneity, unpredictable channel dynamics, sparse resources, and decentralized collaboration frameworks. To address these issues, a series of enabling technologies is identified, including channel modeling and estimation, cloud-native distributed MIMO cooperation, grant-free massive access, network routing, and the proper combination of all these diversity techniques. Furthermore, to heighten the overall resource efficiency, the cross-layer optimization techniques are further developed to meet upper-layer deterministic, adaptive and secure information services requirements. In addition, emerging research directions and new opportunities are highlighted on the way to achieving the DSIN vision.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AsyncSC: An Asynchronous Sidechain for Multi-Domain Data Exchange in Internet of Things</title>
<link>https://arxiv.org/abs/2412.12723</link>
<guid>https://arxiv.org/abs/2412.12723</guid>
<content:encoded><![CDATA[
<div> 关键词：侧链技术、物联网、异步、延迟聚合签名、跨链交互

总结:
本文提出了一种名为AsyncSC的新型异步侧链构造方案，旨在解决物联网多域数据交换中同步网络需求限制的问题，从而实现更高效的跨链互动。AsyncSC利用委员会提供跨区块链服务（C-BaaS），并结合了聚合签名和可验证延迟函数的思想，创新性地提出了延迟聚合签名（DAS）这一密码学原语，用于构建确保跨链交互安全的异步跨链证明（ACP）。为保证异步交易的一致性，文章还设计了一种多级缓冲交易池来保障交易顺序。通过对AsyncSC的安全性进行分析与证明，并在模拟异步通信环境中进行全面评估，实验结果显示AsyncSC相比现有最优方案，在性能上平均提升了1.21至3.96倍，减少了59.76%至83.61%的交易延迟，并保持了相当的资源开销。 <div>
arXiv:2412.12723v1 Announce Type: new 
Abstract: Sidechain techniques improve blockchain scalability and interoperability, providing decentralized exchange and cross-chain collaboration solutions for Internet of Things (IoT) data across various domains. However, current state-of-the-art (SOTA) schemes for IoT multi-domain data exchange are constrained by the need for synchronous networks, hindering efficient cross-chain interactions in discontinuous networks and leading to suboptimal data exchange. In this paper, we propose AsyncSC, a novel asynchronous sidechain construction. It employs a committee to provide Cross-Blockchain as a Service (C-BaaS) for data exchange in multi-domain IoT. To fulfill the need for asynchronous and efficient data exchange, we combine the ideas of aggregate signatures and verifiable delay functions to devise a novel cryptographic primitive called delayed aggregate signature (DAS), which constructs asynchronous cross-chain proofs (ACPs) that ensure the security of cross-chain interactions. To ensure the consistency of asynchronous transactions, we propose a multilevel buffered transaction pool that guarantees the transaction sequencing. We analyze and prove the security of AsyncSC, simulate an asynchronous communication environment, and conduct a comprehensive evaluation. The results show that AsyncSC outperforms SOTA schemes, improving throughput by an average of 1.21 to 3.96 times, reducing transaction latency by 59.76% to 83.61%, and maintaining comparable resource overhead.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scrutinizing the Vulnerability of Decentralized Learning to Membership Inference Attacks</title>
<link>https://arxiv.org/abs/2412.12837</link>
<guid>https://arxiv.org/abs/2412.12837</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化学习、隐私攻击、成员推理攻击、模型混合策略、通信图全局混合属性

总结:
<br />
本文探讨了去中心化学习环境中，针对机器学习模型训练中的敏感信息泄露问题，尤其是成员推理攻击（MIA）的脆弱性。研究通过改变图结构（如邻居数量）、图动态和聚合策略，对不同数据集和数据分布下的多种去中心化学习架构进行了深入分析。文章揭示了一个重要的新发现：去中心化学习对MIA的脆弱性高度相关于( i )每个节点在接收相邻节点模型后执行的局部模型混合策略及( ii )通信图的全局混合特性。实验结果基于四个数据集并理论分析了各种去中心化架构的混合属性，为设计能降低MIA脆弱性的去中心化学习系统提供了宝贵教训。 <div>
arXiv:2412.12837v1 Announce Type: new 
Abstract: The primary promise of decentralized learning is to allow users to engage in the training of machine learning models in a collaborative manner while keeping their data on their premises and without relying on any central entity. However, this paradigm necessitates the exchange of model parameters or gradients between peers. Such exchanges can be exploited to infer sensitive information about training data, which is achieved through privacy attacks (e.g Membership Inference Attacks -- MIA). In order to devise effective defense mechanisms, it is important to understand the factors that increase/reduce the vulnerability of a given decentralized learning architecture to MIA. In this study, we extensively explore the vulnerability to MIA of various decentralized learning architectures by varying the graph structure (e.g number of neighbors), the graph dynamics, and the aggregation strategy, across diverse datasets and data distributions. Our key finding, which to the best of our knowledge we are the first to report, is that the vulnerability to MIA is heavily correlated to (i) the local model mixing strategy performed by each node upon reception of models from neighboring nodes and (ii) the global mixing properties of the communication graph. We illustrate these results experimentally using four datasets and by theoretically analyzing the mixing properties of various decentralized architectures. Our paper draws a set of lessons learned for devising decentralized learning systems that reduce by design the vulnerability to MIA.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>C-FedRAG: A Confidential Federated Retrieval-Augmented Generation System</title>
<link>https://arxiv.org/abs/2412.13163</link>
<guid>https://arxiv.org/abs/2412.13163</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Retrieval Augmented Generation (RAG), Confidential Computing (CC), Federated Retrieval Augmented Generation (FedRAG), NVIDIA FLARE SDK

总结:
本文提出了一种利用机密计算技术解决组织使用大型语言模型（LLMs）进行知识查询和分析时面临的挑战的方法。针对需要跨多个数据孤岛获取更丰富、相关上下文的需求，以及受限于复杂的数据共享政策问题，文章引入了安全的联邦检索增强生成（FedRAG）——Confidential Federated Retrieval Augmented Generation (C-FedRAG)。C-FedRAG系统通过确保上下文机密性，允许在去中心化的数据提供者网络中安全地扩展和连接RAG工作流程。此外，文中还展示了如何使用NVIDIA FLARE SDK实现C-FedRAG系统，并通过MedRAG工具包和MIRAGE基准测试数据集对其性能进行了评估。 <div>
arXiv:2412.13163v1 Announce Type: new 
Abstract: Organizations seeking to utilize Large Language Models (LLMs) for knowledge querying and analysis often encounter challenges in maintaining an LLM fine-tuned on targeted, up-to-date information that keeps answers relevant and grounded. Retrieval Augmented Generation (RAG) has quickly become a feasible solution for organizations looking to overcome the challenges of maintaining proprietary models and to help reduce LLM hallucinations in their query responses. However, RAG comes with its own issues regarding scaling data pipelines across tiered-access and disparate data sources. In many scenarios, it is necessary to query beyond a single data silo to provide richer and more relevant context for an LLM. Analyzing data sources within and across organizational trust boundaries is often limited by complex data-sharing policies that prohibit centralized data storage, therefore, inhibit the fast and effective setup and scaling of RAG solutions. In this paper, we introduce Confidential Computing (CC) techniques as a solution for secure Federated Retrieval Augmented Generation (FedRAG). Our proposed Confidential FedRAG system (C-FedRAG) enables secure connection and scaling of a RAG workflows across a decentralized network of data providers by ensuring context confidentiality. We also demonstrate how to implement a C-FedRAG system using the NVIDIA FLARE SDK and assess its performance using the MedRAG toolkit and MIRAGE benchmarking dataset.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Challenges Faced by Large Language Models in Solving Multi-Agent Flocking</title>
<link>https://arxiv.org/abs/2404.04752</link>
<guid>https://arxiv.org/abs/2404.04752</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv、多智能体集结、大型语言模型、协同空间推理、未来改进

<br /><br />总结:
这篇论文讨论了大型语言模型（LLMs）在实现多智能体集结（flocking）任务中面临的挑战。尽管LLMs在解决个体决策者间的协作任务上展现出强大的能力，但在实现多智能体保持一定形状和距离的同时靠近彼此的行为上却表现不佳，通常仅收敛到初始位置的平均值或相互远离。作者认为，LLMs无法有效地理解和处理保持形状和保持距离的问题。为了解决这一问题并增强LLMs在协同空间推理方面的能力，论文提出了未来的研究和改进建议，以期为更复杂的多智能体任务奠定基础。 <div>
arXiv:2404.04752v2 Announce Type: replace 
Abstract: Flocking is a behavior where multiple agents in a system attempt to stay close to each other while avoiding collision and maintaining a desired formation. This is observed in the natural world and has applications in robotics, including natural disaster search and rescue, wild animal tracking, and perimeter surveillance and patrol. Recently, large language models (LLMs) have displayed an impressive ability to solve various collaboration tasks as individual decision-makers. Solving multi-agent flocking with LLMs would demonstrate their usefulness in situations requiring spatial and decentralized decision-making. Yet, when LLM-powered agents are tasked with implementing multi-agent flocking, they fall short of the desired behavior. After extensive testing, we find that agents with LLMs as individual decision-makers typically opt to converge on the average of their initial positions or diverge from each other. After breaking the problem down, we discover that LLMs cannot understand maintaining a shape or keeping a distance in a meaningful way. Solving multi-agent flocking with LLMs would enhance their ability to understand collaborative spatial reasoning and lay a foundation for addressing more complex multi-agent tasks. This paper discusses the challenges LLMs face in multi-agent flocking and suggests areas for future improvement and research.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- Blockchain and Applications</title>
<link>https://arxiv.org/abs/2410.10110</link>
<guid>https://arxiv.org/abs/2410.10110</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、加密算法、比特币、以太坊、应用领域<br /><br />总结:<br />
本文详细探讨了区块链技术及其在各领域的应用，首先介绍了密码学基础，包括对称加密和非对称加密及其在确保区块链系统安全与信任中的作用。接着分析了比特币和以太坊的结构与机制，涵盖了工作量证明、权益证明以及智能合约等内容。文中还强调了区块链在去中心化金融（DeFi）、供应链管理和身份认证等行业的实际应用，并讨论了区块链共识机制及可扩展性挑战，提到了如Layer 2解决方案和跨链互操作性等新兴技术。最后，文章概述了当前学术界对区块链的研究现状及未来可能的发展方向。 <div>
arXiv:2410.10110v2 Announce Type: replace 
Abstract: A detailed exploration of blockchain technology and its applications across various fields is provided, beginning with an introduction to cryptography fundamentals, including symmetric and asymmetric encryption, and their roles in ensuring security and trust within blockchain systems. The structure and mechanics of Bitcoin and Ethereum are then examined, covering topics such as proof-of-work, proof-of-stake, and smart contracts. Practical applications of blockchain in industries like decentralized finance (DeFi), supply chain management, and identity authentication are highlighted. The discussion also extends to consensus mechanisms and scalability challenges in blockchain, offering insights into emerging technologies like Layer 2 solutions and cross-chain interoperability. The current state of academic research on blockchain and its potential future developments are also addressed.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Benchmarking Federated Learning for Semantic Datasets: Federated Scene Graph Generation</title>
<link>https://arxiv.org/abs/2412.10436</link>
<guid>https://arxiv.org/abs/2412.10436</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, 语义异质性, 客户端数据分布, Panoptic Scene Graph Generation, 联邦学习基准

<br /><br />总结:
本文提出了一种建立具有可控语义异质性的联邦学习(Federated Learning)基准的方法。现有的联邦学习基准主要关注单一语义（如一热标签）的数据处理，而对复杂语义信息（如Panoptic Scene Graph Generation中的对象、主题和它们之间的关系）处理的关注较少。文中提出了两个关键步骤：基于语义的数据聚类和通过可控语义异质性进行客户端数据分布。作为概念验证，构建了一个联邦场景图生成(FL-PSG)基准，展示了现有方法在具有可控语义异质性的联邦学习环境下的有效性。此外，作者还证明了该基准的有效性，通过应用鲁棒的联邦学习算法来应对数据异质性，从而展示性能提升。相关代码已在GitHub上开源。 <div>
arXiv:2412.10436v1 Announce Type: new 
Abstract: Federated learning (FL) has recently garnered attention as a data-decentralized training framework that enables the learning of deep models from locally distributed samples while keeping data privacy. Built upon the framework, immense efforts have been made to establish FL benchmarks, which provide rigorous evaluation settings that control data heterogeneity across clients. Prior efforts have mainly focused on handling relatively simple classification tasks, where each sample is annotated with a one-hot label, such as MNIST, CIFAR, LEAF benchmark, etc. However, little attention has been paid to demonstrating an FL benchmark that handles complicated semantics, where each sample encompasses diverse semantic information from multiple labels, such as Panoptic Scene Graph Generation (PSG) with objects, subjects, and relations between them. Because the existing benchmark is designed to distribute data in a narrow view of a single semantic, e.g., a one-hot label, managing the complicated semantic heterogeneity across clients when formalizing FL benchmarks is non-trivial. In this paper, we propose a benchmark process to establish an FL benchmark with controllable semantic heterogeneity across clients: two key steps are i) data clustering with semantics and ii) data distributing via controllable semantic heterogeneity across clients. As a proof of concept, we first construct a federated PSG benchmark, demonstrating the efficacy of the existing PSG methods in an FL setting with controllable semantic heterogeneity of scene graphs. We also present the effectiveness of our benchmark by applying robust federated learning algorithms to data heterogeneity to show increased performance. Our code is available at https://github.com/Seung-B/FL-PSG.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Client-Side Patching against Backdoor Attacks in Federated Learning</title>
<link>https://arxiv.org/abs/2412.10605</link>
<guid>https://arxiv.org/abs/2412.10605</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning, backdoor attacks, defense mechanism, adversarial learning, model patching

总结:
这篇论文提出了一种针对联邦学习系统的新颖防御机制，旨在减轻客户端遭受的后门攻击。该方法利用对抗学习技术和模型修补来中和后门攻击的影响。通过对MNIST和Fashion-MNIST数据集进行广泛实验，论文表明该防御策略能有效降低后门攻击的准确性，在i.i.d.和非i.i.d.场景下优于现有最先进的防御方法（如LFighter、FLAME和RoseAgg），同时保持了对清洁数据具有竞争力或更优的准确性。<br /><br /> <div>
arXiv:2412.10605v1 Announce Type: new 
Abstract: Federated learning is a versatile framework for training models in decentralized environments. However, the trust placed in clients makes federated learning vulnerable to backdoor attacks launched by malicious participants. While many defenses have been proposed, they often fail short when facing heterogeneous data distributions among participating clients. In this paper, we propose a novel defense mechanism for federated learning systems designed to mitigate backdoor attacks on the clients-side. Our approach leverages adversarial learning techniques and model patching to neutralize the impact of backdoor attacks. Through extensive experiments on the MNIST and Fashion-MNIST datasets, we demonstrate that our defense effectively reduces backdoor accuracy, outperforming existing state-of-the-art defenses, such as LFighter, FLAME, and RoseAgg, in i.i.d. and non-i.i.d. scenarios, while maintaining competitive or superior accuracy on clean data.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Trust-Centric Approach To Quantifying Maturity and Security in Internet Voting Protocols</title>
<link>https://arxiv.org/abs/2412.10611</link>
<guid>https://arxiv.org/abs/2412.10611</guid>
<content:encoded><![CDATA[
<div> 关键词: 投票、互联网投票协议、安全、成熟度框架、电子投票成熟度框架(EVMF)

总结:<br />
本文针对互联网投票协议的安全性和成熟度评估缺乏统一标准和考虑实际部署需求的问题，提出了一种以信任为核心的成熟度评分框架——电子投票成熟度框架（EVMF）。该框架详细分析了十六种互联网投票系统的安全属性、信任假设、技术复杂性和实用可用性。EVMF旨在支持对现实世界部署问题的细微评估，帮助决策者根据特定应用场景选择合适的系统。此外，该框架不仅适用于投票系统，还可以应用于其他需要权衡去中心化、信任和安全性的重要领域，如数字身份、以太坊二层扩容方案以及联邦数据基础设施。EVMF为政策制定者和技术专家提供了一个可扩展的工具包，能够在单变量尺度上标准化技术和非技术要求。 <div>
arXiv:2412.10611v1 Announce Type: new 
Abstract: Voting is a cornerstone of collective participatory decision-making in contexts ranging from political elections to decentralized autonomous organizations (DAOs). Despite the proliferation of internet voting protocols promising enhanced accessibility and efficiency, their evaluation and comparison are complicated by a lack of standardized criteria and unified definitions of security and maturity. Furthermore, socio-technical requirements by decision makers are not structurally taken into consideration when comparing internet voting systems. This paper addresses this gap by introducing a trust-centric maturity scoring framework to quantify the security and maturity of sixteen internet voting systems. A comprehensive trust model analysis is conducted for selected internet voting protocols, examining their security properties, trust assumptions, technical complexity, and practical usability. In this paper we propose the electronic voting maturity framework (EVMF) which supports nuanced assessment that reflects real-world deployment concerns and aids decision-makers in selecting appropriate systems tailored to their specific use-case requirements. The framework is general enough to be applied to other systems, where the aspects of decentralization, trust, and security are crucial, such as digital identity, Ethereum layer-two scaling solutions, and federated data infrastructures. Its objective is to provide an extendable toolkit for policy makers and technology experts alike that normalizes technical and non-technical requirements on a univariate scale.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A technical solution for the rule of law, peace, security, and evolvability of global cyberspace -- solve the three genetic defects of IP network</title>
<link>https://arxiv.org/abs/2412.10722</link>
<guid>https://arxiv.org/abs/2412.10722</guid>
<content:encoded><![CDATA[
<div> 关键词: Co-governed Multi-Identifier Network (CoG-MIN), 网络架构, 区块链技术, 网络安全, 互联网缺陷

<br /><br />总结:
针对现有互联网存在的权力集中、安全隐患及IP协议刚性等问题，本文提出了一个新的网络架构——Co-governed Multi-Identifier Network (CoG-MIN，简称MIN)。该架构利用区块链技术确保全球各国在网络治理和法治方面的平等参与，并通过整合用户认证、数据签名和加密机制提升了网络安全性能，在国际网络安全竞赛中表现出色。此外，CoG-MIN支持不同标识系统的演进与互操作性，保持与IP协议兼容的同时，也为逐步过渡到非IP架构提供了适应性强的生态系统，有利于未来网络架构的多样化发展和持续进化。同时，文中还介绍了关于网络安全的三个定理。 <div>
arXiv:2412.10722v1 Announce Type: new 
Abstract: Since its inception in the 1960s, the internet has profoundly transformed human life. However, its original design now struggles to meet the evolving demands of modern society. Three primary defects have emerged: First, the concentration of power among a few dominant entities has intensified international conflicts and widened the technological divide. Second, the Internet Protocol (IP)-based system lacks inherent security, leading to frequent global cybersecurity incidents. Third, the rigidity of the IP protocol has hindered the sustainable development of cyberspace, as it resists necessary adaptations and innovations. Addressing these issues is crucial for the future resilience and security of the global digital landscape.
  To address these challenges, we propose the Co-governed Multi-Identifier Network (CoG-MIN briefly as MIN), a novel network architecture that leverages blockchain technology to ensure equal participation of countries worldwide in cyberspace governance and the rule of law. As a next-generation network system, CoG-MIN integrates mechanisms such as user authentication, data signatures, and encryption to significantly enhance network security. In testing environments, CoG-MIN has consistently withstood extensive attacks during various international cybersecurity competitions. Additionally, CoG-MIN supports the evolution and interoperability of different identifier systems, remains IP-compatible, and facilitates a gradual transition away from IP, providing an adaptable ecosystem for diverse network architectures. This adaptability fosters the development and evolution of diverse network architectures within CoG-MIN, making it a natural progression for the internet's future development.
  We further introduce a trilogy of cyberspace security theorems... (Due to character limitations, the full abstract is available in the paper PDF.)
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Serial Scammers and Attack of the Clones: How Scammers Coordinate Multiple Rug Pulls on Decentralized Exchanges</title>
<link>https://arxiv.org/abs/2412.10993</link>
<guid>https://arxiv.org/abs/2412.10993</guid>
<content:encoded><![CDATA[
<div> 关键词：scammer addresses, Rug Pulls, decentralized exchanges, scam network, wash trading

<br /><br />总结:
本文研究了普遍存在的连续欺诈者现象，这些欺诈者使用数千个地址在两个最流行的去中心化交易所（Uniswap 和 Pancakeswap）上进行一系列类似的拉高出货行为。研究人员首先构建了一个包含约384,000个欺诈地址的列表，这些地址涉及这两个平台上所有一天内的拉高出货事件，并识别出了多种独特的欺诈模式，如星形、链形和多数流欺诈集群。接着，他们提出了一种算法，能从给定的欺诈地址构建一个完整的欺诈网络，该网络不仅包括欺诈者地址，还包括存款人、取款人、转账者、协调者以及最重要的洗盘交易者。作者指出，现有针对拉高出货的研究未能考虑到洗盘交易的成本，导致利润估计值被夸大。通过了解洗盘交易者的身份，文章对单个欺诈池以及整个（连续）欺诈网络的真实利润进行了更为准确的估算，考虑到了洗盘交易的费用。 <div>
arXiv:2412.10993v1 Announce Type: new 
Abstract: We explored in this work the ubiquitous phenomenon of serial scammers, who deploy thousands of addresses to conduct a series of similar Rug Pulls on popular decentralized exchanges (DEXs). We first constructed a list of about 384,000 scammer addresses behind all 1-day Rug Pulls on the two most popular DEXs, Uniswap (Ethereum) and Pancakeswap (BSC), and identified many distinctive scam patterns including star-shaped, chain-shaped, and majority-flow scam clusters. We then proposed an algorithm to build a complete scam network from given scammer addresses, which consists of not only scammer addresses but also supporting addresses including depositors, withdrawers, transferrers, coordinators, and most importantly, wash traders. We note that profit estimations in existing works on Rug Pulls failed to capture the cost of wash trading, leading to inflated figures. Knowing who the wash traders are, we established a more accurate estimate for the true profit of individual scam pools as well as of the entire (serial) scam network by taking into account the wash-trading expenses.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Knowledge Migration Framework for Smart Contract Vulnerability Detection</title>
<link>https://arxiv.org/abs/2412.11175</link>
<guid>https://arxiv.org/abs/2412.11175</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contract, vulnerability detection, AF-STip, knowledge migration, data-free knowledge distillation, adaptive fusion module, F1值, accuracy

总结:
本文提出了一种新的智能合约漏洞检测框架AF-STip，该框架针对现有模型泛化能力的局限性，通过数据免费的知识蒸馏方法，利用教师网络将处理过的智能合约知识迁移到学生模型中，增强其漏洞检测能力。AF-STip提升了模型的特征提取和跨类适应能力，并降低了计算开销。此外，文中还提出了一种自适应融合模块来强化特征信息的交互与融合，进一步提升漏洞特征的提取效果。实验结果显示，STip模型在不披露原始智能合约数据的情况下，对四种漏洞的平均F1值检测得分为91.16%。为了验证轻量级迁移学习方法的有效性，学生模型被部署到针对新型漏洞类型的迁移学习任务中，取得了91.02%的准确率和90.46%的F1得分。据作者所知，AF-STip是首个将无数据知识迁移应用于智能合约漏洞检测的模型，它在显著降低计算开销的同时，仍能展现出优异的新颖漏洞检测性能。 <div>
arXiv:2412.11175v1 Announce Type: new 
Abstract: As a cornerstone of blockchain technology in the 3.0 era, smart contracts play a pivotal role in the evolution of blockchain systems. In order to address the limitations of existing smart contract vulnerability detection models with regard to their generalisation capability, an AF-STip smart contract vulnerability detection framework incorporating efficient knowledge migration is proposed. AF-STip employs the teacher network as the main model and migrates the knowledge processed by the smart contract to the student model using a data-free knowledge distillation method. The student model utilises this knowledge to enhance its vulnerability detection capabilities. The approach markedly enhances the model's capacity for feature extraction and cross-class adaptation, while concurrently reducing computational overhead.In order to further enhance the extraction of vulnerability features, an adaptive fusion module is proposed in this paper, which aims to strengthen the interaction and fusion of feature information.The experimental results demonstrate that the STip model attains an average F1 value detection score of 91.16% for the four vulnerabilities without disclosing the original smart contract data. To validate the viability of the proposed lightweight migration approach, the student model is deployed in a migration learning task targeting a novel vulnerability type, resulting in an accuracy of 91.02% and an F1 score of 90.46%. To the best of our knowledge, AF-STip is the inaugural model to apply data-free knowledge migration to smart contract vulnerability detection. While markedly reducing the computational overhead, the method still demonstrates exceptional performance in detecting novel vulnerabilities.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ProFe: Communication-Efficient Decentralized Federated Learning via Distillation and Prototypes</title>
<link>https://arxiv.org/abs/2412.11207</link>
<guid>https://arxiv.org/abs/2412.11207</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Federated Learning (DFL)，ProFe，知识蒸馏，原型学习，量化技术

总结:<br />
本文介绍了一种针对去中心化联邦学习（DFL）的新型通信优化算法ProFe。该算法综合运用了知识蒸馏、原型学习和量化技术，旨在解决分布式环境下模型聚合与通信效率的问题，特别是应对异构数据分布带来的挑战。ProFe利用大模型的知识训练更小的模型进行聚合，通过引入原型以更好地学习未见过的类别，并应用量化技术降低通信轮次中的数据传输成本。实验结果显示，ProFe提出的算法在保持或提升模型性能的同时，能够将通信成本降低约40%-50%，但会增加约20%的训练时间，从而形成了一定的效益与复杂性之间的权衡。 <div>
arXiv:2412.11207v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) trains models in a collaborative and privacy-preserving manner while removing model centralization risks and improving communication bottlenecks. However, DFL faces challenges in efficient communication management and model aggregation within decentralized environments, especially with heterogeneous data distributions. Thus, this paper introduces ProFe, a novel communication optimization algorithm for DFL that combines knowledge distillation, prototype learning, and quantization techniques. ProFe utilizes knowledge from large local models to train smaller ones for aggregation, incorporates prototypes to better learn unseen classes, and applies quantization to reduce data transmitted during communication rounds. The performance of ProFe has been validated and compared to the literature by using benchmark datasets like MNIST, CIFAR10, and CIFAR100. Results showed that the proposed algorithm reduces communication costs by up to ~40-50% while maintaining or improving model performance. In addition, it adds ~20% training time due to increased complexity, generating a trade-off.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Domain Generalization with Label Smoothing and Balanced Decentralized Training</title>
<link>https://arxiv.org/abs/2412.11408</link>
<guid>https://arxiv.org/abs/2412.11408</guid>
<content:encoded><![CDATA[
<div> 关键词: 异构数据、联邦学习、域泛化、标签平滑、平衡分散训练

总结:
<br />
本文提出了一种名为FedSB的新方法，用于解决联邦学习框架内的异构数据挑战。FedSB通过客户端的标签平滑技术防止过度拟合特定领域的特征，从而提升模型在不同领域间的泛化能力。同时，该方法还引入了平衡分散训练的预算机制，优化了客户端之间的训练分配，进而提升了全局模型的性能。实验结果显示，在四个常用的多域数据集PACS、VLCS、OfficeHome和TerraInc上，FedSB超越了现有竞争方法，在其中三个数据集上取得了最先进的结果，证明了FedSB在应对数据异构性方面的有效性。 <div>
arXiv:2412.11408v1 Announce Type: new 
Abstract: In this paper, we propose a novel approach, Federated Domain Generalization with Label Smoothing and Balanced Decentralized Training (FedSB), to address the challenges of data heterogeneity within a federated learning framework. FedSB utilizes label smoothing at the client level to prevent overfitting to domain-specific features, thereby enhancing generalization capabilities across diverse domains when aggregating local models into a global model. Additionally, FedSB incorporates a decentralized budgeting mechanism which balances training among clients, which is shown to improve the performance of the aggregated global model. Extensive experiments on four commonly used multi-domain datasets, PACS, VLCS, OfficeHome, and TerraInc, demonstrate that FedSB outperforms competing methods, achieving state-of-the-art results on three out of four datasets, indicating the effectiveness of FedSB in addressing data heterogeneity.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TRAIL: Trust-Aware Client Scheduling for Semi-Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2412.11448</link>
<guid>https://arxiv.org/abs/2412.11448</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、半分布式联邦学习（Semi-Decentralized Federated Learning）、动态客户端状态、信任感知客户端调度机制（TRAIL）、自适应隐藏半马尔可夫模型（AHSMM）

总结:<br />
针对半分布式联邦学习（SD-FL）中客户端通信和训练状态动态变化的问题，本文提出了一个名为TRAIL的信任感知客户端调度机制。TRAIL着重考虑了实际场景中的动态挑战，尤其是在边缘服务器和客户端使用不可靠的簇内模型聚合和簇间模型共识训练共享全局模型的框架下。文章首先利用自适应隐藏半马尔可夫模型（AHSMM）评估客户端的通信状态和贡献；接着，为最小化全局训练损失，提出了一项客户端-服务器关联优化问题；并基于收敛分析设计了一种贪心客户端调度算法。实验结果表明，与现有最优基线相比，TRAIL在真实数据集上的测试精度提高了8.7%，训练损失降低了15.3%。 <div>
arXiv:2412.11448v1 Announce Type: new 
Abstract: Due to the sensitivity of data, federated learning (FL) is employed to enable distributed machine learning while safeguarding data privacy and accommodating the requirements of various devices. However, in the context of semi-decentralized federated learning (SD-FL), clients' communication and training states are dynamic. This variability arises from local training fluctuations, heterogeneous data distributions, and intermittent client participation. Most existing studies primarily focus on stable client states, neglecting the dynamic challenges present in real-world scenarios. To tackle this issue, we propose a trust-aware client scheduling mechanism (TRAIL) that assesses client states and contributions, enhancing model training efficiency through selective client participation. Our focus is on a semi-decentralized federated learning framework where edge servers and clients train a shared global model using unreliable intra-cluster model aggregation and inter-cluster model consensus. First, we develop an adaptive hidden semi-Markov model (AHSMM) to estimate clients' communication states and contributions. Next, we address a client-server association optimization problem to minimize global training loss. Using convergence analysis, we propose a greedy client scheduling algorithm. Finally, our experiments conducted on real-world datasets demonstrate that TRAIL outperforms state-of-the-art baselines, achieving an improvement of 8.7\% in test accuracy and a reduction of 15.3\% in training loss.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>UA-PDFL: A Personalized Approach for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2412.11674</link>
<guid>https://arxiv.org/abs/2412.11674</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、去中心化联邦学习（Decentralized Federated Learning）、非独立同分布数据（Non-IID）、个性化层、UA-PDFL

总结:<br />
本文提出了一种新颖的单元表示辅助个性化去中心化联邦学习框架——UA-PDFL，旨在解决去中心化联邦学习中非独立同分布数据带来的训练问题。该框架通过单元表示自适应地调整个性化层的程度，以应对不同级别的数据偏斜。此外，文中还提出了客户端Dropout和层级个性化策略，以进一步提升去中心化联邦学习的性能。实验结果充分证明了所提方法的有效性。 <div>
arXiv:2412.11674v1 Announce Type: new 
Abstract: Federated learning (FL) is a privacy preserving machine learning paradigm designed to collaboratively learn a global model without data leakage. Specifically, in a typical FL system, the central server solely functions as an coordinator to iteratively aggregate the collected local models trained by each client, potentially introducing single-point transmission bottleneck and security threats. To mitigate this issue, decentralized federated learning (DFL) has been proposed, where all participating clients engage in peer-to-peer communication without a central server. Nonetheless, DFL still suffers from training degradation as FL does due to the non-independent and identically distributed (non-IID) nature of client data. And incorporating personalization layers into DFL may be the most effective solutions to alleviate the side effects caused by non-IID data. Therefore, in this paper, we propose a novel unit representation aided personalized decentralized federated learning framework, named UA-PDFL, to deal with the non-IID challenge in DFL. By adaptively adjusting the level of personalization layers through the guidance of the unit representation, UA-PDFL is able to address the varying degrees of data skew. Based on this scheme, client-wise dropout and layer-wise personalization are proposed to further enhance the learning performance of DFL. Extensive experiments empirically prove the effectiveness of our proposed method.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lightweight Decentralized Neural Network-Based Strategies for Multi-Robot Patrolling</title>
<link>https://arxiv.org/abs/2412.11916</link>
<guid>https://arxiv.org/abs/2412.11916</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized multi-robot patrol, neural network, idleness minimization, intelligent intruder model, communication failure

总结:
<br />
本文提出了一种针对分布式多机器人巡逻问题的新方法，该问题以往主要依赖于手工设计的策略来最小化图结构环境中的“空闲时间”。文章介绍了两种基于轻量级神经网络的策略，并展示它们在减少空闲时间和对抗智能入侵者模型方面显著优于现有策略。此外，文中还研究了这些策略在通信失败情况下的鲁棒性，并对未来策略设计提出了重要考量。 <div>
arXiv:2412.11916v1 Announce Type: new 
Abstract: The problem of decentralized multi-robot patrol has previously been approached primarily with hand-designed strategies for minimization of 'idlenes' over the vertices of a graph-structured environment. Here we present two lightweight neural network-based strategies to tackle this problem, and show that they significantly outperform existing strategies in both idleness minimization and against an intelligent intruder model, as well as presenting an examination of robustness to communication failure. Our results also indicate important considerations for future strategy design.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean Field Game and Control for Switching Hybrid Systems</title>
<link>https://arxiv.org/abs/2412.10522</link>
<guid>https://arxiv.org/abs/2412.10522</guid>
<content:encoded><![CDATA[
<div> 关键词：mean field games, controls, hybrid systems, switching, integro-partial differential equation

总结:
本文提出了一种针对切换混合系统的平均场游戏和控制策略，并设计了解决由此产生的积分偏微分方程的计算方法。该方法使得在大规模具有突发环境变化的紧急疏散等场景中，实现可扩展的、分散式的决策制定成为可能。文章通过数值例子进一步展示了这一理论的应用价值。 <div>
arXiv:2412.10522v1 Announce Type: cross 
Abstract: Mean field games and controls involve guiding the behavior of large populations of interacting agents, where each individual's influence on the group is negligible but collectively impacts overall dynamics. Hybrid systems integrate continuous dynamics with discrete transitions, effectively modeling the complex interplay between continuous flows and instantaneous jumps in a unified framework. This paper formulates mean field game and control strategies for switching hybrid systems and proposes computational methods to solve the resulting integro-partial differential equation. This approach enables scalable, decentralized decision-making in large-scale switching systems, which is illustrated through numerical examples in an emergency evacuation scenario with sudden changes in the surrounding environment.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fuzz on the Beach: Fuzzing Solana Smart Contracts</title>
<link>https://arxiv.org/abs/2309.03006</link>
<guid>https://arxiv.org/abs/2309.03006</guid>
<content:encoded><![CDATA[
<div> 关键词：Solana、智能合约、FuzzDelSol、二进制模糊测试、安全分析

总结:
本文针对Solana智能合约的安全分析领域提出了一种新的解决方案——FuzzDelSol，它是首个专为Solana设计的二进制代码覆盖导向的模糊测试架构。由于Solana执行环境的状态less特性引入了特有的攻击模式，现有的智能合约安全性工具大多无法适应。FuzzDelSol不仅能够准确模拟运行时如智能合约交互等具体细节，而且由于大多数Solana合约没有源代码可用，因此它直接对合约的二进制代码进行操作。为了弥补缺乏语义信息的问题，研究者们从低级别程序和状态信息中精心提取数据，开发出一套涵盖Solana主要错误类别的bug检测器。通过在6049个智能合约上的广泛评估，FuzzDelSol的bug检测器表现出高精度和召回率，据作者所知，这是针对Solana主网的最大规模的安全性评估。 <div>
arXiv:2309.03006v3 Announce Type: replace 
Abstract: Solana has quickly emerged as a popular platform for building decentralized applications (DApps), such as marketplaces for non-fungible tokens (NFTs). A key reason for its success are Solana's low transaction fees and high performance, which is achieved in part due to its stateless programming model. Although the literature features extensive tooling support for smart contract security, current solutions are largely tailored for the Ethereum Virtual Machine. Unfortunately, the very stateless nature of Solana's execution environment introduces novel attack patterns specific to Solana requiring a rethinking for building vulnerability analysis methods.
  In this paper, we address this gap and propose FuzzDelSol, the first binary-only coverage-guided fuzzing architecture for Solana smart contracts. FuzzDelSol faithfully models runtime specifics such as smart contract interactions. Moreover, since source code is not available for the large majority of Solana contracts, FuzzDelSol operates on the contract's binary code. Hence, due to the lack of semantic information, we carefully extracted low-level program and state information to develop a diverse set of bug oracles covering all major bug classes in Solana. Our extensive evaluation on 6049 smart contracts shows that FuzzDelSol's bug oracles find bugs with a high precision and recall. To the best of our knowledge, this is the largest evaluation of the security landscape on the Solana mainnet.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis</title>
<link>https://arxiv.org/abs/2311.02778</link>
<guid>https://arxiv.org/abs/2311.02778</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse、多传感器混合现实房间数据集(MuSHRoom)、几何重建、真实感建模、联合学习

<br /><br />总结:
本文提出了一种名为MuSHRoom的真实世界多传感器混合现实房间数据集，旨在解决元宇宙技术中准确、实时和沉浸式建模的挑战，特别是在消费级硬件上的非人类感知和AR/VR等沉浸式技术应用。MuSHRoom数据集针对如何在一个统一框架内结合几何重建与真实感建模（新颖视角合成）的知识空白提供了研究方向。该数据集要求方法具有成本效益、对嘈杂数据和设备具备鲁棒性，并能同时学习3D重建和新颖视角合成。文章对一些著名管道进行了基准测试，并证明了该数据集和基准在推动3D重建与高质量渲染融合方面的巨大潜力，以实现更强大且计算效率高的端到端方式。相关数据集和代码已在项目网站上发布。 <div>
arXiv:2311.02778v3 Announce Type: replace 
Abstract: Metaverse technologies demand accurate, real-time, and immersive modeling on consumer-grade hardware for both non-human perception (e.g., drone/robot/autonomous car navigation) and immersive technologies like AR/VR, requiring both structural accuracy and photorealism. However, there exists a knowledge gap in how to apply geometric reconstruction and photorealism modeling (novel view synthesis) in a unified framework. To address this gap and promote the development of robust and immersive modeling and rendering with consumer-grade devices, we propose a real-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents exciting challenges and requires state-of-the-art methods to be cost-effective, robust to noisy data and devices, and can jointly learn 3D reconstruction and novel view synthesis instead of treating them as separate tasks, making them ideal for real-world applications. We benchmark several famous pipelines on our dataset for joint 3D mesh reconstruction and novel view synthesis. Our dataset and benchmark show great potential in promoting the improvements for fusing 3D reconstruction and high-quality rendering in a robust and computationally efficient end-to-end fashion. The dataset and code are available at the project website: https://xuqianren.github.io/publications/MuSHRoom/.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)</title>
<link>https://arxiv.org/abs/2403.07573</link>
<guid>https://arxiv.org/abs/2403.07573</guid>
<content:encoded><![CDATA[
<div> 关键词: 6G、资源稀缺、计算网络融合、自适应计算网络融合、持续学习

<br /><br />总结:

本文探讨了在6G发展的背景下，为应对资源稀缺和满足严格的服务质量要求，计算网络融合（CNC）作为资源整合的重要策略受到关注。然而，现有的CNC机制可能难以适应用户、服务和资源持续变化的需求，因此文章提出了自适应计算网络融合（ACNC）的概念。ACNC利用机器学习进行自主的计算和网络资源联合编排，以处理动态且大量的用户请求。该机制主要包括状态识别和上下文检测两个功能，通过降维技术生成系统状态的抽象层次结构，并使用持续学习对系统状态进行分类，由专用的机器学习代理进行高效管理。整个流程在一个闭环中由端到端（E2E）编排器监督资源分配。文章以Metaverse场景为例，阐述了ACNC在资源调配中的应用以及采用Segment Routing v6（SRv6）的情况，并给出了ACNC的工作流程及效率评估的数值分析，最后讨论了相关挑战和未来研究方向。 <div>
arXiv:2403.07573v2 Announce Type: replace 
Abstract: In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent requirements. ACNC encompasses two primary functionalities: state recognition and context detection. Given the intricate nature of the user-service-computing-network space, the paper employs dimension reduction to generate live, holistic, abstract system states in a hierarchical structure. To address the challenges posed by dynamic changes, Continual Learning (CL) is employed, classifying the system state into contexts controlled by dedicated ML agents, enabling them to operate efficiently. These two functionalities are intricately linked within a closed loop overseen by the End-to-End (E2E) orchestrator to allocate resources. The paper introduces the components of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in resource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow, details a numerical analysis for efficiency assessment, and concludes with discussions on relevant challenges and potential avenues for future research.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Block Circulant Codes with Application to Decentralized Systems</title>
<link>https://arxiv.org/abs/2406.12160</link>
<guid>https://arxiv.org/abs/2406.12160</guid>
<content:encoded><![CDATA[
<div> 关键词：块循环码、分布式擦除解码、相对最小距离、数据可用性问题、区块链网络

<br /><br />总结:
本文提出了一种新的[n,k,d]块循环码家族，该码结构由多个局部码[$n_0 \ll n$, $k_0 \ll k$, $d_0$]组成，满足三个特性：(1) 支持分布式擦除解码；(2) 可通过参数调整将最小距离$d$放大至超过$d_0$；(3) 适用于基于密码学承诺方案的低复杂度代码符号验证。这些特性使其成为解决区块链网络中数据可用性问题的理想选择。相较于目前使用的二维Reed-Solomon (RS) 码，这种新码在高码率情况下能在保持给定速率(k/n)的同时，实现较大的相对最小距离(d/n)。

设计过程分为两步：首先，构建了线性依赖关系结构，即块循环拓扑$T_{[\mu,\lambda,\omega]}(\rho)$，其中包含$\mu$个受$\rho$个奇偶校验约束的局部码，各局部码间的符号集合以均匀模式相交，由重叠因子$\lambda$和重叠宽度$\omega$决定。接着，具体化拓扑结构，构造块循环码${\cal C}_{\text{BC}}[\mu,\lambda,\omega,\rho]$，每个局部码为$[\lambda\omega+\rho,\lambda\omega,\rho+1]$的广义RS码。该块循环码有$n=\mu(\rho+\omega)$，$k=\mu\omega$，并证明在一定条件下，其最小距离$d=\lambda\rho+1$。当$\lambda=2$时，可证得$d=2\rho+1$，并提出了一个高效的并行化擦除纠正解码器，当存在不多于$2\rho$个擦除时，能完全恢复原始编码信息。该解码器利用一种新颖的解码机制，通过迭代从一对局部码中恢复擦除的信息。 <div>
arXiv:2406.12160v2 Announce Type: replace 
Abstract: In this paper, we design a family of $[n,k,d]$ block circulant codes that consist of many $[n_0 \ll n,k_0 \ll k,d_0]$ local codes and that satisfy three properties: (1) the code supports distributed erasure decoding, (2) $d$ can be scaled above $d_0$ by a given parameter, and (3) it is amenable to low complexity verification of code symbols using a cryptographic commitment scheme. These properties make the code ideal for use in protocols that address the data availability problem in blockchain networks. Moreover, the code outperforms the currently used 2D Reed-Solomon (RS) code with a larger relative minimum distance $(d/n)$, as desired in the protocol, for a given rate $(k/n)$ in the high-rate regime.
  The code is designed in two steps. First, we develop the topology, i.e., the structure of linear dependence relations among code symbols, and define it as the block circulant topology $T_{[\mu,\lambda,\omega]}(\rho)$. In this topology, there are $\mu$ local codes, each constrained by $\rho$ parity checks. The set of symbols of a local code intersects with another in a uniform pattern, determined by two parameters, namely the overlap factor $\lambda$ and the overlap width $\omega$. Next, we instantiate the topology, i.e., to specify the coefficients of linear dependence relations, to construct the block circulant codes ${\cal C}_{\text{BC}}[\mu,\lambda,\omega,\rho]$. Every local code is a $[\lambda\omega+\rho,\lambda\omega,\rho+1]$ generalized RS code. The block circulant code has $n=\mu(\rho+\omega)$, $k=\mu\omega$ and we show that $d=\lambda\rho+1$ under certain conditions. For $\lambda=2$, we prove that $d=2\rho+1$ always, and provide an efficient, parallelizable erasure-correcting decoder that fully recovers the codeword when there are $\leq 2\rho$ erasures. The decoder uses a novel decoding mechanism that iteratively recovers erasures from pairs of local codes.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Data Analysis in the Era of Large-Language Models</title>
<link>https://arxiv.org/abs/2412.09640</link>
<guid>https://arxiv.org/abs/2412.09640</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链数据分析、大型语言模型、挑战、技术整合、研究机会

<br /><br />总结:
本文探讨了区块链数据分析的重要性及其在欺诈检测、合规性监管、智能合约审计和去中心化金融风险管理等方面的应用。目前，区块链数据分析工具面临着数据稀缺、通用性不足以及缺乏推理能力等挑战。文章提出，大型语言模型（LLMs）能够缓解这些挑战，但关于LLM在区块链数据分析中的综合应用尚未见全面系统的研究。论文系统地探索了LLM集成在区块链数据分析中的潜在技术和设计模式，并指出了未来的研究机遇与挑战，强调了这一有前景领域进一步探索的必要性。该文旨在为学术界、工业界及政策制定者提供有价值的见解，促进LLM在区块链数据分析中的融合应用。 <div>
arXiv:2412.09640v1 Announce Type: new 
Abstract: Blockchain data analysis is essential for deriving insights, tracking transactions, identifying patterns, and ensuring the integrity and security of decentralized networks. It plays a key role in various areas, such as fraud detection, regulatory compliance, smart contract auditing, and decentralized finance (DeFi) risk management. However, existing blockchain data analysis tools face challenges, including data scarcity, the lack of generalizability, and the lack of reasoning capability.
  We believe large language models (LLMs) can mitigate these challenges; however, we have not seen papers discussing LLM integration in blockchain data analysis in a comprehensive and systematic way. This paper systematically explores potential techniques and design patterns in LLM-integrated blockchain data analysis. We also outline prospective research opportunities and challenges, emphasizing the need for further exploration in this promising field. This paper aims to benefit a diverse audience spanning academia, industry, and policy-making, offering valuable insights into the integration of LLMs in blockchain data analysis.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TransferLight: Zero-Shot Traffic Signal Control on any Road-Network</title>
<link>https://arxiv.org/abs/2412.09719</link>
<guid>https://arxiv.org/abs/2412.09719</guid>
<content:encoded><![CDATA[
<div> 关键词：TransferLight、交通信号控制、道路网络、通用性、图神经网络<br /><br />总结：<br />
TransferLight是一个针对交通信号控制的创新框架，旨在实现对不同道路网络、多样化的交通条件和交叉口几何形状的强泛化能力。其核心采用了一个基于log-distance奖励函数，提供空间感知的信号优先级并能适应各种车道配置，克服了传统压力奖励方法的局限。该框架利用层次化、异质性和有向的图神经网络架构，精确捕捉细粒度的交通动态，保证了对任意交叉口布局的可转移性。通过采用分散式多智能体方法、全局奖励和新颖的状态转移先验，TransferLight构建了一个无需重训练即可零样本扩展到任何道路网络的单权重共享策略。此外，通过训练过程中的领域随机化进一步提升了模型的泛化能力。实验结果证明了TransferLight在未见过的场景中表现出优越性能，为满足城市交通日益变化的需求推进了实用且具有泛化的智能交通系统的发展。 <div>
arXiv:2412.09719v1 Announce Type: new 
Abstract: Traffic signal control plays a crucial role in urban mobility. However, existing methods often struggle to generalize beyond their training environments to unseen scenarios with varying traffic dynamics. We present TransferLight, a novel framework designed for robust generalization across road-networks, diverse traffic conditions and intersection geometries. At its core, we propose a log-distance reward function, offering spatially-aware signal prioritization while remaining adaptable to varied lane configurations - overcoming the limitations of traditional pressure-based rewards. Our hierarchical, heterogeneous, and directed graph neural network architecture effectively captures granular traffic dynamics, enabling transferability to arbitrary intersection layouts. Using a decentralized multi-agent approach, global rewards, and novel state transition priors, we develop a single, weight-tied policy that scales zero-shot to any road network without re-training. Through domain randomization during training, we additionally enhance generalization capabilities. Experimental results validate TransferLight's superior performance in unseen scenarios, advancing practical, generalizable intelligent transportation systems to meet evolving urban traffic demands.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Empowering Patients for Disease Diagnosis and Clinical Treatment: A Smart Contract-Enabled Informed Consent Strategy</title>
<link>https://arxiv.org/abs/2412.09820</link>
<guid>https://arxiv.org/abs/2412.09820</guid>
<content:encoded><![CDATA[
<div> 关键词：数字医疗系统、患者数据隐私、安全性、区块链、智能合约

总结:<br />
本文关注于数字医疗系统带来的数据隐私和安全风险，提出了一种基于区块链和智能合约的解决方案。该方案旨在更好地管理患者对于健康记录访问的知情同意授权，确保授权执行的正确性和及时性，并提高透明度与问责制。通过区块链技术保证了同意过程的不可篡改性，而智能合约则能自动执行协议，进一步强化了对患者隐私保护的机制。实验评估表明，该提议的方法可以轻松地与现有医疗系统整合，不会带来重大的财务和技术挑战。 <div>
arXiv:2412.09820v1 Announce Type: new 
Abstract: Digital healthcare systems have revolutionized medical services, facilitating provider collaboration, enhancing diagnosis, and optimizing and improving treatments. They deliver superior quality, faster, reliable, and cost-effective services. Researchers are addressing pressing health challenges by integrating information technology, computing resources, and digital health records. However, digitizing healthcare introduces significant risks to patient data privacy and security, with the potential for unauthorized access to protected health information. Although patients can authorize data access through consent, there is a pressing need for mechanisms to ensure such given consent is informed and executed properly and timely. Patients deserve transparency and accountability regarding the access to their data: who access it, when, and under what circumstances. Current healthcare systems, often centralized, leave much to be desired in managing these concerns, leading to numerous security incidents. To address these issues, we propose a system based on blockchain and smart contracts for managing informed consent for accessing health records by the treatment team members, incorporating safeguards to verify that consent processes are correctly executed. Blockchain's inherent immutability ensures the integrity of consent. Smart contracts automatically execute agreements, enhancing accountability. They provide a robust framework for protecting patient privacy in the digital age. Experimental evaluations show that the proposed approach can be integrated easily with the existing healthcare systems without incurring financial and technological challenges.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SCRUBD: Smart Contracts Reentrancy and Unhandled Exceptions Vulnerability Dataset</title>
<link>https://arxiv.org/abs/2412.09935</link>
<guid>https://arxiv.org/abs/2412.09935</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约, 以太坊区块链, 攻击漏洞, 安全工具, SCRUBD

总结:
本文介绍了针对智能合约（SC）安全性的研究，其中智能合约在以太坊区块链上处理价值数百万美元的交易，因而成为黑客利用漏洞窃取资金的目标。为了评估检测SC漏洞的各种工具的效果，需要一个带标签的SC漏洞数据集。现有的SC数据集存在局限性，如覆盖的漏洞场景有限和标签错误。为填补这一空白，文章提出了名为SCRUBD的新数据集，该数据集包括真实世界SC和合成SC，并对其进行了RE和UX漏洞的手动标记。实证研究表明，Slither在基于众包标注的数据集上检测RE漏洞的表现优于其他工具，而Sailfish则在人工合成的数据集中对于RE漏洞检测表现最佳。对于UX漏洞，Slither同样表现出超越其他工具的检测能力。 <div>
arXiv:2412.09935v1 Announce Type: new 
Abstract: Smart Contracts (SCs) handle transactions in the Ethereum blockchain worth millions of United States dollars, making them a lucrative target for attackers seeking to exploit vulnerabilities and steal funds. The Ethereum community has developed a rich set of tools to detect vulnerabilities in SCs, including reentrancy (RE) and unhandled exceptions (UX). A dataset of SCs labelled with vulnerabilities is needed to evaluate the tools' efficacy. Existing SC datasets with labelled vulnerabilities have limitations, such as covering only a limited range of vulnerability scenarios and containing incorrect labels. As a result, there is a lack of a standardized dataset to compare the performances of these tools. SCRUBD aims to fill this gap. We present a dataset of real-world SCs and synthesized SCs labelled with RE and UX. The real-world SC dataset is labelled through crowdsourcing, followed by manual inspection by an expert, and covers both RE and UX vulnerabilities. On the other hand, the synthesized dataset is carefully crafted to cover various RE scenarios only. Using SCRUBD we compared the performance of six popular vulnerability detection tools. Based on our study, we found that Slither outperforms other tools on a crowdsourced dataset in detecting RE vulnerabilities, while Sailfish outperforms other tools on a manually synthesized dataset for detecting RE. For UX vulnerabilities, Slither outperforms all other tools.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cooperative Target Defense under Communication and Sensing Constraints</title>
<link>https://arxiv.org/abs/2412.09939</link>
<guid>https://arxiv.org/abs/2412.09939</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、入侵者、目标防御、分布式反馈策略、非线性共识问题

总结:
该文研究了一种目标防御问题的变体，其中一组守卫需要同时捕获一个入侵者。入侵者的任务是在不被守卫团队同时捕捉的情况下到达目标位置。部分守卫存在感知限制，无法在任何时候得知入侵者的位置或速度信息。守卫们可以通过连接的通信图进行相互交流。文章提出了一种分布式反馈策略，将同时捕捉问题转化为一个独特的非线性共识问题，并推导出了关于代理人速度、感知和通信能力的同时捕捉充分条件。通过大量的数值模拟对提出的分布式控制器进行了评估。<br /><br /> <div>
arXiv:2412.09939v1 Announce Type: new 
Abstract: We consider a variant of the target defense problems where a group of defenders are tasked to simultaneously capture an intruder. The intruder's objective is to reach a target without being simultaneously captured by the defender team. Some of the defenders are sensing-limited and do not have any information regarding the intruder's position or velocity at any time. The defenders may communicate with each other using a connected communication graph. We propose a decentralized feedback strategy for the defenders, which transforms the simultaneous capture problem into a unique nonlinear consensus problem. We derive a sufficient condition for simultaneous capture in terms of the agents' speeds, sensing, and communication capabilities. The proposed decentralized controller is evaluated through extensive numerical simulations.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI and the Future of Digital Public Squares</title>
<link>https://arxiv.org/abs/2412.09988</link>
<guid>https://arxiv.org/abs/2412.09988</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、互联网、公共空间、对话系统、风险

<br /><br />总结:

近年来，大型语言模型（LLMs）和互联网两大技术进步重塑了公共空间。本文探讨了LLMs在提升数字公共广场的四个应用场景：集体对话系统、桥梁系统、社区管理及证明人性系统。通过收集70多位公民社会专家和技术人员的见解，文章指出LLMs为大规模对话提供了开创性机遇，但同时也带来了加剧社会分歧的风险。因此，文章提出了未来AI研究与投资的议程，旨在强化数字公共广场并防范人工智能可能的误用。 <div>
arXiv:2412.09988v1 Announce Type: new 
Abstract: Two substantial technological advances have reshaped the public square in recent decades: first with the advent of the internet and second with the recent introduction of large language models (LLMs). LLMs offer opportunities for a paradigm shift towards more decentralized, participatory online spaces that can be used to facilitate deliberative dialogues at scale, but also create risks of exacerbating societal schisms. Here, we explore four applications of LLMs to improve digital public squares: collective dialogue systems, bridging systems, community moderation, and proof-of-humanity systems. Building on the input from over 70 civil society experts and technologists, we argue that LLMs both afford promising opportunities to shift the paradigm for conversations at scale and pose distinct risks for digital public squares. We lay out an agenda for future research and investments in AI that will strengthen digital public squares and safeguard against potential misuses of AI.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Decentralized Optimization with Relay Communication</title>
<link>https://arxiv.org/abs/2212.10859</link>
<guid>https://arxiv.org/abs/2212.10859</guid>
<content:encoded><![CDATA[
<div> 关键词：Privacy Leakage Frequency (PLF)，DP-RECAL，分布式优化算法，隐私性能，通信复杂度

总结:
<br />
针对大规模网络环境中的安全问题，该文引入了新的衡量指标“隐私泄漏频率(PLF)”，揭示了算法通信与隐私泄露之间的关系。基于此，文章提出了一种名为DP-RECAL的新颖差分隐私分布式 primal-dual 算法，利用操作器分裂方法和中继通信机制来降低PLF，从而减少整体隐私预算。相较于现有差分隐私算法，DP-RECAL展现了更优的隐私性能和通信复杂度。此外，在无协调的网络独立步长条件下，论文证明了DP-RECAL对于一般凸问题的收敛性，并在满足测地亚正规性的条件下建立了线性收敛率。实证分析和基于真实世界数据集的数值实验验证了理论结果，并表明DP-RECAL能够抵御一些经典的梯度泄露攻击。 <div>
arXiv:2212.10859v2 Announce Type: replace-cross 
Abstract: Security concerns in large-scale networked environments are becoming increasingly critical. To further improve the algorithm security from the design perspective of decentralized optimization algorithms, we introduce a new measure: Privacy Leakage Frequency (PLF), which reveals the relationship between communication and privacy leakage of algorithms, showing that lower PLF corresponds to lower privacy budgets. Based on such assertion, a novel differentially private decentralized primal--dual algorithm named DP-RECAL is proposed to take advantage of operator splitting method and relay communication mechanism to experience less PLF so as to reduce the overall privacy budget. To the best of our knowledge, compared with existing differentially private algorithms, DP-RECAL presents superior privacy performance and communication complexity. In addition, with uncoordinated network-independent stepsizes, we prove the convergence of DP-RECAL for general convex problems and establish a linear convergence rate under the metric subregularity. Evaluation analysis on least squares problem and numerical experiments on real-world datasets verify our theoretical results and demonstrate that DP-RECAL can defend some classical gradient leakage attacks.
]]></content:encoded>
<pubDate>Mon, 16 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reward-based Blockchain Infrastructure for 3D IC Supply Chain Provenance</title>
<link>https://arxiv.org/abs/2412.08777</link>
<guid>https://arxiv.org/abs/2412.08777</guid>
<content:encoded><![CDATA[
<div> 关键词：异构集成、2.5D/3D芯片、区块链技术、供应链信任、分布式信任

<br /><br />总结:
随着半导体行业向异构集成的转变，2.5D/3D芯片因其高性能和能效受到广泛关注。然而，复杂的供应链带来了芯片安全性挑战，特别是在不信任地区生产的芯片可能引入恶意电路。为解决这一问题，本文提出了一种创新方法，利用区块链技术确保集成电路及芯片let在供应链中的可追溯性。针对全球分散且可能处于不同区块链联盟的制造商，文章提出了双层结构的信任建立方案：底层采用基于区块链的IC供应链原产地框架，允许不同联盟运行的区块链实例间进行交易，实现每个IC完整来源有向无环图（DAG）的追踪；上层则实施跨链声誉机制，对实体赋予声誉评分并特别关注高风险的跨信任区域交易。这一方法增强了区块链数据的可信度，有效降低了多联盟使用带来的潜在风险，为日益发展的异构集成中2.5D/3D IC安全提供了坚实基础。 <div>
arXiv:2412.08777v1 Announce Type: new 
Abstract: In response to the growing demand for enhanced performance and power efficiency, the semiconductor industry has witnessed a paradigm shift toward heterogeneous integration, giving rise to 2.5D/3D chips. These chips incorporate diverse chiplets, manufactured globally and integrated into a single chip. Securing these complex 2.5D/3D integrated circuits (ICs) presents a formidable challenge due to inherent trust issues within the semiconductor supply chain. Chiplets produced in untrusted locations may be susceptible to tampering, introducing malicious circuits that could compromise sensitive information. This paper introduces an innovative approach that leverages blockchain technology to establish traceability for ICs and chiplets throughout the supply chain. Given that chiplet manufacturers are dispersed globally and may operate within different blockchain consortiums, ensuring the integrity of data within each blockchain ledger becomes imperative. To address this, we propose a novel dual-layer approach for establishing distributed trust across diverse blockchain ledgers. The lower layer comprises of a blockchain-based framework for IC supply chain provenance that enables transactions between blockchain instances run by different consortiums, making it possible to trace the complete provenance DAG of each IC. The upper layer implements a multi-chain reputation scheme that assigns reputation scores to entities while specifically accounting for high-risk transactions that cross blockchain trust zones. This approach enhances the credibility of the blockchain data, mitigating potential risks associated with the use of multiple consortiums and ensuring a robust foundation for securing 2.5D/3D ICs in the evolving landscape of heterogeneous integration.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BA-ORABE: Blockchain-Based Auditable Registered Attribute-Based Encryption With Reliable Outsourced Decryption</title>
<link>https://arxiv.org/abs/2412.08957</link>
<guid>https://arxiv.org/abs/2412.08957</guid>
<content:encoded><![CDATA[
<div> 关键词：Attribute-based encryption (ABE), registered ABE, key curator, decryption cloud service (DCS), blockchain

总结:<br />
本文提出了首个基于区块链的完全可审计注册属性基加密方案BA-ORABE。该方案实现了无需可信中心的注册属性基加密，并通过可验证标签机制确保了密文转换的可验证性以及诚实解密云服务的豁免性，后者利用零知识欺诈证明在乐观假设下得到保障。此外，BA-ORABE系统还具备公平性和去中心化的外包特性，从而保护各方利益，并通过区块链技术实现透明、全程可审计的注册与外包流程。文章对方案进行了正式的安全分析，并在以太坊上实施和评估，证明了其可行性和效率。 <div>
arXiv:2412.08957v1 Announce Type: new 
Abstract: Attribute-based encryption (ABE) is a generalization of public-key encryption that enables fine-grained access control in cloud services. Recently, Hohenberger et al. (Eurocrypt 2023) introduced the notion of registered ABE, which is an ABE scheme without a trusted central authority. Instead, users generate their own public/secret keys and then register their keys and attributes with a key curator. The key curator is a transparent and untrusted entity and its behavior needs to be audited for malicious registration. In addition, pairing-based registered ABE still suffers the heavy decryption overhead like ABE. A general approach to address this issue is to outsource decryption to a decryption cloud service (DCS). In this work, we propose BA-ORABE, the first fully auditable registered ABE with reliable outsource decryption scheme based on blockchain. First, we utilize a verifiable tag mechanism to achieve verifiability of ciphertext transformation, and the exemptibility which enables the honest DCS to escape from wrong claims is guaranteed by zero knowledge fraud proof under optimistic assumption. Additionally, our system achieves fairness and decentralized outsourcing to protect the interests of all parties and the registration and outsourcing process are transparent and fully auditable through blockchain. Finally, we give formal security analysis and implement and evaluate our scheme on Ethereum to demonstrate its feasibility and efficiency.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Building a Mastodon Compatible Java Server for ActivityPub</title>
<link>https://arxiv.org/abs/2412.09011</link>
<guid>https://arxiv.org/abs/2412.09011</guid>
<content:encoded><![CDATA[
<div> 关键词: ActivityPub、Fediverse、Mastodon、Java Spring Boot、分布式服务器

总结:
本文分析了ActivityPub这一去中心化社交网络协议，并指出了其在Fediverse中的广泛应用。文章深入探讨了Mastodon服务器对ActivityPub协议的具体实现，并介绍了一种使用Java Spring Boot和ActivityPub构建能与Mastodon服务器相互通信的自定义实例的方法。 <div>
arXiv:2412.09011v1 Announce Type: new 
Abstract: ActivityPub is a decentralized social networking protocol that has gained significant attention from the media for its ability to communicate through the Fediverse, short for the federated web. Servers such as Mastodon implement the ActivityPub protocol to communicate over the Fediverse. In this paper, we deconstruct the core protocols used to build the distributed servers of the Fediverse. We explore Mastodon's complex implementation of ActivityPub and created our own Mastodon instance using Java Spring Boot and ActivityPub to interoperate with Mastodon servers.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Convergence of Decentralized Gradient Tracking under the KL Property</title>
<link>https://arxiv.org/abs/2412.09556</link>
<guid>https://arxiv.org/abs/2412.09556</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体优化、去中心化、无向图、Kurdyka-{\L}ojasiewicz (KL)性质、SONATA算法

总结:<br />
本文研究了在由无向图建模的网络环境中的分布式多智能体非凸光滑函数优化问题，该问题包含了满足约束或解决方案额外结构（如稀疏性、低秩）的凸扩展值函数。文章假设目标函数满足具有给定指数$\theta\in[0,1)$的KL性质，这个性质在许多实际应用中的非凸函数中得到满足，并在集中式设置下可以实现强大的收敛性保证。文章证明了著名的分布式梯度跟踪算法SONATA对此类问题也能够达到类似的收敛行为：<br />
1) 当$\theta\in(0,1/2]$时，SONATA生成的序列以R-线性速率收敛到问题的一个驻点解；<br />
2) 当$\theta\in(1/2,1)$时，证明了亚线性收敛率；<br />
3) 当$\theta=0$时，迭代过程将在有限步数内收敛或以R-线性速率收敛。这与集中式proximal梯度算法的收敛行为相匹配，除了当$\theta=0$的情况。数值实验验证了理论发现。 <div>
arXiv:2412.09556v1 Announce Type: cross 
Abstract: We study decentralized multiagent optimization over networks, modeled as undirected graphs. The optimization problem consists of minimizing a nonconvex smooth function plus a convex extended-value function, which enforces constraints or extra structure on the solution (e.g., sparsity, low-rank). We further assume that the objective function satisfies the Kurdyka-{\L}ojasiewicz (KL) property, with given exponent $\theta\in [0,1)$. The KL property is satisfied by several (nonconvex) functions of practical interest, e.g., arising from machine learning applications; in the centralized setting, it permits to achieve strong convergence guarantees. Here we establish convergence of the same type for the notorious decentralized gradient-tracking-based algorithm SONATA. Specifically, $\textbf{(i)}$ when $\theta\in (0,1/2]$, the sequence generated by SONATA converges to a stationary solution of the problem at R-linear rate;$ \textbf{(ii)} $when $\theta\in (1/2,1)$, sublinear rate is certified; and finally $\textbf{(iii)}$ when $\theta=0$, the iterates will either converge in a finite number of steps or converges at R-linear rate. This matches the convergence behavior of centralized proximal-gradient algorithms except when $\theta=0$. Numerical results validate our theoretical findings.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedAA: A Reinforcement Learning Perspective on Adaptive Aggregation for Fair and Robust Federated Learning</title>
<link>https://arxiv.org/abs/2402.05541</link>
<guid>https://arxiv.org/abs/2402.05541</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, 个性化FL, 自适应聚合, 模型稳健性, 公平性

<br /><br />总结:

本文提出了一种名为FedAA的新颖方法，用于解决联邦学习中的统计异质性和对抗攻击问题，以提升模型稳健性和保证参与者之间的公平性。FedAA通过适应性聚合优化客户端贡献，特别采用基于深度确定性策略梯度算法的连续控制聚合权重方案，创新地利用模型参数距离进行客户端选择，并结合验证集性能的奖励机制。实验表明，就鲁棒性而言，FedAA优于现有最先进的方法，同时保持了相当的公平性，为构建抗御性强、公平的分布式联邦系统提供了一个有前景的解决方案。项目代码已发布于https://github.com/Gp1g/FedAA。 <div>
arXiv:2402.05541v2 Announce Type: replace 
Abstract: Federated Learning (FL) has emerged as a promising approach for privacy-preserving model training across decentralized devices. However, it faces challenges such as statistical heterogeneity and susceptibility to adversarial attacks, which can impact model robustness and fairness. Personalized FL attempts to provide some relief by customizing models for individual clients. However, it falls short in addressing server-side aggregation vulnerabilities. We introduce a novel method called \textbf{FedAA}, which optimizes client contributions via \textbf{A}daptive \textbf{A}ggregation to enhance model robustness against malicious clients and ensure fairness across participants in non-identically distributed settings. To achieve this goal, we propose an approach involving a Deep Deterministic Policy Gradient-based algorithm for continuous control of aggregation weights, an innovative client selection method based on model parameter distances, and a reward mechanism guided by validation set performance. Empirically, extensive experiments demonstrate that, in terms of robustness, \textbf{FedAA} outperforms the state-of-the-art methods, while maintaining comparable levels of fairness, offering a promising solution to build resilient and fair federated systems. Our code is available at https://github.com/Gp1g/FedAA.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Protocol Learning, Decentralized Frontier Risk and the No-Off Problem</title>
<link>https://arxiv.org/abs/2412.07890</link>
<guid>https://arxiv.org/abs/2412.07890</guid>
<content:encoded><![CDATA[
<div> 关键词: Protocol Learning、前沿模型、去中心化训练、风险分析、通信效率

总结:<br />
本文提出了第三种开发和分布前沿模型的方法——协议学习，它通过激励参与者的分布式网络进行训练，有望聚合比任何单一中央实体高出几个数量级的计算资源。然而，这也带来了新的挑战，如异构、不可靠的节点、恶意参与者以及需要保护激励机制的不可提取模型等问题，特别是“无关闭问题”，即无法单方面停止集体训练的模型。文章回顾了近期的技术进展，表明去中心化训练可能是可行的，涉及新兴的通信效率策略和容错方法，同时指出了仍存在的关键开放问题。与认为去中心化会放大前沿风险的观点相反，文章认为协议学习的透明性、分布式治理和民主化的访问权限实际上可以降低这些风险，相比当前集中式体制更具优势。 <div>
arXiv:2412.07890v1 Announce Type: new 
Abstract: Frontier models are currently developed and distributed primarily through two channels: centralized proprietary APIs or open-sourcing of pre-trained weights. We identify a third paradigm - Protocol Learning - where models are trained across decentralized networks of incentivized participants. This approach has the potential to aggregate orders of magnitude more computational resources than any single centralized entity, enabling unprecedented model scales and capabilities. However, it also introduces novel challenges: heterogeneous and unreliable nodes, malicious participants, the need for unextractable models to preserve incentives, and complex governance dynamics. To date, no systematic analysis has been conducted to assess the feasibility of Protocol Learning or the associated risks, particularly the 'No-Off Problem' arising from the inability to unilaterally halt a collectively trained model. We survey recent technical advances that suggest decentralized training may be feasible - covering emerging communication-efficient strategies and fault-tolerant methods - while highlighting critical open problems that remain. Contrary to the notion that decentralization inherently amplifies frontier risks, we argue that Protocol Learning's transparency, distributed governance, and democratized access ultimately reduce these risks compared to today's centralized regimes.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learn How to Query from Unlabeled Data Streams in Federated Learning</title>
<link>https://arxiv.org/abs/2412.08138</link>
<guid>https://arxiv.org/abs/2412.08138</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习(Federated Learning)，无标签数据，样本选择，强化学习(Reinforcement Learning)，LeaDQ

总结:
本文探讨了联邦学习中面对无标签数据流时如何有效地选取有信息量的样本进行标注的问题。针对这一挑战，文章提出了名为LeaDQ的新方法，它将数据查询过程视为一个协作分散型决策问题，并利用多智能体强化学习算法来解决。LeaDQ能够在全局信息的隐性指导下，让各个客户端学习有效的局部策略，引导它们选择能提升全局模型准确性的样本。实验结果表明，LeaDQ在图像和文本任务等不同联邦学习场景下均表现出优越性能，优于基准算法。 <div>
arXiv:2412.08138v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative learning among decentralized clients while safeguarding the privacy of their local data. Existing studies on FL typically assume offline labeled data available at each client when the training starts. Nevertheless, the training data in practice often arrive at clients in a streaming fashion without ground-truth labels. Given the expensive annotation cost, it is critical to identify a subset of informative samples for labeling on clients. However, selecting samples locally while accommodating the global training objective presents a challenge unique to FL. In this work, we tackle this conundrum by framing the data querying process in FL as a collaborative decentralized decision-making problem and proposing an effective solution named LeaDQ, which leverages multi-agent reinforcement learning algorithms. In particular, under the implicit guidance from global information, LeaDQ effectively learns the local policies for distributed clients and steers them towards selecting samples that can enhance the global model's accuracy. Extensive simulations on image and text tasks show that LeaDQ advances the model performance in various FL scenarios, outperforming the benchmarking algorithms.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Overview of the Decentralized Reconfiguration Language Concerto-D through its Maude Formalization</title>
<link>https://arxiv.org/abs/2412.08233</link>
<guid>https://arxiv.org/abs/2412.08233</guid>
<content:encoded><![CDATA[
<div> 关键词：Concerto-D、分布式重配置语言、Maude、正式语义、边缘计算、Cyber-Physical Systems (CPS)

<br /><br />总结:

本文提出了一个基于Maude形式化方法的分布式重配置语言Concerto-D的概述。相较于相关工作，Concerto-D在两个方面有所改进：一是通过实现大量局部重配置计划的去中心化协调，避免了在网络不稳定（如边缘计算或Cyber-Physical Systems (CPS)）环境中出现单点故障的问题；二是使用Maude为该语言提供了机械化的形式语义，从而保证了其执行的正确性。文章中，通过一个来源于实际CPS案例研究的重配置示例来说明Concerto-D语言及其语义。由于Maude是一种基于重写逻辑的正式规范语言，因此非常适合描述并发模型。 <div>
arXiv:2412.08233v1 Announce Type: new 
Abstract: We propose an overview of the decentralized reconfiguration language Concerto-D through its Maude formalization. Concerto-D extends the already published Concerto language. Concerto-D improves on two different parameters compared with related work: the decentralized coordination of numerous local reconfiguration plans which avoid a single point of failure when considering unstable networks such as edge computing, or cyber-physical systems (CPS) for instance; and a mechanized formal semantics of the language with Maude which offers guarantees on the executability of the semantics. Throughout the paper, the Concerto-D language and its semantics are exemplified with a reconfiguration extracted from a real case study on a CPS. We rely on the Maude formal specification language, which is based on rewriting logic, and consequently perfectly suited for describing a concurrent model.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pioplat: A Scalable, Low-Cost Framework for Latency Reduction in Ethereum Blockchain</title>
<link>https://arxiv.org/abs/2412.08367</link>
<guid>https://arxiv.org/abs/2412.08367</guid>
<content:encoded><![CDATA[
<div> 关键词：Pioplat、延迟减少、区块链、分布式应用程序、低 latency 通信协议

<br /><br />总结:
本文介绍了Pioplat，一个针对许可式区块链上日益增多的对延迟敏感的应用场景设计的可行、可定制、低成本的延迟降低框架。Pioplat包括位于不同大陆的多个中继节点以及至少一个配备特殊工具的全节点变体。其节点选择策略与低延迟通信协议相结合，提供了有效减少延迟的弹性方法。文章通过在五大洲运行的实验证明了Pioplat的可行性，并显示Pioplat能够显著降低接收区块/交易和发送交易的延迟，从而满足大多数延迟敏感使用场景的需求。此外，为了促进进一步的研究和使人们能够在更多区块链系统上应用该框架，文章提供了Pioplat的完整实现。 <div>
arXiv:2412.08367v1 Announce Type: new 
Abstract: As decentralized applications on permissionless blockchains are prevalent, more and more latency-sensitive usage scenarios emerged, where the lower the latency of sending and receiving messages, the better the chance of earning revenue. To reduce latency, we present Pioplat, a feasible, customizable, and low-cost latency reduction framework consisting of multiple relay nodes on different continents and at least one instrumented variant of a full node. The node selection strategy of Pioplat and the low-latency communication protocol offer an elastic way to reduce latency effectively. We demonstrate Pioplat's feasibility with an implementation running on five continents and show that Pioplat can significantly reduce the latency of receiving blocks/transactions and sending transactions, thus fulfilling the requirements of most latency-sensitive use cases. Furthermore, we provide the complete implementation of Pioplat to promote further research and allow people to apply the framework to more blockchain systems.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grimm: A Plug-and-Play Perturbation Rectifier for Graph Neural Networks Defending against Poisoning Attacks</title>
<link>https://arxiv.org/abs/2412.08555</link>
<guid>https://arxiv.org/abs/2412.08555</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络, 边对抗攻击, 防御策略, 图代理网络, 分布式交互

总结:
本文针对图神经网络(GNNs)在全球优化端到端训练中易受边对抗攻击的问题，提出了一个新的防御模型——图代理网络(GAgN)。GAgN中的每个节点被视为具有1跳视图的代理，通过代理间的分布式交互，它们能够学习推断全局感知并执行包括节点嵌入、度数和邻居关系在内的任务，从而使节点具备过滤敌对边的能力并在执行分类任务时保持鲁棒性。此外，由于代理人具有有限视野，恶意消息无法在全球范围内传播，从而抵抗基于全局优化的次级攻击。理论证明单隐藏层多层感知机(MLPs)足以实现这些功能。实验结果显示，相比于现有最先进的防御方法，GAgN在被扰动的数据集上实现了最优的分类精度。 <div>
arXiv:2412.08555v1 Announce Type: new 
Abstract: End-to-end training with global optimization have popularized graph neural networks (GNNs) for node classification, yet inadvertently introduced vulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit the inherent opened interfaces of GNNs' input and output, perturbing critical edges and thus manipulating the classification results. Current defenses, due to their persistent utilization of global-optimization-based end-to-end training schemes, inherently encapsulate the vulnerabilities of GNNs. This is specifically evidenced in their inability to defend against targeted secondary attacks. In this paper, we propose the Graph Agent Network (GAgN) to address the aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent network in which each node is designed as an 1-hop-view agent. Through the decentralized interactions between agents, they can learn to infer global perceptions to perform tasks including inferring embeddings, degrees and neighbor relationships for given nodes. This empowers nodes to filtering adversarial edges while carrying out classification tasks. Furthermore, agents' limited view prevents malicious messages from propagating globally in GAgN, thereby resisting global-optimization-based secondary attacks. We prove that single-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient to achieve these functionalities. Experimental results show that GAgN effectively implements all its intended capabilities and, compared to state-of-the-art defenses, achieves optimal classification accuracy on the perturbed datasets.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comparative Evaluation of Automated Analysis Tools for Solidity Smart Contracts</title>
<link>https://arxiv.org/abs/2310.20212</link>
<guid>https://arxiv.org/abs/2310.20212</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链智能合约、安全性、评估工具、ISO/IEC 25010标准、基准测试

总结:
本文关注区块链智能合约的安全性问题，着重探讨了十款自动化的以太坊固态智能合约漏洞检测工具。文章提出了一种基于ISO/IEC 25010标准的新颖评价准则来评估这些工具的效果。为了辅助工具评测，作者构建了一个包括389份已标注智能合约和源自现实世界的20,000个独特案例的基准测试集。通过对所选工具进行比较分析，揭示了它们的优势与不足，指出了需要进一步改进的方向。该研究旨在为开发者和研究人员选择及使用智能合约分析工具提供指导，并促进提高智能合约的安全性和可靠性。 <div>
arXiv:2310.20212v4 Announce Type: replace 
Abstract: Blockchain smart contracts have emerged as a transformative force in the digital realm, spawning a diverse range of compelling applications. Since solidity smart contracts across various domains manage trillions of dollars in virtual coins, they become a prime target for attacks. One of the primary challenges is keeping abreast of the latest techniques and tools for developing secure smart contracts and examining those already deployed. In this paper, we seek to address these challenges from four aspects: (1) We begin by examining ten automatic tools, specifically focusing on their methodologies and their ability to identify vulnerabilities in solidity smart contracts. (2) We propose a novel criterion for evaluating these tools, based on the ISO/IEC 25010 standard. (3) To facilitate the evaluation of the selected tools, we construct a benchmark that encompasses two distinct datasets: a collection of 389 labelled smart contracts and a scaled set of 20,000 unique cases from real-world contracts. (4) We provide a comparison of the selected tools, offering insights into their strengths and weaknesses and highlighting areas where further improvements are needed. Through this evaluation, we hope to provide developers and researchers with valuable guidance on selecting and using smart contract analysis tools and contribute to the ongoing efforts to improve the security and reliability of smart contracts.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentMixer: Multi-Agent Correlated Policy Factorization</title>
<link>https://arxiv.org/abs/2401.08728</link>
<guid>https://arxiv.org/abs/2401.08728</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、集中式训练分布式执行、协调、AgentMixer、个体全局一致性

总结:
本文针对多智能体强化学习中的集中式训练分布式执行方法，提出了一种策略修改方案——AgentMixer。该方案旨在解决独立决策可能导致的协作性不足问题，允许智能体非线性地结合局部可观测策略形成联合完全可观测策略，从而促进协作。为确保在联合训练中心化和去中心化策略时的模式一致性，文章引入了“个体全局一致性”原则，并证明AgentMixer能够收敛到$\epsilon$-近似的关联平衡。实验结果显示，在Multi-Agent MuJoCo、SMAC-v2、矩阵游戏以及捕食者-猎物等基准测试中，AgentMixer的表现优于或与当前最先进的方法相当。<br /><br /> <div>
arXiv:2401.08728v2 Announce Type: replace 
Abstract: In multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) methods typically assume that agents make decisions based on their local observations independently, which may not lead to a correlated joint policy with coordination. Coordination can be explicitly encouraged during training and individual policies can be trained to imitate the correlated joint policy. However, this may lead to an \textit{asymmetric learning failure} due to the observation mismatch between the joint and individual policies. Inspired by the concept of correlated equilibrium, we introduce a \textit{strategy modification} called AgentMixer that allows agents to correlate their policies. AgentMixer combines individual partially observable policies into a joint fully observable policy non-linearly. To enable decentralized execution, we introduce \textit{Individual-Global-Consistency} to guarantee mode consistency during joint training of the centralized and decentralized policies and prove that AgentMixer converges to an $\epsilon$-approximate Correlated Equilibrium. In the Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks, AgentMixer outperforms or matches state-of-the-art methods.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal and Efficient Algorithms for Decentralized Online Convex Optimization</title>
<link>https://arxiv.org/abs/2402.09173</link>
<guid>https://arxiv.org/abs/2402.09173</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized online convex optimization (D-OCO)，regret bounds，convex函数，strongly convex函数，communication matrix

总结:

本文研究了分布式在线凸优化(D-OCO)问题，其中一组本地学习者仅使用局部计算和通信来最小化全局损失函数序列。先前的研究为凸函数和强凸函数分别建立了$O(n^{5/4}\rho^{-1/2}\sqrt{T})$和${O}(n^{3/2}\rho^{-1}\log T)$的遗憾界限。然而这些界限与已知的下界存在较大差距。为此，本文提出了一种新的D-OCO算法，将凸函数和强凸函数的遗憾界限降低到$\tilde{O}(n\rho^{-1/4}\sqrt{T})$和$\tilde{O}(n\rho^{-1/2}\log T)$。主要技术在于设计一种在线加速的 gossip 策略，实现更快的局部学习者间的平均共识。此外，通过充分利用特定网络拓扑结构的谱性质，进一步增强下界至$\Omega(n\rho^{-1/4}\sqrt{T})$和$\Omega(n\rho^{-1/2}\log T)$。这些结果表明新算法对于凸函数和强凸函数而言，在$T$、$n$和$\rho$上的遗憾性能近乎最优。最后，针对具有复杂约束的实际应用，文章还提出了一种无需投影操作的算法变体。分析表明该变体可以分别达到${O}(nT^{3/4})$和${O}(nT^{2/3}(\log T)^{1/3})$的遗憾界限，以及几乎最优的$\tilde{O}(\rho^{-1/2}\sqrt{T})$和$\tilde{O}(\rho^{-1/2}T^{1/3}(\log T)^{2/3})$通信轮数。 <div>
arXiv:2402.09173v3 Announce Type: replace 
Abstract: We investigate decentralized online convex optimization (D-OCO), in which a set of local learners are required to minimize a sequence of global loss functions using only local computations and communications. Previous studies have established $O(n^{5/4}\rho^{-1/2}\sqrt{T})$ and ${O}(n^{3/2}\rho^{-1}\log T)$ regret bounds for convex and strongly convex functions respectively, where $n$ is the number of local learners, $\rho<1$ is the spectral gap of the communication matrix, and $T$ is the time horizon. However, there exist large gaps from the existing lower bounds, i.e., $\Omega(n\sqrt{T})$ for convex functions and $\Omega(n)$ for strongly convex functions. To fill these gaps, in this paper, we first develop a novel D-OCO algorithm that can respectively reduce the regret bounds for convex and strongly convex functions to $\tilde{O}(n\rho^{-1/4}\sqrt{T})$ and $\tilde{O}(n\rho^{-1/2}\log T)$. The primary technique is to design an online accelerated gossip strategy that enjoys a faster average consensus among local learners. Furthermore, by carefully exploiting spectral properties of a specific network topology, we enhance the lower bounds for convex and strongly convex functions to $\Omega(n\rho^{-1/4}\sqrt{T})$ and $\Omega(n\rho^{-1/2}\log T)$, respectively. These results suggest that the regret of our algorithm is nearly optimal in terms of $T$, $n$, and $\rho$ for both convex and strongly convex functions. Finally, we propose a projection-free variant of our algorithm to efficiently handle practical applications with complex constraints. Our analysis reveals that the projection-free variant can achieve ${O}(nT^{3/4})$ and ${O}(nT^{2/3}(\log T)^{1/3})$ regret bounds for convex and strongly convex functions with nearly optimal $\tilde{O}(\rho^{-1/2}\sqrt{T})$ and $\tilde{O}(\rho^{-1/2}T^{1/3}(\log T)^{2/3})$ communication rounds, respectively.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Block-Term Tensor Regression for decentralised data analysis in healthcare</title>
<link>https://arxiv.org/abs/2412.06815</link>
<guid>https://arxiv.org/abs/2412.06815</guid>
<content:encoded><![CDATA[
<div> 关键词: Block-Term Tensor Regression (BTTR), Federated Block-Term Tensor Regression (FBTTR), federated learning, data privacy, healthcare

总结:
本文介绍了Federated Block-Term Tensor Regression (FBTTR)，这是一种针对Block-Term Tensor Regression (BTTR)的扩展，旨在解决在联邦学习场景中的数据隐私问题和促进跨机构协作。FBTTR能够在保护数据隐私的同时进行分布式数据分析，适合应用于医疗保健和神经科学等领域。文章通过两个案例研究验证了FBTTR的性能：一是利用BCI Competition IV数据集进行手指运动解码任务，结果显示FBTTR相对于集中式的BTTR在解码准确性上有优势，特别是在预测拇指运动方面。二是将FBTTR应用到预测心脏病的真实临床数据中，其表现优于标准的联邦学习方法以及集中式BTTR模型，在Fed-Heart-Disease数据集上获得了更高的AUC-ROC和准确率。 <div>
arXiv:2412.06815v1 Announce Type: new 
Abstract: Block-Term Tensor Regression (BTTR) has proven to be a powerful tool for modeling complex, high-dimensional data by leveraging multilinear relationships, making it particularly well-suited for applications in healthcare and neuroscience. However, traditional implementations of BTTR rely on centralized datasets, which pose significant privacy risks and hinder collaboration across institutions. To address these challenges, we introduce Federated Block-Term Tensor Regression (FBTTR), an extension of BTTR designed for federated learning scenarios. FBTTR enables decentralized data analysis, allowing institutions to collaboratively build predictive models while preserving data privacy and complying with regulations.
  FBTTR represents a major step forward in applying tensor regression to federated learning environments. Its performance is evaluated in two case studies: finger movement decoding from Electrocorticography (ECoG) signals and heart disease prediction. In the first case study, using the BCI Competition IV dataset, FBTTR outperforms non-multilinear models, demonstrating superior accuracy in decoding finger movements. For the dataset, for subject 3, the thumb obtained a performance of 0.76 $\pm$ .05 compared to 0.71 $\pm$ 0.05 for centralised BTTR. In the second case study, FBTTR is applied to predict heart disease using real-world clinical datasets, outperforming both standard federated learning approaches and centralized BTTR models. In the Fed-Heart-Disease Dataset, an AUC-ROC was obtained of 0.872 $\pm$ 0.02 and an accuracy of 0.772 $\pm$ 0.02 compared to 0.812 $\pm$ 0.003 and 0.753 $\pm$ 0.007 for the centralized model.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution</title>
<link>https://arxiv.org/abs/2412.06855</link>
<guid>https://arxiv.org/abs/2412.06855</guid>
<content:encoded><![CDATA[
<div> 关键词：合作、进化博弈论、人工智能、Web3、激励共生模型

总结:
本文探讨了合作在人类生存和进步中的重要性以及进化博弈论在此方面的作用。随着人工智能在人类系统中变得愈发关键，合作动态产生了前所未有的意义。文章提出利用基于透明度、问责制和信任的去中心化框架——Web3，来促进人与AI之间的合作，通过构建双向激励和相互适应的“激励共生模型”，实现双方目标的一致性。这种激励共生模型被视为一种以Web3原则为灵感的现代道德框架，利用区块链技术定义并执行针对人类和AI代理的规则、激励与后果。通过将这些原则融入到人机交互的架构中，Web3生态系统可以催化出有利于协作创新的环境。文章进一步阐述了激励共生模型在去中心化金融、治理和文化适应等多个领域的变革应用，展示了如何使人与AI共同进化，迈向共享且可持续的发展轨迹。

<br /><br /> <div>
arXiv:2412.06855v1 Announce Type: new 
Abstract: Cooperation is vital to our survival and progress. Evolutionary game theory offers a lens to understand the structures and incentives that enable cooperation to be a successful strategy. As artificial intelligence agents become integral to human systems, the dynamics of cooperation take on unprecedented significance. Decentralized frameworks like Web3, grounded in transparency, accountability, and trust, offer a foundation for fostering cooperation by establishing enforceable rules and incentives for humans and AI agents. Guided by our Incentivized Symbiosis model, a paradigm aligning human and AI agent goals through bidirectional incentives and mutual adaptation, we investigate mechanisms for embedding cooperation into human-agent coevolution. We conceptualize Incentivized Symbiosis as part of a contemporary moral framework inspired by Web3 principles, encoded in blockchain technology to define and enforce rules, incentives, and consequences for both humans and AI agents. By integrating these principles into the very architecture of human-agent interactions, Web3 ecosystems catalyze an environment ripe for collaborative innovation. Our study traverses several transformative applications of Incentivized Symbiosis, from decentralized finance to governance and cultural adaptation, illustrating how AI agents can coevolve with humans to forge a trajectory of shared, sustainable progress.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BrokerChain: A Blockchain Sharding Protocol by Exploiting Broker Accounts</title>
<link>https://arxiv.org/abs/2412.07202</link>
<guid>https://arxiv.org/abs/2412.07202</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链分片、Monoxide、热分片、跨分片交易、BrokerChain

总结:
本文关注了区块链分片技术中的热点分片问题和跨分片交易优化挑战。现有的如Monoxide等方案可能导致交易负载分布不均。为解决这一问题，文章提出了BrokerChain，这是一款针对账户状态分片的跨分片区块链协议。BrokerChain利用细粒度的状态分区和账户分割策略，并通过broker账户处理跨分片交易。文中对BrokerChain的安全性及相关属性进行了严格分析，并使用开源区块链分片原型BlockEmulator进行了一系列评估。结果显示，BrokerChain在交易吞吐量、交易确认延迟、交易池队列大小以及工作负载平衡等方面优于其他基线方案。 <div>
arXiv:2412.07202v1 Announce Type: new 
Abstract: State-of-the-art blockchain sharding solutions such as Monoxide, can cause severely imbalanced distribution of transaction (TX) workloads across all blockchain shards due to the deployment policy of their accounts. Imbalanced TX distributions then produce hot shards, in which the cross-shard TXs may experience an unlimited confirmation latency. Thus, how to address the hot-shard issue and how to reduce crossshard TXs become significant challenges of blockchain sharding. Through reviewing the related studies, we find that a crossshard TX protocol that can achieve workload balance among all shards and simultaneously reduce the quantity of crossshard TXs is still absent from the literature. To this end, we propose BrokerChain, which is a cross-shard blockchain protocol dedicated to account-based state sharding. Essentially, BrokerChain exploits fine-grained state partition and account segmentation. We also elaborate on how BrokerChain handles cross-shard TXs through broker accounts. The security issues and other properties of BrokerChain are analyzed rigorously. Finally, we conduct comprehensive evaluations using an opensource blockchain sharding prototype named BlockEmulator. The evaluation results show that BrokerChain outperforms other baselines in terms of transaction throughput, transaction confirmation latency, the queue size of the transaction pool, and workload balance.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Weighting Push-SUM for Decentralized Optimization with Statistical Diversity</title>
<link>https://arxiv.org/abs/2412.07252</link>
<guid>https://arxiv.org/abs/2412.07252</guid>
<content:encoded><![CDATA[
<div> 关键词：统计多样性、Push-SUM协议、分布式优化、Adaptive Weighting Push-SUM协议、Moreau权重方法

总结:
本文针对数据分布中的统计多样性对基于Push-SUM协议的分布式优化带来的负面影响进行了研究。文章提出了一个新的理论框架——Adaptive Weighting Push-SUM协议，该协议是Push-SUM协议的一个泛化形式，其中原始Push-SUM协议为其特例。理论上分析表明，新协议在充分通信条件下，其共识距离的上界可降低至$O(1/N)$，而Push-SUM协议则保持在$O(1)$。此外，将SGD和Momentum SGD应用于新协议，证明了这两个算法在处理统计多样性上的收敛速度为$O(N/T)$，优于Push-SUM协议的$O(Nd/T)$（其中$d$为训练模型的参数大小）。为了应对实际应用中新协议的统计多样性问题，文章还发展了一种源于莫雷au包络的Moreau权重方法，用于近似优化莫雷au包络的距离惩罚。实验验证了Adaptive Weighting Push-SUM协议在深度学习等实际场景下相比Push-SUM协议具有更高的效率。 <div>
arXiv:2412.07252v1 Announce Type: new 
Abstract: Statistical diversity is a property of data distribution and can hinder the optimization of a decentralized network. However, the theoretical limitations of the Push-SUM protocol reduce the performance in handling the statistical diversity of optimization algorithms based on it. In this paper, we theoretically and empirically mitigate the negative impact of statistical diversity on decentralized optimization using the Push-SUM protocol. Specifically, we propose the Adaptive Weighting Push-SUM protocol, a theoretical generalization of the original Push-SUM protocol where the latter is a special case of the former. Our theoretical analysis shows that, with sufficient communication, the upper bound on the consensus distance for the new protocol reduces to $O(1/N)$, whereas it remains at $O(1)$ for the Push-SUM protocol. We adopt SGD and Momentum SGD on the new protocol and prove that the convergence rate of these two algorithms to statistical diversity is $O(N/T)$ on the new protocol, while it is $O(Nd/T)$ on the Push-SUM protocol, where $d$ is the parameter size of the training model. To address statistical diversity in practical applications of the new protocol, we develop the Moreau weighting method for its generalized weight matrix definition. This method, derived from the Moreau envelope, is an approximate optimization of the distance penalty of the Moreau envelope. We verify that the Adaptive Weighting Push-SUM protocol is practically more efficient than the Push-SUM protocol via deep learning experiments.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tazza: Shuffling Neural Network Parameters for Secure and Private Federated Learning</title>
<link>https://arxiv.org/abs/2412.07454</link>
<guid>https://arxiv.org/abs/2412.07454</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、安全威胁、模型中毒、数据隐私、Tazza

总结:
本文介绍了一种新的联邦学习框架Tazza，该框架同时解决了数据隐私保护和抵御恶意客户端的模型中毒及梯度反转等安全威胁问题。Tazza通过利用神经网络的置换等变性和不变性，通过权重洗牌和模型洗牌验证来增强对多种攻击的鲁棒性，同时也确保了数据的机密性和模型的高准确性。在多个数据集和嵌入式平台上进行的综合评估显示，与现有方案相比，Tazza在提供强大防御能力的同时，计算效率提高了最多6.7倍，且未损害性能。<br /><br /> <div>
arXiv:2412.07454v1 Announce Type: new 
Abstract: Federated learning enables decentralized model training without sharing raw data, preserving data privacy. However, its vulnerability towards critical security threats, such as gradient inversion and model poisoning by malicious clients, remain unresolved. Existing solutions often address these issues separately, sacrificing either system robustness or model accuracy. This work introduces Tazza, a secure and efficient federated learning framework that simultaneously addresses both challenges. By leveraging the permutation equivariance and invariance properties of neural networks via weight shuffling and shuffled model validation, Tazza enhances resilience against diverse poisoning attacks, while ensuring data confidentiality and high model accuracy. Comprehensive evaluations on various datasets and embedded platforms show that Tazza achieves robust defense with up to 6.7x improved computational efficiency compared to alternative schemes, without compromising performance.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Scalable Multi-Layered Blockchain Architecture for Enhanced EHR Sharing and Drug Supply Chain Management</title>
<link>https://arxiv.org/abs/2402.17342</link>
<guid>https://arxiv.org/abs/2402.17342</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、电子健康记录、药物供应链管理、多层架构、性能优化

<br /><br />总结:
本文提出了一种基于区块链技术的、可扩展的多层架构，用于保障医疗领域电子健康记录的安全共享与药物供应链管理。该框架由五个独特层次构成，强化了系统在性能、安全和患者为中心的访问控制方面的表现。通过引入并行处理，系统显著提高了交易吞吐量并减少了网络流量。此外，该解决方案确保了数据完整性、隐私性和互操作性，使其能够与现有医疗系统兼容。实验结果运用Caliper基准进行验证，显示出了交易吞吐量的显著提升和通信开销的降低。同时，这一框架还为药物供应链提供了透明度和实时监控功能，为决策者提供了关键洞察信息。 <div>
arXiv:2402.17342v2 Announce Type: replace 
Abstract: In recent years, the healthcare sector's transition to digital platforms has intensified concerns over data security, privacy, and scalability. Blockchain technology offers a decentralized, secure, and immutable solution to these challenges. This paper presents a scalable, multi-layered blockchain architecture for secure Electronic Health Record (EHR) sharing and drug supply chain management. The proposed framework introduces five distinct layers that enhance system performance, security, and patient-centric access control. By implementing parallelism, the system significantly increases transaction throughput and reduces network traffic. Our solution ensures data integrity, privacy, and interoperability, making it compatible with existing healthcare systems. Experimental results, conducted using the Caliper benchmark, demonstrate notable improvements in transaction throughput and reduced communication overhead. Additionally, the framework provides transparency and real-time drug supply chain monitoring, empowering decision-makers with critical insights.
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative and parametric insurance on the Ethereum blockchain</title>
<link>https://arxiv.org/abs/2412.05321</link>
<guid>https://arxiv.org/abs/2412.05321</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、保险方案、参数化、协作、智能合约

总结:<br />
本文提出了一种结合了参数化和协作元素的基于区块链的保险方案。该方案中，一批投资者（称为盈余提供者）将在智能合约中锁定资金，使得区块链用户能够承保参数化的保险合同。当预定义条件满足时，这些合同将自动触发赔偿。协作体现在生成代币的过程，代币被分配给盈余提供者和投保人，代表其在盈余中的份额并赋予管理决策投票权。该智能合约使用以太坊区块链的高级编程语言Solidity开发，并部署在Sepolia测试网上，数据处理和分析则采用Python进行。此外，还提供了开源代码并指出了主要研究挑战，以便后续研究可以克服这一初步概念验证的局限性。 <div>
arXiv:2412.05321v1 Announce Type: new 
Abstract: This paper introduces a blockchain-based insurance scheme that integrates parametric and collaborative elements. A pool of investors, referred to as surplus providers, locks funds in a smart contract, enabling blockchain users to underwrite parametric insurance contracts. These contracts automatically trigger compensation when predefined conditions are met. The collaborative aspect is embodied in the generation of tokens, which are distributed to both surplus providers and policyholders. These tokens represent each participant's share of the surplus and grant voting rights for management decisions. The smart contract is developed in Solidity, a high-level programming language for the Ethereum blockchain, and deployed on the Sepolia testnet, with data processing and analysis conducted using Python. In addition, open-source code is provided and main research challenges are identified, so that further research can be carried out to overcome limitations of this first proof of concept.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EC-Chain: Cost-Effective Storage Solution for Permissionless Blockchains</title>
<link>https://arxiv.org/abs/2412.05502</link>
<guid>https://arxiv.org/abs/2412.05502</guid>
<content:encoded><![CDATA[
<div> 关键词：permissionless blockchains, EC-Chain, storage solution, erasure coding, dual-trie state management

总结:
<br />
本文提出了EC-Chain，一种针对无许可区块链的成本效益高的存储解决方案。EC-Chain通过批量编码和基于高度的编码优化了现有基于擦除编码的存储优化技术，从而减少了区块链数据中的交易记录（ledger data）的存储开销。同时，为改进状态数据（state data）的存储与检索效率，文章引入了一种易于实现的双哈希树（dual-trie）状态管理系统，该系统利用状态过期、挖掘和创建等流程实现了优化。为了确保无许可环境中的数据可用性，EC-Chain还设计了一种适应动态网络特性的维护方案。综上所述，EC-Chain为无许可区块链面临的存储挑战提供了一个有效的解决方案。实验证明，相比于原生以太坊Geth，EC-Chain可以实现超过90%的存储减少。 <div>
arXiv:2412.05502v1 Announce Type: new 
Abstract: Permissionless blockchains face considerable challenges due to increasing storage demands, driven by the proliferation of Decentralized Applications (DApps). This paper introduces EC-Chain, a cost-effective storage solution for permissionless blockchains. EC-Chain reduces storage overheads of ledger and state data, which comprise blockchain data. For ledger data, EC-Chain refines existing erasure coding-based storage optimization techniques by incorporating batch encoding and height-based encoding. We also introduce an easy-to-implement dual-trie state management system that enhances state storage and retrieval through state expiry, mining, and creation procedures. To ensure data availability in permissionless environments, EC-Chain introduces a network maintenance scheme tailored for dynamism. Collectively, these contributions allow EC-Chain to provide an effective solution to the storage challenges faced by permissionless blockchains. Our evaluation demonstrates that EC-Chain can achieve a storage reduction of over \(90\%\) compared to native Ethereum Geth.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Digital Twins of Blockchain Systems: State Extraction and Mirroring</title>
<link>https://arxiv.org/abs/2412.05527</link>
<guid>https://arxiv.org/abs/2412.05527</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、采纳率、三难困境、共识协议、数字孪生<br /><br />总结：
随着区块链采纳率创历史新高，各类区块链架构应运而生以满足各种应用集成区块链的需求。然而，区块链系统面临三难困境问题，即在扩展性、去中心化和安全性之间难以取得平衡。这一平衡主要由所采用的共识协议决定。由于共识协议针对特定系统条件设计，因此在区块链这种复杂动态的环境下，单一共识协议运行的系统注定会在某些时期遭遇效率低下问题。本文提出的工作是构建基于数字孪生的区块链管理框架的一部分，旨在通过调整共识过程以适应底层系统的条件来解决三难困境问题。具体而言，文章解决了如何从区块链系统中抽取并镜像到其数字孪生体的问题，提出了克服区块链去中心化、异步特性和全局状态同步等基本问题的算法。实验评估了所提算法的鲁棒性。 <div>
arXiv:2412.05527v1 Announce Type: new 
Abstract: Blockchain adoption is reaching an all-time high, with a plethora of blockchain architectures being developed to cover the needs of applications eager to integrate blockchain into their operations. However, blockchain systems suffer from the trilemma trade-off problem, which limits their ability to scale without sacrificing essential metrics such as decentralisation and security. The balance of the trilemma trade-off is primarily dictated by the consensus protocol used. Since consensus protocols are designed to function well under specific system conditions, and consequently, due to the blockchain's complex and dynamic nature, systems operating under a single consensus protocol are bound to face periods of inefficiency. The work presented in this paper constitutes part of an effort to design a Digital Twin-based blockchain management framework to balance the trilemma trade-off problem, which aims to adapt the consensus process to fit the conditions of the underlying system. Specifically, this work addresses the problems of extracting the blockchain system and mirroring it in its digital twin by proposing algorithms that overcome the challenges posed by blockchains' decentralised and asynchronous nature and the fundamental problems of global state and synchronisation in such systems. The robustness of the proposed algorithms is experimentally evaluated.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Balancing Confidentiality and Transparency for Blockchain-based Process-Aware Information Systems</title>
<link>https://arxiv.org/abs/2412.05737</link>
<guid>https://arxiv.org/abs/2412.05737</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain、Process-Aware Information Systems (PAISs)、Transparency、Confidentiality、CONFETTY

总结:
本文提出了一个名为CONFETTY的新架构，该架构旨在同时保护区块链为基础的PAISs中的机密性和透明性。智能合约用于执行、强制和存储公开交互，而属性基加密技术则用于指定对敏感信息的访问权限。通过对系统进行系统性的威胁模型分析，文章评估了解决方案的安全性，并通过实施原型在不同场景下的性能测试证明了其实用可行性。这为需要保密操作但仍需保持一定程度交易可验证性的场合提供了一种新的解决方案。 <div>
arXiv:2412.05737v1 Announce Type: new 
Abstract: Blockchain enables novel, trustworthy Process-Aware Information Systems (PAISs) by enforcing the security, robustness, and traceability of operations. In particular, transparency ensures that all information exchanges are openly accessible, fostering trust within the system. Although this is a desirable property to enable notarization and auditing activities, it also represents a limitation for such cases where confidentiality is a requirement since interactions involve sensible data. Current solutions rely on obfuscation techniques or private infrastructures, hindering the enforcing capabilities of smart contracts and the public verifiability of transactions. Against this background, we propose CONFETTY, an architecture for blockchain-based PAISs aimed at preserving both confidentiality and transparency. Smart contracts enact, enforce and store public interactions, while attribute-based encryption techniques are adopted to specify access grants to confidential information. We assess the security of our solution through a systematic threat model analysis and assess its practical feasibility by gauging the performance of our implemented prototype in different scenarios from the literature.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Dynamic Tree Structure for Hierarchical On-Chain Asset Management</title>
<link>https://arxiv.org/abs/2412.06026</link>
<guid>https://arxiv.org/abs/2412.06026</guid>
<content:encoded><![CDATA[
<div> 关键词：Sarv、区块链、层次关系、数据管理、Algorand Standard Assets

<br /><br />总结：
本文介绍了Sarv，一种新型非整体式区块链基础数据结构，用于表示数字可表示组件之间的层次关系。Sarv为供应链追踪、资产管理及循环经济实施等需要层次化数据管理的应用提供底层支持。该方案采用树形数据结构准确反映产品及其子组件的关系，支持修改、拆解、借用和翻新等现实世界操作。通过基于智能合约设计并利用Algorand Standard Assets (ASAs)，Sarv将层次结构嵌入到链上数据结构中。其独特之处在于紧凑且非整体式的架构、可变性以及增强安全性和资产管理委托的两层授权机制。文章通过实例证明，Sarv为区块链上的层次化数据管理提供了一种可扩展、可变且安全的解决方案。 <div>
arXiv:2412.06026v1 Announce Type: new 
Abstract: In this paper, we introduce the Sarv, a novel non-monolithic blockchain-based data structure designed to represent hierarchical relationships between digitally representable components. Sarv serves as an underlying infrastructure for a wide range of applications requiring hierarchical data management, such as supply chain tracking, asset management, and circular economy implementations. Our approach leverages a tree-based data structure to accurately reflect products and their sub-components, enabling functionalities such as modification, disassembly, borrowing, and refurbishment, mirroring real-world operations. The hierarchy within Sarv is embedded in the on-chain data structure through a smart contract-based design, utilizing Algorand Standard Assets (ASAs). The uniqueness of Sarv lies in its compact and non-monolithic architecture, its mutability, and a two-layer action authorization scheme that enhances security and delegation of asset management. We demonstrate that Sarv addresses real-world requirements by providing a scalable, mutable, and secure solution for managing hierarchical data on the blockchain.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fully Distributed Online Training of Graph Neural Networks in Networked Systems</title>
<link>https://arxiv.org/abs/2412.06105</link>
<guid>https://arxiv.org/abs/2412.06105</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络(GNN), 分布式训练, 在线训练, 通信效率, 大规模网络系统

总结:<br />
本文首次提出了一种针对大规模网络系统的通信高效、完全分布式在线图神经网络(GNN)训练方法。该方法针对含有B个样本的mini-batch，仅需在GNN推理所需的LB轮消息传递基础上额外增加L轮消息传递，同时消息大小翻倍。通过在图节点回归、无线网络中的功率分配和链接调度等场景的数值实验，展示了该方法在监督学习、无监督学习和强化学习范式下有效训练GNN的能力。 <div>
arXiv:2412.06105v1 Announce Type: new 
Abstract: Graph neural networks (GNNs) are powerful tools for developing scalable, decentralized artificial intelligence in large-scale networked systems, such as wireless networks, power grids, and transportation networks. Currently, GNNs in networked systems mostly follow a paradigm of `centralized training, distributed execution', which limits their adaptability and slows down their development cycles. In this work, we fill this gap for the first time by developing a communication-efficient, fully distributed online training approach for GNNs applied to large networked systems. For a mini-batch with $B$ samples, our approach of training an $L$-layer GNN only adds $L$ rounds of message passing to the $LB$ rounds required by GNN inference, with doubled message sizes. Through numerical experiments in graph-based node regression, power allocation, and link scheduling in wireless networks, we demonstrate the effectiveness of our approach in training GNNs under supervised, unsupervised, and reinforcement learning paradigms.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Membership Inference Attacks and Defenses in Federated Learning: A Survey</title>
<link>https://arxiv.org/abs/2412.06157</link>
<guid>https://arxiv.org/abs/2412.06157</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习、隐私泄露、成员推理攻击、防御策略、未来研究方向

<br /><br />总结:
本文针对联邦学习中的一个重要隐私问题——成员推理攻击进行了全面调研。联邦学习是一种分布式机器学习方法，允许客户端本地训练模型并共享更新以构建全局模型，但依然存在隐私泄露风险，尤其是成员推理攻击。该文归纳并总结了针对联邦学习环境下的此类攻击以及相应的防御策略，并依据其特性提出了一种独特的攻击研究分类体系。此外，文章还系统性地概述了各种防御措施的优缺点。最后，对未来的研究方向进行了识别和讨论，为对此领域感兴趣的研究者提供了有价值的参考。 <div>
arXiv:2412.06157v1 Announce Type: new 
Abstract: Federated learning is a decentralized machine learning approach where clients train models locally and share model updates to develop a global model. This enables low-resource devices to collaboratively build a high-quality model without requiring direct access to the raw training data. However, despite only sharing model updates, federated learning still faces several privacy vulnerabilities. One of the key threats is membership inference attacks, which target clients' privacy by determining whether a specific example is part of the training set. These attacks can compromise sensitive information in real-world applications, such as medical diagnoses within a healthcare system. Although there has been extensive research on membership inference attacks, a comprehensive and up-to-date survey specifically focused on it within federated learning is still absent. To fill this gap, we categorize and summarize membership inference attacks and their corresponding defense strategies based on their characteristics in this setting. We introduce a unique taxonomy of existing attack research and provide a systematic overview of various countermeasures. For these studies, we thoroughly analyze the strengths and weaknesses of different approaches. Finally, we identify and discuss key future research directions for readers interested in advancing the field.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BECS: A Privacy-Preserving Computing Sharing Mechanism in 6G Computing Power Network</title>
<link>https://arxiv.org/abs/2412.06196</link>
<guid>https://arxiv.org/abs/2412.06196</guid>
<content:encoded><![CDATA[
<div> 关键词: 6G网络、计算共享、演化算法、区块链、用户隐私

总结:
<br />
本文提出了一个适用于6G计算力网络(CPN)的计算共享机制BECS，该机制基于演化算法和区块链技术，旨在平衡用户设备、边缘设备和云端资源之间的任务卸载，从而提升计算资源利用率。首先，将计算共享建模为一个多目标优化问题，目标是提高资源利用并平衡其他因素。为解决这一NP难问题，文章设计了一种基于核距离的支配关系，并将其融入非支配排序遗传算法III，显著提升了进化种群的多样性。此外，为了保护参与计算共享用户的隐私，文章还提出了一种基于零知识证明的匿名方案。最后的安全分析与模拟结果表明，BECS能充分利用6G CPN中的所有计算资源，显著提高了计算资源利用率，并有效保护了用户隐私。 <div>
arXiv:2412.06196v1 Announce Type: new 
Abstract: 5G networks provide secure and reliable information transmission services for the Internet of Everything, thus paving the way for 6G networks, which is anticipated to be an AI-based network, supporting unprecedented intelligence across applications. Abundant computing resources will establish the 6G Computing Power Network (CPN) to facilitate ubiquitous intelligent services. In this article, we propose BECS, a computing sharing mechanism based on evolutionary algorithm and blockchain, designed to balance task offloading among user devices, edge devices, and cloud resources within 6G CPN, thereby enhancing the computing resource utilization. We model computing sharing as a multi-objective optimization problem, aiming to improve resource utilization while balancing other issues. To tackle this NP-hard problem, we devise a kernel distance-based dominance relation and incorporated it into the Non-dominated Sorting Genetic Algorithm III, significantly enhancing the diversity of the evolutionary population. In addition, we propose a pseudonym scheme based on zero-knowledge proof to protect the privacy of users participating in computing sharing. Finally, the security analysis and simulation results demonstrate that BECS can fully and effectively utilize all computing resources in 6G CPN, significantly improving the computing resource utilization while protecting user privacy.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Scalable Decentralized Reinforcement Learning Framework for UAV Target Localization Using Recurrent PPO</title>
<link>https://arxiv.org/abs/2412.06231</link>
<guid>https://arxiv.org/abs/2412.06231</guid>
<content:encoded><![CDATA[
<div> 关键词：无人机(UAVs)，集体行为，目标定位，Recurrent PPO模型，感知退化环境

<br />
总结:
该研究探索了一种应用于感知退化环境（如无GNSS/GPS信号的地方）中的目标定位任务的Recurrent PPO模型。研究首先开发了一个单无人机的目标识别方法，随后构建了一个去中心化的双无人机模型。利用无人机上的检测传感器和目标信号传感器，单无人机模型实现了93%的精度，而双无人机模型虽然精度达到86%，但所需平均定位步骤更少，显示出在复杂环境条件下，利用此方法进行无人机群高效、有效的辐射目标定位潜力。 <div>
arXiv:2412.06231v1 Announce Type: new 
Abstract: The rapid advancements in unmanned aerial vehicles (UAVs) have unlocked numerous applications, including environmental monitoring, disaster response, and agricultural surveying. Enhancing the collective behavior of multiple decentralized UAVs can significantly improve these applications through more efficient and coordinated operations. In this study, we explore a Recurrent PPO model for target localization in perceptually degraded environments like places without GNSS/GPS signals. We first developed a single-drone approach for target identification, followed by a decentralized two-drone model. Our approach can utilize two types of sensors on the UAVs, a detection sensor and a target signal sensor. The single-drone model achieved an accuracy of 93%, while the two-drone model achieved an accuracy of 86%, with the latter requiring fewer average steps to locate the target. This demonstrates the potential of our method in UAV swarms, offering efficient and effective localization of radiant targets in complex environmental conditions.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Q-PnV: A Quantum Consensus Mechanism for Security Consortium Blockchains</title>
<link>https://arxiv.org/abs/2412.06325</link>
<guid>https://arxiv.org/abs/2412.06325</guid>
<content:encoded><![CDATA[
<div> 关键词：量子区块链、共识算法、Q-PnV、量子投票、量子数字签名

总结:
本文提出了一种名为Q-PnV的新型量子共识机制，该机制基于经典的Proof of Vote (PoV)，并融合了量子投票、量子数字签名和量子随机数生成器（QRNGs）。Q-PnV被应用于构建一种使用加权超图状态的量子区块链解决方案，特别针对联盟链场景。相较于传统的办法，基于Q-PnV的量子区块链能够抵抗量子攻击，并在安全性与公平性方面表现出显著提升，更加适应未来的量子时代需求。<br /><br /> <div>
arXiv:2412.06325v1 Announce Type: new 
Abstract: Due to the rapid development of quantum computing, many classical blockchain technologies are now considered insecure. The emergence of quantum blockchain holds promise for addressing this issue. Various quantum consensus algorithms have been proposed so far, but there has not yet been a quantum consensus algorithm tailored specifically for consortium blockchain scenarios. In this paper, we propose a novel quantum consensus mechanism, named Q-PnV. This consensus mechanism is based on the classical Proof of Vote (PoV), integrating quantum voting, quantum digital signature and quantum random number generators (QRNGs). By combining Q-PnV with a quantum blockchain using weighted hypergraph states, we propose a comprehensive quantum blockchain solution for consortium blockchain scenarios. Compared to the classical method, the quantum blockchain based on Q-PnV can resist quantum attacks and shows significant improvements in security and fairness, making it better suit-ed for the future quantum era.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ICtoken: An NFT for Hardware IP Protection</title>
<link>https://arxiv.org/abs/2412.06726</link>
<guid>https://arxiv.org/abs/2412.06726</guid>
<content:encoded><![CDATA[
<div> 关键词：集成电路保护、非同质化代币(NFTs)、ICtokens、分布式账本技术、区块链<br /><br />总结:<br />
本文提出了一种利用非同质化代币（NFTs）名为ICtokens的新颖框架，用于保护集成电路（ICs）免受盗版和盗窃。每个ICtoken与其对应的物理IC独特链接，存储认证数据、供应链状态、所有权信息以及IC元数据，并可安全集成逻辑锁定密钥。通过公开记录并使用节能型联盟区块链驱动的ICtracker管理ICtokens及其所有者，确保了计量信息的安全隐藏与功能完整，并实现从源头IP持有者到消费者的全链条追溯与审计。此外，该框架创建了IC及嵌入IC产品的不可变数字孪生体，即ICtokens及其交易记录，为IC供应链监控提供了比现有方案更为详尽的审计信息。文章实施了一个开源的原型系统以验证所提框架的易采用性。 <div>
arXiv:2412.06726v1 Announce Type: new 
Abstract: Protecting integrated circuits (ICs) from piracy and theft throughout their lifecycle is a persistent and complex challenge. In order to safeguard against illicit piracy attacks, this work proposes a novel framework utilizing Non-Fungible Tokens (NFTs) called ICtokens, uniquely linked to their corresponding physical ICs. Each ICtoken contains comprehensive information, including authentication data, supply chain stage and status, ownership details, and other IC metadata, while also making provision for the secure integration of a logic-locking key. Designed to be publicly logged, ICtokens securely obscure metering information without compromising functionality. In addition, the ICtracker, a distributed ledger technology powered by a swift and energy-efficient consortium blockchain, is used to register and manage ICtokens and their respective owners, tracking all associated interactions. This robust ledger guarantees the traceability and auditing of ICtokens while simultaneously developing a product-level NFT at every transaction point within the supply chain. Consequently, a scalable framework is established, creating unique, immutable digital twins for ICs and IC-embedded products in the form of ICtokens and their transactions. This provides a robust and reliable supply chain trail back to the original IP owner, while also offering unprecedented assurance to consumers of IC-embedded products. The rich information contained within ICtokens facilitates more detailed audits than previous proposals for IC supply chain monitoring. A proof-of-concept, implemented as an open-source solution, ensures the ease of adoption of the proposed framework.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR) Applications</title>
<link>https://arxiv.org/abs/2412.06759</link>
<guid>https://arxiv.org/abs/2412.06759</guid>
<content:encoded><![CDATA[
<div> 关键词: XRZoo、Extended Reality (XR)、应用数据集、软件工程、安全性研究

总结:<br />
本文介绍了XRZoo，这是一个针对Extended Reality（包括AR、MR和VR）应用的大型、代表性、高质量的数据集，旨在填补XR软件过程研究中的数据空白。XRZoo收录了来自九家应用商店的12,528个免费XR应用程序，涵盖了各种XR技术及应用场景，并包含了详细元数据，如应用描述、分类、发布日期、用户评价数量和硬件规格等信息。通过公开提供XRZoo数据集，该研究期望推动可重复的XR软件工程和安全性研究，促进跨学科调查，并为开发者提供示例以支持高级XR系统的发展。XRZoo将成为对XR应用的可扩展性、可用性和有效性的改进研究与实践工作的重要资源，并将得到持续维护和更新。 <div>
arXiv:2412.06759v1 Announce Type: new 
Abstract: The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR) and spatial computing technologies forms a foundational layer for the emerging Metaverse, enabling innovative applications across healthcare, education, manufacturing, and entertainment. However, research in this area is often limited by the lack of large, representative, and highquality application datasets that can support empirical studies and the development of new approaches benefiting XR software processes. In this paper, we introduce XRZoo, a comprehensive and curated dataset of XR applications designed to bridge this gap. XRZoo contains 12,528 free XR applications, spanning nine app stores, across all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed metadata on key aspects such as application descriptions, application categories, release dates, user review numbers, and hardware specifications, etc. By making XRZoo publicly available, we aim to foster reproducible XR software engineering and security research, enable cross-disciplinary investigations, and also support the development of advanced XR systems by providing examples to developers. Our dataset serves as a valuable resource for researchers and practitioners interested in improving the scalability, usability, and effectiveness of XR applications. XRZoo will be released and actively maintained.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring Data Management Challenges and Solutions in Agile Software Development: A Literature Review and Practitioner Survey</title>
<link>https://arxiv.org/abs/2402.00462</link>
<guid>https://arxiv.org/abs/2402.00462</guid>
<content:encoded><![CDATA[
<div> 关键词：数据管理、敏捷项目、挑战、解决方案、系统atic文献回顾<br /><br />总结:<br />
本文针对软件产品及其开发相关的数据管理在敏捷项目中所面临的显著挑战进行了深入探讨。研究采用混合方法进行，首先通过系统性文献回顾（SLR）对现有研究进行了梳理，分析了45项研究中的数据管理方面及其相关挑战和解决方案。随后，对32位具有丰富数据管理经验的行业从业者进行了调查，以反映实践现状。研究发现实践中主要的数据管理挑战包括：数据集成过程管理、多样化数据捕获、自动化数据收集以及实时分析需求满足等。为解决这些问题，提出了诸如自动化工具、去中心化数据管理实践以及本体驱动的方法等解决方案，这些方案能提升数据集成能力、改善数据质量并为敏捷项目提供灵活框架以支持实时决策。研究表明，对于敏捷开发而言，识别关键数据管理挑战并实施有效的管理和工具解决方案对于提高项目成功率至关重要。 <div>
arXiv:2402.00462v3 Announce Type: replace 
Abstract: Context: Managing data related to a software product and its development poses significant challenges for software projects and agile development teams. These include integrating data from diverse sources and ensuring data quality amidst continuous change and adaptation. Objective: The paper systematically explores data management challenges and potential solutions in agile projects, aiming to provide insights into data management challenges and solutions for both researchers and practitioners. Method: We employed a mixed-methods approach, including a systematic literature review (SLR) to understand the state-of-research followed by a survey with practitioners to reflect on the state-of-practice. The SLR reviewed 45 studies, identifying and categorizing data management aspects along with their associated challenges and solutions. The practitioner survey captured practical experiences and solutions from 32 industry practitioners who were significantly involved in data management to complement the findings from the SLR. Results: Our findings identified major data management challenges in practice, such as managing data integration processes, capturing diverse data, automating data collection, and meeting real-time analysis requirements. To address these challenges, solutions such as automation tools, decentralized data management practices, and ontology-based approaches have been identified. These solutions enhance data integration, improve data quality, and enable real-time decision-making by providing flexible frameworks tailored to agile project needs. Conclusion: The study pinpointed significant challenges and actionable solutions in data management for agile development. Our findings provide practical implications for practitioners and researchers, emphasizing the development of effective data management practices and tools to address those challenges and improve project success.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Retraction-Free Decentralized Non-convex Optimization with Orthogonal Constraints</title>
<link>https://arxiv.org/abs/2405.11590</link>
<guid>https://arxiv.org/abs/2405.11590</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式非凸优化、正交约束、重traction、无重traction着陆算法、DRFGT、收敛率、线性代数操作、计算效率、局部Riemannian P\L条件

总结:
该文研究了带有正交约束的分布式非凸优化问题。针对该问题，传统算法需要使用流形重traction或投影等方法来保证可行性，这些方法涉及到昂贵的线性代数运算（如SVD或矩阵求逆）。文章受到无重traction着陆算法的启发，提出了首个分布式无重traction梯度跟踪算法——DRFGT。理论上，证明了DRFGT具有$\mathcal{O}(1/K)$的ergodic收敛率，与中心化、基于重traction的方法收敛速度相匹配。此外，还在满足局部Riemannian P\L条件的情况下，进一步证明了DRFGT能够实现更快的线性收敛率。数值实验表明，DRFGT的表现与最先进的基于重traction的方法相当，但显著降低了计算开销。<br /><br /> <div>
arXiv:2405.11590v2 Announce Type: replace 
Abstract: In this paper, we investigate decentralized non-convex optimization with orthogonal constraints. Conventional algorithms for this setting require either manifold retractions or other types of projection to ensure feasibility, both of which involve costly linear algebra operations (e.g., SVD or matrix inversion). On the other hand, infeasible methods are able to provide similar performance with higher computational efficiency. Inspired by this, we propose the first decentralized version of the retraction-free landing algorithm, called \textbf{D}ecentralized \textbf{R}etraction-\textbf{F}ree \textbf{G}radient \textbf{T}racking (DRFGT). We theoretically prove that DRFGT enjoys the ergodic convergence rate of $\mathcal{O}(1/K)$, matching the convergence rate of centralized, retraction-based methods. We further establish that under a local Riemannian P{\L} condition, DRFGT achieves a much faster linear convergence rate. Numerical experiments demonstrate that DRFGT performs on par with the state-of-the-art retraction-based methods with substantially reduced computational overhead.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>LiveNet: Robust, Minimally Invasive Multi-Robot Control for Safe and Live Navigation in Constrained Environments</title>
<link>https://arxiv.org/abs/2412.04659</link>
<guid>https://arxiv.org/abs/2412.04659</guid>
<content:encoded><![CDATA[
<div> 关键词: LiveNet、机器人、拥挤环境、安全、实时避障

总结:<br />
本文介绍了LiveNet，这是一种针对密集环境中机器人的全新全分布式神经网络控制器，旨在解决狭窄通道和冲突区域中的碰撞与死锁问题。现有的优化和神经网络方法主要适用于开阔空间，或者过于保守，只能确保安全或活性其中一个方面。LiveNet提供了一种创新的方法，实现了安全性和活性的同时保证，通过统一的CBF（控制 Barrier 函数）形式化并集成到神经网络中以实现鲁棒性。该控制器无需机器人间通信或协作行为即可实现人类般的让行和通行。实验表明，相比常规多机器人优化和学习基导航方法，LiveNet不仅能够成功达到目标，而且速度更快（快10-20倍）、侵入性更小（减少4-5倍），对场景配置变化更具适应性。LiveNet代码已在GitHub上开源。 <div>
arXiv:2412.04659v1 Announce Type: new 
Abstract: Robots in densely populated real-world environments frequently encounter constrained and cluttered situations such as passing through narrow doorways, hallways, and corridor intersections, where conflicts over limited space result in collisions or deadlocks among the robots. Current decentralized state-of-the-art optimization- and neural network-based approaches (i) are predominantly designed for general open spaces, and (ii) are overly conservative, either guaranteeing safety, or liveness, but not both. While some solutions rely on centralized conflict resolution, their highly invasive trajectories make them impractical for real-world deployment. This paper introduces LiveNet, a fully decentralized and robust neural network controller that enables human-like yielding and passing, resulting in agile, non-conservative, deadlock-free, and safe, navigation in congested, conflict-prone spaces. LiveNet is minimally invasive, without requiring inter-agent communication or cooperative behavior. The key insight behind LiveNet is a unified CBF formulation for simultaneous safety and liveness, which we integrate within a neural network for robustness. We evaluated LiveNet in simulation and found that general multi-robot optimization- and learning-based navigation methods fail to even reach the goal, and while methods designed specially for such environments do succeed, they are 10-20 times slower, 4-5 times more invasive, and much less robust to variations in the scenario configuration such as changes in the start states and goal states, among others. We open-source the LiveNet code at https://github.com/srikarg89/LiveNet{https://github.com/srikarg89/LiveNet.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DRDST: Low-latency DAG Consensus through Robust Dynamic Sharding and Tree-broadcasting for IoV</title>
<link>https://arxiv.org/abs/2412.04742</link>
<guid>https://arxiv.org/abs/2412.04742</guid>
<content:encoded><![CDATA[
<div> 关键词: IoV、区块链、分片、DAG共识、动态鲁棒分片<br /><br />总结:

本文针对互联网汽车（IoV）中通信效率和延迟降低的需求，探讨了利用区块链技术面临的挑战。为解决区块链扩展性问题，文章提出了基于有向无环图（DAG）共识和鲁棒动态分片与树广播（DRDST）的方法。首先，通过结合节点网络稳定性和信任值提出了一种新的鲁棒分片模型，并设计了遗传分片算法（GSA）来实现该模型。其次，改进树广播方式以优化整个分片网络的广播延迟，从而减少每个分片内的最大广播延迟。此外，文中还设计了一个基于改进哈希图协议的DAG共识方案，能有效处理跨分片交易。最后，通过仿真验证，所提出的方案在延迟、吞吐量、共识成功率和节点流量负载等方面均优于对比方案。 <div>
arXiv:2412.04742v1 Announce Type: new 
Abstract: The Internet of Vehicles (IoV) is emerging as a pivotal technology for enhancing traffic management and safety. Its rapid development demands solutions for enhanced communication efficiency and reduced latency. However, traditional centralized networks struggle to meet these demands, prompting the exploration of decentralized solutions such as blockchain. Addressing blockchain's scalability challenges posed by the growing number of nodes and transactions calls for innovative solutions, among which sharding stands out as a pivotal approach to significantly enhance blockchain throughput. However, existing schemes still face challenges related to a) the impact of vehicle mobility on blockchain consensus, especially for cross-shard transaction; and b) the strict requirements of low latency consensus in a highly dynamic network. In this paper, we propose a DAG (Directed Acyclic Graph) consensus leveraging Robust Dynamic Sharding and Tree-broadcasting (DRDST) to address these challenges. Specifically, we first develop a standard for evaluating the network stability of nodes, combined with the nodes' trust values, to propose a novel robust sharding model that is solved through the design of the Genetic Sharding Algorithm (GSA). Then, we optimize the broadcast latency of the whole sharded network by improving the tree-broadcasting to minimize the maximum broadcast latency within each shard. On this basis, we also design a DAG consensus scheme based on an improved hashgraph protocol, which can efficiently handle cross-shard transactions. Finally, the simulation proves the proposed scheme is superior to the comparison schemes in latency, throughput, consensus success rate, and node traffic load.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing</title>
<link>https://arxiv.org/abs/2412.04868</link>
<guid>https://arxiv.org/abs/2412.04868</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning as a Service (FLaaS), JointCloud Computing (JCC), TEE (Trusted Execution Environment), NebulaFL, Asynchronous FL

总结:
随着AI基础设施和可信执行环境（TEE）技术的发展，联邦学习作为服务（FLaaS）通过联合云计算（JCC）有望打破传统联邦学习中的异构边缘设备资源约束。然而，FLaaS面临着数据异质性导致的训练性能低下、不同云之间的高通信开销以及缺乏有效资源调度策略等问题。为了解决这些问题，本文提出了一种新的异步联邦学习方法——NebulaFL，用于多个云端的协同模型训练。针对数据异质性问题，NebulaFL在每个数据中心采用基于版本控制的异步FL训练方案来平衡数据所有者间的训练时间。为了降低通信开销，NebulaFL采用了去中心化的模型旋转机制实现知识的有效共享。同时，为了平衡训练时间和成本，NebulaFL整合了奖励引导的数据选择和资源调度策略。实验结果显示，与现有最先进的FL方法相比，NebulaFL能够在保持目标准确率的前提下，提高最多5.71%的准确性，减少高达50%的通信开销，并将成本降低了61.94%。 <div>
arXiv:2412.04868v1 Announce Type: new 
Abstract: With advancements in AI infrastructure and Trusted Execution Environment (TEE) technology, Federated Learning as a Service (FLaaS) through JointCloud Computing (JCC) is promising to break through the resource constraints caused by heterogeneous edge devices in the traditional Federated Learning (FL) paradigm. Specifically, with the protection from TEE, data owners can achieve efficient model training with high-performance AI services in the cloud. By providing additional FL services, cloud service providers can achieve collaborative learning among data owners. However, FLaaS still faces three challenges, i.e., i) low training performance caused by heterogeneous data among data owners, ii) high communication overhead among different clouds (i.e., data centers), and iii) lack of efficient resource scheduling strategies to balance training time and cost. To address these challenges, this paper presents a novel asynchronous FL approach named NebulaFL for collaborative model training among multiple clouds. To address data heterogeneity issues, NebulaFL adopts a version control-based asynchronous FL training scheme in each data center to balance training time among data owners. To reduce communication overhead, NebulaFL adopts a decentralized model rotation mechanism to achieve effective knowledge sharing among data centers. To balance training time and cost, NebulaFL integrates a reward-guided strategy for data owners selection and resource scheduling. The experimental results demonstrate that, compared to the state-of-the-art FL methods, NebulaFL can achieve up to 5.71\% accuracy improvement. In addition, NebulaFL can reduce up to 50% communication overhead and 61.94% costs under a target accuracy.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bridging Culture and Finance: A Multimodal Analysis of Memecoins in the Web3 Ecosystem</title>
<link>https://arxiv.org/abs/2412.04913</link>
<guid>https://arxiv.org/abs/2412.04913</guid>
<content:encoded><![CDATA[
<div> 关键词：Memecoins、Coin-Meme数据集、Web3生态系统、多模态分析框架、Solana区块链

总结:<br />
本文介绍了针对Web3生态系统中迅速崛起的基于社交媒体互动和文化叙事驱动的Memecoins进行研究的相关成果。文章提出了一个名为Coin-Meme的数据集，该数据集包含了来源于Solana区块链上Pump.fun平台的关于视觉、文本、社区及金融方面的开放源数据。同时，文中提出了一种多模态框架，用于分析Memecoins的文化主题、社区互动以及金融行为。通过聚类、情感分析和词云可视化方法，研究者们识别出了以幽默、动物和政治讽刺为主题的独特群体。此外，文章还通过对Market Entry Time和Market Capitalization等指标的分析，提供了对Memecoins作为文化产物和Web3环境中金融工具的全面见解。该Coin-Meme数据集已在GitHub上公开发布。 <div>
arXiv:2412.04913v1 Announce Type: new 
Abstract: Memecoins, driven by social media engagement and cultural narratives, have rapidly grown within the Web3 ecosystem. Unlike traditional cryptocurrencies, they are shaped by humor, memes, and community sentiment. This paper introduces the Coin-Meme dataset, an open-source collection of visual, textual, community, and financial data from the Pump.fun platform on the Solana blockchain. We also propose a multimodal framework to analyze memecoins, uncovering patterns in cultural themes, community interaction, and financial behavior. Through clustering, sentiment analysis, and word cloud visualizations, we identify distinct thematic groups centered on humor, animals, and political satire. Additionally, we provide financial insights by analyzing metrics such as Market Entry Time and Market Capitalization, offering a comprehensive view of memecoins as both cultural artifacts and financial instruments within Web3. The Coin-Meme dataset is publicly available at https://github.com/hwlongCUHK/Coin-Meme.git.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Experimental Framework for Implementing Decentralized Autonomous Database Systems in Rust</title>
<link>https://arxiv.org/abs/2412.05078</link>
<guid>https://arxiv.org/abs/2412.05078</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Autonomous Database Systems (DADBS), Rust编程语言, 实验框架, 性能评估, 安全性分析

总结:
本文介绍了使用Rust编程语言实现去中心化自治数据库系统(DADBS)的实验框架。该研究聚焦于利用Rust的独特特性以提高系统可靠性和性能，应对传统集中式数据库在可扩展性、安全性及自主性方面的挑战。文章通过评估实施的DADBS在吞吐量、读取延迟、写入延迟、可扩展性、CPU利用率、内存使用和网络I/O等方面的性能，得出了一组连续运行24小时的平均数据。安全分析显示，即使恶意节点比例增加，DADBS仍能保持高吞吐量和一致性。文中还讨论了关键设计决策，强调Rust的所有权模型和并发特性如何解决分布式系统的常见问题。同时，文中也探讨了当前方法的局限性以及未来的研究方向。通过提供基于Rust的DADBS全面概述，本文旨在为日益壮大的去中心化数据库架构及其实际实现的知识库做出贡献。 <div>
arXiv:2412.05078v1 Announce Type: new 
Abstract: This paper presents an experimental framework for implementing Decentralized Autonomous Database Systems (DADBS) using the Rust programming language. As traditional centralized databases face challenges in scalability, security, and autonomy, DADBS emerge as a promising solution, using blockchain principles to create distributed, self-governing database systems. Our framework explores the practical aspects of building a DADBS, focusing on Rust's unique features that improves system reliability and performance. We evaluated our DADBS implementation across several key performance metrics: throughput, latency(read), latency(write), scalability, CPU utilization, Memory Usage and Network I/O, The average results obtained over a 24-hour period of continuous operation were 3,000 transactions/second, 75 ms, 250 ms, 55%, 2.5 GB, 100MB/s. The security analysis depicts that even with an increase in the percentage of malicious nodes, DADBS still maintains high throughput and consistency. The paper discusses key design decisions, highlighting how Rust's ownership model and concurrency features address common challenges in distributed systems. We also examine the current limitations of our approach and potential areas for future research. By providing this comprehensive overview of a Rust-based DADBS implementation, we aim to contribute to the growing body of knowledge on decentralized database architectures and their practical realization.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Supply Chain Insecurity: The Lack of Integrity Protection in SBOM Solutions</title>
<link>https://arxiv.org/abs/2412.05138</link>
<guid>https://arxiv.org/abs/2412.05138</guid>
<content:encoded><![CDATA[
<div> 关键词：SolarWinds攻击、软件账单材料(SBOM)、供应链安全、漏洞管理、许可管理<br /><br />总结:

该文深入调查了软件账单材料(SBOM)的完整性，这是确保软件供应链安全的重要工具，特别是在美国总统拜登签署的行政命令中强制要求联邦机构购买的软件必须提供SBOM。文章分析了SBOM在生成和消费阶段可能被利用的各种攻击向量，发现四种SBOM消费工具缺乏对依赖项的完整性的控制机制，同时七个主流编程语言的SBOM生成过程也容易受到完整性攻击，如通过操纵包管理器中的依赖版本号和额外文件导致SBOM数据不准确，进而可能导致在SBOM消费过程中忽视软件依赖关系和漏洞的存在。为解决这些问题，文中提出了一个采用去中心化存储软件库哈希值的解决方案。 <div>
arXiv:2412.05138v1 Announce Type: new 
Abstract: The SolarWinds attack that exploited weaknesses in the software update mechanism highlights the critical need for organizations to have better visibility into their software dependencies and potential vulnerabilities associated with them, and the Software Bill of Materials (SBOM) is paramount in ensuring software supply chain security. Under the Executive Order issued by President Biden, the adoption of the SBOM has become obligatory within the United States. The executive order mandates that an SBOM should be provided for all software purchased by federal agencies. The main applications of SBOMs are vulnerability management and license management. This work presents an in-depth and systematic investigation into the integrity of SBOMs. We explore different attack vectors that can be exploited to manipulate SBOM data, including flaws in the SBOM generation and consumption phases in the SBOM life cycle. We thoroughly investigated four SBOM consumption tools and the generation process of SBOMs for seven prominent programming languages. Our systematic investigation reveals that the tools used for consumption lack integrity control mechanisms for dependencies. Similarly, the generation process is susceptible to integrity attacks as well, by manipulating dependency version numbers in package managers and additional files, resulting in incorrect SBOM data. This could lead to incorrect views on software dependencies and vulnerabilities being overlooked during SBOM consumption. To mitigate these issues, we propose a solution incorporating the decentralized storage of hash values of software libraries.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy Drift: Evolving Privacy Concerns in Incremental Learning</title>
<link>https://arxiv.org/abs/2412.05183</link>
<guid>https://arxiv.org/abs/2412.05183</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、隐私漂移、概念漂移、模型更新、数据分布转移

总结:
<br />
本文探讨了在机器学习领域中，联邦学习（Federated Learning）带来的分布式模型训练和用户数据隐私保护的范式转变。文章提出了“隐私漂移”的新概念，将其与已知的现象——概念漂移相联系。隐私漂移描述的是随着模型增量训练，私人信息泄露程度的变化。研究通过定义并分析隐私漂移，揭示了模型性能演进与数据隐私完整性的微妙关系。实验深入探究了在FL系统中隐私漂移的动力学，重点关注模型更新和数据分布变化如何影响模型对隐私攻击（如成员推理攻击）的敏感性。结果表明，模型准确性的提高可能导致更大的隐私风险。研究者使用基于CIFAR-100定制的数据集进行了实验证明，展示了数据和概念漂移对隐私的影响。这项工作为未来关于隐私意识机器学习的研究奠定了基础，旨在寻求在去中心化环境中实现模型准确性与数据隐私之间的微妙平衡。 <div>
arXiv:2412.05183v1 Announce Type: new 
Abstract: In the evolving landscape of machine learning (ML), Federated Learning (FL) presents a paradigm shift towards decentralized model training while preserving user data privacy. This paper introduces the concept of ``privacy drift", an innovative framework that parallels the well-known phenomenon of concept drift. While concept drift addresses the variability in model accuracy over time due to changes in the data, privacy drift encapsulates the variation in the leakage of private information as models undergo incremental training. By defining and examining privacy drift, this study aims to unveil the nuanced relationship between the evolution of model performance and the integrity of data privacy. Through rigorous experimentation, we investigate the dynamics of privacy drift in FL systems, focusing on how model updates and data distribution shifts influence the susceptibility of models to privacy attacks, such as membership inference attacks (MIA). Our results highlight a complex interplay between model accuracy and privacy safeguards, revealing that enhancements in model performance can lead to increased privacy risks. We provide empirical evidence from experiments on customized datasets derived from CIFAR-100 (Canadian Institute for Advanced Research, 100 classes), showcasing the impact of data and concept drift on privacy. This work lays the groundwork for future research on privacy-aware machine learning, aiming to achieve a delicate balance between model accuracy and data privacy in decentralized environments.
]]></content:encoded>
<pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Securing RC Based P2P Networks: A Blockchain-based Access Control Framework utilizing Ethereum Smart Contracts for IoT and Web 3.0</title>
<link>https://arxiv.org/abs/2412.03709</link>
<guid>https://arxiv.org/abs/2412.03709</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、访问控制框架、以太坊智能合约、动态P2P网络、安全模型

总结:
<br />
本文提出了一种基于区块链的访问控制框架，该框架利用以太坊智能合约解决高度动态的点对点（P2P）网络中的安全性问题，特别是对于在线交易和智能设备服务。针对P2P环境中传统角色基础访问控制（RBAC）系统的不足，此框架通过静态和动态策略管理的访问控制合约（ACC）、处理不当行为的法官合约（JC）以及记录和管理ACC与JC交互的注册合约（RC），提供了灵活、透明和去中心化的解决方案。文章所描述的安全模型结合了影响和严重性评估，运用CIA（机密性、完整性和可用性）和STRIDE原则，确保威胁应对措施能够适应不同的威胁级别。该系统不仅解决了P2P网络中节点成员变更带来的基础问题，还为物联网（IoT）和Web 3.0等技术领域提供了一个可扩展的解决方案。 <div>
arXiv:2412.03709v1 Announce Type: new 
Abstract: Ensuring security for highly dynamic peer-to-peer (P2P) networks has always been a challenge, especially for services like online transactions and smart devices. These networks experience high churn rates, making it difficult to maintain appropriate access control. Traditional systems, particularly Role-Based Access Control (RBAC), often fail to meet the needs of a P2P environment. This paper presents a blockchain-based access control framework that uses Ethereum smart contracts to address these challenges. Our framework aims to close the gaps in existing access control systems by providing flexible, transparent, and decentralized security solutions. The proposed framework includes access control contracts (ACC) that manage access based on static and dynamic policies, a Judge Contract (JC) to handle misbehavior, and a Register Contract (RC) to record and manage the interactions between ACCs and JC. The security model combines impact and severity-based threat assessments using the CIA (Confidentiality, Integrity, Availability) and STRIDE principles, ensuring responses are tailored to different threat levels. This system not only stabilizes the fundamental issues of peer membership but also offers a scalable solution, particularly valuable in areas such as the Internet of Things (IoT) and Web 3.0 technologies.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems</title>
<link>https://arxiv.org/abs/2412.03851</link>
<guid>https://arxiv.org/abs/2412.03851</guid>
<content:encoded><![CDATA[
<div> 关键词: 个性化医疗、联邦学习、数据异质性、累积傅里叶聚合、协同迁移优化

总结:
本文提出了Federated Meta-Learning for Personalized Medication（FedMetaMed）框架，旨在解决分布式医疗系统中个性化药物治疗面临的挑战。该框架结合了联邦学习和元学习，以适应不同医疗机构间的患者数据多样性。针对联邦学习中的服务器聚合阶段性能退化问题，FedMetaMed引入了累积傅里叶聚合（CFA）方法，从低到高频率逐步整合客户端模型，提升全局知识聚合的稳定性和有效性。在客户端，文章实施了一种名为协作迁移优化（CTO）的策略，通过检索、回馈和精炼三步流程，有效实现全球知识向本地个性化模型的平滑转移。实验结果显示，FedMetaMed在真实世界医学影像数据集上优于现有的联邦学习方法，表现出更强的泛化能力，尤其在外分布样本上表现突出。 <div>
arXiv:2412.03851v1 Announce Type: new 
Abstract: Personalized medication aims to tailor healthcare to individual patient characteristics. However, the heterogeneity of patient data across healthcare systems presents significant challenges to achieving accurate and effective personalized treatments. Ethical concerns further complicate the aggregation of large volumes of data from diverse institutions. Federated Learning (FL) offers a promising decentralized solution by enabling collaborative model training through the exchange of client models rather than raw data, thus preserving privacy. However, existing FL methods often suffer from retrogression during server aggregation, leading to a decline in model performance in real-world medical FL settings. To address data variability in distributed healthcare systems, we introduce Federated Meta-Learning for Personalized Medication (FedMetaMed), which combines federated learning and meta-learning to create models that adapt to diverse patient data across healthcare systems. The FedMetaMed framework aims to produce superior personalized models for individual clients by addressing these limitations. Specifically, we introduce Cumulative Fourier Aggregation (CFA) at the server to improve stability and effectiveness in global knowledge aggregation. CFA achieves this by gradually integrating client models from low to high frequencies. At the client level, we implement a Collaborative Transfer Optimization (CTO) strategy with a three-step process - Retrieve, Reciprocate, and Refine - to enhance the personalized local model through seamless global knowledge transfer. Experiments on real-world medical imaging datasets demonstrate that FedMetaMed outperforms state-of-the-art FL methods, showing superior generalization even on out-of-distribution cohorts.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>JANUS: A Difference-Oriented Analyzer For Financial Centralization Risks in Smart Contracts</title>
<link>https://arxiv.org/abs/2412.03938</link>
<guid>https://arxiv.org/abs/2412.03938</guid>
<content:encoded><![CDATA[
<div> 关键词: JANUS、智能合约、中心化风险、检测精度、状态遍历

<br /><br />总结:
本文提出了一种名为JANUS的新工具，用于自动分析Solidity智能合约并独立于具体行为模式检测金融中心化风险。JANUS通过比较特权账户与普通账户所达到的状态差异，并分析这些差异是否与财务相关，从而聚焦于风险的影响而非行为本身，提高了检测准确性。对包含540份合同的测试集进行评估显示，JANUS在检测金融中心化风险方面的准确率优于现有代表性工具。此外，在实际应用中，JANUS对33,151份合同进行了评估，成功发现了其他工具未能检测到的两种类型的风险。同时证明，JANUS使用的状态遍历方法和变量摘要并不会导致检测中的误报或遗漏。 <div>
arXiv:2412.03938v1 Announce Type: new 
Abstract: Some smart contracts violate decentralization principles by defining privileged accounts that manage other users' assets without permission, introducing centralization risks that have caused financial losses. Existing methods, however, face challenges in accurately detecting diverse centralization risks due to their dependence on predefined behavior patterns. In this paper, we propose JANUS, an automated analyzer for Solidity smart contracts that detects financial centralization risks independently of their specific behaviors. JANUS identifies differences between states reached by privileged and ordinary accounts, and analyzes whether these differences are finance-related. Focusing on the impact of risks rather than behaviors, JANUS achieves improved accuracy compared to existing tools and can uncover centralization risks with unknown patterns.
  To evaluate JANUS's performance, we compare it with other tools using a dataset of 540 contracts. Our evaluation demonstrates that JANUS outperforms representative tools in terms of detection accuracy for financial centralization risks . Additionally, we evaluate JANUS on a real-world dataset of 33,151 contracts, successfully identifying two types of risks that other tools fail to detect. We also prove that the state traversal method and variable summaries, which are used in JANUS to reduce the number of states to be compared, do not introduce false alarms or omissions in detection.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>WACANA: A Concolic Analyzer for Detecting On-chain Data Vulnerabilities in WASM Smart Contracts</title>
<link>https://arxiv.org/abs/2412.03946</link>
<guid>https://arxiv.org/abs/2412.03946</guid>
<content:encoded><![CDATA[
<div> 关键词: WebAssembly (WASM), 智能合约, 安全漏洞, WACANA, 精细粒度模拟

总结:
<br />
本文介绍了针对WebAssembly (WASM)智能合约的安全分析工具WACANA。该工具通过精细粒度地模拟链上数据API来准确检测合同中的安全漏洞，从而克服了现有工具精度有限的问题。WACANA精确地模拟了链上数据表的结构和对应的API函数，并结合具体执行与符号执行，在保证准确性的同时提高了效率。实验结果显示，WACANA在对133份有漏洞的合约进行评估时，其准确性超过了当前最先进的工具。进一步在5,602个真实世界的合约中进行验证，证实了WACANA的实际有效性。 <div>
arXiv:2412.03946v1 Announce Type: new 
Abstract: WebAssembly (WASM) has emerged as a crucial technology in smart contract development for several blockchain platforms. Unfortunately, since their introduction, WASM smart contracts have been subject to several security incidents caused by contract vulnerabilities, resulting in substantial economic losses. However, existing tools for detecting WASM contract vulnerabilities have accuracy limitations, one of the main reasons being the coarse-grained emulation of the on-chain data APIs.
  In this paper, we introduce WACANA, an analyzer for WASM contracts that accurately detects vulnerabilities through fine-grained emulation of on-chain data APIs. WACANA precisely simulates both the structure of on-chain data tables and their corresponding API functions, and integrates concrete and symbolic execution within a coverage-guided loop to balance accuracy and efficiency. Evaluations on a vulnerability dataset of 133 contracts show WACANA outperforming state-of-the-art tools in accuracy. Further validation on 5,602 real-world contracts confirms WACANA's practical effectiveness.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dimension Reduction via Random Projection for Privacy in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2412.04031</link>
<guid>https://arxiv.org/abs/2412.04031</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent System (MAS), 信息融合中心, 隐私风险, 数据 utility, 数据隐私保护<br /><br />总结：<br />
本文探讨了多智能体系统(MAS)中，各智能体向信息融合中心发送观测数据时，为提高系统效率而需要附加私人参数所面临的隐私风险问题。为了在保证数据通信安全、防止数据隐私泄露和推理攻击的同时，尽可能减少对数据实用性的损失，文章使用余弦相似性量化系统的实用性和隐私性。文中首先将MAS问题形式化为一个可通过压缩方法解决的概念问题，接着提出一种基于此类压缩方法的创新性数据净化机制，旨在解决实用性与隐私保护之间的权衡问题。 <div>
arXiv:2412.04031v1 Announce Type: new 
Abstract: The agents in a Multi-Agent System (MAS) make observations about the system and send that information to a fusion center. The fusion center aggregates the information and concludes about the system parameters with as much accuracy as possible. However for the purposes of better efficiency of the system at large, the agents need to append some private parameters to the observed data. In this scenario, the data sent to the fusion center is faced with privacy risks. The data communicated to the fusion center must be secured against data privacy breaches and inference attacks in a decentralized manner. However, this in turn leads to a loss of utility of the data being sent to the fusion center. We quantify the utility and privacy of the system using Cosine similarity. We formulate our MAS problem in terms of deducing a concept for which compression-based methods are there in literature. Next, we propose a novel sanitization mechanism for our MAS using one such compression-based method while addressing the utility-privacy tradeoff problem.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Dynamic Event-triggered Output-feedback Control of Stochastic Non-triangular Interconnected Systems with Unknown Time-varying Sensor Sensitivity</title>
<link>https://arxiv.org/abs/2412.04131</link>
<guid>https://arxiv.org/abs/2412.04131</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized output-feedback control, stochastic non-triangular nonlinear systems, time-varying sensor sensitivity, dynamic event-triggered control, global asymptotic stability

总结:<br />
针对具有未知时变传感器灵敏度的随机非三角形非线性互联系统，该研究提出了一种新颖的去中心化动态事件触发输出反馈控制策略。首先，通过独特的坐标变换建立了各子系统的状态向量与两个误差向量之间的线性关系，有效处理了非三角形结构不确定性带来的复杂性。其次，引入了一种包含状态观测器和去中心化输出反馈控制器的动态事件触发机制，设计了一个基于预测plant状态值和时钟变量演化的辅助变量，确保了执行间隔时间存在正下界，从而避免Zeno行为。通过对封闭环路系统的Lyapunov分析，证实了系统全局概收敛稳定性，每个局部子系统的状态和输出均以概率收敛至原点。此外，还保证了触发时刻之间存在最小驻留时间。 <div>
arXiv:2412.04131v1 Announce Type: new 
Abstract: This study addresses the intricate challenge of decentralized output-feedback control for stochastic non-triangular nonlinear interconnected systems with unknown time-varying sensor sensitivity in a dynamic event-triggered context. The presence of stochastic disturbances, non-triangular structural uncertainties, and evolving sensor sensitivity distinguishes this problem of global asymptotic stability from conventional event-triggered control scenarios. Existing event-triggered control approaches with static event conditions encounter difficulties in simultaneously ensuring zero tracking/stabilization error and preventing the occurrence of Zeno behavior. In this work, we develop a novel solution to address this complex issue. Firstly, we establish a linear relationship between the state vector of each interconnected subsystem and two error vectors through a unique coordinate transformation. This transformation effectively handles the complexities introduced by non-triangular structural uncertainties. Secondly, we introduce a decentralized dynamic event-triggered output-feedback control strategy, which involves a state observer and a decentralized output-feedback controller. Unlike conventional event-triggered control methods with static event conditions, this strategy formulates a modified clock-based dynamic triggering mechanism by introducing an auxiliary variable that evolves based on predicted plant state values, while utilizing a clock variable to guarantee the existence of a positive lower bound on inter-execution times. Rigorous Lyapunov analysis confirms the global asymptotic stability in probability of the closed-loop system, with the states and the output of each local subsystem converging to the equilibrium at the origin in probability. Additionally, the existence of a minimal dwell-time between triggering instants is guaranteed.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DistB-VNET: Distributed Cluster-based Blockchain Vehicular Ad-Hoc Networks through SDN-NFV for Smart City</title>
<link>https://arxiv.org/abs/2412.04222</link>
<guid>https://arxiv.org/abs/2412.04222</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能城市、车联网、分布式区块链、软件定义网络、网络功能虚拟化<br /><br />总结:
本文提出了一个名为DistB-VNET的分布式区块链车联网架构，旨在为智能城市的车辆与基础设施交互提供安全、可扩展和可靠的通信。该架构融合了二进制恶意流量分类、软件定义网络(SDN)和网络功能虚拟化(NFV)，利用去中心化的区块链保障数据安全管理，结合SDN-NFV实现动态网络管理和资源效率提升。同时，采用孤立森林算法作为入侵检测系统，其在识别恶意流量方面达到了99.23%的高精度。DistB-VNET还引入了双层区块链系统，其中分布式区块链确保车车间的安全通信，而云中的集中式区块链负责数据验证和存储，增强了安全性、可扩展性和适应性，有助于优化交通管理、提高数据安全性和隐私保护。此外，这种方案显著降低了延迟，提高了网络安全性能并减少了网络拥塞，为现有的智能城市基础设施提供了有效的替代选择。 <div>
arXiv:2412.04222v1 Announce Type: new 
Abstract: In the developing topic of smart cities, Vehicular Ad-Hoc Networks (VANETs) are crucial for providing successful interaction between vehicles and infrastructure. This research proposes a distributed Blockchain-based Vehicular Ad-hoc Network (DistB-VNET) architecture that includes binary malicious traffic classification, Software Defined Networking (SDN), and Network Function Virtualization (NFV) to ensure safe, scalable, and reliable vehicular networks in smart cities. The suggested framework is the decentralized blockchain for safe data management and SDN-NFV for dynamic network management and resource efficiency and a noble isolation forest algorithm works as an IDS (Intrusion Detection System). Further, "DistB-VNET" offers a dual-layer blockchain system, where a distributed blockchain provides safe communication between vehicles, while a centralized blockchain in the cloud is in charge of data verification and storage. This improves security, scalability, and adaptability, ensuring better traffic management, data security, and privacy in VANETs. Furthermore, the unsupervised isolation forest model achieves a high accuracy of 99.23% for detecting malicious traffic. Additionally, reveals that our method greatly improves network performance, offering decreased latency, increased security, and reduced congestion, an effective alternative for existing smart city infrastructures.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>VMGuard: Reputation-Based Incentive Mechanism for Poisoning Attack Detection in Vehicular Metaverse</title>
<link>https://arxiv.org/abs/2412.04349</link>
<guid>https://arxiv.org/abs/2412.04349</guid>
<content:encoded><![CDATA[
<div> 关键词：vehicular Metaverse, 数据中毒攻击, 安全框架, 信任度评估, 口碑激励机制

总结:
<br />
本文提出了一种名为vehicular Metaverse guard (VMGuard)的四层安全框架，用于保护车载元宇宙系统免受数据中毒攻击。该框架针对虚拟服务提供商(VSPs)通过恶意物联网(IoT)设备收集物理环境数据时可能存在的内容篡改问题，以及具有道德风险的恶意SIoT设备可能出于私利提供有毒数据以降低VMUs的服务质量和用户体验(QoS和QoE)的问题。VMGuard采用了基于用户反馈和主观逻辑建模的口碑激励机制，为参与的SIoT设备根据历史交互记录分配声誉评分。通过综合模拟验证，该机制能有效阻止恶意SIoT设备发起的中毒攻击，并确保先前被误分类的可靠SIoT设备不会被排除在未来市场轮次之外。 <div>
arXiv:2412.04349v1 Announce Type: new 
Abstract: The vehicular Metaverse represents an emerging paradigm that merges vehicular communications with virtual environments, integrating real-world data to enhance in-vehicle services. However, this integration faces critical security challenges, particularly in the data collection layer where malicious sensing IoT (SIoT) devices can compromise service quality through data poisoning attacks. The security aspects of the Metaverse services should be well addressed both when creating the digital twins of the physical systems and when delivering the virtual service to the vehicular Metaverse users (VMUs). This paper introduces vehicular Metaverse guard (VMGuard), a novel four-layer security framework that protects vehicular Metaverse systems from data poisoning attacks. Specifically, when the virtual service providers (VSPs) collect data about physical environment through SIoT devices in the field, the delivered content might be tampered. Malicious SIoT devices with moral hazard might have private incentives to provide poisoned data to the VSP to degrade the service quality (QoS) and user experience (QoE) of the VMUs. The proposed framework implements a reputation-based incentive mechanism that leverages user feedback and subjective logic modeling to assess the trustworthiness of participating SIoT devices. More precisely, the framework entails the use of reputation scores assigned to participating SIoT devices based on their historical engagements with the VSPs. Ultimately, we validate our proposed model using comprehensive simulations. Our key findings indicate that our mechanism effectively prevents the initiation of poisoning attacks by malicious SIoT devices. Additionally, our system ensures that reliable SIoT devices, previously missclassified, are not barred from participating in future rounds of the market.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Providing Differential Privacy for Federated Learning Over Wireless: A Cross-layer Framework</title>
<link>https://arxiv.org/abs/2412.04408</link>
<guid>https://arxiv.org/abs/2412.04408</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Over-the-air FL, Differential Privacy, Power Control, Cooperative Jammer

<br /><br />总结:
本文提出了一个针对无线边缘网络中Over-the-air FL的物理层设计，旨在增强差分隐私保护。该设计采用一种去中心化、动态的功率控制策略，利用无线信道中的高斯噪声和合作干扰器（CJ）生成额外的人工噪声以在需要更高隐私级别时提供支持。虽然主要应用于Upcycled-FL框架，但该功率控制策略也可适用于FedAvg和FedProx等其他FL框架，展现了其灵活性和普适性。此外，该设计通过合作干扰器增强了隐私保护，无需客户端注入人工噪声，同时保证了传输效率。文中使用Moments Accountant方法进行了隐私分析，并对非凸目标函数下的收敛性进行了分析，探讨了隐私与准确性之间的权衡。数值结果表明，无论是在FEMNIST非独立同分布数据集上，还是在相同的差分隐私条件下，与现有技术相比，本文提出的方法都表现出了优越性能，并突显了合作干扰器在确保严格隐私方面的有效性。 <div>
arXiv:2412.04408v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed machine learning framework that inherently allows edge devices to maintain their local training data, thus providing some level of privacy. However, FL's model updates still pose a risk of privacy leakage, which must be mitigated. Over-the-air FL (OTA-FL) is an adapted FL design for wireless edge networks that leverages the natural superposition property of the wireless medium. We propose a wireless physical layer (PHY) design for OTA-FL which improves differential privacy (DP) through a decentralized, dynamic power control that utilizes both inherent Gaussian noise in the wireless channel and a cooperative jammer (CJ) for additional artificial noise generation when higher privacy levels are required. Although primarily implemented within the Upcycled-FL framework, where a resource-efficient method with first-order approximations is used at every even iteration to decrease the required information from clients, our power control strategy is applicable to any FL framework, including FedAvg and FedProx as shown in the paper. This adaptation showcases the flexibility and effectiveness of our design across different learning algorithms while maintaining a strong emphasis on privacy. Our design removes the need for client-side artificial noise injection for DP, utilizing a cooperative jammer to enhance privacy without affecting transmission efficiency for higher privacy demands. Privacy analysis is provided using the Moments Accountant method. We perform a convergence analysis for non-convex objectives to tackle heterogeneous data distributions, highlighting the inherent trade-offs between privacy and accuracy. Numerical results show that our approach with various FL algorithms outperforms the state-of-the-art under the same DP conditions on the non-i.i.d. FEMNIST dataset, and highlight the cooperative jammer's effectiveness in ensuring strict privacy.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Market Consequences of Perceived Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers</title>
<link>https://arxiv.org/abs/2401.12064</link>
<guid>https://arxiv.org/abs/2401.12064</guid>
<content:encoded><![CDATA[
<div> 关键词：Crypto donations, NFT charity fundraisers, Social image, Market outcomes, Online experiment

<br /><br />总结：
本文探讨了非同质化代币（NFT）慈善筹款活动中捐赠者的动机和经济后果，特别是捐赠者从升值的NFT中可能获得的财务收益对社会形象的影响。研究通过利用区块链上交易处理时间的随机变化来识别在慈善筹款活动中购买NFT对捐赠者后续市场结果的因果效应。进一步分析发现，将购得的慈善NFT重新上市出售（显示战略性慷慨行为）的个人以及在NFT市场中有较高社交曝光度的人，在其其他NFT的价格方面会受到显著惩罚。在线实验的结果也证实了这一发现，表明将慈善NFT转售以获利会让他人将其初始捐赠视为具有战略性的慷慨行为，从而降低他人从该捐赠者处购买NFT的意愿。这项研究强调了在加密慈善和更广泛的网络慈善领域中，数字可见性和可追溯性日益重要的影响。 <div>
arXiv:2401.12064v2 Announce Type: replace-cross 
Abstract: Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about donors' motivations in these charity fundraisers, potentially resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of perceived strategic generosity) and based on an individual's social exposure within the NFT marketplace. We show that charity-NFT 're-listers' experience significant penalties in the market regarding the prices they can command for their other NFTs, particularly among those who are more socially exposed. Finally, we report the results of a scenario-based online experiment, which again support our findings, highlighting that the re-listing a charity NFT for sale at a profit leads others to perceive their initial donation as strategic generosity and reduces those others' willingness to purchase NFTs from the donor. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Block MedCare: Advancing healthcare through blockchain integration with AI and IoT</title>
<link>https://arxiv.org/abs/2412.02851</link>
<guid>https://arxiv.org/abs/2412.02851</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、医疗健康、电子病历管理、以太坊、安全性、效率、患者控制、数字签名、角色访问控制、多层架构、去中心化应用、物联网设备、人工智能分析、整合成本、互操作性

<br /><br />总结：
该研究探索了将区块链技术应用于医疗健康领域，尤其是如何通过构建基于以太坊的新型系统来提升电子病历（EHR）管理的安全性和效率。此系统让病人能够安全地掌控自己的医疗数据，同时解决了实施医疗区块链面临的可扩展性、隐私和法规遵从性等挑战。该系统采用了数字签名、基于角色的访问控制以及多层架构，确保对数据的可控和安全访问。研究人员开发了一个面向患者、医生和管理员的用户友好的去中心化应用（dApp），展示了解决方案的实际应用价值。针对医疗保健专业人士和IT专家进行的调查显示，他们对于区块链技术的应用表示强烈兴趣，同时也关注其整合成本问题。此外，研究还探讨了未来与物联网设备和人工智能驱动的分析工具的融合，以期推动更安全、高效、互操作性的医疗系统的进化，从而利用前沿技术为改善患者护理提供支持。 <div>
arXiv:2412.02851v1 Announce Type: new 
Abstract: This research explores the integration of blockchain technology in healthcare, focusing on enhancing the security and efficiency of Electronic Health Record (EHR) management. We propose a novel Ethereum-based system that empowers patients with secure control over their medical data. Our approach addresses key challenges in healthcare blockchain implementation, including scalability, privacy, and regulatory compliance. The system incorporates digital signatures, Role-Based Access Control, and a multi-layered architecture to ensure secure, controlled access. We developed a decentralized application (dApp) with user-friendly interfaces for patients, doctors, and administrators, demonstrating the practical application of our solution. A survey among healthcare professionals and IT experts revealed strong interest in blockchain adoption, while also highlighting concerns about integration costs. The study explores future enhancements, including integration with IoT devices and AI-driven analytics, contributing to the evolution of secure, efficient, and interoperable healthcare systems that leverage cutting-edge technologies for improved patient care.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BGTplanner: Maximizing Training Accuracy for Differentially Private Federated Recommenders via Strategic Privacy Budget Allocation</title>
<link>https://arxiv.org/abs/2412.02934</link>
<guid>https://arxiv.org/abs/2412.02934</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦推荐系统(FR)，差分隐私(DP)，Differentially Private Federated Recommender (DPFR)，预算规划器(BGTplanner)，上下文多臂博弈(CMAB)

总结:<br />
本文针对差分隐私联邦推荐系统(DPFR)存在的噪声失真导致的准确性不足问题，提出了一种名为BGTplanner的新方法，用于战略性的在每轮DPFR训练中分配隐私预算以提升整体训练性能。BGTplanner利用高斯过程回归预测给定隐私预算下推荐精度的变化，并结合历史信息以及上下文多臂博弈(CMAB)进行决策，平衡当前优化与长期隐私约束。实验结果显示，相比于现有最优基线，BGTplanner在真实数据集上平均提高了6.76%的训练性能。 <div>
arXiv:2412.02934v1 Announce Type: new 
Abstract: To mitigate the rising concern about privacy leakage, the federated recommender (FR) paradigm emerges, in which decentralized clients co-train the recommendation model without exposing their raw user-item rating data. The differentially private federated recommender (DPFR) further enhances FR by injecting differentially private (DP) noises into clients. Yet, current DPFRs, suffering from noise distortion, cannot achieve satisfactory accuracy. Various efforts have been dedicated to improving DPFRs by adaptively allocating the privacy budget over the learning process. However, due to the intricate relation between privacy budget allocation and model accuracy, existing works are still far from maximizing DPFR accuracy. To address this challenge, we develop BGTplanner (Budget Planner) to strategically allocate the privacy budget for each round of DPFR training, improving overall training performance. Specifically, we leverage the Gaussian process regression and historical information to predict the change in recommendation accuracy with a certain allocated privacy budget. Additionally, Contextual Multi-Armed Bandit (CMAB) is harnessed to make privacy budget allocation decisions by reconciling the current improvement and long-term privacy constraints. Our extensive experimental results on real datasets demonstrate that \emph{BGTplanner} achieves an average improvement of 6.76\% in training performance compared to state-of-the-art baselines.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Mobile Target Tracking Using Consensus-Based Estimation with Nearly-Constant-Velocity Modeling</title>
<link>https://arxiv.org/abs/2412.03095</link>
<guid>https://arxiv.org/abs/2412.03095</guid>
<content:encoded><![CDATA[
<div> 关键词：移动目标跟踪、分布式追踪框架、一致性估计滤波器（CBEF）、近似常速模型、饱和基过滤技术

总结:
本文提出了一种利用一致性估计滤波器（CBEF）与近似常速模型集成的分布式移动目标跟踪框架。该框架允许网络中的代理节点通过共享局部观测数据并达成共识来共同估计目标位置，即使存在通信约束和测量噪声也能实现这一目标。文中采用饱和基过滤技术增强了系统的鲁棒性，降低了由于传感器数据噪声带来的影响。仿真结果表明，所提出的方案能够随时间有效降低均方估计误差（MSEE），从而提高估计算法的精度和可靠性。这凸显了CBEF在分布式环境中的有效性及其在不确定性条件下的可扩展性和韧性。 <div>
arXiv:2412.03095v1 Announce Type: new 
Abstract: Mobile target tracking is crucial in various applications such as surveillance and autonomous navigation. This study presents a decentralized tracking framework utilizing a Consensus-Based Estimation Filter (CBEF) integrated with the Nearly-Constant-Velocity (NCV) model to predict a moving target's state. The framework facilitates agents in a network to collaboratively estimate the target's position by sharing local observations and achieving consensus despite communication constraints and measurement noise. A saturation-based filtering technique is employed to enhance robustness by mitigating the impact of noisy sensor data. Simulation results demonstrate that the proposed method effectively reduces the Mean Squared Estimation Error (MSEE) over time, indicating improved estimation accuracy and reliability. The findings underscore the effectiveness of the CBEF in decentralized environments, highlighting its scalability and resilience in the presence of uncertainties.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction</title>
<link>https://arxiv.org/abs/2412.03188</link>
<guid>https://arxiv.org/abs/2412.03188</guid>
<content:encoded><![CDATA[
<div> 关键词：智能移动、分布式传感器、时空图神经网络（ST-GNN）、半去中心化训练、云计算节点

总结:<br />
本文针对智能移动领域中大量地理分布传感器产生的高频率时空数据实时处理问题，提出了利用半去中心化的时空图神经网络（ST-GNN）训练技术。文章设计了一个模拟框架，将传感器按地理位置划分为多个云计算节点，每个节点处理交通图的一部分并从其他节点获取节点特征来训练本地ST-GNN模型，同时与其他节点交换模型更新以保持一致性，从而提高可扩展性和容错性。通过对比分析四种不同的ST-GNN训练设置（集中式、传统联邦学习、无服务器联邦学习和Gossip Learning），在大规模交通数据集METR-LA和PeMS-BAY上进行短期、中期和长期车辆速度预测任务的实验，结果显示半去中心化设置在性能指标上与集中式方法相当，但在可扩展性和容错性方面具有优势。此外，文中还指出了现有文献中关于分布式ST-GNNs常常被忽视的问题，如不同地理区域间因特定交通模式导致的模型性能差异以及由GNN大感受野引发的显著通信开销和计算成本，进而造成大量的数据传输和局部嵌入计算增加。 <div>
arXiv:2412.03188v1 Announce Type: new 
Abstract: In smart mobility, large networks of geographically distributed sensors produce vast amounts of high-frequency spatio-temporal data that must be processed in real time to avoid major disruptions. Traditional centralized approaches are increasingly unsuitable to this task, as they struggle to scale with expanding sensor networks, and reliability issues in central components can easily affect the whole deployment. To address these challenges, we explore and adapt semi-decentralized training techniques for Spatio-Temporal Graph Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation framework where sensors are grouped by proximity into multiple cloudlets, each handling a subgraph of the traffic graph, fetching node features from other cloudlets to train its own local ST-GNN model, and exchanging model updates with other cloudlets to ensure consistency, enhancing scalability and removing reliance on a centralized aggregator. We perform extensive comparative evaluation of four different ST-GNN training setups -- centralized, traditional FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed predictions. Experimental results show that semi-decentralized setups are comparable to centralized approaches in performance metrics, while offering advantages in terms of scalability and fault tolerance. In addition, we highlight often overlooked issues in existing literature for distributed ST-GNNs, such as the variation in model performance across different geographical areas due to region-specific traffic patterns, and the significant communication overhead and computational costs that arise from the large receptive field of GNNs, leading to substantial data transfers and increased computation of partial embeddings.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>HCC: A Language-Independent Hardening Contract Compiler for Smart Contracts</title>
<link>https://arxiv.org/abs/2203.00364</link>
<guid>https://arxiv.org/abs/2203.00364</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全智能合约、HCC、源代码级安全检查、代码属性图(CPG)、实用型编译器

总结:
本文提出了一种名为HCC的首个实用型智能合约编译器，旨在自动在源代码层面插入基于新型语言无关代码属性图(CPG)表示的安全强化检查。CPG的高度表达性使HCC能够缓解包括重入攻击、整数错误、自杀式智能合约、不恰当使用tx.origin、不受信任的委托调用以及未检查的低级别调用等最常见的智能合约漏洞。通过对1万个真实世界的智能合约及几组来自相关工作的易受攻击的合约进行大规模评估，结果显示HCC具有高度实用性，优于现有的合约强化技术，并能有效阻止所有验证过的攻击交易，同时并未损害功能正确性。<br /><br /> <div>
arXiv:2203.00364v2 Announce Type: replace 
Abstract: Developing secure smart contracts remains a challenging task. Existing approaches are either impractical or leave the burden to developers for fixing bugs. In this paper, we propose the first practical smart contract compiler, called HCC, which automatically inserts security hardening checks at the source-code level based on a novel and language-independent code property graph (CPG) notation. The high expressiveness of our developed CPG allows us to mitigate all of the most common smart contract vulnerabilities, namely reentrancy, integer bugs, suicidal smart contracts, improper use of tx.origin, untrusted delegate-calls, and unchecked low-level call bugs. Our large-scale evaluation on 10k real-world contracts and several sets of vulnerable contracts from related work demonstrates that HCC is highly practical, outperforms state-of-the-art contract hardening techniques, and effectively prevents all verified attack transactions without hampering functional correctness.
]]></content:encoded>
<pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Development and Application of a Decentralized Domain Name Service</title>
<link>https://arxiv.org/abs/2412.01959</link>
<guid>https://arxiv.org/abs/2412.01959</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Domain Name Service (DDNS)，区块链(Phicoin)，分布式存储(IPFS)，中心化架构，安全稳定性

总结:
<br />
本文提出了一种基于区块链(Phicoin)和分布式存储(IPFS)的去中心化域名服务系统（DDNS），旨在解决现有域名系统(DNS)存在的问题。传统DNS存在中心化架构带来的审查风险、单点故障及解析过程中的加密安全性不足等问题，同时高运营成本限制了中小用户参与与创新。DDNS通过利用区块链的不可篡改性以及IPFS的内容验证特性，实现了域名记录的去中心化存储和分布，消除了对传统DNS的中心化依赖。该系统支持每15秒快速广播一次域名更新，显著提高了解析效率。DDNS的目标是作为现有DNS系统的补充或备份，提供一种抗污染、抗审查、高性能、低成本的域名解析解决方案，为互联网的安全稳定提供了新的技术路径。 <div>
arXiv:2412.01959v1 Announce Type: new 
Abstract: The current Domain Name System (DNS), as a core infrastructure of the internet, exhibits several shortcomings: its centralized architecture leads to censorship risks and single points of failure, making domain name resolution vulnerable to attacks. The lack of encryption in the resolution process exposes it to DNS hijacking and cache poisoning attacks. Additionally, the high operational costs limit participation and innovation among small to medium-sized users. To address these issues, this paper proposes a Decentralized Domain Name Service (DDNS) based on blockchain (Phicoin) and distributed storage (IPFS). By leveraging the immutability of blockchain and the content verification of IPFS, the system achieves decentralized storage and distribution of domain name records, eliminating the centralized dependencies of traditional DNS. With a block time of 15 seconds, the system supports rapid broadcasting of domain name updates, significantly improving resolution efficiency. The DDNS aims to serve as a complement or backup to the existing DNS system, providing a pollution-resistant, censorship-resistant, high-performance, and low-cost domain name resolution solution, offering a new technical path for the security and stability of the internet.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generalized EXTRA stochastic gradient Langevin dynamics</title>
<link>https://arxiv.org/abs/2412.01993</link>
<guid>https://arxiv.org/abs/2412.01993</guid>
<content:encoded><![CDATA[
<div> 关键词：Langevin算法，Markov Chain Monte Carlo，贝叶斯学习，分布式SGLD（DE-SGLD），generalized EXTRA stochastic gradient Langevin dynamics

<br /><br />总结:
该文主要关注在数据分散于网络各节点并受到通信和隐私限制的情况下，如何进行贝叶斯学习的问题。标准的随机梯度Langevin动力学（SGLD）不适用于此场景，因此提出了分布式SGLD（DE-SGLD）算法。然而，现有的DE-SGLD算法在每个节点上存在偏差问题，即使使用完整批次的数据也是如此。为此，文章受EXTRA算法及其优化版本启发，提出了一种广义EXTRA随机梯度Langevin动力学算法，该算法成功消除了在全批次设置下的这一偏差。此外，在迷你批次设置下，新算法还提供了优于现有DE-SGLD算法的性能边界。数值实验进一步证实了所提方法的有效性。 <div>
arXiv:2412.01993v1 Announce Type: new 
Abstract: Langevin algorithms are popular Markov Chain Monte Carlo methods for Bayesian learning, particularly when the aim is to sample from the posterior distribution of a parametric model, given the input data and the prior distribution over the model parameters. Their stochastic versions such as stochastic gradient Langevin dynamics (SGLD) allow iterative learning based on randomly sampled mini-batches of large datasets and are scalable to large datasets. However, when data is decentralized across a network of agents subject to communication and privacy constraints, standard SGLD algorithms cannot be applied. Instead, we employ decentralized SGLD (DE-SGLD) algorithms, where Bayesian learning is performed collaboratively by a network of agents without sharing individual data. Nonetheless, existing DE-SGLD algorithms induce a bias at every agent that can negatively impact performance; this bias persists even when using full batches and is attributable to network effects. Motivated by the EXTRA algorithm and its generalizations for decentralized optimization, we propose the generalized EXTRA stochastic gradient Langevin dynamics, which eliminates this bias in the full-batch setting. Moreover, we show that, in the mini-batch setting, our algorithm provides performance bounds that significantly improve upon those of standard DE-SGLD algorithms in the literature. Our numerical results also demonstrate the efficiency of the proposed approach.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>AVA: Fault-tolerant Reconfigurable Geo-Replication on Heterogeneous Clusters</title>
<link>https://arxiv.org/abs/2412.01999</link>
<guid>https://arxiv.org/abs/2412.01999</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2412.01999v1, 故障容错, 分布式数据库系统, 集群复制协议, AVA

总结:
该论文介绍了arXiv:2412.01999v1中提出的一种新型技术，针对全球金融基础设施构建中能源消耗更低的、容错性强的复制数据库系统。现有的集群复制协议往往假设节点数量恒定且均匀分布，并仅考虑简单故障模型（如停止失败）。论文提出了适用于具有任意故障情况的异构可重构的地理复制协议AVA，允许副本动态加入和离开集群，并形式化证明了协议的安全性和活性。此外，AVA协议共识机制无关，即每个集群可以使用任何本地复制机制。实验结果显示，在谷歌云上进行的地理分布式部署实验表明，无需显著影响交易处理即可重新配置集群成员，而集群的异构性则可能显著提高吞吐量。 <div>
arXiv:2412.01999v1 Announce Type: new 
Abstract: Fault-tolerant replicated database systems consume less energy than the compute-intensive proof-of-work blockchain. Thus, they are promising technologies for the building blocks that assemble global financial infrastructure. To facilitate global scaling, clustered replication protocols are essential in orchestrating nodes into clusters based on proximity. However, the existing approaches often assume a homogeneous and fixed model in which the number of nodes across clusters is the same and fixed, and often limited to a fail-stop fault model. This paper presents heterogeneous and reconfigurable clustered replication for the general environment with arbitrary failures. In particular, we present AVA, a fault-tolerant reconfigurable geo-replication that allows dynamic membership: replicas are allowed to join and leave clusters. We formally state and prove the safety and liveness properties of the protocol. Furthermore, our replication protocol is consensus-agnostic, meaning each cluster can utilize any local replication mechanism. In our comprehensive evaluation, we instantiate our replication with both HotStuff and BFT-SMaRt. Experiments on geo-distributed deployments on Google Cloud demonstrates that members of clusters can be reconfigured without considerably affecting transaction processing, and that heterogeneity of clusters may significantly improve throughput.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Enabled Device-Enhanced Multi-Access Edge Computing in Open Adversarial Environments</title>
<link>https://arxiv.org/abs/2412.02233</link>
<guid>https://arxiv.org/abs/2412.02233</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC), Honeybee框架, 区块链技术, 安全性, 效率

总结:
<br />
本文提出了一个名为Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC)的新框架，该框架基于Honeybee的按需资源池化理念并结合区块链技术，旨在确保不同拥有者的设备之间的信任、安全和可问责性。通过使计算过程可追溯，BdMEC降低了来自恶意设备的风险。原型与实验结果表明，BdMEC能够在多个设备间有效地、安全地管理分布式计算任务。 <div>
arXiv:2412.02233v1 Announce Type: new 
Abstract: We propose Blockchain-enabled Device-enhanced Multi-access Edge Computing (BdMEC). BdMEC extends the Honeybee framework for on-demand resource pooling with blockchain technology to ensure trust, security, and accountability among devices (even when they are owned by different parties). BdMEC mitigates risks from malicious devices by making computations traceable. Our prototype and results demonstrate BdMEC's ability to manage distributed computing tasks efficiently and securely across multiple devices.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence</title>
<link>https://arxiv.org/abs/2412.02263</link>
<guid>https://arxiv.org/abs/2412.02263</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链智能合约、大型语言模型、数据聚合、语义相关性、信任度发现

<br /><br />总结:
本文提出了一个名为{\sysname}的通用框架，旨在解决区块链智能合约与大型语言模型（LLMs）之间集成的难题，克服两者之间的互操作性障碍。通过结合语义相关性和真相发现方法，文章提出了一种创新的数据聚合方法{\funcname}，能显著提升由LLMs生成数据的准确性和可信度。为了验证框架的有效性，研究构建了一个包含三种类型问题的实验数据集，涵盖了10个预言机节点和5个LLM模型的Q&amp;A交互。实验结果显示，即使在40%恶意节点的情况下，该方案相比最优基线仍能平均提高数据准确性17.74%。这项研究不仅为智能合约的智能化增强提供了创新解决方案，还突显了LLMs与区块链技术深度整合的潜力，为未来更智能、更复杂的智能合约应用铺平道路。 <div>
arXiv:2412.02263v1 Announce Type: new 
Abstract: Blockchain smart contracts have catalyzed the development of decentralized applications across various domains, including decentralized finance. However, due to constraints in computational resources and the prevalence of data silos, current smart contracts face significant challenges in fully leveraging the powerful capabilities of Large Language Models (LLMs) for tasks such as intelligent analysis and reasoning. To address this gap, this paper proposes and implements a universal framework for integrating LLMs with blockchain data, {\sysname}, effectively overcoming the interoperability barriers between blockchain and LLMs. By combining semantic relatedness with truth discovery methods, we introduce an innovative data aggregation approach, {\funcname}, which significantly enhances the accuracy and trustworthiness of data generated by LLMs. To validate the framework's effectiveness, we construct a dataset consisting of three types of questions, capturing Q\&amp;A interactions between 10 oracle nodes and 5 LLM models. Experimental results demonstrate that, even with 40\% malicious nodes, the proposed solution improves data accuracy by an average of 17.74\% compared to the optimal baseline. This research not only provides an innovative solution for the intelligent enhancement of smart contracts but also highlights the potential for deep integration between LLMs and blockchain technology, paving the way for more intelligent and complex applications of smart contracts in the future.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learn More by Using Less: Distributed Learning with Energy-Constrained Devices</title>
<link>https://arxiv.org/abs/2412.02289</link>
<guid>https://arxiv.org/abs/2412.02289</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、系统异构性、能源限制、LeanFed、电池寿命

总结:
<br />
本文提出了一种名为LeanFed的能源感知型联邦学习框架，旨在解决参与训练的分布式设备因能源容量差异而带来的实际部署问题。LeanFed通过动态调整每个设备在训练过程中使用的局部数据比例，优化客户端选择和训练工作负载，从而最大化通信轮次中的设备参与度并确保它们不会耗尽电池电量。通过对CIFAR-10和CIFAR-100数据集进行模拟实验，与传统FedAvg方法对比，结果显示LeanFed在具有高度数据异构性和有限电池寿命的情况下，能显著提高模型准确性和稳定性，减少了客户端掉线情况，并延长了设备可用时间。这一方法彰显了能源高效、隐私保护的联邦学习在现实世界大规模应用中的潜力，为资源受限网络上的强大且可持续的人工智能奠定了基础。 <div>
arXiv:2412.02289v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a solution for distributed model training across decentralized, privacy-preserving devices, but the different energy capacities of participating devices (system heterogeneity) constrain real-world implementations. These energy limitations not only reduce model accuracy but also increase dropout rates, impacting on convergence in practical FL deployments. In this work, we propose LeanFed, an energy-aware FL framework designed to optimize client selection and training workloads on battery-constrained devices. LeanFed leverages adaptive data usage by dynamically adjusting the fraction of local data each device utilizes during training, thereby maximizing device participation across communication rounds while ensuring they do not run out of battery during the process. We rigorously evaluate LeanFed against traditional FedAvg on CIFAR-10 and CIFAR-100 datasets, simulating various levels of data heterogeneity and device participation rates. Results show that LeanFed consistently enhances model accuracy and stability, particularly in settings with high data heterogeneity and limited battery life, by mitigating client dropout and extending device availability. This approach demonstrates the potential of energy-efficient, privacy-preserving FL in real-world, large-scale applications, setting a foundation for robust and sustainable pervasive AI on resource-constrained networks.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bio-inspired visual relative localization for large swarms of UAVs</title>
<link>https://arxiv.org/abs/2412.02393</link>
<guid>https://arxiv.org/abs/2412.02393</guid>
<content:encoded><![CDATA[
<div> 关键词: visual perception, relative localization, UAVs, swarm control, neighbor density regression

总结:<br />
本文提出了一种新的用于无人机群体大规模相对定位的视觉感知方法。该方法受到生物感知机制的启发，如沙丁鱼群和蜜蜂群等动物群体能以分散但协调的方式移动，不再依赖于每个个体对邻居的位置估计，而是通过回归距离上的邻居密度来实现相对定位，从而提高了距离估算的准确性并提升了对邻数量级变化的可扩展性。此外，文章还提出了一种与新定位方法相兼容的新型群体控制算法。通过对所提方法的详尽评估，结果表明，基于回归的距离估计方法对于目标相对姿态变化更具鲁棒性，并且适合作为群体稳定控制的主要相对定位来源。 <div>
arXiv:2412.02393v1 Announce Type: new 
Abstract: We propose a new approach to visual perception for relative localization of agents within large-scale swarms of UAVs. Inspired by biological perception utilized by schools of sardines, swarms of bees, and other large groups of animals capable of moving in a decentralized yet coherent manner, our method does not rely on detecting individual neighbors by each agent and estimating their relative position, but rather we propose to regress a neighbor density over distance. This allows for a more accurate distance estimation as well as better scalability with respect to the number of neighbors. Additionally, a novel swarm control algorithm is proposed to make it compatible with the new relative localization method. We provide a thorough evaluation of the presented methods and demonstrate that the regressing approach to distance estimation is more robust to varying relative pose of the targets and that it is suitable to be used as the main source of relative localization for swarm stabilization.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Ensemble-Based Semi-Supervised Learning for Illicit Account Detection in Ethereum DeFi Transactions</title>
<link>https://arxiv.org/abs/2412.02408</link>
<guid>https://arxiv.org/abs/2412.02408</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), Ethereum区块链, 自动学习, 非法账户检测, SLEID框架

<br /><br />总结:

本文提出了一个名为Self-Learning Ensemble-based Illicit account Detection (SLEID)的新型框架，用于解决以太坊区块链上去中心化金融(DeFi)领域日益严重的安全风险问题，特别是非法账户欺诈行为。SLEID框架采用Isolation Forest进行初步异常检测，并利用自训练机制生成未标注账户的伪标签，从而提高检测准确性。通过大量实验，SLEID展示出了比传统监督方法和近期半监督模型更高的精确度、召回率和F1分数，尤其在识别非法账户方面表现出色。相较于现有最先进的方法，SLEID在降低对标注数据依赖的同时，实现了更好的检测性能，为保护DeFi生态系统及防范恶意账户带来的风险提供了有力保障。 <div>
arXiv:2412.02408v1 Announce Type: new 
Abstract: The advent of smart contracts has enabled the rapid rise of Decentralized Finance (DeFi) on the Ethereum blockchain, offering substantial rewards in financial innovation and inclusivity. However, this growth has also introduced significant security risks, including the proliferation of illicit accounts involved in fraudulent activities. Traditional detection methods are limited by the scarcity of labeled data and the evolving tactics of malicious actors. In this paper, we propose a novel Self-Learning Ensemble-based Illicit account Detection (SLEID) framework to address these challenges. SLEID employs an Isolation Forest for initial outlier detection and a self-training mechanism to iteratively generate pseudo-labels for unlabeled accounts, thereby enhancing detection accuracy. Extensive experiments demonstrate that SLEID significantly outperforms traditional supervised approaches and recent semi-supervised models, achieving superior precision, recall, and F1-scores, particularly in detecting illicit accounts. Compared to state-of-the-art methods, our approach achieves better detection performance while reducing reliance on labeled data. The results affirm SLEID's efficacy as a robust solution for safeguarding the DeFi ecosystem and mitigating risks posed by malicious accounts.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Defending Against Diverse Attacks in Federated Learning Through Consensus-Based Bi-Level Optimization</title>
<link>https://arxiv.org/abs/2412.02535</link>
<guid>https://arxiv.org/abs/2412.02535</guid>
<content:encoded><![CDATA[
<div> 关键词：adversarial attacks、federated learning、bi-level optimization、CB$^2$O、FedCB$^2$O

总结:
针对机器学习中对抗性攻击带来的挑战，特别是分布式训练和联邦学习中的问题，本文提出了一种将训练任务建模为双层优化问题的方法。文章对共识型双层优化（CB$^2$O）方法在有恶意代理的对抗性环境下的鲁棒性进行了理论分析，证明了CB$^2$O在均场定律下在全球收敛性方面的优势，揭示了其对于各种攻击的抵抗能力，并阐述了如何通过选择特定的超参数来减轻对抗性影响。从实践层面出发，本文将CB$^2$O扩展到聚类联邦学习场景，提出了新型的交互多粒子系统——FedCB$^2$O，并设计了一个适用于实际应用的算法。实验结果表明，FedCB$^2$O算法在去中心化聚类联邦学习场景下对于标签翻转攻击具有较强的鲁棒性，显示出了其实战的有效性。 <div>
arXiv:2412.02535v1 Announce Type: new 
Abstract: Adversarial attacks pose significant challenges in many machine learning applications, particularly in the setting of distributed training and federated learning, where malicious agents seek to corrupt the training process with the goal of jeopardizing and compromising the performance and reliability of the final models. In this paper, we address the problem of robust federated learning in the presence of such attacks by formulating the training task as a bi-level optimization problem. We conduct a theoretical analysis of the resilience of consensus-based bi-level optimization (CB$^2$O), an interacting multi-particle metaheuristic optimization method, in adversarial settings. Specifically, we provide a global convergence analysis of CB$^2$O in mean-field law in the presence of malicious agents, demonstrating the robustness of CB$^2$O against a diverse range of attacks. Thereby, we offer insights into how specific hyperparameter choices enable to mitigate adversarial effects. On the practical side, we extend CB$^2$O to the clustered federated learning setting by proposing FedCB$^2$O, a novel interacting multi-particle system, and design a practical algorithm that addresses the demands of real-world applications. Extensive experiments demonstrate the robustness of the FedCB$^2$O algorithm against label-flipping attacks in decentralized clustered federated learning scenarios, showcasing its effectiveness in practical contexts.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Reliability Estimation for Low Latency Mixnets</title>
<link>https://arxiv.org/abs/2406.06760</link>
<guid>https://arxiv.org/abs/2406.06760</guid>
<content:encoded><![CDATA[
<div> 关键词: mixnet、匿名路由、低延迟、可验证性、可靠性评分

总结:
<br />
本文提出了一种新的方案，旨在解决大规模低延迟混合网络（mixnet）与强可验证性和可靠性之间的挑战。现有的可验证性机制会引入显著的延迟开销，限制了mixnet的应用范围。该方案能够以几乎最优的时间复杂度，在去中心化的环境中估算mixnet中链接和节点的可靠性评分，且此过程独立于通过mixnet路由的总流量。它依赖于客户端凭证和基于VRF的路由新原语，确保合法客户端数据包遵循mixnet的路由策略，并随机生成不可伪造的测量数据包。实验结果在不可靠和对抗性环境下验证了该构造的可行性，证明了其可以实现在不影响客户端数据包传输延迟或产生显著带宽开销的情况下进行可靠性的估计。 <div>
arXiv:2406.06760v2 Announce Type: replace 
Abstract: While there exist mixnets that can anonymously route large amounts of data packets with end to end latency that can be as low as a second, %making them attractive for a variety of applications, combining this level of performance with strong verifiability and reliability properties that ensure the correct processing and delivery of packets has proved challenging. Indeed, existing verifiability mechanisms are incompatible with scalable low-latency operation due to imposing significant latency overheads measuring in minutes to hours, hence severely limiting the variety of applications mixnets can serve. We address this important gap by proposing a scheme that can estimate reliability scores for a mixnet's links and nodes in a decentralized manner with essentially optimal complexity that is independent of the total traffic routed through the mixnet. The scores can be computed publicly by all participants from a set of measurement packets that are eventually revealed and act as a random sample of the traffic, without affecting mixnet transmission latency for client packets or incurring significant bandwidth overhead. Our scheme assumes client credentials and relies on VRF-based routing, a novel primitive that ensures that legitimate client packets follow the routing policy of the mixnet, as well as randomly generating unforgeable measurement packets. We experimentally validate our construction both in unreliable and adversarial settings, demonstrating its feasibility.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Relaxing Trust Assumptions on Quantum Key Distribution Networks</title>
<link>https://arxiv.org/abs/2402.13136</link>
<guid>https://arxiv.org/abs/2402.13136</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、长距离、不信任中继器、QKD网络、信任级别

总结:
本文探讨了在量子通信网络中如何在对中继器的信任程度降低的情况下实现安全的秘密接力。文章提出了三种不同的QKD中继器信任级别：完全访问信任（FAT）、部分访问信任（PAT）和无访问信任（NAT），定义了中继器处理秘密信息的不同权限。针对不同信任级别，文中回顾并提出多种基于QKD的密钥管理系统构建方案，特别是在无访问信任级别的密钥管理系统的评估上，重点讨论了集中式与新型去中心化的密钥管理系统架构。这些不同架构为QKD网络的需求提供了灵活性，为未来长距离安全通信提供了一种更可靠且实用的解决方案思路。 <div>
arXiv:2402.13136v2 Announce Type: replace-cross 
Abstract: Quantum security over long distances with untrusted relays is largely unfounded and is still an open question for active research. Nevertheless, quantum networks based on trusted relays are being built across the globe. However, standard QKD network architecture implores a complete trust requirement on QKD relays, which is too demanding and limits the use cases for QKD networks. In this work, we explore the possibility to securely relay a secret in a QKD network by relaxing the trust assumptions (if not completely) on the relay. We characterize QKD relays with different trust levels, namely, Full Access Trust (FAT), Partial Access Trust (PAT), and No Access Trust (NAT). As the name suggests, each level defines the degree with which a relay is required to be trusted with the secret provided by the key management system for end-to-end communication. We then review and propose multiple constructions of the QKD key management system based on the different trust levels. Main contribution of the paper is realized by evaluating key management systems with no access trust level. In principle, we review key management with centralized topology and propose a new decentralized key management system. These different topologies provide various advantages based on the QKD network requirements, allowing an operational flexibility in the architecture. We believe this work presents a new perspective to the open problem of providing a confiding and a practical solution for future long range secure communications
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeTEcT: Dynamic and Probabilistic Parameters Extension</title>
<link>https://arxiv.org/abs/2405.16688</link>
<guid>https://arxiv.org/abs/2405.16688</guid>
<content:encoded><![CDATA[
<div> 关键词：DeTEcT框架、财富分布、参数化、动态货币供应、模拟经济活动

总结:
本文扩展了Sadykhov等人提出的DeTEcT框架，该框架用于建模代币经济中的财富分配和宏观经济场景模拟。文章提出了四种对DeTEcT框架进行参数化的方法，包括动态与静态以及概率性与非概率性的区分。通过这些参数化技术，研究者展示了如何限制框架以从DeTEcT中推导出现有的财富分布模型。此外，论文还探讨了使DeTEcT框架中的货币供应变得动态化的可能性及其对财富分布动态的影响，其目的在于使DeTEcT能够应用于没有最大供应量（如Ethereum）的代币经济模型，并为框架增加了约束形式的对称性。 <div>
arXiv:2405.16688v2 Announce Type: replace-cross 
Abstract: This paper presents a theoretical extension of the DeTEcT framework proposed by Sadykhov et al., DeTEcT, where a formal analysis framework was introduced for modelling wealth distribution in token economies. DeTEcT is a framework for analysing economic activity, simulating macroeconomic scenarios, and algorithmically setting policies in token economies. This paper proposes four ways of parametrizing the framework, where dynamic vs static parametrization is considered along with the probabilistic vs non-probabilistic. Using these parametrization techniques, we demonstrate that by adding restrictions to the framework it is possible to derive the existing wealth distribution models from DeTEcT. In addition to exploring parametrization techniques, this paper studies how money supply in DeTEcT framework can be transformed to become dynamic, and how this change will affect the dynamics of wealth distribution. The motivation for studying dynamic money supply is that it enables DeTEcT to be applied to modelling token economies without maximum supply (i.e., Ethereum), and it adds constraints to the framework in the form of symmetries.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Supercomputing Based Distributed Cloud Marketplace</title>
<link>https://arxiv.org/abs/2412.00016</link>
<guid>https://arxiv.org/abs/2412.00016</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、51%攻击、可扩展性、LuluChain、超级计算机速度

总结:<br />
本文提出了一个新的区块链技术——LuluChain，它旨在解决当前区块链面临的51%攻击威胁和可扩展性问题。现有的区块链系统在处理能力上不及集中式系统，这使得51%攻击成为可能。LuluChain致力于提供一种无限可扩展、安全且高吞吐量的解决方案，能实现接近超级计算机速度的性能，仅使用商业现成硬件。该系统简化了区块链模型，提高了功能、速度、可扩展性、隐私和灵活性，并能对抗云计算市场的寡头垄断定价模式，因为它对计算工作负载的需求极低。通过消除时间戳同步和所有参与者之间的多数同意需求，LuluChain开启了可靠信任、低成本即时交易和灵活即时智能合约的新可能。作为一个基于高性能分布式系统的分布式云市场基础，LuluChain被视为一种理想方案。 <div>
arXiv:2412.00016v1 Announce Type: new 
Abstract: The once mythological 51% attack has moved beyond the hypothetical and now poses a legitimate widespread threat to blockchain technology. Current blockchains provide inferior throughput capacity when compared to that of centralized systems, creating an obvious vulnerability which allows the 51% attack to occur within decentralized systems. Despite recent advancements in blockchain which introduce interesting models that achieve high throughputs with enhanced security and privacy, no current networks have evolved to deploy the optimal solution of combining scalability, security, and distributed systems to create a legitimate supercomputing enterprise-grade developer sandbox. In this paper, we introduce an infinitely scalable, secure, and high throughput blockchain capable of amassing supercomputer speeds with off-the-shelf hardware, LuluChain. LuluChain simplifies the blockchain model to obtain greater functionality, speed, scalability, privacy, and flexibility, that works to combat the inflated pricing models set by the oligopolistic cloud computing market as it requires minimal computational work. By eliminating the need for timestamp synchronization and majority agreement among all participants, LuluChain opens the door to reliable trust, low-cost instant transactions, and flexible instant smart contracts. The supercomputing, high throughput distributed system is the ideal foundation for an essential distributed cloud marketplace.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Collaboration in Incident Response with Large Language Models</title>
<link>https://arxiv.org/abs/2412.00652</link>
<guid>https://arxiv.org/abs/2412.00652</guid>
<content:encoded><![CDATA[
<div> 关键词：incident response，large language models，multi-agent collaboration，Backdoors & Breaches框架，cybersecurity training

<br /><br />总结:
本文探讨了利用大型语言模型（LLMs）作为智能代理来提升网络安全中事件响应（IR）协作效率和效果的新方法。研究通过在Backdoors & Breaches框架下模拟真实的IR场景，采用了集中式、分布式和混合型等多种团队结构进行实验。通过对不同配置下的代理人交互与性能分析，文章揭示了LLMs在优化多代理协作、增强决策制定、提高适应性和流程整合以更有效地应对网络威胁方面的潜力。 <div>
arXiv:2412.00652v1 Announce Type: new 
Abstract: Incident response (IR) is a critical aspect of cybersecurity, requiring rapid decision-making and coordinated efforts to address cyberattacks effectively. Leveraging large language models (LLMs) as intelligent agents offers a novel approach to enhancing collaboration and efficiency in IR scenarios. This paper explores the application of LLM-based multi-agent collaboration using the Backdoors & Breaches framework, a tabletop game designed for cybersecurity training. We simulate real-world IR dynamics through various team structures, including centralized, decentralized, and hybrid configurations. By analyzing agent interactions and performance across these setups, we provide insights into optimizing multi-agent collaboration for incident response. Our findings highlight the potential of LLMs to enhance decision-making, improve adaptability, and streamline IR processes, paving the way for more effective and coordinated responses to cyber threats.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.00661</link>
<guid>https://arxiv.org/abs/2412.00661</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、子采样、均值场Q学习（MFQ）、多项式时间、收敛性

总结:
本文提出了一种名为“SUBSAMPLE-MFQ”的新算法，用于解决多智能体强化学习中的挑战，特别是应对由于智能体数量增加导致的联合状态和动作空间指数级增长的问题。该算法结合了子采样技术和均值场Q学习，设计了一个针对$n$个智能体系统的去中心化随机策略。SUBSAMPLE-MFQ能够在时间复杂度为$k$的多项式时间内学习到系统策略，并随着子采样的智能体数量$k$增加，其收敛至最优策略的阶数为$\tilde{O}(1/\sqrt{k})$。实验部分验证了该方法在高斯挤压和全局探索等场景的有效性。 <div>
arXiv:2412.00661v1 Announce Type: new 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging due to the fact that the size of the joint state and action spaces are exponentially large in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm \texttt{SUBSAMPLE-MFQ} (\textbf{Subsample}-\textbf{M}ean-\textbf{F}ield-\textbf{Q}-learning) and a decentralized randomized policy for a system with $n$ agents. For $k\leq n$, our algorithm system learns a policy for the system in time polynomial in $k$. We show that this learned policy converges to the optimal policy in the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. We validate our method empirically on Gaussian squeeze and global exploration settings.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChainGuard: A Blockchain-based Authentication and Access Control Scheme for Distributed Networks</title>
<link>https://arxiv.org/abs/2412.00677</link>
<guid>https://arxiv.org/abs/2412.00677</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、去中心化认证、访问控制、ChainGuard、智能合约

<br /><br />总结:
本文提出了一个名为ChainGuard的新型方案，旨在解决如何在分布式网络中实现去中心化的身份认证和访问控制问题。ChainGuard利用区块链技术动态管理用户角色和权限，无需中央服务器，从而消除了传统集中式系统的瓶颈。该机制同时支持跨多个组织的用户交互，提升了安全性、效率和透明度。通过解决可扩展性、安全性和透明度等关键挑战，ChainGuard不仅弥合了传统集中式系统与区块链去中心化理念之间的鸿沟，还进一步加强了数据保护和操作效率。 <div>
arXiv:2412.00677v1 Announce Type: new 
Abstract: As blockchain technology gains traction for enhancing data security and operational efficiency, traditional centralized authentication systems remain a significant bottleneck. This paper addresses the challenge of integrating decentralized authentication and access control within distributed networks. We propose a novel solution named ChainGuard, a fully decentralized authentication and access control mechanism based on smart contracts. ChainGuard eliminates the need for a central server by leveraging blockchain technology to manage user roles and permissions dynamically. Our scheme supports user interactions across multiple organizations simultaneously, enhancing security, efficiency, and transparency. By addressing key challenges such as scalability, security, and transparency, ChainGuard not only bridges the gap between traditional centralized systems and blockchain's decentralized ethos but also enhances data protection and operational efficiency.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SEAM: A Secure Automated and Maintainable Smart Contract Upgrade Framework</title>
<link>https://arxiv.org/abs/2412.00680</link>
<guid>https://arxiv.org/abs/2412.00680</guid>
<content:encoded><![CDATA[
<div> 关键词: smart contracts, upgrading, SEAM, diamond pattern, security

总结:<br />
本文提出了一种名为SEAM的新颖框架，用于解决智能合约升级这一关键挑战。SEAM通过使用钻石模式自动化将标准Solidity合约转换为可升级版本，简化了升级流程并解决了函数选择器冲突和存储槽碰撞两个主要安全漏洞问题。此外，该框架还提供了用于高效部署、修改和管理智能合约生命周期的工具。通过增强合同安全性并降低开发者的学习曲线，SEAM为构建更灵活和可维护的区块链应用奠定了坚实基础。 <div>
arXiv:2412.00680v1 Announce Type: new 
Abstract: This work addresses the critical challenges of upgrading smart contracts, which are vital for trust in automated transactions but difficult to modify once deployed. To address this issue, we propose SEAM, a novel framework that automates the conversion of standard Solidity contracts into upgradable versions using the diamond pattern. SEAM simplifies the upgrade process and addresses two key vulnerabilities: function selector clashes and storage slot collisions. Additionally, the framework provides tools for efficiently deploying, modifying, and managing smart contract lifecycles. By enhancing contract security and reducing the learning curve for developers, SEAM lays a robust foundation for more flexible and maintainable blockchain applications.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Proof-of-Work: A Secure Dynamic Approach to Fair and Efficient Blockchain Mining</title>
<link>https://arxiv.org/abs/2412.00690</link>
<guid>https://arxiv.org/abs/2412.00690</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof-of-Work (PoW), 能耗, 中心化, Collaborative Proof-of-Work (CPoW), 动态挖矿池形成协议

总结:<br />
本文针对Proof-of-Work (PoW)系统存在的能耗过高、挖矿权力中心化等问题，以及静态挖矿池对区块链去中心化特性与公平性的削弱，提出了一个新的Collaborative Proof-of-Work (CPoW)挖矿方法。该方法致力于提升以太坊网络的效率和公平性，具体表现为设计了一种动态挖矿池形成协议，使矿工能够根据计算能力进行协作，并通过精准验证和分配奖励的机制保障了奖励分配的安全与公正。这一研究通过解决传统挖矿的中心化和能源效率问题，为构建更加可持续的区块链生态系统做出了贡献。 <div>
arXiv:2412.00690v1 Announce Type: new 
Abstract: Proof-of-Work (PoW) systems face critical challenges, including excessive energy consumption and the centralization of mining power among entities with expensive hardware. Static mining pools exacerbate these issues by reducing competition and undermining the decentralized nature of blockchain networks, leading to economic inequality and inefficiencies in resource allocation. Their reliance on centralized pool managers further introduces vulnerabilities by creating a system that fails to ensure secure and fair reward distribution. This paper introduces a novel Collaborative Proof-of-Work (CPoW) mining approach designed to enhance efficiency and fairness in the Ethereum network. We propose a dynamic mining pool formation protocol that enables miners to collaborate based on their computational capabilities, ensuring fair and secure reward distribution by incorporating mechanisms to accurately verify and allocate rewards. By addressing the centralization and energy inefficiencies of traditional mining, this research contributes to a more sustainable blockchain ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Forking Way: When TEEs Meet Consensus</title>
<link>https://arxiv.org/abs/2412.00706</link>
<guid>https://arxiv.org/abs/2412.00706</guid>
<content:encoded><![CDATA[
<div> 关键词：Trusted Execution Environments (TEE), 区块链, 分布式平台, 叉攻击, 安全性分析

总结:
本文针对越来越多的分布式平台结合可信执行环境(TEE)和区块链的情况进行了系统研究，强调了这一组合被认为是保障区块链机密计算与防御叉攻击的良好方式。通过对29项TEE基区块链方案的深入分析，发现社区中对于如何整合TEE和区块链缺乏共识，并归纳出四种主要的互联手段及其局限性。此外，文章还揭示了三个生产就绪的TEE基区块链——Ten、Phala和Secret Network中存在的此前未被记录的叉攻击漏洞，并对这些漏洞提出了有效的应对措施。已将研究成果负责任地披露给相关平台的开发者。 <div>
arXiv:2412.00706v1 Announce Type: new 
Abstract: An increasing number of distributed platforms combine Trusted Execution Environments (TEEs) with blockchains. Indeed, many hail the combination of TEEs and blockchains a good "marriage": TEEs bring confidential computing to the blockchain while the consensus layer could help defend TEEs from forking attacks.
  In this paper, we systemize how current blockchain solutions integrate TEEs and to what extent they are secure against forking attacks. To do so, we thoroughly analyze 29 proposals for TEE-based blockchains, ranging from academic proposals to production-ready platforms. We uncover a lack of consensus in the community on how to combine TEEs and blockchains. In particular, we identify four broad means to interconnect TEEs with consensus, analyze their limitations, and discuss possible remedies. Our analysis also reveals previously undocumented forking attacks on three production-ready TEE-based blockchains: Ten, Phala, and the Secret Network. We leverage our analysis to propose effective countermeasures against those vulnerabilities; we responsibly disclosed our findings to the developers of each affected platform.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EnFed: An Energy-aware Opportunistic Federated Learning in Resource Constrained Environments for Human Activity Recognition</title>
<link>https://arxiv.org/abs/2412.00768</link>
<guid>https://arxiv.org/abs/2412.00768</guid>
<content:encoded><![CDATA[
<div> 关键词：能源效率、联邦学习、人类活动监测、模型更新、预测准确性

总结:<br />
本文提出了一种能源高效的联邦学习方法及其在人体活动监测与识别中的应用。该方法中，需要模型的应用设备请求其附近设备进行协作，同意请求的附近设备将模型更新发送至请求设备。请求设备接收到模型更新后进行聚合以构建自身模型。鉴于移动设备电池寿命有限，参与轮数依据所需精度水平和请求设备的电池电量来决定。实验结果表明，相比于分布式联邦学习方法，当使用LSTM作为底层数据分析模型时，该提议的方法能分别降低第一和第二数据集约59%和19%的训练时间和约19%的训练能量消耗；而使用MLP作为底层数据分析模型时，可分别减少约55%和72%的训练时间和训练能量消耗，同时保持了良好的预测准确性。 <div>
arXiv:2412.00768v1 Announce Type: new 
Abstract: This paper proposes an energy-efficient federated learning method and its application in human activity monitoring and recognition. In the proposed approach, the device that needs a model for an application requests its nearby devices for collaboration. The nearby devices that accept the request, send their model updates to the requesting device. The device receives the model updates from the collaborators and performs aggregation to build its model. As mobile devices have limited battery life, the number of rounds is decided based on the desired accuracy level and battery level of the requesting device. The performance of the proposed approach is evaluated with respect to prediction accuracy, training time, training energy consumption of the device, and response time. We have used two different datasets for performance evaluation. The first dataset contains different types of physical activities and the respective calorie burn. The second dataset is a human activity recognition dataset that considers six types of physical activities. The experimental results show that using the proposed method the training time and training energy consumption of the device are reduced by approximately 59% and 19% for the first and second datasets respectively, than the decentralized federated learning approach, while using LSTM as the underlying data analysis model. The results also present that the proposed method reduces the training time and energy consumption by approximately 55% and 72% for the first and second datasets respectively, than the decentralized federated learning approach while using MLP as the underlying data analysis model.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Post-Vaccination COVID-19 Data Analysis: Privacy and Ethics</title>
<link>https://arxiv.org/abs/2412.00774</link>
<guid>https://arxiv.org/abs/2412.00774</guid>
<content:encoded><![CDATA[
<div> 关键词：COVID-19疫苗、区块链、个人隐私、不可变性、授权访问

总结:
<p>
该论文针对COVID-19疫苗接种过程中出现的公民隐私保护和个人数据滥用问题，提出了一种基于区块链的应用方案。此系统利用IEEE 2418.2TM-2020标准构建数据模型，旨在确保公民个人信息匿名性、疫苗接种数据的不可变性以及对抗性实体（如政府）对数据进行有限制且便捷的验证与分析。该系统在以太坊区块链上实现，并通过Python API模拟和验证疫苗接种过程中的每一步骤，从而在保障公民隐私的同时实现系统的可问责性。</p> <div>
arXiv:2412.00774v1 Announce Type: new 
Abstract: The COVID-19 pandemic has severely affected the world in terms of health, economy and peace. Fortunately, the countries are trying to overcome the situation by actively carrying out vaccinations. However, like any other massive operation involving humans such as human resource management, elections, surveys, etc., the vaccination process raises several questions about citizen privacy and misuse of personal data. In most of the countries, few attempts have been made to verify the vaccination statistics as reported by the health centers. These issues collectively require the solutions of anonymity of citizens' personal information, immutability of vaccination data and easy yet restricted access by adversarial bodies such as the government for the verification and analysis of the data. This paper introduces a blockchain-based application to simulate and monitor the vaccination process. The structure of data model used in the proposed system is based on the IEEE Standard for Data Format for Blockchain Systems 2418.2TM-2020. The proposed system enables authorized stakeholders to share and access relevant information for vaccination process chain while preserving citizen privacy and accountability of the system. It is implemented on the Ethereum blockchain and uses a Python API for the simulation and validation of each step of the vaccination process.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provable Partially Observable Reinforcement Learning with Privileged Information</title>
<link>https://arxiv.org/abs/2412.00985</link>
<guid>https://arxiv.org/abs/2412.00985</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、部分可观测性、特权信息、专家蒸馏、不对称actor-critic<br /><br />总结:
本文研究了在部分可观测环境下强化学习中利用特权信息的挑战与优势。首先，文章形式化了实践中的“专家蒸馏”（教师-学生学习）范式，并指出了其在寻找近似最优策略时的局限性。接着，提出了一种环境条件——确定性滤波条件，在此条件下，专家蒸馏可以实现样本和计算复杂度均为多项式级的效率。随后，探讨了另一种实用范式——不对称actor-critic，并针对可观察部分可观测马尔科夫决策过程设计了一个信念加权的不对称actor-critic算法，该算法具有多项式级样本复杂度和拟多项式级计算复杂度。其中，还包括了一个新的可证明的关于学习保持滤波稳定性的信念状态的Oracle。最后，文中还研究了在特权信息支持下的部分可观测多智能体强化学习的可证明效率，提出了基于集中训练与分布式执行框架的算法，这些算法在上述两种范式下都具有多项式级样本复杂度和（拟）多项式级计算复杂度。相比于近期相关理论研究，本文更注重于理解实践中启发式的算法范式，而不依赖于计算上不可行的Oracle。 <div>
arXiv:2412.00985v1 Announce Type: new 
Abstract: Partial observability of the underlying states generally presents significant challenges for reinforcement learning (RL). In practice, certain \emph{privileged information}, e.g., the access to states from simulators, has been exploited in training and has achieved prominent empirical successes. To better understand the benefits of privileged information, we revisit and examine several simple and practically used paradigms in this setting. Specifically, we first formalize the empirical paradigm of \emph{expert distillation} (also known as \emph{teacher-student} learning), demonstrating its pitfall in finding near-optimal policies. We then identify a condition of the partially observable environment, the \emph{deterministic filter condition}, under which expert distillation achieves sample and computational complexities that are \emph{both} polynomial. Furthermore, we investigate another useful empirical paradigm of \emph{asymmetric actor-critic}, and focus on the more challenging setting of observable partially observable Markov decision processes. We develop a belief-weighted asymmetric actor-critic algorithm with polynomial sample and quasi-polynomial computational complexities, in which one key component is a new provable oracle for learning belief states that preserve \emph{filter stability} under a misspecified model, which may be of independent interest. Finally, we also investigate the provable efficiency of partially observable multi-agent RL (MARL) with privileged information. We develop algorithms featuring \emph{centralized-training-with-decentralized-execution}, a popular framework in empirical MARL, with polynomial sample and (quasi-)polynomial computational complexities in both paradigms above. Compared with a few recent related theoretical studies, our focus is on understanding practically inspired algorithmic paradigms, without computationally intractable oracles.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair</title>
<link>https://arxiv.org/abs/2412.01072</link>
<guid>https://arxiv.org/abs/2412.01072</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件系统、大型语言模型、自动化程序修复、联邦学习、数据隐私

总结:<br />
本文探讨了随着软件系统快速演进导致的bug增加以及大型语言模型（LLMs）在自动化程序修复（APR）中的应用潜力。然而，现有的公共代码库无法充分反映各行业实际开发实践中的多样性和细节，因此利用私有数据集能有效提升软件开发和维护水平。为解决数据隐私问题，文章研究了联邦学习作为一种保护隐私的方法，允许私有实体在分散且保密的数据上对LLMs进行微调，促进各方协作以充分利用数据资源。实验表明，联邦学习下的微调能够提升程序修复能力，而且不同来源的代码数据对LLM微调的影响不大，意味着各行各业可以无视数据分布差异，从协同开发中获益。此外，各类联邦算法在不同的LLMs优化过程中展现出独特优势，提示我们可以通过针对LLMs特性的定制化优化来进一步增强程序修复的微调效果。 <div>
arXiv:2412.01072v1 Announce Type: new 
Abstract: Software systems have been evolving rapidly and inevitably introducing bugs at an increasing rate, leading to significant losses in resources consumed by software maintenance. Recently, large language models (LLMs) have demonstrated remarkable potential in enhancing software development and maintenance practices, particularly in automated program repair (APR) with improved accuracy and efficiency of bug fixing. However, LLM-based APR heavily relies on high-quality code repositories. A larger portion of existing code repositories are for private use and proprietary assets from various industries, reflecting more diversity and nuances in the data since real-world industries often have more extensive software development practices, which cannot be covered by merely public datasets. Therefore, utilizing private datasets shows significant potential in enhancing software development and maintenance. However, obtaining such data from various industries is hindered by data privacy concerns, as companies are reluctant to share their codebases. To address the gap, we investigate the use of federated learning as a privacy-preserving approach that enables private entities to fine-tune LLMs on proprietary and decentralized data, facilitating the collaboration between clients to fully utilize their data to help enhance software development and maintenance. Our evaluation reveals that federated fine-tuning can effectively enhance program repair capabilities. Notably, the impact of heterogeneous code on LLM fine-tuning is negligible, indicating that real-world industries can benefit from collaborative development regardless of diverse data distributions. Furthermore, each type of federated algorithm exhibits unique strengths across different LLMs, suggesting that fine-tuning for program repair can be enhanced by tailoring the optimization process to specific characteristics of different LLMs.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hierarchical Heuristic for Clustered Steiner Trees in the Plane with Obstacles</title>
<link>https://arxiv.org/abs/2412.01094</link>
<guid>https://arxiv.org/abs/2412.01094</guid>
<content:encoded><![CDATA[
<div> 关键词：Euclidean Steiner树、多根、障碍避免、层次方法、捆绑操作

总结:
本文研究了一种嵌入捆绑操作的层次方法用于计算多个互不相交的欧几里得Steiner树，这些树能够避开平面上的障碍物，这对于建模受限二维空间中去中心化和多点协调的智能体具有重要意义。实验表明，该方法对于计算具有任意障碍配置（包括凸形和非凸形几何形状）的多个避障Steiner树具有可行性及优良性能。本研究结果为避障Steiner树的新运算器设计提供了机制启示。 <div>
arXiv:2412.01094v1 Announce Type: new 
Abstract: Euclidean Steiner trees are relevant to model minimal networks in real-world applications ubiquitously. In this paper, we study the feasibility of a hierarchical approach embedded with bundling operations to compute multiple and mutually disjoint Euclidean Steiner trees that avoid clutter and overlapping with obstacles in the plane, which is significant to model the decentralized and the multipoint coordination of agents in constrained 2D domains. Our computational experiments using arbitrary obstacle configuration with convex and non-convex geometries show the feasibility and the attractive performance when computing multiple obstacle-avoiding Steiner trees in the plane. Our results offer the mechanisms to elucidate new operators for obstacle-avoiding Steiner trees.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Lossless and Privacy-Preserving Graph Convolution Network for Federated Item Recommendation</title>
<link>https://arxiv.org/abs/2412.01141</link>
<guid>https://arxiv.org/abs/2412.01141</guid>
<content:encoded><![CDATA[
<div> 关键词: 图神经网络 (GNN), 推荐系统, 隐私保护, 联邦推荐, LP-GCN

总结:
本文提出了一种新的隐私保护图卷积网络——LP-GCN，用于解决基于GNN的推荐系统中的隐私问题。现有的GNN推荐方法依赖于集中式的用户-物品交互子图存储和全局图训练，可能引发隐私关注。针对此问题，一些联邦推荐方法利用分布式和碎片化的用户-物品子图以保护用户隐私，但其图卷积过程不完整，影响推荐性能。LP-GCN创新性地实现了在分布式子图上完整进行图卷积的过程，同时确保了隐私安全，并且其性能与非联邦（即集中式）方案相当。理论分析和实证研究表明，LP-GCN在三个真实数据集上的表现优于现有联邦推荐方法。论文接受后，相关代码将公开发布。 <div>
arXiv:2412.01141v1 Announce Type: new 
Abstract: Graph neural network (GNN) has emerged as a state-of-the-art solution for item recommendation. However, existing GNN-based recommendation methods rely on a centralized storage of fragmented user-item interaction sub-graphs and training on an aggregated global graph, which will lead to privacy concerns. As a response, some recent works develop GNN-based federated recommendation methods by exploiting decentralized and fragmented user-item sub-graphs in order to preserve user privacy. However, due to privacy constraints, the graph convolution process in existing federated recommendation methods is incomplete compared with the centralized counterpart, causing a degradation of the recommendation performance. In this paper, we propose a novel lossless and privacy-preserving graph convolution network (LP-GCN), which fully completes the graph convolution process with decentralized user-item interaction sub-graphs while ensuring privacy. It is worth mentioning that its performance is equivalent to that of the non-federated (i.e., centralized) counterpart. Moreover, we validate its effectiveness through both theoretical analysis and empirical studies. Extensive experiments on three real-world datasets show that our LP-GCN outperforms the existing federated recommendation methods. The code will be publicly available once the paper is accepted.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>INTELLECT-1 Technical Report</title>
<link>https://arxiv.org/abs/2412.01152</link>
<guid>https://arxiv.org/abs/2412.01152</guid>
<content:encoded><![CDATA[
<div> 关键词: INTELLECT-1、PRIME、分布式训练、ElasticDeviceMesh、DiLoCo-FSDP2

总结:
本文介绍了INTELLECT-1，这是全球首个人工智能社区合作训练的拥有100亿参数的语言模型，证明大规模模型训练不再仅限于大型企业，而是可以通过分布式的社区驱动方式实现。INTELLECT-1使用了1万亿个令牌，在跨三大洲的最多14个并发节点上进行训练，共有30家独立计算资源提供商动态加入和退出训练过程，期间保持了83-96%的计算利用率和36.2-41.4%的模型FLOPS利用率。为实现这一目标，研究团队开发了PRIME框架，该框架具有弹性设备网格（ElasticDeviceMesh）、用于互联网和本地节点间容错通信的动态全局进程组以及现场检查点恢复内核等功能。通过结合PRIME、DiLoCo和定制的int8全Reduce技术，他们实现了与传统数据并行训练相比高达400倍的通信带宽降低，同时保证了相当的性能。这些成果显示出利用全球GPU资源的分散网络训练前沿基础模型的可能性和前景。 <div>
arXiv:2412.01152v1 Announce Type: new 
Abstract: In this report, we introduce INTELLECT-1, the first 10 billion parameter language model collaboratively trained across the globe, demonstrating that large-scale model training is no longer confined to large corporations but can be achieved through a distributed, community-driven approach. INTELLECT-1 was trained on 1 trillion tokens using up to 14 concurrent nodes distributed across 3 continents, with contributions from 30 independent compute providers dynamically joining and leaving the training process, while maintaining 83-96% compute utilization and 36.2-41.4% model FLOPS utilization. We leverage PRIME, our scalable distributed training framework designed for fault-tolerant, high-performance training on unreliable, globally distributed nodes. Key innovations in PRIME include the ElasticDeviceMesh, which manages dynamic global process groups for fault-tolerant communication across the internet and local process groups for communication within a node, live checkpoint recovery kernels, and a hybrid DiLoCo-FSDP2 implementation. Using PRIME with DiLoCo and our custom int8 all-reduce, we achieve a 400x reduction in communication bandwidth compared to traditional data-parallel training settings while delivering comparable performance. These results demonstrate the feasibility and promise of training frontier foundation models in a decentralized network of global GPU resources.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hybrid BPMN-DMN Framework for Secure Inter-organizational Processes and Decisions Collaboration on Permissioned Blockchain</title>
<link>https://arxiv.org/abs/2412.01196</link>
<guid>https://arxiv.org/abs/2412.01196</guid>
<content:encoded><![CDATA[
<div> 关键词: BlockCollab、BPMN、DMN、区块链、智能合约<br /><br />总结:
本文提出了一种名为BlockCollab的新型模型驱动框架，该框架针对数字商务领域中跨组织协作的需求，将Business Process Model and Notation（BPMN）与Decision Model and Notation（DMN）相结合，用于标准化并实现在许可型区块链平台上协同业务流程和决策的实施。BlockCollab实现了三个主要创新：1) 提供了一种标准化的方法，使用集成的BPMN-DMN模型来建模协同过程和决策；2) 自动化生成兼容Hyperledger Fabric的智能合约，同时保持过程逻辑和决策规则，并考虑隐私约束；3) 引入了混合式链上/链下执行环境，通过安全数据传输和外部系统集成优化协同工作流程。实验结果表明，该方法在11个真实世界的协作场景中实现100%的执行准确性，并证明了其实用性和可靠性。此外，文中还介绍了一个基于区块链技术的开源第三方协作平台。 <div>
arXiv:2412.01196v1 Announce Type: new 
Abstract: In the rapidly evolving digital business landscape, organizations increasingly need to collaborate across boundaries to achieve complex business objectives, requiring both efficient process coordination and flexible decision-making capabilities. Traditional collaboration approaches face significant challenges in transparency, trust, and decision flexibility, while existing blockchain-based solutions primarily focus on process execution without addressing the integrated decision-making needs of collaborative enterprises. This paper proposes BlockCollab, a novel model-driven framework that seamlessly integrates Business Process Model and Notation (BPMN) with Decision Model and Notation (DMN) to standardize and implement collaborative business processes and decisions on permissioned blockchain platforms. Our approach automatically translates integrated BPMN-DMN models into smart contracts(SCs) compatible with Hyperledger Fabric, enabling privacy-aware multi-organizational process execution through blockchain-based Attribute-Based Access Control (ABAC). The framework introduces three key innovations: (1) a standardized method for modeling collaborative processes and decisions using integrated BPMN-DMN model, (2) an automated SC generator that preserves both process logic and decision rules while maintaining privacy constraints, and (3) a hybrid on-chain/off-chain execution environment that optimizes collaborative workflows through secure data transfer and external system integration. Experimental evaluation across 11 real-world collaboration scenarios demonstrates that our approach achieves 100\% accuracy in process execution. Furthermore, an analysis of various execution processes highlights the strong practical applicability and reliability of our approach. The proposed framework includes an open-source third-party collaboration platform based on blockchain.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>GeoTP: Latency-aware Geo-Distributed Transaction Processing in Database Middlewares (Extended Version)</title>
<link>https://arxiv.org/abs/2412.01213</link>
<guid>https://arxiv.org/abs/2412.01213</guid>
<content:encoded><![CDATA[
<div> 关键词：数据库中间件、分布式事务处理、网络延迟、锁竞争、GeoTP

总结:
<br />
本文提出了GeoTP，一种针对数据库中间件的延迟感知型地理分布事务处理方法，旨在解决分布式事务处理中的性能瓶颈。首先，GeoTP设计了一种去中心化的准备机制，减少了分布式事务所需的网络往返次数。其次，它引入了一个延迟感知调度器，通过策略性地推迟锁获取时间点来最大限度地减少锁竞争持续时间。再者，为调度器提出了启发式优化方法，进一步降低锁竞争持续时间。实验结果显示，在Apache Shardingsphere这一先进的数据库中间件上实现并扩展至Apache ScalarDB后的GeoTP，在YCSB和TPC-C基准测试中，相比于Shardingsphere实现了最高达17.7倍的性能提升。 <div>
arXiv:2412.01213v1 Announce Type: new 
Abstract: The widespread adoption of database middleware for supporting distributed transaction processing is prevalent in numerous applications, with heterogeneous data sources deployed across national and international boundaries. However, transaction processing performance significantly drops due to the high network latency between the middleware and data sources and the long lock contention span, where transactions may be blocked while waiting for the locks held by concurrent transactions. In this paper, we propose GeoTP, a latency-aware geo-distributed transaction processing approach in database middlewares. GeoTP incorporates three key techniques to enhance geo-distributed transaction performance. First, we propose a decentralized prepare mechanism, which diminishes the requirement of network round trips for distributed transactions. Second, we design a latency-aware scheduler to minimize the lock contention span by strategically postponing the lock acquisition time point. Third, heuristic optimizations are proposed for the scheduler to reduce the lock contention span further. We implemented GeoTP on Apache Shardingsphere, a state-of-the-art middleware, and extended it into Apache ScalarDB. Experimental results on YCSB and TPC-C demonstrate that GeoTP achieves up to 17.7x performance improvement over Shardingsphere.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeFi: Concepts and Ecosystem</title>
<link>https://arxiv.org/abs/2412.01357</link>
<guid>https://arxiv.org/abs/2412.01357</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Finance (DeFi), bibliometric analysis, thematic review, participants, risks

<br />
总结:
该文深入研究了去中心化金融（DeFi）的发展态势，通过文献计量分析揭示了其基础概念、研究趋势和生态系统。文章指出，DeFi研究的关注点从初期的技术创新逐渐转向可持续性、环境影响及监管挑战等问题。研究主题主要集中在去中心化、智能合约、代币化和可持续性关注等方面。同时，文章分析了DeFi生态系统的参与者角色与互动，如开发者、流动性提供者、审计员和监管机构，并指出了关键风险，包括智能合约漏洞、流动性约束以及监管不确定性。研究强调了DeFi在推动金融包容性和透明度方面的变革潜力，但同时也需要强有力的安全框架和监管监督以确保长期稳定性。本文通过对文献计量和主题分析的整合，全面解释了DeFi生态系统，为研究人员、实践者和政策制定者提供了有价值的见解，有助于推进DeFi在全球金融系统中的可持续发展和整合。 <div>
arXiv:2412.01357v1 Announce Type: new 
Abstract: This paper investigates the evolving landscape of decentralized finance (DeFi) by examining its foundational concepts, research trends, and ecosystem. A bibliometric analysis was conducted to identify thematic clusters and track the evolution of DeFi research. Additionally, a thematic review was performed to analyze the roles and interactions of key participants within the DeFi ecosystem, focusing on its opportunities and inherent risks. The bibliometric analysis identified a progression in research priorities, transitioning from an initial focus on technological innovation to addressing sustainability, environmental impacts, and regulatory challenges. Key thematic clusters include decentralization, smart contracts, tokenization, and sustainability concerns. The analysis of participants highlighted the roles of developers, liquidity providers, auditors, and regulators while identifying critical risks such as smart contract vulnerabilities, liquidity constraints, and regulatory uncertainties. The study underlines the transformative potential of DeFi to enhance financial inclusion and transparency while emphasizing the need for robust security frameworks and regulatory oversight to ensure long-term stability. This paper comprehensively explains the DeFi ecosystem by integrating bibliometric and thematic analyses. It offers valuable insights for researchers, practitioners, and policymakers, contributing to the ongoing discourse on the sustainable development and integration of DeFi into the global financial system.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Future of Document Verification: Leveraging Blockchain and Self-Sovereign Identity for Enhanced Security and Transparency</title>
<link>https://arxiv.org/abs/2412.01531</link>
<guid>https://arxiv.org/abs/2412.01531</guid>
<content:encoded><![CDATA[
<div> 关键词：文档认证、区块链、自我主权身份、去中心化技术、COVID-19疫情

<br />
总结:
文章提出了一种利用区块链和自我主权身份等去中心化技术改进文档认证的新策略。当前传统文档认证流程存在耗时长、伪证流通以及数据隐私问题，特别是在COVID-19疫情期间，物理出席要求导致了认证过程的显著延误，且缺乏实时跟踪功能。该新策略旨在克服这些难题，构建一个高效、安全且用户友好的认证生态系统。 <div>
arXiv:2412.01531v1 Announce Type: new 
Abstract: Attestation of documents like legal papers, professional qualifications, medical records, and commercial documents is crucial in global transactions, ensuring their authenticity, integrity, and trustworthiness. Companies expanding operations internationally need to submit attested financial statements and incorporation documents to foreign governments or business partners to prove their businesses and operations' authenticity, legal validity, and regulatory compliance. Attestation also plays a critical role in education, overseas employment, and authentication of legal documents such as testaments and medical records. The traditional attestation process is plagued by several challenges, including time-consuming procedures, the circulation of counterfeit documents, and concerns over data privacy in the attested records. The COVID-19 pandemic brought into light another challenge: ensuring physical presence for attestation, which caused a significant delay in the attestation process. Traditional methods also lack real-time tracking capabilities for attesting entities and requesters. This paper aims to propose a new strategy using decentralized technologies such as blockchain and self-sovereign identity to overcome the identified hurdles and provide an efficient, secure, and user-friendly attestation ecosystem.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart Contract Vulnerabilities, Tools, and Benchmarks: An Updated Systematic Literature Review</title>
<link>https://arxiv.org/abs/2412.01719</link>
<guid>https://arxiv.org/abs/2412.01719</guid>
<content:encoded><![CDATA[
<div> 关键词：智能合约、以太坊、安全漏洞、自动化检测工具、基准评价

<br />
总结:
本文是一篇关于以太坊智能合约安全漏洞的系统性文献综述，重点关注了自动化检测工具及其基准评估。研究团队从五个数字图书馆和五个主要软件工程会议中筛选了1,888份研究，最终选取了131篇高质量论文进行分析。文章构建了一个由101种智能合约漏洞组成的十级分类体系；列出了144款具有相应功能、方法及代码转换技术的智能合约检测工具；并汇总了用于工具评估的102个基准。通过对现有研究的深入剖析，文中对以太坊智能合约安全性现状进行了总结，并指出了未来研究的方向。 <div>
arXiv:2412.01719v1 Announce Type: new 
Abstract: Smart contracts are self-executing programs on blockchain platforms like Ethereum, which have revolutionized decentralized finance by enabling trustless transactions and the operation of decentralized applications. Despite their potential, the security of smart contracts remains a critical concern due to their immutability and transparency, which expose them to malicious actors. The connections of contracts further complicate vulnerability detection. This paper presents a systematic literature review that explores vulnerabilities in Ethereum smart contracts, focusing on automated detection tools and benchmark evaluation. We reviewed 1,888 studies from five digital libraries and five major software engineering conferences, applying a structured selection process that resulted in 131 high-quality studies. The key results include a hierarchical taxonomy of 101 vulnerabilities grouped into ten categories, a comprehensive list of 144 detection tools with corresponding functionalities, methods, and code transformation techniques, and a collection of 102 benchmarks used for tool evaluation. We conclude with insights on the current state of Ethereum smart contract security and directions for future research.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining Blockchain and Biometrics: A Survey on Technical Aspects and a First Legal Analysis</title>
<link>https://arxiv.org/abs/2302.10883</link>
<guid>https://arxiv.org/abs/2302.10883</guid>
<content:encoded><![CDATA[
<div> 关键词: 生物识别、区块链、集成、法律分析、挑战与潜力

<br /><br />总结:
本文是对生物识别技术和区块链技术融合应用的学术文献调研，探讨了二者的结合在身份验证、分布式信任服务和身份管理等领域的潜在优势。文章指出，虽然目前这种组合在实际实时应用中还面临区块链效率和经济性不足的问题，但其对于推动生物识别领域创新具有积极意义。从法律角度来看，责任分配问题成为主要挑战，同时进行适当的数据保护影响评估也存在困难。最后，该研究提出了针对这一组合的技术和法律建议，旨在帮助充分利用其优点并降低风险。 <div>
arXiv:2302.10883v2 Announce Type: replace 
Abstract: Biometric recognition as a unique, hard-to-forge, and efficient way of identification and verification has become an indispensable part of the current digital world. The fast evolution of this technology has been a strong incentive for integrating it into many applications. Meanwhile, blockchain, the very attractive decentralized ledger technology, has been widely received both by the research and industry in the past years and it is being increasingly deployed nowadays in many different applications, such as money transfer, IoT, healthcare, or logistics. Recently, researchers have started to speculate what would be the pros and cons and what would be the best applications when these two technologies cross paths. This paper provides a survey of technical literature research on the combination of blockchain and biometrics and includes a first legal analysis of this integration to shed light on challenges and potentials. While this combination is still in its infancy and a growing body of literature discusses specific blockchain applications and solutions in an advanced technological set-up, this paper presents a holistic understanding of blockchains applicability in the biometric sector. This study demonstrates that combining blockchain and biometrics would be beneficial for novel applications in biometrics such as the PKI mechanism, distributed trusted service, and identity management. However, blockchain networks at their current stage are not efficient and economical for real-time applications. From a legal point of view, the allocation of accountability remains a main issue, while other difficulties remain, such as conducting a proper Data Protection Impact Assessment. Finally, it supplies technical and legal recommendations to reap the benefits and mitigate the risks of the combination.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Estimating Continuous Muscle Fatigue For Multi-Muscle Coordinated Exercise: A Pilot Study on Walking</title>
<link>https://arxiv.org/abs/2303.17614</link>
<guid>https://arxiv.org/abs/2303.17614</guid>
<content:encoded><![CDATA[
<div> 关键词：肌肉疲劳评估、多肌协调、神经肌肉特征、贝叶斯高斯过程、生理学原理模型

<br /><br />总结：
本文提出了一种用于评估日常锻炼中肌肉疲劳进展的方法。首先，通过肌肉协同作用分数化和脊髓模块放电变异性等特征，结合疲劳诱导的神经肌肉适应性理论来描绘肌肉疲劳。其次，利用贝叶斯高斯过程建立模型，以捕捉疲劳随时间演变的进程。为解决缺乏监督信息的问题，文中将疲劳的时间演化特性数学化作为损失函数。最后，依据肌肉疲劳的生理学原则制定量化评价指标。实验结果显示，该方法在不同天之间的相似度达到0.99，与其他疲劳观点的相似度超过0.7，并具有接近1的弱单调性，性能优于其他方法。这项研究旨在实现肌肉疲劳的客观评估。 <div>
arXiv:2303.17614v2 Announce Type: replace 
Abstract: Assessing the progression of muscle fatigue for daily exercises provides vital indicators for precise rehabilitation, personalized training dose, especially under the context of Metaverse. Assessing fatigue of multi-muscle coordination-involved daily exercises requires the neuromuscular features that represent the fatigue-induced characteristics of spatiotemporal adaptions of multiple muscles and the estimator that captures the time-evolving progression of fatigue. In this paper, we propose to depict fatigue by the features of muscle compensation and spinal module activation changes and estimate continuous fatigue by a physiological rationale model. First, we extract muscle synergy fractionation and the variance of spinal module spikings as features inspired by the prior of fatigue-induced neuromuscular adaptations. Second, we treat the features as observations and develop a Bayesian Gaussian process to capture the time-evolving progression. Third, we solve the issue of lacking supervision information by mathematically formulating the time-evolving characteristics of fatigue as the loss function. Finally, we adapt the metrics that follow the physiological principles of fatigue to quantitatively evaluate the performance. Our extensive experiments present a 0.99 similarity between days, a over 0.7 similarity with other views of fatigue and a nearly 1 weak monotonicity, which outperform other methods. This study would aim the objective assessment of muscle fatigue.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>No-Regret Learning and Equilibrium Computation in Quantum Games</title>
<link>https://arxiv.org/abs/2310.08473</link>
<guid>https://arxiv.org/abs/2310.08473</guid>
<content:encoded><![CDATA[
<div> 关键词：量子处理器、分布式系统、无遗憾算法、量子纳什均衡、分离型量子粗相关均衡

总结:
本文探讨了随着量子处理器的发展，涉及互动量子代理的大规模分布式系统的出现。研究重点在于无遗憾算法在量子环境中如何驱动多智能体在时间上更新其行为。对于双人量子零和游戏与多玩家量子聚合零和游戏，文章证明无遗憾算法会收敛到时间平均下的可分离量子纳什均衡。针对更一般的多玩家量子游戏情况，文中引入了一个新概念——分离型量子粗相关均衡（QCCE），这是无遗憾学习算法行为时间平均收敛的结果，为分布式量子系统提供了一种自然的解决方案。此外，论文还表明计算QCCE可以形式化为半正定规划问题，并确立了存在纠缠（即非可分离）的QCCE，这类均衡无法通过当前的无遗憾学习范式得到学习。<br /><br /> <div>
arXiv:2310.08473v3 Announce Type: replace 
Abstract: As quantum processors advance, the emergence of large-scale decentralized systems involving interacting quantum-enabled agents is on the horizon. Recent research efforts have explored quantum versions of Nash and correlated equilibria as solution concepts of strategic quantum interactions, but these approaches did not directly connect to decentralized adaptive setups where agents possess limited information. This paper delves into the dynamics of quantum-enabled agents within decentralized systems that employ no-regret algorithms to update their behaviors over time. Specifically, we investigate two-player quantum zero-sum games and polymatrix quantum zero-sum games, showing that no-regret algorithms converge to separable quantum Nash equilibria in time-average. In the case of general multi-player quantum games, our work leads to a novel solution concept, that of the {separable} quantum coarse correlated equilibria (QCCE), as the convergent outcome of the time-averaged behavior no-regret algorithms, offering a natural solution concept for decentralized quantum systems. Finally, we show that computing QCCEs can be formulated as a semidefinite program and establish the existence of entangled (i.e., non-separable) QCCEs, which are unlearnable via the current paradigm of no-regret learning.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>MASP: Scalable GNN-based Planning for Multi-Agent Navigation</title>
<link>https://arxiv.org/abs/2312.02522</link>
<guid>https://arxiv.org/abs/2312.02522</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体导航、强化学习、规划方法、层次化规划、图模型

总结:<br />
本文提出了一个名为Multi-Agent Scalable Graph-based Planner (MASP)的新型层次化规划器，用于解决具有大量智能体的分布式环境中的多目标导航任务。MASP采用层次框架降低探索空间复杂度，通过将大空间分解为多个目标条件子空间来实现。它利用图模型来更好地捕捉智能体和目标之间的关系，以促进合作并适应团队规模的变化。具体而言，MASP包括两个部分：高层面的Goal Matcher使用基于图的自编码器和交叉编码器优化目标分配；低层面的Coordinated Action Executor引入了Group Information Fusion技术，有助于小组划分并提取跨组的智能体间关系，从而提高训练效率并增强智能体的合作能力。实验结果显示，MASP在任务效率方面优于强化学习和基于规划的方法基线。 <div>
arXiv:2312.02522v2 Announce Type: replace 
Abstract: We investigate multi-agent navigation tasks, where multiple agents need to reach initially unassigned goals in a limited time. Classical planning-based methods suffer from expensive computation overhead at each step and offer limited expressiveness for complex cooperation strategies. In contrast, reinforcement learning (RL) has recently become a popular approach for addressing this issue. However, RL struggles with low data efficiency and cooperation when directly exploring (nearly) optimal policies in a large exploration space, especially with an increased number of agents(e.g., 10+ agents) or in complex environments (e.g., 3-D simulators). In this paper, we propose the Multi-Agent Scalable Graph-based Planner (MASP), a goal-conditioned hierarchical planner for navigation tasks with a substantial number of agents in the decentralized setting. MASP employs a hierarchical framework to reduce space complexity by decomposing a large exploration space into multiple goal-conditioned subspaces, where a high-level policy assigns agents goals, and a low-level policy navigates agents toward designated goals. For agent cooperation and the adaptation to varying team sizes, we model agents and goals as graphs to better capture their relationship. The high-level policy, the Goal Matcher, leverages a graph-based Self-Encoder and Cross-Encoder to optimize goal assignment by updating the agent and the goal graphs. The low-level policy, the Coordinated Action Executor, introduces the Group Information Fusion to facilitate group division and extract agent relationships across groups, enhancing training efficiency for agent cooperation. The results demonstrate that MASP outperforms RL and planning-based baselines in task efficiency.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Global and Local Error-Tolerant Decentralized State Estimation under Partially Ordered Observations</title>
<link>https://arxiv.org/abs/2401.09110</link>
<guid>https://arxiv.org/abs/2401.09110</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized state estimation、discrete event system、malicious attacker、global errors、local errors

总结:
本文研究了在存在恶意攻击者可能篡改或破坏信息的情况下，离散事件系统的分布式状态估计问题。系统由一组局部观测站点（OSs）观察，并定期向协调器发送其记录的观测序列以进行状态估计。文中将错误分为两种类型：全局错误和局部错误，前者指所有OSs记录相同的错误，后者则指不同OSs记录不同的错误。针对每种类型的错误，文章提出了两种有效执行状态估计的方法，一种基于修改原系统，另一种基于推断原系统的匹配行为。对于每种方法，采用估算释放策略设计相应的同步器算法来进行状态估计。 <div>
arXiv:2401.09110v2 Announce Type: replace 
Abstract: We investigate decentralized state estimation for a discrete event system in a setting where the information received at a coordinator may be corrupted or tampered by a malicious attacker. Specifically, a system is observed by a set of (local) observation sites (OSs) which occasionally send their recorded sequences of observations to the coordinator that is in charge of estimating the system state. The malfunctions and attacks, referred to as errors in this paper, include symbol deletions, insertions and replacements, each of which bears a positive cost. Two types of errors, global errors and local errors, are proposed to describe the impact of errors on decentralized information processing. Global errors occur when all OSs record the same error, while local errors occur when different OSs record different errors. Distinguishing these types of errors is important for a proper design of decentralized information processing (so as to be more resilient and better equipped to handle attacks and failures). For each type of error, we propose two methods to efficiently perform state estimation: one based on appropriately modifying the original system and the other based on inferring the matching behavior of the original system. For each method, we adopt an estimation-by-release methodology to design an algorithm for constructing a corresponding synchronizer for state estimation.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RO-SVD: A Reconfigurable Hardware Copyright Protection Framework for AIGC Applications</title>
<link>https://arxiv.org/abs/2406.11536</link>
<guid>https://arxiv.org/abs/2406.11536</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式人工智能 (GenAI)，区块链，版权可追溯性框架，环形振荡器-奇异值分解 (RO-SVD)，现场可编程门阵列 (FPGA)

总结:

本文提出了一种基于区块链的版权可追溯性框架RO-SVD，该框架利用硬件熵源产生的低秩矩阵的分解计算，旨在解决生成式人工智能（GenAI）产生的多维度数据的安全管理和使用问题。通过结合现场可编程门阵列（FPGA）的并行性和可重构性，该框架能够在现有AI加速设备上低成本构建，针对AI生成内容（AIGC）的版权问题提供解决方案。研究团队开发了一个软硬件协同设计原型，并在多种适用于AI的FPGA上进行了实船试验和分析，以AI生成图像为例展示了该框架的有效性、定制化、不可预测性、效率以及可管理性和可重构性。据作者所知，这是首次针对AI生成内容具体实施版权可追溯性的硬件研究报告。 <div>
arXiv:2406.11536v2 Announce Type: replace 
Abstract: The dramatic surge in the utilisation of generative artificial intelligence (GenAI) underscores the need for a secure and efficient mechanism to responsibly manage, use and disseminate multi-dimensional data generated by artificial intelligence (AI). In this paper, we propose a blockchain-based copyright traceability framework called ring oscillator-singular value decomposition (RO-SVD), which introduces decomposition computing to approximate low-rank matrices generated from hardware entropy sources and establishes an AI-generated content (AIGC) copyright traceability mechanism at the device level. By leveraging the parallelism and reconfigurability of field-programmable gate arrays (FPGAs), our framework can be easily constructed on existing AI-accelerated devices and provide a low-cost solution to emerging copyright issues of AIGC. We developed a hardware-software (HW/SW) co-design prototype based on comprehensive analysis and on-board experiments with multiple AI-applicable FPGAs. Using AI-generated images as a case study, our framework demonstrated effectiveness and emphasised customisation, unpredictability, efficiency, management and reconfigurability. To the best of our knowledge, this is the first practical hardware study discussing and implementing copyright traceability specifically for AI-generated content.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation</title>
<link>https://arxiv.org/abs/2406.17249</link>
<guid>https://arxiv.org/abs/2406.17249</guid>
<content:encoded><![CDATA[
<div> 关键词：实时、分布式、多机器人、语义SLAM、环境映射

总结:
本文提出了一种实时分布式语义SLAM算法框架，适用于异构机器人团队在无GPS条件下共同构建基于对象的三维环境地图，包括室内、城市和森林场景。该框架集成了数据驱动的前端，用于从RGBD相机或LiDAR进行实例分割，并采用定制后端优化机器人轨迹和地图中的物体地标。为实现多个机器人信息融合，设计了基于语义的场景识别算法，利用对象级别的语义地图的信息丰富度和视角不变性进行机器人间的环闭检测。同时设计了一个通信模块来跟踪各机器人的观测数据以及在通信链路可用时其他机器人的观测数据。该框架支持机器人实时分布式运行，使它们能够灵活利用通信资源。文章将提出的框架与多种空中和地面机器人的自主导航及探索系统整合，并在各种室内外环境中进行了大量实验，验证了其在机器人间定位和物体映射准确性方面的表现，同时展现了对计算、存储和通信资源的需求适度。该框架已开源并作为模块化堆栈发布，适用于单 agent 和多机器人场景的对象级语义SLAM应用。项目网站和代码分别可在https://xurobotics.github.io/slideslam/ 和 https://github.com/XuRobotics/SLIDE_SLAM 找到。 <div>
arXiv:2406.17249v4 Announce Type: replace 
Abstract: This paper develops a real-time decentralized metric-semantic Simultaneous Localization and Mapping (SLAM) algorithm framework that enables a heterogeneous robot team to collaboratively construct object-based metric-semantic maps of 3D environments featuring indoor, urban, and forests without relying on GPS. The framework integrates a data-driven front-end for instance segmentation from either RGBD cameras or LiDARs and a custom back-end for optimizing robot trajectories and object landmarks in the map. To allow multiple robots to merge their information, we design semantics-driven place recognition algorithms that leverage the informativeness and viewpoint invariance of the object-level metric-semantic map for inter-robot loop closure detection. A communication module is designed to track each robot's observations and those of other robots whenever communication links are available. Our framework enables real-time decentralized operations onboard robots, allowing them to opportunistically leverage communication. We integrate the proposed framework with the autonomous navigation and exploration systems of three types of aerial and ground robots, conducting extensive experiments in a variety of indoor and outdoor environments. These experiments demonstrate accuracy in inter-robot localization and object mapping, along with its moderate demands on computation, storage, and communication resources. The framework is open-sourced and available as a modular stack for object-level metric-semantic SLAM, suitable for both single-agent and multi-robot scenarios. The project website and code can be found at https://xurobotics.github.io/slideslam/ and https://github.com/XuRobotics/SLIDE_SLAM, respectively.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Know Your Account: Double Graph Inference-based Account De-anonymization on Ethereum</title>
<link>https://arxiv.org/abs/2411.18875</link>
<guid>https://arxiv.org/abs/2411.18875</guid>
<content:encoded><![CDATA[
<div> 关键词：Web 3.0, 区块链, 以太坊, 双重图, 账户匿名化推理

<br /><br />总结:
本文提出了一种名为DBG4ETH的新型双重图基以太坊账户去匿名化推理方法，旨在全面捕获账户的行为模式并增强对当前复杂、持续生成的交易行为的分析和判断能力。该方法首先构建了一个全局静态图，用于建立所有交易数据中各类账户节点间的复杂交互关系；随后，又构建了局部动态图来学习不同时间段内交易的逐渐演变过程。两种图从不同视角聚焦信息，通过DBG4ETH可以获取全球与局部、静态与动态交易图的特征。此外，文中还提出了自适应置信度校准方法，将校准后的加权预测值输入分类器以进行预测结果的预测。实验结果显示，DBG4ETH在账户识别任务上达到了最先进的结果，相比于分别处理每种图类型，其F1分数提高了至少3.75%，最高可达40.52%，并且相比类似的账户身份推断方法，性能提升了5.23%至12.91%。 <div>
arXiv:2411.18875v1 Announce Type: new 
Abstract: The scaled Web 3.0 digital economy, represented by decentralized finance (DeFi), has sparked increasing interest in the past few years, which usually relies on blockchain for token transfer and diverse transaction logic. However, illegal behaviors, such as financial fraud, hacker attacks, and money laundering, are rampant in the blockchain ecosystem and seriously threaten its integrity and security. In this paper, we propose a novel double graph-based Ethereum account de-anonymization inference method, dubbed DBG4ETH, which aims to capture the behavioral patterns of accounts comprehensively and has more robust analytical and judgment capabilities for current complex and continuously generated transaction behaviors. Specifically, we first construct a global static graph to build complex interactions between the various account nodes for all transaction data. Then, we also construct a local dynamic graph to learn about the gradual evolution of transactions over different periods. Different graphs focus on information from different perspectives, and features of global and local, static and dynamic transaction graphs are available through DBG4ETH. In addition, we propose an adaptive confidence calibration method to predict the results by feeding the calibrated weighted prediction values into the classifier. Experimental results show that DBG4ETH achieves state-of-the-art results in the account identification task, improving the F1-score by at least 3.75% and up to 40.52% compared to processing each graph type individually and outperforming similar account identity inference methods by 5.23% to 12.91%.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Swarm Intelligence-Driven Client Selection for Federated Learning in Cybersecurity applications</title>
<link>https://arxiv.org/abs/2411.18877</link>
<guid>https://arxiv.org/abs/2411.18877</guid>
<content:encoded><![CDATA[
<div> 关键词: Swarm Intelligence Optimization, Federated Learning, Cybersecurity, Grey Wolf Optimization, Particle Swarm Optimization

总结:<br />
本文针对 Swarm Intelligence Optimization（群智优化）算法在联邦学习（Federated Learning, FL）中的客户端选择应用展开研究，特别是在网络安全领域的应用。当前研究主要关注集中式机器学习的优化技术，而对FL中客户端多样性、非独立同分布数据以及敌对噪音等独特挑战的关注不足。为此，文章评估了九种群智优化算法，包括Grey Wolf Optimization（灰狼优化）、Particle Swarm Optimization（粒子群优化）、Cuckoo Search等在四种实验场景下的表现：固定客户端参与、动态参与模式、异质非独立同分布数据以及对抗性噪声条件。结果显示，GWO展现出优异的适应性和鲁棒性，在所有配置下均取得了最高的准确率、召回率和F1分数；同时，PSO和Cuckoo Search也表现出色。这些发现强调了群智优化算法在解决分布式和对抗性FL问题上的潜力，为网络安全应用，如IoT和大规模网络入侵检测，提供了可扩展和韧性强的解决方案。 <div>
arXiv:2411.18877v1 Announce Type: new 
Abstract: This study addresses a critical gap in the literature regarding the use of Swarm Intelligence Optimization (SI) algorithms for client selection in Federated Learning (FL), with a focus on cybersecurity applications. Existing research primarily explores optimization techniques for centralized machine learning, leaving the unique challenges of client diveristy, non-IID data distributions, and adversarial noise in decentralized FL largely unexamined. To bridge this gap, we evaluate nine SI algorithms-Grey Wolf Optimization (GWO), Particle Swarm Optimization (PSO), Cuckoo Search, Bat Algorithm, Bee Colony, Ant Colony Optimization, Fish Swarm, Glow Worm, and Intelligent Water Droplet-across four experimental scenarios: fixed client participation, dynamic participation patterns, hetergeneous non-IID data distributions, and adversarial noise conditions. Results indicate that GWO exhibits superior adaptability and robustness, achieving the highest accuracy, recall and F1-scoress across all configurations, while PSO and Cuckoo Search also demonstrate strong performance. These findings underscore the potential of SI algorithms to address decentralized and adversarial FL challenges, offereing scalable and resilient solutions for cybersecurity applications, including intrusion detection in IoT and large-scale networks.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Continual Graph Learning</title>
<link>https://arxiv.org/abs/2411.18919</link>
<guid>https://arxiv.org/abs/2411.18919</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦持续图学习（FCGL）、图神经网络（GNNs）、局部图遗忘（LGF）、全局专家冲突（GEC）、POWER框架

总结:<br />
本文针对大数据时代下不断演进的图数据管理所面临的存储成本和隐私问题，提出了联邦持续图学习（FCGL）这一全新研究方向。FCGL旨在适应多个分布式环境中的变化图数据，同时解决存储和隐私约束下的性能优化问题。文章通过实证分析揭示了FCGL在实现过程中面临的两大挑战：局部图遗忘（LGF）与全局专家冲突（GEC）。为了解决这些问题，作者提出了名为POWER的框架，该框架通过保存并回放具有最大局部-全局覆盖范围的经验节点来缓解LGF，同时采用伪原型重建策略和轨迹感知的知识转移方法在中央服务器端解决GEC。实验结果表明，POWER在多个图数据集上的表现优于现有的中心化CGL算法的联邦扩展版本以及视觉焦点的联邦持续学习算法。相关代码已开源，可在https://github.com/zyl24/FCGL_POWER获取。 <div>
arXiv:2411.18919v1 Announce Type: new 
Abstract: In the era of big data, managing evolving graph data poses substantial challenges due to storage costs and privacy issues. Training graph neural networks (GNNs) on such evolving data usually causes catastrophic forgetting, impairing performance on earlier tasks. Despite existing continual graph learning (CGL) methods mitigating this to some extent, they predominantly operate in centralized architectures and overlook the potential of distributed graph databases to harness collective intelligence for enhanced performance optimization. To address these challenges, we present a pioneering study on Federated Continual Graph Learning (FCGL), which adapts GNNs to multiple evolving graphs within decentralized settings while adhering to storage and privacy constraints. Our work begins with a comprehensive empirical analysis of FCGL, assessing its data characteristics, feasibility, and effectiveness, and reveals two principal challenges: local graph forgetting (LGF), where local GNNs forget prior knowledge when adapting to new tasks, and global expertise conflict (GEC), where the global GNN exhibits sub-optimal performance in both adapting to new tasks and retaining old ones, arising from inconsistent client expertise during server-side parameter aggregation. To tackle these, we propose the POWER framework, which mitigates LGF by preserving and replaying experience nodes with maximum local-global coverage at each client and addresses GEC by using a pseudo prototype reconstruction strategy and trajectory-aware knowledge transfer at the central server. Extensive evaluations across multiple graph datasets demonstrate POWER's superior performance over straightforward federated extensions of the centralized CGL algorithms and vision-focused federated continual learning algorithms. Our code is available at https://github.com/zyl24/FCGL_POWER.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Guardians of the Ledger: Protecting Decentralized Exchanges from State Derailment Defects</title>
<link>https://arxiv.org/abs/2411.18935</link>
<guid>https://arxiv.org/abs/2411.18935</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化交易所(DEX)，智能合约，状态脱轨缺陷，StateGuard，深度学习

总结:<br />
本文首次对去中心化交易所(DEX)中的状态脱轨缺陷进行了系统性研究，定义了五类状态脱轨缺陷并进行详细分析。为了解决这一问题，文中提出了一种名为StateGuard的新型深度学习框架，用于检测DEX智能合约中的状态脱轨缺陷。该框架利用智能合约拆解器将合约转化为抽象语法树(AST)，从中提取出五类依赖特征；接着，通过图优化器处理结构化数据；最后，使用图卷积网络(GCNs)对优化后的数据进行分析，以识别潜在的状态脱轨缺陷。在包含46个DEX项目和5,671个智能合约的数据集上评估后，StateGuard达到了94.25%的F1得分，并在与现有最优方法的对比实验中提升了6.29%的F1得分。为了验证其实用性，StateGuard还被应用于审计真实世界的合同并成功发现了多个新的CVE漏洞。 <div>
arXiv:2411.18935v1 Announce Type: new 
Abstract: The decentralized exchange (DEX) leverages smart contracts to trade digital assets for users on the blockchain. Developers usually develop several smart contracts into one project, implementing complex logic functions and multiple transaction operations. However, the interaction among these contracts poses challenges for developers analyzing the state logic. Due to the complex state logic in DEX projects, many critical state derailment defects have emerged in recent years. In this paper, we conduct the first systematic study of state derailment defects in DEX. We define five categories of state derailment defects and provide detailed analyses of them. Furthermore, we propose a novel deep learning-based framework StateGuard for detecting state derailment defects in DEX smart contracts. It leverages a smart contract deconstructor to deconstruct the contract into an Abstract Syntax Tree (AST), from which five categories of dependency features are extracted. Next, it implements a graph optimizer to process the structured data. At last, the optimized data is analyzed by Graph Convolutional Networks (GCNs) to identify potential state derailment defects. We evaluated StateGuard through a dataset of 46 DEX projects containing 5,671 smart contracts, and it achieved 94.25% F1-score. In addition, in a comparison experiment with state-of-the-art, StateGuard leads the F1-score by 6.29%. To further verify its practicality, we used StateGuar to audit real-world contracts and successfully authenticated multiple novel CVEs.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Game-Theoretic Approach to the Study of Blockchain's Robustness</title>
<link>https://arxiv.org/abs/2411.19175</link>
<guid>https://arxiv.org/abs/2411.19175</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、以太坊权益证明、安全性、活性、激励机制

总结:
<br />
本文针对近年来备受关注的区块链技术，尤其是以太坊权益证明（PoS）协议的鲁棒性进行了深入研究。首先，从分布式系统角度对Ethereum PoS协议进行形式化定义，并通过这一视角发现潜在的安全性和活性方面的漏洞。其次，分析了维持系统活性的关键机制——不活动泄露机制，但指出其可能导致牺牲安全性的风险。最后，运用博弈论模型探讨了理性验证者在Ethereum PoS中的策略选择，揭示了他们在何种条件下可能偏离预设协议以最大化收益。这些研究成果强调了激励机制对于区块链鲁棒性的重要性，并为设计更为健壮的区块链协议提供了洞见。 <div>
arXiv:2411.19175v1 Announce Type: new 
Abstract: Blockchains have sparked global interest in recent years, gaining importance as they increasingly influence technology and finance. This thesis investigates the robustness of blockchain protocols, specifically focusing on Ethereum Proof-of-Stake. We define robustness in terms of two critical properties: Safety, which ensures that the blockchain will not have permanent conflicting blocks, and Liveness, which guarantees the continuous addition of new reliable blocks.
  Our research addresses the gap between traditional distributed systems approaches, which classify agents as either honest or Byzantine (i.e., malicious or faulty), and game-theoretic models that consider rational agents driven by incentives. We explore how incentives impact the robustness with both approaches.
  The thesis comprises three distinct analyses. First, we formalize the Ethereum PoS protocol, defining its properties and examining potential vulnerabilities through a distributed systems perspective. We identify that certain attacks can undermine the system's robustness. Second, we analyze the inactivity leak mechanism, a critical feature of Ethereum PoS, highlighting its role in maintaining system liveness during network disruptions but at the cost of safety. Finally, we employ game-theoretic models to study the strategies of rational validators within Ethereum PoS, identifying conditions under which these agents might deviate from the prescribed protocol to maximize their rewards.
  Our findings contribute to a deeper understanding of the importance of incentive mechanisms for blockchain robustness and provide insights into designing more resilient blockchain protocols.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartLLMSentry: A Comprehensive LLM Based Smart Contract Vulnerability Detection Framework</title>
<link>https://arxiv.org/abs/2411.19234</link>
<guid>https://arxiv.org/abs/2411.19234</guid>
<content:encoded><![CDATA[
<div> 关键词: SmartLLMSentry、智能合约、区块链、大型语言模型、ChatGPT

总结:
本文介绍了SmartLLMSentry，这是一个利用大型语言模型（特别是ChatGPT和上下文训练）进行智能合约漏洞检测的新框架。与传统的基于规则的方法相比，SmartLLMSentry通过LLM有效地改进了新检测规则的集成过程。研究团队创建了一个专门针对五种随机选择的漏洞的训练和评估数据集，结果显示，在充分的数据支持下，该模型具有高达91.1%的精确匹配准确率。然而，实验发现GPT-4在规则生成方面的性能不如GPT-3。这项研究表明，SmartLLMSentry通过LLM驱动的规则整合显著提升了漏洞检测的速度和准确性，为提升区块链安全性和解决智能合约中以前未被充分探索的漏洞提供了一种新的方法。 <div>
arXiv:2411.19234v1 Announce Type: new 
Abstract: Smart contracts are essential for managing digital assets in blockchain networks, highlighting the need for effective security measures. This paper introduces SmartLLMSentry, a novel framework that leverages large language models (LLMs), specifically ChatGPT with in-context training, to advance smart contract vulnerability detection. Traditional rule-based frameworks have limitations in integrating new detection rules efficiently. In contrast, SmartLLMSentry utilizes LLMs to streamline this process. We created a specialized dataset of five randomly selected vulnerabilities for model training and evaluation. Our results show an exact match accuracy of 91.1% with sufficient data, although GPT-4 demonstrated reduced performance compared to GPT-3 in rule generation. This study illustrates that SmartLLMSentry significantly enhances the speed and accuracy of vulnerability detection through LLMdriven rule integration, offering a new approach to improving Blockchain security and addressing previously underexplored vulnerabilities in smart contracts.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning</title>
<link>https://arxiv.org/abs/2411.19335</link>
<guid>https://arxiv.org/abs/2411.19335</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, PEFT, 信息安全, 攻击向量, 防御策略

总结:
<br />
本文探讨了联邦学习中参数高效微调（FedPEFT）的新安全威胁。FedPEFT是一种用于保护隐私和提高预训练语言模型在分布式环境下的适应效率的方法。然而，文章提出了一种名为PEFT-as-an-Attack (PaaA) 的新攻击手段，该攻击利用PEFT方法如LoRA，即使在少量参数可训练及仅少数客户端恶意操作的情况下，也能绕过PLM的安全对齐，生成有害内容。实验显示，此攻击的成功率约为80%。为应对这一威胁，文章研究了包括鲁棒聚合方案（RASs）和后PEFT安全对齐（PPSA）在内的防御策略，但发现现有防御措施在处理高度异构数据分布情况时存在局限性，如DnC和ClippedClustering等先进RASs防御效果不佳；而PPSA虽能降低攻击成功率至10%以下，却会显著损害模型在目标任务上的准确性。因此，文章强调了急需开发更有效的防御机制以同时确保安全性并保持FedPEFT范式的性能。 <div>
arXiv:2411.19335v1 Announce Type: new 
Abstract: Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising paradigm for privacy-preserving and efficient adaptation of Pre-trained Language Models (PLMs) in Federated Learning (FL) settings. It preserves data privacy by keeping the data decentralized and training the model on local devices, ensuring that raw data never leaves the user's device. Moreover, the integration of PEFT methods such as LoRA significantly reduces the number of trainable parameters compared to fine-tuning the entire model, thereby minimizing communication costs and computational overhead. Despite its potential, the security implications of FedPEFT remain underexplored. This paper introduces a novel security threat to FedPEFT, termed PEFT-as-an-Attack (PaaA), which exposes how PEFT can be exploited as an attack vector to circumvent PLMs' safety alignment and generate harmful content in response to malicious prompts. Our evaluation of PaaA reveals that with less than 1% of the model's parameters set as trainable, and a small subset of clients acting maliciously, the attack achieves an approximate 80% attack success rate using representative PEFT methods such as LoRA. To mitigate this threat, we further investigate potential defense strategies, including Robust Aggregation Schemes (RASs) and Post-PEFT Safety Alignment (PPSA). However, our empirical analysis highlights the limitations of these defenses, i.e., even the most advanced RASs, such as DnC and ClippedClustering, struggle to defend against PaaA in scenarios with highly heterogeneous data distributions. Similarly, while PPSA can reduce attack success rates to below 10%, it severely degrades the model's accuracy on the target task. Our results underscore the urgent need for more effective defense mechanisms that simultaneously ensure security and maintain the performance of the FedPEFT paradigm.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Integrating Transit Signal Priority into Multi-Agent Reinforcement Learning based Traffic Signal Control</title>
<link>https://arxiv.org/abs/2411.19359</link>
<guid>https://arxiv.org/abs/2411.19359</guid>
<content:encoded><![CDATA[
<div> 关键词：Transit Signal Priority (TSP)，multi-agent reinforcement learning (MARL)，traffic signal control，value decomposition network (VDN)，intersection delay

<br /><br />总结：
本文将Transit Signal Priority (TSP)整合到基于多智能体强化学习(MARL)的交通信号控制中。首先，研究开发了一种针对两个协同工作的交叉路口的自适应信号控制系统，使用MARL和价值分解网络(VDN)架构进行集中训练，结果显示其性能略优于基于v/c为0.95的整体交叉口延迟的协调感应信号控制。接着，将训练好的信号控制智能体作为背景控制器，研究了两种事件驱动的TSP智能体方案：一种是在分散式训练和分散式执行(DTDE)框架下训练独立的TSP智能体；另一种则采用集中式训练和分散式执行(CTDE)框架以及VDN架构训练协调的TSP智能体以选择并实施跨两个交叉路口的协调TSP策略。经过训练，两种TSP方案都能有效减少公交车延误，其中独立TSP智能体相较于无TSP情况可降低两个交叉口的公交车延误达22%，而协调TSP智能体能实现27%的延误减少。在此过程中，对于多数次级街道行驶方向，仅有轻微的延迟增加。 <div>
arXiv:2411.19359v1 Announce Type: new 
Abstract: This study integrates Transit Signal Priority (TSP) into multi-agent reinforcement learning (MARL) based traffic signal control. The first part of the study develops adaptive signal control based on MARL for a pair of coordinated intersections in a microscopic simulation environment. The two agents, one for each intersection, are centrally trained using a value decomposition network (VDN) architecture. The trained agents show slightly better performance compared to coordinated actuated signal control based on overall intersection delay at v/c of 0.95. In the second part of the study the trained signal control agents are used as background signal controllers while developing event-based TSP agents. In one variation, independent TSP agents are formulated and trained under a decentralized training and decentralized execution (DTDE) framework to implement TSP at each intersection. In the second variation, the two TSP agents are centrally trained under a centralized training and decentralized execution (CTDE) framework and VDN architecture to select and implement coordinated TSP strategies across the two intersections. In both cases the agents converge to the same bus delay value, but independent agents show high instability throughout the training process. For the test runs, the two independent agents reduce bus delay across the two intersections by 22% compared to the no TSP case while the coordinated TSP agents achieve 27% delay reduction. In both cases, there is only a slight increase in delay for a majority of the side street movements.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Local Information Aggregation based Multi-Agent Reinforcement Learning for Robot Swarm Dynamic Task Allocation</title>
<link>https://arxiv.org/abs/2411.19526</link>
<guid>https://arxiv.org/abs/2411.19526</guid>
<content:encoded><![CDATA[
<div> 关键词：动态环境、任务分配、机器人集群、局部信息聚合、分布式部分可观测马尔可夫决策过程 (Dec-POMDP)、LIA_MADDPG算法、集中式训练与分布式执行 (CTDE)

总结:<br />
本文研究了如何针对动态环境优化机器人集群的任务分配问题，提出了一种利用分布式部分可观测马尔可夫决策过程(Dec-POMDP)的新框架。该框架设计了一个名为局部信息聚合多智能体深度确定性策略梯度（LIA_MADDPG）的算法，实现了集中式训练和分布式执行相结合。其中，LIA模块在训练阶段负责从邻近机器人收集关键数据以提升决策效率；在执行阶段，则提出了根据变化和部分可观测的环境条件动态调整任务分配的策略改进方法。实验结果显示，LIA模块可以无缝融入基于CTDE的多种MARL方法，显著提升了性能。相比于六种传统强化学习算法和一个启发式算法，LIA_MADDPG展现出了更优的可扩展性、对环境变化的快速适应能力以及维持稳定性和收敛速度的能力，证实了其在动态环境下通过增强局部协作和自适应策略执行来有效改善机器人集群任务分配的潜力。 <div>
arXiv:2411.19526v1 Announce Type: new 
Abstract: In this paper, we explore how to optimize task allocation for robot swarms in dynamic environments, emphasizing the necessity of formulating robust, flexible, and scalable strategies for robot cooperation. We introduce a novel framework using a decentralized partially observable Markov decision process (Dec_POMDP), specifically designed for distributed robot swarm networks. At the core of our methodology is the Local Information Aggregation Multi-Agent Deep Deterministic Policy Gradient (LIA_MADDPG) algorithm, which merges centralized training with distributed execution (CTDE). During the centralized training phase, a local information aggregation (LIA) module is meticulously designed to gather critical data from neighboring robots, enhancing decision-making efficiency. In the distributed execution phase, a strategy improvement method is proposed to dynamically adjust task allocation based on changing and partially observable environmental conditions. Our empirical evaluations show that the LIA module can be seamlessly integrated into various CTDE-based MARL methods, significantly enhancing their performance. Additionally, by comparing LIA_MADDPG with six conventional reinforcement learning algorithms and a heuristic algorithm, we demonstrate its superior scalability, rapid adaptation to environmental changes, and ability to maintain both stability and convergence speed. These results underscore LIA_MADDPG's outstanding performance and its potential to significantly improve dynamic task allocation in robot swarms through enhanced local collaboration and adaptive strategy execution.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Secure Filtering against Spatio-Temporal False Data under Asynchronous Sampling</title>
<link>https://arxiv.org/abs/2411.19765</link>
<guid>https://arxiv.org/abs/2411.19765</guid>
<content:encoded><![CDATA[
<div> 关键词：状态估计、连续LTI系统、非周期性采样、异步采样、攻击防护

总结:

本文针对存在非周期性和异步采样测量值情况下，连续线性时不变（LTI）系统的状态估计问题进行了研究。文章考虑了传感器通过未受保护的通信通道向融合中心传输测量值及时间戳的过程中，系统可能遭受包括篡改测量值、篡改时间戳以及混合恶意活动等攻击。为应对这类更强大的攻击，文中提出了一种分散式局部估计算法，每个传感器根据其自身的测量数据以异步方式维护本地状态估计。通过时间预测和事件触发的方式实现局部状态同步与融合。当采样时间无病态情况时，证明在没有攻击的情况下，本地估计可恢复到最优卡尔曼估计。在存在攻击的情况下，文章提出了采用$\ell_1$范数正则化的最小二乘问题生成安全估计，并确保在满足可观测性冗余条件下误差保持有界。最后，通过对IEEE 14-bus系统的基准案例分析展示了所提算法的有效性。<br /><br /> <div>
arXiv:2411.19765v1 Announce Type: new 
Abstract: This paper addresses the state estimation problem in continuous LTI systems under attacks with non-periodic and asynchronous sampled measurements. The non-periodic and asynchronous sampling requires sensors to transmit not only the measurement values but also the sampling time-stamps to the fusion center via unprotected communication channels. This communication scheme leaves the system vulnerable to a variety of malicious activities such as (i) manipulating measurement values, (ii) manipulating time-stamps, (iii) hybrid manipulations such as generating fake measurements or eliminating the measurement. To deal with such more powerful attacks, we propose a decentralized local estimation algorithm where each sensor maintains its local state estimate based on its measurements in an asynchronous fashion. The local states are synchronized by time-prediction and fused in an event-triggered manner. In the absence of attacks, local estimates are proved to recover the optimal Kalman estimation by our carefully designed weighted least square problem, given that the sample time is non-pathological. In the presence of attacks, an $\ell_1$ regularized least square problem is proposed to generate secure estimates with uniformly bounded error as long as the observability redundancy is satisfied. The effectiveness of the proposed algorithm is demonstrated through a benchmark example of the IEEE 14-bus system.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing AI microscopy for foodborne bacterial classification via adversarial domain adaptation across optical and biological variability</title>
<link>https://arxiv.org/abs/2411.19514</link>
<guid>https://arxiv.org/abs/2411.19514</guid>
<content:encoded><![CDATA[
<div> 关键词：AI赋能显微镜、对抗性领域适应、多域适应、细菌分类、食品安全

<br />
总结:
本文提出了一种利用AI赋能显微镜进行食品中病原菌快速检测的方法，通过对抗性领域适应增强了算法对不同条件下细菌图像识别的泛化能力。研究比较了单目标和多域适应方法在六个代表性菌株分类中的性能。采用EfficientNetV2作为基础架构，结合细粒度特征提取技术处理小目标图像，并运用少量样本学习。通过训练模型对源域（控制条件下的相位对比显微镜数据）进行学习，再在目标域（包括明亮场显微镜、低放大倍数以及延长培养时间等情况）下进行评估，结果显示，单域适应网络(DANNs)能分别提升20x、20x-5h和BF目标域的分类准确率最高达54.45%、43.44%和31.67%，同时对源域的影响极小。而多域适应网络(MDANNs)在BF和20x域表现更优。Grad-CAM和t-SNE可视化验证了模型能够在各种条件下学习到领域不变的特征。这项研究为实现细菌分类提供了一个可扩展和适应性强的框架，减少了对复杂样本准备的依赖，有助于在分散和资源有限的环境中应用，从而更好地保障食品安全与质量。 <div>
arXiv:2411.19514v1 Announce Type: cross 
Abstract: Rapid detection of foodborne bacteria is critical for food safety and quality, yet traditional culture-based methods require extended incubation and specialized sample preparation. This study addresses these challenges by i) enhancing the generalizability of AI-enabled microscopy for bacterial classification using adversarial domain adaptation and ii) comparing the performance of single-target and multi-domain adaptation. Three Gram-positive (Bacillus coagulans, Bacillus subtilis, Listeria innocua) and three Gram-negative (E. coli, Salmonella Enteritidis, Salmonella Typhimurium) strains were classified. EfficientNetV2 served as the backbone architecture, leveraging fine-grained feature extraction for small targets. Few-shot learning enabled scalability, with domain-adversarial neural networks (DANNs) addressing single domains and multi-DANNs (MDANNs) generalizing across all target domains. The model was trained on source domain data collected under controlled conditions (phase contrast microscopy, 60x magnification, 3-h bacterial incubation) and evaluated on target domains with variations in microscopy modality (brightfield, BF), magnification (20x), and extended incubation to compensate for lower resolution (20x-5h). DANNs improved target domain classification accuracy by up to 54.45% (20x), 43.44% (20x-5h), and 31.67% (BF), with minimal source domain degradation (<4.44%). MDANNs achieved superior performance in the BF domain and substantial gains in the 20x domain. Grad-CAM and t-SNE visualizations validated the model's ability to learn domain-invariant features across diverse conditions. This study presents a scalable and adaptable framework for bacterial classification, reducing reliance on extensive sample preparation and enabling application in decentralized and resource-limited environments.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eden: An Provably Secure, Ultra-Fast, and Fully Decentralized Blockchain Interoperability Protocol</title>
<link>https://arxiv.org/abs/2311.17454</link>
<guid>https://arxiv.org/abs/2311.17454</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、互操作性、Eden、SparkleX、零知识 MapReduce

总结:
<br />
随着区块链生态系统的成长和多样化，不同区块链网络间的无缝互操作性变得至关重要。本文介绍了用于SparkleX的Eden协议，它是一种基于零知识 MapReduce 框架的弹性去中心化使者网络，实现了超快速、安全且完全去中心化的跨链通信。Eden的设计、强大的安全性模型以及确保其在网络环境压力下仍具有弹性和韧性的创新机制都得到了深入探讨。 <div>
arXiv:2311.17454v2 Announce Type: replace 
Abstract: As the blockchain ecosystem grows and diversifies, seamless interoperability between blockchain networks has become essential. Interoperability not only enhances the usability and reach of individual chains but also fosters collaboration, unlocking new opportunities for decentralized applications. In this paper, we introduce Eden, the parallel-verified messaging protocol powering SparkleX. Eden is an elastic, decentralized envoy network built on a zero-knowledge MapReduce framework (i.e., ZK-MapReduce), enabling ultra-fast, secure, and fully decentralized cross-chain communication. We explore Eden's design, its robust security model, and the innovative mechanisms that ensure its elasticity and resilience, even in demanding network environments.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Joint Resource Optimization, Computation Offloading and Resource Slicing for Multi-Edge Traffic-Cognitive Networks</title>
<link>https://arxiv.org/abs/2411.17782</link>
<guid>https://arxiv.org/abs/2411.17782</guid>
<content:encoded><![CDATA[
<div> 关键词: 边缘计算、资源分配、任务卸载、Stackelberg博弈、贝叶斯优化

总结:<br />
本文探讨了边缘计算环境下，平台与边缘服务器（ESs）之间动态交互的日益变化态势。面对高效资源利用和严格的服务质量（QoS）要求，需要对ESs进行激励并优化平台运营目标。研究内容涉及一个多智能体系统，其中平台和ESs都是具有自我利益的实体。文章提出了一个基于Stackelberg博弈的新型框架来建模各利益相关者之间的互动，并采用一种基于贝叶斯优化的集中式算法解决联合优化问题。针对因隐私顾虑带来的实际信息收集挑战，文中进一步设计了一种利用神经网络优化和隐私保护信息交换协议的分布式解决方案。大量的数值评估证明了所提机制相比现有基准能实现更优性能。 <div>
arXiv:2411.17782v1 Announce Type: new 
Abstract: The evolving landscape of edge computing envisions platforms operating as dynamic intermediaries between application providers and edge servers (ESs), where task offloading is coupled with payments for computational services. Ensuring efficient resource utilization and meeting stringent Quality of Service (QoS) requirements necessitates incentivizing ESs while optimizing the platforms operational objectives. This paper investigates a multi-agent system where both the platform and ESs are self-interested entities, addressing the joint optimization of revenue maximization, resource allocation, and task offloading. We propose a novel Stackelberg game-based framework to model interactions between stakeholders and solve the optimization problem using a Bayesian Optimization-based centralized algorithm. Recognizing practical challenges in information collection due to privacy concerns, we further design a decentralized solution leveraging neural network optimization and a privacy-preserving information exchange protocol. Extensive numerical evaluations demonstrate the effectiveness of the proposed mechanisms in achieving superior performance compared to existing baselines.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>CrypQ: A Database Benchmark Based on Dynamic, Ever-Evolving Ethereum Data</title>
<link>https://arxiv.org/abs/2411.17913</link>
<guid>https://arxiv.org/abs/2411.17913</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据库系统、动态数据、区块链、CrypQ、查询优化器

总结:
现代数据库系统需要处理随时间演变的动态数据，但许多流行基准测试未能充分评估这一特性。本文引入了一个名为CrypQ的新数据库基准，它利用公开的、动态变化的以太坊区块链数据，提供了反映现实和活跃加密货币市场中不可预测性的大规模、不断进化的数据集。文章详细描述了CrypQ的数据模式、创建数据快照和更新序列的方法以及一系列相关的SQL查询。作为示例，作者展示了使用CrypQ如何在复杂、演进的数据分布上评价基于成本的查询优化器，这些分布具有真实世界的偏斜性和依赖性。<br /><br /> <div>
arXiv:2411.17913v1 Announce Type: new 
Abstract: Modern database systems are expected to handle dynamic data whose characteristics may evolve over time. Many popular database benchmarks are limited in their ability to evaluate this dynamic aspect of the database systems. Those that use synthetic data generators often fail to capture the complexity and unpredictable nature of real data, while most real-world datasets are static and difficult to create high-volume, realistic updates for. This paper introduces CrypQ, a database benchmark leveraging dynamic, public Ethereum blockchain data. CrypQ offers a high-volume, ever-evolving dataset reflecting the unpredictable nature of a real and active cryptocurrency market. We detail CrypQ's schema, procedures for creating data snapshots and update sequences, and a suite of relevant SQL queries. As an example, we demonstrate CrypQ's utility in evaluating cost-based query optimizers on complex, evolving data distributions with real-world skewness and dependencies.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging A New GAN-based Transformer with ECDH Crypto-system for Enhancing Energy Theft Detection in Smart Grid</title>
<link>https://arxiv.org/abs/2411.18023</link>
<guid>https://arxiv.org/abs/2411.18023</guid>
<content:encoded><![CDATA[
<div> 关键词：能源盗窃检测、分裂学习、GAN-Transformer、隐私泄漏保护、变压器架构

总结:
<br />
本文提出了一种基于GAN-Transformer的新型分裂学习框架，用于提高能源盗窃检测的准确性并保障用户数据隐私。该框架利用变压器架构处理能源消耗数据长程依赖性的优势，提升了检测效果。为应对传统分裂学习中的隐私泄露问题，文中创新性地采用了一种基于掩码的方法，这是首次将其应用于针对AI敌手的分裂学习场景中，有效保护了敏感信息。实验结果显示，该提议的框架不仅达到了与传统方法相当的检测精度，而且显著增强了隐私保护力度。这表明GAN-Transformer分裂学习框架在能源盗窃检测领域具有高效且安全的应用潜力。 <div>
arXiv:2411.18023v1 Announce Type: new 
Abstract: Detecting energy theft is vital for effectively managing power grids, as it ensures precise billing and prevents financial losses. Split-learning emerges as a promising decentralized machine learning technique for identifying energy theft while preserving user data confidentiality. Nevertheless, traditional split learning approaches are vulnerable to privacy leakage attacks, which significantly threaten data confidentiality. To address this challenge, we propose a novel GAN-Transformer-based split learning framework in this paper. This framework leverages the strengths of the transformer architecture, which is known for its capability to process long-range dependencies in energy consumption data. Thus, it enhances the accuracy of energy theft detection without compromising user privacy. A distinctive feature of our approach is the deployment of a novel mask-based method, marking a first in its field to effectively combat privacy leakage in split learning scenarios targeted at AI-enabled adversaries. This method protects sensitive information during the model's training phase. Our experimental evaluations indicate that the proposed framework not only achieves accuracy levels comparable to conventional methods but also significantly enhances privacy protection. The results underscore the potential of the GAN-Transformer split learning framework as an effective and secure tool in the domain of energy theft detection.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hidden Data Privacy Breaches in Federated Learning</title>
<link>https://arxiv.org/abs/2411.18269</link>
<guid>https://arxiv.org/abs/2411.18269</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、数据重建攻击、恶意代码注入、高分辨率图像、防御方法

<br /><br />总结:

本文提出了一个针对联邦学习(Federated Learning)的新式数据重建攻击方法。该攻击利用恶意代码注射技术，结合独特的稀疏编码设计和区块划分策略，能够在不引起模型明显变化的情况下，隐秘地嵌入隐藏模型并系统性地抽取敏感数据。通过基于斐波那契指数的设计实现高效结构化的数据检索，而区块划分则增强了处理大规模及高分辨率图像的能力。实验结果显示，与五种最先进的数据重建攻击方法相比，本文的方法在五个不同的检测方法下表现更优，且能够逃避现有的数据重建防御手段，同时适用于FedAVG和FedSGD两种联邦学习场景。文章强调了开发者需要针对此类新威胁开发新的防御措施，并承诺将在论文被接受后开源相关代码。 <div>
arXiv:2411.18269v1 Announce Type: new 
Abstract: Federated Learning (FL) emerged as a paradigm for conducting machine learning across broad and decentralized datasets, promising enhanced privacy by obviating the need for direct data sharing. However, recent studies show that attackers can steal private data through model manipulation or gradient analysis. Existing attacks are constrained by low theft quantity or low-resolution data, and they are often detected through anomaly monitoring in gradients or weights. In this paper, we propose a novel data-reconstruction attack leveraging malicious code injection, supported by two key techniques, i.e., distinctive and sparse encoding design and block partitioning. Unlike conventional methods that require detectable changes to the model, our method stealthily embeds a hidden model using parameter sharing to systematically extract sensitive data. The Fibonacci-based index design ensures efficient, structured retrieval of memorized data, while the block partitioning method enhances our method's capability to handle high-resolution images by dividing them into smaller, manageable units. Extensive experiments on 4 datasets confirmed that our method is superior to the five state-of-the-art data-reconstruction attacks under the five respective detection methods. Our method can handle large-scale and high-resolution data without being detected or mitigated by state-of-the-art data reconstruction defense methods. In contrast to baselines, our method can be directly applied to both FedAVG and FedSGD scenarios, underscoring the need for developers to devise new defenses against such vulnerabilities. We will open-source our code upon acceptance.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning with Uncertainty and Personalization via Efficient Second-order Optimization</title>
<link>https://arxiv.org/abs/2411.18385</link>
<guid>https://arxiv.org/abs/2411.18385</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Bayesian、优化方法、效率、通信成本

总结:<br />
本文提出了一种新颖的用于联邦学习（Federated Learning）的贝叶斯方法，该方法利用高效的二阶优化技术，旨在解决传统贝叶斯FL在计算和通信成本上的问题。新方法与Adam等一阶优化方法具有相似的计算成本，同时保持了贝叶斯方法对于FL的优势，如不确定性量化、个性化建模以及通过层级贝叶斯框架处理客户端间共性。实验表明，新方法在标准及个性化FL设置中均比当前最优的贝叶斯FL方法更高效且准确，不仅提高了预测精度，也改进了不确定性估计。 <div>
arXiv:2411.18385v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a promising method to collaboratively learn from decentralized and heterogeneous data available at different clients without the requirement of data ever leaving the clients. Recent works on FL have advocated taking a Bayesian approach to FL as it offers a principled way to account for the model and predictive uncertainty by learning a posterior distribution for the client and/or server models. Moreover, Bayesian FL also naturally enables personalization in FL to handle data heterogeneity across the different clients by having each client learn its own distinct personalized model. In particular, the hierarchical Bayesian approach enables all the clients to learn their personalized models while also taking into account the commonalities via a prior distribution provided by the server. However, despite their promise, Bayesian approaches for FL can be computationally expensive and can have high communication costs as well because of the requirement of computing and sending the posterior distributions. We present a novel Bayesian FL method using an efficient second-order optimization approach, with a computational cost that is similar to first-order optimization methods like Adam, but also provides the various benefits of the Bayesian approach for FL (e.g., uncertainty, personalization), while also being significantly more efficient and accurate than SOTA Bayesian FL methods (both for standard as well as personalized FL settings). Our method achieves improved predictive accuracies as well as better uncertainty estimates as compared to the baselines which include both optimization based as well as Bayesian FL methods.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proving and Rewarding Client Diversity to Strengthen Resilience of Blockchain Networks</title>
<link>https://arxiv.org/abs/2411.18401</link>
<guid>https://arxiv.org/abs/2411.18401</guid>
<content:encoded><![CDATA[
<div> 关键词: 客户端多样性、以太坊区块链、网络韧性、经济激励、verifiable execution

<br /><br />总结:
本文关注的是以太坊区块链中的客户端多样性问题，提出了一种新的概念框架以增强网络韧性的系统属性。该框架的核心目标在于利用经济激励和可验证执行来促进少数客户端的采用，从而打造更为健壮的区块链生态系统。具体来说，文章建议明确并可验证地识别出协议参与者的客户端实现，并通过向使用少数客户端的参与者提供更高的参与奖励来鼓励其使用。此外，文中针对以太坊提出了这一框架的详细蓝图。该提议对于提升区块链客户端多样性具有变革性意义，并可应用于增强任何去中心化分布式系统的韧性。 <div>
arXiv:2411.18401v1 Announce Type: new 
Abstract: Client diversity in the Ethereum blockchain refers to the use of multiple independent implementations of the Ethereum protocol. This effectively enhances network resilience by reducing reliance on any single software client implementation. With client diversity, a single bug cannot tear the whole network down. However, despite multiple production-grade client implementations being available, there is still a heavily skewed distribution of clients in Ethereum. This is a concern for the community. In this paper, we introduce a novel conceptual framework for client diversity. The core goal is to improve the network resilience as a systemic property. Our key insight is to leverage economic incentives and verifiable execution to encourage the adoption of minority clients, thereby fostering a more robust blockchain ecosystem. Concretely, we propose to unambiguously and provably identify the client implementation used by any protocol participant, and to use this information to incentivize the usage of minority clients by offering higher participation rewards. We outline a detailed blueprint for our conceptual framework, in the realm of Ethereum. Our proposal is a game changer for improving client diversity of blockchains. Ultimately, it applies to strengthening the resilience of any decentralized distributed systems.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Planning of Carbon-Neutral Heating Demand Coverage Under Uncertainty in a Coupled Multi-Energy Grid</title>
<link>https://arxiv.org/abs/2305.04577</link>
<guid>https://arxiv.org/abs/2305.04577</guid>
<content:encoded><![CDATA[
<div> 关键词：多能源网格、消费者行为、不确定性、鲁棒优化、碳中和

<br /><br />总结:
本文提出了一种以消费者为中心的电网规划方法，针对燃气和区域供暖与电力网融合的多能源网格系统。文章指出实际情况下，消费者的供暖技术采纳行为受成本和政府法规影响，具有高度不确定性，这增加了电网扩展投资的风险。为应对这一挑战，论文运用鲁棒优化模型来处理能源价格的不确定性，采用比例偏差的区间不确定性进行建模，使规划者能够预测不同地区的特定供暖技术采纳率并优先考虑必要的电网扩张。研究以汉堡为例进行了应用，结果表明在高密度地区，区域能源供暖扩展是实现碳中和的低风险投资；而在较低密度地区，电能驱动的分布式热泵成为支持方案；当电气化扩展不切实际时，氢气管网成为可行选项。随着不确定性的增加，解决方案将变得更加保守。 <div>
arXiv:2305.04577v3 Announce Type: replace 
Abstract: Integrating the gas and district heating with the electrical grid in a multi-energy grid has been shown to provide flexibility and prevent bottlenecks in the operation of electrical distribution grids. This integration assumes a top-down grid planning approach and a perfect knowledge of consumer behaviour. In reality, consumers decides whether to adopt a heating technology based on costs and government regulation. This behavior is highly uncertain and depends on fluctuations in heating technology costs and energy prices. The uncertainty associated with consumer behavior increases the risk of investment in grid expansion. In response to this challenge, this paper proposes an approach with the consumer at the center of the planning method. Robust optimization is used to model the uncertainty in prices to reduce the risk of investment in grid expansion. The uncertainty in energy prices is modeled using interval uncertainty with a proportional deviation. This allows planners, operators and regulators to predict the adoption rate of certain heating technology in different geographical areas and prioritize the expansion of specific grids where they are required. By minimizing a cost function subject to robust constraints, the strategy ensures robustness against uncertainties in energy prices. This robust optimization approach is applied to Hamburg as a case study. The result of the optimization represents the consumer's decision. The impact of the consumer's decision on the electrical grid is analzed on different benchmark distribution grids. The study concludes that district heating expansion in high-density areas is a low-risk investment for carbon neutrality. In less dense areas, electrification supports decentralized heat pumps. Meanwhile, hydrogen gas grids are viable where electric expansion is impractical. Increased uncertainty leads to more conservative solutions.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning in Chemical Engineering: A Tutorial on a Framework for Privacy-Preserving Collaboration Across Distributed Data Sources</title>
<link>https://arxiv.org/abs/2411.16737</link>
<guid>https://arxiv.org/abs/2411.16737</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning、化学工程、数据隐私、制造优化、TensorFlow Federated

总结:
本文介绍了Federated Learning（联邦学习）这一分布式机器学习方法，尤其针对化学工程领域的应用提供了易于理解的介绍。文章通过实例和手把手教程探讨了联邦学习在制造业优化、多模态数据分析和药物发现等任务中的运用，并着重讨论了如何保护专有信息和管理分布式数据集的独特挑战。文中使用$\texttt{Flower}$和$\texttt{TensorFlow Federated}$等关键框架构建了教程，旨在为化学工程师提供适用于特定需求的FL工具。通过对比FL与集中式学习在三个与化工应用相关的不同数据集上的性能，结果显示FL通常能保持或提高分类性能，尤其是在处理复杂和异构数据时表现更优。最后，文章指出了联邦学习面临的开放性挑战及现有的改进措施和策略。 <div>
arXiv:2411.16737v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized machine learning approach that has gained attention for its potential to enable collaborative model training across clients while protecting data privacy, making it an attractive solution for the chemical industry. This work aims to provide the chemical engineering community with an accessible introduction to the discipline. Supported by a hands-on tutorial and a comprehensive collection of examples, it explores the application of FL in tasks such as manufacturing optimization, multimodal data integration, and drug discovery while addressing the unique challenges of protecting proprietary information and managing distributed datasets. The tutorial was built using key frameworks such as $\texttt{Flower}$ and $\texttt{TensorFlow Federated}$ and was designed to provide chemical engineers with the right tools to adopt FL in their specific needs. We compare the performance of FL against centralized learning across three different datasets relevant to chemical engineering applications, demonstrating that FL will often maintain or improve classification performance, particularly for complex and heterogeneous data. We conclude with an outlook on the open challenges in federated learning to be tackled and current approaches designed to remediate and improve this framework.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain Meets LLMs: A Living Survey on Bidirectional Integration</title>
<link>https://arxiv.org/abs/2411.16809</link>
<guid>https://arxiv.org/abs/2411.16809</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、多模态、区块链技术、安全性、隐私保护

<br /><br />总结:

本文探讨了大型语言模型与区块链技术的融合及其潜在优势和发展前景。随着大型语言模型和可解释性研究领域的显著进步，以及对安全性和隐私问题的关注，区块链技术因其去中心化、防篡改等特性提供了新的解决方案。文章分析了两种技术各自的优势及限制，并从两个方向研究它们的结合：一是将大型语言模型应用于区块链，提出六种发展方向并探索改善区块链技术及其应用场景的方法；二是利用区块链技术的特点来弥补大型语言模型的不足，并发掘其在多个领域的应用潜力。 <div>
arXiv:2411.16809v1 Announce Type: new 
Abstract: In the domain of large language models, considerable advancements have been attained in multimodal large language models and explainability research, propelled by the continuous technological progress and innovation. Nonetheless, security and privacy concerns continue to pose as prominent challenges in this field. The emergence of blockchain technology, marked by its decentralized nature, tamper-proof attributes, distributed storage functionality, and traceability, has provided novel approaches for resolving these issues. Both of these technologies independently hold vast potential for development; yet, their combination uncovers substantial cross-disciplinary opportunities and growth prospects. The current research tendencies are increasingly concentrating on the integration of blockchain with large language models, with the aim of compensating for their respective limitations through this fusion and promoting further technological evolution. In this study, we evaluate the advantages and developmental constraints of the two technologies, and explore the possibility and development potential of their combination. This paper primarily investigates the technical convergence in two directions: Firstly, the application of large language models to blockchain, where we identify six major development directions and explore solutions to the shortcomings of blockchain technology and their application scenarios; Secondly, the application of blockchain technology to large language models, leveraging the characteristics of blockchain to remedy the deficiencies of large language models and exploring its application potential in multiple fields.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EvoChain: a Recovery Approach for Permissioned Blockchain Applications</title>
<link>https://arxiv.org/abs/2411.16976</link>
<guid>https://arxiv.org/abs/2411.16976</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、EvoChain、数据红动作业、时间限制条件、Hyperledger Fabric

总结:<br />
本文介绍了EvoChain，这是一个针对区块链技术的智能合约框架扩展，旨在为数据红动作业和有条件的数据恢复引入受控可变性。该机制允许在生效不可变性之前的一段宽限期内进行错误修正。通过基于Hyperledger Fabric的供应链应用WineTracker进行了验证，EvoChain使某些用户能够在不影响区块链安全性和保持数据一致性的情况下撤销不必要的操作。性能评估显示，这种方法带来了功能性优势的同时，仅产生了轻微的额外开销。 <div>
arXiv:2411.16976v1 Announce Type: new 
Abstract: Blockchain technology supports decentralized, consensus-driven data storage and processing, ensuring integrity and auditability. It is increasingly adopted for use cases with multiple stakeholders with shared ownership scenarios like digital identity and supply chain management. However, real-world deployments face challenges with mistakes and intrusions. This article presents EvoChain, a chaincode framework extension introducing controlled mutability for data redaction and recovery under time-limited or specific conditions. This mechanism allows corrections during a grace period before immutability takes effect. We validated our approach using WineTracker, a Hyperledger Fabric-based supply chain application. It enables some users to cancel unwanted operations while preserving the blockchain security and maintaining data consistency. Performance evaluations showed minimal overhead with functional benefits.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Storage And Self-Sovereign Identity For Document-Based Claims</title>
<link>https://arxiv.org/abs/2411.16987</link>
<guid>https://arxiv.org/abs/2411.16987</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化身份系统、用户隐私、数字文档验证、SoverClaim、Hyperledger Indy、Storj、去中心化、自主权身份、文档存储、透明审计日志

<br /><br />总结:
本文介绍了SoverClaim，这是一个基于去中心化理念设计的身份管理和数字文档验证原型应用。它旨在解决中心化身份系统可能带来的用户隐私问题和对在线活动追踪或数据泄露的风险。SoverClaim利用了Hyperledger Indy区块链技术来发行和展示具有透明审计日志的自主权数字身份，并结合Storj的去中心化点对点服务实现安全、去中心化的文档存储及后续删除功能。该原型实现了将自主权身份与基于文档的申明无缝整合，并能在不到750毫秒的时间内完成响应，适合及时的人机交互场景。 <div>
arXiv:2411.16987v1 Announce Type: new 
Abstract: Users increasingly rely on identity providers for accessing online services and resources. However, centralized identity systems often compromise user privacy due to online activity tracking or data breaches. At the same time, many online services require digital copies of physical documents for validation in claims processes, such as providing proof of residence for opening a bank account or verifying medical images for health insurance claims. With centralized solutions, privacy depends entirely on the trusted party, but there are emerging decentralized approaches that offer greater transparency.
  This article introduces SoverClaim, a decentralized application prototype that empowers users to control their identity and also allows them to present digital documents with privacy. SoverClaim leverages Hyperledger Indy, a blockchain for issuing and presenting self-sovereign digital identities with transparent audit logs, and Storj, a decentralized peer-to-peer service, for secure and decentralized document storage and subsequent deletion. The prototype demonstrates the seamless integration of self-sovereign identities and document-based claims, achieving response times of under 750 ms, making it suitable for timely human interactions.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing Vulnerability in Smart Contracts: The Role of Code Complexity Metrics in Security Analysis</title>
<link>https://arxiv.org/abs/2411.17343</link>
<guid>https://arxiv.org/abs/2411.17343</guid>
<content:encoded><![CDATA[
<div> 关键词: code complexity metrics, vulnerable code, smart contracts, Solidity, vulnerability assessment

总结:<br />
本文研究了代码复杂性指标在识别Solidity智能合约漏洞中的作用。文章强调了代码复杂性度量作为安全性评估补充特征的重要性，并探讨了各项指标的关联性、与漏洞的相关性以及区分脆弱代码和中立代码的能力。通过对21项复杂性指标分析，发现某些指标之间存在高相关性和冗余性，但单个指标与漏洞之间的相关性较弱。尽管如此，所有指标都能有效地区分脆弱代码和中立代码，大多数复杂性指标在脆弱代码中的值要高于中立代码，仅有三个例外。 <div>
arXiv:2411.17343v1 Announce Type: new 
Abstract: Codes with specific characteristics are more exposed to security vulnerabilities. Studies have revealed that codes that do not adhere to best practices are more challenging to verify and maintain, increasing the likelihood of unnoticed or unintentionally introduced vulnerabilities. Given the crucial role of smart contracts in blockchain systems, ensuring their security and conducting thorough vulnerability analysis is critical. This study investigates the use of code complexity metrics as indicators of vulnerable code in Solidity smart contracts. We highlight the significance of complexity metrics as valuable complementary features for vulnerability assessment and provide insights into the individual power of each metric. By analyzing 21 complexity metrics, we explored their interrelation, association with vulnerability, discriminative power, and mean values in vulnerable versus neutral codes. The results revealed some high correlations and potential redundancies among certain metrics, but weak correlations between each independent metric and vulnerability. Nevertheless, we found that all metrics can effectively discriminate between vulnerable and neutral codes, and most complexity metrics, except for three, exhibited higher values in vulnerable codes.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Decentralized AI (DeAI)</title>
<link>https://arxiv.org/abs/2411.17461</link>
<guid>https://arxiv.org/abs/2411.17461</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能(AI)，集中化，区块链，去中心化AI(DeAI)，系统化知识(SoK)

总结:
<br />
本文探讨了人工智能集中化所带来的挑战，如单点故障、内在偏见、数据隐私和可扩展性问题，特别是在封闭源码大型语言模型中的问题。为解决这些问题，区块链为基础的去中心化AI（DeAI）被提出作为一种有前景的解决方案。该研究进行了关于区块链基础DeAI解决方案的系统化知识(SoK)梳理，提出了基于模型生命周期对现有DeAI协议进行分类的taxonomy。通过这个分类体系，作者清晰地概述了DeAI协议的现状并分析了其异同点。文章进一步分析了区块链在DeAI中的作用，阐述了区块链特性如何增强AI过程的安全性、透明度和可信度，并确保公平激励AI数据和模型贡献者。同时，文中还指出了开发DeAI协议的关键洞察和研究空白，强调了几条未来研究的重要方向。 <div>
arXiv:2411.17461v1 Announce Type: new 
Abstract: The centralization of Artificial Intelligence (AI) poses significant challenges, including single points of failure, inherent biases, data privacy concerns, and scalability issues. These problems are especially prevalent in closed-source large language models (LLMs), where user data is collected and used without transparency. To mitigate these issues, blockchain-based decentralized AI (DeAI) has emerged as a promising solution. DeAI combines the strengths of both blockchain and AI technologies to enhance the transparency, security, decentralization, and trustworthiness of AI systems. However, a comprehensive understanding of state-of-the-art DeAI development, particularly for active industry solutions, is still lacking. In this work, we present a Systematization of Knowledge (SoK) for blockchain-based DeAI solutions. We propose a taxonomy to classify existing DeAI protocols based on the model lifecycle. Based on this taxonomy, we provide a structured way to clarify the landscape of DeAI protocols and identify their similarities and differences. We analyze the functionalities of blockchain in DeAI, investigating how blockchain features contribute to enhancing the security, transparency, and trustworthiness of AI processes, while also ensuring fair incentives for AI data and model contributors. In addition, we identify key insights and research gaps in developing DeAI protocols, highlighting several critical avenues for future research.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Metaverse Innovation Canvas: A Tool for Extended Reality Product/Service Development</title>
<link>https://arxiv.org/abs/2411.17541</link>
<guid>https://arxiv.org/abs/2411.17541</guid>
<content:encoded><![CDATA[
<div> 关键词：augmented reality (AR), virtual reality (VR), metaverse, startup failure, Metaverse Innovation Canvas (MIC)

<br /><br />总结:
本文针对虚拟现实(VR)和增强现实(AR)初创企业在新兴元宇宙领域中的失败原因进行了深入研究。通过分析2016年至2022年间29家失败的AR/VR初创企业案例，确定了关键问题，包括缺乏可扩展性、用户体验不佳、价值主张不明确以及未能解决特定用户问题等。基于这些发现，文章提出了适用于XR产品和服务的创新框架——Metaverse Innovation Canvas (MIC)。该画布引导创业者定义用户问题、阐述独特的XR价值主张、评估如运动交互负载这样的可用性因素、考虑社交/虚拟经济机会以及规划长期可扩展性。与通用模型不同，MIC专门的模块促使从一开始就关注到XR的关键因素。通过对五家失败创业公司的案例进行专家测试，结果显示该工具能有效提前揭示被忽视的可用性问题和技术限制，从而提高未来元宇宙初创企业的可行性。 <div>
arXiv:2411.17541v1 Announce Type: new 
Abstract: This study investigated the factors contributing to the failure of augmented reality (AR) and virtual reality (VR) startups in the emerging metaverse landscape. Through an in-depth analysis of 29 failed AR/VR startups from 2016 to 2022, key pitfalls were identified, such as a lack of scalability, poor usability, unclear value propositions, and the failure to address specific user problems. Grounded in these findings, we developed the Metaverse Innovation Canvas (MIC) a tailored business ideation framework for XR products and services. The canvas guides founders to define user problems, articulate unique XR value propositions, evaluate usability factors such as the motion-based interaction load, consider social/virtual economy opportunities, and plan for long term scalability. Unlike generalized models, specialized blocks prompt the consideration of critical XR factors from the outset. The canvas was evaluated through expert testing with startup consultants on five failed venture cases. The results highlighted the tool's effectiveness in surfacing overlooked usability issues and technology constraints upfront, enhancing the viability of future metaverse startups.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinML-Chain: A Blockchain-Integrated Dataset for Enhanced Financial Machine Learning</title>
<link>https://arxiv.org/abs/2411.16277</link>
<guid>https://arxiv.org/abs/2411.16277</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、金融市场、区块链技术、交易费机制、经济机制设计

<br /><br />总结:
本文探讨了机器学习在金融市场中的应用及其面临的挑战，并指出区块链技术能够解决其中的一些问题。作者提出了一种框架，该框架将高频链上数据与低频链下数据进行整合，用于研究经济机制设计中的新型问题，特别是以交易费机制为例进行了深入分析。通过线性回归、深度神经网络、XGBoost和LSTM等四种机器学习方法，展示了该框架构建的数据集能推动金融研究并增进对区块链驱动系统的理解。此外，作者开源了一个由该框架生成的样例数据集和处理流程代码，为金融机器学习提供了一个基准，并促进了研究工作的可重复性、透明度和协作。这一举措旨在支持研究者在此基础上进一步拓展工作，发展创新性的金融机器学习模型，从而推动机器学习、区块链与经济学之间的交叉领域研究进步。 <div>
arXiv:2411.16277v1 Announce Type: cross 
Abstract: Machine learning is critical for innovation and efficiency in financial markets, offering predictive models and data-driven decision-making. However, challenges such as missing data, lack of transparency, untimely updates, insecurity, and incompatible data sources limit its effectiveness. Blockchain technology, with its transparency, immutability, and real-time updates, addresses these challenges. We present a framework for integrating high-frequency on-chain data with low-frequency off-chain data, providing a benchmark for addressing novel research questions in economic mechanism design. This framework generates modular, extensible datasets for analyzing economic mechanisms such as the Transaction Fee Mechanism, enabling multi-modal insights and fairness-driven evaluations. Using four machine learning techniques, including linear regression, deep neural networks, XGBoost, and LSTM models, we demonstrate the framework's ability to produce datasets that advance financial research and improve understanding of blockchain-driven systems. Our contributions include: (1) proposing a research scenario for the Transaction Fee Mechanism and demonstrating how the framework addresses previously unexplored questions in economic mechanism design; (2) providing a benchmark for financial machine learning by open-sourcing a sample dataset generated by the framework and the code for the pipeline, enabling continuous dataset expansion; and (3) promoting reproducibility, transparency, and collaboration by fully open-sourcing the framework and its outputs. This initiative supports researchers in extending our work and developing innovative financial machine-learning models, fostering advancements at the intersection of machine learning, blockchain, and economics.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Embedded Blockchains: A Synthesis of Blockchains, Spread Spectrum Watermarking, Perceptual Hashing &amp; Digital Signatures</title>
<link>https://arxiv.org/abs/2009.00951</link>
<guid>https://arxiv.org/abs/2009.00951</guid>
<content:encoded><![CDATA[
<div> 关键词：音频视频伪造检测、区块链、加密扩频水印、感知哈希、数字签名

总结:
本文提出了一种用于检测操纵音频和视频的方案。该方案综合运用了区块链、加密扩频水印、感知哈希以及数字签名技术，称为嵌入式区块链。通过这一方案，利用区块链的数据结构——加密链接列表，进行绝对比对；使用感知哈希实现灵活比对；利用数字签名证明所有权；并借助加密扩频水印将区块链嵌入媒体背景噪声中。每个媒体记录都有其独特的区块链，其中每个区块存储描述媒体片段的信息。验证媒体完整性的问题被重新表述为逐块遍历区块链并与媒体分段进行对比的过程。如果链路断裂，则通过计算与提取到的感知哈希的差异来估计媒介操纵的程度。 <div>
arXiv:2009.00951v5 Announce Type: replace 
Abstract: In this paper we introduce a scheme for detecting manipulated audio and video. The scheme is a synthesis of blockchains, encrypted spread spectrum watermarks, perceptual hashing and digital signatures, which we call an Embedded Blockchain. Within this scheme, we use the blockchain for its data structure of a cryptographically linked list, cryptographic hashing for absolute comparisons, perceptual hashing for flexible comparisons, digital signatures for proof of ownership, and encrypted spread spectrum watermarking to embed the blockchain into the background noise of the media. So each media recording has its own unique blockchain, with each block holding information describing the media segment. The problem of verifying the integrity of the media is recast to traversing the blockchain, block-by-block, and segment-by-segment of the media. If any chain is broken, the difference in the computed and extracted perceptual hash is used to estimate the level of manipulation.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>POWQMIX: Weighted Value Factorization with Potentially Optimal Joint Actions Recognition for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.08036</link>
<guid>https://arxiv.org/abs/2405.08036</guid>
<content:encoded><![CDATA[
<div> 关键词：价值函数分解、多智能体强化学习、QMIX、最优联合动作加权、POWQMIX

总结:
本文提出了一种针对合作多智能体强化学习的价值函数分解新方法——潜在最优联合动作加权QMIX（POWQMIX），旨在解决QMIX及其变体因强加单调性约束而导致的表示能力受限问题。在训练过程中，POWQMIX算法识别并赋予潜在最优联合动作更高的损失权重，理论上证明了该加权训练方法可以保证恢复得到最优策略。实验结果显示，POWQMIX在矩阵游戏、增强难度的猎物捕食者以及StarCraft II多智能体挑战等环境中，相比于当前最先进的基于值函数的多智能体强化学习方法表现更优。<br /><br /> <div>
arXiv:2405.08036v4 Announce Type: replace 
Abstract: Value function factorization methods are commonly used in cooperative multi-agent reinforcement learning, with QMIX receiving significant attention. Many QMIX-based methods introduce monotonicity constraints between the joint action value and individual action values to achieve decentralized execution. However, such constraints limit the representation capacity of value factorization, restricting the joint action values it can represent and hindering the learning of the optimal policy. To address this challenge, we propose the Potentially Optimal Joint Actions Weighted QMIX (POWQMIX) algorithm, which recognizes the potentially optimal joint actions and assigns higher weights to the corresponding losses of these joint actions during training. We theoretically prove that with such a weighted training approach the optimal policy is guaranteed to be recovered. Experiments in matrix games, difficulty-enhanced predator-prey, and StarCraft II Multi-Agent Challenge environments demonstrate that our algorithm outperforms the state-of-the-art value-based multi-agent reinforcement learning methods.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry</title>
<link>https://arxiv.org/abs/2411.14593</link>
<guid>https://arxiv.org/abs/2411.14593</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、Level 5、高速公路入口、深度强化学习、多智能体游戏理论

总结:<br />
本文研究了实现全自主驾驶的关键技术之一——完全自动化的高速公路入口匝道控制问题。该研究采用基于深度强化学习（DRL）的多智能体（MA）游戏理论方法，使车辆能安全地在并入高速交通流过程中控制纵向位置。相较于以往仅针对两辆车的研究，本文扩展到更多车辆的场景，系统性地增加了道路场景中的交通和目标车辆数量。文章指出，在非协调的去中心化环境中，理论上无法找到完全避免碰撞的控制器，但通过所提出的方法学习得到的控制器在实际操作中接近理想的最优控制器表现。 <div>
arXiv:2411.14593v1 Announce Type: new 
Abstract: Vehicles today can drive themselves on highways and driverless robotaxis operate in major cities, with more sophisticated levels of autonomous driving expected to be available and become more common in the future. Yet, technically speaking, so-called "Level 5" (L5) operation, corresponding to full autonomy, has not been achieved. For that to happen, functions such as fully autonomous highway ramp entry must be available, and provide provably safe, and reliably robust behavior to enable full autonomy. We present a systematic study of a highway ramp function that controls the vehicles forward-moving actions to minimize collisions with the stream of highway traffic into which a merging (ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to this problem and study the use of controllers based on deep reinforcement learning (DRL). The virtual environment of the MA DRL uses self-play with simulated data where merging vehicles safely learn to control longitudinal position during a taper-type merge. The work presented in this paper extends existing work by studying the interaction of more than two vehicles (agents) and does so by systematically expanding the road scene with additional traffic and ego vehicles. While previous work on the two-vehicle setting established that collision-free controllers are theoretically impossible in fully decentralized, non-coordinated environments, we empirically show that controllers learned using our approach are nearly ideal when measured against idealized optimal controllers.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Initial Evidence of Elevated Reconnaissance Attacks Against Nodes in P2P Overlay Networks</title>
<link>https://arxiv.org/abs/2411.14623</link>
<guid>https://arxiv.org/abs/2411.14623</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、P2P网络、攻击、蜜罐、安全策略

总结:
我们提出假设认为，点对点（P2P）重叠网络节点由于其可见性、持续在线时间和资源潜力可能对攻击者具有吸引力。为验证这一假设，我们在全球分布式位置与实际以太坊节点并行部署了一系列蜜罐，研究针对以太坊P2P网络节点的活跃侦察攻击状况。结果发现，以太坊节点不仅遭受更多攻击，而且遭遇了特定类型、针对特定端口和服务的攻击。此外，通过对其他可达对等节点进行端口扫描，我们发现对我们节点的威胁评估适用于更广泛的P2P网络。这些发现为我们提供了改进P2P网络层安全性的潜在缓解策略的见解。 <div>
arXiv:2411.14623v1 Announce Type: new 
Abstract: We hypothesize that peer-to-peer (P2P) overlay network nodes can be attractive to attackers due to their visibility, sustained uptime, and resource potential. Towards validating this hypothesis, we investigate the state of active reconnaissance attacks on Ethereum P2P network nodes by deploying a series of honeypots alongside actual Ethereum nodes across globally distributed vantage points. We find that Ethereum nodes experience not only increased attacks, but also specific types of attacks targeting particular ports and services. Furthermore, we find evidence that the threat assessment on our nodes is applicable to the wider P2P network by having performed port scans on other reachable peers. Our findings provide insights into potential mitigation strategies to improve the security of the P2P networking layer.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OCD-FL: A Novel Communication-Efficient Peer Selection-based Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2403.04037</link>
<guid>https://arxiv.org/abs/2403.04037</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘智能、物联网、联邦学习、去中心化联邦学习、机会性通信

总结:
本文关注的是在边缘智能和不断发展的物联网背景下，联邦学习（尤其是去中心化联邦学习）所面临的挑战与改进。针对去中心化联邦学习中的通信成本和数据异质性问题，文章提出了一种名为“机会性通信效率去中心化联邦学习”（OCD-FL）的新方案。该方案通过系统性的FL节点选择策略，旨在在减少能源消耗的同时实现最大的联邦学习知识增益。实验结果显示，OCD-FL能够在保持与完全协作式联邦学习相当或更好的性能水平的同时，将能耗降低至少30%，最高可达80%。<br /><br /> <div>
arXiv:2403.04037v2 Announce Type: replace 
Abstract: The conjunction of edge intelligence and the ever-growing Internet-of-Things (IoT) network heralds a new era of collaborative machine learning, with federated learning (FL) emerging as the most prominent paradigm. With the growing interest in these learning schemes, researchers started addressing some of their most fundamental limitations. Indeed, conventional FL with a central aggregator presents a single point of failure and a network bottleneck. To bypass this issue, decentralized FL where nodes collaborate in a peer-to-peer network has been proposed. Despite the latter's efficiency, communication costs and data heterogeneity remain key challenges in decentralized FL. In this context, we propose a novel scheme, called opportunistic communication-efficient decentralized federated learning, a.k.a., OCD-FL, consisting of a systematic FL peer selection for collaboration, aiming to achieve maximum FL knowledge gain while reducing energy consumption. Experimental results demonstrate the capability of OCD-FL to achieve similar or better performances than the fully collaborative FL, while significantly reducing consumed energy by at least 30% and up to 80%.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Two-agent Motion Planning Strategies from Generalized Nash Equilibrium for Model Predictive Control</title>
<link>https://arxiv.org/abs/2411.13983</link>
<guid>https://arxiv.org/abs/2411.13983</guid>
<content:encoded><![CDATA[
<div> 关键词：Implicit Game-Theoretic MPC (IGT-MPC)，多智能体运动规划，模型预测控制(MPC)，动态游戏，神经网络

总结:
本文提出了一个名为隐式博弈论模型预测控制(IGT-MPC)的新型分散式算法，该算法应用于双智能体运动规划问题。IGT-MPC利用学习得到的价值函数来预测游戏理论中的交互结果，并将其作为MPC框架中的终端成本到目标函数，使智能体能够隐含地考虑与其他智能体的交互并最大化其奖励。该方法适用于竞争性和合作性的多智能体运动规划问题，将这类问题形式化为受约束的动态游戏。通过随机采样初始条件并求解广义纳什均衡(GNE)生成GNE解的数据集，从而计算每个游戏理论交互的奖励结果。这些数据被用来训练一个简单的神经网络以预测奖励结果，该网络进而被用作MPC方案中的终端成本到目标函数。实验展示了IGT-MPC在两车对头竞赛和无信号交叉口导航等场景中产生的竞争性和协调性行为。IGT-MPC提供了一种将机器学习与博弈论推理整合进基于模型的分散式多智能体运动规划的新方法。 <div>
arXiv:2411.13983v1 Announce Type: new 
Abstract: We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized algorithm for two-agent motion planning that uses a learned value function that predicts the game-theoretic interaction outcomes as the terminal cost-to-go function in a model predictive control (MPC) framework, guiding agents to implicitly account for interactions with other agents and maximize their reward. This approach applies to competitive and cooperative multi-agent motion planning problems which we formulate as constrained dynamic games. Given a constrained dynamic game, we randomly sample initial conditions and solve for the generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions, computing the reward outcome of each game-theoretic interaction from the GNE. The data is used to train a simple neural network to predict the reward outcome, which we use as the terminal cost-to-go function in an MPC scheme. We showcase emerging competitive and coordinated behaviors using IGT-MPC in scenarios such as two-vehicle head-to-head racing and un-signalized intersection navigation. IGT-MPC offers a novel method integrating machine learning and game-theoretic reasoning into model-based decentralized multi-agent motion planning.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-Layer Blockchain Simulator and Performance Evaluation of Social Internet of Vehicles with Multi-Connectivity Management</title>
<link>https://arxiv.org/abs/2411.14000</link>
<guid>https://arxiv.org/abs/2411.14000</guid>
<content:encoded><![CDATA[
<div> 关键词：V2X通信、区块链技术、分布式、多层架构、资源管理<br /><br />总结:<br />
本文提出了将去中心化的区块链技术与车辆到万物（V2X）通信创新融合的一种多层架构方案，该架构结合了城市交通模拟器SUMO和区块链模拟器BlockSim。随着社交车联网（SIoV）的发展，为保证无缝通信，有效的资源管理变得至关重要。文中还提出了一种名为“增强型MAX-SINR”的多连接性管理参考方法，旨在推进针对区块链特定方法的研究，并考虑重传成功率。通过评估区块链在城市、郊区和农村等不同环境中的性能，文章证明了提高与区块链相关的重传消息的成功率能显著提升区块链交易性能，为构建智能SIoV系统奠定了基础。 <div>
arXiv:2411.14000v1 Announce Type: new 
Abstract: The evolution of vehicle-to-everything (V2X) communication brings significant challenges, such as data integrity and vulnerabilities stemming from centralized management. This paper presents an innovative integration of decentralized blockchain technology with V2X communication through a multi-layered architecture that combines the Simulation of Urban Mobility (SUMO) traffic simulator and the BlockSim blockchain simulator. In addition, as the Social Internet of Vehicles (SIoV) emerges, efficient resource management becomes indispensable for ensuring seamless communication. We also propose a reference multi-connectivity management method named Enhanced MAX-SINR, designed to advance research in blockchain-specific approaches, taking into account retransmission successfull rates. We evaluate blockchain performance in diverse environments such as urban, suburban, and rural areas, demonstrating that enhancing the success rate of retransmitted blockchain-related messages significantly boosts blockchain transaction performance and provides a foundation for developing intelligent SIoV systems.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Adaptive Asynchronous Federated Learning for Human Activity Recognition</title>
<link>https://arxiv.org/abs/2411.14070</link>
<guid>https://arxiv.org/abs/2411.14070</guid>
<content:encoded><![CDATA[
<div> 关键词：多标签分类、极度异构数据、分布式机器学习、联邦学习（FL）、人类活动识别（HAR）

总结:
<br />
本文针对极度异构数据环境下的多标签分类问题以及在物联网场景中应用联邦学习进行了研究。文章聚焦于将人类活动识别（HAR）任务从集中式学习（CL）迁移到FL的挑战，由于HAR数据和设备的多样性导致标签和特征分布的显著偏差。为解决这一问题，文章提出了从集中式到FL迁移的具体解决方案和工具，并强调了需要做出的关键设计决策。利用开源的HAR数据集，实验评估了数据增强、缩放、优化器选择、学习率和批大小等因素对ML模型性能的影响，发现SGD-m优化器、全局特征缩放及在存在异构HAR数据时持续的特征偏斜等问题的重要性。最后，文章提供了Flower框架的一个开源扩展，支持异步FL。 <div>
arXiv:2411.14070v1 Announce Type: new 
Abstract: In this work, we tackle the problem of performing multi-label classification in the case of extremely heterogeneous data and with decentralized Machine Learning. Solving this issue is very important in IoT scenarios, where data coming from various sources, collected by heterogeneous devices, serve the learning of a distributed ML model through Federated Learning (FL). Specifically, we focus on the combination of FL applied to Human Activity Recognition HAR), where the task is to detect which kind of movements or actions individuals perform. In this case, transitioning from centralized learning (CL) to federated learning is non-trivial as HAR displays heterogeneity in action and devices, leading to significant skews in label and feature distributions. We address this scenario by presenting concrete solutions and tools for transitioning from centralized to FL for non-IID scenarios, outlining the main design decisions that need to be taken. Leveraging an open-sourced HAR dataset, we experimentally evaluate the effects that data augmentation, scaling, optimizer, learning rate, and batch size choices have on the performance of resulting machine learning models. Some of our main findings include using SGD-m as an optimizer, global feature scaling across clients, and persistent feature skew in the presence of heterogeneous HAR data. Finally, we provide an open-source extension of the Flower framework that enables asynchronous FL.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>On PI-control in Capacity-Limited Networks</title>
<link>https://arxiv.org/abs/2411.14077</link>
<guid>https://arxiv.org/abs/2411.14077</guid>
<content:encoded><![CDATA[
<div> 关键词：控制、多智能体系统、非线性、抗饱和控制、分布式策略

总结:<br />
本文研究了一类多动态稳定智能体共享非线性、有界控制互联系统的控制问题。当扰动过大，无法通过可用控制动作完全消除，使得无法将所有智能体稳定在期望状态。针对这一非线性环境，文章分析了两种配备抗饱和控制的比例积分控制策略。首先证明了一个全分布式的控制策略能全局渐近地稳定一个唯一的平衡点，且该平衡点使跟踪误差的加权和达到最小。其次，考虑了在此基础上引入 rank-1 协调机制的轻量级改进策略，该策略下的任何平衡点都将确保任一智能体的最大跟踪误差最小化。这些结果的重要特点是它们对智能体间的互联系统假设非常少。最后，文中展示了所考虑模型在区域供暖场景的应用，并通过仿真验证了两种控制器的效果。 <div>
arXiv:2411.14077v1 Announce Type: new 
Abstract: This paper concerns control of a class of systems where multiple dynamically stable agents share a nonlinear and bounded control-interconnection. The agents are subject to a disturbance which is too large to reject with the available control action, making it impossible to stabilize all agents in their desired states. In this nonlinear setting, we consider two different anti-windup equipped proportional-integral control strategies and analyze their properties. We show that a fully decentralized strategy will globally, asymptotically stabilize a unique equilibrium. This equilibrium also minimizes a weighted sum of the tracking errors. We also consider a light addition to the fully decentralized strategy, where rank-1 coordination between the agents is introduced via the anti-windup action. We show that any equilibrium to this closed-loop system minimizes the maximum tracking error for any agent. A remarkable property of these results is that they rely on extremely few assumptions on the interconnection between the agents. Finally we illustrate how the considered model can be applied in a district heating setting, and demonstrate the two considered controllers in a simulation.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-terminal Strong Coordination subject to Secrecy Constraints</title>
<link>https://arxiv.org/abs/2411.14123</link>
<guid>https://arxiv.org/abs/2411.14123</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式网络系统、安全多终端强协调、多址访问窃听信道、编码策略、信息泄露防护

总结:<br />
本文研究了在分布式网络系统中，利用多址访问窃听信道实现安全多终端强协调的问题。要求两个发送方观测到相关源的独立同分布副本并通过该信道进行编码输入，合法接收方需根据接收到的通道输出及与源相关的侧信息生成与源近似独立同分布的输出变量。同时确保外部窃听者通过观察其自身的MAC-WT输出无法获取关于源和模拟输出序列的有效信息。文章提出了结合协调编码和窃听编码的可达成率区域以及外界边界，并展示了当源条件独立于解码器侧信息且合法通道由确定性链接组成时，内界与外界相匹配，完全刻画了此特殊情形下的问题。此外，还分析了一种具有可能的编码器协作情况，其中一个编码器可以非因果地从其他编码器的输入中获取信息，并提出了相应的可达成率区域。文章最后对具有和不具有编码器间 cribbing 的示例进行了具体的率区域计算，证明了cribbing能严格改进可达率区域。 <div>
arXiv:2411.14123v1 Announce Type: new 
Abstract: A fundamental problem in decentralized networked systems is to coordinate actions of different agents so that they reach a state of agreement. In such applications, it is additionally desirable that the actions at various nodes may not be anticipated by malicious eavesdroppers. Motivated by this, we investigate the problem of secure multi-terminal strong coordination aided by a multiple-access wiretap channel. In this setup, independent and identically distributed copies of correlated sources are observed by two transmitters who encode the channel inputs to the MAC-WT. The legitimate receiver observing the channel output and side information correlated with the sources must produce approximately i.i.d. copies of an output variable jointly distributed with the sources. Furthermore, we demand that an external eavesdropper learns essentially nothin g about the sources and the simulated output sequence by observing its own MAC-WT output. This setting is aided by the presence of independent pairwise shared randomness between each encoder and the legitimate decoder, that is unavailable to the eavesdropper. We derive an achievable rate region based on a combination of coordination coding and wiretap coding, along with an outer bound. The inner bound is shown to be tight and a complete characterization is derived for the special case when the sources are conditionally independent given the decoder side information and the legitimate channel is composed of deterministic links. Further, we also analyze a more general scenario with possible encoder cooperation, where one of the encoders can non-causally crib from the other encoders input, for which an achievable rate region is proposed. We then explicitly compute the rate regions for an example both with and without cribbing between the encoders, and demonstrate that cribbing strictly improves upon the achievable rate region.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pulsar Consensus</title>
<link>https://arxiv.org/abs/2411.14245</link>
<guid>https://arxiv.org/abs/2411.14245</guid>
<content:encoded><![CDATA[
<div> 关键词：Pulsar、proof of stake、sidechain、proof of work、chain selection rule

<br /><br />总结：
本文介绍了Pulsar权益证明共识协议，并讨论了相关的设计决策和考量。Pulsar协议旨在促进工作量证明区块链创建权益证明侧链。文章提出了一个新颖的可组合密度基础的链选择规则，该规则可以看作权益证明协议中某些标准最长链规则的超集。文中将Pulsar协议与其他现有的权益证明协议进行了比较，明确了其相较于现有设计的优势，并定义了本工作的局限性。目前，Pulsar协议已实现在Mintlayer权益证明比特币侧链中的实施。 <div>
arXiv:2411.14245v1 Announce Type: new 
Abstract: In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Iteration-Free Cooperative Distributed MPC through Multiparametric Programming</title>
<link>https://arxiv.org/abs/2411.14319</link>
<guid>https://arxiv.org/abs/2411.14319</guid>
<content:encoded><![CDATA[
<div> 关键词：Cooperative Distributed Model Predictive Control (DiMPC)，communication reduction，computational costs，multiparametric (mp) programming，iteration-free算法

<br /><br />总结：

本文提出了基于多参数编程的新型无迭代解算器算法，显著降低了Cooperative Distributed Model Predictive Control (DiMPC)架构中的信息交换量和计算成本。通过将迭代过程替换为同时求解显式mpDiMPC控制律函数的方法，成功减少了局部控制器间的通信，从而降低了系统延迟，这对于实时控制应用至关重要。通过涉及由输入相互连接并通过合作型全局成本函数耦合的线性子系统的全面数值模拟，验证了所提无迭代mpDiMPC算法的有效性。 <div>
arXiv:2411.14319v1 Announce Type: new 
Abstract: Cooperative Distributed Model Predictive Control (DiMPC) architecture employs local MPC controllers to control different subsystems, exchanging information with each other through an iterative procedure to enhance overall control performance compared to the decentralized architecture. However, this method can result in high communication between the controllers and computational costs. In this work, the amount of information exchanged and the computational costs of DiMPC are reduced significantly by developing novel iteration-free solution algorithms based on multiparametric (mp) programming. These algorithms replace the iterative procedure with simultaneous solutions of explicit mpDiMPC control law functions. The reduced communication among local controllers decreases system latency, which is crucial for real-time control applications. The effectiveness of the proposed iteration-free mpDiMPC algorithms is demonstrated through comprehensive numerical simulations involving groups of coupled linear subsystems, which are interconnected through their inputs and a cooperative plant-wide cost function.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Deep Learning Approach to Predict the Fall [of Price] of Cryptocurrency Long Before its Actual Fall</title>
<link>https://arxiv.org/abs/2411.13615</link>
<guid>https://arxiv.org/abs/2411.13615</guid>
<content:encoded><![CDATA[
<div> 关键词：加密货币市场、风险因素、波动性、机器学习算法、预测模型

<br /><br />总结:
该研究关注于加密货币市场的风险因素（即波动性）预测问题。针对这一市场高波动性和低流动性的特点，研究提出了一种新的预测方法，运用卷积神经网络（CNN）、长短期记忆网络（LSTM）、双向LSTM和门控循环单元（GRU）等多种机器学习算法对加密货币市场的二十项参数进行风险因素预测。研究人员开发了优于已有模型的新预测模型，其表现最优的RMSE值为0.0089，最差为1.3229，显著优于现有模型中最高RMSE值为14.5092、最低为0.02769的表现。通过此模型，投资者能更好地应对比特币、以太坊、狗狗币等复杂且具有挑战性的金融资产交易。 <div>
arXiv:2411.13615v1 Announce Type: cross 
Abstract: In modern times, the cryptocurrency market is one of the world's most rapidly rising financial markets. The cryptocurrency market is regarded to be more volatile and illiquid than traditional markets such as equities, foreign exchange, and commodities. The risk of this market creates an uncertain condition among the investors. The purpose of this research is to predict the magnitude of the risk factor of the cryptocurrency market. Risk factor is also called volatility. Our approach will assist people who invest in the cryptocurrency market by overcoming the problems and difficulties they experience. Our approach starts with calculating the risk factor of the cryptocurrency market from the existing parameters. In twenty elements of the cryptocurrency market, the risk factor has been predicted using different machine learning algorithms such as CNN, LSTM, BiLSTM, and GRU. All of the models have been applied to the calculated risk factor parameter. A new model has been developed to predict better than the existing models. Our proposed model gives the highest RMSE value of 1.3229 and the lowest RMSE value of 0.0089. Following our model, it will be easier for investors to trade in complicated and challenging financial assets like bitcoin, Ethereum, dogecoin, etc. Where the other existing models, the highest RMSE was 14.5092, and the lower was 0.02769. So, the proposed model performs much better than models with proper generalization. Using our approach, it will be easier for investors to trade in complicated and challenging financial assets like Bitcoin, Ethereum, and Dogecoin.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPARKLE: A Unified Single-Loop Primal-Dual Framework for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2411.14166</link>
<guid>https://arxiv.org/abs/2411.14166</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized bilevel optimization, gradient tracking, EXTRA, Exact Diffusion, SPARKLE

总结:
<br />
本文研究了多智能体协作解决具有嵌套优化结构的去中心化双层优化问题。现有的大多数文献主要利用梯度跟踪来缓解数据异质性的影响，而未充分探索如EXTRA或Exact Diffusion等其他知名的异质性校正技术。此外，这些研究通常对上层和下层问题采用相同的去中心化策略，忽视了在不同层次间运用不同机制的优势。针对以上局限性，文章提出了SPARKLE，即一种统一的单循环 primal-dual 算法框架，用于去中心化双层优化，该框架能灵活地将各种异质性校正策略融入算法，并允许上下层问题采取不同的解决方案。作者为SPARKLE及其变种提供了统一的收敛性分析，并与现有去中心化双层算法相比展现出最先进的收敛速率。结果进一步表明，在去中心化双层优化中，EXTRA和Exact Diffusion更为适用，而在双层算法中混合使用多种策略比单纯依赖梯度跟踪更具优势。 <div>
arXiv:2411.14166v1 Announce Type: cross 
Abstract: This paper studies decentralized bilevel optimization, in which multiple agents collaborate to solve problems involving nested optimization structures with neighborhood communications. Most existing literature primarily utilizes gradient tracking to mitigate the influence of data heterogeneity, without exploring other well-known heterogeneity-correction techniques such as EXTRA or Exact Diffusion. Additionally, these studies often employ identical decentralized strategies for both upper- and lower-level problems, neglecting to leverage distinct mechanisms across different levels. To address these limitations, this paper proposes SPARKLE, a unified Single-loop Primal-dual AlgoRithm frameworK for decentraLized bilEvel optimization. SPARKLE offers the flexibility to incorporate various heterogeneitycorrection strategies into the algorithm. Moreover, SPARKLE allows for different strategies to solve upper- and lower-level problems. We present a unified convergence analysis for SPARKLE, applicable to all its variants, with state-of-the-art convergence rates compared to existing decentralized bilevel algorithms. Our results further reveal that EXTRA and Exact Diffusion are more suitable for decentralized bilevel optimization, and using mixed strategies in bilevel algorithms brings more benefits than relying solely on gradient tracking.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Public sentiments on the fourth industrial revolution: An unsolicited public opinion poll from Twitter</title>
<link>https://arxiv.org/abs/2411.14230</link>
<guid>https://arxiv.org/abs/2411.14230</guid>
<content:encoded><![CDATA[
<div> 关键词：第四次工业革命、社交媒体、情绪分析、机器学习、公共感知

<br /><br />总结：
该文章通过分析六个欧洲国家的社交媒体推文和媒体文章数据，探讨公众对第四次工业革命（4IR）的看法。利用情感分析和机器学习技术，研究发现公众对人工智能、机器人和区块链等技术融入社会的态度呈现显著两极分化，从中立立场转向更为明确的支持或反对态度。正面观点主要关联到科技对生活质量与经济机遇的提升，而担忧则集中在隐私、数据安全及伦理问题上。这表明政策制定者需要积极与公众沟通，以缓解恐惧并利用4IR技术的优势。此外，文章还提倡开展数字素养和公共意识项目，以减少错误信息并促进有关未来技术整合的明智公共讨论。这项研究为如何使科技进步与社会价值观和需求相一致提供了见解，强调了形成有效政策过程中知情公众意见的重要性。 <div>
arXiv:2411.14230v1 Announce Type: cross 
Abstract: This article explores public perceptions on the Fourth Industrial Revolution (4IR) through an analysis of social media discourse across six European countries. Using sentiment analysis and machine learning techniques on a dataset of tweets and media articles, we assess how the public reacts to the integration of technologies such as artificial intelligence, robotics, and blockchain into society. The results highlight a significant polarization of opinions, with a shift from neutral to more definitive stances either embracing or resisting technological impacts. Positive sentiments are often associated with technological enhancements in quality of life and economic opportunities, whereas concerns focus on issues of privacy, data security, and ethical implications. This polarization underscores the need for policymakers to engage proactively with the public to address fears and harness the benefits of 4IR technologies. The findings also advocate for digital literacy and public awareness programs to mitigate misinformation and foster an informed public discourse on future technological integration. This study contributes to the ongoing debate on aligning technological advances with societal values and needs, emphasizing the role of informed public opinion in shaping effective policy.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Privacy-Aware Data Acquisition under Data Similarity in Regression Markets</title>
<link>https://arxiv.org/abs/2312.02611</link>
<guid>https://arxiv.org/abs/2312.02611</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据市场、数据相似性、隐私偏好、局部差分隐私、Stackelberg游戏

总结:
该文探讨了数据市场上数据相似性和隐私偏好的重要影响，并提出了一个基于局部差分隐私的两方数据获取协议。研究中，作者将隐私意识强的数据拥有者与学习者之间的战略互动分析为一个关于询问价格和隐私因子的Stackelberg游戏，模型应用于回归数据分析市场。文章通过数值分析揭示了数据相似性如何影响市场的参与度及交易数据的价值。 <div>
arXiv:2312.02611v2 Announce Type: replace 
Abstract: Data markets facilitate decentralized data exchange for applications such as prediction, learning, or inference. The design of these markets is challenged by varying privacy preferences as well as data similarity among data owners. Related works have often overlooked how data similarity impacts pricing and data value through statistical information leakage. We demonstrate that data similarity and privacy preferences are integral to market design and propose a query-response protocol using local differential privacy for a two-party data acquisition mechanism. In our regression data market model, we analyze strategic interactions between privacy-aware owners and the learner as a Stackelberg game over the asked price and privacy factor. Finally, we numerically evaluate how data similarity affects market participation and traded data value.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Structured stability analysis of networked systems with uncertain links</title>
<link>https://arxiv.org/abs/2403.14931</link>
<guid>https://arxiv.org/abs/2403.14931</guid>
<content:encoded><![CDATA[
<div> 关键词：网络系统、不确定链接动力学、输入-输出方法、稳定性分析、积分二次约束

总结:<br />
该文针对具有不确定链路动态的网络系统，探索了一种基于输入-输出的稳定性分析方法。主要成果是一组积分二次约束条件，当理想链接下系统达到稳定性时，这些条件共同确保了不确定网络系统的鲁棒稳定性。这些条件具备分散性特点，每个仅涉及对应链接的局部代理和不确定性模型参数，因此该主要结果对于无特定网络结构限制的大规模系统研究非常适用。 <div>
arXiv:2403.14931v2 Announce Type: replace 
Abstract: An input-output approach to stability analysis is explored for networked systems with uncertain link dynamics. The main result consists of a collection of integral quadratic constraints, which together imply robust stability of the uncertain networked system, under the assumption that stability is achieved with ideal links. The conditions are decentralized inasmuch as each involves only agent and uncertainty model parameters that are local to a corresponding link. This makes the main result, which imposes no restriction on network structure, suitable for the study of large-scale systems.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>TrustMesh: A Blockchain-Enabled Trusted Distributed Computing Framework for Open Heterogeneous IoT Environments</title>
<link>https://arxiv.org/abs/2411.13039</link>
<guid>https://arxiv.org/abs/2411.13039</guid>
<content:encoded><![CDATA[
<div> 关键词: TrustMesh、区块链、物联网(IoT)、分布式计算、拜占庭容错(PBFT)

<br /><br />总结:
本文提出了TrustMesh，一个创新的区块链驱动的框架，旨在解决物联网环境下安全可信的分布式计算问题。TrustMesh采用独特的三层架构，结合了许可型区块链技术和一种新颖的多阶段实用拜占庭容错(PBFT)共识协议。其关键创新在于能在支持非确定性调度算法的同时保持拜占庭容错特性，这是传统区块链系统中难以兼得的。此外，该框架还具备灵活的资源管理方法，可在保证区块链验证安全性的同时实现灵活的调度决策。实验结果显示，在实际的冷链监测场景下，TrustMesh能够在150毫秒内的故障检测延迟下维持拜占庭容错，并在不同计算负载和网络扩展情况下保持一致的框架开销。这些结果证明了TrustMesh在无信任物联网环境中平衡安全、性能和灵活性需求的能力，从而推动了安全分布式计算框架领域的前沿进展。 <div>
arXiv:2411.13039v1 Announce Type: new 
Abstract: The rapid evolution of Internet of Things (IoT) environments has created an urgent need for secure and trustworthy distributed computing systems, particularly when dealing with heterogeneous devices and applications where centralized trust cannot be assumed. This paper proposes TrustMesh, a novel blockchain-enabled framework that addresses these challenges through a unique three-layer architecture combining permissioned blockchain technology with a novel multi-phase Practical Byzantine Fault Tolerance (PBFT) consensus protocol. The key innovation lies in TrustMesh's ability to support non-deterministic scheduling algorithms while maintaining Byzantine fault tolerance - features traditionally considered mutually exclusive in blockchain systems. The framework supports a sophisticated resource management approach that enables flexible scheduling decisions while preserving the security guarantees of blockchain-based verification. Our experimental evaluation using a real-world cold chain monitoring scenario demonstrates that TrustMesh successfully maintains Byzantine fault tolerance with fault detection latencies under 150 milliseconds, while maintaining consistent framework overhead across varying computational workloads even with network scaling. These results establish TrustMesh's effectiveness in balancing security, performance, and flexibility requirements in trustless IoT environments, advancing the state-of-the-art in secure distributed computing frameworks.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Blockchain-Enhanced Framework for Secure Third-Party Vendor Risk Management and Vigilant Security Controls</title>
<link>https://arxiv.org/abs/2411.13447</link>
<guid>https://arxiv.org/abs/2411.13447</guid>
<content:encoded><![CDATA[
<div> 关键词: 第三方供应商风险、区块链技术、安全框架、智能合约、持续监控

总结:
本文提出了一种综合安全框架，用于管理第三方供应商风险，并整合了区块链技术以确保评估和交互过程中的透明度、可追溯性和不可篡改性。该框架利用区块链增强了供应商安全审计的完整性，并通过智能合约减少人为错误，实现实时合规与安全控制监测。重点强调了对数据加密、访问控制机制、多因素认证和零信任架构等关键安全控制的评估。通过区块链实现的持续监控确保了供应商合规流程的不变性和透明度。文中通过iHealth迁移到AWS云的案例研究展示了该框架的实际应用，结果显示显著降低了漏洞并提高了事件响应时间。采用这种区块链赋能的方法，组织可以有效降低供应商风险、简化合规流程并提升整体安全态势。 <div>
arXiv:2411.13447v1 Announce Type: new 
Abstract: In an era of heightened digital interconnectedness, businesses increasingly rely on third-party vendors to enhance their operational capabilities. However, this growing dependency introduces significant security risks, making it crucial to develop a robust framework to mitigate potential vulnerabilities. This paper proposes a comprehensive secure framework for managing third-party vendor risk, integrating blockchain technology to ensure transparency, traceability, and immutability in vendor assessments and interactions. By leveraging blockchain, the framework enhances the integrity of vendor security audits, ensuring that vendor assessments remain up-to-date and tamperproof. This proposed framework leverages smart contracts to reduce human error while ensuring real-time monitoring of compliance and security controls. By evaluating critical security controls-such as data encryption, access control mechanisms, multi-factor authentication, and zero-trust architecture-this approach strengthens an organization's defense against emerging cyber threats. Additionally, continuous monitoring enabled by blockchain ensures the immutability and transparency of vendor compliance processes. In this paper, a case study on iHealth's transition to AWS Cloud demonstrates the practical implementation of the framework, showing a significant reduction in vulnerabilities and marked improvement in incident response times. Through the adoption of this blockchain-enabled approach, organizations can mitigate vendor risks, streamline compliance, and enhance their overall security posture.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinBERT-BiLSTM: A Deep Learning Model for Predicting Volatile Cryptocurrency Market Prices Using Market Sentiment Dynamics</title>
<link>https://arxiv.org/abs/2411.12748</link>
<guid>https://arxiv.org/abs/2411.12748</guid>
<content:encoded><![CDATA[
<div> 关键词: 时间序列预测、金融市场、加密货币、深度学习模型、Bi-LSTM + FinBERT 混合模型

总结:<br />
本文介绍了时间序列预测在金融市场的关键作用，特别是在波动性极高的比特币和以太坊等加密货币市场中的应用。传统方法已难以应对这类市场的极端价格波动，因此研究转向了如LSTM、Bi-LSTM及FinBERT等深度学习模型。鉴于此，文章提出了一种混合模型，将双向长短时记忆网络（Bi-LSTM）与专门用于金融领域的FinBERT结合，旨在提升加密货币价格预测的准确性。这一创新方法融合了高级时间序列模型与情绪分析，为投资者和分析师在不确定性的金融市场中提供更为有价值的决策依据。 <div>
arXiv:2411.12748v1 Announce Type: cross 
Abstract: Time series forecasting is a key tool in financial markets, helping to predict asset prices and guide investment decisions. In highly volatile markets, such as cryptocurrencies like Bitcoin (BTC) and Ethereum (ETH), forecasting becomes more difficult due to extreme price fluctuations driven by market sentiment, technological changes, and regulatory shifts. Traditionally, forecasting relied on statistical methods, but as markets became more complex, deep learning models like LSTM, Bi-LSTM, and the newer FinBERT-LSTM emerged to capture intricate patterns. Building upon recent advancements and addressing the volatility inherent in cryptocurrency markets, we propose a hybrid model that combines Bidirectional Long Short-Term Memory (Bi-LSTM) networks with FinBERT to enhance forecasting accuracy for these assets. This approach fills a key gap in forecasting volatile financial markets by blending advanced time series models with sentiment analysis, offering valuable insights for investors and analysts navigating unpredictable markets.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Supervised Autoencoders with Fractionally Differentiated Features and Triple Barrier Labelling Enhance Predictions on Noisy Data</title>
<link>https://arxiv.org/abs/2411.12753</link>
<guid>https://arxiv.org/abs/2411.12753</guid>
<content:encoded><![CDATA[
<div> 关键词：神经网络、监督自编码器(SAE)、噪声增强、三重障碍标签、风险调整回报

总结:<br />
本文研究了利用神经网络中的监督自编码器（SAE）来提升金融时间序列预测的准确性，旨在改善投资策略的表现。研究期间选取了比特币、莱特币和以太坊作为交易资产，时间段为2016年1月1日至2022年4月30日。结果表明，采用平衡噪声增强与适当瓶颈大小的监督自编码器能显著提高策略的有效性。然而，过多的噪声以及过大的瓶颈尺寸可能会对性能产生负面影响。 <div>
arXiv:2411.12753v1 Announce Type: cross 
Abstract: This paper investigates the enhancement of financial time series forecasting with the use of neural networks through supervised autoencoders (SAE), to improve investment strategy performance. Using the Sharpe and Information Ratios, it specifically examines the impact of noise augmentation and triple barrier labeling on risk-adjusted returns. The study focuses on Bitcoin, Litecoin, and Ethereum as the traded assets from January 1, 2016, to April 30, 2022. Findings indicate that supervised autoencoders, with balanced noise augmentation and bottleneck size, significantly boost strategy effectiveness. However, excessive noise and large bottleneck sizes can impair performance.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy</title>
<link>https://arxiv.org/abs/2411.12756</link>
<guid>https://arxiv.org/abs/2411.12756</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、阿尔茨海默症分类、迁移学习、联邦学习、数据隐私

总结:
<br />
本文提出了一种新的阿尔茨海默症分类方法，该方法结合了先进的深度学习技术和安全的数据处理方法。研究主要利用ResNet、ImageNet和VNet等预训练模型从医学图像数据中提取高层特征，并针对阿尔茨海默症的相关细微模式对这些模型进行微调，以实现对不同数据源的鲁棒性特征提取。此外，为了提高预测性能并保护数据隐私，文中还引入了联邦学习方法。通过采用联邦学习的方式构建模型，无需共享敏感患者数据即可实现分布式训练，同时确保数据的保密性和完整性。为保障在整个训练与分类过程中的患者信息安全，还采用了基于密码学的加密机制。实验结果表明，这种方法不仅提高了阿尔茨海默症分类的准确性，而且还提供了一个用于安全、协作分析医疗健康数据的框架。 <div>
arXiv:2411.12756v1 Announce Type: cross 
Abstract: This research work introduces a novel approach to the classification of Alzheimer's disease by using the advanced deep learning techniques combined with secure data processing methods. This research work primary uses transfer learning models such as ResNet, ImageNet, and VNet to extract high-level features from medical image data. Thereafter, these pre-trained models were fine-tuned for Alzheimer's related subtle patterns such that the model is capable of robust feature extraction over varying data sources. Further, the federated learning approaches were incorporated to tackle a few other challenges related to classification, aimed to provide better prediction performance and protect data privacy. The proposed model was built using federated learning without sharing sensitive patient data. This way, the decentralized model benefits from the large and diversified dataset that it is trained upon while ensuring confidentiality. The cipher-based encryption mechanism is added that allows us to secure the transportation of data and further ensure the privacy and integrity of patient information throughout training and classification. The results of the experiments not only help to improve the accuracy of the classification of Alzheimer's but at the same time provides a framework for secure and collaborative analysis of health care data.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Delegating Data Collection in Decentralized Machine Learning</title>
<link>https://arxiv.org/abs/2309.01837</link>
<guid>https://arxiv.org/abs/2309.01837</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、机器学习、数据收集、合同理论、信息不对称

<br /><br />总结:
本文针对去中心化机器学习生态系统中出现的数据收集委托问题，结合合同理论进行研究。文章探讨了在此场景下两种基本的信息不对称性：模型质量评估的不确定性以及对最优模型性能的不确定。文中设计了实现近似最优效用的简单线性合同，并表明通过这种合同，主体可以应对上述不对称性，达到理想效用的1-1/e比例。为解决关于最优性能的未知问题，文章提出了一种能自适应并高效计算最优合同的凸优化程序。此外，对于多次交互的复杂环境，文中还研究了线性合同并得出了最优效用情况。 <div>
arXiv:2309.01837v3 Announce Type: replace 
Abstract: Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve 1-1/e fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also study linear contracts and derive the optimal utility in the more complex setting of multiple interactions.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction</title>
<link>https://arxiv.org/abs/2411.11894</link>
<guid>https://arxiv.org/abs/2411.11894</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse网络流量预测、扩展现实(XR)服务、测试床、视帧(VF)算法、ResLearn、Transformer、错误学习、资源管理、服务质量(QoS)、用户体验。

<br /><br />总结:
本文提出了一种针对Metaverse网络流量预测的全面解决方案，旨在满足扩展现实(XR)服务中智能资源管理的需求。研究内容包括建立一个先进的测试床，用于收集并公开虚拟现实(VR)、增强现实(AR)和混合现实(MR)的真实世界交通数据。为了提高预测精度，文章提出了一种名为视帧(VF)的新型算法，该算法能准确识别流量中的视频帧并确保隐私合规性。此外，还开发了一种基于Transformer的递进误差学习算法——ResLearn，该算法利用全连接神经网络减少预测错误，特别是在高峰流量时段，相较于先前工作提高了99%的性能。这些贡献为互联网服务提供商(ISPs)提供了实时网络管理的强大工具，以满足Metaverse中的服务质量(QoS)需求并提升用户体验。 <div>
arXiv:2411.11894v1 Announce Type: new 
Abstract: Our work proposes a comprehensive solution for predicting Metaverse network traffic, addressing the growing demand for intelligent resource management in eXtended Reality (XR) services. We first introduce a state-of-the-art testbed capturing a real-world dataset of virtual reality (VR), augmented reality (AR), and mixed reality (MR) traffic, made openly available for further research. To enhance prediction accuracy, we then propose a novel view-frame (VF) algorithm that accurately identifies video frames from traffic while ensuring privacy compliance, and we develop a Transformer-based progressive error-learning algorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn significantly improves time-series predictions by using fully connected neural networks to reduce errors, particularly during peak traffic, outperforming prior work by 99%. Our contributions offer Internet service providers (ISPs) robust tools for real-time network management to satisfy Quality of Service (QoS) and enhance user experience in the Metaverse.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simultaneous Ground Reaction Force and State Estimation via Constrained Moving Horizon Estimation</title>
<link>https://arxiv.org/abs/2411.12047</link>
<guid>https://arxiv.org/abs/2411.12047</guid>
<content:encoded><![CDATA[
<div> 关键词：地面反作用力估计、腿部机器人、状态估计、运动 horizon 估计（MHE）、漂移基座

总结:<br />
本文提出了一种针对腿部机器人的同时地面反作用力和状态估计框架。该框架系统性地解决了传感器噪声问题以及状态与动力学之间的耦合问题。通过单独估计浮动基座姿态，采用分散式的运动 Horizon 估计方法，将机器人动力学、本体感觉传感器、外感觉传感器及确定性的接触互补约束融合在一个凸优化的窗口化问题中。实验表明，该方法能够在频率为 200Hz 和过去时间窗口为 0.04s 的条件下，对包括开源教育平面双足机器人 STRIDE 和四足机器人 Unitree Go1 在内的多种腿部机器人实现准确的地面反作用力和状态估计。 <div>
arXiv:2411.12047v1 Announce Type: new 
Abstract: Accurate ground reaction force (GRF) estimation can significantly improve the adaptability of legged robots in various real-world applications. For instance, with estimated GRF and contact kinematics, the locomotion control and planning assist the robot in overcoming uncertain terrains. The canonical momentum-based methods, formulated as nonlinear observers, do not fully address the noisy measurements and the dependence between floating base states and the generalized momentum dynamics. In this paper, we present a simultaneous ground reaction force and state estimation framework for legged robots, which systematically addresses the sensor noise and the coupling between states and dynamics. With the floating base orientation estimated separately, a decentralized Moving Horizon Estimation (MHE) method is implemented to fuse the robot dynamics, proprioceptive sensors, exteroceptive sensors, and deterministic contact complementarity constraints in a convex windowed optimization. The proposed method is shown to be capable of providing accurate GRF and state estimation on several legged robots, including the open-source educational planar bipedal robot STRIDE and quadrupedal robot Unitree Go1, with a frequency of 200Hz and a past time window of 0.04s.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning</title>
<link>https://arxiv.org/abs/2411.12220</link>
<guid>https://arxiv.org/abs/2411.12220</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning（联邦学习）、backdoor attacks（后门攻击）、DeTrigger、gradient analysis（梯度分析）、temperature scaling（温度缩放）

<br /><br />总结:

本文提出了一个名为DeTrigger的可扩展且高效的抵御后门攻击的联邦学习框架。DeTrigger利用对抗性攻击方法的洞察力，通过结合梯度分析与温度缩放技术来检测和隔离后门触发器，并精确地进行模型权重剪枝以去除后门激活部分，同时尽量保全正常模型知识。实验表明，DeTrigger相比于传统方法能实现高达251倍的更快检测速度，并能有效缓解高达98.9%的后门攻击，对全局模型准确性的影响极小。因此，DeTrigger被认为是保护联邦学习环境免受复杂后门威胁的一种健壮且可扩展的解决方案。 <div>
arXiv:2411.12220v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across distributed devices while preserving local data privacy, making it ideal for mobile and embedded systems. However, the decentralized nature of FL also opens vulnerabilities to model poisoning attacks, particularly backdoor attacks, where adversaries implant trigger patterns to manipulate model predictions. In this paper, we propose DeTrigger, a scalable and efficient backdoor-robust federated learning framework that leverages insights from adversarial attack methodologies. By employing gradient analysis with temperature scaling, DeTrigger detects and isolates backdoor triggers, allowing for precise model weight pruning of backdoor activations without sacrificing benign model knowledge. Extensive evaluations across four widely used datasets demonstrate that DeTrigger achieves up to 251x faster detection than traditional methods and mitigates backdoor attacks by up to 98.9%, with minimal impact on global model accuracy. Our findings establish DeTrigger as a robust and scalable solution to protect federated learning environments against sophisticated backdoor threats.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hyper-parameter Optimization for Federated Learning with Step-wise Adaptive Mechanism</title>
<link>https://arxiv.org/abs/2411.12244</link>
<guid>https://arxiv.org/abs/2411.12244</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning (FL), Automated Machine Learning (Auto-ML), Hyper-Parameter Optimization (HPO), Raytune, Optuna

<br /><br />总结:
本文研究了在联邦学习（FL）环境中部署和整合两个轻量级超参数优化工具——Raytune和Optuna的方法。针对FL中大量客户端及服务器间的全局训练轮次带来的调参过程耗时、资源受限的问题，文章提出了一种逐步反馈机制，加速超参数调优过程，并协调Auto-ML工具包与FL服务器之间的协作。同时，结合局部和全局反馈机制缩小搜索空间，加快HPO进程。此外，还引入了一种新的客户端选择技术来缓解Auto-FL中的“拖尾”效应。通过FEMNIST和CIFAR10两个基准数据集对该方法进行了评估。文章最后讨论了成功HPO工具应具备的关键属性以及其与FL流水线的集成机制，同时指出了FL环境分布式和异构性所带来的挑战。 <div>
arXiv:2411.12244v1 Announce Type: new 
Abstract: Federated Learning (FL) is a decentralized learning approach that protects sensitive information by utilizing local model parameters rather than sharing clients' raw datasets. While this privacy-preserving method is widely employed across various applications, it still requires significant development and optimization. Automated Machine Learning (Auto-ML) has been adapted for reducing the need for manual adjustments. Previous studies have explored the integration of AutoML with different FL algorithms to evaluate their effectiveness in enhancing FL settings. However, Automated FL (Auto-FL) faces additional challenges due to the involvement of a large cohort of clients and global training rounds between clients and the server, rendering the tuning process time-consuming and nearly impossible on resource-constrained edge devices (e.g., IoT devices). This paper investigates the deployment and integration of two lightweight Hyper-Parameter Optimization (HPO) tools, Raytune and Optuna, within the context of FL settings. A step-wise feedback mechanism has also been designed to accelerate the hyper-parameter tuning process and coordinate AutoML toolkits with the FL server. To this end, both local and global feedback mechanisms are integrated to limit the search space and expedite the HPO process. Further, a novel client selection technique is introduced to mitigate the straggler effect in Auto-FL. The selected hyper-parameter tuning tools are evaluated using two benchmark datasets, FEMNIST, and CIFAR10. Further, the paper discusses the essential properties of successful HPO tools, the integration mechanism with the FL pipeline, and the challenges posed by the distributed and heterogeneous nature of FL environments.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging NFTs for Spectrum Securitization in 6G Networks</title>
<link>https://arxiv.org/abs/2411.12347</link>
<guid>https://arxiv.org/abs/2411.12347</guid>
<content:encoded><![CDATA[
<div> 关键词：动态频谱共享、激励机制、ERC404标准、非同质化代币、同质化代币

总结:
<br />
本文提出了基于ERC404标准并结合非同质化代币（NFT）和同质化代币（FT）技术的频谱证券化模型，旨在激励原始用户积极分享其频谱资源。通过该模型，在以太坊测试网络上实现动态频谱资源共享的有效促进，进而提高频谱资源利用率。 <div>
arXiv:2411.12347v1 Announce Type: new 
Abstract: Dynamic Spectrum Sharing can enhance spectrum resource utilization by promoting the dynamic distribution of spectrum resources. However, to effectively implement dynamic spectrum resource allocation, certain mechanisms are needed to incentivize primary users to proactively share their spectrum resources. This paper, based on the ERC404 standard and integrating Non-Fungible Token and Fungible Token technologies, proposes a spectrum securitization model to incentivize spectrum resource sharing and implements it on the Ethereum test net.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Centralized RAN to Open RAN: A Survey on the Evolution of Distributed Antenna Systems</title>
<link>https://arxiv.org/abs/2411.12166</link>
<guid>https://arxiv.org/abs/2411.12166</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式天线系统(DAS), 无线接入网(RAN), 云无线接入网(C-RAN), 雾无线接入网(F-RAN), 开放无线接入网(O-RAN)

<br /><br />总结:
本文对分布式天线系统（DAS）进行了全面的调查研究，探讨了从传统分散式RAN向DAS演进的各种架构，包括云无线接入网（C-RAN）、雾无线接入网（F-RAN）、虚拟化无线接入网（V-RAN）、无细胞大规模多输入多输出（CF-mMIMO）以及最新的开放无线接入网（O-RAN）。文章分析了这些架构的优势和局限性，如有限容量的前传链路、上行/下行协作编码策略、跨层优化及DAS性能优化技术。同时，文中还介绍了下一代RAN系统的关键使能技术，如边缘计算、网络功能虚拟化、软件定义网络和网络切片，以及重要的无线接入技术，如毫米波、大规模多输入多输出、设备到设备通信和大规模机器类型通信。最后，文章指出了DAS领域的重大研究挑战并提出了未来可能的研究方向。 <div>
arXiv:2411.12166v1 Announce Type: cross 
Abstract: Next-generation mobile networks require evolved radio access network (RAN) architectures to meet the demands of high capacity, massive connectivity, reduced costs, and energy efficiency, and to realize communication with ultra-low latency and ultra-high reliability. {Meeting such} requirements for both mobile users and vertical industries in the next decade {requires novel solutions. One of the potential solutions that attracted significant research attention in the past 15 years} is to redesign the radio access network (RAN). In this survey, we present a comprehensive survey on distributed antenna system (DAS) architectures that address these challenges and improve network performance. We cover the transition from traditional decentralized RAN to DAS, including cloud radio-access networks (C-RAN), fog radio-access networks (F-RAN), virtualized radio-access networks (V-RAN), cell-free massive multiple-input multiple-output (CF-mMIMO), and {the most recent advances manifested in} open radio-access network (O-RAN). In the process, we discuss the benefits and limitations of these architectures, including the impact of limited-capacity fronthaul links, various cooperative uplink and downlink coding strategies, cross-layer optimization, and techniques to optimize the performance of DAS. Moreover, we review key enabling technologies for next-generation RAN systems, such as multi-access edge computing, network function virtualization, software-defined networking, and network slicing; in addition to some crucial radio access technologies, such as millimeter wave, massive multi-input multi-output, device-to-device communication, and massive machine-type communication. Last but not least, we discuss the major research challenges in DAS and identify several possible directions for future research.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Adaptive Motion Planning with Nonlinear Model Predictive Control for Safety-Critical Collaborative Loco-Manipulation</title>
<link>https://arxiv.org/abs/2411.10699</link>
<guid>https://arxiv.org/abs/2411.10699</guid>
<content:encoded><![CDATA[
<div> 关键词：legged机器人、多机器人任务、安全、层次化控制系统、非线性模型预测控制

<br />
总结:
本文提出了一种用于四足机器人团队协同对象操作的层次化控制系统，重点关注在工业和自主建筑领域的应用。该系统确保了复杂场景中多机器人任务的安全性。文章的关键点包括：<br />
1. 针对大型重物处理的需求，强调了多足机器人协作操纵的重要性以及安全性保证。<br />
2. 提出了一种层次化的控制系统，结合运动规划器与去中心化的步态控制器，实现安全、适应性的团队规划。<br />
3. 高层采用非线性模型预测控制规划器生成避免碰撞的路径，通过控制 Barrier 函数考虑静态和动态障碍物，同时计算接触点和力并适应未知物体及地形属性。<br />
4. 去中心化的loco-manipulation控制器确保每个机器人能在规划器指导下保持稳定的步态和操纵功能。<br />
5. 通过模拟实验和真实硬件实验验证了方法的有效性，机器人团队能根据对象配置穿越含有静态和动态障碍物的环境。相关代码已在开源仓库发布。 <div>
arXiv:2411.10699v1 Announce Type: new 
Abstract: As legged robots take on roles in industrial and autonomous construction, collaborative loco-manipulation is crucial for handling large and heavy objects that exceed the capabilities of a single robot. However, ensuring the safety of these multi-robot tasks is essential to prevent accidents and guarantee reliable operation. This paper presents a hierarchical control system for object manipulation using a team of quadrupedal robots. The combination of the motion planner and the decentralized locomotion controller in a hierarchical structure enables safe, adaptive planning for teams in complex scenarios. A high-level nonlinear model predictive control planner generates collision-free paths by incorporating control barrier functions, accounting for static and dynamic obstacles. This process involves calculating contact points and forces while adapting to unknown objects and terrain properties. The decentralized loco-manipulation controller then ensures each robot maintains stable locomotion and manipulation based on the planner's guidance. The effectiveness of our method is carefully examined in simulations under various conditions and validated in real-life setups with robot hardware. By modifying the object's configuration, the robot team can maneuver unknown objects through an environment containing both static and dynamic obstacles. We have made our code publicly available in an open-source repository at \url{https://github.com/DRCL-USC/collaborative_loco_manipulation}.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Task Offloading for Vehicular Edge Computing Based on Improved Hotstuff under Parking Assistance</title>
<link>https://arxiv.org/abs/2411.10770</link>
<guid>https://arxiv.org/abs/2411.10770</guid>
<content:encoded><![CDATA[
<div> 关键词：Parked-assisted vehicular edge computing (PVEC), 区块链, 任务卸载, 共识节点选择, 游戏模型<br /><br />总结：<br />
本文提出了一种基于区块链的停车辅助车联网边缘计算（BPVEC）卸载框架，旨在增强任务卸载和交易的安全性和可靠性。该框架利用连接支配集（CDS）的共识节点选择算法改进了Hotstuff共识，以根据停车时间、计算能力和通信质量提升区块链在计算卸载和交易过程中的可靠性。同时，文章构建了一个双层Stackelberg游戏模型，将路侧单元（RSUs）和停车车辆（PVs）作为领导者，请求车辆（RVs）作为跟随者，以此优化卸载策略和定价。通过梯度下降法设计了BPVEC卸载策略算法来最大化系统收益。仿真结果显示，所提出的BPVEC卸载方案能够在确保最大利益的同时，实现安全可靠的运行。 <div>
arXiv:2411.10770v1 Announce Type: new 
Abstract: Parked-assisted vehicular edge computing (PVEC) fully leverages communication and computing resources of parking vehicles, thereby significantly alleviating the pressure on edge servers. However, resource sharing and trading for vehicular task offloading in the PVEC environment usually occur between untrustworthy entities, which compromises the security of data sharing and transactions by vehicles and edge devices. To address these concerns, blockchain is introduced to provide a secure and trustworthy environment for offloading and transactions in PVEC. Nevertheless, due to the mobility of the vehicles, the processes of computing offloading and blockchain transactions are interrupted, which greatly reduces the reliability of the blockchain in edge computing process. In this paper, we propose a blockchain-based PVEC (BPVEC) offloading framework to enhance the security and reliability of the task offloading and transaction. Specifically, a consensus node selection algorithm based on the connected dominating set (CDS) is designed to improve the Hotstuff consensus according to parking time, computing capability and communication quality, which enhances blockchain reliability in computing offloading and transactions. Meanwhile, a Stackelberg game model, establishing the roadside units (RSUs) and parking vehicles (PVs) as leaders and the requesting vehicles (RVs) as follower, is utilized to optimize the offloading strategy and pricing. Subsequently, a BPVEC offloading strategy algorithm with gradient descent method is designed to maximize system revenue. Simulation results show that the proposed BPVEC offloading scheme is secure and reliable while ensuring maximum benefits.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating Relative Over-Generalization in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.11099</link>
<guid>https://arxiv.org/abs/2411.11099</guid>
<content:encoded><![CDATA[
<div> 关键词: decentralized multi-agent reinforcement learning, relative over-generalization, MaxMax Q-Learning (MMQ), optimal joint policy, sample efficiency

<br /><br />总结:
本文提出了一种解决去中心化多智能体强化学习中相对过泛化问题的新方法——setMax Q-Learning (MMQ)。该方法通过迭代采样和评估潜在的下一个状态，并选择具有最大Q值的状态进行学习，从而更好地逼近协作智能体的理想联合策略。理论分析表明MMQ具有潜力，实验结果证实了在易出现相对过泛化的各种环境中，MMQ相对于现有基线更常表现出更好的收敛性和样本效率。 <div>
arXiv:2411.11099v1 Announce Type: new 
Abstract: In decentralized multi-agent reinforcement learning, agents learning in isolation can lead to relative over-generalization (RO), where optimal joint actions are undervalued in favor of suboptimal ones. This hinders effective coordination in cooperative tasks, as agents tend to choose actions that are individually rational but collectively suboptimal. To address this issue, we introduce MaxMax Q-Learning (MMQ), which employs an iterative process of sampling and evaluating potential next states, selecting those with maximal Q-values for learning. This approach refines approximations of ideal state transitions, aligning more closely with the optimal joint policy of collaborating agents. We provide theoretical analysis supporting MMQ's potential and present empirical evaluations across various environments susceptible to RO. Our results demonstrate that MMQ frequently outperforms existing baselines, exhibiting enhanced convergence and sample efficiency.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Emergent Structure in Multi-agent Systems Using Geometric Embeddings</title>
<link>https://arxiv.org/abs/2411.11142</link>
<guid>https://arxiv.org/abs/2411.11142</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、无人机、自组织、局部观测、虚拟嵌入<br /><br />总结: 本文研究了多智能体系统如何自组织形成封闭轨迹，这是无人机监控任务中的常见需求。为实现这一目标，提出了一个去中心化的控制系统架构，该架构仅基于本地观察信息即可产生全局稳定的 emergent 结构，无需各个代理共享全球计划或遵循预设路径。核心在于利用从实际代理人位置诱导的旋转形成的单射虚拟嵌入。此嵌入作为结构保持映射，使得所有代理稳定其相对位置并允许使用成熟的线性控制技术。通过构造使嵌入与期望轨迹（即同胚）具有相同拓扑性质，从而保持稳定性特性。文章通过在一组Quanser QDrone四旋翼无人机上实施该方法，展示了其实现无人机群自组织到期望轨迹同时保持均匀间距的灵活性和有效性。 <div>
arXiv:2411.11142v1 Announce Type: new 
Abstract: This work investigates the self-organization of multi-agent systems into closed trajectories, a common requirement in unmanned aerial vehicle (UAV) surveillance tasks. In such scenarios, smooth, unbiased control signals save energy and mitigate mechanical strain. We propose a decentralized control system architecture that produces a globally stable emergent structure from local observations only; there is no requirement for agents to share a global plan or follow prescribed trajectories. Central to our approach is the formulation of an injective virtual embedding induced by rotations from the actual agent positions. This embedding serves as a structure-preserving map around which all agent stabilize their relative positions and permits the use of well-established linear control techniques. We construct the embedding such that it is topologically equivalent to the desired trajectory (i.e., a homeomorphism), thereby preserving the stability characteristics. We demonstrate the versatility of this approach through implementation on a swarm of Quanser QDrone quadcopters. Results demonstrate the quadcopters self-organize into the desired trajectory while maintaining even separation.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Signaling and Social Learning in Swarms of Robots</title>
<link>https://arxiv.org/abs/2411.11616</link>
<guid>https://arxiv.org/abs/2411.11616</guid>
<content:encoded><![CDATA[
<div> 关键词：communication, coordination, robot swarms, learning, decentralized

总结:
本文研究了通信在改善机器人 Swarm 中协调性方面的作用，重点关注同时进行学习和执行的分布式环境。文章强调了通信在解决功劳分配问题（个体对整体性能的贡献）以及它如何受此影响的重要性。文中提出了一种关于通信的分类体系，主要分为信息选择和物理抽象两个轴线，从低层次的无损压缩与原始信号提取处理到高层次的有损压缩与结构化通信模型。通过对进化机器人、多智能体（深度）强化学习、语言模型和生物物理模型等领域的现有研究进行回顾，文章概述了在通过局部消息交换不断从彼此中学习的集体机器人中，通信所面临的挑战与机遇，展示了一种社会学习的形式。<br /><br /> <div>
arXiv:2411.11616v1 Announce Type: new 
Abstract: This paper investigates the role of communication in improving coordination within robot swarms, focusing on a paradigm where learning and execution occur simultaneously in a decentralized manner. We highlight the role communication can play in addressing the credit assignment problem (individual contribution to the overall performance), and how it can be influenced by it. We propose a taxonomy of existing and future works on communication, focusing on information selection and physical abstraction as principal axes for classification: from low-level lossless compression with raw signal extraction and processing to high-level lossy compression with structured communication models. The paper reviews current research from evolutionary robotics, multi-agent (deep) reinforcement learning, language models, and biophysics models to outline the challenges and opportunities of communication in a collective of robots that continuously learn from one another through local message exchanges, illustrating a form of social learning.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Incremental Named Entity Recognition</title>
<link>https://arxiv.org/abs/2411.11623</link>
<guid>https://arxiv.org/abs/2411.11623</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Named Entity Recognition (FNER), Federated Incremental NER, Local-Global Forgetting Defense (LGFD), 知识蒸馏, 异型对比学习

总结:
本文提出了一种针对联邦增量命名实体识别（Federated Incremental NER）问题的解决方案，该问题涉及到连续出现新实体类型和不定期加入的新客户端。为了解决此问题，研究者们提出了局部-全局遗忘防御（LGFD）模型。针对客户端内部遗忘的问题，LGFD模型采用结构知识蒸馏损失以保持潜在空间的特征结构，并利用伪标签引导的异型对比损失增强不同实体类型的判别能力，有效保存了先前学到的知识。对于客户端间遗忘的挑战，LGFD模型设计了一个任务切换监控器，能够在保护隐私的前提下自动识别新实体类型，并存储最新的旧全局模型用于知识蒸馏和伪标签生成。实验结果显示，与比较方法相比，LGFD模型有显著的性能提升。 <div>
arXiv:2411.11623v1 Announce Type: new 
Abstract: Federated Named Entity Recognition (FNER) boosts model training within each local client by aggregating the model updates of decentralized local clients, without sharing their private data. However, existing FNER methods assume fixed entity types and local clients in advance, leading to their ineffectiveness in practical applications. In a more realistic scenario, local clients receive new entity types continuously, while new local clients collecting novel data may irregularly join the global FNER training. This challenging setup, referred to here as Federated Incremental NER, renders the global model suffering from heterogeneous forgetting of old entity types from both intra-client and inter-client perspectives. To overcome these challenges, we propose a Local-Global Forgetting Defense (LGFD) model. Specifically, to address intra-client forgetting, we develop a structural knowledge distillation loss to retain the latent space's feature structure and a pseudo-label-guided inter-type contrastive loss to enhance discriminative capability over different entity types, effectively preserving previously learned knowledge within local clients. To tackle inter-client forgetting, we propose a task switching monitor that can automatically identify new entity types under privacy protection and store the latest old global model for knowledge distillation and pseudo-labeling. Experiments demonstrate significant improvement of our LGFD model over comparison methods.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Competing Bandits in Decentralized Large Contextual Matching Markets</title>
<link>https://arxiv.org/abs/2411.11794</link>
<guid>https://arxiv.org/abs/2411.11794</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体资源受限匹配市场、分布式学习、两-sided匹配市场、线性上下文带宽算法、动态匹配市场

总结:
这篇论文关注的是在多智能体资源受限匹配市场中，针对具有时间变化偏好的两-sided匹配市场的分布式学习问题。现有的探索-然后-承诺或上界置信区间等学习算法对于该问题效率低下，其单个代理的遗憾值与手臂数量 $K$ 成正比。受到线性上下文带宽框架的启发，文章假设每个代理对手臂的期望回报可以用已知特征向量和未知（代理特定）参数的线性函数表示。此外，文中设定的场景还捕获了匹配市场需求随时间动态变化的本质。为此，论文提出了实现与手臂数量无关的实例依赖对数遗憾值的新算法。<br /><br /> <div>
arXiv:2411.11794v1 Announce Type: new 
Abstract: Sequential learning in a multi-agent resource constrained matching market has received significant interest in the past few years. We study decentralized learning in two-sided matching markets where the demand side (aka players or agents) competes for a `large' supply side (aka arms) with potentially time-varying preferences, to obtain a stable match. Despite a long line of work in the recent past, existing learning algorithms such as Explore-Then-Commit or Upper-Confidence-Bound remain inefficient for this problem. In particular, the per-agent regret achieved by these algorithms scales linearly with the number of arms, $K$. Motivated by the linear contextual bandit framework, we assume that for each agent an arm-mean can be represented by a linear function of a known feature vector and an unknown (agent-specific) parameter.
  Moreover, our setup captures the essence of a dynamic (non-stationary) matching market where the preferences over arms change over time. Our proposed algorithms achieve instance-dependent logarithmic regret, scaling independently of the number of arms, $K$.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DecTest: A Decentralised Testing Architecture for Improving Data Accuracy of Blockchain Oracle</title>
<link>https://arxiv.org/abs/2404.13535</link>
<guid>https://arxiv.org/abs/2404.13535</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、oracle、数据准确性、去中心化测试架构（DecTest）、随机秘密测试机制

<br /><br />总结:

本文针对区块链系统中链上与链下数据交互的难题以及现有oracle节点可能存在外部攻击或出于自私动机提供不准确数据的问题，提出了一种新的去中心化测试架构（DecTest）。该架构首先引入了一个区块链预言机随机秘密测试机制，通过建立动态匿名提问验证委员会，增强了对节点的监控和验证。在此基础上，设计了一个全面的评价激励机制，依据节点的声誉分数对其工作表现进行评估并给予激励。模拟结果显示，该方案成功地将获取数据的离散熵值降低了61.4%，从而提高了数据的真实性和准确性。 <div>
arXiv:2404.13535v2 Announce Type: replace 
Abstract: Blockchain technology ensures secure and trustworthy data flow between multiple participants on the chain, but interoperability of on-chain and off-chain data has always been a difficult problem that needs to be solved. To solve the problem that blockchain systems cannot access off-chain data, oracle is introduced. However, existing research mainly focuses on the consistency and integrity of data, but ignores the problem that oracle nodes may be externally attacked or provide false data for selfish motives, resulting in the unresolved problem of data accuracy. In this paper, we introduce a new Decentralized Testing architecture (DecTest) that aims to improve data accuracy. A blockchain oracle random secret testing mechanism is first proposed to enhance the monitoring and verification of nodes by introducing a dynamic anonymized question-verification committee. Based on this, a comprehensive evaluation incentive mechanism is designed to incentivize honest work performance by evaluating nodes based on their reputation scores. The simulation results show that we successfully reduced the discrete entropy value of the acquired data and the real value of the data by 61.4%.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Space-Air-Ground Integrated MEC-Assisted Industrial Cyber-Physical Systems: An Online Decentralized Optimization Approach</title>
<link>https://arxiv.org/abs/2411.09712</link>
<guid>https://arxiv.org/abs/2411.09712</guid>
<content:encoded><![CDATA[
<div> 关键词: 云计算, 边缘计算, 空天地一体化多接入边缘计算(SAGIMEC), 工业 cyber-物理系统(ICPS), 联合优化问题(JSC4OP)

<br /><br />总结:
本文介绍了SAGIMEC辅助的ICPS架构，该架构通过卫星网络实现云边计算与无缝连接，以提升IoTDs的服务质量和系统的确定性。文章提出了一个综合的联合卫星选择、计算卸载、通信资源分配、计算资源分配和无人机轨迹控制优化问题(JSC4OP)，旨在最大化IoTDs的服务质量，同时考虑了系统环境动态、不确定性及无人机的资源和能源限制。为解决这个复杂问题，文章提出了一种在线分散式优化方法(ODOA)。首先，利用Lyapunov优化将JSC4OP转化为实时决策优化问题(RDOP)；接着，引入在线学习的延迟预测方法预测不确定的系统环境，并采用博弈论决策方法进行实时决策。理论分析证实了ODOA的有效性，而仿真结果表明，所提出的ODOA方案相比于其他替代方法在整体系统性能上表现出优越性。 <div>
arXiv:2411.09712v1 Announce Type: new 
Abstract: Cloud computing and edge/fog computing are playing a pivotal role in driving the transformation of industrial cyber-physical systems (ICPS) towards greater intelligence and automation by providing high-quality computation offloading services to Internet of Things devices (IoTDs). Recently, space-air-ground integrated multi-access edge computing (SAGIMEC) is emerging as a promising architecture combining edge computing and cloud computing, which has the potential to be integrated with ICPS to accelerate the realization of the above vision. In this work, we first present an SAGIMEC-assisted ICPS architecture that incorporates edge computing and cloud computing through seamless connectivity supported by satellite networks to achieve determinism in connectivity, networked computing, and intelligent networked control. Then, we formulate a joint satellite selection, computation offloading, communication resource allocation, computation resource allocation, and UAV trajectory control optimization problem (JSC4OP) to maximize the quality of service (QoS) of IoTDs. This problem considers both the dynamics and uncertainties of the system environment, as well as the limited resources and energy of UAVs. Given the complexity of JSC4OP, we propose an online decentralized optimization approach (ODOA) to solve the problem. Specifically, JSC4OP is first transformed into a real-time decision-making optimization problem (RDOP) by leveraging Lyapunov optimization. Then, to solve the RDOP, we introduce an online learning-based latency prediction method to predict the uncertain system environment and a game theoretic decision-making method to make real-time decisions. Finally, theoretical analysis confirms the effectiveness of the ODOA, while the simulation results demonstrate that the proposed ODOA outperforms other alternative approaches in terms of overall system performance.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Readability Evaluation for Graph Layouts: 2D Geometric Distributed Algorithms</title>
<link>https://arxiv.org/abs/2411.09809</link>
<guid>https://arxiv.org/abs/2411.09809</guid>
<content:encoded><![CDATA[
<div> 关键词: 图可视化、可读性指标、计算复杂性、分布式环境、Spark

总结:
本文主要探讨了图在社交网络、金融和区块链等领域中的重要性以及其可视化对于识别结构模式的关键作用。现有的可读性评估方法在处理大规模图时面临计算密集型挑战。针对这一问题，先前利用机器学习预测渲染图像的可读性得分的方法虽有一定提升，但在处理大量节点的图时，存在内存需求大、准确度不高的缺点。为解决这些问题，该研究提出了一种利用Spark的DataFrame和GraphFrame框架在分布式环境中实现可读性评价的可扩展算法。实验结果显示，这些分布式算法显著减少了计算时间，对于大型数据集的节点遮挡计算速度提高了约17倍，边交叉计算速度提高了约146倍。这使得大规模图的可读性评估变得更加实用和高效，有效克服了以往机器学习方法的局限性。<br /><br /> <div>
arXiv:2411.09809v1 Announce Type: new 
Abstract: Graphs, consisting of vertices and edges, are vital for representing complex relationships in fields like social networks, finance, and blockchain. Visualizing these graphs helps analysts identify structural patterns, with readability metrics-such as node occlusion and edge crossing-assessing layout clarity. However, calculating these metrics is computationally intensive, making scalability a challenge for large graphs. Without efficient readability metrics, layout generation processes-despite numerous studies focused on accelerating them-face bottleneck, making it challenging to select or produce optimized layouts swiftly. Previous approaches attempted to accelerate this process through machine learning models. Machine learning approaches aimed to predict readability scores from rendered images of graphs. While these models offered some improvement, they struggled with scalability and accuracy, especially for graphs with thousands of nodes. For instance, this approach requires substantial memory to process large images, as it relies on rendered images of the graph; graphs with more than 600 nodes cannot be inputted into the model, and errors can exceed 55% in some readability metrics due to difficulties in generalizing across diverse graph layouts. This study addresses these limitations by introducing scalable algorithms for readability evaluation in distributed environments, utilizing Spark's DataFrame and GraphFrame frameworks to efficiently manage large data volumes across multiple machines. Experimental results show that these distributed algorithms significantly reduce computation time, achieving up to a 17x speedup for node occlusion and a 146x improvement for edge crossing on large datasets. These enhancements make scalable graph readability evaluation practical and efficient, overcoming the limitations of previous machine-learning approaches.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>FedRewind: Rewinding Continual Model Exchange for Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2411.09842</link>
<guid>https://arxiv.org/abs/2411.09842</guid>
<content:encoded><![CDATA[
<div> 关键词：FedRewind、去中心化联邦学习、数据分布偏移、持续学习、模型交换

<br />
总结:
本文提出了FedRewind，一种新颖的去中心化联邦学习方法，该方法利用节点间的模型交换来应对数据分布偏移问题。FedRewind借鉴了持续学习（CL）原理和认知神经科学中关于记忆保持的理论，实现了一个去中心化的路由机制，使得节点可以向其他节点发送/接收模型，以解决分布式学习中的空间分布挑战。在局部训练过程中，联盟节点定期将其模型回传（即回溯）到它们最初接收到模型的节点进行有限次数的迭代，以此减少节点间数据分布的差异，从而提升学习和泛化性能。实验结果显示，FedRewind优于标准的去中心化联邦学习方法以及那些在联盟内部强制实施特定路由策略的方法。此外，通过结合联邦学习与持续学习的概念，FedRewind还能应对更为复杂的联邦持续学习任务，即同时存在空间和时间上的数据偏移变化，超过了现有的基线方法。 <div>
arXiv:2411.09842v1 Announce Type: new 
Abstract: In this paper, we present FedRewind, a novel approach to decentralized federated learning that leverages model exchange among nodes to address the issue of data distribution shift. Drawing inspiration from continual learning (CL) principles and cognitive neuroscience theories for memory retention, FedRewind implements a decentralized routing mechanism where nodes send/receive models to/from other nodes in the federation to address spatial distribution challenges inherent in distributed learning (FL). During local training, federation nodes periodically send their models back (i.e., rewind) to the nodes they received them from for a limited number of iterations. This strategy reduces the distribution shift between nodes' data, leading to enhanced learning and generalization performance. We evaluate our method on multiple benchmarks, demonstrating its superiority over standard decentralized federated learning methods and those enforcing specific routing schemes within the federation. Furthermore, the combination of federated and continual learning concepts enables our method to tackle the more challenging federated continual learning task, with data shifts over both space and time, surpassing existing baselines.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Express Yourself: Enabling large-scale public events involving multi-human-swarm interaction for social applications with MOSAIX</title>
<link>https://arxiv.org/abs/2411.09975</link>
<guid>https://arxiv.org/abs/2411.09975</guid>
<content:encoded><![CDATA[
<div> 关键词：Robot swarms, Multi-human-swarm interaction, MOSAIX, Swarm of robot Tiles, Public event

总结:<br />
本文介绍了研究团队在利用机器人蜂群MOSAIX于科学博物馆中促进公众创新思维的过程。MOSAIX由63台机器人“智能便利贴”组成，它们能够收集公众意见并根据主题进行聚合，为参观者提供了一个动态的可视化工具，从而吸引游客参与其中。该工作着重在于创建了一个大规模（涉及63台机器人和294名参与者）的真实生活场景下的公共活动，并采用了一种完全去中心化的蜂群系统。此外，文中还分享了从中获得的经验教训，以期对未来的多人类与机器人蜂群互动研究提供参考。 <div>
arXiv:2411.09975v1 Announce Type: new 
Abstract: Robot swarms have the potential to help groups of people with social tasks, given their ability to scale to large numbers of robots and users. Developing multi-human-swarm interaction is therefore crucial to support multiple people interacting with the swarm simultaneously - which is an area that is scarcely researched, unlike single-human, single-robot or single-human, multi-robot interaction. Moreover, most robots are still confined to laboratory settings. In this paper, we present our work with MOSAIX, a swarm of robot Tiles, that facilitated ideation at a science museum. 63 robots were used as a swarm of smart sticky notes, collecting input from the public and aggregating it based on themes, providing an evolving visualization tool that engaged visitors and fostered their participation. Our contribution lies in creating a large-scale (63 robots and 294 attendees) public event, with a completely decentralized swarm system in real-life settings. We also discuss learnings we obtained that might help future researchers create multi-human-swarm interaction with the public.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoK: Consensus for Fair Message Ordering</title>
<link>https://arxiv.org/abs/2411.09981</link>
<guid>https://arxiv.org/abs/2411.09981</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本系统、共识协议、公平性、最大可提取价值(MEV)、消息排序

<br /><br />总结:
本文针对分布式账本系统（如区块链）中依赖于共识协议进行消息排序的问题进行了深入研究，重点关注了那些致力于促进消息排序公平性的方法，包括基于先进先出（FIFO）、随机和盲排序等不同策略的共识协议。文章讨论了在拜占庭容错环境下实现公平消息排序所面临的挑战与权衡，并总结了构建公平消息排序共识协议的关键步骤。此外，文中提出了一条设计指导原则，并以此为依据优化了当前最先进的FIFO排序协议——Themis。该工作建立了一个统一的框架，用于评估和提升分布式账本系统的公平性。 <div>
arXiv:2411.09981v1 Announce Type: new 
Abstract: Distributed ledger systems, such as blockchains, rely on consensus protocols that constantly commit messages in an agreed order for processing. In practice, message ordering within these systems is often reward-driven. This raises concerns about fairness, particularly in decentralized finance applications, where nodes can exploit transaction orders to maximize rewards (Maximal Extractable Value, MEV). This paper provides a structured review of consensus protocols that order messages with different approaches, especially focusing on the ones that promote order fairness, using methods including First-In-First-Out (FIFO), random, and blind ordering. We review the challenges and trade-offs of deriving fair message ordering in a Byzantine fault-tolerant setting, and summarize the key steps for making a fair message ordering consensus protocol. We introduce a design guideline, with which we propose a performance optimization to the state-of-the-art FIFO ordering protocol Themis. This work establishes a unified framework for accessing and enhancing fairness in distributed ledger systems.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Roadmap for Quantum- Resistant Security: A Framework for Preparing Industries for the Quantum Threat</title>
<link>https://arxiv.org/abs/2411.09995</link>
<guid>https://arxiv.org/abs/2411.09995</guid>
<content:encoded><![CDATA[
<div> 关键词: 量子计算, 密码系统, 抗量子攻击, STL-QCRYPTO框架, 行业安全

总结:<br />
随着量子计算的发展，其对广泛使用的密码系统的威胁给现代网络安全带来了重大挑战。本文提出了一种应对量子攻击的战略路线图，旨在帮助各行业预见并减轻量子风险。文章介绍了一个名为STL-QCRYPTO的新型战略框架，该框架为实现行业特定的量子安全系统提供了务实和战略性的方法。文中深入评估了金融服务业、银行业、医疗保健、关键基础设施等十四大高风险行业的量子威胁脆弱性，并着重探讨了这些行业实施量子安全防护系统的实际路径。同时，论文还讨论了采用抗量子技术所面临的技術、操作及监管难题。通过提供结构化的时间线和可操作建议，本文构建的路线图与框架有助于各行业在量子计算时代制定抵御潜在安全威胁的战略。 <div>
arXiv:2411.09995v1 Announce Type: new 
Abstract: As quantum computing continues to advance, its ability to compromise widely used cryptographic systems projects a significant challenge to modern cybersecurity. This paper outlines a strategic roadmap for industries to anticipate and mitigate the risks posed by quantum attacks. Our study explores the development of a quantum-resistant cryptographic solutioning framework for the industry, offering a practical and strategic approach to mitigating quantum attacks. We, here, propose a novel strategic framework, coined name STL-QCRYPTO, outlines tailored, industry-specific methodologies to implement quantum-safe security systems, ensuring long-term protection against the disruptive potential of quantum computing. The following fourteen high-risk sectors: Financial Services, Banking, Healthcare, Critical Infrastructure, Government & Defence, E-commerce, Energy & Utilities, Automotive & Transportation, Cloud Computing & Data Storage, Insurance, Internet & Telecommunications, Blockchain Applications, Metaverse Applications, and Multiagent AI Systems - are critically assessed for their vulnerability to quantum threats. The evaluation emphasizes practical approaches for the deployment of quantum-safe security systems to safeguard these industries against emerging quantum-enabled cyber risks. Additionally, the paper addresses the technical, operational, and regulatory hurdles associated with adopting quantum-resistant technologies. By presenting a structured timeline and actionable recommendations, this roadmap with proposed framework prepares industries with the essential strategy to safeguard their potential security threats in the quantum computing era.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Omnichain Web: The Universal Framework for Streamlined Chain Abstraction and Cross-Layer Interaction</title>
<link>https://arxiv.org/abs/2411.10132</link>
<guid>https://arxiv.org/abs/2411.10132</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3、碎片化流动性、互操作性、Omnichain Web、跨链资产结算

总结:
<br />
Omnichain Web 是一个旨在解决Web3生态系统中碎片化流动性与Layer 1和Layer 2区块链之间有限互操作性的框架。它通过核心组件——OmniRollups、Proof Network、Ragno Network和Builder Marketplace实现统一化的去中心化网络。该生态系统支持无缝跨链资产结算和互操作性，并为开发用户友好的去中心化应用（dApp）提供便利。其创新技术包括模块化证明网络和可信执行环境（TEEs），并结合先进的零知识证明系统及AI代理兼容性，实现意图驱动和自主功能，优化了区块链间的流动性管理和用户体验。此外，Omnichain Web还提供了用于L1基础设施的去中心化市场，降低了运营开销，并促进了可扩展、安全和高效的跨链协议。作为一项开创性解决方案，Omnichain Web无缝连接Web2和Web3，推动了一个全面互联的数字经济发展。 <div>
arXiv:2411.10132v1 Announce Type: new 
Abstract: The evolution of the Web3 ecosystem has been hindered by fragmented liquidity and limited interoperability across Layer 1 (L1) and Layer 2 (L2) blockchains, which leads to inefficiencies and elevated costs. Omnichain Web addresses these challenges by introducing a comprehensive framework to unify decentralized networks through its core components: OmniRollups, Proof Network, Ragno Network, and Builder Marketplace. This ecosystem enables seamless cross-chain asset settlement, interoperability, and user-friendly decentralized application (dApp) development, driven by innovative technologies such as modular proof networks and trusted execution environments (TEEs). By integrating advanced zero-knowledge proof systems and compatibility with AI agents, Omnichain Web empowers intent-driven and autonomous functionalities, streamlining liquidity management and user interactions across blockchains. Furthermore, its decentralized marketplace for L1 infrastructure reduces operational overhead and promotes scalable, secure, and efficient cross-chain protocols. As a pioneering solution, Omnichain Web seamlessly connects Web2 and Web3, enabling a holistic and interconnected digital economy.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Definition and Detection of Centralization Defects in Smart Contracts</title>
<link>https://arxiv.org/abs/2411.10169</link>
<guid>https://arxiv.org/abs/2411.10169</guid>
<content:encoded><![CDATA[
<div> 关键词: 中心化缺陷、智能合约、安全事件、CDRipper、检测工具

<br /><br />总结:

本文针对近年来由于智能合约中心化缺陷导致的安全事件及大量财务损失问题进行了研究。文章提出了六种类型的智能合约中心化缺陷，并通过分析597篇Stack Exchange帖子和117份审计报告进行详细描述与实例展示。为填补当前对这类缺陷分析不足的空白，作者开发了一款名为CDRipper的工具，该工具通过构建权限依赖图(PDG)，从智能合约源代码中提取函数的权限依赖关系，并检测函数中的敏感操作，依据预定义模式识别中心化缺陷。实验结果显示，在对244,424个真实世界的智能合约进行大规模检测后，共有82,446个合同存在至少一种中心化缺陷，而CDRipper工具在此过程中达到了93.7%的整体精确度。 <div>
arXiv:2411.10169v1 Announce Type: new 
Abstract: In recent years, security incidents stemming from centralization defects in smart contracts have led to substantial financial losses. A centralization defect refers to any error, flaw, or fault in a smart contract's design or development stage that introduces a single point of failure. Such defects allow a specific account or user to disrupt the normal operations of smart contracts, potentially causing malfunctions or even complete project shutdowns. Despite the significance of this issue, most current smart contract analyses overlook centralization defects, focusing primarily on other types of defects. To address this gap, our paper introduces six types of centralization defects in smart contracts by manually analyzing 597 Stack Exchange posts and 117 audit reports. For each defect, we provide a detailed description and code examples to illustrate its characteristics and potential impacts. Additionally, we introduce a tool named CDRipper (Centralization Defects Ripper) designed to identify the defined centralization defects. Specifically, CDRipper constructs a permission dependency graph (PDG) and extracts the permission dependencies of functions from the source code of smart contracts. It then detects the sensitive operations in functions and identifies centralization defects based on predefined patterns. We conduct a large-scale experiment using CDRipper on 244,424 real-world smart contracts and evaluate the results based on a manually labeled dataset. Our findings reveal that 82,446 contracts contain at least one of the six centralization defects, with our tool achieving an overall precision of 93.7%.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Driven Decentralized Control Design for Discrete-Time Large-Scale Systems</title>
<link>https://arxiv.org/abs/2411.10243</link>
<guid>https://arxiv.org/abs/2411.10243</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、控制器设计、离散时间大系统、解中心化控制、半定规划问题

<br />
总结:
本文提出了一种针对离散时间大规模系统的数据驱动控制器设计方法。该方法将大规模系统转化为等效的数据驱动形式，并利用其子系统的状态、控制输入和互联系统输入数据来参数化解中心化控制器。通过结合开发的数据驱动方法与李亚普诺夫方法，构建了一个数据驱动的半定规划问题以求得稳定性的解中心化控制器。这种方法在对一串质量弹簧模型的验证中表现出显著优势，即避免了繁琐的建模过程。 <div>
arXiv:2411.10243v1 Announce Type: new 
Abstract: In this paper, a data-driven approach is developed for controller design for a class of discrete-time large-scale systems, where a large-scale system can be expressed in an equivalent data-driven form and the decentralized controllers can be parameterized by the data collected from its subsystems, i.e., system state, control input, and interconnection input. Based on the developed data-driven method and the Lyapunov approach, a data-driven semi-definite programming problem is constructed to obtain decentralized stabilizing controllers. The proposed approach has been validated on a mass-spring chain model, with the significant advantage of avoiding extensive modeling processes.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>How the interplay between power concentration, competition, and propagation affects the resource efficiency of distributed ledgers</title>
<link>https://arxiv.org/abs/2411.10249</link>
<guid>https://arxiv.org/abs/2411.10249</guid>
<content:encoded><![CDATA[
<div> 关键词：Bitcoin网络、分叉、共识协议、矿工异质性、块传播时间

<br /><br />总结:
本文介绍了关于比特币网络中自然分叉的研究，其频率作为分布式账本效率的关键指标，可能导致资源浪费和网络安全问题。研究提出了一种模型，用于预测具有不同矿工数量、哈希率分布以及块传播时间的异质矿工网络中的自然分叉率。该模型预测的分叉率与实测的废弃区块率相当。过去十年间，采矿池的数量大约减少了三分之一，论文量化了这一变化对分叉率的影响，并揭示了由于全球能源供应限制导致的哈希率分布呈现截尾幂律分布的现象。文章通过实证分析和定量模型证明，块传播时间和挖矿时间的比例是评估分叉率的一个准确指标，并进一步量化了它对矿工活动异质性的依赖。此外，文中提供了理论和实证证据表明，哈希率集中度降低和块传播时间缩短可以减少分布式账本中的分叉率。这项工作为研究分布式网络上的权力集中和竞争提供了一个稳健的数学框架，有助于解释由自私挖矿策略和不对称传播时间引起的分叉率差异，从而为现有和新兴区块链分布式挖掘系统的未来设计提供了有效的工具。 <div>
arXiv:2411.10249v1 Announce Type: new 
Abstract: Forks in the Bitcoin network result from the natural competition in the blockchain's Proof-of-Work consensus protocol. Their frequency is a critical indicator for the efficiency of a distributed ledger as they can contribute to resource waste and network insecurity. We introduce a model for the estimation of natural fork rates in a network of heterogeneous miners as a function of their number, the distribution of hash rates and the block propagation time over the peer-to-peer infrastructure. Despite relatively simplistic assumptions, such as zero propagation delay within mining pools, the model predicts fork rates which are comparable with the empirical stale blocks rate. In the past decade, we observe a reduction in the number of mining pools approximately by a factor 3, and quantify its consequences for the fork rate, whilst showing the emergence of a truncated power-law distribution in hash rates, justified by a rich-get-richer effect constrained by global energy supply limits. We demonstrate, both empirically and with the aid of our quantitative model, that the ratio between the block propagation time and the mining time is a sufficiently accurate estimator of the fork rate, but also quantify its dependence on the heterogeneity of miner activities. We provide empirical and theoretical evidence that both hash rate concentration and lower block propagation time reduce fork rates in distributed ledgers. Our work introduces a robust mathematical setting for investigating power concentration and competition on a distributed network, for interpreting discrepancies in fork rates -- for example caused by selfish mining practices and asymmetric propagation times -- thus providing an effective tool for designing future and alternative scenarios for existing and new blockchain distributed mining systems.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bitcoin Research with a Transaction Graph Dataset</title>
<link>https://arxiv.org/abs/2411.10325</link>
<guid>https://arxiv.org/abs/2411.10325</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、大规模数据集、交易图、节点标签、图神经网络

<br /><br />总结:
本文介绍了由Satoshi Nakamoto于2008年创立的比特币如何构建了一个无需中央权威机构即可存储和转移价值的全新数字经济。文章提出了一项大规模比特币交易数据集，该数据集以交易图的形式呈现，包含了约2.52亿个节点、7.85亿条边，时间跨度近13年，涵盖了6.7亿笔交易，且每个节点和边都带有时间戳。数据集提供了两个标注集合：一是基于实体类型的3.3万个节点；二是将近10万比特币地址，标注了实体名称和类型，这是迄今为止公开可用的最大规模比特币交易数据集，旨在促进该领域的深入研究，克服现有数据集的局限性。此外，通过训练各种图神经网络模型来预测节点标签，为未来研究建立了基准，并展示了数据集在比特币分析之外的多种应用场景。最后，所有数据和源代码均对公众开放，以实现结果的可复现性。 <div>
arXiv:2411.10325v1 Announce Type: new 
Abstract: Bitcoin, launched in 2008 by Satoshi Nakamoto, established a new digital economy where value can be stored and transferred in a fully decentralized manner - alleviating the need for a central authority. This paper introduces a large scale dataset in the form of a transactions graph representing transactions between Bitcoin users along with a set of tasks and baselines. The graph includes 252 million nodes and 785 million edges, covering a time span of nearly 13 years of and 670 million transactions. Each node and edge is timestamped. As for supervised tasks we provide two labeled sets i. a 33,000 nodes based on entity type and ii. nearly 100,000 Bitcoin addresses labeled with an entity name and an entity type. This is the largest publicly available data set of bitcoin transactions designed to facilitate advanced research and exploration in this domain, overcoming the limitations of existing datasets. Various graph neural network models are trained to predict node labels, establishing a baseline for future research. In addition, several use cases are presented to demonstrate the dataset's applicability beyond Bitcoin analysis. Finally, all data and source code is made publicly available to enable reproducibility of the results.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Game Theoretic Liquidity Provisioning in Concentrated Liquidity Market Makers</title>
<link>https://arxiv.org/abs/2411.10399</link>
<guid>https://arxiv.org/abs/2411.10399</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化标记制造商 (AMM), 集中流动性市场制造商 (CLMM), 流动性提供者 (LP), 纳什均衡, 水平填充策略

<br /><br />总结:
本文介绍了自动化标记制造商（AMMs）和集中流动性市场制造商（CLMMs），这是一种允许自动交易数字资产并由流动性提供者（LPs）提供存款的去中心化交易所。研究重点在于CLMMs中LPs的战略规划与激励机制。文章构建了一个博弈论模型分析LPs的行为，并发现原问题可能存在多个纳什均衡且复杂度随价格刻度数量呈二次增长，但可简化为具有唯一纳什均衡、复杂度线性增长的游戏。简化后的纳什均衡表现为低预算LP会使用全部预算，而富裕LP则不会完全投入。通过对真实世界CLMM数据的拟合，观察到在含有风险资产的流动资金池中，LPs的投资策略远离纳什均衡，他们倾向于在更少且更宽的价格范围内投资，并减少流动性更新频率。研究进一步表明，如果LPs调整其策略以更接近游戏的纳什均衡，他们的日均收益可提高约116美元，即日投资回报率中位数增加0.009%。 <div>
arXiv:2411.10399v1 Announce Type: new 
Abstract: Automated marker makers (AMMs) are a class of decentralized exchanges that enable the automated trading of digital assets. They accept deposits of digital tokens from liquidity providers (LPs); tokens can be used by traders to execute trades, which generate fees for the investing LPs. The distinguishing feature of AMMs is that trade prices are determined algorithmically, unlike classical limit order books. Concentrated liquidity market makers (CLMMs) are a major class of AMMs that offer liquidity providers flexibility to decide not only \emph{how much} liquidity to provide, but \emph{in what ranges of prices} they want the liquidity to be used. This flexibility can complicate strategic planning, since fee rewards are shared among LPs. We formulate and analyze a game theoretic model to study the incentives of LPs in CLMMs. Our main results show that while our original formulation admits multiple Nash equilibria and has complexity quadratic in the number of price ticks in the contract, it can be reduced to a game with a unique Nash equilibrium whose complexity is only linear. We further show that the Nash equilibrium of this simplified game follows a waterfilling strategy, in which low-budget LPs use up their full budget, but rich LPs do not. Finally, by fitting our game model to real-world CLMMs, we observe that in liquidity pools with risky assets, LPs adopt investment strategies far from the Nash equilibrium. Under price uncertainty, they generally invest in fewer and wider price ranges than our analysis suggests, with lower-frequency liquidity updates. We show that across several pools, by updating their strategy to more closely match the Nash equilibrium of our game, LPs can improve their median daily returns by \$116, which corresponds to an increase of 0.009\% in median daily return on investment.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Coordination of Distributed Energy Resources through Local Energy Markets and Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2404.13142</link>
<guid>https://arxiv.org/abs/2404.13142</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式能源资源、电力网、交易性能源、深度强化学习、社区净负荷变异性

总结:
随着分布式能源资源（DERs）的增长，电力网格面临边缘区域净负荷波动性增加的问题，影响了运行可靠性和稳定性。交易性能源通过本地能源市场提供了一种分散式的、间接的需求响应解决方案，而深度强化学习（DRL）等模型无关控制技术则使自动化、分散化的参与成为可能。然而，现有研究大多忽视了社区层面的净负荷变异性问题，更关注经济社会指标。本文针对这一空白，利用DRL代理自动参与名为ALEX的本地能源市场，各代理独立行动以最小化各自能源费用。结果表明，降低电费与减少净负荷变异性之间存在紧密联系，通过评估不同时间范围内的指标如爬坡率、负载因子和峰值需求得到证实。将DRL代理与近乎最优的动态规划方法进行基准对比，动态规划方法分别实现了每日进口、出口和峰值需求降低22.05%、83.92%和24.09%，而DRL代理表现出可比或更优的结果，分别降低了21.93%、84.46%和27.02%。该研究表明，DRL在分散化电网管理中的有效性，突显了其在社区驱动的能源市场中实现接近最优性能、减少净负荷变异性方面的可扩展性。 <div>
arXiv:2404.13142v2 Announce Type: replace 
Abstract: As distributed energy resources (DERs) grow, the electricity grid faces increased net load variability at the grid edge, impacting operability and reliability. Transactive energy, facilitated through local energy markets, offers a decentralized, indirect demand response solution, with model-free control techniques, such as deep reinforcement learning (DRL), enabling automated, decentralized participation. However, existing studies largely overlook community-level net load variability, focusing instead on socioeconomic metrics.
  This study addresses this gap by using DRL agents to automate end-user participation in a local energy market (ALEX), where agents act independently to minimize individual energy bills. Results reveal a strong link between bill reduction and decreased net load variability, assessed across metrics such as ramping rate, load factor, and peak demand over various time horizons. Using a no-control baseline, DRL agents are benchmarked against a near-optimal dynamic programming approach. The dynamic programming benchmark achieves reductions of 22.05 percent, 83.92 percent, and 24.09 percent in daily import, export, and peak demand, respectively, while the DRL agents show comparable or superior results with reductions of 21.93 percent, 84.46 percent, and 27.02 percent.
  This study demonstrates the effectiveness of DRL in decentralized grid management, highlighting its scalability and near-optimal performance in reducing net load variability within community-driven energy markets.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multilingual Standalone Trustworthy Voice-Based Social Network for Disaster Situations</title>
<link>https://arxiv.org/abs/2411.08889</link>
<guid>https://arxiv.org/abs/2411.08889</guid>
<content:encoded><![CDATA[
<div> 关键词：灾难场景、语音通信、多语言、人工智能、区块链技术

总结:<br />
本文介绍了一种针对灾难场景下语言障碍问题而设计的创新性、多语言语音社交网络。该系统利用先进的人工智能实现语音实时翻译，确保跨语言间的流畅交流，并结合区块链技术存储安全、不可篡改的消息记录，保证信息完整性。此外，系统能在离线环境下通过本地网络独立运行，提高可靠性，并可在多种设备上跨平台使用，包括移动手机和桌面电脑，具有很好的适应性和易用性。评估结果显示，该系统在语音识别与翻译准确度、低延迟以及用户满意度方面表现优异，验证了其在危机时刻提升沟通效率和包容性的有效作用，代表了灾难通信领域的重大进步。 <div>
arXiv:2411.08889v1 Announce Type: new 
Abstract: In disaster scenarios, effective communication is crucial, yet language barriers often hinder timely and accurate information dissemination, exacerbating vulnerabilities and complicating response efforts. This paper presents a novel, multilingual, voice-based social network specifically designed to address these challenges. The proposed system integrates advanced artificial intelligence (AI) with blockchain technology to enable secure, asynchronous voice communication across multiple languages. The application operates independently of external servers, ensuring reliability even in compromised environments by functioning offline through local networks. Key features include AI-driven real-time translation of voice messages, ensuring seamless cross-linguistic communication, and blockchain-enabled storage for secure, immutable records of all interactions, safeguarding message integrity. Designed for cross-platform use, the system offers consistent performance across devices, from mobile phones to desktops, making it highly adaptable in diverse disaster situations. Evaluation metrics demonstrate high accuracy in speech recognition and translation, low latency, and user satisfaction, validating the system's effectiveness in enhancing communication during crises. This solution represents a significant advancement in disaster communication, bridging language gaps to support more inclusive and efficient emergency response.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Designing Automated Market Makers for Combinatorial Securities: A Geometric Viewpoint</title>
<link>https://arxiv.org/abs/2411.08972</link>
<guid>https://arxiv.org/abs/2411.08972</guid>
<content:encoded><![CDATA[
<div> 关键词：automated market makers (AMMs)，prediction markets，combinatorial securities，VC dimension，range query problem

总结:
这篇文章提出了一种设计任意集系统中自动化做市商(AMMs)的框架，将预测市场的挑战与计算几何中的范围查询问题建立了新的联系。研究者展示了在流行的组合对数市场评分规则市场中，价格查询和交易更新等同于范围查询和范围更新问题，并基于此等价性，构建了当集合系统的VC维数有限时的次线性时间算法，并证明了在VC维数无限的情况下不存在此类算法。此外，他们还将这种方法扩展到了具有二次和幂次评分规则的组合预测市场的AMMs。文章还引入了去中心化金融中AMM的组合交换操作问题，并将其有效地归约为范围更新问题。最后，展示了多分辨率市场设计可以自然地融入到分区树方案中。 <div>
arXiv:2411.08972v1 Announce Type: new 
Abstract: Designing automated market makers (AMMs) for prediction markets on combinatorial securities over large outcome spaces poses significant computational challenges. Prior research has primarily focused on combinatorial prediction markets within specific set systems (e.g., intervals, permutations). We introduce a framework for designing AMMs on arbitrary set systems by building a novel connection to the range query problem in computational geometry. This connection enables the analysis of computational complexity and the design of efficient AMMs.
  We first demonstrate the equivalence between price queries and trade updates under the popular combinatorial logarithmic market scoring rule market and the range query and range update problem. Building on this equivalence, we construct sublinear time algorithms when the VC dimension of the set system is bounded and show the non-existence of such algorithms for unbounded VC dimension cases. We then extend this approach to AMMs for combinatorial prediction markets with quadratic and power scoring rules. Finally, we show that the multi-resolution market design can be naturally integrated into the partition-tree scheme.
  Additionally, we introduce the combinatorial swap operation problem for automated market makers in decentralized finance and show that it can be efficiently reduced to range update problems.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Information Need in Metaverse Recordings - A Field Study</title>
<link>https://arxiv.org/abs/2411.09053</link>
<guid>https://arxiv.org/abs/2411.09053</guid>
<content:encoded><![CDATA[
<div> 关键词：Metaverse Recordings (MVRs)，Multimedia Information Retrieval (MMIR)，field study，information needs，search behaviors

<br /><br />总结:
该论文针对多媒体信息检索(MMIR)领域中新兴且未充分探索的媒体类型——元宇宙记录（MVRs）进行了研究。通过专家访谈和分析，本研究揭示了MVR检索的应用场景以及从元宇宙中检索多媒体内容所面临的挑战。研究结果表明，MVRs现有的应用场景强调了捕获图形渲染过程及相关输入输出设备的时间序列数据的重要性，这些数据对于满足用户需求具有高度相关性。此外，研究还为开发专门针对MVRs的检索系统定义了使用案例、用户画像以及具体要求，从而为MVR检索系统的未来研究与设计奠定了基础，进一步加深了对MVR检索中的信息搜索行为的理解。 <div>
arXiv:2411.09053v1 Announce Type: new 
Abstract: Metaverse Recordings (MVRs) represent an emerging and underexplored media type within the field of Multimedia Information Retrieval (MMIR). This paper presents findings from a field study aimed at understanding the users information needs and search behaviors specific to MVR retrieval. By conducting and analyzing expert interviews, the study identifies application scenarios and highlights challenges in retrieving multimedia content from the metaverse. The results reveal existing application scenarios of MVRs and confirm the relevance of capturing time-series data from the graphical rendering process and related input-output devices, which are also highly relevant to user needs. Furthermore, the study provides a foundation for developing retrieval systems tailored to MVRs by defining use cases, user stereotypes, and specific requirements for MVR Retrieval systems. The findings contribute to a better understanding of information search behaviors in MVR Retrieval and pave the way for future research and system design in this field.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartInv: Multimodal Learning for Smart Contract Invariant Inference</title>
<link>https://arxiv.org/abs/2411.09217</link>
<guid>https://arxiv.org/abs/2411.09217</guid>
<content:encoded><![CDATA[
<div> 关键词：Smart合同、机器不可审计漏洞、智能合约不变量推理框架、多模态信息、零日漏洞

总结:<br />
本文介绍了针对智能合约中“机器不可审计”漏洞检测的新方法——SmartInv。该框架是一款准确快速的智能合约不变量推理工具，旨在通过理解并跨多种模态信息（如源代码和自然语言）进行推理来生成描述智能合约预期行为的不变量。研究提出了一种新的提示策略——层级思考（Tier of Thought, ToT），用于多模态智能合约的理解与推理。实验结果显示，SmartInv相比于现有最先进的工具能生成3.5倍更多的关键性bug不变量，并在显著缩短（150倍）的时间内发现4倍以上的严重漏洞。此外，SmartInv从89,621份真实世界的智能合约中发现了119个零日漏洞，其中五个已被开发者确认为“高危”级别的严重漏洞。 <div>
arXiv:2411.09217v1 Announce Type: new 
Abstract: Smart contracts are software programs that enable diverse business activities on the blockchain. Recent research has identified new classes of "machine un-auditable" bugs that arise from both transactional contexts and source code. Existing detection methods require human understanding of underlying transaction logic and manual reasoning across different sources of context (i.e. modalities), such as code, dynamic transaction executions, and natural language specifying the expected transaction behavior.
  To automate the detection of ``machine un-auditable'' bugs, we present SmartInv, an accurate and fast smart contract invariant inference framework. Our key insight is that the expected behavior of smart contracts, as specified by invariants, relies on understanding and reasoning across multimodal information, such as source code and natural language. We propose a new prompting strategy to foundation models, Tier of Thought (ToT), to reason across multiple modalities of smart contracts and ultimately to generate invariants. By checking the violation of these generated invariants, SmartInv can identify potential vulnerabilities.
  We evaluate SmartInv on real-world contracts and re-discover bugs that resulted in multi-million dollar losses over the past 2.5 years (from January 1, 2021 to May 31, 2023). Our extensive evaluation shows that SmartInv generates (3.5X) more bug-critical invariants and detects (4$\times$) more critical bugs compared to the state-of-the-art tools in significantly (150X) less time. \sys uncovers 119 zero-day vulnerabilities from the 89,621 real-world contracts. Among them, five are critical zero-day bugs confirmed by developers as ``high severity.''
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient and Secure Cross-Domain Data-Sharing for Resource-Constrained Internet of Things</title>
<link>https://arxiv.org/abs/2411.09229</link>
<guid>https://arxiv.org/abs/2411.09229</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网(IoT), 区块链, 数据共享, 分布式密钥生成, 安全性

总结:
<br />
本文针对物联网环境中日益复杂的跨域数据共享所面临的显著安全挑战，提出了一种基于区块链的高效、安全的数据共享方案。该方案采用分布式密钥生成方法，避免了单点故障，并实现了独立的伪名生成和密钥更新，从而提高了认证灵活性并降低了计算开销。此外，该方案还涵盖了数据上传、存储和分享的全过程，确保了数据可追溯性、完整性和隐私保护。通过安全分析，证实了该方案理论上具有安全性，并能抵抗多种攻击；性能评估显示其相比于现有解决方案具有更低的计算和通信开销，因此对于物联网应用而言，该方案既安全又高效。 <div>
arXiv:2411.09229v1 Announce Type: new 
Abstract: The growing complexity of Internet of Things (IoT) environments, particularly in cross-domain data sharing, presents significant security challenges. Existing data-sharing schemes often rely on computationally expensive cryptographic operations and centralized key management, limiting their effectiveness for resource-constrained devices. To address these issues, we propose an efficient, secure blockchain-based data-sharing scheme. First, our scheme adopts a distributed key generation method, which avoids single point of failure. This method also allows independent pseudonym generation and key updates, enhancing authentication flexibility while reducing computational overhead. Additionally, the scheme provides a complete data-sharing process, covering data uploading, storage, and sharing, while ensuring data traceability, integrity, and privacy. Security analysis shows that the proposed scheme is theoretically secure and resistant to various attacks, while performance evaluations demonstrate lower computational and communication overhead compared to existing solutions, making it both secure and efficient for IoT applications.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards efficient compression and communication for prototype-based decentralized learning</title>
<link>https://arxiv.org/abs/2411.09267</link>
<guid>https://arxiv.org/abs/2411.09267</guid>
<content:encoded><![CDATA[
<div> 关键词: prototype-based federated learning, decentralized learning, prototype redundancy, data compression, age-of-information (AoI)

总结:
<br />
本文研究了一种基于原型的去中心化联邦学习系统的设计，旨在提高通信效率。针对原型冗余问题，文章提出了双重数据压缩技术：仅当原型具有信息论上的有用性（通过Jensen-Shannon距离判断）时发送更新消息，并利用聚类对原型进行压缩以减小 gossip 协议中的更新消息大小。此外，文中采用了并行而非序列化的 gossip 通信，并分析了其年龄信息（AoI）。实验结果显示，通过这些改进，可以在不降低学习算法收敛速度的前提下显著减少通信负载。 <div>
arXiv:2411.09267v1 Announce Type: new 
Abstract: In prototype-based federated learning, the exchange of model parameters between clients and the master server is replaced by transmission of prototypes or quantized versions of the data samples to the aggregation server. A fully decentralized deployment of prototype- based learning, without a central agregartor of prototypes, is more robust upon network failures and reacts faster to changes in the statistical distribution of the data, suggesting potential advantages and quick adaptation in dynamic learning tasks, e.g., when the data sources are IoT devices or when data is non-iid. In this paper, we consider the problem of designing a communication-efficient decentralized learning system based on prototypes. We address the challenge of prototype redundancy by leveraging on a twofold data compression technique, i.e., sending only update messages if the prototypes are informationtheoretically useful (via the Jensen-Shannon distance), and using clustering on the prototypes to compress the update messages used in the gossip protocol. We also use parallel instead of sequential gossiping, and present an analysis of its age-of-information (AoI). Our experimental results show that, with these improvements, the communications load can be substantially reduced without decreasing the convergence rate of the learning algorithm.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fully Local Last-Generated Rule in a Blockchain</title>
<link>https://arxiv.org/abs/2411.08439</link>
<guid>https://arxiv.org/abs/2411.08439</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、故意分叉、最后生成规则、局部应用、诚实矿工

总结:
本文提出了一种针对区块链中故意分叉的有效抑制方法——局部可应用的最后生成规则。该规则在发生链并列时选择最近生成的链作为主链，有助于使敌人持有的区块无效。与现有局部方法相比，新方法通过将时钟偏移量$\Delta_{O_i}$的上限设定为200秒，能将诚实矿工在链并列情况下跟随攻击者的情况减少超过40%。这一创新设计更好地满足了保守型加密货币系统（如比特币）对于完全局部化方法的需求。 <div>
arXiv:2411.08439v1 Announce Type: new 
Abstract: An effective method for suppressing intentional forks in a blockchain is the last-generated rule, which selects the most recent chain as the main chain in the event of a chain tie. This rule helps invalidate blocks that are withheld by adversaries for a certain period. However, existing last-generated rules face an issue in that their applications to the system are not fully localized. In conservative cryptocurrency systems such as Bitcoin, it is desirable for methods to be applied in a fully local manner. In this paper, we propose a locally applicable last-generated rule. Our method is straightforward and is based on a relative time reference. By conservatively setting the upper bound for the clock skews $\Delta_{O_i}$ to 200 s, our proposed method reduces the proportion $\gamma$ of honest miners following the attacker during chain ties by more than 40% compared to existing local methods.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secure Intelligent O-RAN Architecture: Vulnerabilities, Threats and Promising Technical Solutions using LLMs</title>
<link>https://arxiv.org/abs/2411.08640</link>
<guid>https://arxiv.org/abs/2411.08640</guid>
<content:encoded><![CDATA[
<div> 关键词: O-RAN、安全分析、零信任、移动目标防御(MTD)、区块链、大型语言模型(LLM)、深度强化学习、网络切片、可解释人工智能(XAI)

<br /><br />总结:
本文深入分析了开放无线接入网(O-RAN)架构的安全性，探讨了不同O-RAN层次可能面临的潜在威胁及其对保密性、完整性和可用性(CIA)三元组的影响。文章提出零信任、移动目标防御(MTD)、区块链和大型语言模型(LLM)技术可用于增强O-RAN的安全态势。此外，文中通过数值演示展示了MTD如何赋能动态网络切片接纳控制中的鲁棒深度强化学习方法。同时，文章还研究了基于LLM的可解释人工智能(XAI)在保障系统安全性方面的作用。 <div>
arXiv:2411.08640v1 Announce Type: new 
Abstract: The evolution of wireless communication systems will be fundamentally impacted by an open radio access network (O-RAN), a new concept defining an intelligent architecture with enhanced flexibility, openness, and the ability to slice services more efficiently. For all its promises, and like any technological advancement, O-RAN is not without risks that need to be carefully assessed and properly addressed to accelerate its wide adoption in future mobile networks. In this paper, we present an in-depth security analysis of the O-RAN architecture, discussing the potential threats that may arise in the different O-RAN architecture layers and their impact on the Confidentiality, Integrity, and Availability (CIA) triad. We also promote the potential of zero trust, Moving Target Defense (MTD), blockchain, and large language models(LLM) technologies in fortifying O-RAN's security posture. Furthermore, we numerically demonstrate the effectiveness of MTD in empowering robust deep reinforcement learning methods for dynamic network slice admission control in the O-RAN architecture. Moreover, we examine the effect of explainable AI (XAI) based on LLMs in securing the system.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking negative sampling in content-based news recommendation</title>
<link>https://arxiv.org/abs/2411.08700</link>
<guid>https://arxiv.org/abs/2411.08700</guid>
<content:encoded><![CDATA[
<div> 关键词: news recommender systems, relevance decay, neural techniques, negative sampling, decentralization

<br /><br />总结:
本文探讨了新闻推荐系统因文章时效性短暂导致的相关性衰减问题。研究发现，内容基神经技术对此有所助益，但现有模型复杂且对负例处理不足。为此，文中提出了一个新的负例采样技术，该技术能提升模型准确性并有利于推荐系统的去中心化。实验使用MIND数据集证明了所提方法的精度可与最先进的模型相媲美。此外，这种采样技术有助于降低模型复杂度、加速训练过程，并保持高精度。最后，文章还讨论了去中心化模型如何改善隐私性和可扩展性。 <div>
arXiv:2411.08700v1 Announce Type: new 
Abstract: News recommender systems are hindered by the brief lifespan of articles, as they undergo rapid relevance decay. Recent studies have demonstrated the potential of content-based neural techniques in tackling this problem. However, these models often involve complex neural architectures and often lack consideration for negative examples. In this study, we posit that the careful sampling of negative examples has a big impact on the model's outcome. We devise a negative sampling technique that not only improves the accuracy of the model but also facilitates the decentralization of the recommendation system. The experimental results obtained using the MIND dataset demonstrate that the accuracy of the method under consideration can compete with that of State-of-the-Art models. The utilization of the sampling technique is essential in reducing model complexity and accelerating the training process, while maintaining a high level of accuracy. Finally, we discuss how decentralized models can help improve privacy and scalability.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication Efficient Decentralization for Smoothed Online Convex Optimization</title>
<link>https://arxiv.org/abs/2411.08355</link>
<guid>https://arxiv.org/abs/2411.08355</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体、光滑在线凸优化、分布式算法、异步通信图、计算复杂度

总结:
本文研究了多智能体光滑在线凸优化（SOCO）问题，其中$N$个智能体通过通信图进行交互。每个轮次中，每个智能体$i$会以在线方式接收到强凸击打成本函数$f^i_t$并选择动作$x^i_t\in\mathbb{R}^d$。目标是最小化全局累积成本，包括个体击打成本之和、决策变化的“切换成本”以及相邻智能体决策偏离的“不相似性成本”。文章首次提出了一个多智能体SOOC的分布式算法并证明其渐近最优性。该算法允许每个智能体仅利用与其直接邻接节点的信息进行操作。对于有限时间性能，文章证明了竞争比的优值差随时间序列$T$减小，并可以根据每个智能体每轮可利用的计算资源进行便捷调整。此外，即使通信图可以随时间任意和自适应地改变，该方法仍然有效。最后，文章表明每轮的计算复杂度仅与智能体数量对数相关且几乎线性依赖于它们在图中的度数，确保了大系统实施的可扩展性。<br /><br /> <div>
arXiv:2411.08355v1 Announce Type: cross 
Abstract: We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where $N$ agents interact through a communication graph. In each round, each agent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online fashion and selects an action $x^i_t \in \mathbb{R}^d$. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs $f^i_t(x^i_t)$, a temporal "switching cost" for changing decisions, and a spatial "dissimilarity cost" that penalizes deviations in decisions among neighboring agents. We propose the first decentralized algorithm for multi-agent SOCO and prove its asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in competitive ratio decreases with the time horizon $T$ and can be conveniently tuned based on the per-round computation available to each agent. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, we establish that the computational complexity per round depends only logarithmically on the number of agents and almost linearly on their degree within the graph, ensuring scalability for large-system implementations.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Merit-Based Sortition in Decentralized Systems</title>
<link>https://arxiv.org/abs/2411.07302</link>
<guid>https://arxiv.org/abs/2411.07302</guid>
<content:encoded><![CDATA[
<div> 关键词：decentralized systems、sortition、performance optimization、merit-based sortition、infinite chances

总结:<br />
本文提出了一个针对分布式系统中参与者选择问题的“基于绩效的排序”（merit-based sortition）算法。该算法旨在优化计算限制或资源效率的同时，确保选出的活跃子集既具有高性能又保持代表性。与古典随机抽签相比，此算法允许每个参与者的入选概率与其质量相关联，而未被选中的参与者仍有无限次非零概率进入活跃集合，从而保证了向上流动性。通过数值实验，文章表明基于绩效的排序算法可以使活跃子集的性能指标提升超过两倍内在随机性的水平，这意味着该方法能够在显著提高表现性能的同时，满足分布式系统对于性能优化的需求。 <div>
arXiv:2411.07302v1 Announce Type: new 
Abstract: In decentralized systems, it is often necessary to select an 'active' subset of participants from the total participant pool, with the goal of satisfying computational limitations or optimizing resource efficiency. This selection can sometimes be made at random, mirroring the sortition practice invented in classical antiquity aimed at achieving a high degree of statistical representativeness. However, the recent emergence of specialized decentralized networks that solve concrete coordination problems and are characterized by measurable success metrics often requires prioritizing performance optimization over representativeness. We introduce a simple algorithm for 'merit-based sortition', in which the quality of each participant influences its probability of being drafted into the active set, while simultaneously retaining representativeness by allowing inactive participants an infinite number of chances to be drafted into the active set with non-zero probability. Using a suite of numerical experiments, we demonstrate that our algorithm boosts the quality metric describing the performance of the active set by $>2$ times the intrinsic stochasticity. This implies that merit-based sortition ensures a statistically significant performance boost to the drafted, 'active' set, while retaining the property of classical, random sortition that it enables upward mobility from a much larger 'inactive' set. This way, merit-based sortition fulfils a key requirement for decentralized systems in need of performance optimization.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Zoning of Industrial Environments with Autonomous Mobile Robots</title>
<link>https://arxiv.org/abs/2411.07382</link>
<guid>https://arxiv.org/abs/2411.07382</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主移动机器人(AMR), 分区调度算法, 均衡任务分配, 动态分区算法, 德分布式动态分区(DTZ)

<br /><br />总结:

本文提出了一种应用于制造/仓库环境中的自主移动机器人(AMR)调度算法，该算法将工作区域划分为若干个由AMR负责执行零件捡取和投放任务的分区。每个分区的任务量得到均衡分配，以确保每台AMR平等地承担任务，并能随生产波动动态调整分区布局，避免单一AMR过载。文章引入了分布式动态分区(DDZ)算法，旨在找到最优分区设计并消除中央控制单元单点故障的可能性。通过建立仿真模型对比分析了DDZ与其他动态分区算法的适应性，初步结果显示虽然DDZ的吞吐量较低，但其任务分布更为均匀。AMR总行驶距离的标准偏差降低了68.7%，即DDZ下的AMR在生产过程中行驶距离更接近，有利于现实中设计充电和维护计划，减少停机时间。文章还提供了系统运行的视频演示链接。 <div>
arXiv:2411.07382v1 Announce Type: new 
Abstract: This paper presents a scheduling algorithm that divides a manufacturing/warehouse floor into zones that an Autonomous Mobile Robot (AMR) will occupy and complete part pick-up and drop-off tasks. Each zone is balanced so that each AMR will share each task equally. These zones change over time to accommodate fluctuations in production and to avoid overloading an AMR with tasks. A decentralized dynamic zoning (DDZ) algorithm is introduced to find the optimal zone design, eliminating the possibility of single-point failure from a centralized unit. Then a simulation is built comparing the adaptability of DDZ and other dynamic zoning algorithms from previous works. Initial results show that DDZ has a much lower throughput than other dynamic zoning algorithms but DDZ can achieve a better distribution of tasks. Initial results show that DDZ had a lower standard deviation of AMR total travel distance which was 2874.7 feet less than previous works. This 68.7\% decrease in standard deviation suggests that AMRs under DDZ travel a similar distance during production. This could be useful for real-world applications by making it easier to design charging and maintenance schedules without much downtime. Video demonstration of the system working can be seen here: \url{https://youtu.be/yVi026oVD7U}
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning Client Pruning for Noisy Labels</title>
<link>https://arxiv.org/abs/2411.07391</link>
<guid>https://arxiv.org/abs/2411.07391</guid>
<content:encoded><![CDATA[
<div> 关键词: Federated Learning, Noisy Labels, ClipFL, Noise Candidacy Score, Performance Improvement

<br /><br />总结:
本文提出了一个新的Federated Learning框架——ClipFL，该框架针对边缘设备训练中存在的噪声标签问题。现有FL方法在处理高噪声水平的数据集时表现有限，而ClipFL通过引入噪声候选分数（NCS）来识别并排除具有噪声数据的客户端。它分为三个阶段：预客户端修剪以识别潜在噪声客户端并计算其NCS，客户端修剪则根据NCS排除一定比例的噪声客户端，以及后客户端修剪阶段，使用标准FL对干净客户端进行全局模型的微调。实验表明，ClipFL在各种数据集和噪声水平下都表现出准确的噪声客户端识别能力、更优的性能、更快的收敛速度以及更低的通信成本，相较于当前最先进的FL方法有显著优势。相关代码已在https://github.com/MMorafah/ClipFL上开源。 <div>
arXiv:2411.07391v1 Announce Type: new 
Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, existing FL methods often assume clean annotated datasets, impractical for resource-constrained edge devices. In reality, noisy labels are prevalent, posing significant challenges to FL performance. Prior approaches attempt label correction and robust training techniques but exhibit limited efficacy, particularly under high noise levels. This paper introduces ClipFL (Federated Learning Client Pruning), a novel framework addressing noisy labels from a fresh perspective. ClipFL identifies and excludes noisy clients based on their performance on a clean validation dataset, tracked using a Noise Candidacy Score (NCS). The framework comprises three phases: pre-client pruning to identify potential noisy clients and calculate their NCS, client pruning to exclude a percentage of clients with the highest NCS, and post-client pruning for fine-tuning the global model with standard FL on clean clients. Empirical evaluation demonstrates ClipFL's efficacy across diverse datasets and noise levels, achieving accurate noisy client identification, superior performance, faster convergence, and reduced communication costs compared to state-of-the-art FL methods. Our code is available at https://github.com/MMorafah/ClipFL.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Network Topology Design for Task Offloading in Mobile Edge Computing</title>
<link>https://arxiv.org/abs/2411.07485</link>
<guid>https://arxiv.org/abs/2411.07485</guid>
<content:encoded><![CDATA[
<div> 关键词：移动边缘计算(MEC)，网络拓扑设计，任务卸载，分布式，效率优化

总结:
本文探讨了物联网设备处理能力有限背景下，延迟敏感且计算密集型应用带来的挑战，并指出移动边缘计算（MEC）为此类问题提供了一种有前景的解决方案。然而，针对MEC的网络拓扑优化以提升计算效率的研究尚不充分。文章提出了一种新颖的、用于任务卸载的分布式网络拓扑设计策略（DNTD-TO），该策略同时考虑了拓扑设计与任务分配，并借鉴通信和传感器网络的经验，有效地构建了三层网络结构用于任务卸载，并为这些结构生成最优的任务分配方案。研究表明，相较于现有拓扑设计方法，DNTD-TO展现出了优越的性能表现。 <div>
arXiv:2411.07485v1 Announce Type: new 
Abstract: The rise of delay-sensitive yet computing-intensive Internet of Things (IoT) applications poses challenges due to the limited processing power of IoT devices. Mobile Edge Computing (MEC) offers a promising solution to address these challenges by placing computing servers close to end users. Despite extensive research on MEC, optimizing network topology to improve computational efficiency remains underexplored. Recognizing the critical role of network topology, we introduce a novel decentralized network topology design strategy for task offloading (DNTD-TO) that jointly considers topology design and task allocation. Inspired by communication and sensor networks, DNTD-TO efficiently constructs three-layered network structures for task offloading and generates optimal task allocations for these structures. Comparisons with existing topology design methods demonstrate the promising performance of our approach.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Semantic Sleuth: Identifying Ponzi Contracts via Large Language Models</title>
<link>https://arxiv.org/abs/2411.07498</link>
<guid>https://arxiv.org/abs/2411.07498</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能合约、庞氏骗局、PonziGuard、PonziSleuth、LLM

总结:
本文介绍了智能合约在区块链技术特别是去中心化金融和Web3中的重要性，但庞氏骗局的兴起对这一领域构成重大风险。现有的检测方法如PonziGuard依赖大量标注数据，难以识别新型庞氏骗局。为解决此问题，文章提出了一种新的无标注训练数据驱动的庞氏骗局智能合约检测方法——PonziSleuth。该方法利用大型语言模型（LLMs）的高级语义理解能力，通过创新的两步零样本思考提示技术分析智能合约源代码。实验结果显示，PonziSleuth在基准数据集和实际合约上的表现与现有方法相当或更优，例如使用GPT-3.5-turbo时平衡检测准确率达到96.06%。在真实环境检测中，PonziSleuth成功从Etherscan于2024年3月验证的4,597份合同中识别出15个新型庞氏骗局，具有0%的假阴性和0.29%的假阳性率，证实了其对多样化和新型庞氏骗局的检测能力，标志着利用LLMs增强区块链安全和防范金融欺诈的重要进步。 <div>
arXiv:2411.07498v1 Announce Type: new 
Abstract: Smart contracts, self-executing agreements directly encoded in code, are fundamental to blockchain technology, especially in decentralized finance (DeFi) and Web3. However, the rise of Ponzi schemes in smart contracts poses significant risks, leading to substantial financial losses and eroding trust in blockchain systems. Existing detection methods, such as PonziGuard, depend on large amounts of labeled data and struggle to identify unseen Ponzi schemes, limiting their reliability and generalizability. In contrast, we introduce PonziSleuth, the first LLM-driven approach for detecting Ponzi smart contracts, which requires no labeled training data. PonziSleuth utilizes advanced language understanding capabilities of LLMs to analyze smart contract source code through a novel two-step zero-shot chain-of-thought prompting technique. Our extensive evaluation on benchmark datasets and real-world contracts demonstrates that PonziSleuth delivers comparable, and often superior, performance without the extensive data requirements, achieving a balanced detection accuracy of 96.06% with GPT-3.5-turbo, 93.91% with LLAMA3, and 94.27% with Mistral. In real-world detection, PonziSleuth successfully identified 15 new Ponzi schemes from 4,597 contracts verified by Etherscan in March 2024, with a false negative rate of 0% and a false positive rate of 0.29%. These results highlight PonziSleuth's capability to detect diverse and novel Ponzi schemes, marking a significant advancement in leveraging LLMs for enhancing blockchain security and mitigating financial scams.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Performance Analysis of BFT Consensus for Blockchains</title>
<link>https://arxiv.org/abs/2411.07622</link>
<guid>https://arxiv.org/abs/2411.07622</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式账本、区块链、共识协议、BFT、Istanbul BFT、HotStuff、网络拓扑、 Folded-Clos、Dragonfly、定时器、分析模型、一致性时间

<br /><br />总结:
该文探讨了分布式账本中使用区块链作为底层基础设施的情况，并重点关注两种共识协议（Istanbul BFT和HotStuff）以及两种网络拓扑结构（Folded-Clos和Dragonfly）。文章提出了一种针对崩溃故障情况的分析模型，旨在研究不同共识协议在性能上的差异以及通信网络对其影响。此外，还讨论了共识协议中如何设置定时器以确保进程推进的问题。通过建立闭合形式的表达式，分析了定时器值、参与者数量、故障数和交换机数目对达成一致所需时间的影响。这些公式与仿真结果进行了验证，最后文中给出了一些此类协议分析建模的建议。 <div>
arXiv:2411.07622v1 Announce Type: new 
Abstract: Distributed ledgers are common in the industry. Some of them can use blockchains as their underlying infrastructure. A blockchain requires participants to agree on its contents. This can be achieved via a consensus protocol, and several BFT (Byzantine Fault Tolerant) protocols have been proposed for this purpose. How do these protocols differ in performance? And how is this difference affected by the communication network? Moreover, such a protocol would need a timer to ensure progress, but how should the timer be set?
  This paper presents an analytical model to address these and related issues in the case of crash faults. Specifically, it focuses on two consensus protocols (Istanbul BFT and HotStuff) and two network topologies (Folded-Clos and Dragonfly). The model provides closed-form expressions for analyzing how the timer value and number of participants, faults and switches affect the consensus time. The formulas and analyses are validated with simulations. The conclusion offers some tips for analytical modeling of such protocols.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>SoliDiffy: AST Differencing for Solidity Smart Contracts</title>
<link>https://arxiv.org/abs/2411.07718</link>
<guid>https://arxiv.org/abs/2411.07718</guid>
<content:encoded><![CDATA[
<div> 关键词: Solidity、智能合约、抽象语法树(AST)、差异分析、SoliDiffy

总结:
本文介绍了SoliDiffy，这是一种专为Solidity智能合约设计的新颖的抽象语法树(AST)差异工具。SoliDiffy能够生成准确且简洁的编辑脚本，从而实现对智能合约的细粒度分析和维护，适用于漏洞检测、自动化代码修复以及代码审查等下游任务。通过对大量真实世界的Solidity合同进行综合评估，结果显示SoliDiffy相比于现有最先进的工具能提供更短且更精确的编辑脚本，并在处理复杂的合同修改时表现出一致性。SoliDiffy已在https://github.com/mojtaba-eshghie/SoliDiffy上公开发布。 <div>
arXiv:2411.07718v1 Announce Type: new 
Abstract: Smart contracts, primarily written in Solidity, are integral to blockchain software applications, yet precise analysis and maintenance are hindered by the limitations of existing differencing tools. We introduce SoliDiffy, a novel Abstract Syntax Tree (AST) differencing tool specifically designed for Solidity. SoliDiffy enables fine-grained analysis by generating accurate and concise edit scripts of smart contracts, making it ideal for downstream tasks such as vulnerability detection, automated code repair, and code reviews. Our comprehensive evaluation on a large dataset of real-world Solidity contracts demonstrates that SoliDiffy delivers shorter and more precise edit scripts compared to state-of-the-art tools, while performing consistently in complex contract modifications. SoliDiffy is made publicly available at https://github.com/mojtaba-eshghie/SoliDiffy.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>ALANINE: A Novel Decentralized Personalized Federated Learning For Heterogeneous LEO Satellite Constellation</title>
<link>https://arxiv.org/abs/2411.07752</link>
<guid>https://arxiv.org/abs/2411.07752</guid>
<content:encoded><![CDATA[
<div> 关键词：低地球轨道卫星星座、数据异质性、联邦学习、模型压缩、图像超分辨率

总结:<br />
针对近年来低地球轨道(LEO)卫星星座在通信、导航和遥感等领域功能增强所面临的挑战，尤其是数据异质性及有效进行星际协同计算的问题，本文提出了一种名为ALANINE的新颖分布式个性化联邦学习框架。ALANINE利用分布式联邦学习(DFL)对卫星图像进行超分辨率处理，提升输入数据质量；再结合个性化联邦学习(PFL)，以适应卫星数据的独特特性。同时，该框架采用高级模型压缩技术优化模型复杂度和传输效率。实验结果表明，相较于传统的集中式方法，ALANINE在轨训练图像超分辨率及PFL图像处理模型方面表现出更优性能，显著提高了数据采集效率、处理精度以及模型对局部卫星条件的适应性。 <div>
arXiv:2411.07752v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite constellations have seen significant growth and functional enhancement in recent years, which integrates various capabilities like communication, navigation, and remote sensing. However, the heterogeneity of data collected by different satellites and the problems of efficient inter-satellite collaborative computation pose significant obstacles to realizing the potential of these constellations. Existing approaches struggle with data heterogeneity, varing image resolutions, and the need for efficient on-orbit model training. To address these challenges, we propose a novel decentralized PFL framework, namely, A Novel Decentra L ized Person A lized Federated Learning for Heteroge N eous LEO Satell I te Co N st E llation (ALANINE). ALANINE incorporates decentralized FL (DFL) for satellite image Super Resolution (SR), which enhances input data quality. Then it utilizes PFL to implement a personalized approach that accounts for unique characteristics of satellite data. In addition, the framework employs advanced model pruning to optimize model complexity and transmission efficiency. The framework enables efficient data acquisition and processing while improving the accuracy of PFL image processing models. Simulation results demonstrate that ALANINE exhibits superior performance in on-orbit training of SR and PFL image processing models compared to traditional centralized approaches. This novel method shows significant improvements in data acquisition efficiency, process accuracy, and model adaptability to local satellite conditions.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enabling Data Confidentiality with Public Blockchains</title>
<link>https://arxiv.org/abs/2308.03791</link>
<guid>https://arxiv.org/abs/2308.03791</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、自动化、多党合作、隐私保护、MARTSIA

<br /><br />总结:
本文提出了一个名为MARTSIA的多权威交易系统方法，用于实现不同应用间的互操作性。该方法基于Multi-Authority Attribute-Based Encryption（MA-ABE），解决了公共区块链中数据透明度与企业保密要求之间的矛盾，通过用户定义的策略控制对共享数据的部分访问权限，仅允许具有特定属性的参与者解读加密信息，同时确保网络中所有节点能验证数据的发布。文章对MARTSIA的安全性进行了形式化分析，并在多个区块链平台上实现了概念证明。为了展示其实现多 party 过程执行和跨平台互操作性的能力，文中还以NFT市场、供应链和零售领域的三个实际应用场景为例进行了演示。 <div>
arXiv:2308.03791v5 Announce Type: replace 
Abstract: Blockchain technology is apt to facilitate the automation of multi-party cooperations among various players in a decentralized setting, especially in cases where trust among participants is limited. Transactions are stored in a ledger, a replica of which is retained by every node of the blockchain network. The operations saved thereby are thus publicly accessible. While this aspect enhances transparency, reliability, and persistence, it hinders the utilization of public blockchains for process automation as it violates typical confidentiality requirements in corporate settings. To overcome this issue, we propose our approach named Multi-Authority Approach to Transaction Systems for Interoperating Applications (MARTSIA). Based on Multi-Authority Attribute-Based Encryption (MA-ABE), MARTSIA enables read-access control over shared data at the level of message parts. User-defined policies determine whether an actor can interpret the publicly stored information or not, depending on the actor's attributes declared by a consortium of certifiers. Still, all nodes in the blockchain network can attest to the publication of the (encrypted) data. We provide a formal analysis of the security guarantees of MARTSIA, and illustrate the proof-of-concept implementation over multiple blockchain platforms. To demonstrate its interoperability, we showcase its usage in ensemble with a state-of-the-art blockchain-based engine for multi-party process execution, and three real-world decentralized applications in the context of NFT markets, supply chain, and retail.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers</title>
<link>https://arxiv.org/abs/2411.06135</link>
<guid>https://arxiv.org/abs/2411.06135</guid>
<content:encoded><![CDATA[
<div> 关键词：在线多任务学习(OMTL)，梯度下降法，交替方向乘子法(ADMM)，分布式计算，数据规模

总结:
本文提出了一种基于交替方向乘子方法(ADMM)的新型在线多任务学习(OMTL)框架，旨在解决现有梯度下降法在OMTL中可能遇到的梯度消失和条件恶化问题，并适应在线并行优化的需求。该框架动态建模多个任务之间的关系，以适应不断变化的在线环境。在具有中央服务器的经典分布式计算架构下，利用ADMM优化器的OMTL算法在准确性和效率上优于基于SGD的方法。为进一步应对大数据场景下的中央服务器瓶颈问题，文章还针对去中心化设置调整了算法，使得每个节点仅需与其局部邻居交换信息即可工作。实验证实在合成数据集及几个真实世界数据集上的实验结果表明了所提方法的有效性。 <div>
arXiv:2411.06135v1 Announce Type: new 
Abstract: Online multi-task learning (OMTL) enhances streaming data processing by leveraging the inherent relations among multiple tasks. It can be described as an optimization problem in which a single loss function is defined for multiple tasks. Existing gradient-descent-based methods for this problem might suffer from gradient vanishing and poor conditioning issues. Furthermore, the centralized setting hinders their application to online parallel optimization, which is vital to big data analytics. Therefore, this study proposes a novel OMTL framework based on the alternating direction multiplier method (ADMM), a recent breakthrough in optimization suitable for the distributed computing environment because of its decomposable and easy-to-implement nature. The relations among multiple tasks are modeled dynamically to fit the constant changes in an online scenario. In a classical distributed computing architecture with a central server, the proposed OMTL algorithm with the ADMM optimizer outperforms SGD-based approaches in terms of accuracy and efficiency. Because the central server might become a bottleneck when the data scale grows, we further tailor the algorithm to a decentralized setting, so that each node can work by only exchanging information with local neighbors. Experimental results on a synthetic and several real-world datasets demonstrate the efficiency of our methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Sharded Blockchain-Based Secure Federated Learning Framework for LEO Satellite Networks</title>
<link>https://arxiv.org/abs/2411.06137</link>
<guid>https://arxiv.org/abs/2411.06137</guid>
<content:encoded><![CDATA[
<div> 关键词：Low Earth Orbit (LEO)，卫星网络，人工智能，网络安全，区块链，联邦学习，SBFL-LEO，模型验证，攻击防御

总结:<br />
随着低地球轨道(LEO)卫星网络在空间人工智能应用中的重要性日益增强，其面临来自卫星间通信链接的网络安全风险也随之增加。传统解决方案无法有效应对有限通信窗口条件下的安全挑战。为此，本文提出了基于分片区块链的LEO卫星网络联邦学习框架SBFL-LEO。该框架利用区块链技术强化卫星间的通信可靠性，并为每颗卫星分配特定角色。矿工卫星通过余弦相似性和DBSCAN算法识别恶意模型并互相监控，以检测不准确的聚合模型。安全分析和实验结果显示，与基线方法相比，SBFL-LEO在模型精度和能效方面表现出优越性能，显著提升了系统对抗攻击的鲁棒性。 <div>
arXiv:2411.06137v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite networks are increasingly essential for space-based artificial intelligence (AI) applications. However, as commercial use expands, LEO satellite networks face heightened cyberattack risks, especially through satellite-to-satellite communication links, which are more vulnerable than ground-based connections. As the number of operational satellites continues to grow, addressing these security challenges becomes increasingly critical. Traditional approaches, which focus on sending models to ground stations for validation, often overlook the limited communication windows available to LEO satellites, leaving critical security risks unaddressed. To tackle these challenges, we propose a sharded blockchain-based federated learning framework for LEO networks, called SBFL-LEO. This framework improves the reliability of inter-satellite communications using blockchain technology and assigns specific roles to each satellite. Miner satellites leverage cosine similarity (CS) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to identify malicious models and monitor each other to detect inaccurate aggregated models. Security analysis and experimental results demonstrate that our approach outperforms baseline methods in both model accuracy and energy efficiency, significantly enhancing system robustness against attacks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>BM-PAW: A Profitable Mining Attack in the PoW-based Blockchain System</title>
<link>https://arxiv.org/abs/2411.06187</link>
<guid>https://arxiv.org/abs/2411.06187</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、PoW、挖矿攻击、BM-PAW、对策

总结:
<br />
本文介绍了针对PoW区块链系统的新型挖矿策略——BM-PAW，该策略允许攻击者和目标矿池获得比现有最先进的挖矿攻击（PAW）更大的收益。通过分析，发现BM-PAW攻击者有动力向其他目标提供适当的贿赂，以使这些目标遵循其指令。进一步研究了在两池BM-PAW博弈场景中，攻击者如何通过其挖矿算力来规避“矿工困境”的均衡分析。最后，文章提出了应对这类新型矿池攻击的实际对策。 <div>
arXiv:2411.06187v1 Announce Type: new 
Abstract: Mining attacks enable an adversary to procure a disproportionately large portion of mining rewards by deviating from honest mining practices within the PoW-based blockchain system. In this paper, we demonstrate that the security vulnerabilities of PoW-based blockchain extend beyond what these mining attacks initially reveal. We introduce a novel mining strategy, named BM-PAW, which yields superior rewards for both the attacker and the targeted pool compared to the state-of-the-art mining attack: PAW. Our analysis reveals that BM-PAW attackers are incentivized to offer appropriate bribe money to other targets, as they comply with the attacker's directives upon receiving payment. We find the BM-PAW attacker can circumvent the "miner's dilemma" through equilibrium analysis in a two-pool BM-PAW game scenario, wherein the outcome is determined by the attacker's mining power. We finally propose practical countermeasures to mitigate these novel pool attacks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation</title>
<link>https://arxiv.org/abs/2411.06221</link>
<guid>https://arxiv.org/abs/2411.06221</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、智能合约、安全挑战、LLM、Smart-LLaMA

总结:
随着区块链技术的迅速发展，智能合约安全性成为一个重大挑战。现有智能合约漏洞检测方法面临三大问题：数据集质量不足，缺乏详细解释和精确漏洞位置信息；大型语言模型（LLMs）对智能合约领域的适应性有限，因为大多数LLMs仅在通用文本数据上预训练而缺少智能合约特定的数据；对于检测到的漏洞缺乏高质量的解释，现有方法只关注检测而非清晰解释。为解决这些问题，文章提出了基于LLaMA语言模型的高级检测方法Smart-LLaMA。首先，构建了一个涵盖四种漏洞类型的全面数据集，其中包含标签、详细解释及精确漏洞位置信息。其次，引入了针对智能合约的专业持续预训练，使用原始智能合约数据使LLM能够学习智能合约的语法和语义，提升其领域适应性。此外，还提出了解释引导的微调方法，通过成对的脆弱代码及其解释对LLM进行微调，实现既检测漏洞又给出有理有据的解释。实验结果显示，Smart-LLaMA在性能上优于当前最优基线，F1分数和准确率平均分别提高了6.49%和3.78%，同时提供了可靠的解释。 <div>
arXiv:2411.06221v1 Announce Type: new 
Abstract: With the rapid development of blockchain technology, smart contract security has become a critical challenge. Existing smart contract vulnerability detection methods face three main issues: (1) Insufficient quality of datasets, lacking detailed explanations and precise vulnerability locations. (2) Limited adaptability of large language models (LLMs) to the smart contract domain, as most LLMs are pre-trained on general text data but minimal smart contract-specific data. (3) Lack of high-quality explanations for detected vulnerabilities, as existing methods focus solely on detection without clear explanations. These limitations hinder detection performance and make it harder for developers to understand and fix vulnerabilities quickly, potentially leading to severe financial losses. To address these problems, we propose Smart-LLaMA, an advanced detection method based on the LLaMA language model. First, we construct a comprehensive dataset covering four vulnerability types with labels, detailed explanations, and precise vulnerability locations. Second, we introduce Smart Contract-Specific Continual Pre-Training, using raw smart contract data to enable the LLM to learn smart contract syntax and semantics, enhancing their domain adaptability. Furthermore, we propose Explanation-Guided Fine-Tuning, which fine-tunes the LLM using paired vulnerable code and explanations, enabling both vulnerability detection and reasoned explanations. We evaluate explanation quality through LLM and human evaluation, focusing on Correctness, Completeness, and Conciseness. Experimental results show that Smart-LLaMA outperforms state-of-the-art baselines, with average improvements of 6.49% in F1 score and 3.78% in accuracy, while providing reliable explanations.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Client Contribution Normalization for Enhanced Federated Learning</title>
<link>https://arxiv.org/abs/2411.06352</link>
<guid>https://arxiv.org/abs/2411.06352</guid>
<content:encoded><![CDATA[
<div> 关键词：移动设备、联邦学习（FL）、统计异质性、局部模型、均值潜表示归一化

<br /><br />总结:
本文针对移动设备产生的分散异构数据带来的挑战，重点研究了联邦学习（FL）中的统计异质性问题。为了解决非独立同分布（non-IID）数据对FL模型收敛性和性能的影响，文章提出了一种新颖的方法，该方法利用本地训练模型导出的均值潜表示进行归一化，使服务器能够在聚合过程中估计和调整客户端贡献的差异。这一归一化策略能提升全局模型的泛化能力并缓解传统联邦平均方法的局限性。主要贡献包括：引入基于均值潜表示的归一化方案处理FL中的统计异质性；展示该方法与现有FL算法的无缝集成，可在非-IID设置中提高性能；并通过在多个多样化数据集上的广泛实验验证了该方法，结果表明在数据分布偏斜的情况下，模型准确性和一致性有显著提升。实验还涉及FedAvg、FedProx、FedBABU、FedNova、SCAFFOLD及SGDM等六种FL方案，突显了所提方法的鲁棒性。该研究通过提供一种实用且计算效率高的解决方案，推动了FL应对统计异质性的能力，有助于构建更可靠和泛化的机器学习模型。 <div>
arXiv:2411.06352v1 Announce Type: new 
Abstract: Mobile devices, including smartphones and laptops, generate decentralized and heterogeneous data, presenting significant challenges for traditional centralized machine learning models due to substantial communication costs and privacy risks. Federated Learning (FL) offers a promising alternative by enabling collaborative training of a global model across decentralized devices without data sharing. However, FL faces challenges due to statistical heterogeneity among clients, where non-independent and identically distributed (non-IID) data impedes model convergence and performance. This paper focuses on data-dependent heterogeneity in FL and proposes a novel approach leveraging mean latent representations extracted from locally trained models. The proposed method normalizes client contributions based on these representations, allowing the central server to estimate and adjust for heterogeneity during aggregation. This normalization enhances the global model's generalization and mitigates the limitations of conventional federated averaging methods. The main contributions include introducing a normalization scheme using mean latent representations to handle statistical heterogeneity in FL, demonstrating the seamless integration with existing FL algorithms to improve performance in non-IID settings, and validating the approach through extensive experiments on diverse datasets. Results show significant improvements in model accuracy and consistency across skewed distributions. Our experiments with six FL schemes: FedAvg, FedProx, FedBABU, FedNova, SCAFFOLD, and SGDM highlight the robustness of our approach. This research advances FL by providing a practical and computationally efficient solution for statistical heterogeneity, contributing to the development of more reliable and generalized machine learning models.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Will Central Bank Digital Currencies (CBDC) and Blockchain Cryptocurrencies Coexist in the Post Quantum Era?</title>
<link>https://arxiv.org/abs/2411.06362</link>
<guid>https://arxiv.org/abs/2411.06362</guid>
<content:encoded><![CDATA[
<div> 关键词: CBDCs, 区块链, 量子计算, 多方计算, 隐蔽传输<br /><br />总结:<br />
本文探讨了中央银行数字货币(CBDCs)和基于区块链的加密货币在后量子计算环境下的共存可能性。文章分析了新兴量子算法和密码技术，如多方计算(MPC)和隐蔽传输(OT)，对CBDCs及加密货币的影响。同时研究了如何使CBDCs和加密货币整合后量子密码学防御机制，以及过渡传统系统并推动新标准的广泛应用所面临的重大挑战。文中还对量子环境中的CBDC进行了全面评估，并对比了不同加密货币模型。此外，文章深入剖析了相关量子方法及其与区块链架构的接口问题。作者还考察了量子威胁对加密货币方案的重要性，并讨论了预期中量子计算进步对未来算法及其应用的影响。最后，论文得出结论：只要通过持续的协同努力解决挑战、验证解决方案并指导政策演进，长期共存是可行的。 <div>
arXiv:2411.06362v1 Announce Type: new 
Abstract: This paper explores the coexistence possibilities of Central Bank Digital Currencies (CBDCs) and blockchain-based cryptocurrencies within a post-quantum computing landscape. It examines the implications of emerging quantum algorithms and cryptographic techniques such as Multi-Party Computation (MPC) and Oblivious Transfer (OT). While exploring how CBDCs and cryptocurrencies might integrate defenses like post-quantum cryptography, it highlights the substantial hurdles in transitioning legacy systems and fostering widespread adoption of new standards. The paper includes comprehensive evaluations of CBDCs in a quantum context. It also features comparisons to alternative cryptocurrency models. Additionally, the paper provides insightful analyses of pertinent quantum methodologies. Examinations of interfaces between these methods and blockchain architectures are also included. The paper carries out considered appraisals of quantum threats and their relevance for cryptocurrency schemes. Furthermore, it features discussions of the influence of anticipated advances in quantum computing on algorithms and their applications. The paper renders the judicious conclusion that long-term coexistence is viable provided challenges are constructively addressed through ongoing collaborative efforts to validate solutions and guide evolving policies.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Bus Voltage Restoration for DC Microgrids</title>
<link>https://arxiv.org/abs/2411.06531</link>
<guid>https://arxiv.org/abs/2411.06531</guid>
<content:encoded><![CDATA[
<div> 关键词: DC微电网、电压调节、集中式控制、分布式控制、通信链接

总结:
本文介绍了一种针对DC微电网中直流母线电压调节的新方法，旨在确保可靠性并维持负载端电压稳定。现有的电压恢复技术主要依赖于中心化的二级控制层，通过通信链路对每个转换器发送校正指令。与之不同的是，该论文提出了一种局部而直接的分布式控制策略，通过在每个转换器内部增加一个基于转换器输出电流和馈线电阻的附加控制环路反馈来补偿馈线电阻导致的电压降。这种方法经仿真和硬件在环测试验证有效，消除了对通信链接的依赖，从而提高了系统可靠性和降低了网络安全威胁。 <div>
arXiv:2411.06531v1 Announce Type: new 
Abstract: Regulating the voltage of the common DC bus, also referred to as the load bus, in DC microgrids is crucial for ensuring reliability and maintaining the nominal load voltage, which is essential for protecting sensitive loads from voltage variations. Stability and reliability are thereby enhanced, preventing malfunctions and extending the lifespan of sensitive loads (e.g., electronic devices). Voltage drops are caused by resistances of feeders connecting converters to the common DC bus, resulting in a reduced DC bus voltage compared to the nominal/desired value. Existing techniques to restore this voltage in DC microgrids are mainly centralized and rely on secondary control layers. These layers sense the common DC bus voltage, compare it to the nominal value, and utilize a PI controller to send corrections via communication links to each converter. In this paper, a local and straightforward approach to restoring the bus voltage in DC microgrids is presented, ensuring regulation in a decentralized manner. Voltage drops across resistances of feeders are compensated by an additional control loop feedback within each converter, based on the converter output current and feeder resistance. The proposed approach is verified through simulation and hardware-in-the-loop results, eliminating the need for communication links and hence increasing reliability and reducing cybersecurity threats.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Next-Generation Approach to Airline Reservations: Integrating Cloud Microservices with AI and Blockchain for Enhanced Operational Performance</title>
<link>https://arxiv.org/abs/2411.06538</link>
<guid>https://arxiv.org/abs/2411.06538</guid>
<content:encoded><![CDATA[
<div> 关键词: 云微服务、分布式人工智能模块、区块链技术、航空预订系统、效率安全顾客满意度

<br /><br />总结:
本文提出了一种下一代航空预订系统的设计方案，该系统融合了云微服务、分布式人工智能模块和区块链技术，旨在提升效率、数据安全性和顾客满意度。通过采用模块化和数据驱动设计方法，解决了传统预订系统在扩展性、数据完整性和服务水平方面的问题，实现了系统高可用性提升30%，性能增强40%的可扩展性提升。利用AI模块预测需求并提供个性化推荐，使客户参与度提高了25%。区块链技术的应用为交易提供了不可篡改的账本系统，降低了欺诈事件发生，提升了透明度达20%。经模拟器和机器学习评估分析，新系统的交易处理速度提高35%，系统响应时间缩短15%。此外，该系统也可应用于物流和酒店等其他高交易量行业。这项创新设计展示了先进科技将如何重塑航空预订领域，实现更高效、更安全以及更高顾客满意度的发展。 <div>
arXiv:2411.06538v1 Announce Type: new 
Abstract: This research proposes the development of a next generation airline reservation system that incorporates the Cloud microservices, distributed artificial intelligence modules and the blockchain technology to improve on the efficiency, safety and customer satisfaction. The traditional reservation systems encounter issues related to the expansion of the systems, the integrity of the data provided and the level of service offered to the customers, which is the main focus of this architecture through the modular and data centric design approaches. This will allow different operations such as reservations, payments, and customer data management among others to be performed separately thereby facilitating high availability of the system by 30% and enhancing performance of the system by 40% on its scalability. Such systems contain AI driven modules that utilize the past booking patterns along with the profile of the customer to estimate the demand and make recommendations, which increases to 25 % of customer engagement. Moreover, blockchain is effective in engaging an incorruptible ledger system for the all transactions therefore mitigating fraud incidences and increasing the clarity by 20%. The system was subjected to analysis using a simulator and using machine learning evaluations that rated it against other conventional systems. The results show that there were clear enhancements in the speed of transactions where the rates of secure data processing rose by 35%, and the system response time by 15 %. The system can also be used for other high transaction industries like logistics and hospitality. This structural design is indicative of how the use of advanced technologies will revolutionize the airline reservation sector. The implications are growing effectiveness, improvement in security and greater customer contentment.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Using Diffusion Models as Generative Replay in Continual Federated Learning -- What will Happen?</title>
<link>https://arxiv.org/abs/2411.06618</link>
<guid>https://arxiv.org/abs/2411.06618</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、连续学习（Continuous Learning）、灾难性遗忘（Catastrophic Forgetting）、非独立同分布数据（Non-IID Input Data）、扩散模型（Diffusion Model）

<br /><br />总结:
本文介绍了针对动态分布式学习环境中不断变化的数据分布所提出的连续联邦学习（CFL）任务及其挑战。为了解决其中的灾难性遗忘和非独立同分布输入数据问题，文章引入了一个名为DCFL的新框架。DCFL利用条件扩散模型在通信期间于每个本地设备生成合成的历史数据，有效缓解了动态数据分布输入带来的潜在变化。此外，文章还给出了所提CFL框架的收敛界，并通过多个数据集展示了其优越性能，证明了它在应对CFL任务复杂性方面的有效性。 <div>
arXiv:2411.06618v1 Announce Type: new 
Abstract: Federated learning (FL) has become a cornerstone in decentralized learning, where, in many scenarios, the incoming data distribution will change dynamically over time, introducing continuous learning (CL) problems. This continual federated learning (CFL) task presents unique challenges, particularly regarding catastrophic forgetting and non-IID input data. Existing solutions include using a replay buffer to store historical data or leveraging generative adversarial networks. Nevertheless, motivated by recent advancements in the diffusion model for generative tasks, this paper introduces DCFL, a novel framework tailored to address the challenges of CFL in dynamic distributed learning environments. Our approach harnesses the power of the conditional diffusion model to generate synthetic historical data at each local device during communication, effectively mitigating latent shifts in dynamic data distribution inputs. We provide the convergence bound for the proposed CFL framework and demonstrate its promising performance across multiple datasets, showcasing its effectiveness in tackling the complexities of CFL tasks.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DynaShard: Secure and Adaptive Blockchain Sharding Protocol with Hybrid Consensus and Dynamic Shard Management</title>
<link>https://arxiv.org/abs/2411.06895</link>
<guid>https://arxiv.org/abs/2411.06895</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链分片、DynaShard、动态工作负载、跨片交易、系统完整性

总结:
本文提出了一种名为DynaShard的新颖解决方案，旨在解决区块链分片技术在处理动态工作负载、确保跨片交易安全及维护系统完整性的现有挑战。DynaShard结合了自适应分片管理、混合共识机制以及高效的状态同步和争议解决协议。通过在模拟真实网络条件和交易负载的实验环境下进行性能评估，结果显示DynaShard相比FTBS方法在吞吐量、延迟和分片利用率方面表现出显著优势，特别是在高交易量和可变跨片交易比例的情况下，能将延迟降低最多42.6%，分片利用率提升高达78.77%。这些成果表明DynaShard能够在可扩展性和系统韧性方面超越现有的区块链分片方法，对于未来区块链技术的发展具有重大影响，为构建更高效、安全的分布式系统奠定了基础。

<br /><br /> <div>
arXiv:2411.06895v1 Announce Type: new 
Abstract: Blockchain sharding has emerged as a promising solution to the scalability challenges in traditional blockchain systems by partitioning the network into smaller, manageable subsets called shards. Despite its potential, existing sharding solutions face significant limitations in handling dynamic workloads, ensuring secure cross-shard transactions, and maintaining system integrity. To address these gaps, we propose DynaShard, a dynamic and secure cross-shard transaction processing mechanism designed to enhance blockchain sharding efficiency and security. DynaShard combines adaptive shard management, a hybrid consensus approach, plus an efficient state synchronization and dispute resolution protocol. Our performance evaluation, conducted using a robust experimental setup with real-world network conditions and transaction workloads, demonstrates DynaShard's superior throughput, reduced latency, and improved shard utilization compared to the FTBS method. Specifically, DynaShard achieves up to a 42.6% reduction in latency and a 78.77% improvement in shard utilization under high transaction volumes and varying cross-shard transaction ratios. These results highlight DynaShard's ability to outperform state-of-the-art sharding methods, ensuring scalable and resilient blockchain systems. We believe that DynaShard's innovative approach will significantly impact future developments in blockchain technology, paving the way for more efficient and secure distributed systems.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Multi-Agent Collaborative Manipulation for Long-Horizon Quadrupedal Pushing</title>
<link>https://arxiv.org/abs/2411.07104</link>
<guid>https://arxiv.org/abs/2411.07104</guid>
<content:encoded><![CDATA[
<div> 关键词：四足机器人、多智能体强化学习、障碍物感知、长期推动物理任务、模拟与现实世界

<br />
总结:

本文提出了一种用于多四足机器人的层次化多智能体强化学习框架，旨在提升它们在处理大型物体方面的操纵能力，特别是实现障碍物感知的长期推动物理任务。该框架包含三个控制层级：高层控制器结合RRT规划器和集中式自适应策略生成子目标；中层控制器采用分布式目标条件策略指导机器人朝这些子目标移动；而预训练的低层运动策略执行移动指令。文章通过在仿真环境中对比多个基线方法，表明所提方法成功率提高了36.0%，完成时间减少了24.5%。此外，该框架成功地使Go1机器人在真实世界中完成了如Push-Cuboid和Push-T等长期、障碍物感知的操纵任务。 <div>
arXiv:2411.07104v1 Announce Type: new 
Abstract: Recently, quadrupedal locomotion has achieved significant success, but their manipulation capabilities, particularly in handling large objects, remain limited, restricting their usefulness in demanding real-world applications such as search and rescue, construction, industrial automation, and room organization. This paper tackles the task of obstacle-aware, long-horizon pushing by multiple quadrupedal robots. We propose a hierarchical multi-agent reinforcement learning framework with three levels of control. The high-level controller integrates an RRT planner and a centralized adaptive policy to generate subgoals, while the mid-level controller uses a decentralized goal-conditioned policy to guide the robots toward these sub-goals. A pre-trained low-level locomotion policy executes the movement commands. We evaluate our method against several baselines in simulation, demonstrating significant improvements over baseline approaches, with 36.0% higher success rates and 24.5% reduction in completion time than the best baseline. Our framework successfully enables long-horizon, obstacle-aware manipulation tasks like Push-Cuboid and Push-T on Go1 robots in the real world.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2411.07161</link>
<guid>https://arxiv.org/abs/2411.07161</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-Agent Systems, decentralized group decision-making, communication dynamics, voting rules, linguistic features

总结:
本研究关注了多智能体系统在无中心化的环境中如何通过跨智能体通信和群体决策增强集体智慧。研究重点在于不同社会选择方法中的通信和决策动态，并发现适度的决策灵活性能带来更好的结果。通过对智能体间对话的语言特征进行探索，揭示了有效协作的指标，为理解和识别促进或阻碍协作的沟通模式提供了洞见。此外，文章还提出了依据语言线索确定多智能体合作最优停止点的各种方法。这些发现深化了我们对去中心化决策制定和小组讨论如何塑造多智能体协作的理解，对于构建更有效的多智能体系统环境具有启示意义。<br /><br /> <div>
arXiv:2411.07161v1 Announce Type: new 
Abstract: This study investigates the efficacy of Multi-Agent Systems in eliciting cross-agent communication and enhancing collective intelligence through group decision-making in a decentralized setting. Unlike centralized mechanisms, where a fixed hierarchy governs social choice, decentralized group decision-making allows agents to engage in joint deliberation. Our research focuses on the dynamics of communication and decision-making within various social choice methods. By applying different voting rules in various environments, we find that moderate decision flexibility yields better outcomes. Additionally, exploring the linguistic features of agent-to-agent conversations reveals indicators of effective collaboration, offering insights into communication patterns that facilitate or hinder collaboration. Finally, we propose various methods for determining the optimal stopping point in multi-agent collaborations based on linguistic cues. Our findings contribute to a deeper understanding of how decentralized decision-making and group conversation shape multi-agent collaboration, with implications for the design of more effective MAS environments.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Approaching multifractal complexity in decentralized cryptocurrency trading</title>
<link>https://arxiv.org/abs/2411.05951</link>
<guid>https://arxiv.org/abs/2411.05951</guid>
<content:encoded><![CDATA[
<div> 关键词：多尺度分形、Multifractal Detrended Fluctuation Analysis (MFDFA)、去中心化交易所、交易量、收益率

总结:
该研究使用多尺度分形分析方法(Multifractal Detrended Fluctuation Analysis, MFDFA)，针对2023年6月6日至2024年6月30日期间从Uniswap去中心化交易所Universal Router合约获取的逐笔交易数据进行分析。结果显示，尽管去中心化交易所的流动性相较于集中式交易所仍然较低，但已显现出明显的多尺度分形特征。这些多尺度分形主要源于大波动，而小波动则更像无相关噪声。值得注意的是，交易量时间序列的多尺度分形特征比收益率更为显著，并在较大事件层面观察到了两者之间的多尺度交叉相关性。 <div>
arXiv:2411.05951v1 Announce Type: cross 
Abstract: Multifractality is a concept that helps compactly grasping the most essential features of the financial dynamics. In its fully developed form, this concept applies to essentially all mature financial markets and even to more liquid cryptocurrencies traded on the centralized exchanges. A new element that adds complexity to cryptocurrency markets is the possibility of decentralized trading. Based on the extracted tick-by-tick transaction data from the Universal Router contract of the Uniswap decentralized exchange, from June 6, 2023, to June 30, 2024, the present study using Multifractal Detrended Fluctuation Analysis (MFDFA) shows that even though liquidity on these new exchanges is still much lower compared to centralized exchanges convincing traces of multifractality are already emerging on this new trading as well. The resulting multifractal spectra are however strongly left-side asymmetric which indicates that this multifractality comes primarily from large fluctuations and small ones are more of the uncorrelated noise type. What is particularly interesting here is the fact that multifractality is more developed for time series representing transaction volumes than rates of return. On the level of these larger events a trace of multifractal cross-correlations between the two characteristics is also observed.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Semantic Communication and Cooperative Tracking Control for a UAV Swarm over Wireless MIMO Fading Channels</title>
<link>https://arxiv.org/abs/2411.06136</link>
<guid>https://arxiv.org/abs/2411.06136</guid>
<content:encoded><![CDATA[
<div> 关键词：UAV Swarm, Semantic Communication, Cooperative Tracking Control, Unreliable Wireless MIMO Channels, Drift-Plus-Penalty Optimization

总结:
该文研究了一种由领导无人机和多个跟随无人机组成的无人机群的语义通信与合作跟踪控制问题。文中首先建立了考虑内部交互和无线多输入多输出（MIMO）信道不稳定性影响的无人机群动态模型。接着，将无人机功率成本纳入考量，并将通信与合作跟踪控制挑战建模为一个漂移加罚优化问题，进而导出了能根据跟踪误差成本和局部信道条件自适应调整的分布式语义架构下的最优解。通过Lyapunov漂移分析方法，确立了确保无人机群跟踪性能稳定的封闭形式充分条件。数值结果表明，所提出的方案相较于现有多种方法具有显著优势。 <div>
arXiv:2411.06136v1 Announce Type: cross 
Abstract: This paper investigates the semantic communication and cooperative tracking control for an UAV swarm comprising a leader UAV and a group of follower UAVs, all interconnected via unreliable wireless multiple-input-multiple-output (MIMO) channels. Initially, we develop a dynamic model for the UAV swarm that accounts for both the internal interactions among the cooperative follower UAVs and the imperfections inherent in the MIMO channels that interlink the leader and follower UAVs. Building on this model, we incorporate the power costs of the UAVs and formulate the communication and cooperative tracking control challenge as a drift-plus-penalty optimization problem. We then derive a closed-form optimal solution that maintains a decentralized semantic architecture, dynamically adjusting to the tracking error costs and local channel conditions within the swarm. Employing Lyapunov drift analysis, we establish closed-form sufficient conditions for the stabilization of the UAV swarm's tracking performance. Numerical results demonstrate the significant enhancements in our proposed scheme over various state-of-the-art methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Graph Condensation with Information Bottleneck Principles</title>
<link>https://arxiv.org/abs/2405.03911</link>
<guid>https://arxiv.org/abs/2405.03911</guid>
<content:encoded><![CDATA[
<div> 关键词: 图压缩，联邦学习，隐私保护，图神经网络，信息瓶颈

总结:
本文提出了一个新的研究问题——联邦图压缩，针对大规模分布式图数据场景，旨在在保护数据持有者隐私的同时，进行有效的图压缩。为解决此问题，文章提出了一种联邦图压缩框架，该框架将传统的图压缩中的梯度匹配过程分解为客户端的梯度计算和服务器端的梯度匹配，有效减轻了客户端的计算负担。然而，实验表明在联邦学习环境下，压缩过程中会持续泄露数据成员身份隐私，对此，文中创新性地引入信息瓶颈原理，在局部预训练阶段仅提取部分节点特征并在联邦训练中使用，从而有效防止会员信息泄露。实验证明，所提出的联邦图压缩框架不仅在训练过程中能较好地保护成员隐私，而且其性能与现有集中式图压缩和联邦图学习方法相比也表现出可比甚至更优的效果。 <div>
arXiv:2405.03911v2 Announce Type: replace 
Abstract: Graph condensation, which reduces the size of a large-scale graph by synthesizing a small-scale condensed graph as its substitution, has immediately benefited various graph learning tasks. However, existing graph condensation methods rely on centralized data storage, which is unfeasible for real-world decentralized data distribution, and overlook data holders' privacy-preserving requirements. To bridge the gap, we propose and study the novel problem of federated graph condensation for graph neural networks (GNNs). Specifically, we first propose a general framework for federated graph condensation, in which we decouple the typical gradient matching process for graph condensation into client-side gradient calculation and server-side gradient matching. In this way, the burdensome computation cost in client-side is largely alleviated. Besides, our empirical studies show that under the federated setting, the condensed graph will consistently leak data membership privacy, i.e., the condensed graph during the federated training can be utilized to steal the training data under the membership inference attacks (MIA). To tackle this issue, we innovatively incorporate information bottleneck principles into the federated graph condensation, which only needs to extract partial node features in one local pre-training step and utilize the features during federated training. Extensive experiments on real-world datasets demonstrate that our framework can consistently protect membership privacy during training. Meanwhile, it also achieves comparable and even superior performance against existing centralized graph condensation and federated graph learning methods.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sustainable business decision modelling with blockchain and digital twins: A survey</title>
<link>https://arxiv.org/abs/2405.12101</link>
<guid>https://arxiv.org/abs/2405.12101</guid>
<content:encoded><![CDATA[
<div> 关键词：Industry 4.0、Business Decision Modelling (BDM)、区块链、Digital Twin (DT)、可持续性

<br /><br />总结:
本文探讨了工业4.0及其未来发展将严重依赖可持续性的商业决策建模（BDM），而区块链和数字孪生（DT）技术可以加速这一进程。BDM基于模型和框架，需要通过关键识别因素、数据分析和适用于复杂业务场景的数学或计算方法进行提炼。为了从收集的数据中获取可用于BDM的行动智能，需建立确保数据透明度、安全性和可访问性的基础设施，并注重其可持续性。文章强调组织应考虑社会、经济和环境因素（基于三重底线原则），以确保整合此类基础设施时的可持续性。通过对现有研究的深入审查，定义了分类体系来评估区块链和DT的可持续性特征，并进行了详细的比较评价，揭示了这些解决方案在理念、访问控制和性能开销方面的可达性。同时提出了若干研究问题以推动进一步的研究，并结合供应链管理系统的实例展示区块链和DT与BDM之间的互操作性。 <div>
arXiv:2405.12101v2 Announce Type: replace 
Abstract: Industry 4.0 and beyond will rely heavily on sustainable Business Decision Modelling (BDM) that can be accelerated by blockchain and Digital Twin (DT) solutions. BDM is built on models and frameworks refined by key identification factors, data analysis, and mathematical or computational aspects applicable to complex business scenarios. Gaining actionable intelligence from collected data for BDM requires a carefully considered infrastructure to ensure data transparency, security, accessibility and sustainability. Organisations should consider social, economic and environmental factors (based on the triple bottom line approach) to ensure sustainability when integrating such an infrastructure. These sustainability features directly impact BDM concerning resource optimisation, stakeholder engagement, regulatory compliance and environmental impacts. To further understand these segments, taxonomies are defined to evaluate blockchain and DT sustainability features based on an in-depth review of the current state-of-the-art research. Detailed comparative evaluations provide insight into the reachability of the sustainable solution in terms of ideologies, access control and performance overheads. Several research questions are put forward to motivate further research that significantly impacts BDM. Finally, a case study based on an exemplary supply chain management system is presented to show the interoperability of blockchain and DT with BDM.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smoothed Gradient Clipping and Error Feedback for Decentralized Optimization under Symmetric Heavy-Tailed Noise</title>
<link>https://arxiv.org/abs/2310.16920</link>
<guid>https://arxiv.org/abs/2310.16920</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模机器学习、梯度裁剪、分布式优化、误差反馈机制、重尾噪声

总结:
本文针对具有重尾梯度噪声的大规模机器学习背景下，研究了带有梯度裁剪的去中心化优化问题。鉴于常规梯度裁剪在异构分布式环境中会引入偏差导致收敛性问题，文章提出了一个平滑裁剪操作员和一种结合误差反馈机制的去中心化梯度方法，该方法将裁剪操作应用在当地梯度估计与局部随机梯度之差上。在考虑对称重尾梯度噪声且不假设梯度有界的情况下，文中证明了所提方法在强凸光滑局部函数场景下能达到均方误差（MSE）收敛率为$O(1/t^\delta)$，其中$\delta \in (0, 2/5)$，指数$\delta$与高阶梯度噪声矩$\alpha > 1$的存在性无关，且由一些与条件数相关的常数下界保证。据作者所知，这是首次在未假设梯度有界的重尾噪声环境下，对于去中心化梯度裁剪提出的MSE收敛结果。实验验证了理论发现的有效性。<br /><br /> <div>
arXiv:2310.16920v3 Announce Type: replace-cross 
Abstract: Motivated by understanding and analysis of large-scale machine learning under heavy-tailed gradient noise, we study decentralized optimization with gradient clipping, i.e., in which certain clipping operators are applied to the gradients or gradient estimates computed from local nodes prior to further processing. While vanilla gradient clipping has proven effective in mitigating the impact of heavy-tailed gradient noise in non-distributed setups, it incurs bias that causes convergence issues in heterogeneous distributed settings. To address the inherent bias introduced by gradient clipping, we develop a smoothed clipping operator, and propose a decentralized gradient method equipped with an error feedback mechanism, i.e., the clipping operator is applied on the difference between some local gradient estimator and local stochastic gradient. We consider strongly convex and smooth local functions under symmetric heavy-tailed gradient noise that may not have finite moments of order greater than one. We show that the proposed decentralized gradient clipping method achieves a mean-square error (MSE) convergence rate of $O(1/t^\delta)$, $\delta \in (0, 2/5)$, where the exponent $\delta$ is independent of the existence of higher order gradient noise moments $\alpha > 1$ and lower bounded by some constant dependent on condition number. To the best of our knowledge, this is the first MSE convergence result for decentralized gradient clipping under heavy-tailed noise without assuming bounded gradient. Numerical experiments validate our theoretical findings.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>EPIC: Enhancing Privacy through Iterative Collaboration</title>
<link>https://arxiv.org/abs/2411.05167</link>
<guid>https://arxiv.org/abs/2411.05167</guid>
<content:encoded><![CDATA[
<div> 关键词：病毒序列数据、机器学习、联邦学习、隐私保护、协同优化

<br /><br />总结:

本文提出了一种名为“EPIC”的创新隐私增强迭代协作架构，该架构旨在解决在不转移原始SARS-CoV-2基因序列数据的情况下，对其序列数据谱系进行监督分类的问题。随着基因组学技术的进步和病毒序列数据量的增长，机器学习在生物信息学中的应用日益增加，但传统的集中式数据处理方式面临现实医疗场景下的挑战以及数据隐私、所有权和严格法规等问题。联邦学习作为一种解决方案，通过设立中央聚合服务器和共享全局模型，在保证数据隐私的同时提取知识。EPIC架构将网络分布式部署于本地和集中式服务器之间，致力于构建一个允许不同数据持有者合作并收敛至单一预测模型的通用去中心化优化框架。实验结果表明，隐私保护策略可以成功应用于聚合方法中，而不影响学习收敛的程度。最后，文章还指出了基于联邦学习的医疗应用方法面临的潜在问题及研究前景。 <div>
arXiv:2411.05167v1 Announce Type: new 
Abstract: Advancements in genomics technology lead to a rising volume of viral (e.g., SARS-CoV-2) sequence data, resulting in increased usage of machine learning (ML) in bioinformatics. Traditional ML techniques require centralized data collection and processing, posing challenges in realistic healthcare scenarios. Additionally, privacy, ownership, and stringent regulation issues exist when pooling medical data into centralized storage to train a powerful deep learning (DL) model. The Federated learning (FL) approach overcomes such issues by setting up a central aggregator server and a shared global model. It also facilitates data privacy by extracting knowledge while keeping the actual data private. This work proposes a cutting-edge Privacy enhancement through Iterative Collaboration (EPIC) architecture. The network is divided and distributed between local and centralized servers. We demonstrate the EPIC approach to resolve a supervised classification problem to estimate SARS-CoV-2 genomic sequence data lineage without explicitly transferring raw sequence data. We aim to create a universal decentralized optimization framework that allows various data holders to work together and converge to a single predictive model. The findings demonstrate that privacy-preserving strategies can be successfully used with aggregation approaches without materially altering the degree of learning convergence. Finally, we highlight a few potential issues and prospects for study in FL-based approaches to healthcare applications.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>DWFL: Enhancing Federated Learning through Dynamic Weighted Averaging</title>
<link>https://arxiv.org/abs/2411.05173</link>
<guid>https://arxiv.org/abs/2411.05173</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、生物信息学、数据隐私、蛋白质序列分类、深度神经网络

<br /><br />总结:
本文提出了一种基于深度前馈神经网络的增强型联邦学习方法，用于蛋白质序列分类，以解决在保护数据隐私的同时提高准确性的问题。针对联邦学习在蛋白质序列分析中的优化整合未被充分探索的情况，该研究引入了动态加权联邦学习（DWFL），这是一种根据本地模型性能指标进行权重调整的联邦学习方法，通过赋予表现优秀的模型更高的权重，构建更强大的全局模型初始版本，从而提升整体学习过程的准确性。实验使用真实世界的蛋白质序列数据集验证了DWFL的有效性，结果表明，所提出的方案显著提高了模型准确性，使联邦学习成为协作机器学习任务中更为优选、强大且注重隐私保护的方法。 <div>
arXiv:2411.05173v1 Announce Type: new 
Abstract: Federated Learning (FL) is a distributed learning technique that maintains data privacy by providing a decentralized training method for machine learning models using distributed big data. This promising Federated Learning approach has also gained popularity in bioinformatics, where the privacy of biomedical data holds immense importance, especially when patient data is involved. Despite the successful implementation of Federated learning in biological sequence analysis, rigorous consideration is still required to improve accuracy in a way that data privacy should not be compromised. Additionally, the optimal integration of federated learning, especially in protein sequence analysis, has not been fully explored. We propose a deep feed-forward neural network-based enhanced federated learning method for protein sequence classification to overcome these challenges. Our method introduces novel enhancements to improve classification accuracy. We introduce dynamic weighted federated learning (DWFL) which is a federated learning-based approach, where local model weights are adjusted using weighted averaging based on their performance metrics. By assigning higher weights to well-performing models, we aim to create a more potent initial global model for the federated learning process, leading to improved accuracy. We conduct experiments using real-world protein sequence datasets to assess the effectiveness of DWFL. The results obtained using our proposed approach demonstrate significant improvements in model accuracy, making federated learning a preferred, more robust, and privacy-preserving approach for collaborative machine-learning tasks.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discern-XR: An Online Classifier for Metaverse Network Traffic</title>
<link>https://arxiv.org/abs/2411.05184</link>
<guid>https://arxiv.org/abs/2411.05184</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse, 网络流量分类器, Discern-XR, 分段学习, FVR算法, FIA算法, 在线训练, A2R-OT算法, 实际Metaverse数据集, 性能提升, 错误率降低

总结:
本文提出了一种名为Discern-XR的专门针对Metaverse网络流量的分类器，旨在帮助ISP和路由器制造商提升Metaverse服务的质量。该方法利用分段学习，提出了Frame Vector Representation (FVR)算法和Frame Identification Algorithm (FIA)，从仅具有四个应用层特征的原始网络数据中提取关键帧相关统计信息。同时，文章还设计了一个新颖的在线训练算法A2R-OT，用于寻找准确的分类模型。此外，作者为研究贡献了一个实际的Metaverse数据集，包含了虚拟现实游戏、VR视频、VR聊天、增强现实以及混合现实等不同类型的流量样本，为业界提供了全面的基准测试资源。Discern-XR相比于现有最先进的分类器性能提升了7%，并提高了训练效率，降低了错误负例率，从而推动了Metaverse网络流量分类技术的发展，成为当前领域的最佳解决方案。 <div>
arXiv:2411.05184v1 Announce Type: new 
Abstract: In this paper, we design an exclusive Metaverse network traffic classifier, named Discern-XR, to help Internet service providers (ISP) and router manufacturers enhance the quality of Metaverse services. Leveraging segmented learning, the Frame Vector Representation (FVR) algorithm and Frame Identification Algorithm (FIA) are proposed to extract critical frame-related statistics from raw network data having only four application-level features. A novel Augmentation, Aggregation, and Retention Online Training (A2R-OT) algorithm is proposed to find an accurate classification model through online training methodology. In addition, we contribute to the real-world Metaverse dataset comprising virtual reality (VR) games, VR video, VR chat, augmented reality (AR), and mixed reality (MR) traffic, providing a comprehensive benchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while improving training efficiency and reducing false-negative rates. Our work advances Metaverse network traffic classification by standing as the state-of-the-art solution.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning</title>
<link>https://arxiv.org/abs/2411.05260</link>
<guid>https://arxiv.org/abs/2411.05260</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、Homomorphic Encryption、Quantization、Pruning、QuanCrypt-FL

总结:<br />
本文提出了一种名为QuanCrypt-FL的新颖算法，旨在解决联邦学习（Federated Learning）中的隐私保护和通信效率问题。针对联邦学习在训练和推理过程中面临的攻击风险，如梯度反演和成员资格推断，文章提出了结合低比特量化和剪枝技术的方法，以增强对攻击的防护并显著降低训练过程中的计算成本。同时，为了解决量化溢出或误差，文中还引入了均值裁剪策略。通过整合这些方法，QuanCrypt-FL构建了一个既保证隐私又能兼顾通信效率和模型准确性的FL框架。实验结果表明，QuanCrypt-FL在MNIST、CIFAR-10和CIFAR-100数据集上相比于现有方法表现出优越性能，其准确性与Vanilla-FL相当，并在加密速度、解密速度和推理速度方面分别实现了最多9倍、16倍和1.5倍的提升，训练时间最多可减少3倍，相较于BatchCrypt展现了更高的计算效率和攻击鲁棒性。 <div>
arXiv:2411.05260v1 Announce Type: new 
Abstract: Federated Learning has emerged as a leading approach for decentralized machine learning, enabling multiple clients to collaboratively train a shared model without exchanging private data. While FL enhances data privacy, it remains vulnerable to inference attacks, such as gradient inversion and membership inference, during both training and inference phases. Homomorphic Encryption provides a promising solution by encrypting model updates to protect against such attacks, but it introduces substantial communication overhead, slowing down training and increasing computational costs. To address these challenges, we propose QuanCrypt-FL, a novel algorithm that combines low-bit quantization and pruning techniques to enhance protection against attacks while significantly reducing computational costs during training. Further, we propose and implement mean-based clipping to mitigate quantization overflow or errors. By integrating these methods, QuanCrypt-FL creates a communication-efficient FL framework that ensures privacy protection with minimal impact on model accuracy, thereby improving both computational efficiency and attack resilience. We validate our approach on MNIST, CIFAR-10, and CIFAR-100 datasets, demonstrating superior performance compared to state-of-the-art methods. QuanCrypt-FL consistently outperforms existing method and matches Vanilla-FL in terms of accuracy across varying client. Further, QuanCrypt-FL achieves up to 9x faster encryption, 16x faster decryption, and 1.5x faster inference compared to BatchCrypt, with training time reduced by up to 3x.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digitalization and Virtual Assistive Systems in Tourist Mobility: Evolution, an Experience (with Observed Mistakes), Appropriate Orientations and Recommendations</title>
<link>https://arxiv.org/abs/2411.05446</link>
<guid>https://arxiv.org/abs/2411.05446</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字化、虚拟化、旅游管理、用户体验、元宇宙

总结:
本文探讨了数字化和虚拟化在包括旅游管理在内的多个领域中的活跃应用和重要性。通过一个为期7周的旅行案例研究，文章指出了当前旅游业中适宜与不足的情况，并强调了用户体验对于辅助系统及用户界面满意度验证的关键作用。同时，文章还展望了未来元宇宙在该领域发展中预期扮演的重要角色。 <div>
arXiv:2411.05446v1 Announce Type: new 
Abstract: Digitalization and virtualization are extremely active and important approaches in a large scope of activities (marketing, selling, enterprise management, logistics). Tourism management is also highly concerned by this evolution. In this paper we try to present today's situation based on a 7-week trip showing appropriate and shame situations. After this case study, we give a list of appropriate practices and orientations and confirm the fundamental role of User Experience in validating the proposed assistive system and the User Interfaces needed for client/user satisfaction. We also outline the expected role of Metaverse in the future of the evolution of this domain.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Emergent Cooperative Strategies for Multi-Agent Shepherding via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2411.05454</link>
<guid>https://arxiv.org/abs/2411.05454</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式强化学习、多智能体、牧羊控制问题、两层控制器、大规模系统

<br /><br />总结:

本文提出了一种分布式强化学习方法来解决多智能体牧羊控制问题，该问题不再假设目标群体具有凝聚力。这种方法采用双层控制架构：低层控制器引导每个牧羊者将特定目标保持在目标区域内；而高层层动态选择牧羊者应瞄准并围堵的目标。合作行为自然产生，因为牧羊者自主选择不同的目标以加速任务完成。此外，该方法还被扩展到大型系统中，其中每个牧羊者应用由少数代理训练的共享策略，同时管理一组固定的子代理。 <div>
arXiv:2411.05454v1 Announce Type: new 
Abstract: We present a decentralized reinforcement learning (RL) approach to address the multi-agent shepherding control problem, departing from the conventional assumption of cohesive target groups. Our two-layer control architecture consists of a low-level controller that guides each herder to contain a specific target within a goal region, while a high-level layer dynamically selects from multiple targets the one an herder should aim at corralling and containing. Cooperation emerges naturally, as herders autonomously choose distinct targets to expedite task completion. We further extend this approach to large-scale systems, where each herder applies a shared policy, trained with few agents, while managing a fixed subset of agents.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Network EM Algorithm for Gaussian Mixture Model in Decentralized Federated Learning</title>
<link>https://arxiv.org/abs/2411.05591</link>
<guid>https://arxiv.org/abs/2411.05591</guid>
<content:encoded><![CDATA[
<div> 关键词：网络期望最大化（Network EM）、高斯混合模型、分布式联邦学习、动量网络EM（MNEM）、半监督MNEM（semi-MNEM）

<br /><br />总结:
本文系统研究了应用于高斯混合模型的多种网络期望最大化（EM）算法，在分布式联邦学习的框架下。针对异质数据和成分分离不良的问题，文章提出了两种创新解决方案。首先，为处理异质数据，文章引入了动量网络EM（MNEM）算法，该算法使用动量参数结合当前与历史估计器的信息。其次，为应对成分分离不良的挑战，他们开发了半监督MNEM（semi-MNEM）算法，利用部分标注的数据。理论分析表明，即使在异质场景中，当混合组件满足一定的分离条件时，MNEM可以实现与全样本估计器相当的统计效率。此外，semi-MNEM算法能加快MNEM算法的收敛速度，有效解决了成分分离不良情况下的数值收敛难题。通过大量的模拟和真实数据分析验证了这些理论发现。 <div>
arXiv:2411.05591v1 Announce Type: cross 
Abstract: We systematically study various network Expectation-Maximization (EM) algorithms for the Gaussian mixture model within the framework of decentralized federated learning. Our theoretical investigation reveals that directly extending the classical decentralized supervised learning method to the EM algorithm exhibits poor estimation accuracy with heterogeneous data across clients and struggles to converge numerically when Gaussian components are poorly-separated. To address these issues, we propose two novel solutions. First, to handle heterogeneous data, we introduce a momentum network EM (MNEM) algorithm, which uses a momentum parameter to combine information from both the current and historical estimators. Second, to tackle the challenge of poorly-separated Gaussian components, we develop a semi-supervised MNEM (semi-MNEM) algorithm, which leverages partially labeled data. Rigorous theoretical analysis demonstrates that MNEM can achieve statistical efficiency comparable to that of the whole sample estimator when the mixture components satisfy certain separation conditions, even in heterogeneous scenarios. Moreover, the semi-MNEM estimator enhances the convergence speed of the MNEM algorithm, effectively addressing the numerical convergence challenges in poorly-separated scenarios. Extensive simulation and real data analyses are conducted to justify our theoretical findings.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large problems are not necessarily hard: A case study on distributed NMPC paying off</title>
<link>https://arxiv.org/abs/2411.05627</link>
<guid>https://arxiv.org/abs/2411.05627</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式模型预测控制(MPC), 计算性能, 并行计算, 中心化解算器, 频率控制

总结:<br />
本文研究了分布式模型预测控制（MPC）在处理大型系统中的计算性能，特别是针对线性和非线性系统的合作型分布式MPC。文中提出了一种定制化的分散实时迭代方案应用于电力系统的频率控制。研究表明，在所考虑的线性及非线性基准测试中，分布式MPC和分布式非线性MPC（NMPC）具有良好的扩展性，因为它们所需的迭代次数并不随子系统的数量增加而增加。与多线程中心化解算器进行比较后发现，所提出的分散优化算法展现出与其竞争性的性能。 <div>
arXiv:2411.05627v1 Announce Type: cross 
Abstract: A key motivation in the development of distributed Model Predictive Control (MPC) is to widen the computational bottleneck of centralized MPC for large-scale systems. Parallelizing computations among individual subsystems, distributed MPC has the prospect of scaling well for large networks. However, the communication demand may deteriorate the performance of iterative decentralized optimization, if excessively many optimizer iterations are required per control step. Moreover, centralized solvers often exhibit faster asymptotic convergence rates and, by parallelizing costly linear algebra operations, they can also benefit from modern multi-core computing architectures. On this canvas, we study the computational performance of cooperative distributed MPC for linear and nonlinear systems. To this end, we apply a tailored decentralized real-time iteration scheme to frequency control for power systems. For the considered linear and nonlinear benchmarks, distributed MPC and distributed Nonlinear MPC (NMPC) scale well as the required number of iterations does not depend on the number of subsystems. Comparisons with multithreaded centralized solvers show competitive performance of the considered decentralized optimization algorithms.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Fast Confirmation Rule for the Ethereum Consensus Protocol</title>
<link>https://arxiv.org/abs/2405.00549</link>
<guid>https://arxiv.org/abs/2405.00549</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、确认规则、比特币、以太坊、Gasper<br /><br />总结:
本文讨论了区块链中的确认规则，特别是以太坊网络中的确认机制。现有的以太坊共识协议中采用的是FFG最终化规则（Gasper），但在异步网络条件下确认交易速度较慢，最佳情况下也需要约13至19分钟。为此，文章提出了一个新的快速确认规则，该规则基于同步网络条件，能将交易的最好情况下的确认时间缩短到仅12秒，显著提高了确认效率。因此，用户可以根据对网络条件的判断和快速响应的需求选择适合自己的确认规则。 <div>
arXiv:2405.00549v2 Announce Type: replace 
Abstract: A Confirmation Rule, within blockchain networks, refers to an algorithm implemented by network nodes that determines (either probabilistically or deterministically) the permanence of certain blocks on the blockchain. An example of Confirmation Ruble is the Bitcoin's longest chain Confirmation Rule where a block $b$ is confirmed (with high probability) when it has a sufficiently long chain of successors, its siblings have notably shorter successor chains, the majority of the network's total computation power (hashing) is controlled by honest nodes, and network synchrony holds.
  The only Confirmation Rule currently available in the Ethereum protocol, Gasper, is the FFG Finalization Rule. While this Confirmation Rule works under asynchronous network conditions, it is quite slow for many use cases. Specifically, best-case scenario, it takes around 13 to 19 min to confirm a transaction, where the actual figure depends on when the transaction is submitted to the network.
  In this work, we devise a Fast Confirmation Rule for Ethereum's consensus protocol. Our Confirmation Rule relies on synchrony conditions, but provides a best-case confirmation time of 12 seconds only, greatly improving on the latency of the FFG Finalization Rule.
  Users can then rely on the Confirmation Rule that best suits their needs depending on their belief about the network conditions and the need for a quick response.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses</title>
<link>https://arxiv.org/abs/2411.04139</link>
<guid>https://arxiv.org/abs/2411.04139</guid>
<content:encoded><![CDATA[
<div> 关键词：6G车辆元宇宙、车辆数字孪生、资源分配、无人机、学习优化算法

<br />
总结:
本文探讨了6G赋能的车辆元宇宙中，如何利用车辆数字孪生技术解决实时车联网服务面临的挑战。针对高需求的车辆数字孪生任务和地面基站有限资源的问题，文中提出采用无人机作为空中边缘服务器辅助处理这些任务。然而，由于无人机的高流动性导致与地面基站之间存在信息不对称，进而影响到资源分配效率。为了解决这一问题，文章提出了一个基于学习的改良第二价格拍卖机制，该机制考虑了任务延迟和准确性，优化了地空基站之间的资源分配。同时，设计了一种扩散式强化学习算法来优化价格调整因子，以最大化资源提供者的总剩余价值并最小化车辆数字孪生任务的延迟。仿真结果显示，所提出的扩散式改良第二价格拍卖机制相比于传统方法具有更好的资源分布性能和服务质量提升效果。 <div>
arXiv:2411.04139v1 Announce Type: new 
Abstract: The rise of 6G-enable Vehicular Metaverses is transforming the automotive industry by integrating immersive, real-time vehicular services through ultra-low latency and high bandwidth connectivity. In 6G-enable Vehicular Metaverses, vehicles are represented by Vehicle Twins (VTs), which serve as digital replicas of physical vehicles to support real-time vehicular applications such as large Artificial Intelligence (AI) model-based Augmented Reality (AR) navigation, called VT tasks. VT tasks are resource-intensive and need to be offloaded to ground Base Stations (BSs) for fast processing. However, high demand for VT tasks and limited resources of ground BSs, pose significant resource allocation challenges, particularly in densely populated urban areas like intersections. As a promising solution, Unmanned Aerial Vehicles (UAVs) act as aerial edge servers to dynamically assist ground BSs in handling VT tasks, relieving resource pressure on ground BSs. However, due to high mobility of UAVs, there exists information asymmetry regarding VT task demands between UAVs and ground BSs, resulting in inefficient resource allocation of UAVs. To address these challenges, we propose a learning-based Modified Second-Bid (MSB) auction mechanism to optimize resource allocation between ground BSs and UAVs by accounting for VT task latency and accuracy. Moreover, we design a diffusion-based reinforcement learning algorithm to optimize the price scaling factor, maximizing the total surplus of resource providers and minimizing VT task latency. Finally, simulation results demonstrate that the proposed diffusion-based MSB auction outperforms traditional baselines, providing better resource distribution and enhanced service quality for vehicular users.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenFLAME: Building a large scale federated localization and mapping service</title>
<link>https://arxiv.org/abs/2411.04271</link>
<guid>https://arxiv.org/abs/2411.04271</guid>
<content:encoded><![CDATA[
<div> 关键词: OpenFLAME、去中心化、定位服务、联邦、地图抽象

总结:
OpenFLAME 是首个提出的去中心化、联邦定位服务系统，旨在解决随着室内定位技术进步和应用拓展而产生的对可扩展到私人空间的全球化、分布式位置管理系统的需要。该系统通过链接负责特定区域定位的服务器，为应用程序提供无缝的全球视野。针对联邦定位系统中的服务发现和服务整合等挑战，OpenFLAME 利用域名系统（DNS）实现服务发现，并运用地图抽象方法来检索和合并不同地图上的位置信息。其基于真实数据的研究表明，跨越远程服务器的联邦定位具有可行性和可接受的查询延迟。为了展示系统的潜力，开发了一个适用于大型室内的增强现实导航应用，证明了OpenFLAME能够成功地支持位置为基础的应用程序运行。 <div>
arXiv:2411.04271v1 Announce Type: new 
Abstract: The widespread availability of maps has enabled the development of numerous location-based applications, including navigation, ride-sharing, fitness tracking, gaming, robotics, and augmented reality. Today, the maps that power these services are predominantly controlled by a few large corporations and mostly cover outdoor spaces. As the use of these applications expands and indoor localization technologies advance, we are seeing the need for a scalable, federated location management system that can extend into private spaces.
  We introduce OpenFLAME (Open Federated Localization and Mapping Engine), the first federated and decentralized localization service. OpenFLAME links servers that handle localization for specific regions, providing applications with a seamless global view. Creating a federated localization system poses challenges, such as discovering the appropriate servers for a region and integrating services managed by independent providers. To address these issues and ensure scalability, we leverage Domain Name System (DNS) for service discovery and implement map abstractions to retrieve and merge locations across different maps. Our trace-driven study demonstrates that federated localization across remote servers is feasible with acceptable query latencies. To highlight the potential of the system, we developed an augmented reality navigation application for a large indoor space, showing that OpenFLAME can successfully power location-based applications.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Intersections of Web3 and AI -- View in 2024</title>
<link>https://arxiv.org/abs/2411.04318</link>
<guid>https://arxiv.org/abs/2411.04318</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3、AI技术、整合、缺口、创新方法

总结:
<br />
本文通过全面回顾现有学术论文、行业报告和以太坊研究社区博客文章，概述了Web3与AI技术的交叉点、两者之间的协同效应以及对于这些技术融合可能存在的一些认识缺口。作者将焦点放在感知到的缺口上，并详细提出了一些新颖的方法，旨在促进区块链/Web3生态系统的进步。这篇论文提供的综述预计将为关注Web3与AI技术交叉领域的研究人员提供指导。 <div>
arXiv:2411.04318v1 Announce Type: new 
Abstract: This paper summarises the intersection of Web3 and AI technologies, synergies between these technologies, and gaps that we suggest exist in the conception of the possible integrations of these technologies. The summary is informed by a comprehensive literature review of current academic and industry papers, analyst reports, and Ethereum research community blogposts. We focus our contribution on the perceived gaps and detail some novel approaches that would benefit the blockchain/Web3 ecosystem. We believe that the overview presented in this paper will help guide researchers interested in the intersection of Web3 and AI technologies.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Secured Smart Grid 2.0: Exploring Security Threats, Protection Models, and Challenges</title>
<link>https://arxiv.org/abs/2411.04365</link>
<guid>https://arxiv.org/abs/2411.04365</guid>
<content:encoded><![CDATA[
<div> 关键词: 绿色转型、智能电网2.0(SG2)、通信网络、安全威胁、防御策略

<br /><br />总结:

1. 许多国家正推动能源领域的绿色转型以实现2050年碳中和目标，其中智能电网2.0 (SG2)利用数据驱动分析和通信技术提升分布式可再生能源系统的效率与可持续性。
   
2. SG2对通信网络高度依赖，但其连通性的潜在级联故障可能导致数据同步至远程控制系统受阻。

3. 文章调研了电力运营商、通信网络提供商及消费者等SG2利益相关者的安全威胁与防御策略，发现易受到变电站攻击/破坏、恶意软件/勒索软件威胁、区块链漏洞及供应链中断等问题的影响。

4. SG2中人工智能(AI)融入自主能源管理带来新挑战，如电力读数和测量传感器上对抗样本和虚假数据注入可能导致AI控制功能失效、储能错误检查混乱、电动汽车充电能量估算不准确以及点对点能源交易模型中的欺诈交易。

5. 针对未来研究，具有潜力的保护模型包括可扩展的基于区块链的模型、物理不可克隆函数、互操作性安全协议及面向分布式微电网管理的可信AI模型。 <div>
arXiv:2411.04365v1 Announce Type: new 
Abstract: Many nations are promoting the green transition in the energy sector to attain neutral carbon emissions by 2050. Smart Grid 2.0 (SG2) is expected to explore data-driven analytics and enhance communication technologies to improve the efficiency and sustainability of distributed renewable energy systems. These features are beyond smart metering and electric surplus distribution in conventional smart grids. Given the high dependence on communication networks to connect distributed microgrids in SG2, potential cascading failures of connectivity can cause disruption to data synchronization to the remote control systems. This paper reviews security threats and defense tactics for three stakeholders: power grid operators, communication network providers, and consumers. Through the survey, we found that SG2's stakeholders are particularly vulnerable to substation attacks/vandalism, malware/ransomware threats, blockchain vulnerabilities and supply chain breakdowns. Furthermore, incorporating artificial intelligence (AI) into autonomous energy management in distributed energy resources of SG2 creates new challenges. Accordingly, adversarial samples and false data injection on electricity reading and measurement sensors at power plants can fool AI-powered control functions and cause messy error-checking operations in energy storage, wrong energy estimation in electric vehicle charging, and even fraudulent transactions in peer-to-peer energy trading models. Scalable blockchain-based models, physical unclonable function, interoperable security protocols, and trustworthy AI models designed for managing distributed microgrids in SG2 are typical promising protection models for future research.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Comprehensive Review of Multimodal XR Applications, Risks, and Ethical Challenges in the Metaverse</title>
<link>https://arxiv.org/abs/2411.04508</link>
<guid>https://arxiv.org/abs/2411.04508</guid>
<content:encoded><![CDATA[
<div> 关键词：Extended Reality (XR)，Metaverse，Virtual Reality (VR)，Augmented Reality (AR)，Mixed Reality (MR)

总结:
本文是一篇关于扩展现实（XR）技术，包括虚拟现实（VR）、增强现实（AR）和混合现实（MR），及其在元宇宙应用中的范围审查。XR正在教育、医疗培训、神经心理评估等领域引发革命，并带来沉浸式体验的提升。然而，随着多模态技术如触觉、眼动追踪等的应用，XR扩张也带来了数据隐私风险、网络安全问题、身心健康挑战（如网络病态、成瘾、脱节、骚扰等）以及社会不平等影响。因此，文章强调了制定强有力的伦理框架和监管指南以应对这些风险并促进公平访问、隐私保护、自主权及心理健康的重要性。随着XR技术与人工智能日益融合，负责任的治理对于确保元宇宙及其他领域中XR安全、有益的发展至关重要。 <div>
arXiv:2411.04508v1 Announce Type: new 
Abstract: This scoping review examines the broad applications, risks, and ethical challenges associated with Extended Reality (XR) technologies, including Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), within the context of Metaverse. XR is revolutionizing fields such as immersive learning in education, medical and professional training, neuropsychological assessment, therapeutic interventions, arts, entertainment, retail, e-commerce, remote work, sports, architecture, urban planning, and cultural heritage preservation. The integration of multimodal technologies such as haptics, eye-tracking, face- and body-tracking, and brain-computer interfaces, enhances user engagement and interactivity, playing a key role in shaping the immersive experiences in the Metaverse. However, XR's expansion raises serious concerns, including data privacy risks, cybersecurity vulnerabilities, cybersickness, addiction, dissociation, harassment, bullying, and misinformation. These psychological, social, and security challenges are further complicated by intense advertising, manipulation of public opinion, and social inequality, which could disproportionately affect vulnerable individuals and social groups. This review emphasizes the urgent need for robust ethical frameworks and regulatory guidelines to address these risks while promoting equitable access, privacy, autonomy, and mental well-being. As XR technologies increasingly integrate with artificial intelligence, responsible governance is essential to ensure the safe and beneficial development of the Metaverse and the broader application of XR in enhancing human development.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
<item>
<title>RainCloud: Decentralized Coordination and Communication in Heterogeneous IoT Swarms</title>
<link>https://arxiv.org/abs/2411.04593</link>
<guid>https://arxiv.org/abs/2411.04593</guid>
<content:encoded><![CDATA[
<div> 关键词: IoT系统、计算连续体、分布式协调、蚁群优化(ACO)、随机搜索、 gossip协议、任务分配

<br /><br />总结:
本文关注物联网(IoT)系统日益增长的复杂性和规模需求，提出从云中心模型向称为“计算连续体”的去中心化IoT架构转变。这种转变带来了新的研究挑战，特别是对于分布式协调的需求。为了解决这一问题，文章提出了一种基于语义通信的方案和一种利用蚁群优化(ACO)的轻量级自适应任务分配策略。该策略与随机搜索和基于gossip协议的算法进行了比较。实验在静态和动态环境（包括设备故障）下，涉及多达一百个节点进行验证。结果显示，ACO能在最少的跳数和消息发送次数下找到匹配节点，虽然gossip协议在成功分配任务数量上表现出色，但ACO在可扩展性方面更优，因此是物联网集群中实现分布式任务协调的一种有前景的方法。 <div>
arXiv:2411.04593v1 Announce Type: new 
Abstract: The increasing volume and complexity of IoT systems demand a transition from the cloud-centric model to a decentralized IoT architecture in the so-called Computing Continuum, with no or minimal reliance on central servers. This paradigm shift, however, raises novel research concerns for decentralized coordination, calling for accurate policies. However, building such strategies is not trivial. Our work aims to relieve the DevOps engineers from this concern and propose a solution for autonomous, decentralized task allocation at runtime for IoT systems. To this end, we present a semantic communication approach and an ad-hoc lightweight coordination strategy based on Ant Colony Optimization (ACO). We compare the ACO strategy with Random Search and Gossip protocol-based algorithms. We conduct accurate experiments with up to a hundred nodes in both a static and a dynamic environment, i.e., with device outages. We show that ACO finds a matching node with the smallest hops and messages sent. While the Gossip strategy can allocate the most tasks successfully, ACO scales better, thus being a promising candidate for decentralized task coordination in IoT clusters.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
</item>
</channel>
</rss>